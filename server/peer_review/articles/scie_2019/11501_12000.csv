PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Tracking of multiple quantiles in dynamically varying data streams	PATTERN ANALYSIS AND APPLICATIONS										Dynamic environment; Incremental algorithm; Multiple quantiles; Quantile tracking		In this paper, we consider the problem of tracking multiple quantiles of dynamically varying data stream distributions. The method is based on making incremental updates of the quantile estimates every time a new sample is received. The method is memory and computationally efficient since it only stores one value for each quantile estimate and only performs one operation per quantile estimate when a new sample is received from the data stream. The estimates are realistic in the sense that the monotone property of quantiles is satisfied in every iteration. Experiments show that the method efficiently tracks multiple quantiles and outperforms state-of-the-art methods.																	1433-7541	1433-755X				FEB	2020	23	1					225	237		10.1007/s10044-019-00778-3													
J								Deep learned Inter-Channel Colored Texture Pattern: a new chromatic-texture descriptor	PATTERN ANALYSIS AND APPLICATIONS										Content-based image retrieval; ICCTP; Information retrieval; Texture descriptor	LOCAL BINARY PATTERNS; IMAGE RETRIEVAL; REPRESENTATION; CLASSIFICATION; FEATURES; SCALE	Texture is a dominant tool for feature extraction. Incorporation of inter-channel chromatic information along with the texture feature will improve the accuracy of feature extraction. This paper provides deep learned Inter-Channel Colored Texture Pattern which gives the inter-channel chromatic texture information of an image. The information is extracted individually from the co-occurrent pixel values of various channels. It affords the unique channel-wise information and its relation with neighboring pixel information of opponent space. Deep learning with convolutional neural network is applied for learning the feature based on color and texture. The experiments for content-based image retrieval are carried out on three different databases which vary in nature: CIFAR-10 dataset (DB1) (Krizhevsky in Learning multiple layers of features from tiny images, University of Toronto, 2009), Corel database (DB2) (Corel 1000 and Corel 10000 image database, ) and Facescrub dataset (DB3) (Ng and Winkler in 2014 IEEE international conference on image processing (ICIP), pp 343-347, 2014). Facescrub dataset is used for face recognition. The experimental analysis by applying this descriptor provides considerable improvement from the previous works for content-based image retrieval and face recognition.																	1433-7541	1433-755X				FEB	2020	23	1					239	251		10.1007/s10044-019-00780-9													
J								Weighted feature-task-aware regularization learner for multitask learning	PATTERN ANALYSIS AND APPLICATIONS										Multitask learning; Online learning; Weighted optimization; Sparsity	MULTIPLE TASKS; SPARSITY	Multitask learning has recently received extensive attention due to the fact that it can share knowledge between tasks and improve the collective performance leverage shared structures among the tasks to jointly build a better model for each task. However, most existing multitask learning methods only focus on selecting features across the tasks, how to enhance the sparsity of the learned variables is not taken into consideration there is little concern on how to enhance the sparsity of the learned variables. In this paper, we first present a weighted feature-task-aware regularization learning model for multitask learning in order to enhance the sparsity of the weight matrices, and then propose an online learning algorithm to train the proposed model together with theoretical guarantee. Finally, we conduct experiments to compare the resulting approach with some related methods used for multitask learning, which illustrates the efficiency of the proposed method. To verify the effectiveness of the proposed approach, extensive experiments are conducted on two widely used data for multitask learning. The encouraging performance of the proposed approach over the related methods demonstrates its superiority.																	1433-7541	1433-755X				FEB	2020	23	1					253	263		10.1007/s10044-019-00781-8													
J								Video spatiotemporal mapping for human action recognition by convolutional neural network	PATTERN ANALYSIS AND APPLICATIONS										Video spatiotemporal mapping; Convolutional neural network; Data augmentation; Human action recognition	FEATURES; TRAJECTORIES; DESCRIPTORS; HISTOGRAMS; DENSE	In this paper, a 2D representation of a video clip called video spatiotemporal map (VSTM) is presented. VSTM is a compact representation of a video clip which incorporates its spatial and temporal properties. It is created by vertical concatenation of feature vectors generated from subsequent frames. The feature vector corresponding to each frame is generated by applying wavelet transform to that frame (or its subtraction from the subsequent frame) and computing vertical and horizontal projection of quantized coefficients of some specific wavelet subbands. VSTM enables convolutional neural networks (CNNs) to process a video clip for human action recognition (HAR). The proposed approach benefits from power of CNNs to analyze visual patterns and attempts to overcome some CNN challenges such as variable video length problem and lack of training data that leads to over-fitting. VSTM presents a sequence of frames to CNN without imposing any additional computational cost to the CNN learning algorithm. The experimental results of the proposed method on the KTH, Weizmann, and UCF Sports HAR benchmark datasets have shown the supremacy of the proposed method compared with the state-of-the-art methods that used CNN to solve HAR problem.																	1433-7541	1433-755X				FEB	2020	23	1					265	279		10.1007/s10044-019-00788-1													
J								Human action recognition: a framework of statistical weighted segmentation and rank correlation-based selection	PATTERN ANALYSIS AND APPLICATIONS										Action recognition; Weighted segmentation; Feature selection; Rank correlation; Weighted KNN	FEATURES; SILHOUETTE; TEXTURE; MODEL; BAG	Human action recognition from a video sequence has received much attention lately in the field of computer vision due to its range of applications in surveillance, healthcare, smart homes, tele-immersion, to name but a few. However, it is still facing several challenges such as human variations, occlusion, change in illumination, complex background. In this article, we consider the problems related to multiple human detection and classification using novel statistical weighted segmentation and rank correlation-based feature selection approach. Initially, preprocessing is performed on a set of frames to remove existing noise and to make the foreground maximal differentiable compared to the background. A novel weighted segmentation method is also introduced for human extraction prior to feature extraction. Ternary features are exploited including color, shape, and texture, which are later combined using serial-based features fusion method. To avoid redundancy, rank correlation-based feature selection technique is employed, which acts as a feature optimizer and leads to improved classification accuracy. The proposed method is validated on six datasets including Weizmann, KTH, Muhavi, WVU, UCF sports, and MSR action and validated based on seven performance measures. A fair comparison with existing work is also provided which proves the significance of proposed compared to other techniques.																	1433-7541	1433-755X				FEB	2020	23	1					281	294		10.1007/s10044-019-00789-0													
J								ML-SLSTSVM: a new structural least square twin support vector machine for multi-label learning	PATTERN ANALYSIS AND APPLICATIONS										Multi-label learning; Support vector machine; Twin SVM; Structural SVM; Lest square SVM	NEURAL-NETWORK; CLASSIFICATION; PREDICTION	Multi-label learning (MLL) is a special supervised learning task, where any single instance possibly belongs to several classes simultaneously. Nowadays, MLL methods are increasingly required by modern applications, such as protein function classification, speech recognition and textual data classification. In this paper, a structural least square twin support vector machine (SLSTSVM) classifier for multi-label learning is presented. This proposed ML-SLSTSVM focuses on the cluster-based structural information of the corresponding class in each optimization problem, which is vital for designing a good classifier in different real-world problems. This method is extended to a nonlinear version by the kernel trick. Experimental results demonstrate that proposed method is superior in generalization performance to other classifiers.																	1433-7541	1433-755X				FEB	2020	23	1					295	308		10.1007/s10044-019-00779-2													
J								Face detection based on evolutionary Haar filter	PATTERN ANALYSIS AND APPLICATIONS										Objects seeking; Haar filters; AdaBoost; Convolutional neural network (CNN ); Evolutionary algorithms	FEATURES; CASCADE	Face detection is considered to be one of the principal techniques of biometrics. Several methods for face detection have been proposed and described in the literature, but the Viola and Jones method is one of the most prominent. This method is based on the principle of Haar filters. In this study, we propose a new type of Haar filter called a dispersed Haar filter. This new structure provides more flexibility for very complex geometry, such as the human face. To create the structure of the filter, we used three optimizations methods: differential evolution (DE), genetic algorithm (GA), and particle swarm optimization (PSO). To test our approaches rigorously, we performed two types of tests. The first test is facial detection on fixed images from three different databases (Caltech 10K, FDDB, and CMU-MIT), which presents a significant challenge. The second test is more efficient and involves the recognition of human faces from a video database. For our experiment, we used a YouTube celebrity dataset. This system consists of two stages: Face detection using three detectors: Haar-DE, Haar-PSO, and Haar-GA. Face recognition using three machine-learning algorithms: multilayer perceptron (MLP), support vector machine (SVM), and convolutional neural network (CNN) with multi-scale images. The proposed Haar-DE algorithm demonstrates good detection performance on several databases compared with the state-of-the-art methods.																	1433-7541	1433-755X				FEB	2020	23	1					309	330		10.1007/s10044-019-00784-5													
J								Automatic grayscale image segmentation based on Affinity Propagation clustering	PATTERN ANALYSIS AND APPLICATIONS										Affinity Propagation; Cluster analysis; Clustering validity index; Image segmentation	FUZZY C-MEANS; LOCAL INFORMATION; VALIDITY INDEX; ALGORITHM	Image segmentation is an important research subject in the field of image analysis and pattern recognition. Based on the affinity propagation (AP) clustering algorithm, an automatic segmentation method is proposed for grayscale images. The AP algorithm is used for image segmentation to avoid the choice of initial clustering centers and enhance the stability of the segmentation results, and a new index is proposed to analyze the validity of segmentation results and determine the optimal number of segments. Moreover, gray values instead of pixels in gray space are clustered as the dataset to decrease the time complexity of the similarity matrix and validity analysis. Theoretical analysis and experimental results demonstrate the effectiveness of the proposed index and method.																	1433-7541	1433-755X				FEB	2020	23	1					331	348		10.1007/s10044-019-00785-4													
J								Correlation maximization machine for multi-modalities multiclass classification	PATTERN ANALYSIS AND APPLICATIONS										Maximum correlation; Randomized nonlinear features; Multimodal classification; Multiclass classification		Support vector machine (SVM) learns the maximum margin to separate training examples that belong to two classes and has been widely used in many pattern recognition tasks due to its high effectiveness. However, conventional SVM suffers from the following deficiencies: (1) SVM cannot take full advantage of multiple modalities in a dataset if they are available, and (2) SVM trains the marginal hyper-plane by solving the quadratic programming problem, and thus costs too much computational overheads. In this paper, we propose a correlation maximization machine (CMM) model to overcome the aforementioned deficiencies by integrating two modalities in a dataset to boost the classification performance and utilizing randomized nonlinear features to output labels from multiple classes. In particular, CMM reveals the nonlinear relationships among both modalities by generating randomized nonlinear features for each modality. CMM learns to project these features into a common subspace with a constraint that their coefficients are highly correlated, and narrows the gap between the coefficients of both modalities and the class indicator of each training example to deal with multiclass classification problem. At the classification stage, CMM indicates the classes of a test example by using the summation of its coefficients of both modalities. Since the objective function of CMM is non-convex, it is quite difficult to obtain the global minimum. In this paper, we developed a block coordinate descent-based algorithm to optimize CMM and theoretically proved its convergence to a local minimum. Experimental results of face recognition on three popular face image datasets and experimental results of image retrieval on CIFAR-10, NUS-Wide, and Wikipedia datasets demonstrate that CMM outperforms the representative methods.																	1433-7541	1433-755X				FEB	2020	23	1					349	358		10.1007/s10044-019-00795-2													
J								Entropy-based multi-view matrix completion for clustering with side information	PATTERN ANALYSIS AND APPLICATIONS										Multi-view clustering; Fuzzy membership; Matrix completion	CLASSIFICATION	Multi-view clustering aims to group multi-view samples into different clusters based on the similarity. Since side information can describe the relation between samples, for example, must-links and cannot-links, thus multi-view clustering with the consideration about side information along with samples can get more feasible clustering results. As a recent developed multi-view clustering approach, multi-view matrix completion (MVMC) constructs similarity matrix for each view and casts clustering into a matrix completion problem. Different from traditional multi-view clustering approaches, MVMC enforces the consistency of clustering results on different views as constraints for alternative optimization and the global optimal solution can be obtained. Although related experiments show that MVMC exhibits impressive performance, it still neglects the possibility of a sample belonging to a cluster. In this paper, we consider the possibility on the base of entropy and develop an entropy-based multi-view matrix completion for clustering with side information (EMVMC). Experiments on multi-view datasets Course, Citeseer, Cora, WebKB, NewsGroup, and Reuters validate the effectiveness of EMVMC.																	1433-7541	1433-755X				FEB	2020	23	1					359	370		10.1007/s10044-019-00797-0													
J								A novel high-performance holistic descriptor for face retrieval	PATTERN ANALYSIS AND APPLICATIONS										Face recognition; Gray-level co-occurrence matrix; Gray-level total displacement matrix; Texture extraction	LOCAL BINARY PATTERNS; LEVEL COOCCURRENCE MATRIX; RECOGNITION; INFORMATION; CLASSIFICATION; EIGENFACES; SCALE	Texture extraction-based classification has become the facto methodology applied in face recognition. Haralick feature extraction from gray-level co-occurrence matrix (GLCM) is one of the basic holistic studies that has inspired many face recognition algorithms. This paper presents a theoretically simple, yet efficient, holistic approach that utilizes the spatial relationships of the same pixel patterns occurring at different positions in an image rather than their occurrence statistics as applied in GLCM-based counterparts. The matrix holding the statistical values for the total displacement of the pixel patterns is called the gray-level total displacement matrix (GLTDM). Three approaches are proposed for feature extraction. In the first approach, classical Haralick features extraction is conducted. The second approach (D_GLTDM) utilizes the GLTDM directly as the feature vector rather than extra feature extraction process. In the last approach, principle component analysis (PCA) is used as the feature extraction method. Comprehensive simulations are conducted on images retrieved from the popular face databases, namely face94, ORL, JAFFE and Yale. The performance of the proposed method is compared with that of GLCM, local binary pattern and PCA used in the leading studies. The simulation results and their comparative analysis show that D_GLTDM exhibits promising results and outperforms the other leading methods in terms of classification accuracy.																	1433-7541	1433-755X				FEB	2020	23	1					371	383		10.1007/s10044-019-00803-5													
J								RTS-ELM: an approach for saliency-directed image segmentation with ripplet transform	PATTERN ANALYSIS AND APPLICATIONS										Ripplet transform; Trimap; Saliency map; ELM	EXTREME LEARNING-MACHINE; EXTRACTION; MODEL	In spite of great advancements in the field of computer vision in recent times, efficient identification of salient regions in an image/scene and applying the results to image segmentation are a fertile area to be explored by researchers. This paper deals with a novel approach for image segmentation called RTS-ELM which uses cues from salient region identification. Initially, salient regions of an image are identified using ripplet transform. Based on the saliency map, a trimap is generated for an image which highlights the dominant regions of an image. Using histogram analysis, the dominant pixels of foreground and background are grouped together to produce the positive and negative groups of training data. The salient regions are then segmented using the trained ELM classifier. After a rigmarole process of comparing with eleven extant approaches using three benchmark datasets, RTS-ELM is found to be an efficient method for reifying effective segmentation in different types of images with only a few errors.																	1433-7541	1433-755X				FEB	2020	23	1					385	397		10.1007/s10044-019-00800-8													
J								Real-time and robust multiple-view gender classification using gait features in video surveillance	PATTERN ANALYSIS AND APPLICATIONS										Gender classification; Gait energy image; Average gait image; Support vector machine	PROPORTION	It is common to view people in real applications walking in arbitrary directions, holding items, or wearing heavy coats. These factors are challenges in gait-based application methods, because they significantly change a person's appearance. This paper proposes a novel method for classifying human gender in real time using gait information. The use of an average gait image, rather than a gait energy image, allows this method to be computationally efficient and robust against view changes. A viewpoint model is created for automatically determining the viewing angle during the testing phase. A distance signal model is constructed to remove any areas with an attachment (carried items, worn coats) from a silhouette to reduce the interference in the resulting classification. Finally, the human gender is classified using multiple-view-dependent classifiers trained using a support vector machine. Experiment results confirm that the proposed method achieves a high accuracy of 98.8% on the CASIA Dataset B and outperforms the recent state-of-the-art methods.																	1433-7541	1433-755X				FEB	2020	23	1					399	413		10.1007/s10044-019-00802-6													
J								Single-shot 3D hand pose estimation using radial basis function networks trained on synthetic data	PATTERN ANALYSIS AND APPLICATIONS										3D hand pose estimation; Radial basis functions; Neural networks; Synthetic dataset; Hand pose regression; Iterative refinement; Depth map		In this work, we present a novel framework to perform single-shot hand pose estimation using depth data as input. The method follows a coarse to fine strategy and employs several radial basis function networks (RBFNs) that are trained on a dataset containing only synthetically generated depth maps. Thus, compared to most contemporary deep learning approaches, it does not require the laborious annotation of large, real-world datasets. At run time, an initialization RBFN is used to provide a rough estimation of the hand's 3D pose. Subsequently, several specialized RBFNs are employed to improve that initial estimation in an iterative refinement scheme. To train the RBFNs, we select a set of hand poses from a real-world sequence that are as diverse as possible. We use this representative set, along with a dense sampling of all possible rotations, as a seed to generate a large synthetic training set. The method is parallelizable, taking advantage of the inherent data parallelism of RBFNs. Furthermore, the method requires few real-world data and virtually no manual annotation. We perform a quantitative evaluation of our method on a testing sequence of our own. We also present quantitative and qualitative results on a public dataset that is commonly used to evaluate hand pose estimation and tracking methods. We show that in all cases, our approach achieves promising results. Moreover, it can achieve comparable or even faster computational performance than current deep learning approaches but on a single CPU core, i.e., without requiring GPU processing.																	1433-7541	1433-755X				FEB	2020	23	1					415	428		10.1007/s10044-019-00801-7													
J								Pore-based indexing for fingerprints acquired using high-resolution sensors	PATTERN ANALYSIS AND APPLICATIONS										Biometrics; High-resolution fingerprints; Fingerprint indexing; Pore-based features; k-means clustering	FEATURES	With the advent of high-resolution fingerprint sensors, there have been efforts to develop high-resolution fingerprint identification systems. In this paper, we present an indexing method for high-resolution fingerprints using pore-based features. In the proposed approach, the dynamic pore filtering method is employed to extract pores from high-resolution fingerprint images. The extracted pores are treated as keypoints, and a pore descriptor is computed for each of the keypoints. The pore descriptor thus obtained is used as a feature vector for indexing. Finally, a cluster-based retrieval scheme is employed for fast and effective retrieval of the candidate list. Performance of the proposed approach has been evaluated on the Hong Kong PolyU high-resolution fingerprint databases, DBI and DBII and in-house databases, IITI-HRFP and IITI-HRF. The proposed indexing approach achieves an improvement of 67%, 49%, 42% and 28% points in pre-selection error rate (for penetration rate of 10%) over the existing method that employs pore features for indexing on DBI, DBII, IITI-HRFP and IITI-HRF, respectively. Most importantly, our approach provides better performance than the state-of-the-art minutiae-based fingerprint indexing algorithm on DBI and IITI-HRFP, which contain partial fingerprints.																	1433-7541	1433-755X				FEB	2020	23	1					429	441		10.1007/s10044-019-00805-3													
J								Adaptive graph-regularized fixed rank representation for subspace segmentation	PATTERN ANALYSIS AND APPLICATIONS										Subspace segmentation; Low-rank representation; Fixed-rank representation; Graph regularizer	DIMENSIONALITY REDUCTION; FACE-RECOGNITION	Low-rank representation (LRR) has shown its great power in subspace segmentation tasks. However, by using matrix factorization skill, fixed-rank representation dominates LRR in many subspace segmentation applications. In this paper, based on the depth analyses on fixed-rank representation (FRR), we propose a new graph-regularized FRR method which is termed adaptive graph-regularized fixed-rank representation (AGFRR). Different from the existing methods which use the original data set to build the graph regularizer for a reconstruction coefficient matrix, AGFRR uses one of the matrix factor of a reconstruction matrix to construct the graph regularizer for the reconstruction matrix itself. We claim that the constructed graph regularizer can discover the manifold structure of a given data set more faithfully. Hence, AGFRR is more suitable for revealing the nonlinear subspace structures of data sets than FRR. Moreover, an optimization algorithm for solving AGFRR problem is also provided. Finally, the subspace segmentation experiments on both synthetic and real-world data sets show that AGFRR is superior to the existing LRR and FRR-related algorithms.																	1433-7541	1433-755X				FEB	2020	23	1					443	453		10.1007/s10044-019-00786-3													
J								Effect of cluster size distribution on clustering: a comparative study of k-means and fuzzy c-means clustering	PATTERN ANALYSIS AND APPLICATIONS										Clustering; Data distribution; k-means; Fuzzy c-means (FCM); Fuzzifier; Uniform effect	ALGORITHM	Data distribution has a significant impact on clustering results. This study focuses on the effect of cluster size distribution on clustering, namely the uniform effect of k-means and fuzzy c-means (FCM) clustering. We first provide some related works of k-means and FCM clustering. Then, the structure decomposition analysis of the objective functions of k-means and FCM is presented. Afterward, extensive experiments on both synthetic two-dimensional and three-dimensional data sets and real-world data sets from the UCI machine learning repository are conducted. The results demonstrate that FCM has stronger uniform effect than k-means clustering. Also, it reveals that the fuzzifier value m = 2 in FCM, which has been widely adopted in many applications, is not a good choice, particularly for data sets with great variation in cluster sizes. Therefore, for data sets with significant uneven distributions in cluster sizes, a smaller fuzzifier value is preferred for FCM clustering, and k-means clustering is a better choice compared with FCM clustering.																	1433-7541	1433-755X				FEB	2020	23	1					455	466		10.1007/s10044-019-00783-6													
J								Filter-based feature selection in the context of evolutionary neural networks in supervised machine learning	PATTERN ANALYSIS AND APPLICATIONS										Artificial neural networks; Feed-forward; Evolutionary programming; Classification; Feature selection; Filters	OPTIMIZATION; ALGORITHM	This paper presents a workbench to get simple neural classification models based on product evolutionary networks via a prior data preparation at attribute level by means of filter-based feature selection. Therefore, the computation to build the classifier is shorter, compared to a full model without data pre-processing, which is of utmost importance since the evolutionary neural models are stochastic and different classifiers with different seeds are required to get reliable results. Feature selection is one of the most common techniques for pre-processing the data within any kind of learning task. Six filters have been tested to assess the proposal. Fourteen (binary and multi-class) difficult classification data sets from the University of California repository at Irvine have been established as the test bed. An empirical study between the evolutionary neural network models obtained with and without feature selection has been included. The results have been contrasted with nonparametric statistical tests and show that the current proposal improves the test accuracy of the previous models significantly. Moreover, the current proposal is much more efficient than the previous methodology; the time reduction percentage is above 40%, on average. Our approach has also been compared with several classifiers both with and without feature selection in order to illustrate the performance of the different filters considered. Lastly, a statistical analysis for each feature selector has been performed providing a pairwise comparison between machine learning algorithms.																	1433-7541	1433-755X				FEB	2020	23	1					467	491		10.1007/s10044-019-00798-z													
J								Multi-task non-negative matrix factorization for visual object tracking	PATTERN ANALYSIS AND APPLICATIONS										Non-negative matrix factorization; Multi-task sparse learning; Alternating direction method of multipliers; Subspace learning	GLOBAL OPTIMIZATION; PARTS; MODEL	This paper proposes an online object tracking algorithm in which the object tracking is achieved by using multi-task sparse learning and non-negative matrix factorization under the particle filtering framework. The object appearance is first modeled by subspace learning to reflect the target variations across frames. Combination of non-negative components is learned from examples observed in previous frames. In order to robust tracking an object, group sparsity constraints are included to the non-negativity one. Furthermore, the alternating direction method of multipliers algorithm is employed to compute the model efficiently. Qualitative and quantitative experiments on a variety of challenging sequences show favorable performance of the proposed algorithm against state-of-the-art methods.																	1433-7541	1433-755X				FEB	2020	23	1					493	507		10.1007/s10044-019-00812-4													
J								Evaluating the websites of academic departments through SEO criteria: a hesitant fuzzy linguistic MCDM approach	ARTIFICIAL INTELLIGENCE REVIEW										AHP; Hesitant fuzzy linguistic term set; Search engine optimization; TOPSIS; Website evaluation	SEARCH ENGINE OPTIMIZATION; E-COMMERCE WEBSITES; DECISION-MAKING; QUALITY EVALUATION; MULTIPLE-CRITERIA; EVALUATION MODEL; SERVICE QUALITY; TOPSIS; AHP	Search Engine Optimization (SEO) is the process of managing web content in a manner that elevates page rankings in search engines. Among other sectors, academic world is one of the number-one categories for search based on the percentage of web traffic generated through search engine referrals. However, SEO includes a number of factors grouped into two as 'on page' and 'off page.' To obtain maximum benefit from SEO, relevant factors/criteria should be considered using multi-criteria decision making (MCDM) methods. The focus of this paper is to consider SEO criteria evaluation as a MCDM problem in which the criteria are in different priority levels and the criteria values take the form of hesitant fuzzy linguistic term sets to facilitate the elicitation of information in hesitate situations. A three-step solution approach is developed: (i) determination of 21 SEO criteria, such as page loading time, page size and meta-keyword (ii) prioritizing the criteria using hesitant fuzzy analytic hierarchy process, and (iii) ranking 70 Turkish websites of the industrial engineering departments using Technique for Order Preference by Similarity to Ideal Solution. The results show that trust flow and XML sitemap are the determinant criteria among others. Using the proposed method, web designers can approach SEO from weighted criteria perspective.																	0269-2821	1573-7462				FEB	2020	53	2					875	905		10.1007/s10462-019-09681-z													
J								A meta-heuristic proposal for inverse kinematics solution of 7-DOF serial robotic manipulator: quantum behaved particle swarm algorithm	ARTIFICIAL INTELLIGENCE REVIEW										Quantum particle swarm optimization; Inverse kinematics; 7-DOF robotic manipulator; Particle swarm optimization; Swarm algorithms	SIMULATED ANNEALING APPROACH; OPTIMIZATION	In this study, a quantum behaved particle swarm algorithm has used for inverse kinematic solution of a 7-degree-of-freedom serial manipulator and the results have been compared with other swarm techniques such as firefly algorithm (FA), particle swarm optimization (PSO) and artificial bee colony (ABC). Firstly, the DH parameters of the robot manipulator are created and transformation matrices are revealed. Afterward, the position equations are derived from these matrices. The position of the end effector of the robotic manipulator in the work space is estimated using Quantum PSO and other swarm algorithms. For this reason, a fitness function which name is Euclidian has been determined. This function calculates the difference between the actual position and the estimated position of the manipulator end effector. In this study, the algorithms have tested with two different scenarios. In the first scenario, values for a single position were obtained while values for a hundred different positions were obtained in the second scenario. In fact, the second scenario confirms the quality of the QPSO in the inverse kinematic solution by verifying the first scenario. According to the results obtained; Quantum behaved PSO has yielded results that are much more efficient than standard PSO, ABC and FA. The advantages of the improved algorithm are the short computation time, fewer iterations and the number of particles.																	0269-2821	1573-7462				FEB	2020	53	2					949	964		10.1007/s10462-019-09683-x													
J								A study on features of social recommender systems	ARTIFICIAL INTELLIGENCE REVIEW										Recommender system; Social recommender system; Cold-start; Collaborative filtering; Social networks; Information overload	NETWORK; TRUST; TAG; INFORMATION	Recommender system is an emerging field of research with the advent of World Wide Web and E-commerce. Recently, an increasing usage of social networking websites plausibly has a great impact on diverse facets of our lives in different ways. Initially, researchers used to consider recommender system and social networks as independent topics. With the passage of time, they realized the importance of merging the two to produce enhanced recommendations. The integration of recommender system with social networks produces a new system termed as social recommender system. In this study, we initially describe the concept of recommender system and social recommender system and then investigates different features of social networks that play a major role in generating effective recommendations. Each feature plays an essential role in giving good recommendations and resolving the issues of traditional recommender systems. Lastly, this paper also discusses future work in this area that can aid in enriching the quality of social recommender systems.																	0269-2821	1573-7462				FEB	2020	53	2					965	988		10.1007/s10462-019-09684-w													
J								The state of the art and taxonomy of big data analytics: view from new big data framework	ARTIFICIAL INTELLIGENCE REVIEW										Parallel and distributed computing; Big data tools; Big data analytics techniques; Domain area	MAP REDUCE SOLUTION; REAL-TIME; ATTRIBUTE REDUCTION; HIGH-PERFORMANCE; DECISION-MAKING; STREAMING DATA; EFFICIENT; MAPREDUCE; CLASSIFICATION; ARCHITECTURE	Big data has become a significant research area due to the birth of enormous data generated from various sources like social media, internet of things and multimedia applications. Big data has played critical role in many decision makings and forecasting domains such as recommendation systems, business analysis, healthcare, web display advertising, clinicians, transportation, fraud detection and tourism marketing. The rapid development of various big data tools such as Hadoop, Storm, Spark, Flink, Kafka and Pig in research and industrial communities has allowed the huge number of data to be distributed, communicated and processed. Big data applications use big data analytics techniques to efficiently analyze large amounts of data. However, choosing the suitable big data tools based on batch and stream data processing and analytics techniques for development a big data system are difficult due to the challenges in processing and applying big data. Practitioners and researchers who are developing big data systems have inadequate information about the current technology and requirement concerning the big data platform. Hence, the strengths and weaknesses of big data technologies and effective solutions for Big Data challenges are needed to be discussed. Hence, due to that, this paper presents a review of the literature that analyzes the use of big data tools and big data analytics techniques in areas like health and medical care, social networking and internet, government and public sector, natural resource management, economic and business sector. The goals of this paper are to (1) understand the trend of big data-related research and current frames of big data technologies; (2) identify trends in the use or research of big data tools based on batch and stream processing and big data analytics techniques; (3) assist and provide new researchers and practitioners to place new research activity in this domain appropriately. The findings of this study will provide insights and knowledge on the existing big data platforms and their application domains, the advantages and disadvantages of big data tools, big data analytics techniques and their use, and new research opportunities in future development of big data systems.																	0269-2821	1573-7462				FEB	2020	53	2					989	1037		10.1007/s10462-019-09685-9													
J								Can autism be catered with artificial intelligence-assisted intervention technology? A comprehensive survey	ARTIFICIAL INTELLIGENCE REVIEW										Computer aided systems (CAS); Computer vision assisted technologies (CVAT); Autism spectrum disorder (ASD); Facial expression recognition; Artificial intelligence; Virtual reality	HIGH-FUNCTIONING AUTISM; FACIAL EXPRESSION RECOGNITION; SPECTRUM DISORDERS; ASPERGER-SYNDROME; VIRTUAL ENVIRONMENTS; EMOTION RECOGNITION; SOCIAL-INTERACTION; CHILDREN; SKILLS; ADULTS	This article presents an extensive literature review of technology based intervention methodologies for individuals facing autism spectrum disorder (ASD). Reviewed methodologies include: contemporary computer aided systems, computer vision assisted technologies and virtual reality (VR) or artificial intelligence (AI)-assisted interventions. The research over the past decade has provided enough demonstrations that individuals with ASD have a strong interest in technology based interventions, which are useful in both, clinical settings as well as at home and classrooms. Despite showing great promise, research in developing an advanced technology based intervention that is clinically quantitative for ASD is minimal. Moreover, the clinicians are generally not convinced about the potential of the technology based interventions due to non-empirical nature of published results. A major reason behind this lack of acceptability is that a vast majority of studies on distinct intervention methodologies do not follow any specific standard or research design. We conclude from our findings that there remains a gap between the research community of computer science, psychology and neuroscience to develop an AI assisted intervention technology for individuals suffering from ASD. Following the development of a standardized AI based intervention technology, a database needs to be developed, to devise effective AI algorithms.																	0269-2821	1573-7462				FEB	2020	53	2					1039	1069		10.1007/s10462-019-09686-8													
J								Fall prediction using behavioural modelling from sensor data in smart homes	ARTIFICIAL INTELLIGENCE REVIEW										Prediction; Sensor data; Data analytics; Health	GAIT VELOCITY; NETWORK; SYSTEM; RISK; TRACKING; BALANCE; SPEED; INDEX	The number of methods for identifying potential fall risk is growing as the rate of elderly fallers continues to rise in the UK. Assessments for identifying risk of falling are usually performed in hospitals and other laboratory environments, however these are costly and cause inconvenience for the subject and health services. Replacing these intrusive testing methods with a passive in-home monitoring solution would provide a less time-consuming and cheaper alternative. As sensors become more readily available, machine learning models can be applied to the large amount of data they produce. This can support activity recognition, falls detection, prediction and risk determination. In this review, the growing complexity of sensor data, the required analysis, and the machine learning techniques used to determine risk of falling are explored. The current research on using passive monitoring in the home is discussed, while the viability of active monitoring using vision-based and wearable sensors is considered. Methods of fall detection, prediction and risk determination are then compared.																	0269-2821	1573-7462				FEB	2020	53	2					1071	1091		10.1007/s10462-019-09687-7													
J								Covering based multigranulation fuzzy rough sets and corresponding applications	ARTIFICIAL INTELLIGENCE REVIEW										Multigranulation rough set; Covering based fuzzy rough set; Fuzzy beta-neighborhood; Decision making	GROUP DECISION-MAKING; NEIGHBORHOOD OPERATORS; APPROXIMATION OPERATORS; GRANULATION; INFORMATION; MODELS	By combining covering based rough sets, fuzzy rough sets, and multigranulation rough sets, we introduce covering based multigranulation fuzzy rough set models by means of fuzzy beta-neighborhoods. We investigate axiomatic characterizations of covering based optimistic, pessimistic and variable precision multigranulation fuzzy rough set models. We propose coverings based alpha-optimistic (pessimistic) multigranulation fuzzy rough sets and D-optimistic (pessimistic) multigranulation fuzzy rough sets from fuzzy measures. We examine the relationships among these kinds of coverings based fuzzy rough sets. Finally, we apply the proposed models to solve problems for multi-criteria group decision-making.																	0269-2821	1573-7462				FEB	2020	53	2					1093	1126		10.1007/s10462-019-09690-y													
J								An enhanced colliding bodies optimization and its application	ARTIFICIAL INTELLIGENCE REVIEW										Meta-heuristic algorithm; Colliding bodies optimization (CBO); Teaching-learning-based optimization algorithm (TLBO); Learning strategy; Application	LEARNING-BASED OPTIMIZATION; DIFFERENTIAL EVOLUTION; DESIGN OPTIMIZATION; PARTICLE SWARM; GLOBAL OPTIMIZATION; ALGORITHM; CONTROLLER; INFORMATION; STRATEGY; CHAOS	Colliding bodies optimization (CBO) is a recently proposed algorithm, and there are no algorithm-specific parameters that should be previously determined in updating equations of bodies. CBO has been used to solve various optimization problems because of its simple structure. However, CBO suffers from low convergence speed and premature convergence. To enhance CBO's performance, a new variant named learning strategy based colliding bodies optimization (LSCBO), which is based on the learning strategy of the Teaching-learning-based optimization algorithm (TLBO), is proposed in this paper. In this method, a hybrid strategy combining the colliding process of CBO and the learning process of TLBO is proposed to generate new positions of the bodies. Compared with some other CBO variants, the guidance of the best individual is introduced to improve the convergence speed of CBO, and a random mutation method based on the historic information is designed to help bodies escape from local optima. Moreover, a new method for determining the mass of bodies is designed to avoid computation overflow. To evaluate the effectiveness of LSCBO, 47 benchmark functions and three real-world structural design problems are tested in the simulation experiments, and the results are compared with those of other well-known meta-heuristic algorithms. The statistical simulation results indicate that the performance of CBO is obviously improved by the developed method.																	0269-2821	1573-7462				FEB	2020	53	2					1127	1186		10.1007/s10462-019-09691-x													
J								Filtering techniques for channel selection in motor imagery EEG applications: a survey	ARTIFICIAL INTELLIGENCE REVIEW										Channel selection; EEG; Filter method; BCI; Motor imagery	BRAIN-COMPUTER INTERFACES; FLOATING SEARCH METHODS; CLASSIFICATION ACCURACY; MUTUAL INFORMATION; ALGORITHMS; FEATURES; SIGNALS; DESYNCHRONIZATION; IMPLEMENTATION; OPTIMIZATION	Brain computer interface (BCI) systems are used in a wide range of applications such as communication, neuro-prosthetic and environmental control for disabled persons using robots and manipulators. A typical BCI system uses different types of inputs; however, Electroencephalography (EEG) signals are most widely used due to their non-invasive EEG electrodes, portability, and cost efficiency. The signals generated by the brain while performing or imagining a motor related task [motor imagery (MI)] signals are one of the important inputs for BCI applications. EEG data is usually recorded from more than 100 locations across the brain, so efficient channel selection algorithms are of great importance to identify optimal channels related to a particular application. The main purpose of applying channel selection is to reduce computational complexity while analysing EEG signals, improve classification accuracy by reducing over-fitting, and decrease setup time. Different channel selection evaluation algorithms such as filtering, wrapper, and hybrid methods have been used for extracting optimal channel subsets by using predefined criteria. After extensively reviewing the literature in the field of EEG channel selection, we can conclude that channel selection algorithms provide a possibility to work with fewer channels without affecting the classification accuracy. In some cases, channel selection increases the system performance by removing the noisy channels. The research in the literature shows that the same performance can be achieved using a smaller channel set, with 10-30 channels in most cases. In this paper, we present a survey of recent development in filtering channel selection techniques along with their feature extraction and classification methods for MI-based EEG applications.																	0269-2821	1573-7462				FEB	2020	53	2					1207	1232		10.1007/s10462-019-09694-8													
J								Multi-agent system for microgrids: design, optimization and performance	ARTIFICIAL INTELLIGENCE REVIEW										Multi-agent systems; Microgrid; Renewable energy sources; Optimization and learning algorithms; Consensus; Performance indicators	DEMAND-SIDE-MANAGEMENT; POWER ENGINEERING APPLICATIONS; ENERGY MANAGEMENT; ECONOMIC-DISPATCH; CONTROL STRATEGY; STORAGE; CONSENSUS; OPERATION; ARCHITECTURE; RESTORATION	Smart grids are considered a promising alternative to the existing power grid, combining intelligent energy management with green power generation. Decomposed further into microgrids, these small-scaled power systems increase control and management efficiency. With scattered renewable energy resources and loads, multi-agent systems are a viable tool for controlling and improving the operation of microgrids. They are autonomous systems, where agents interact together to optimize decisions and reach system objectives. This paper presents an overview of multi-agent systems for microgrid control and management. It discusses design elements and performance issues, whereby various performance indicators and optimization algorithms are summarized and compared in terms of convergence time and performance in achieving system objectives. It is found that Particle Swarm Optimization has a good convergence time, so it is combined with other algorithms to address optimization issues in microgrids. Further, information diffusion and consensus algorithms are explored, and according to the literature, many variants of average-consensus algorithm are used to asynchronously reach an equilibrium. Finally, multi-agent system for multi-microgrid service restoration is discussed. Throughout the paper, challenges and research gaps are highlighted in each section as an opportunity for future work.																	0269-2821	1573-7462				FEB	2020	53	2					1233	1292		10.1007/s10462-019-09695-7													
J								Online AdaBoost-based methods for multiclass problems	ARTIFICIAL INTELLIGENCE REVIEW										Boosting; Multiclass; Online learning; Data streams	CONCEPT DRIFT	Boosting is a technique forged to transform a set of weak classifiers into a strong ensemble. To achieve this, the components are trained with different data samples and the hypotheses are aggregated in order to perform a better prediction. The use of boosting in online environments is a comparatively new activity, inspired by its success in offline environments, which is emerging to meet new demands. One of the challenges is to make the methods handle significant amounts of information taking into account computational constraints. This paper proposes two new online boosting methods: the first aims to perform a better weight distribution of the instances to closely match the behavior of AdaBoost.M1 whereas the second focuses on multiclass problems and is based on AdaBoost.M2. Theoretical arguments were used to demonstrate their convergence and also that both methods retain the main features of their traditional counterparts. In addition, we performed experiments to compare the accuracy as well as the memory usage of the proposed methods against other approaches using 20 well-known datasets. Results suggest that, in many different situations, the proposed algorithms maintain high accuracies, outperforming the other tested methods.																	0269-2821	1573-7462				FEB	2020	53	2					1293	1322		10.1007/s10462-019-09696-6													
J								Attribute reducts of multi-granulation information system	ARTIFICIAL INTELLIGENCE REVIEW										Rough sets; Multi-granulation; Reduct; Lower and upper approximations	MULTIGRANULATION ROUGH SETS; TEXT FEATURE-SELECTION; KRILL HERD ALGORITHM; APPROXIMATIONS; SCHEME	In recent years, more and more methods and theories of multi-granulation information systems have been explored. However, there is very limited investigation on the attribute reducts of multi-granulation rough sets. Therefore, the main objective of this paper is to draw attention to the attribute reducts of multi-granulation information system. For any subset of information system, we usually characterize it by its upper and lower approximations. In order to calculate the upper and lower approximations faster, we must reduce the redundant information of the information system. According to the preceding analysis, we first introduce three types of attribute reduct, which are called arbitrary union reduct, neighborhood union reduct and neighborhood intersection reduct, respectively. Then many basic and important results of these reducts are deeply explored. In order to apply the theories of attribute reducts to deal with practical issues, we develop three algorithms so as to compute multi-granulation upper and lower approximations. Next, we further study the interrelationships among these attribute reducts. Finally, we present a multi-granulation information system with respect to thirty students' exam scores and calculate the corresponding attribute reducts by using the algorithms listed in the paper.																	0269-2821	1573-7462				FEB	2020	53	2					1353	1371		10.1007/s10462-019-09699-3													
J								Bird swarm algorithms with chaotic mapping	ARTIFICIAL INTELLIGENCE REVIEW										Swarm intelligence; Bird swarm algorithm; Chaotic maps	BAT ALGORITHM; OPTIMIZATION; DESIGN; SELECTION	Swarm intelligence based optimization methods have been proposed by observing the movements of alive swarms such as bees, birds, cats, and fish in order to obtain a global solution in a reasonable time when mathematical models cannot be formed. However, many swarm intelligence algorithms suffer premature convergence and they may stumble in local optima. Bird swarm algorithm (BSA) is one of the most recent swarm-based methods that suffers the same problems in some situations. In order to obtain a faster convergence with high accuracy from the swarm based optimization algorithms, different methods have been utilized for balancing the exploitation and exploration. In this paper, chaos has been integrated into the standard BSA, for the first time, in order to enhance the global convergence feature by preventing premature convergence and stumbling in the local solutions. Furthermore, a new research area has been introduced for chaotic dynamics. The standard BSA and the chaotic BSAs proposed in this paper have been tested on unimodal and multimodal unconstrained benchmark functions, and on constrained real-life engineering design problems. Generally, the obtained results from the proposed novel chaotic BSAs with an appropriate chaotic map can outperform the standard BSA on benchmark functions and engineering design problems. The proposed chaotic BSAs are expected to be used effectively in many complex problems in future by integrating enhanced multi-dimensional chaotic maps, time-continuous chaotic systems, and hybrid multi-dimensional maps.																	0269-2821	1573-7462				FEB	2020	53	2					1373	1414		10.1007/s10462-019-09704-9													
J								Hybrid computational intelligence algorithms and their applications to detect food quality	ARTIFICIAL INTELLIGENCE REVIEW										Moth flame optimization; Gravitational search algorithm; Particle swarm optimization; Simple linear iterative clustering (SLIC) superpixels; K-means clustering; Multilevel clustering; Support vector machines	ELECTRONIC-NOSE; SHELF-LIFE; OPTIMIZATION; APPLES	Food security is a major problem faced today. With primitive storage facilities, especially in developing countries, it often leads to extensive losses. This work aims to develop algorithms based on vision data to assess the food quality and deploy them in food storage facilities to detect early signs of spoilage. This paper presents various segmentation techniques for finding spoilt food. Novel optimization techniques have been developed and implemented to improve K-means clustering and multilevel thresholding. A hybrid of moth flame optimization (MFO) and gravitational search algorithm (GSA) has been developed. Also, in another hybrid, particle swarm optimization (PSO) was also incorporated along with MFO and GSA. Both the hybrids performed better than the individual algorithms and the MFO-GSA-PSO hybrid performed better than the MFO-GSA hybrid on the benchmark functions. Segmented images using optimized K-means were used for feature extraction using local binary patterns (LBP). Multiclass support vector machine was used for classification which gave an accuracy of 81% for features from segmented images obtained using MFO-GSA hybrid and 83.33% for that using MFO-GSA-PSO hybrid. Results of simple linear iterative clustering superpixels for segmentation have also been discussed. The segmented clusters are then used to judge the rottenness of the food. Classification using LBP and Haralick features of the segmented image obtained using graphs over superpixels gave an accuracy of 81.7% and 78% respectively.																	0269-2821	1573-7462				FEB	2020	53	2					1415	1440		10.1007/s10462-019-09705-8													
J								A novel chaotic selfish herd optimizer for global optimization and feature selection	ARTIFICIAL INTELLIGENCE REVIEW										Selfish herd optimizer; Chaotic selfish herd optimizer; Global optimization; Feature selection; Chaos theory	ARTIFICIAL BEE COLONY; FLOWER POLLINATION ALGORITHM; PARTICLE SWARM OPTIMIZATION; GREY WOLF OPTIMIZATION; BUTTERFLY OPTIMIZATION; GENETIC ALGORITHM; FIREFLY ALGORITHM; CLASSIFICATION; MAPS	Selfish Herd Optimizer (SHO) is a recently proposed population-based metaheuristic inspired by the predatory interactions of herd and predators. It has been proved that SHO can provide competitive results in comparison to other well-known metaheuristics on various optimization problems. Like other metaheuristic algorithms, the main problem faced by the SHO is that it may easily get trapped into local optimal solutions, creating low precision and slow convergence speeds. Therefore, in order to enhance the global convergence speeds, and to obtain better performance, chaotic search have been augmented to searching process of SHO. Various chaotic maps were considered in the proposed Chaotic Selfish Herd Optimizer (CSHO) algorithm in order to replace the value of survival parameter of each searching agent which assists in controlling both exploration and exploitation. The performance of the proposed CSHO is compared with recent high performing meta-heuristics on 13 benchmark functions having unimodal and multimodal properties. Additionally the performance of CSHO as a feature selection approach is compared with various state-of-the-art feature selection approaches. The simulation results demonstrated that the chaotic maps (especially tent map) are able to significantly boost the performance of SHO. Moreover, the results clearly indicated the competency of CSHO in achieving the optimal feature subset by accomplishing maximum accuracy and a minimum number of features.																	0269-2821	1573-7462				FEB	2020	53	2					1441	1486		10.1007/s10462-019-09707-6													
J								A v-twin projection SVR with automatic accuracy adjustment	ARTIFICIAL INTELLIGENCE REVIEW										Support vector regression; Twin support vector regression; Projection axis; Projection variance; Support vectors	SUPPORT VECTOR MACHINE; REGRESSION; IMPROVEMENTS	Taking motivation from v-insensitive twin support vector regression (v-TSVR) and the projection idea, this paper proposes a novel v-twin projection support vector regression model, called v-TPSVR. This v-TPSVR, based on v-TSVR, determines the regression function through a pair of nonparallel hyperplanes solved by two smaller sized quadratic programming problems (QPPs). The proposed v-TPSVR model also can automatically optimize the parameters epsilon(1) and epsilon(2) via the user specified parameters v(1) and v(2), which is the same as v-TSVR. But different from v-TSVR, v-TPSVR seeks a projection axis in each QPP such that the variance of the projected points is minimized, so the empirical correlation coefficient between each hyperplane and the projected inputs is maximized. Although the training speed of the proposed algorithm is similar to that of other compared algorithms, it is obvious that the introduction of the projection axis makes the number of SV less than that of v-TSVR under the same values of v(1) and v(2), it would lead to faster testing speed. In addition, The experimental results indicate that the proposed v-TPSVR obtains the better prediction performance than the popular epsilon-TSVR and v-TSVR.																	0269-2821	1573-7462				FEB	2020	53	2					1511	1527		10.1007/s10462-019-09711-w													
J								Horizon line detection using supervised learning and edge cues	COMPUTER VISION AND IMAGE UNDERSTANDING											GEO-LOCALIZATION; ALGORITHM; SCALE	Traditionally, edge detection has been extensively employed as the basic step for the horizon line detection problem. However, generally such methods do not discriminate between edges belonging to horizon boundary and others due to clouds or other natural phenomenon. Additionally, most edge based methods suffer more in the presence of edge gaps. To address these issues, we propose an edge-less horizon line detection approach based on pixel classification, hence not relying on edge information. The key idea is formulating a multi-stage graph using classification maps, instead of edge maps, where each node cost reflects the likelihood of pixel belonging to the horizon boundary. The shortest path is found in the formulated multi-stage graph using dynamic programming which conforms to the detected horizon line. We demonstrate the performance of the proposed approach on two challenging data sets and provide comparisons with two edge-based methods: one relying on edge detection while the other based on edge classification. Overall, the proposed approach achieves comparable performance against carefully crafted edge based formulations. A by-product of the edge-less approach is its capability of associating a confidence level with the found solution, which can be used to confirm the presence or absence of a horizon line in a given image. The method is also capable of dealing with partial horizon line in an image. To further improve the detection performance, we propose a fusion strategy which combines both edge-based and edge-less information. Extensive evaluations, including a publicly available data set, illustrate the superiority of the proposed fusion approach.																	1077-3142	1090-235X				FEB	2020	191								102879	10.1016/j.cviu.2019.102879													
J								An efficient EM-ICP algorithm for non-linear registration of large 3D point sets	COMPUTER VISION AND IMAGE UNDERSTANDING										Point sets; Surface; Non-linear registration; Alignment; ICP; EM; EM-ICP	NONRIGID REGISTRATION; LIKELIHOOD; MIXTURE; ROBUST; SHAPE	In this paper, we present a new method for non-linear pairwise registration of 3D point sets. In this method, we consider the points of the first set as the draws of a Gaussian mixture model whose centres are the displaced points of the second set. Next we perform a maximum a posteriori estimation of the parameters (which include the unknown transformation) of this model using the expectation-maximisation (EM) algorithm. Compared to other methods using the same "EM-ICP" framework, we propose four key modifications leading to an efficient algorithm allowing for fast registration of large 3D point sets: (1) truncation of the cost function; (2) symmetrisation of the point-to-point correspondences; (3) specification of priors on these correspondences using differential geometry; (4) efficient encoding of deformations using the RKHS theory and the Fourier analysis. We evaluate the added value of these modifications and compare our method to the state-of-the-art CPD algorithm on real and simulated data.																	1077-3142	1090-235X				FEB	2020	191								102854	10.1016/j.cviu.2019.102854													
J								An Entropic Optimal Transport loss for learning deep neural networks under label noise in remote sensing images	COMPUTER VISION AND IMAGE UNDERSTANDING										Optimal transport; Entropic Optimal Transport; Robust deep learning; Noisy labels; Remote sensing	CLASSIFICATION	Deep neural networks have established as a powerful tool for large scale supervised classification tasks. The state-of-the-art performances of deep neural networks are conditioned to the availability of large number of accurately labeled samples. In practice, collecting large scale accurately labeled datasets is a challenging and tedious task in most scenarios of remote sensing image analysis, thus cheap surrogate procedures are employed to label the dataset. Training deep neural networks on such datasets with inaccurate labels easily overfits to the noisy training labels and degrades the performance of the classification tasks drastically. To mitigate this effect, we propose an original solution with entropic optimal transportation. It allows to learn in an end-to-end fashion deep neural networks that are, to some extent, robust to inaccurately labeled samples. We empirically demonstrate on several remote sensing datasets, where both scene and pixel-based hyperspectral images are considered for classification. Our method proves to be highly tolerant to significant amounts of label noise and achieves favorable results against state-of-the-art methods.																	1077-3142	1090-235X				FEB	2020	191								102863	10.1016/j.cviu.2019.102863													
J								Human Visual System vs Convolution Neural Networks in food recognition task: An empirical comparison	COMPUTER VISION AND IMAGE UNDERSTANDING										Deep learning; Machine learning; Food recognition		Automated food recognition from food plate is useful for smartphone-based applications promoting healthy lifestyles and for automated carbohydrate counting, e.g. targeted at type I diabetic patients, but the variation of appearance of food items makes it a difficult task. Convolution Neural Networks (CNNs) raised to prominence in recent years, and they will enable those applications if they are able to match HVS accuracy at least in meal classification. In this work we run an experimental comparison of accuracy between CNNs and HVS based on a simple meal recognition task. We set up a survey for humans with two phases, training and testing, and also give the food dataset to state-of-the-art CNNs. The results, considering some relevant variations in the setup, allow us to reach conclusions regarding the comparison, characteristics and limitations of CNNs, which are relevant for future improvements.																	1077-3142	1090-235X				FEB	2020	191								102878	10.1016/j.cviu.2019.102878													
J								CRF with deep class embedding for large scale classification	COMPUTER VISION AND IMAGE UNDERSTANDING										CRF; Class embedding; Matrix factorization; Surrogate likelihood; Batch normalization		This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling. We also show improved results on a standard OCR dataset.																	1077-3142	1090-235X				FEB	2020	191								102865	10.1016/j.cviu.2019.102865													
J								Identifying motion pathways in highly crowded scenes: A non-parametric tracklet clustering approach	COMPUTER VISION AND IMAGE UNDERSTANDING										Manuscript; Tracklet similarity; DD-CRP; Semantic prior; Tracklet cluster likelihood; Anomaly detection	BEHAVIORS; MODEL; FLOW	Many approaches that address the analysis of crowded scenes rely on using short trajectory fragments, also known as tracklets, of moving objects to identify motion pathways. Typically, such approaches aim at defining meaningful relationships among tracklets. However, defining these relationships and incorporating them in a crowded scene analysis framework is a challenge. In this article, we introduce a robust approach to identifying motion pathways based on tracklet clustering. We formulate a novel measure, inspired by line geometry, to capture the pairwise similarities between tracklets. For tracklet clustering, the recent distance dependent Chinese restaurant process (DD-CRP) model is adapted to use the estimated pairwise tracklet similarities. The motion pathways are identified based on two hierarchical levels of DD-CRP clustering such that the output clusters correspond to the pathways of moving objects in the crowded scene. Moreover, we extend our DD-CRP clustering adaptation to incorporate the source and sink gate probabilities for each tracklet as a high-level semantic prior for improving clustering performance. For qualitative evaluation, we propose a robust pathway matching metric, based on the chi-square distance, that accounts for both spatial coverage and motion orientation in the matched pathways. Our experimental evaluation on multiple crowded scene datasets, principally, the challenging Grand Central Station dataset, demonstrates the state-of-the-art performance of our approach. Finally, we demonstrate the task of motion abnormality detection, both at the tracklet and frame levels, against the normal motion patterns encountered in the motion pathways identified by our method, with competent quantitative performance on multiple datasets.																	1077-3142	1090-235X				FEB	2020	191								102710	10.1016/j.cviu.2018.08.004													
J								Comparison of monocular depth estimation methods using geometrically relevant metrics on the IBims-1 dataset	COMPUTER VISION AND IMAGE UNDERSTANDING											ACCURATE; IMAGE; SHAPE	The task of predicting a dense depth map from a monocular RGB image, commonly known as single-image depth estimation (SIDE) or monocular depth estimation (MDE), is an active research topic in computer vision for decades. With the significant progress of deep models in recent years, new standards were set yielding remarkable results in capturing the 3D structure from a single image. However, established evaluation schemes of predicted depth maps are still limited, as they only consider global statistics of the depth residuals. In order to allow for a geometry-aware analysis, we propose a set of novel quality criteria addressing the preservation of depth discontinuities and planar regions, the depth consistency across the image, and a distance-related assessment. As current datasets do not fulfill the requirements of all proposed error metrics, we provide a new high-quality indoor RGB-D test dataset, acquired by a digital single-lens reflex (DSLR) camera together with a laser scanner. New insights into the performance of current state-of-the-art SIDE approaches, as well as subtle differences among them, could be unveiled by employing the proposed error metrics on our reference dataset. Additionally, investigations on the real-world applicability of SIDE methods by a series of experiments regarding different image augmentations, illumination changes and textured planar regions have shown current limitations in this research field.																	1077-3142	1090-235X				FEB	2020	191								102877	10.1016/j.cviu.2019.102877													
J								CompactNets: Compact Hierarchical Compositional Networks for Visual Recognition	COMPUTER VISION AND IMAGE UNDERSTANDING										Deep learning; Regularization; Group sparsity; Image categorization		CNN-based models currently provide state-of-the-art performance in image categorization tasks. While these methods are powerful in terms of representational capacity, they are generally not conceived with explicit means to control complexity. This might lead to scenarios where resources are used in a non-optimal manner, increasing the number of unspecialized or repeated neurons, and overfitting to data. In this work we propose CompactNets, a new approach to visual recognition that learns a hierarchy of shared, discriminative, specialized, and compact representations. CompactNets naturally capture the notion of compositional compactness, a characterization of complexity in compositional models, consisting on using the smallest number of patterns to build a suitable visual representation. We employ a structural regularizer with group-sparse terms in the objective function, that induces on each layer, an efficient and effective use of elements from the layer below. In particular, this allows groups of top-level features to be specialized based on category information. We evaluate CompactNets on the ILSVRC12 dataset, obtaining compact representations and competitive performance, using an order of magnitude less parameters than common CNN-based approaches. We show that CompactNets are able to outperform other group-sparse-based approaches, in terms of performance and compactness. Finally, transfer-learning experiments on small-scale datasets demonstrate high generalization power, providing remarkable categorization performance with respect to alternative approaches.																	1077-3142	1090-235X				FEB	2020	191								102841	10.1016/j.cviu.2019.102841													
J								Weakly supervised semantic segmentation using distinct class specific saliency maps	COMPUTER VISION AND IMAGE UNDERSTANDING										Semantic segmentation; Weakly supervised learning; Weakly supervised segmentation; Visualization; Deep learning		Weakly supervised segmentation has drawn considerable attention, because of the high costs associated with the creation of pixel-wise annotated image datasets that are used for training fully supervised segmentation models. We propose a weakly supervised semantic segmentation method using CNN-based class-specific saliency maps and fully connected CRF. To obtain distinct class-specific saliency maps (DCSM) that can be used as unary potentials of CRF, we propose a novel method of estimating class saliency maps, which significantly improves the method proposed by Simonyan et al. (2014) through the following improvements: (1) using CNN derivatives with respect to feature maps of the intermediate convolutional layers with up-sampling instead of an input image; (2) subtracting the saliency maps of other classes from the saliency maps of the target class to differentiate target objects among other objects; (3) aggregating multiple-scale class saliency maps to compensate for the low resolution in feature maps. In addition, we propose the use of a novel algorithm for estimating segmentation "Easiness" combined with the proposed saliency-based method. Wei et al. (2016) recently demonstrated that a fully supervised segmentation model enhanced the performance of weakly supervised segmentation by training the model using the estimated initial masks in a weakly supervised setting. However, the initial estimated masks tend to include some noise, which sometimes produces erroneous results. Therefore, we focus on improving the quality of the initial estimated masks for training a fully supervised segmentation model. We propose a method for retrieving "good seeds" by predicting the segmentation "Easiness" of images based on the consistency of the outputs under different conditions. We illustrate that our proposed method can retrieve "good seeds". Despite of the trade-off between training data quality and the number of training images, retrieved images can improve the accuracy of weakly supervised segmentation by combining data augmentation.																	1077-3142	1090-235X				FEB	2020	191								102712	10.1016/j.cviu.2018.08.006													
J								Descriptor extraction based on a multilayer dictionary architecture for classification of natural images	COMPUTER VISION AND IMAGE UNDERSTANDING										Supervised dictionary learning; Sparse coding; Classification	SPARSE REPRESENTATION; SELECTION	This paper presents a descriptor extraction method in the context of image classification, based on a multilayer structure of dictionaries. We propose to learn an architecture of discriminative dictionaries for classification in a supervised framework using a patch-level approach. This method combines many layers of sparse coding and pooling in order to reduce the dimension of the problem. The supervised learning of dictionary atoms allows them to be specialized for a classification task. The method has been tested on known datasets of natural images such as MNIST, CIFAR-10 and STL, in various conditions, especially when the size of the training set is limited, and in a transfer learning application. The results are also compared with those obtained with Convolutional Neural Network (CNN) of similar complexity in terms of number of layers and processing pipeline.																	1077-3142	1090-235X				FEB	2020	191								102708	10.1016/j.cviu.2018.08.002													
J								Simultaneous compression and quantization: A joint approach for efficient unsupervised hashing	COMPUTER VISION AND IMAGE UNDERSTANDING												For unsupervised data-dependent hashing, the two most important requirements are to preserve similarity in the low-dimensional feature space and to minimize the binary quantization loss. A well-established hashing approach is Iterative Quantization (ITQ), which addresses these two requirements in separate steps. In this paper, we revisit the ITQ approach and propose novel formulations and algorithms to the problem. Specifically, we propose a novel approach, named Simultaneous Compression and Quantization (SCQ), to jointly learn to compress (reduce dimensionality) and binarize input data in a single formulation under strict orthogonal constraint. With this approach, we introduce a loss function and its relaxed version, termed Orthonormal Encoder (OnE) and Orthogonal Encoder (OgE) respectively, which involve challenging binary and orthogonal constraints. We propose to attack the optimization using novel algorithms based on recent advance in cyclic coordinate descent approach. Comprehensive experiments on unsupervised image retrieval demonstrate that our proposed methods consistently outperform other state-of-the-art hashing methods. Notably, our proposed methods outperform recent deep neural networks and GAN based hashing in accuracy, while being very computationally-efficient.																	1077-3142	1090-235X				FEB	2020	191								102852	10.1016/j.cviu.2019.102852													
J								A novel algebraic solution to the perspective-three-line pose problem	COMPUTER VISION AND IMAGE UNDERSTANDING										Perspective-three-line problem (P3L); Absolute position and attitude; Pose estimation; Imaging geometry; Computer vision	LINE; CORRESPONDENCES	In this work, we present a novel algebraic method to the perspective-three-line (P3L) problem for determining the position and attitude of a calibrated camera from features of three known reference lines. Unlike other methods, the proposed method uses an intermediate camera frame F and an intermediate world frame E, with sparse known line coordinates, facilitating formulations of the P3L problem. Additionally, the rotation matrix between the frame E and the frame F is parameterized by using its orthogonality, and then a closed-form solution for the P3L pose problem is obtained from subsequent substitutions. This algebraic method makes the processes more easily followed and significantly improves the performance. The experimental results show that the proposed method offers numerical stability, accuracy and efficiency comparable or better than that of state-of-the-art method.																	1077-3142	1090-235X				FEB	2020	191								102711	10.1016/j.cviu.2018.08.005													
J								Registration and matching method for directed point set with orientation attributes and local information	COMPUTER VISION AND IMAGE UNDERSTANDING										Directed point set; Registration and matching; TPS	VERIFICATION; RECOGNITION	Point set registration and matching are the basic problems of pattern recognition and computer vision. The key to solve these problems is to determine the correspondences between the two point sets and to describe the deformation between them. In this paper, we propose an optimization model for the registration and matching of 2D directed point sets with coordinate and orientation attributes (x, y, theta). First, the thin-plate spline (TPS) function with coordinate and orientation attributes is derived by variational method to describe the directed point set deformation. Second, an optimization objective function with coordinates and angles is constructed for point set registration and matching. Finally, the objective function is solved by alternately obtaining the correspondences and describing the deformation between the point sets. In the algorithm, the initial solution of correspondences is obtained by utilizing the neighborhood information of the point set to make the algorithm more robust. Several registration and matching experiments were performed on the artificial point sets and FVC fingerprint image databases to verify the robustness, effectiveness, and accuracy of the algorithm. Compared with the current popular algorithm, the proposed algorithm shows higher precision and robustness.																	1077-3142	1090-235X				FEB	2020	191								102866	10.1016/j.cviu.2019.102866													
J								Relevant feature selection and ensemble classifier design using bi-objective genetic algorithm	KNOWLEDGE AND INFORMATION SYSTEMS										Feature selection; Cellular automata; Lower bound approximation; Kullback-Leibler divergence; Bi-objective genetic algorithm; Ensemble classifier	ROUGH SET; SYSTEMS	In the era of digital boom, single classifier cannot perform well in various datasets. Ensemble classifier aims to bridge this performance gap by combining multiple classifiers of diverse characteristics to get better generalization. But classifier selection highly depends on the dataset, and its efficiency degrades tremendously due to the presence of irrelevant features. Feature selection aids the performance of classifier by removing those irrelevant features. Initially, we have proposed a bi-objective genetic algorithm-based feature selection method (FSBOGA), where nonlinear, uniform, hybrid cellular automata are used to generate an initial population. Objective functions are defined using lower bound approximation of rough set theory and Kullback-Leibler divergence method of information theory to select unambiguous and informative features. The replacement strategy for creation of next-generation population is based on the Pareto optimal solution with respect to both the objective functions. Next, a novel bi-objective genetic algorithm-based ensemble classification method (CCBOGA) is devised to ensemble the individual classifiers designed using obtained reduced datasets. It is observed that the constructed ensemble classifier performs better than the individual classifiers. The performances of proposed FSBOGA and CCBOGA are investigated on some popular datasets and compared with the state-of-the-art algorithms to demonstrate their effectiveness.																	0219-1377	0219-3116				FEB	2020	62	2					423	455		10.1007/s10115-019-01341-6													
J								Dataset-Transformation: improving clustering by enhancing the structure with DipScaling and DipTransformation	KNOWLEDGE AND INFORMATION SYSTEMS										Dip-test; Dataset-Transformation; Data mining; Clustering; k-means		A data set might have a well-defined structure, but this does not necessarily lead to good clustering results. If the structure is hidden in an unfavourable scaling, clustering will usually fail. The aim of this work is to present techniques-DipScaling and DipTransformation-which enhance the data set by rescaling and transforming its features and thus emphasizing and accentuating its structure. If the structure is sufficiently clear, clustering algorithms will perform far better. We refer to such techniques as "Dataset-Transformations" and try to provide a mathematical framework for them. To show that our algorithms work well, we have conducted extensive experiments on several real-world data sets, where we improve clustering not only for k-means, which is our main focus but also for other standard clustering approaches.																	0219-1377	0219-3116				FEB	2020	62	2					457	484		10.1007/s10115-019-01388-5													
J								HEEL: exploratory entity linking for heterogeneous information networks	KNOWLEDGE AND INFORMATION SYSTEMS										Heterogeneous information network; Exploratory entity linking; Partial classification EM; Author name disambiguation		A heterogeneous information network (HIN) is a ubiquitous data model, consisting of multiple types of entities and relations. Names of entities in HINs are inherently ambiguous, making it difficult to fully disambiguate a HIN. In this paper, we introduce the task of exploratory entity linking for HINs. Given a partially disambiguated HIN, we aim at linking ambiguous names to disambiguated entities in the HIN if their referent entities are present. We also try to "explore" other alternatives by discovering new entities and adding them to the HIN. A partial classification EM-based approach is proposed to address this task. We present a constrained probability propagation model to link surface names to entities in the HIN. New entity detection process is modeled as a maximum edge weight clique problem. Experiments illustrate that our method outperforms state-of-the-art methods for entity linking with HINs and author name disambiguation.																	0219-1377	0219-3116				FEB	2020	62	2					485	506		10.1007/s10115-019-01354-1													
J								Clustering analysis using a novel locality-informed grey wolf-inspired clustering approach	KNOWLEDGE AND INFORMATION SYSTEMS										Optimization; Grey wolf optimizer; GWO; Tabu search; Data clustering	PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION; GENETIC ALGORITHM; TABU SEARCH	Grey wolf optimizer (GWO) is known as one of the recent popular metaheuristic algorithms inspired from the social collaboration and team hunting activities of grey wolves in nature. This algorithm benefits from stochastic operators, but it is still prone to stagnation in local optima and premature convergence when solving problems with a large number of variables (e.g., clustering problems). To alleviate this shortcoming, the GWO algorithm is hybridized with the well-known tabu search (TS). To investigate the performance of the proposed hybrid GWO and TS (GWOTS), it is compared with well-regarded metaheuristics on various clustering datasets. The comprehensive experiments and analysis verify that the proposed GWOTS shows an improved performance compared to GWO and can be utilized for clustering applications.																	0219-1377	0219-3116				FEB	2020	62	2					507	539		10.1007/s10115-019-01358-x													
J								Automatic attribute construction for basketball modelling	KNOWLEDGE AND INFORMATION SYSTEMS										Sports modelling; Markov process; Attribute construction; Match simulation; NBA		We address the problem of automatic extraction of patterns in the sequence of events in basketball games and construction of statistical models for generating a plausible simulation of a match between two distinct teams. We present a method for automatic construction of an attribute space which requires very little expert knowledge. The attributes are defined as the ratio between the number of entries and exits from higher-level concepts that are identified as groups of similar in-game events. The similarity between events is determined by the similarity between probability distributions describing the preceding and the following events in the observed sequences of game progression. The methodology is general and is applicable to any sports game that can be modelled as a random walk through the state space. Experiments on basketball show that automatically generated attributes are as informative as those derived using expert knowledge. Furthermore, the obtained simulations are in line with empirical data.																	0219-1377	0219-3116				FEB	2020	62	2					541	570		10.1007/s10115-019-01361-2													
J								Random walk-based ranking in signed social networks: model and algorithms	KNOWLEDGE AND INFORMATION SYSTEMS										Signed networks; Signed random walk with restart; Personalized node ranking; Trustworthiness measure	STRUCTURAL BALANCE	How can we rank nodes in signed social networks? Relationships between nodes in a signed network are represented as positive (trust) or negative (distrust) edges. Many social networks have adopted signed networks to express trust between users. Consequently, ranking friends or enemies in signed networks has received much attention from the data mining community. The ranking problem, however, is challenging because it is difficult to interpret negative edges. Traditional random walk-based methods such as PageRank and random walk with restart cannot provide effective rankings in signed networks since they assume only positive edges. Although several methods have been proposed by modifying traditional ranking models, they also fail to account for proper rankings due to the lack of ability to consider complex edge relations. In this paper, we propose Signed Random Walk with Restart (SRWR), a novel model for personalized ranking in signed networks. We introduce a signed random surfer so that she considers negative edges by changing her sign for walking. Our model provides proper rankings considering signed edges based on the signed random walk. We develop two methods for computing SRWR scores: SRWR-Iter and SRWR-Pre which are iterative and preprocessing methods, respectively. SRWR-Iter naturally follows the definition of SRWR, and iteratively updates SRWR scores until convergence. SRWR-Pre enables fast ranking computation which is important for the performance of applications of SRWR. Through extensive experiments, we demonstrate that SRWR achieves the best accuracy for link prediction, predicts trolls more accurately, and shows a satisfactory performance for inferring missing signs of edges compared to other competitors. In terms of efficiency, SRWR-Pre preprocesses a signed network 4.5xfaster and requires 11x less memory space than other preprocessing methods; furthermore, SRWR-Pre computes SRWR scores up to 14x faster than other methods in the query phase.																	0219-1377	0219-3116				FEB	2020	62	2					571	610		10.1007/s10115-019-01364-z													
J								Measures of uncertainty for knowledge bases	KNOWLEDGE AND INFORMATION SYSTEMS										Rough set theory; Granular computing; Knowledge base; Knowledge granule; Knowledge structure; Dependence; Uncertainty; Measure; Effectiveness	INFORMATION ENTROPY; ROUGH ENTROPY; GRANULATION	This paper investigates measures of uncertainty for knowledge bases by using their knowledge structures. Knowledge structures of knowledge bases are first introduced. Then, dependence and independence between knowledge structures of knowledge bases are proposed, which are characterized by inclusion degree. Next, measures of uncertainty for a given knowledge base are studied, and it is proved that the proposed measures are based on the knowledge structure of this knowledge base. Finally, a numerical experiment is conducted to show performance of the proposed measures and effectiveness analysis is done from two aspects of dispersion and correlation in statistics. These results will be significant for understanding the essence of uncertainty for knowledge bases.																	0219-1377	0219-3116				FEB	2020	62	2					611	637		10.1007/s10115-019-01363-0													
J								Leader-aware community detection in complex networks	KNOWLEDGE AND INFORMATION SYSTEMS										Community detection; Leader-aware; Dependence tree	MODEL	Community structures are very common in complex networks. Detecting these communities is important for understanding the hidden features of networks. Besides, each community usually has one leader, which presents its significant influence over the whole community. However, most existing methods just focus on the problem of graph clustering, ignoring the role of community leaders. To solve this problem, in this paper, we propose a novel leader-aware community detection algorithm, which can find community structures as well as leaders of each community. This algorithm measures the leadership of each node and lets each one adhere to its local leader, forming dependence trees. Once all dependence trees are definitely settled, the community structures emerge because one tree actually is a cluster. Additionally, each root node of the tree is exactly the leader of corresponding community. This method can quickly determine the belonging of each node. Experimental results on real-world and benchmark networks demonstrate the effectiveness and the efficiency of our algorithm compared with other state-of-the-art approaches.																	0219-1377	0219-3116				FEB	2020	62	2					639	668		10.1007/s10115-019-01362-1													
J								Anomaly detection of event sequences using multiple temporal resolutions and Markov chains	KNOWLEDGE AND INFORMATION SYSTEMS										Anomaly detection; Markov Chains; Multiple temporal resolutions; Event sequences; Video-on-demand		Streaming data services, such as video-on-demand, are getting increasingly more popular, and they are expected to account for more than 80% of all Internet traffic in 2020. In this context, it is important for streaming service providers to detect deviations in service requests due to issues or changing end-user behaviors in order to ensure that end-users experience high quality in the provided service. Therefore, in this study we investigate to what extent sequence-based Markov models can be used for anomaly detection by means of the end-users' control sequences in the video streams, i.e., event sequences such as play, pause, resume and stop. This anomaly detection approach is further investigated over three different temporal resolutions in the data, more specifically: 1 h, 1 day and 3 days. The proposed anomaly detection approach supports anomaly detection in ongoing streaming sessions as it recalculates the probability for a specific session to be anomalous for each new streaming control event that is received. Two experiments are used for measuring the potential of the approach, which gives promising results in terms of precision, recall, F1-score and Jaccard index when compared to k-means clustering of the sessions.																	0219-1377	0219-3116				FEB	2020	62	2					669	686		10.1007/s10115-019-01365-y													
J								Dynamic clustering of interval data based on hybrid L-q distance	KNOWLEDGE AND INFORMATION SYSTEMS										L-q distance; Symbolic data analysis; Clustering; Data models	DISCRIMINANT-ANALYSIS; MODELS	Dynamic clustering defines partitions within data and prototypes to each partition. Distance metrics are responsible for checking the closeness between instances and prototypes. Considering the literature about interval data, distances depend on interval bounds and the information inside the intervals is ignored. This paper proposes new distances, which explore the information inside of intervals. It also presents a mapping of intervals to points, which preserves their spatial location and internal variation. We formulate a new hybrid distance for interval data based on the well-known L-q distance for point data. This new distance allows for a weighted formulation of the hybridism. Hence, we propose a Hybrid L-q distance, a Weighted Hybrid L-q distance, as well as the adaptive version of the Hybrid L-q distance for interval data. Experiments with synthetic and real interval data sets illustrate the usefulness of the hybrid approach to improve dynamic clustering for interval data.																	0219-1377	0219-3116				FEB	2020	62	2					687	718		10.1007/s10115-019-01367-w													
J								Unsupervised online change point detection in high-dimensional time series	KNOWLEDGE AND INFORMATION SYSTEMS										Time series; Online change point detection; Segmentation; Information Gain Theory	DYNAMIC FEATURE-SELECTION; SEGMENTATION	A critical problem in time series analysis is change point detection, which identifies the times when the underlying distribution of a time series abruptly changes. However, several shortcomings limit the use of some existing techniques in real-world applications. First, several change point detection techniques are offline methods, where the whole time series needs to be stored before change point detection can be performed. These methods are not applicable to streaming time series. Second, most techniques assume that the time series is low-dimensional and hence have problems handling high-dimensional time series, where not all dimensions may cause the change. Finally, most methods require user-defined parameters that need to be chosen based on the observed data, which limits their applicability to new unseen data. To address these issues, we propose an Information Gain-based method that does not require prior distributional knowledge for detecting change points and handles high-dimensional time series. The advantages of our proposed method compared to the state-of-the-art algorithms are demonstrated from theoretical basis, as well as via experiments on four synthetic and three real-world human activity datasets.																	0219-1377	0219-3116				FEB	2020	62	2					719	750		10.1007/s10115-019-01366-x													
J								A new order relation for Pythagorean fuzzy numbers and application to multi-attribute group decision making	KNOWLEDGE AND INFORMATION SYSTEMS										Pythagorean fuzzy set; Multi-attribute group decision making; Relative distance; Information reliability; Knowledge measure	IMPROVED SCORE FUNCTION; AGGREGATION OPERATORS; SIMILARITY MEASURES; PROGRAMMING METHOD; MEMBERSHIP GRADES; ACCURACY FUNCTION; INFORMATION; SETS; TOPSIS; DISTANCE	This paper proposes a new order relation for Pythagorean fuzzy numbers (PFNs) and applies to multi-attribute group decision making (MAGDM). The main contributions are outlined as five aspects: (1) the concepts of relative distance and information reliability of PFN are proposed. Then, a new order relation is developed to compare PFNs. Moreover, the new order relation of PFNs is demonstrated to be an admissible order. (2) Knowledge measure of PFN is defined to describe the amount of information. The desirable properties of knowledge measure of PFN are studied concretely. (3) For MAGDM with PFNs, the comprehensive distance between individual Pythagorean fuzzy matrices and a mean one are defined. Then, the decision makers' weights are obtained by the comprehensive distances. Thus, a collective Pythagorean fuzzy matrix is derived by using the Pythagorean fuzzy weighted average operator. (4) To determine attribute weights, a multi-objective programming model is constructed by maximizing the overall knowledge measure of each alternative. This model is further transformed into a single-objective mathematical program to resolve. (5) According to the defined new order relation of PFNs, the ranking order of alternatives is generated by the comprehensive values of alternatives. Therefore, a new method is proposed to solve MAGDM with PFNs. Finally, an example of venture capital investment selection is provided to illustrate the effectiveness of the proposed method.																	0219-1377	0219-3116				FEB	2020	62	2					751	785		10.1007/s10115-019-01369-8													
J								Measuring the diversity of recommendations: a preference-aware approach for evaluating and adjusting diversity	KNOWLEDGE AND INFORMATION SYSTEMS										Recommender systems; Diversity measurement; Diversification; Linked data; Similarity measures; Diversity calibration	INFORMATION	While recent research has highlighted the importance of identifying diverse aspects of user preferences in terms of the quality of recommendations, most of the widely used performance measures tend to consider the accuracy of the recommendations and ignore other important aspects such as preference for diversity in recommendations. This is despite the emerging consensus that improving the diversity in recommendations allows users to discover a wider variety of items and encourage them to extend their range of interests in domains such as books, movies, and music. By proposing a novel diversity evaluation metric, this paper aims to address the problem of measuring the diversity with respect to the distribution of preferences for diversity among recommendation system users. We perform several experiments in order to provide a better understanding of the diversity preferences of users and present the results of diversity evaluations of several recommendation methods. These experiments highlight the accuracy-diversity trade-off and show that higher accuracy does not lead to higher performance in terms of the diversity of the recommendations and that the users' preferred level of diversity should be considered when designing and evaluating recommender systems. This paper also proposes our Diversity Adjustment algorithm that modifies the diversity of recommendations to suit each user's preferences while preserving the accuracy. Our experiments suggest that diversifying the recommendations without considering the user's preferences can lead to a dramatic decline in accuracy, while adjusting the diversity based on users' diversity needs can support recommender systems in maintaining overall accuracy.																	0219-1377	0219-3116				FEB	2020	62	2					787	811		10.1007/s10115-019-01371-0													
J								Generating synthetic positive and negative business process traces through abduction	KNOWLEDGE AND INFORMATION SYSTEMS										Synthetic log generation; Declarative and procedural business model; Artificially positive and negative events; Abductive reasoning	PROCESS MODELS; FRAMEWORK	As recent years have seen the rise of a new discipline commonly addressed as process mining, focused on the management of business processes, two tasks have gained increasing attention in research: process discovery and compliance monitoring. In both these fields, the demand for event log benchmarks with predefined characteristics has determined the design of various methodologies and tools for synthetic log generation. However, artificially created as well as real-life logs often contain positive examples only (i.e. process instances deemed as compliant w.r.t. the model), while the presence of negative process instances (i.e. non-compliant traces) can be crucial to correctly evaluate the performance and robustness of a novel process discovery or conformance checking technique. In this work, we investigate positive and negative trace generation in case of both declarative and procedural model specifications and we present our abduction-based approach to log synthesis. The theoretical study is concretely applied in a software prototype for log generation, which takes as input a declarative or structured workflow model and emits logs containing positive and negative traces. The approach provides both a highly expressive notation for the description of the business model and the ability to generate logs with various customizable features. The final comparative study of other existing log generators reveals several advantages of the proposed approach and draws the direction of future improvements.																	0219-1377	0219-3116				FEB	2020	62	2					813	839		10.1007/s10115-019-01372-z													
J								Weighted tensor nuclear norm minimization for tensor completion using tensor-SVD	PATTERN RECOGNITION LETTERS										Tensor completion; Tensor-SVD; Weighted nuclear norm; KKT conditions; Video completion	MATRIX; FACTORIZATION; RECOVERY; MANIFOLD; SPARSE; IMAGE	In this paper, we consider the tensor completion problem, which aims to estimate missing values from limited information. Our model is based on the recently proposed tensor-SVD, which uses the relationships among the color channels in an image or video recovery problem. To improve the availability of the model, we propose the weighted tensor nuclear norm whose weights are fixed in the algorithm, study its properties and prove the Karush-Kuhn-Tucker (KKT) conditions of the proposed algorithm. We conduct extensive experiments to verify the recovery capability of the proposed algorithm. The experimental results demonstrate improvements in computation time and recovery effect compared with related methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		4	11		10.1016/j.patrec.2018.12.012													
J								Modality-correlation-aware sparse representation for RGB-infrared object tracking	PATTERN RECOGNITION LETTERS											VISUAL TRACKING; ROBUST; HISTOGRAMS; FUSION	To intelligently analyze and understand video content, a key step is to accurately perceive the motion of the interested objects in videos. To this end, the task of object tracking, which aims to determine the position and status of the interested object in consecutive video frames, is very important, and has received great research interest in the last decade. Although numerous algorithms have been proposed for object tracking in RGB videos, most of them may fail to track the object when the information from the RGB video is not reliable (e.g. in dim environment or large illumination change). To address this issue, with the popularity of dual-camera systems for capturing RGB and infrared videos, this paper presents a feature representation and fusion model to combine the feature representation of the object in RGB and infrared modalities for object tracking. Specifically, this proposed model is able to (1) perform feature representation of objects in different modalities by employing the robustness of sparse representation, and (2) combine the representation by exploiting the modality correlation. Extensive experiments demonstrate the effectiveness of the proposed method. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		12	20		10.1016/j.patrec.2018.10.002													
J								Depth image super-resolution based on joint sparse coding	PATTERN RECOGNITION LETTERS										Image super-resolution; Joint sparse coding	MAP SUPERRESOLUTION; REPRESENTATION	This paper proposes a new approach to single depth image super-resolution (SR), based upon a novel joint sparse coding model. A low-resolution color is used as a guide in the SR process. Firstly, we introduce synthetic characteristic image patch to learn a joint dictionary from the low-resolution depth map as well as its corresponding low-resolution intensity image. Then, we derive the joint nonlocal center sparse representation model based on sparse coding and theoretical analysis. In reconstruction process, we use Bayesian interpretation approach to estimation the sparse code coefficients for each unknown HR image patch. Meanwhile, we use an iterative algorithm to solve the JSC model. In addition, we exploit image patch redundancy within and across different scales, produce visually pleasing results without extensive training on external database. Experimental results demonstrate that the proposed method outperforms favorably many current state-of-the-art depth map super-resolution approaches on both visual effects and objective image quality and underpin the validity of our proposed model. Published by Elsevier B.V.																	0167-8655	1872-7344				FEB	2020	130				SI		21	29		10.1016/j.patrec.2018.07.023													
J								Quick automatic head image matting method based on segmentation and propagation	PATTERN RECOGNITION LETTERS										Image matting; Image segmentation; Gray level; Propagation method; Contour extraction		Image matting is a process of extracting objects from background in an image, which is an important work in digital image processing and video editing. Previous methods have poor performance and most methods need trimap or scribble to compute to get accurate image matting results. In this paper a quick automatic head image matting method for certificate photo production is put forward, which could rapidly extract satisfied head photo from images that are shoot by portable camera. First a new training data set about hair matting is created, and the image is segmented into different regions according to different gray level; then we detect and locate the face and eyes to adjust the correct head position; Finally, the accurate hair pixels are extracted from the edge region around head by multimodal Gaussian process regression. It's the advantage that the regions with clear foreground and background could be quickly extracted by segmented method, and the regions with similar foreground and background colors or complicated textures were labeled (the edge regions with hair around head), thus the hair could be extracted in smaller area. In our method the quick and accurate extracting of head photo needn't the trimap or scribbling or lots of training. Experimental results clearly demonstrate the superiority of our algorithm over previous methods. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		30	37		10.1016/j.patrec.2019.02.012													
J								Joint spatial-spectral hyperspectral image classification based on convolutional neural network	PATTERN RECOGNITION LETTERS										Hyperspectral image classification; Joint spatial-spectral; Spatial enhancement; CNN	REMOTE-SENSING IMAGES; SPARSE REPRESENTATION; SVM	Hyperspectral image (HSI) classification technology has been widely used in many earth observation tasks, such as detection, recognition, and surveillance. The traditional hyperspectral image classification methods mainly utilize hand-crafted features, such as edge and texture descriptors, which are not robust for different input data. By contrast, deep learning based methods exploit high-level features for hyperspectral image classification, but they usually degenerate the spatial-spectral structure, depend on a large number of training samples, and ignore a large amount of implicitly useful information. To address these problems, a new joint spatial-spectral hyperspectral image classification method based on different-scale two-stream convolutional network and spatial enhancement strategy is proposed in this paper. First, the pixel blocks at different scales around the center pixel are selected as the basic units to be processed. Then, a spatial enhancement strategy is designed to obtain various spatial location information under the limited training samples by the spatial rotation and row-column transformation. Finally, the spatial-spectral feature is learned by a different-scale two-stream convolutional network, and the classification result of the center pixel is obtained by a softmax layer. Experimental results on two datasets demonstrate that the proposed method outperforms other state-of-the-art methods qualitatively and quantitatively. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		38	45		10.1016/j.patrec.2018.10.003													
J								Software expert discovery via knowledge domain embeddings in a collaborative network	PATTERN RECOGNITION LETTERS										Knowledge discovery; Stack overflow; Expertise finding; Question answering; Expert as a Service		Community Question Answering (CQA) websites can be claimed as the most major venues for knowledge sharing, and the most effective way of exchanging knowledge at present. Considering that massive amount of users are participating online and generating huge amount data, management of knowledge here systematically can be challenging. Expert recommendation is one of the major challenges, as it highlights users in CQA with potential expertise, which may help match unresolved questions with existing high quality answers while at the same time may help external services like human resource systems as another reference to evaluate their candidates. In this paper, we in this work we propose to exploring experts in CQA websites. We take advantage of recent distributed word representation technology to help summarize text chunks, and in a semantic view exploiting the relationships between natural language phrases to extract latent knowledge domains. By domains, the users' expertise is determined on their historical performance, and a rank can be compute to given recommendation accordingly. In particular, Stack Overflow is chosen as our dataset to test and evaluate our work, where inclusive experiment shows our competence. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		46	53		10.1016/j.patrec.2018.10.030													
J								FC-RCCN: Fully convolutional residual continuous CRF network for semantic segmentation	PATTERN RECOGNITION LETTERS										Continuous conditional random field (C-CRF); Semantic segmentation; Unary network; Pairwise network		Enlarging the spatial resolution of features generated by fully convolutional networks (FCNs) can improve the performance of semantic segmentation. To achieve this goal, deeper network with deconvolutional structure can be applied. However, when the network architecture becomes more complex, the training efficiency may degrade. To address the joint optimization problem of improving spatial resolution through deeper networks and training deeper networks more effectively, we propose a Fully Convolutional Residual Continuous CRF Network (FC-RCCN) for semantic segmentation. FC-RCCN is composed of three subnetworks: a unary network, a pairwise network, and a superpixel based continuous conditional random filed (C-CRF) network. In order to generate full spatial resolution predictions with high-quality, a residual block based unary network with multi-scale features fusion is proposed. Even though the unary network is a deeper network, the whole framework can be trained effectively in an end-to-end way using the joint pixel-level and superpixel-level supervised learning strategy which is optimized by a pixel-level softmax cross entropy loss and a superpixel-level log-likelihood loss. Besides, C-CRF inference is fused with pixel-level prediction during the test procedure, which guarantees the method's robustness to the superpxiel errors. In the experiments, we evaluatee the power of the three subnetworks and the learning strategy comprehensively. Experiments on three benchmark datasets demonstrate that the proposed FC-RCCN outperforms previous segmentation methods and obtains the state-of-the-art performance. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		54	63		10.1016/j.patrec.2018.08.030													
J								Visual saliency guided complex image retrieval	PATTERN RECOGNITION LETTERS										Visual saliency; Complex image; Image retrieval; Feature extraction	COLOR	Compared with the traditional text data, multimedia data are concise and contains rich meanings, so people are more willing to use the multimedia data to store information. How to effectively retrieve information is essential. This paper proposes a novel visual saliency guided complex image retrieval model. Initially, Itti visual saliency model is presented. In this model, the overall saliency map is generated by the integration of direction, intensity and color saliency map, respectively. Then, to help describe the image pattern more clearly, we present the multi-feature fusion paradigm of images. To address the complexity of the images, we propose a two-stage definition: (1) Cognitive load based complexity; (2) Cognitive level of complexity classification. The group sparse logistic regression model is integrated to finalize the image retrieval system. The performance of the proposed system is tested on different databases compared with the other state-of-the-art models which overcome the baselines in complex scenarios. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		64	72		10.1016/j.patrec.2018.08.010													
J								A Hybrid convolutional neural network for sketch recognition	PATTERN RECOGNITION LETTERS										Sketch recognition; Convolutional neural network; Feature extraction; Sketch-based image retrieval	SHAPE; CLASSIFICATION; DESCRIPTOR; CURVES	With the popularity of touch-screen devices, it is becoming increasingly important to understand users' free-hand sketches in computer vision and human-computer interaction. Most of existing sketch recognition methods employ the similar strategies used in image recognition, relying on appearance information represented by hand-crafted features or deep features from convolutional neural networks. We believe that sketch recognition can benefit from learning both appearance and shape representation. In this paper, we propose a novel architecture, named Hybrid CNN, which is composed of A-Net and S-Net. They describe appearance information and shape information, respectively. Hybrid CNN is then comprehensively evaluated in the sketch classification and retrieval tasks on different datasets, including TU-Berlin, Sketchy and Flickr15k. Experimental results demonstrate that the Hybrid CNN achieves competitive accuracy compared with the state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		73	82		10.1016/j.patrec.2019.01.006													
J								Fast large scale deep face search	PATTERN RECOGNITION LETTERS										Face recognition; Semantic hashing; Deep convolution neural network; Face search		Towards the large scale face search problem, this paper proposes a fast deep face search method which is realized by combination of deep convolution neural network (CNN), semantic hashing, and hash-based similarity search. First of all, to boost the performance in accuracy of face search, the residual network (Resnet) is exploited to construct a deep face feature model and then train it over the cleaned MS-Celeb-1M, which is used to extract real-valued face feature. Next, by imposing PCA and binarization operations, we convert the real-valued feature into compact hash code used for speeding up the face search. Based on the extracted dual features, the face search can be efficiently performed by adopting two-stage matching (i.e., coarse matching and fine matching) strategy. The coarse matching is implemented under the support of efficient hash indexing technique for yielding a small number of candidates while the fine stage is to filter out the unrelated images by cosine distance comparison of real-valued features. It is worth noting that we offer two coarse matching methods, such as GPU-hash and M-index-hash based matching, which are suitable for tens-of million and billion scale scenarios respectively. The experimental results demonstrate that the proposed method is very effective for large scale face search in both aspects of accuracy and real time property. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		83	90		10.1016/j.patrec.2019.01.012													
J								Progressive generative adversarial networks with reliable sample identification	PATTERN RECOGNITION LETTERS										Generative adversarial networks; Sample selection; Unsupervised learning		Generative Adversarial Networks (GANs) are deep neural network architectures comprising of two neural networks, namely discriminator and generator, which contest with each other in a zero-sum game. In the past years, although original GANs and their variations have achieved impressive success, there are some challenges still remain, especially unstable training progress leading to gradient vanishing or saturation. We can show by inspection that the reliable samples with smaller errors are beneficial to achieve a better generator, while the unreliable one might disturb the training procedure. Enlightened from this observation, we introduce an indicator for each sample to indicate its reliability in this paper. Based on this, we exploit a new objective function to learn the generator/discriminator and infer the indicator for each sample simultaneously. In such a way, the unreliable samples that might result in the opposite side are discarded in training stage. Meanwhile, when the training errors become smaller, more and more samples are included in the reliable set of samples, until no more reliable one are produced. It is noteworthy that the proposed method is adapted to both the original GANs and its variations. Experiments on CIFAR-10, STL-10 and LSUN datasets demonstrate the state-of-the-art performance of the proposed framework with respect to GANs and its variations. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		91	98		10.1016/j.patrec.2019.01.007													
J								Weighted constraint based dictionary learning for image classification	PATTERN RECOGNITION LETTERS										Image classification; Sparse representation; Dictionary learning; Discrimination performance	SPARSE REPRESENTATION; FACE RECOGNITION; COLLABORATIVE REPRESENTATION; K-SVD; TRACKING; ROBUST; ILLUMINATION; REDUCTION; ALGORITHM; POSE	Dictionary learning (DL) is a popular approach of image classification. Most DL methods ignore the information hidden in training samples or atoms, and thus cannot enhance the discrimination performance of a dictionary learning algorithm effectively. In addition, the training samples are prone to a wide range of variances such as sample noise and illumination change, which results in the degraded classification performance. Hence, in this paper, we propose a weighted constraint based dictionary learning algorithm to improve the classification performance of dictionary learning. More specifically, the proposed algorithm uses a diagonal weighted matrix to construct a constraint item for reducing the auto-correlation between atoms. Meanwhile, the training samples of the same class enjoy similar coding coefficients such that the reconfiguration and discrimination performance of dictionary is enhanced. Furthermore, in order to avoid over-fitting, we convert a strict two valued label matrix into a flexible matrix in the classification procedure allowing more degrees of freedom to fit the class labels. Experimental results show that the proposed algorithm outperforms massive state-of-the-art dictionary learning and sparse representation algorithms in image classification. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		99	106		10.1016/j.patrec.2018.09.008													
J								General model for linear information extraction based on the shear transformation	PATTERN RECOGNITION LETTERS										Linear information extraction; The shear transformation; General model; Edge detection; Line extraction	CHINESE CALLIGRAPHY WORKS; EDGE-DETECTION	Most images have lots of linear information, which plays an important role in the tasks of image processing and pattern recognition. However, due to the interference of complex background in the images, the multiple directional characteristics of the linear information, and the problems of directional limitations in traditional methods, all these lead to the incomplete and discontinuities existed in the extracted linear information. To solve these problems, this paper puts forward a general model for improving the performance of the linear information extraction methods (LIEM) by utilizing the shear transformation. In this model, the shear transformation can transform an object (a filter or an image) in multiple directions, which directly or indirectly increases the directional characteristics of the traditional LIEM, and improves their performances to extract directional linear information and weak linear information. This paper elaborates on the basic principles of the model and its two implementations for the specific tasks. Furthermore, a variety of experiments are made to verify the versatility and effectiveness of the proposed model. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		107	115		10.1016/j.patrec.2018.10.010													
J								3D Convolutional Neural Network based on memristor for video recognition	PATTERN RECOGNITION LETTERS										3D Convolution; Basic memristor array; Behavior recognition; Memristors; Neuromorphic network		Memristors have emerged as a potential tool to implement the training and operation of an integrated neural network, because of its current-voltage curve of the hysteresis loop and unique pulse regulation resistance method. However, most of the existing neural networks implemented on memristors are relatively basic architecture, and the processing functions are limited to the recognition of the simple signal and image models. In this paper, we propose a 3D Convolutional Neural Network based on memristor to recognize and classify the behaviors of human in the video with 6 main actions. As an extension of 2D Convolutional Neural Networks, 3D Convolutional Neural Networks have attracted attention for video information processing, since it introduces the time dimension innovatively on the basis of spatial dimensions to capture the contextual information between the different frames in the video. Accordingly, we use the 3D Convolution to construct our proposed neural network based on memristors. Besides, we use the basic 3 x 3 memristor arrays to construct the larger functional memristor arrays and form the 3D convolutional layers of our network by considering that the 3 x 3 basic memristor array has excellent flexibility and anti-jamming capability. With this strategy, we can make full use of the hardware structure to improve accuracy while reducing hardware noise. Finally, we implemented network obtain more than 70% accuracy on the Weizmann video dataset. This demonstration is an important step that memristors can implement the much larger and more complex neural networks for processing the more complex applications. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		116	124		10.1016/j.patrec.2018.12.005													
J								Land contained sea area ship detection using spaceborne image	PATTERN RECOGNITION LETTERS										Synthetic aperture radar; Image understanding; Ship detection; Land contained sea area		Using spaceborne remote sensing images for ship detection is a significant application for maritime monitoring, especially the synthetic aperture radar (SAR) image which can provide data all days and all weather. Limited attention to the problem of detection in land contained sea area, which is the more difficult than detection on pure sea surface. In this letter, we propose a ship detection for the land contained sea area. In order to decrease the possibly existing false alarms form the island, an island filter is used as the first step. An automatically segmentation method called constant false alarm rate (CFAR) is used to get candidates from the big map then. In the third step, we use a CNN based classifier to separate false alarms from ship object. In order to fit for the SAR slice, a pooling utilization type called "max-mean pooling" is proposed. Finally, some experiments are given to demonstrate the effectiveness. (C) 2019 Published by Elsevier B.V.																	0167-8655	1872-7344				FEB	2020	130				SI		125	131		10.1016/j.patrec.2019.01.015													
J								Locality-constrained group lasso coding for microvessel image classification	PATTERN RECOGNITION LETTERS										Image classification; Group sparse coding; Microvessel	PULMONARY NODULE; TUMOR; MODEL	Image-based classification of histology sections plays an important role in predicting clinical outcomes. In this paper, we propose a Locality-Constrained Group Lasso Coding (LCGLC) method for microvessel image classification, which realizes the automatic "hot spot" detection of angiogenesis for human liver carcinoma. First, we extract Scale-Invariant Feature Transform (SIFT) descriptors on the Single-Opponent (SO) feature map, which simulates the biological functionality of human visual systems. Then, we present the feature-biased dictionary learning to effectively generate the dictionary of SIFT descriptors. With the learned dictionary, our LCGLC method introduces the locality constraint in classical group lasso problem to encode SIFT descriptors. Furthermore, we apply the Spatial Pyramid Matching (SPM) for the code pooling of microvessel images. Finally, we use Support Vector Machine (SVM) to classify a tissue image as having angiogenesis or not. Comprehensive experiments on the microvessel dataset show that the proposed LCGLC method achieves better performance compared with other representative approaches. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		132	138		10.1016/j.patrec.2019.02.011													
J								Wavelet energy feature based source camera identification for ear biometric images	PATTERN RECOGNITION LETTERS										Ear biometric; Digital forensic; Source camera identification		In this paper a source camera identification algorithm for ear biometric images has been proposed based on tunable filter bank as a feature extractor. Maintaining the frequency selectivity property, distinct features are extracted by this filter bank, based on a half-band polynomial of 14th order. With the help of four ear databases, it is demonstrated that tunable filter bank based features correctly identify the sources of ear images with an average accuracy of 99.25% when there are limited number of camera sources available. It is also shown that accuracy would fall when significantly large number of cameras are introduced to acquire ear images. Depending on the experimental results, it can be well concluded that tunable filter bank based feature, apart from its recognition performance, is also a promising candidate to support forensic validation of camera source. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		139	147		10.1016/j.patrec.2018.10.009													
J								LPR-Net: Recognizing Chinese license plate in complex environments	PATTERN RECOGNITION LETTERS										License plate recognition; Deep neural network; License plate location; Character segmentation; Character recognition	RECOGNITION; CLASSIFICATION; ALGORITHM	License plate recognition (LPR) technology has been attracting increasing interest during recent years for its exclusive role in real world intelligent traffic management systems. Owing to its importance, numerous LPR methods have been developed. These methods are generally composed of three processing steps, i.e. license plate location, character segmentation and character recognition. However, the three-step scheme always yields unsatisfactory recognition performance in challenging complex environment like uneven illumination, adverse atmospheric conditions, complex backgrounds, unclear vehicle plates, low-quality surveillance camera, etc. In such scenes, the obtained license plates are usually not clear, which will cause imprecise results of localization and segmentation. Consequently, the recognition capacity is inadequate as its performance highly depends on the effects of localization and segmentation. To address these challenges, we propose a novel Chinese vehicle license plate recognition method to directly recognize license plate through an end-to-end deep learning architecture named license plate recognition net (LPR-Net). The LPR-Net is a hybrid deep architecture that consists of a residual error network for extracting basic features, a multi-scale net for extracting multi-scale features, a regression net for locating plate and characters, and a classification net for recognition. Moreover, an effective scheme based on batch normalization is used to accelerate training speed in the learning procedure. Extensive experiments demonstrate that the proposed method achieves excellent recognition accuracy and works more robustly and efficiently compared with the state-of-the-art methods in complex environments. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		148	156		10.1016/j.patrec.2018.09.026													
J								Pattern complexity-based JND estimation for quantization watermarking	PATTERN RECOGNITION LETTERS										Perceptual JND model; Pattern complexity; Logarithmic STDM; Watermarking robustness	DITHER MODULATION; PERCEPTUAL MODEL; INVARIANT	The perceptual just noticeable distortion (JND), which plays an important role in perceptual image watermarking and can refers to the optimal tradeoff between imperceptibility and robustness. Major challenges of the perceptual quantization watermarking approach are two-fold: (1) Most DCT-based JND models cannot accurately estimate the contrast masking effect due to the complicated interaction among visual contents. Research on cognitive science shows that the HVS is adaptive to extract the visual pattern for image understanding, and we can formulate the pattern complexity as another factor to determine the total watermarking strength. (2) Moreover, the calculated JND values will change as watermark embedding can affect the pixels of the image, i.e. the operation in cross-domain reduce the watermarking robustness. Therefore, in this regard, the maximum directional energy is calculated by three AC DCT coefficients, which can measure the different direction energy and keep the pattern complexity measurement insensitive to the changes caused by watermarking procedure. The luminance contrast is also calculated in the DCT domain. So a pattern complexity-based perceptual JND estimation model is designed by takeing DCT-based pattern complexity and luminance contrast into account. Furthermore, a new logarithmic quantization watermarking scheme is presented based on the proposed model to verify the feasibility and effectiveness of our proposed JND model. Experimental results show that the new built JND model can effectively enhance the robustness of the quantization watermarking scheme. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		157	164		10.1016/j.patrec.2018.08.009													
J								Multi-class joint subspace learning for cross-modal retrieval	PATTERN RECOGNITION LETTERS										Multi-class; Cross-modal retrieval; Subspace learning		Most existing supervised subspace learning methods use the label information for high-level semantic exploration and learn one couple of common mapping matrices for all classes in the retrieval task. However, there are different semantic distributions among different classes and thus we propose to learn different mapping matrices for different classes in this paper, which facilitates learning more discriminative subspace. In addition, semantic overlap usually exists among different classes, which is reflected through common samples in different classes. Therefore, the multi-class joint subspace learning algorithm (MJSL) is proposed to distinct the different classes and mine the potential shared information of semantic overlap as much as possible. Specifically, the MJSL method considers exploring high-level semantic, keeping pair-wised closeness and selecting optimal features to obtain the most discriminative subspace for each class. Meanwhile, the trace-norm based joint learning is used for exploring the potential shared information of semantic overlap among different classes. Since the optimal mapping matrices have been learned via an iterative joint optimization algorithm with fast convergence, a linear SVM classifier is trained to establish the mapping relationship between multi-modal data and their potential semantic classes. Thus, the most related mapping matrices can be identified for each query adaptively and the retrieval performance can be promoted. Extensive experiments on two popular public datasets demonstrate that our algorithm outperforms several state-of-the-art cross-modal retrieval algorithms. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		165	173		10.1016/j.patrec.2018.08.012													
J								Efficient weakly-supervised discrete hashing for large-scale social image retrieval	PATTERN RECOGNITION LETTERS										Hashing; Image retrieval	ALGORITHMS; REDUCTION	Hashing has been widely exploited for information retrieval recently, because of its high computation efficiency and low storage cost. However, many existing hashing methods cannot perform well on large-scale social image retrieval, due to the relaxed hash optimization and the lack of supervised semantic labels. In this paper, we propose an efficient Weakly-supervised Discrete Hashing (WDH) to solve the limitations. We formulate a unified weakly-supervised hash learning framework. It could effectively enrich the semantics of image hash codes with the freely obtained user-provided social tags and simultaneously remove their involved adverse noises. Furthermore, instead of relaxed hash optimization, we propose an efficient discrete hash optimization method based on Augmented Lagrangian Multiplier (ALM) to directly solve the hash codes without quantization information loss. Experiments on two standard social image datasets demonstrate the superior performance of the proposed method compared with several state-ofthe-art hashing techniques. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		174	181		10.1016/j.patrec.2018.08.033													
J								Multi-task learning for object keypoints detection and classification	PATTERN RECOGNITION LETTERS										Object keypoints detection; Classification; Multi-task learning		Object keypoints detection and classification are both central research topics in computer vision. Due to their wide range potential applications in the real world, substantial efforts have been taken to advance their performance. However, these two related tasks are mainly treated separately in previous works. We argue that keypoints detection and classification can be complementary tasks and beneficial to each other. Knowing the category of a object is able to reduce the searching space of keypoints detection models and facilitate more precise localization. On the other hand, having the knowledge of object keypoints can make classification models pay more attention on areas that are more associated with the object, which will inevitably promote classification accuracy. Embracing this observation, we propose to model keypoints detection and classification in a multi-task learning framework. Specifically, a multi-task deep network is designed and trained to conduct both tasks, where we devise the model structure delicately to carry out sufficient training of both tasks. Extensive experiments are set up on the AIFASHION DATASET and Human3.6M DATASET to validate our proposal, we show that our algorithm outperforms separate models trained individually on each task. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		182	188		10.1016/j.patrec.2018.08.013													
J								Learning cross-modal correlations by exploring inter-word semantics and stacked co-attention	PATTERN RECOGNITION LETTERS										Cross-modal correlation; Inter-word semantics; Fine-grained correlation; Stacked co-attention; Cross-modal retrieval		Cross-modal information retrieval aims to find heterogeneous data of various modalities from a given query of one modality. The main challenge is to learn the semantic correlations between different modalities and measure the distance across modalities. For text-image retrieval, existing work mostly uses off-the-shelf Convolutional Neural Network (CNN) for image feature extraction. For texts, word-level features such as bag-of-words or word2vec are employed to build deep learning models to represent texts. Besides word-level semantics, the semantic relations between words are also informative but less explored. In this paper, we explore the inter-word semantics by modelling texts by graphs using similarity measure based on word2vec. Besides feature presentations, we further study the problem of information imbalance between different modalities when describing the same semantics. For example textual descriptions often contain more background information that cannot be conveyed by images and vice versa. We propose a stacked co-attention network to progressively learn the mutually attended features of different modalities and enhance their fine-grained correlations. A dual-path neural network is proposed for cross-modal information retrieval. The model is trained by a pairwise similarity loss function to maximize the similarity of relevant text-image pairs and minimize the similarity of irrelevant pairs. Experimental results show that the proposed model outperforms the state-of-the-art methods significantly, with 19% improvement on accuracy for the best case. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		189	198		10.1016/j.patrec.2018.08.017													
J								Weakly-paired deep dictionary learning for cross-modal retrieval	PATTERN RECOGNITION LETTERS										Deep dictionary learning; Cross-modal retrieval; Weak pairing		Many multi-modal data suffers from significant weak-pairing characteristics, i.e., there is no sample-to-sample correspondence between modalities, rather classes of samples in one modality correspond to classes of samples in the other modality. This provides great challenges for the cross-modal learning for retrieval. In this work, our focus is learning cross-modal representations with minimal class label supervision and without correspondences between samples. To tackle this challenging problem, we establish a scalable hierarchical learning architecture to deal with the extensive weakly-paired heterogeneous multi-modal data. A shared classifier across different modalities is used to effectively deal with label supervision information, and a multi-modal low-rank model is introduced to encourage the modal-invariant representation. Finally, some cross-modal validations on publicly available datasets are performed to show the advantages of the proposed method. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		199	206		10.1016/j.patrec.2018.06.021													
J								Tensor-based sparse representations of multi-phase medical images for classification of focal liver lesions	PATTERN RECOGNITION LETTERS										Multi-phase CT; Tensor analysis; Sparse coding; Image classification; Focal liver lesion	CONTENT-BASED RETRIEVAL; BAG	Medical images play an important role in clinics. In most clinic sites, the diagnosis of diseases and the comprehending of disease progression need firstly accurate interpretation of the available medical images, which would be time-consuming in manual interpretation of the accumulated large amount of medical images. Thus automatical analysis and understanding of the available medical images become an active research topic, and therein, feature extraction of medical images plays an important role for achieving diagnosis performance. Natural images hold two-dimensional structures and linear statistical methods, such as k-means, GMM, and sparse coding, are widely applied for extracting compact and inherent representations. In contrast, medical images themselves have three-dimensional structures and possibly consist of multi-phase extension. Directly applying linear methods on the available medical data would lead to high dimensional vectors by reshaping the multi-dimensional data and would destroy the correlated relation among different dimensions of the raw medical data domain. Therefore, this study proposes a multilinear extension of the linear sparse coding for extracting compact and effective intermediate representations of the multi-dimensional local structures in multi-phase CT images, and aggregating the intermediate representations in the Bag-of-Visual-Words (BoVW) manner for classification of focal liver lesions (FLLs). In the proposed approach, three-layer volumes from the corresponding slices of multi-phase CT images are formed and spatiotemporal local structures from the volumes are extracted as 3rd-order tensors. Regarding the high dimensional local structures as tensors, we propose a K-CP (CANDECOMP/PARAFAC) algorithm to learn a tensor dictionary in an iterative way and extract the sparse representation with a multilinear OMP method. The aggregation of the sparse representation is implemented in the BoVW manner, which has been proved to be an effective method for extracting features from natural images and medical images. The proposed strategy is evaluated in classification of focal liver lesions and achieved better results than conventional BoVW with linear statistical methods. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		207	215		10.1016/j.patrec.2019.01.001													
J								A hierarchical autoencoder learning model for path prediction and abnormality detection	PATTERN RECOGNITION LETTERS										Motion features; Autoencoder; Hierarchical learning; Behavior understanding; Abnormality detection; Path prediction		In this paper, we introduce an unsupervised hierarchical framework for modeling trajectories in surveillance scenarios. Inspired by the object recognition field, a novel feature representation optimized for a neural network learning architecture is proposed. Low levels of the hierarchy capture local spatio-temporal motion attributes such as spatial orientation and speed, while higher levels contribute to obtaining richer semantic information. The bottom-up construction of the hierarchical framework exploits the inherent statistical correlations between neighboring elements using an increasing spatio-temporal grid. Cross-entropy based optimization in combination with autoencoders is used to learn weights for subsequent hierarchical layers. Finally, the Bayesian probabilistic framework built on top of the hierarchical model is proposed for applications such as long-term path prediction and abnormality detection. We demonstrate the efficiency of the proposed model on both indoor and outdoor datasets, achieving results comparable with state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		216	224		10.1016/j.patrec.2019.06.030													
J								Improved image clustering with deep semantic embedding	PATTERN RECOGNITION LETTERS										Semantic embedding; Image clustering; Deep neural networks; Deep autoencoder	CLASSIFICATION	Dimensionality reduction has found extensive use in the area of high dimensional data clustering. But unfortunately some valuable discriminative information might be lost in the process of dimensionality reduction, including feature extraction and feature selection. This issue inevitably degrades the performance of clustering algorithms. Recently, the semantic space embedding is emerging as a promising technique for state-of-the-art clustering methods, which can provide extra discriminative information and reasonably improve the clustering performance. In this paper, we plan to improve the performance of high dimensional image clustering by embedding semantic information into the original visual space. Inspired by the great success of deep learning, we employed a multi-layer autoencoder based on deep neural networks (DNNs) to undertake the semantic feature embedding and dimensionality reduction. By this way, the final image clustering task is carried out in the lower-dimensional feature space with deep semantic embedding. A series of experiments on acknowledged benchmark image datasets demonstrate that the proposed approaches can achieve superior performance over several existing clustering methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		225	233		10.1016/j.patrec.2018.10.022													
J								Polycrystalline silicon wafer defect segmentation based on deep convolutional neural networks	PATTERN RECOGNITION LETTERS										Polycrystalline silicon wafer; RPN; Defects segmentation; CNN	CRACK DETECTION; IMAGE CLASSIFICATION; TARGET DETECTION; INSPECTION; SURFACE; CELLS	Defect segmentation is an important way for defect detection in machine vision. For polycrystalline silicon wafer production, it is difficult to automatically segment defects due to its inhomogeneous background and unpredictable defect shapes. The conventional methods based on handcrafted models or features not only heavily rely on the expertise, but also are not flexible from one application case to another. In this paper, we propose a defect segmentation method for polycrystalline silicon wafer based on the deep convolutional networks. Firstly, we apply Region Proposal Network (RPN) to generate underlying defect regions. Then, these generated image patches are processed to suitable sizes for feeding into a improved segmentation network which is modified based on U-net and a dilation convolution. Real defect images are used to test the proposed method and experimental results show that proposed method achieves better performance compared with the state-of-the-art methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		234	241		10.1016/j.patrec.2018.12.013													
J								Spatio-temporal fall event detection in complex scenes using attention guided LSTM	PATTERN RECOGNITION LETTERS										Fall event detection; Fall event dataset; LSTM	TARGET DETECTION; MODEL	Fall events are one of the greatest risks for public safety, especially in some complex scenes with large number of people. Nevertheless, there are few researches on fall detection in complex scenes, and even no public datasets. A fall event dataset in crowded and complex scenes is constructed. Aiming at detecting fall events in complex scenes, we further propose an attention guided LSTM model. Our method provides the spatial and temporal locations of fall events, which are indispensable information for danger alarm in complex public scenes. Specifically, the effective YOLO v3 is employed to detect pedestrian in videos, and followed by a tracking module. CNN features are extracted for each tracked bounding boxes. Fall events are detected by the attention guided LSTM. Experimental results show that our method achieves good performance, outperforming the state-of-the-art methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		242	249		10.1016/j.patrec.2018.08.031													
J								A general non-parametric active learning framework for classification on multiple manifolds	PATTERN RECOGNITION LETTERS										Active learning; Multi-class classification; Label propagation; Non-parametric	QUANTIZATION; IMAGE	Active learning is an important paradigm for investigating learners' behavior and reducing costs on labeling. We propose a novel non-parametric active learning framework which utilizes label propagation to sense the potential data clusters/manifolds in the feature space and minimizes global uncertainty to investigate the unexplored clusters/manifolds for querying examples. Based on this framework, it is convenient to design new active learning algorithms for targeted problems. Furthermore, we analyze the sample selection mechanism of our proposed method and provide a formal proof. While selecting informative examples, our method has the following characteristics: (1) in each iteration, examples are primarily chosen from the cluster which contains unlabeled samples; (2) if there is more than one cluster with unlabeled samples, it will choose from the one containing the most samples; (3) the example which has the closest connection with the others will be preferentially selected for the same cluster. The designed algorithms achieve empirical success in multi-class classification and dramatically reduce the label costs on several real world datasets. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		250	258		10.1016/j.patrec.2019.01.013													
J								Multi-label chest X-ray image classification via category-wise residual attention learning	PATTERN RECOGNITION LETTERS										Chest X-ray; Residual attention; Convolutional neural network; Image classification	SEGMENTATION	This paper considers the problem of multi-label thorax disease classification on chest X-ray images. Identifying one or more pathologies from a chest X-ray image is often hindered by the pathologies unrelated to the targets. In this paper, we address the above problem by proposing a category-wise residual attention learning (CRAL) framework. CRAL predicts the presence of multiple pathologies in a class-specific attentive view. It aims to suppress the obstacles of irrelevant classes by endowing small weights to the corresponding feature representation. Meanwhile, the relevant features would be strengthened by assigning larger weights. Specifically, the proposed framework consists of two modules: feature embedding module and attention learning module. The feature embedding module learns high-level features with a convolutional neural network (CNN) while the attention learning module focuses on exploring the assignment scheme of different categories. The attention module can be flexibly integrated into any feature embedding networks with end-to-end training. The comprehensive experiments are conducted on the Chest X-ray14 dataset. CRAL yields the average AUC score of 0.816 which is a new state of the art. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		259	266		10.1016/j.patrec.2018.10.027													
J								Workflow recognition with structured two-stream convolutional networks	PATTERN RECOGNITION LETTERS										Workflow recognition; Action recognition; Deep learning; Two-stream CNNs		Intelligent monitoring plays an important role in the context of Industry 4.0 '', and behavior recognition is one of the research points in computer vision. However, monitoring the workflow of human beings and machines in production process is very difficult in the real-world complex factory environment. In this paper, we propose a novel workflow recognition framework based on the structured two-stream convolutional neural networks (CNNs) to recognize the behavior of both workers and machines. To improve the accuracy of workflow recognition, we use the CNNs to extract the spatial-temporal features and integrate an attention mechanism to detect the valuable behavior. Then, a Video Triple model is introduced to gain extra timestamp information, which can extend the behavior recognition to workflow recognition. Extensive simulation experiments are conducted on THUMOS'14 dataset and a real-world workflow dataset that show the significant performance improvement in video activity recognition. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		267	274		10.1016/j.patrec.2018.10.011													
J								Diverse fuzzy c-means for image clustering	PATTERN RECOGNITION LETTERS										Image clustering; Diversity regularization; Fuzzy c-means; Cluster one-sidedness	SPARSE REPRESENTATION; SYSTEMS; DATABASE; MODELS	Image clustering is a key technique for better accomplishing image annotation and searching in large image repositories. Fuzzy c-means and its variations have achieved excellent performance on image clustering because they allow each image to belong to more than one cluster. However, these methods neglect the relations between different image clusters, and hence often suffer from the "cluster one-sidedness" problem that redundant centers are learned to characterize the same or similar image clusters. To this issue, we propose a diverse fuzzy c-means for image clustering via introducing a novel diversity regularization into the traditional fuzzy c-means objective. This diversity regularization guarantees the learned image cluster centers to be different from each other and to fill the image data space as much as possible. An efficient optimization algorithm is exploited to address the diverse fuzzy c-means objective, which is proved to converge to local optimal solutions and has a satisfactory time complexity. Experiments on synthetic and six image datasets demonstrate the effectiveness of the proposed method as well as the necessity of the diversity regularization. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		275	283		10.1016/j.patrec.2018.07.004													
J								Bayesian query expansion for multi-camera person re-identification	PATTERN RECOGNITION LETTERS										Person re-identification; Re-rank; Query expansion	IMAGE; SEARCH	Person re-identification (re-ID) is challenging because pedestrians may exhibit distinct appearance under different cameras. Given a query image, previous methods usually output the person retrieval results directly, which may perform badly due to the limited information provided by the single query image. To mine more query information, we add an expansion step to post-process the initial ranking list. The intuition is that a true match in the gallery may be difficult to be found by the query alone, but it can be easily retrieved by other true matches in the initial ranking list. In this paper, we propose the Bayesian Query Expansion (BQE) method to generate a new query with information from the initial ranking list. The Bayesian model is used to predict true matches in the gallery. We apply pooling on the features of these "true matches" to get a single vector, i.e., the expanded new query, with which the retrieval process is performed again to obtain the final results. We evaluate BQE with various feature extraction methods and distance metric learning methods on four large-scale re-ID datasets. We observe consistent improvement over all the baselines and report competitive performances compared with the state-of-the-art results. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		284	292		10.1016/j.patrec.2018.06.009													
J								Engineering Hand-designed and Deeply-learned features for person Re-identification	PATTERN RECOGNITION LETTERS										Deep feature; Hand-crafted; Multimodal feature fusion; Person re-identification		Person re-identification is still a useful and challenging task in pattern recognition and computer vision. Based on a probe image, the task focuses on identifying a set of matching images from a gallery set. In this work, a novel multi-feature fusion-based person re-identification framework is proposed. The key technique is to intelligently fuze hand-crafted feature and deeply-learned feature. More specifically, hand-crafted features from both local and global region are extracted from each image. Afterward, a novel Convolutional Neural Networks (CNN) is trained based on combining the three datasets, wherein robust deep features can be obtained. Finally, the above hand-crafted feature as well as the deep features are optimally fuzed for calculating a robust re-identification result. Extensive experimental results on three state-of-the-art data sets have demonstrated the effectiveness of our method. (C) 2018 Published by Elsevier B.V.																	0167-8655	1872-7344				FEB	2020	130				SI		293	298		10.1016/j.patrec.2018.11.016													
J								Adaptive multi-view subspace clustering for high-dimensional data	PATTERN RECOGNITION LETTERS										Subspace clustering; Multi-view clustering; Adaptive learning; Feature selection	MODELS	With the rapid development of multimedia technologies, we frequently confront with high-dimensional data and multi-view data, which usually contain redundant features and distinct types of features. How to efficiently cluster such kinds of data is still a great challenge. Traditional multi-view subspace clustering aims to determine the distribution of views by extra empirical parameters and search the optimal projection matrix by eigenvalue decomposition, which is impractical for real-world applications. In this paper, we propose a new adaptive multi-view subspace clustering method to integrate heterogenous data in the low-dimensional feature space. Concretely, we extend K-means clustering with feature learning to handle high-dimensional data. Besides, for multi-view data, we evaluate the weights of distinct views according to their compactness of the cluster structure in the low-dimensional subspace. We apply the proposed method to four benchmark datasets and compare it with several widely used clustering algorithms. Experimental results demonstrate the effectiveness of the proposed method. (C) 2019 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		299	305		10.1016/j.patrec.2019.01.016													
J								Joint deep semantic embedding and metric learning for person re-identification	PATTERN RECOGNITION LETTERS										Person re-identification; Video re-id; Deep metric learning		We focus on the person re-identification (re-id) task, whose goal is to automatically re-identify individual persons from multiple non-overlapping cameras or the same camera across time. While most existing works rely on exploring properties of the visual data, we consider taking advantage of both visual and textual representations. Given images and natural language descriptions of the persons in the probe, the re-id system is required to rank all the samples in the gallery set. We embed the visual representations and textual descriptions in a unified space, in which we map similar examples close to each other and map dissimilar examples farther apart. Our premise is that, in general, strong semantic correlations exist between different persons. The space casts a person in gallery set as a combination of the persons in probe set. The model is trained in an end-to-end fashion. We conduct extensive experiments on the challenging i-LIDS, PRID-2011, CUHK03 and Market-1501 datasets, and confirm that the proposed model achieves state-of-the-art performances. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		306	311		10.1016/j.patrec.2018.08.011													
J								Parallel implementation for 3D medical volume fuzzy segmentation	PATTERN RECOGNITION LETTERS										Fuzzy C-means; Pattern recognition; 3D segmentation; GPU; Medical imaging; 3D visualization; Image processing	COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL NEURAL-NETWORK; IMAGE SEGMENTATION; CT; OPTIMIZATION; REGISTRATION; ALGORITHMS; SYSTEM	In the past, 2D models were the main models for medical image processing applications, whereas the wide adoption of 3D models has appeared only in recent years. The 2D Fuzzy C-Means (FCM) algorithm has been extensively used for segmenting medical images due to its effectiveness. Various extensions of it were proposed throughout the years. In this work, we propose a modified version of FCM for segmenting 3D medical volumes, which has been rarely implemented for 3D medical image segmentation. We present a parallel implementation of the proposed algorithm using Graphics Processing Unit (GPU). Researchers state that efficiency is one of the main problems of using FCM for medical imaging when dealing with 3D models. Thus, a hybrid parallel implementation of FCM for extracting volume objects from medical files is proposed. The proposed algorithm has been validated using real medical data and simulated phantom data. Segmentation accuracy of predefined datasets and real patient datasets were the key factors for the system validation. The processing times of both the sequential and the parallel implementations are measured to illustrate the efficiency of each implementation. The acquired results conclude that the parallel implementation is 5X faster than the sequential version of the same operation. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		312	318		10.1016/j.patrec.2018.07.026													
J								Fast semi-supervised learning with anchor graph for large hyperspectral images	PATTERN RECOGNITION LETTERS										Hyperspectral images (HSI) classification; Graph-based semi-supervised learning (SSL); Anchor graph	SEMISUPERVISED CLASSIFICATION; REGRESSION	As the labeled samples of hyperspectral image (HSI) are very scarce and labeling sample costs too much time and is expensive, semi-supervised learning (SSL) has an important application in hyperspectral image (HSI) classification. Among SSL approaches, graph-based SSL (GSSL) model has recently attracted much attention. However, most GSSL methods still can not deal with the large HSI as their high computational complexity. In this letter, we propose a novel approach, called fast semi-supervised learning with anchor graph (FSSLAG) to solve the large HSI classification problem. In the proposed FSSLAG algorithm, the anchor graph, which is parameter-free, naturally sparse and scale invariant, is first constructed. Then the label of samples can be inferred through the graph. The computational complexity of FSSLAG can be reduced to O(ndm), which is a significant improvement compared with traditional graph-based SSL methods that need O(n(3)), where n, d and m are the number of samples, features and anchors, respectively. Several experiments have demonstrated the effectiveness and efficiency of FSSLAG in terms of computational speed and classification accuracy. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		319	326		10.1016/j.patrec.2018.08.008													
J								Sequence in sequence for video captioning	PATTERN RECOGNITION LETTERS										Video captioning; Encoding; Decoding; Spatio-temporal representation		For video captioning, the words in the caption are closely related to an overall understanding of the video. Thus, a suitable representation for the video is rather important for the description. For more precise words in the task of video captioning, we aim to encode the video feature for current word at each time-stamp of the generation process. This paper proposes a new framework of 'Sequence in Sequence' to encode the sequential frames into a spatio-temporal representation at each time-stamp to utter a word and further distill most related visual content by an extra semantic loss. First, we aggregate the sequential frames to extract related visual content guided by last word, and get a representation with rich spatio-temporal information. Then, to decode the aggregated representation for a precise word, we leverage two layers of GRU structure, where the first layer further distills useful visual content based on an extra semantic loss and the second layer selects the correct word according to the distilled features. Experiments on two benchmark datasets demonstrate that our method outperforms the current state-ofthe-art methods on Bleu@4, METEOR and CIDEr metrics. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		327	334		10.1016/j.patrec.2018.07.024													
J								Semi-supervised cross-modal common representation learning with vector-valued manifold regularization	PATTERN RECOGNITION LETTERS										Cross-media retrieval; Vector-valued RKHS; Manifold regularization; Semi-supervised; Kernel method		While cross-media data, like text, image, audio, video and 3D model, has been the main form of big data, there is a current dearth of research on cross-media retrieval. In this paper, we focus on how to learn the common representation of heterogeneous data which is a key challenge for cross-media retrieval. Most existing approaches linearly project original low-level feature into a joint feature space for isomorphic data representation. However, linear projection cannot capture most complex cross-modal correlation with high nonlinearity. In this paper, we propose a novel feature learning algorithm, which is semi-supervised cross-modal vector-valued manifold regularization (SCVM), to explore common representation of heterogeneous data. SCVM jointly explores low-level feature correlation and semantic information in a unified framework. Based on manifold regularization, we learn cross-media features from vector-valued reproducing kernel Hilbert spaces (RKHS) by kernel transformation on both labeled and unlabeled samples; moreover, we impose smoothness constraints of possible solutions to improve retrieval accuracy. Comparing with the current state-of-the-art approaches on two public datasets, comprehensive experimental results show superior performance of our SCVM. The method is more robust and stable when extended from two media types to five media types, which is very attractive in practical application. (C) 2019 Published by Elsevier B.V.																	0167-8655	1872-7344				FEB	2020	130				SI		335	344		10.1016/j.patrec.2019.01.002													
J								Fast spectral clustering learning with hierarchical bipartite graph for large-scale data	PATTERN RECOGNITION LETTERS										Spectral clustering; Hierarchical graph; Bipartite graph; Large scale data; Out-of-sample		Spectral clustering (SC) is drawing more and more attention due to its effectiveness in unsupervised learning. However, all of these methods still have limitations. First, the method is not suitable for large-scale problems due to its high computational complexity. Second, the neighborhood weighted graph is constructed by the Gaussian kernel, meaning that more work is required to tune the heat-kernel parameter. In order to overcome these issues, we propose a novel spectral clustering based on hierarchical bipartite graph (SCHBG) approach by exploring multiple-layer anchors with a pyramid-style structure. First, the proposed algorithm constructs a hierarchical bipartite graph, and then performs spectral analysis on the graph. As a result, the computational complexity can be largely reduced. Furthermore, we adopt a parameter-free yet effective neighbor assignment strategy to construct the similarity matrix, which avoids the need to tune the heat-kernel parameter. Finally, the algorithm is able to deal with the out-of-sample problem for large-scale data and its computational complexity is significantly reduced. Experiments demonstrate the efficiency and effectiveness of the proposed SCHBG algorithm. Results show that the SCHBG approach can achieve good clustering accuracy (76%) on an 8-million datasets. Furthermore, owing to the use of the bipartite graph, the algorithm can reduce the time cost for out-of-sample situations with almost the same clustering accuracy as for large sizes of data. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		345	352		10.1016/j.patrec.2018.06.024													
J								Object detection with class aware region proposal network and focused attention objective	PATTERN RECOGNITION LETTERS										Convolutional neural networks; Object detection; Region proposal		In this paper, we propose a novel deep CNN-based framework to improve object detection performance. First, we introduce the Class Aware Region Proposal Network (CARPN) to produce high quality region proposals by using a new strategy for anchor generation, and by training the network with both bounding boxes and category labels of the objects. Instead of learning a binary object/non-object classifier for generating region proposals, we assign the class label to each anchor, and train the region proposal network with a multi-class loss. Second, we introduce the Focused Attention (FA) objective to encourage the network to learn features mainly from objects of interest while suppressing those features from the background region. As a result, false positive proposals caused by strong background features can be reduced to a large extent. Comprehensive experimental evaluations reveal that the proposed CARPN & FA framework remarkably outperforms the baseline Faster R-CNN method up to 4.1% mAP with a shallower network and 2.8% mAP with a deeper network, and achieves a better mAP than most of the latest state-of-the-art methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		353	361		10.1016/j.patrec.2018.09.025													
J								Subgraph learning for graph matching	PATTERN RECOGNITION LETTERS										Graph matching; Markov Chain Monte Carlo; Image matching; Object retrieval		Graph matching is a powerful tool for computer vision, distance measure and machine learning. However, many factors influences the accuracy of matching. The outliers is a key problem in the process of matching. In this paper, a novel approach is proposed to handle graph matching problem based on Markov Chain Monte Carlo framework. By constructing a target distribution, the proposed can perform a process of sampling to maximize the graph matching objective. In this process, our method can effectively save matching pairwise under one-to-one matching constraints and also avoid the effect of outliers and deformation. The corresponding experiments on synthetic graphs, real images and view-based 3D model retrieval demonstrate the superiority of the proposed method. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		362	369		10.1016/j.patrec.2018.07.005													
J								Efficient CNN based summarization of surveillance videos for resource-constrained devices	PATTERN RECOGNITION LETTERS										Video analysis; Video summarization; Surveillance; Energy-efficiency; Resource-constrained devices	FRAMEWORK; EXTRACTION	The widespread usage of surveillance cameras in smart cities has resulted in a gigantic volume of video data whose indexing, retrieval and management is a challenging issue. Video summarization tends to detect important visual data from the surveillance stream and can help in efficient indexing and retrieval of required data from huge surveillance datasets. In this research article, we propose an efficient convolutional neural network based summarization method for surveillance videos of resource-constrained devices. Shot segmentation is considered as a backbone of video summarization methods and it affects the overall quality of the generated summary. Thus, we propose an effective shot segmentation method using deep features. Furthermore, our framework maintains the interestingness of the generated summary using image memorability and entropy. Within each shot, the frame with highest memorability and entropy score is considered as a keyframe. The proposed method is evaluated on two benchmark video datasets and the results are encouraging compared to state-of-the-art video summarization methods. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		370	375		10.1016/j.patrec.2018.08.003													
J								Unsupervised object-level video summarization with online motion auto-encoder	PATTERN RECOGNITION LETTERS										Object-level video summarization; Online motion auto-encoder; Stacked sparse LSTM auto-encoder		Unsupervised video summarization plays an important role on digesting, browsing, and searching the ever-growing videos every day, and the underlying fine-grained semantic and motion information (i.e., objects of interest and their key motions) in online videos has been barely touched. In this paper, we investigate a pioneer research direction towards the fine-grained unsupervised object-level video summarization. It can be distinguished from existing pipelines in two aspects: extracting key motions of participated objects, and learning to summarize in an unsupervised and online manner. To achieve this goal, we propose a novel online motion Auto-Encoder (online motion-AE) framework that functions on the super-segmented object motion clips. Comprehensive experiments on a newly-collected surveillance dataset and public datasets have demonstrated the effectiveness of our proposed method. (C) 2018 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				FEB	2020	130				SI		376	385		10.1016/j.patrec.2018.07.030													
J								LPV-MP planning for autonomous racing vehicles considering obstacles	ROBOTICS AND AUTONOMOUS SYSTEMS										Autonomous driving; Racing planning; MPC; LPV; Obstacle avoidance	PATH	In this paper, we present an effective online planning solution for autonomous vehicles that aims at improving the computational load while preserving high levels of performance in racing scenarios. The method follows the structure of the model predictive (MP) optimal strategy where the main objective is to maximize the velocity while smoothing the dynamic behavior and fulfilling varying constraints. We focus on reformulating the non-linear original problem into a pseudo-linear problem by convexifying the objective function and reformulating the non-linear vehicle equations to be expressed in a Linear Parameter Varying (LPV) form. In addition, the ability of avoiding obstacles is introduced in a simple way and with reduced computational cost. We test and compare the performance of the proposed strategy against its non-linear approach through simulations. We focus on testing the performance of the trajectory planning approach in a racing scenario. First, the case of free obstacles track and afterwards a scenario including static obstacles. Simulation results show the effectiveness of the proposed strategy by reducing the algorithm elapsed time while finding appropriate trajectories under several input/state constraints. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103392	10.1016/j.robot.2019.103392													
J								Shape-centric modeling for control of traveling wave rectilinear locomotion on snake-like robots	ROBOTICS AND AUTONOMOUS SYSTEMS										Snake-like robot; Rectilinear; Dynamics; Trajectory planning; Control	GAIT GENERATION; KINEMATICS; FRAMEWORK; MOTION	A traveling wave rectilinear gait for elongated, continuous bodies is modeled as a cyclically-varying backbone curve. The gait shapes are represented as planar deviations relative to an average body curve and an associated, rigidly-attached body frame. Body-ground contact patterns and other geometric properties integral to computation of external forcing are conveniently defined with respect to this average body curve. Introducing a body-ground rolling friction model permits the controlled equations of motion to be derived in closed form. Incorporating a constant curvature into the average body realizes turning movements, and hence turning control. Repeated numerical integration of the system dynamics facilitates construction of a control-to-action mapping, characterizing steady system behavior with respect to the gaits parameter space. The control-to-action map reduces this complex dynamical system to a kinematic unicycle model for which feedback tracking strategies are well understood. To illustrate its utility, it is applied in a trajectory planning and tracking framework for locomotion around obstacles. Using the framework, a robotic snake exercising the traveling wave rectilinear gait successfully plans feasible trajectories and traverses non-trivial obstacle arrangements to reach specified goal positions. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103406	10.1016/j.robot.2019.103406													
J								Robust aerial scene-matching algorithm based on relative velocity model	ROBOTICS AND AUTONOMOUS SYSTEMS										Scene matching; Feature points; Aerial image; Inertial navigation system; Horizontal pixel boundary	VISUAL TERRAIN INFORMATION; VEHICLE MOTION ESTIMATION; IMAGE REGISTRATION; UAV; LOCALIZATION; NAVIGATION; FEATURES	We present a robust scene-matching (SM) algorithm using time-invariant features that are propagated and bounded by a model propagator and pixel boundary. The SM based absolute navigation has the advantage that the position of the vehicle can be independently calculated without external information, making it possible to calculate a stable navigation solution without cumulative errors. However, SM-based absolute localization has a mismatching problem, this is due to the difference between the reference for the matching and the input image, and the more the change, the higher the probability of mismatching. In this paper we propose an algorithm that can mitigate the mismatching problem with a model-based propagator and time-invariant features. The propagator is based on a relative velocity of the inertial navigation system (INS) model, which is very accurate for a short time. Also the propagated feature points have pixel boundaries, which considers not only INS model uncertainty but also distortion of the aerial images caused by various terrain characteristics. The proposed algorithm is verified by simulation using real experimental data. Consequently we can found the proposed algorithm is very effective in mitigating the mismatching problem in urban areas. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103372	10.1016/j.robot.2019.103372													
J								Practical formulation of obstacle avoidance in the Task-Priority framework for use in robotic inspection and intervention scenarios	ROBOTICS AND AUTONOMOUS SYSTEMS										I-AUV; Set-based Task-Priority; Obstacle avoidance; Robot control; Valve turning		This paper presents a new formulation of a reactive obstacle avoidance algorithm, in the Task-Priority framework, delivering a practical solution for obstacle avoidance between vehicle-manipulator systems and complex environments. The presented concepts were implemented on an intervention autonomous underwater vehicle (I-AUV) and tested in an underwater pipe structure inspection and valve turning scenario, in a test tank, using GIRONA500 with an ECA 5E Micro manipulator. The obstacle avoidance is treated as an inequality (set-based) task, which takes into account all obstacles that are interacting with the robot links. Both the robot and the obstacles are represented by spheres to allow for analytical formulation. However, the environment is wrapped with spheres based on its actual geometry stored as an Octomap, hence it can be represented at different resolutions. Depending on the type of the mission performed by the robot we defined two modes of operation: (1) Navigation and Inspection, and (2) Intervention. For each mode, the algorithm takes into account different number of key points at the I-AUV and a different resolution of the environment representation. Typically, for the Intervention mode the resolution is higher, to allow for more precise motion. We also present an escape point strategy in case of the robot getting stuck between obstacles. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103396	10.1016/j.robot.2019.103396													
J								Safety barrier functions and multi-camera tracking for human-robot shared environment	ROBOTICS AND AUTONOMOUS SYSTEMS										Human-robot interaction; Collision avoidance; Control barrier function	INDUSTRIAL ROBOTS	A new vision in human-robot collaboration has allowed to place robots nearby human operators, working close to each other in industrial environments. As a consequence, human safety has become a dominant issue, together with production efficiency. In this paper we propose an optimization-based control algorithm that allows robots to avoid obstacles (like human operators) while minimizing the difference between the nominal acceleration input and the commanded one. Control Barrier Functions are exploited to build safety barriers around each robot link, to guarantee collision-free trajectories along the whole robot body. Human accelerations and velocities are computed by means of a bank of Kalman filters. To solve obstruction problems, two RGB-D cameras are used and the measured skeleton data are processed and merged using the mentioned bank of Kalman filters. The algorithm is implemented on an Universal Robots UR5 in order to validate the proposed approach. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103388	10.1016/j.robot.2019.103388													
J								Distributed tunneling reconfiguration of cubic modular robots without meta-module's disassembling in severe space requirement	ROBOTICS AND AUTONOMOUS SYSTEMS										Cubic modular robots; Reconfiguration algorithm; Distributed robots	LOCOMOTION	This paper studies a tunneling-based reconfiguration algorithm for cubic modular robots. Tunneling-based reconfiguration is a promising approach for cubic modular robot reconfiguration in severe space requirements. This is because a tunneling modular robot only uses spaces occupied by the start and goal configurations. However, previously proposed methods have a limitation on the arrangement of the start and goal configurations, in which the overlapped part between them must be connected. We propose a tunneling reconfiguration algorithm that removes the limitation and is available for cases with multi-overlapped parts between the start and goal configurations. It is often the case that a tunneling-based reconfiguration assumes the use of a meta-module-based structure to maintain the connectivity and mobility of the robot structure. However, in previous methods, the meta-modules often come apart during the tunneling process, and each module belongs to a different meta-module before and after the reconfiguration. The proposed algorithm also solves this problem. We implement the algorithm in a distributed form and prove its completeness for assumed robot structures. We examine the proposed tunneling algorithm by simulation. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103369	10.1016/j.robot.2019.103369													
J								Monocular person tracking and identification with on-line deep feature selection for person following robots	ROBOTICS AND AUTONOMOUS SYSTEMS										Person tracking; Person identification; Mobile robot	PEOPLE	This paper presents a new person tracking and identification framework based on solely a monocular camera. In this framework, we first track persons in the robot coordinate space using Unscented Kalman filter with the ground plane information and human height estimation. Then, we identify the target person to be followed with the combination of Convolutional Channel Features (CCF) and online boosting. It allows us to take advantage of deep neural network-based feature representation while adapting the person classifier to a specific target person depending on the circumstances. The entire system can be run on a recent embedded computation board with a GPU (NVIDIA Jetson TX2), and it can easily be reproduced and reused on a new mobile robot platform. Through evaluations, we validated that the proposed method outperforms existing person identification methods for mobile robots. We applied the proposed method to a real person following robot, and it has been shown that CCF-based person identification realizes robust person following in both indoor and outdoor environments. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103348	10.1016/j.robot.2019.103348													
J								Bootstrapped Neuro-Simulation as a method of concurrent neuro-evolution and damage recovery	ROBOTICS AND AUTONOMOUS SYSTEMS										Evolutionary robotics; Evolutionary computation; Machine learning	NETWORK DEVELOPMENT; CONTROLLER; REALITY; ROBOTS	Bootstrapped Neuro-Simulation (BNS) is a method of concurrent simulator and robot controller evolution. The algorithm requires little domain knowledge and no pre-investigation data gathering. Additionally, it bridges the reality gap effectively, rapidly evolves functional controllers, and recovers from damage automatically. In this paper, the first evidence of the ability of BNS to evolve closed-loop controllers is shown; in this case to solve a light-following problem. The algorithm is then evaluated for its damage recovery ability for these closed-loop controllers and shown to be very effective, with only minor adaptations. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103398	10.1016/j.robot.2019.103398													
J								A dual-stage parking system for differential-drive robots	ROBOTICS AND AUTONOMOUS SYSTEMS										Asymptotic parking; Nonholonomic systems; Singularity line; Parking controller; Tracking controller	EXPONENTIAL STABILIZATION; DESIGN	Due to the nonholonomic constraints, it is challenging to asymptotically stabilize a differential-drive robot at an arbitrary pose with desirable transient response. In this paper, an advanced parking system is introduced to tackle the problem of nonholonomic stabilization from an arbitrary starting position. The overall parking process is composed of two stages: a reference tracking stage and an asymptotically stabilization one. In the tracking stage, a reference trajectory is carefully generated by taking the robot kinematic constraints into consideration. An existing reference tracking controller is adopted to drive the robot to follow the prescribed route. In the second stage, a parking controller is switched on and is able to asymptotically stabilize the robot by taking advantage of straight and smooth motions in a "singularity line". The overall performance of the parking system has been validated through simulation and real experiments. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103365	10.1016/j.robot.2019.103365													
J								Estimation and exploitation of objects' inertial parameters in robotic grasping and manipulation: A survey	ROBOTICS AND AUTONOMOUS SYSTEMS										Robot identification; Inertial parameters; Object dynamics; Robot grasping and manipulation	IDENTIFICATION METHOD; IMPEDANCE CONTROL; MASS ESTIMATION; PERCEPTION; VOLUME; TENSOR; STABILITY; CONTACT; FRUITS; HANDS	Inertial parameters characterise an object's motion under applied forces, and can provide strong priors for planning and control of robotic actions to manipulate the object. However, these parameters are not available a-priori in situations where a robot encounters new objects. In this paper, we describe and categorise the ways that a robot can identify an object's inertial parameters. We also discuss grasping and manipulation methods in which knowledge of inertial parameters is exploited in various ways. We begin with a discussion of literature which investigates how humans estimate the inertial parameters of objects, to provide background and motivation for this area of robotics research. We frame our discussion of the robotics literature in terms of three categories of estimation methods, according to the amount of interaction with the object: purely visual, exploratory, and fixed-object. Each category is analysed and discussed. To demonstrate the usefulness of inertial estimation research, we describe a number of grasping and manipulation applications that make use of the inertial parameters of objects. The aim of the paper is to thoroughly review and categorise existing work in an important, but under-explored, area of robotics research, present its background and applications, and suggest future directions. Note that this paper does not examine methods of identification of the robot's inertial parameters, but rather the identification of inertial parameters of other objects which the robot is tasked with manipulating. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103374	10.1016/j.robot.2019.103374													
J								A robot-assisted bilateral upper limb training strategy with subject-specific workspace: A pilot study	ROBOTICS AND AUTONOMOUS SYSTEMS										Robot-assisted; Bilateral; Upper limb; Training strategy; Subject-specific workspace	REHABILITATION ROBOT; THERAPY; EXOSKELETON	This paper proposes a new robot-assisted bilateral upper limb training strategy, focusing on the bilateral coordination of users' upper limbs. The strategy is implemented and evaluated on a bilateral upper limb rehabilitation device (BULReD) that is an H-bot mechanism actuated by two Maxon DC motors. The control system consists of a position controller, an admittance controller and an adaptive algorithm, where the BULReD stiffness is modified session by session based on training performance. This strategy is also integrated with subject-specific workspace for enhanced training safety. Experiments were carried out with five subjects through active reaching tasks. Results indicate that the proposed training strategy requires significant coordination of bilateral upper limbs for task completion, and is able to tune control parameters to an appropriate difficulty level based on participants' training performance. Future work will focus on its clinical evaluation on patients with upper limb disabilities. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103334	10.1016/j.robot.2019.103334													
J								Self-optimization of resilient topologies for fallible multi-robots	ROBOTICS AND AUTONOMOUS SYSTEMS										Fault-tolerance; Resilience; Multi-robot systems; Connectivity; Graph theory; Control; Online optimization; Robotic hardware	CONNECTIVITY MAINTENANCE; COVERAGE; SWARM	Effective exchange of information in multi-robot systems is one of the grand challenges of today's robotics. Here, we address the problem of simultaneously maximizing the (i) resilience to faults and (ii) area coverage of dynamic multi-robot topologies. We want to avoid the onset of single points of failure, i.e., situations in which the failure of a single robot causes the loss of connectivity in the overall network. Our methodology is based on (i) a three-fold control law and (ii) a distributed online optimization strategy that computes the optimal choice of control parameters for each robot. By doing so, connectivity is not only preserved, but also made resilient to failures as the network topology evolves. To assess the effectiveness of our approach, we ran experiments with a team of eight two-wheeled robots and we evaluated it against the injection of two separate classes of faults: communication and hardware failures. Results show that the proposed approach continues to perform as intended, even in the presence of these hazards. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103384	10.1016/j.robot.2019.103384													
J								A chaotic path planning generator based on logistic map and modulo tactics	ROBOTICS AND AUTONOMOUS SYSTEMS										Autonomous mobile robot; Path planning; Terrain coverage; Chaos; Logistic map	MOBILE ROBOT; SURVEILLANCE MISSIONS; BOUNDARY SURVEILLANCE; COVERAGE; SYSTEM	A simple, short and efficient chaotic path planning algorithm is proposed for autonomous mobile robots, with the aim of covering a given terrain using chaotic, unpredictable motion. The proposed technique utilizes the logistic map with a chaotic tactic that utilizes a modulo function to produce a sequence of directions for a robot that can move in eight different directions on a grid. Extensive simulations are performed, and the results show a fast and efficient scanning of the given area. In addition, the proposed algorithm is further enhanced with a pheromone inspired memory technique, with good improvements in efficiency. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103377	10.1016/j.robot.2019.103377													
J								Active robot-assisted feeding with a general-purpose mobile manipulator: Design, evaluation, and lessons learned	ROBOTICS AND AUTONOMOUS SYSTEMS										Assistive robots; Manipulation; Assistive feeding; Meal assistance	SYSTEM	Eating is an essential activity of daily living (ADL) for staying healthy and living at home independently. Although numerous assistive devices have been introduced, many people with disabilities are still restricted from independent eating due to the devices physical or perceptual limitations. In this work, we present a new meal-assistance system and evaluations of this system with people with motor impairments. We also discuss learned lessons and design insights based on the evaluations. The meal-assistance system uses a general-purpose mobile manipulator, a Willow Garage PR2, which has the potential to serve as a versatile form of assistive technology. Our active feeding framework enables the robot to autonomously deliver food to the users mouth, reducing the need for head movement by the user. The user interface, visually-guided behaviors, and safety tools allow people with severe motor impairments to successfully use the system. We evaluated our system with a total of 10 able-bodied participants and 9 participants with motor impairments. Both groups of participants successfully ate various foods using the system and reported high rates of success for the system's autonomous behaviors. In general, participants who operated the system reported that it was comfortable, safe, and easy-to-use. (C) 2019 The Authors. Published by Elsevier B.V.																	0921-8890	1872-793X				FEB	2020	124								103344	10.1016/j.robot.2019.103344													
J								Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks	ROBOTICS AND AUTONOMOUS SYSTEMS										Inverse kinematics; Inverse dynamics; Generative adversarial networks	MODEL	Obtaining inverse kinematics and dynamics of a robotic manipulator is often crucial for robot control. Analytical models are typically used to approximate real robot systems, and various controllers have been designed on top of the analytical model to compensate for the approximation error. Recently, machine learning techniques have been developed for error compensation, resulting in better performance. Unfortunately, combining a learned compensator with an analytical model makes the designed controller redundant and computationally expensive. Also, general machine learning techniques require a lot of data to perform the training process and approximation, especially in solving high dimensional problems. As a result, state-of-the-art machine learning applications are either expensive in terms of computation and data collection, or limited to a local approximation for a specific task or routine. In order to address the high dimensionality problem in learning inverse kinematics and dynamics, as well as to make the training process more data efficient, this paper presents a novel approach using a series of modified Generative Adversarial Networks (GANs). Namely, we use Conditional GANs (CGANs), Least Squares GANs (LSGANs), Bidirectional GANs (BiGANs) and Dual GANs(DualGANs). We trained and tested the proposed methods using real-world data collected from two types of robotic manipulators, a MICO robotic manipulator and a Fetch robotic manipulator. The data input to the GANs was obtained using a sampling method applied to the real data. The proposed approach enables approximating the real model using limited data without compromising the performance and accuracy. The proposed methods were tested in real-world experiments using unseen trajectories to validate the "learned" approximate inverse kinematics and inverse dynamics as well as to demonstrate the capability and effectiveness of the proposed algorithm over existing analytical models. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103386	10.1016/j.robot.2019.103386													
J								Lagrange modeling and navigation based on quaternion for controlling a micro AUV under perturbations	ROBOTICS AND AUTONOMOUS SYSTEMS										Underwater vehicle; Dynamic model; Lagrange; Quaternions; Adaptive sliding mode control		This paper addresses the modeling of an autonomous underwater vehicle using quaternion formulation for angular position description and Lagrange method to compute the equations of motion. As the four parameters are dependent and generate a constraint, Lagrange multipliers are used with Baumgarte method to solve and stabilize the system. The dynamic model includes underwater effects like added mass and inertia, hydrodynamic damping, buoyancy and propeller forces. Moreover, a quaternion-based line of sight guidance algorithm is derived to avoid any use of trigonometric function and compute directly the orientation error of the underwater vehicle and the desired attitude in terms of quaternions. Motion control is achieved with a quaternion-based adaptive sliding mode controller rejecting model uncertainties and water current. The simulation results, where the vehicle follows a sequence of way-points including vertical diving motion demonstrate that the proposed guidance algorithm and motion control are deeply relevant both in terms of effectiveness and robustness for this particular type of vehicle and orientation formulation. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103408	10.1016/j.robot.2019.103408													
J								Evolution of robust high speed optical-flow-based landing for autonomous MAVs	ROBOTICS AND AUTONOMOUS SYSTEMS										Evolutionary robotics; Bio-inspired landing; Reality gap; High speed flight	STRATEGY	Automatic optimization of robotic behavior has been the long-standing goal of Evolutionary Robotics. Allowing the problem at hand to be solved by automation often leads to novel approaches and new insights. A common problem encountered with this approach is that when this optimization occurs in a simulated environment, the optimized policies are subject to the reality gap when implemented in the real world. This often results in sub-optimal behavior, if it works at all. This paper investigates the automatic optimization of neurocontrollers to perform quick but safe landing maneuvers for a quadrotor micro air vehicle using the divergence of the optical flow field of a downward looking camera. The optimized policies showed that a piece-wise linear control scheme is more effective than the simple linear scheme commonly used, something not yet considered by human designers. Additionally, we show the utility in using abstraction on the input and output of the controller as a tool to improve the robustness of the optimized policies to the reality gap by testing our policies optimized in simulation on real world vehicles. We tested the neurocontrollers using two different methods to generate and process the visual input, one using a conventional CMOS camera and one a dynamic vision sensor, both of which perform significantly differently than the simulated sensor. The use of the abstracted input resulted in near seamless transfer to the real world with the controllers showing high robustness to a clear reality gap. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103380	10.1016/j.robot.2019.103380													
J								RISE-based adaptive control for EICoSI exoskeleton to assist knee joint mobility	ROBOTICS AND AUTONOMOUS SYSTEMS										Adaptive controller; Asymptotic stability; RISE feedback; Knee exoskeleton	NONLINEAR-SYSTEMS; ASYMPTOTIC TRACKING; ROBOT; REHABILITATION; ORTHOSIS; WALKING; DESIGN; ADAPTATION; STROKE	Exoskeleton devices are used to assist joint motion of subjects suffering from mobility deficiencies. Controlling an exoskeleton subjects to high nonlinearities, which are mainly due to the mechanical coupling, external disturbances, parameter uncertainties, and modeling errors. Keeping in view the requirement of a relatively accurate movement tracking while reducing the disturbances effects, there is a need for a robust controller. In this paper, an adaptive RISE (Robust Integral of Sign Error) controller is developed and implemented on the EICoSI (Exoskeleton Intelligently Communicating and Sensitive to Intention) knee exoskeleton. RISE has an advantage over standard controllers that it achieves semi-global asymptotic tracking even in the presence of unstructured disturbances. But to achieve this tracking, high control gains are required. Thus, to limit such high gains, RISE control strategy is combined with an adaptive controller, which has the advantage of improving the tracking performance while reducing the eventual overshoots. The stability of the coupled human/ exoskeleton system is analyzed based on Lyapunov theory and the system has shown semi-global asymptotic stability. The adaptive RISE controller gives better SNR (signal to noise ratio) by 11% and 2% as compared with adaptive and RISE controller respectively. In terms of tracking error, the adaptive RISE controller shows 9% more RMSE than adaptive controller but 41% less when compared with RISE controller Three experimental scenarios are analyzed to validate the proposed controller, namely (i) external disturbances, that could come from the ground during walking; (ii) induced payload, that could come from the resistive/assistive torque from the muscles and (iii) payload with external disturbances. The system is found to be robust and efficient in tracking the reference trajectories while maintaining limited error and high signal to noise ratio. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103354	10.1016/j.robot.2019.103354													
J								Waterline and obstacle detection in images from low-cost autonomous boats for environmental monitoring	ROBOTICS AND AUTONOMOUS SYSTEMS										Water detection; Autonomous surface vessels; Robotic boats; Robot vision; Water quality monitoring		Waterline detection from images taken by cameras mounted on low-cost autonomous surface vehicles (ASVs) is a key process for obtaining a fast obstacle detection. Achieving an accurate waterline prediction is difficult due to the instability of the ASV on which the camera is mounted and the presence of reflections, illumination changes, and waves. In this work, we present a method for waterline and obstacle detection designed for low-cost ASVs employed in environmental monitoring. The proposed approach is made of two steps: (1) a pixel-wise segmentation of the current image is used to generate a binary mask separating water and non-water regions, (2) the mask is analyzed to infer the position of the waterline, which in turn is used for detecting obstacles. Experiments were carried out on two publicly available datasets containing floating obstacles such as buoys, sailing and motor boats, and swans moving near the ASV. Quantitative results show the effectiveness of the proposed approach with 98.8% pixel-wise segmentation accuracy running at 10 frames per second on an embedded GPU board. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103346	10.1016/j.robot.2019.103346													
J								A data-driven approach to probabilistic impedance control for humanoid robots	ROBOTICS AND AUTONOMOUS SYSTEMS										Impedance control; Probabilistic model; Humanoid robot	IMITATION; TASK	This paper presents a novel approach toward synthesizing whole-body motions from visual perception and reaction force for a humanoid robot that maintains a suitable physical interaction with an environment. A behavior containing a whole-body motion, reaction force, and visual perception is encoded into a probabilistic model referred to as a "motion symbol". The humanoid robot selects a motion symbol appropriate to the current situation and computes references for joint angles and reaction forces according to the selected symbol. The robot subsequently modifies these references to satisfy a desired impedance relating the robot whole-body positions and forces. This computation builds visual and physical feedback loops with knowledge about the behaviors, making it possible for a humanoid robot to not only perform human-like motion behaviors similar to training behaviors, but to also physically adapt to the immediate environment. We applies this proposed framework only to controlling the upper-body motion for a humanoid robot. Experiments demonstrate that the proposed method allows a humanoid robot to control its upper-body motion in response to visual perception and reaction forces acting on its hands to achieve five tasks while controlling its lower-body motion for its balance. (C) 2019 The Authors. Published by Elsevier B.V.																	0921-8890	1872-793X				FEB	2020	124								103353	10.1016/j.robot.2019.103353													
J								Representation and classification of whole-body motion integrated with finger motion	ROBOTICS AND AUTONOMOUS SYSTEMS										Motion primitive; Motion classification; Stochastic model	LANGUAGE; PRIMITIVES	This paper presents a novel approach toward representing human whole-body motions with fingers and classification of human motions while performing tasks that require delicate finger movements, such as holding or grasping. Human whole-body motions are recorded using an optical motion capture system that measures positions of markers attached to a performer. Additionally, the performer wears data gloves with strain gauges fixed at the finger joints to measure flexions and extensions. Combining whole-body motion with finger motions forms a representation of integrated motion, which is subsequently encoded into a probabilistic model whose parameters are optimized such that the model most likely generates the training data for the integrated motion. Observations of integrated motion are classified into the relevant probabilistic model with the largest probability of generating the observation. Synchronous measurements of human whole-body and finger motions created a dataset of integrated human motions. We tested our proposed approach on this dataset, thereby demonstrating that representations of whole-body motion integrated with finger motions improved classification of human motions while manipulating objects. (C) 2019 The Authors. Published by Elsevier B.V.																	0921-8890	1872-793X				FEB	2020	124								103378	10.1016/j.robot.2019.103378													
J								Robust mission planning for Autonomous Marine Vehicle fleets	ROBOTICS AND AUTONOMOUS SYSTEMS										Planning Al; Multi-robot systems; Marine robotics	ORIENTEERING PROBLEM; ARCHITECTURE; ALGORITHM	Mission planning for Autonomous Marine Vehicles (AMVs) is non-trivial because significant uncertainty is present when profiling the operating environment, especially for underwater missions. Mission complexity is compounded for each vehicle added to the mission. In practice, fleet operations are formulated as separate temporal problems by the operator and solved using a temporal planner. This paper proposes a planning method that uses energy as the base planning resource instead of time. Unlike temporal planners, energy planners account for physical loads endured by the vehicles. The extent of uncertainty in the vehicle loads is clarified by using the vehicle dynamics model and Monte Carlo simulation on the model parameters. The planning method is a multistage procedure to decompose operator specified task, obstacle, and vehicle data into an energy formulation of the Team Orienteering Problem (TOP) which is then solved using Discrete Strengthened PSO (DStPSO). The DStPSO algorithm has been modified to include a selective swarm size decay method that allows for larger initial swarm sizes to promote early exploration and preserves a percentage of the best performing particles on each iteration to save computational resources. The planner produces near-optimal routes containing feasible trajectories for individual vehicles that maximise tasks completed according to individual vehicle energy constraints. A case-study mission for long-term, large-scale, underwater inspection of a wind turbine array was converted into input data to evaluate the planner. Energy planning presents the opportunity for vehicles to actively monitor the feasibility of their individual plan against their current energy consumption, allowing for advanced reasoning and fault handling to occur in situ without operator assistance. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103404	10.1016/j.robot.2019.103404													
J								A synthetic dataset for Visual SLAM evaluation	ROBOTICS AND AUTONOMOUS SYSTEMS										Synthetic dataset; Computer graphic; Visual SLAM; Algorithm validation; Evaluation criteria	ODOMETRY; VISION	Vision-based self-localization methods are key functionalities for various research topics. Recent research results on related fields have catalyzed several accurate, versatile and reliable real-time Visual SLAM systems suitable for self-localization under a wide variety of environmental preconditions. These methods extend their functionalities from being only a good camera tracker to being able to recursively build up camera's surroundings. The fast development of Visual SLAM research has proposed demands on innovating evaluation methods for Visual SLAM systems. However, retrieving images and ground truth from various kinds of environments, estimating calibration parameters between several sensors and annotating useful labels all require cumbersome human labor and will introduce inevitable errors. In this paper, we propose a method that uses virtually established models to automatically generate photorealistic images with accurate ground truth and several kinds of pixel-level annotations useful for Visual SLAM development and evaluation. We build and render a challenging dataset in low-texture environments with large scale camera movement, multiple moving objects and varying luminance status. We also propose several new evaluation criteria that can fully take advantage of ground truth and annotations from synthetic datasets. Experiments are conducted using the proposed datasets and criteria with several state-of-the-art Visual SLAM methods to demonstrate the functionality of our datasets. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103336	10.1016/j.robot.2019.103336													
J								Disturbance compensation based controller for an indoor blimp robot	ROBOTICS AND AUTONOMOUS SYSTEMS										Blimp robot; Navigation; Estimation; Uncertainty compensation; Robust control	TRAJECTORY TRACKING; PATH-TRACKING; AIRSHIP; SYSTEM	This paper presents the robust controller design for an indoor blimp robot to achieve application such as the surveillance. The commonly used 6 degrees of freedom dynamic model is simplified under reasonable assumptions and decoupled into two independent parts. The blimp simplified horizontal plane movement model is complemented with disturbance terms to ensure the modeling accuracy, then it is transformed to a simpler form for the ease of controller design. Next, the disturbance terms are evaluated by the designed real-time estimator, and the perturbation estimates are compensated in the conceived motion controller for cancellation of the influence of disturbances. The performance and robustness of the disturbance compensation-based controller are verified by both simulations and experiments on the developed blimp robot. Finally, the results prove the feasibility of the blimp robot in indoor surveillance application by stabilizing itself at a fixed position or patrolling along a predefined path. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103402	10.1016/j.robot.2019.103402													
J								A survey of underwater docking guidance systems	ROBOTICS AND AUTONOMOUS SYSTEMS										Autonomous underwater vehicles; Autonomous docking; Universal docking guidance framework	MODEL-PREDICTIVE CONTROL; RECEDING HORIZON CONTROL; TIME TRAJECTORY GENERATION; OPTIMIZATION; VEHICLES; AIRCRAFT; DESIGN; MANAGEMENT; ALGORITHM; DYNAMICS	Autonomous underwater vehicles (AUVs) are increasingly being used for underwater survey and exploration missions. The expanding mission scope for AUVs highlights the need for a long-endurance operational capability, which mainly depends on propulsion system efficiency and battery capacity. The use of submerged docking stations permitting battery recharge and data download/upload offers a means of enabling persistence without compromising propulsion and payload power budgets, while also reducing associated deployment/recovery costs and risks. Autonomous docking with an underwater station is, however, complicated by the presence of currents and obstacles in the water, and by the relative dynamic differences in pose between the dock and the vehicle. A robust docking guidance system is identified as a core and crucial component for ensuring successful AUV docking. This paper presents a detailed literature review summarizing the current state-of-the-art in AUV docking guidance methodologies, identifying their relative merits and shortcomings, and revealing the docking guidance methodologies that seems to be the most prominent. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103382	10.1016/j.robot.2019.103382													
J								Enhancing adaptability with local reactive behaviors for hexapod walking robot via sensory feedback integrated central pattern generator	ROBOTICS AND AUTONOMOUS SYSTEMS										Hexapod walking robot; Legged locomotion; Local reactive behavior; Central pattern generator (CPG)	NEURAL-NETWORKS; LOCOMOTION; CPG; COORDINATION; LEG; POSITION; INSECTS; SYSTEM; GAIT	Local reactive behaviors endow animals the ability to exhibit agile and dexterous performance when traversing challenging terrains. This paper presents a novel locomotion control method based on the central pattern generator (CPG) concept for hexapod walking robot with local reactive behavior to cope with terrain irregularities. Firstly, a two-layered CPG-based single-leg controller is developed to generate the rhythmical movement for each leg executing tripod walking. The Van der Pol oscillator is employed on the high-layer to construct a coupled CPG network which serves as a phase regulator (PR) to produce rhythmic signals with prescribed phase relations amongst neurons. On the low-layer, an auxiliary linear converter (LC) transforms these signals into the desired joint trajectories. Subsequently, by embodying the proprioceptive sensing and external tactile information as the sensory feedback, two typical local reactive mechanisms including the elevator reflex and searching reflex are achieved by virtue of on-line adjusting the coupling scheme of the PR and the coefficients of the LC. A locomotion control framework for hexapod walking robot is further established by combining the single-leg controller with a finite state machine to allocate swing/stance commands for individual joints in dealing with terrain perturbations. The effectiveness of the proposed method has been verified through both virtual model simulation and experiments on a physical hexapod platform. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103401	10.1016/j.robot.2019.103401													
J								Flocking and topology manipulation based on space partitioning	ROBOTICS AND AUTONOMOUS SYSTEMS										Network topology; Space partitioning; Decision-making; Limited ranges	NETWORK TOPOLOGIES; STEALTH	Network topology plays a critical role in enabling a multi-agent system to adapt to environment changes and achieve desired objectives. This paper presents distributed topology manipulation schemes for a group of mobile agents. The agents have limited heterogeneous communication ranges, and connections among them are directional. The topology is established from the overlapping communication ranges. The admissible space is partitioned into enclosed areas by connectivity among the agents based on their communication ranges. Each agent occupies an enclosed area, and its decision-making manipulates the topology by guiding itself to an adjacent enclosed area. Both independent and coordinated decision-making approaches are provided. A guidance algorithm is designed to drive the vehicles to a flexible formation, in which the robustness of the network topology is enhanced. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103328	10.1016/j.robot.2019.103328													
J								Vision-based magnetic actuator positioning for wireless control of microrobots	ROBOTICS AND AUTONOMOUS SYSTEMS											SYSTEM; FIELD; ROBOT	This work is concerned with targeted drug delivery inside the human body using magnetic microrobots. It proposes a vision-based magnetic platform for guiding microrobots in both open-loop/closed-loop schemes. The open-loop scheme can be used for example in the case of the inner ear, where the microrobots cannot be localized in real time. On the other hand, for more accuracy, closed-loop scheme can be used for organs as the human eye since microrobots can be localized using a vision sensor. For both schemes, the platform is designed to compensate for human body movements. It is composed of a new magnetic actuator mounted on a robot end-effector and a hybrid vision system. The latter consists of a camera and two microscopes, while the newly proposed magnetic actuator is built using four permanent magnets. The proposed actuator has been designed to create a local maximum of the magnetic field magnitude in a planar workspace. This results in a convergence point for magnetic microrobots that are in its influence zone, making possible open-loop control with a satisfactory accuracy. The procedures for calibrating each component of the proposed platform are described and validated. Finally, several experiments have been carried out to validate the modeling part and to show the feasibility of the concept. The obtained experimental results show that using such platform, the microrobots guiding can be achieved in open-loop under reasonable perturbations and in closed-loop with an accuracy of 200 mu m. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				FEB	2020	124								103366	10.1016/j.robot.2019.103366													
J								Non-aligned double JPEG compression detection based on refined Markov features in QDCT domain	JOURNAL OF REAL-TIME IMAGE PROCESSING										Color image forensics; Non-aligned double JPEG compression detection; Quaternion discrete cosine transform Markov model; Real-time image feature selection	SERVICE RECOMMENDATION; IMAGES	Due to the widespread use of the JPEG format, non-aligned double JPEG (NA-DJPEG) compression is very common in image tampering. Therefore, non-aligned double JPEG compression detection has attracted significant attention in digital forensics in recent years. In most of the previous detection algorithms, grayscale images are used directly, or color images are first converted into grayscale images and then processed. However, it is worth noting that most tampered images are color images. To make full use of the color information in images, a detection algorithm, which uses color images directly, is put forward in this paper. The algorithm based on refined Markov in quaternion discrete cosine transform (QDCT) domain is proposed for NA-DJPEG compression detection. Firstly, color information of a given JPEG image is extracted from blocked images to construct quaternion, and then block image QDCT coefficient matrices, including amplitude and three angles (psi, phi, and theta) can be obtained. Secondly, the refined Markov features are generated from the transition probability matrix in the corresponding refinement process. Our proposed refinement method not only reduces redundant features but also makes the acquired features more efficient in detection. Therefore, the refined Markov features can not only capture the intra-block correlation between block QDCT coefficients but also improve computing efficiency in real-time. Finally, support vector machine (SVM) method is employed for NA-DJPEG compression detection. The experiment results demonstrate that the proposed algorithm not only make use of color information of images, but also can achieve better detection performance with small size images (i.e., 64x64) outperforming state-of-the-art detection methods tested on the same dataset.																	1861-8200	1861-8219				FEB	2020	17	1			SI		7	16		10.1007/s11554-019-00929-z													
J								Real-time estimation for the parameters of Gaussian filtering via deep learning	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image forensics; Real-time; Convolutional neural network; Gaussian filtering	DIGITAL IMAGE FORENSICS; FORGERY DETECTION; SERVICE RECOMMENDATION; JPEG COMPRESSION	Driven by the development of digital technology, manipulation towards digital images becomes simpler than ever before in recent years. Many smartphone applications bring the convenience for ordinary people to edit images in real-time without any professional skills. The digital forensics is an important research field in information security against the situation. In image forensics, it is necessary to validate all possible manipulation during the forming history of given images. Thus, many image forensics researchers focus on detecting certain manipulations to protect the integrity of images such as verifying Gaussian filtering. However, these works tend to make binary classification that if the image is processed by certain manipulation or not. The classification of same manipulation based on parameters are ignored. Here, we propose a method to estimate the parameters of Gaussian filtering to process images based on convolutional neural networks (CNN). Besides, in the modern world, it is also extremely important to enable the simulation in real-time to process with the given data immediately. The proposed method can also validate the given image in a quite short time. Our experiments show that the proposed method can provide excellent real-time performance in estimating the window size and standard deviation of Gaussian filterings. The well-trained model can satisfy us with not only the estimation accuracy, but also the validation time simultaneously.																	1861-8200	1861-8219				FEB	2020	17	1			SI		17	27		10.1007/s11554-019-00907-5													
J								A real-time image forensics scheme based on multi-domain learning	JOURNAL OF REAL-TIME IMAGE PROCESSING										Multi-domain learning; Design of neural network; Real-time detection; Design of classifiers; Image forensic		In recent years, researchers have attempted to explore methods for real-time image forgery detection. Many approaches were developed to detect a certain number of image modification methods. There are many limitations in practical application. In this paper, a multi-domain learning convolutional neural network (MDL-CNN) is proposed to overcome this limitation. We extract the periodicity property from the original and modified image. Features of modified image extracted from different datasets are then fed into the neural network in training process. Since the proposed MDL-CNN is trained by different types of tempering datasets, our method can distinguish many types of image modifications. To decrease the computation of proposed scheme, 1 x 1 kernel convolution layer is used in the second convolutional layer of each network. Furthermore, a multi-domain loss function is developed to enhance the recognition ability of in-depth learning features. Experimental evaluation results show that MDL-CNN method can significantly improve the forensic performance.																	1861-8200	1861-8219				FEB	2020	17	1			SI		29	40		10.1007/s11554-019-00893-8													
J								A real-time reversible image authentication method using uniform embedding strategy	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image authentication; Tamper detection; Pixel value ordering; Reversible data hiding	IMPROVED PVO; SERVICE RECOMMENDATION; SCHEME; EXPANSION; PEE	Reversible image authentication (RIA) is an emerging research field for image tampering operation detection. Tampered regions can be localized precisely by embedding an authentication code (AC) into each divided image block in advance. Once the image is identified as an authentic image, the original image can be recovered without any loss. Under these two preconditions, an efficient RIA scheme is proposed to further improve the detection precision of the final authentication results. Compared with existing methods, a uniform embedding strategy is adopted in this paper, in which one AC bit is embedded into each divided image block to ensure they have the same authentication capability. To improve the forgery localization precision, the block size is adaptively sought according to the embedding capacity of the image. In addition, during the image authentication process, the embedding parameters and location map information are verified to increase the process's rigorousness. The experimental results demonstrate the superiority of the detection precision of the proposed method.																	1861-8200	1861-8219				FEB	2020	17	1			SI		41	54		10.1007/s11554-019-00904-8													
J								Multi-level feature fusion model-based real-time person re-identification for forensics	JOURNAL OF REAL-TIME IMAGE PROCESSING										LBP; HOG; Multi-levels; Fusion	SERVICE RECOMMENDATION	Person forensics aims to retrieve the specified person across non-overlapping cameras. It is difficult owing to the appearance variations caused by occlusion, human pose change, background clutter, illumination variation, etc. In this scenario, current models face great challenges in extracting effective features. Recent deep learning models mainly focus on extracting representative deep features to cope with appearance variations, while handcrafted features are not fully explored. In this paper, a multi-level feature fusion model (MFFM) is designed to combine both deep features and handcrafted features in real time. MFFM is first utilized to describe person appearance. Then, local binary pattern (LBP) and histogram of oriented gradient (HOG) are extracted to cope with geometric change and illumination variance. Using LBP and HOG, 11.89% on the CUHK03, 15.30% on the Market-1501 and 8.25% on the VIPeR top-1 recognition accuracy improvement for the proposed method are achieved with only 9.66%, 4.90%, and 7.59% extra processing time. Experimental results indicate MFFM can achieve the best performance compared to the state-of-the-art models on the Market1501, CUHK03, and VIPeR datasets.																	1861-8200	1861-8219				FEB	2020	17	1			SI		73	81		10.1007/s11554-019-00908-4													
J								Real-time human cross-race aging-related face appearance detection with deep convolution architecture	JOURNAL OF REAL-TIME IMAGE PROCESSING										Human age estimation; Cross-race relationships; Aging-related facial appearance features; Deep convolutional neural networks	HUMAN AGE ESTIMATION; SERVICE RECOMMENDATION; REGRESSION; ALGORITHM	Human age estimation (AE) is an emerging research topic in computer vision and machine learning and has attracted increasing amount of research due its wide potential applications. In the process of human aging, facial appearances change from glabrous to crinkly similarly across all races, from European, Hispanic and African to Asian. To specially explore the relationships between aging and facial appearances across races, this paper is devoted to determining the correspondence between facial aging and facial appearances. Specifically, we first extract appearance vector features from facial images with their spatial structure preserved. Then, we propose to select the aging-related features shared by different races to explore their aging-related common facial regions, while removing redundant features. Thirdly, we improve the proposed model by incorporating potential cross-race relationships in an automated learning manner. Additionally, we extend our model with deep convolution architecture. Finally, we evaluate the proposed methodologies on a large face aging database with real-time efficiency.																	1861-8200	1861-8219				FEB	2020	17	1			SI		83	93		10.1007/s11554-019-00903-9													
J								A real-time typhoon eye detection method based on deep learning for meteorological information forensics	JOURNAL OF REAL-TIME IMAGE PROCESSING										Deep learning; Image detection; Information forensics; Typhoon	IMAGE SEGMENTATION; SATELLITE; MODEL	The development of meteorological satellite technology has made it feasible to observe cloud cover over the Earth's surface, and the number of high-precision meteorological satellite images available has increased dramatically over the years. However, there exists a gap between meteorological satellite cloud images and the true information of the pictured clouds. Therefore, extracting the true atmospheric information from "forged" satellite images in real time is a challenging task. In this paper, we proposed a real-time typhoon eye detection method from meteorological satellite cloud images based on deep learning. This new approach is the first step in detecting hidden information in satellite cloud images and provides important data support to detect true typhoon information. We performed simulation experiments and the results showed that the proposed method performs well in identifying typhoons, where the positive sample accuracy rate, negative sample accuracy rate, and total average accuracy rate are 94.22%, 99.43%, and 96.83%, respectively. In the testing process, the average time needed to detect each sample is 6 ms, which fulfills the requirement for real-time typhoon eye detection. Our method outperforms the k-nearest neighbors (KNN) and support vector machine (SVM) algorithms.																	1861-8200	1861-8219				FEB	2020	17	1			SI		95	102		10.1007/s11554-019-00899-2													
J								Enhancing reliability and efficiency for real-time robust adaptive steganography using cyclic redundancy check codes	JOURNAL OF REAL-TIME IMAGE PROCESSING										Robust steganography; STC-CRC codes; JPEG compression resistant; Statistical detection resistant	RESISTING JPEG COMPRESSION; IMAGE	The development of multimedia and deep learning technology bring new challenges to steganography and steganalysis techniques. Meanwhile, robust steganography, as a class of new techniques aiming to solve the problem of covert communication under lossy channels, has become a new research hotspot in the field of information hiding. To improve the communication reliability and efficiency for current real-time robust steganography methods, a concatenated code, composed of Syndrome-Trellis codes (STC) and cyclic redundancy check (CRC) codes, is proposed in this paper. The enhanced robust adaptive steganography framework proposed is this paper is characterized by a strong error detection capability, high coding efficiency, and low embedding costs. On this basis, three adaptive steganographic methods resisting JPEG compression and detection are proposed. Then, the fault tolerance of the proposed steganography methods is analyzed using the residual model of JPEG compression, thus obtaining the appropriate coding parameters. Experimental results show that the proposed methods have a significantly stronger robustness against compression, and are more difficult to be detected by statistical based steganalytic methods.																	1861-8200	1861-8219				FEB	2020	17	1			SI		115	123		10.1007/s11554-019-00905-7													
J								Coverless real-time image information hiding based on image block matching and dense convolutional network	JOURNAL OF REAL-TIME IMAGE PROCESSING										Coverless information hiding; Data hiding; Deep learning; DCT; DenseNet; Real-time image processing	RECOGNITION	Information security has become a key issue of public concern recently. In order to radically resist the decryption and analysis in the field of image information hiding and significantly improve the security of the secret information, a novel coverless information hiding approach based on deep learning is proposed in this paper. Deep learning can select the appropriate carrier according to requirements to achieve real-time image data hiding and the high-level semantic features extracted by CNN are more accurate than the low-level features. This method does not need to employ the designated image for embedding the secret data but transfer a set of real-time stego-images which share one or several visually similar blocks with the given secret image. In this approach, a group of real-time images searched online are segmented according to specific requirements. Then, the DenseNet is used to extract the high-level semantic features of each similar block. At the same time, a robust hash sequence with feature sequence, DC and location is generated by DCT. The inverted index structure based on the hash sequence is constructed to attain real-time image matching efficiently. At the sending end, the stego-images are matched and sent through feature retrieval. At the receiving end, the secret image can be recovered by extracting similar blocks through the received stego-images and stitching the image blocks according to the location information. Experimental results demonstrate that the proposed method without any modification traces provides better robustness and has higher retrieval accuracy and capacity when compared with some existing coverless image information hiding.																	1861-8200	1861-8219				FEB	2020	17	1			SI		125	135		10.1007/s11554-019-00917-3													
J								Efficient binary image steganalysis based on ensemble neural network of multi-module	JOURNAL OF REAL-TIME IMAGE PROCESSING										Steganalysis; CNN; Binary image	COPY-MOVE DETECTION; SPLICING DETECTION; MARKOV FEATURES; SCHEME	There are few studies on binary image steganalysis based on convolutional neural network (CNN). In this paper, an efficient binary image steganalysis scheme based on CNN which integrates high-pass filters, truncated linear unit and subnetworks is proposed. In the process of binary image steganography, flipped pixels usually scatter on the boundaries of the content in the image. Therefore, the first convolutional layer is constructed with high-pass filters to capture the structure of embedded signals better. Truncated linear unit (TLU) is also adopted after the first convolutional layer for the same purpose. 4 truncated linear units with different truncated values are adopted to capture embedding signals of different intensities. We also adopt 4 subnets after the 4 truncated linear units to further boost the performance of the CNN network. The experimental results show that our proposed scheme is efficient and effective on binary steganalysis.																	1861-8200	1861-8219				FEB	2020	17	1			SI		137	147		10.1007/s11554-019-00885-8													
J								Deep learning for real-time image steganalysis: a survey	JOURNAL OF REAL-TIME IMAGE PROCESSING										Deep learning; Steganography; Image steganalysis; CNN; DNN	COMPUTATION OFFLOADING METHOD; SERVICE RECOMMENDATION; PRIVACY PRESERVATION	Steganography is a technique that transmits secret data or message in an appropriate multimedia carrier, e.g., image, audio, and video files. It comes under the assumption that if the feature is visible, the point of attack is evident. However, such technology is always used by criminals who do not want to be easily discovered to hide harmful information in various media, especially in images. Massive spreading of those harmful information will increase the difficulty of social security management. In this case, excellent image steganalysis should be developed and applied. Specially, real-time image steganalysis is necessary when information timelines need to be protected. If detection scene has large amounts of users, deep learning can be applied to improve performance of image steganalysis benefiting from its powerful processing capability. Using deep learning, real-time image steganalysis system gets higher accuracy and efficiency. In this paper, we give an account of preliminary knowledge first. A brief overview of the deep neural networks (DNN) is also presented. The combination of DNN and real-time image steganalysis is introduced. Then, we import the concept of CNN in DNN, and expound theory as well as advantages of combining CNN and image steganalysis. For multi-user scenarios, we analyze a practical real-time image steganalysis application based on outlier detection methods. At last, we prospect the future issues of real-time image steganalysis.																	1861-8200	1861-8219				FEB	2020	17	1			SI		149	160		10.1007/s11554-019-00915-5													
J								A privacy-preserving image retrieval method based on deep learning and adaptive weighted fusion	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image retrieval; Adaptive weighted fusion; PCA dimension reduction; Locality-sensitive hashing; DenseNet	RECOGNITION; EFFICIENT; SCHEME	With the development of big data and cloud computing, more and more data owners store the data in cloud server. Considering privacy preserving, image data need to be encrypted before uploaded to the cloud, which will lead to inefficient image retrieval of ciphertext domain. Therefore, the challenge of encrypted image retrieval is how to improve the performance. Toward this goal, this paper proposes a privacy-preserving image retrieval method based on deep learning and adaptive weighted fusion. Firstly, extracting low-level feature EHD (edge histogram descriptor), BOW (bag of words) and high-level semantic feature of images. Secondly, reducing the dimension of 1024-dim high-level semantic feature by PCA (principal component analysis), and the three features were binarized. Then these types of features are adaptively fused. Finally, constructing a prefilter table for fusion features to improve search efficiency by locality sensitive hashing (LSH) algorithm. K-nearest neighbor (KNN) algorithm and logistic encryption method were used to protect the privacy of fused features and images, respectively. The experiments show that the proposed method can not only ensure image security but also improve the retrieval accuracy of encrypted image.																	1861-8200	1861-8219				FEB	2020	17	1			SI		161	173		10.1007/s11554-019-00909-3													
J								Secure real-time image protection scheme with near-duplicate detection in cloud computing	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image protection; Cloud computing; Near-duplicate detection; Deep learning	EFFICIENT; NETWORKS	With advancements in technologies of the Internet and multi-media, various images need to be generated and transmitted anytime. Restricted by local constrained storage space, users can store their images with the assist of the cloud. However, the cloud is a remote semi-trusted party that may extract stored images for adversaries due to monetary reasons. In this paper, a secure real-time image protection scheme is proposed, which can be used to enhance the security of the stored images in cloud computing. Moreover, the convergent encryption is used to construct our scheme, which can provide functionalities of image deduplication checking and near-duplicate detection for the image owner. To improve the efficiency of the near-duplicate detection, deep learning is exploited in our scheme to extract images. Security analysis indicates that the proposed scheme can meet the security requirements of correctness and security. Performance analysis shows that the proposed scheme can be performed with low computational cost.																	1861-8200	1861-8219				FEB	2020	17	1			SI		175	184		10.1007/s11554-019-00887-6													
J								Enriching Data Imputation under Similarity Rule Constraints	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Measurement; Roads; Sun; Databases; Approximation algorithms; Data integration; Cleaning; Similarity rules; similarity neighbors; data imputation		Incomplete information often occurs along with many database applications, e.g., in data integration, data cleaning, or data exchange. The idea of data imputation is often to fill the missing data with the values of its neighbors who share the same/similar information. Such neighbors could either be identified certainly by editing rules or extensively by similarity relationships. Owing to data sparsity, the number of neighbors identified by editing rules w.r.t. value equality is rather limited, especially in the presence of data values with variances. To enrich the imputation candidates, a natural idea is to extensively consider the neighbors with similarity relationship. However, the candidates suggested by these (heterogenous) similarity neighbors may conflict with each other. In this paper, we propose to utilize the similarity rules with tolerance to small variations (instead of the aforesaid editing rules with strict equality constraints) to rule out the invalid candidates provided by similarity neighbors. To enrich the data imputation, i.e., imputing the missing values more, we study the problem of maximizing the missing data imputation. Our major contributions include (1) the np-hardness analysis on solving as well as approximating the problem, (2) exact algorithms for tackling the problem, and (3) efficient approximation with performance guarantees. Experiments on real and synthetic data sets demonstrate the superiority of our proposal in filling accuracy. We also demonstrate that the record matching application is indeed improved, after applying the proposed imputation.																	1041-4347	1558-2191				FEB 1	2020	32	2					275	287		10.1109/TKDE.2018.2883103													
J								MV-RNN: A Multi-View Recurrent Neural Network for Sequential Recommendation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Markov processes; Recurrent neural networks; Visualization; Task analysis; Collaboration; Logic gates; Multi-view; sequential recommendation; recurrent neural network; cold start		Sequential recommendation is a fundamental task for network applications, and it usually suffers from the item cold start problem due to the insufficiency of user feedbacks. There are currently three kinds of popular approaches which are respectively based on matrix factorization (MF) of collaborative filtering, Markov chain (MC), and recurrent neural network (RNN). Although widely used, they have some limitations. MF based methods could not capture dynamic users interest. The strong Markov assumption greatly limits the performance of MC based methods. RNN based methods are still in the early stage of incorporating additional information. Based on these basic models, many methods with additional information only validate incorporating one modality in a separate way. In this work, to make the sequential recommendation and deal with the item cold start problem, we propose a Multi-View Rrecurrent Neural Network (MV-RNN) model. Given the latent feature, MV-RNN can alleviate the item cold start problem by incorporating visual and textual information. First, At the input of MV-RNN, three different combinations of multi-view features are studied, like concatenation, fusion by addition and fusion by reconstructing the original multi-modal data. MV-RNN applies the recurrent structure to dynamically capture the users interest. Second, we design a separate structure and a united structure on the hidden state of MV-RNN to explore a more effective way to handle multi-view features. Experiments on two real-world datasets show that MV-RNN can effectively generate the personalized ranking list, tackle the missing modalities problem, and significantly alleviate the item cold start problem.																	1041-4347	1558-2191				FEB 1	2020	32	2					317	331		10.1109/TKDE.2018.2881260													
J								Simple Statistics Are Sometime Too Simple: A Case Study in Social Media Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Semantics; Twitter; Principal component analysis; YouTube; LinkedIn; Correlation; Online social media; PCA; Simpson's paradox; data analysis		In this work we ask to which extent are simple statistics useful to make sense of social media data. By simple statistics we mean counting and bookkeeping type features such as the number of likes given to a users post, a users number of friends, etc. We find that relying solely on simple statistics is not always a good approach. Specifically, we develop a statistical framework that we term semantic shattering which allows to detect semantic inconsistencies in the data that may occur due to relying solely on simple statistics. We apply our framework to simple-statistics data collected from six online social media platforms and arrive at a surprising counter-intuitive finding in three of them, Twitter, Instagram and YouTube. We find that overall, the activity of the user is not correlated with the feedback that the user receives on that activity. A hint to understand this phenomenon may be found in the fact that the activity-feedback shattering did not occur in LinkedIn, Steam and Flickr. A possible explanation for this separation is the amount of effort required to produce content. The lesser the effort the lesser the correlation between activity and feedback. The amount of effort may be a proxy to the level of commitment that the users feel towards each other in the network, and indeed sociologists claim that commitment explains consistent human behavior, or lack thereof. However, the amount of effort or the level of commitment are by no means a simple statistic.																	1041-4347	1558-2191				FEB 1	2020	32	2					402	408		10.1109/TKDE.2019.2899355													
J								High-Fidelity Monocular Face Reconstruction Based on an Unsupervised Model-Based Face Autoencoder	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Face; Image reconstruction; Three-dimensional displays; Training; Decoding; Shape; Lighting	SHAPE; RECOGNITION; REGRESSION	In this work, we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is the differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance, and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world datasets feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation. This work is an extended version of [1] , where we additionally present a stochastic vertex sampling technique for faster training of our networks, and moreover, we propose and evaluate analysis-by-synthesis and shape-from-shading refinement approaches to achieve a high-fidelity reconstruction.																	0162-8828	1939-3539				FEB	2020	42	2					357	370		10.1109/TPAMI.2018.2876842													
J								Comparison of Supervised Classifiers and Image Features for Crop Rows Segmentation on Aerial Images	APPLIED ARTIFICIAL INTELLIGENCE											WEED DETECTION; FUSION	In this paper we present a comparison of supervised classifiers and image features for crop row segmentation of aerial images captured from an unmanned aerial vehicle (UAV). The main goal is to investigate which methods are the most suitable to solve this specific problem, as well as to test quantitatively how well they perform for robust segmentation of row patterns. For this purpose, we conducted a systematic literature review over the recent methods specifically designed for aerial image crop row segmentation, and for comparison purposes we implemented the most prominent approaches. Most used Color-texture features were faced against most used classifiers, resulting into a total of 48 combinations, usually having their construction concepts based on the following two step-procedures: (i) supervised training step to build some model over the selected color-texture feature space which is also based upon user-selected samples from the input image; and (ii) classification step, where each pixel of the input image is classified employing the corresponding classifier. The obtained results were compared against a Ground-Truth (GT) image, performed by a human expert, using two distinct evaluation metrics, indicating the most suitable combination of color-texture descriptors and classifiers able to solve the segmentation problem of specific cultures obtained from UAV images.																	0883-9514	1087-6545				MAR 20	2020	34	4					271	291		10.1080/08839514.2020.1720131		FEB 2020											
J								Conversion Prediction from Clickstream: Modeling Market Prediction and Customer Predictability	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Predictive models; Data models; Measurement; Microsoft Windows; Advertising; Tools; Computer science; Retargeting; conversion prediction; predictability; market model; digital marketing; E-commerce	BEHAVIOR	As 98 percent of shoppers do not make a purchase on the first visit, we study the problem of predicting whether they would come back for a purchase later (i.e., conversion prediction). This problem is important for strategizing "retargeting", for example, by sending coupons for customers who are likely to convert. For this goal, we study the following two problems, prediction of market and predictability of customer. First, prediction of market aims at identifying a conversion rate for a given product and its customer behavior modeling, which is an important analytics metric for retargeting process. Compared to existing approaches using either of customer or product-level conversion pattern, we propose a joint modeling of both patterns based on the well-studied buying decision process. Second, we can observe customer-specific behaviors after showing retargeting ads, to predict whether this specific customer follows the market model (high predictability) or not (low predictability). For the former, we apply the market model, and for the latter, we propose a new customer-specific prediction based on dynamic ad behavior features. To evaluate the effectiveness of our methods, we perform extensive experiments on the simulated dataset generated based on a set of real-world web logs and retargeting campaign logs. The evaluation results show that conversion predictions and predictability by our approach are consistently more accurate and robust than those by existing baselines in dynamic market environment.																	1041-4347	1558-2191				FEB 1	2020	32	2					246	259		10.1109/TKDE.2018.2884467													
J								Fast and Low Memory Cost Matrix Factorization: Algorithm, Analysis, and Case Study	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Imaging; Optimization; Recommender systems; Manifolds; Convergence; Minimization; Dynamic range; Matrix factorization; matrix recovery; efficient optimization; convergence guarantees; recommender systems; HDR imaging; batch image alignment	COMPLETION; OPTIMIZATION; MODEL	Matrix factorization has been widely applied to various applications. With the fast development of storage and internet technologies, we have been witnessing a rapid increase of data. In this paper, we propose new algorithms for matrix factorization with the emphasis on efficiency. In addition, most existing methods of matrix factorization only consider a general smooth least square loss. Differently, many real-world applications have distinctive characteristics. As a result, different losses should be used accordingly. Therefore, it is beneficial to design new matrix factorization algorithms that are able to deal with both smooth and non-smooth losses. To this end, one needs to analyze the characteristics of target data and use the most appropriate loss based on the analysis. We particularly study two representative cases of low-rank matrix recovery, i.e., collaborative filtering for recommendation and high dynamic range imaging. To solve these two problems, we respectively propose a stage-wise matrix factorization algorithm by exploiting manifold optimization techniques. From our theoretical analysis, they are both are provably guaranteed to converge to a stationary point. Extensive experiments on recommender systems and high dynamic range imaging demonstrate the satisfactory performance and efficiency of our proposed method on large-scale real data.																	1041-4347	1558-2191				FEB 1	2020	32	2					288	301		10.1109/TKDE.2018.2882197													
J								First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Forecasting; Task analysis; Predictive models; Trajectory; Cameras; Learning (artificial intelligence); Visualization; First-person vision; activity forecasting; inverse reinforcement learning; online learning	PREDICTION	We address the problem of incrementally modeling and forecasting long-term goals of a first-person camera wearer: what the user will do, where they will go, and what goal they seek. In contrast to prior work in trajectory forecasting, our algorithm, Darko, goes further to reason about semantic states (will I pick up an object?), and future goal states that are far in terms of both space and time. Darko learns and forecasts from first-person visual observations of the user's daily behaviors via an Online Inverse Reinforcement Learning (IRL) approach. Classical IRL discovers only the rewards in a batch setting, whereas Darko discovers the transitions, rewards, and goals of a user from streaming data. Among other results, we show Darko forecasts goals better than competing methods in both noisy and ideal settings, and our approach is theoretically and empirically no-regret.																	0162-8828	1939-3539				FEB	2020	42	2					304	317		10.1109/TPAMI.2018.2873794													
J								Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Benchmark testing; Visualization; Predictive models; Analytical models; Image color analysis; Knowledge discovery; Task analysis; Inverse visual question answering; VQA visualisation; visuo-linguistic understanding; reinforcement learning		In recent years, visual question answering (VQA) has become topical. The premise of VQA's significance as a benchmark in AI, is that both the image and textual question need to be well understood and mutually grounded in order to infer the correct answer. However, current VQA models perhaps 'understand' less than initially hoped, and instead master the easier task of exploiting cues given away in the question and biases in the answer distribution [1] . In this paper we propose the inverse problem of VQA (iVQA). The iVQA task is to generate a question that corresponds to a given image and answer pair. We propose a variational iVQA model that can generate diverse, grammatically correct and content correlated questions that match the given answer. Based on this model, we show that iVQA is an interesting benchmark for visuo-linguistic understanding, and a more challenging alternative to VQA because an iVQA model needs to understand the image better to be successful. As a second contribution, we show how to use iVQA in a novel reinforcement learning framework to diagnose any existing VQA model by way of exposing its belief set: the set of question-answer pairs that the VQA model would predict true for a given image. This provides a completely new window into what VQA models 'believe' about images. We show that existing VQA models have more erroneous beliefs than previously thought, revealing their intrinsic weaknesses. Suggestions are then made on how to address these weaknesses going forward.																	0162-8828	1939-3539				FEB	2020	42	2					460	474		10.1109/TPAMI.2018.2880185													
J								Deep Learning for Generic Object Detection: A Survey	INTERNATIONAL JOURNAL OF COMPUTER VISION										Object detection; Deep learning; Convolutional neural networks; Object recognition	CONVOLUTIONAL NETWORKS; RECOGNITION; CLASSIFICATION; REPRESENTATION; SEGMENTATION; LOCALIZATION; ANNOTATION; GRADIENTS; CONTEXT; IMAGES	Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.																	0920-5691	1573-1405				FEB	2020	128	2					261	318		10.1007/s11263-019-01247-4													
J								Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization	INTERNATIONAL JOURNAL OF COMPUTER VISION										Grad-CAM; Visual explanations; Visualizations; Explanations; Interpretability; Transparency		We propose a technique for producing 'visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach-Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say 'dog' in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a 'stronger' deep network from a 'weaker' one even when both make identical predictions. Our code is available at , along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265-290. Springer, 2015) () and a video at .																	0920-5691	1573-1405				FEB	2020	128	2					336	359		10.1007/s11263-019-01228-7													
J								Deep Insights into Convolutional Networks for Video Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION										Computer vision; Machine learning; Deep learning; Video recognition; Neural network visualization; Action recognition	COLOR; MOVEMENT; SYSTEM	As the success of deep models has led to their deployment in all areas of computer vision, it is increasingly important to understand how these representations work and what they are capturing. In this paper, we shed light on deep spatiotemporal representations by visualizing the internal representation of models that have been trained to recognize actions in video. We visualize multiple two-stream architectures to show that local detectors for appearance and motion objects arise to form distributed representations for recognizing human actions. Key observations include the following. First, cross-stream fusion enables the learning of true spatiotemporal features rather than simply separate appearance and motion features. Second, the networks can learn local representations that are highly class specific, but also generic representations that can serve a range of classes. Third, throughout the hierarchy of the network, features become more abstract and show increasing invariance to aspects of the data that are unimportant to desired distinctions (e.g. motion patterns across various speeds). Fourth, visualizations can be used not only to shed light on learned representations, but also to reveal idiosyncrasies of training data and to explain failure cases of the system.																	0920-5691	1573-1405				FEB	2020	128	2					420	437		10.1007/s11263-019-01225-w													
J								A Convolutional Fuzzy Neural Network Architecture for Object Classification with Small Training Database	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Convolutional neural network; Fuzzy neural network; Small data; Object classification		In this paper, we propose a novel architecture that combines the convolutional neural network (CNN) with a fuzzy neural network (FNN). We utilize the fuzzy neural network with semi-connected layers to sum up feature information. During the training process, to map membership values, the CNN generates feature maps as outputs and feeds into fuzzifier layers, alternatively called fuzzy maps. The proposed method increases classification accuracy, because fuzzy neural networks can generate not only crisp values but also fuzzy values; this means that there is potentially more information contained in the fuzzy set. Our model is evaluated by cross-validation tests. While big data is necessary for training in general, we train our model with small data and test with big data to demonstrate its ability of object classification in cases where sufficient data are not available.																	1562-2479	2199-3211				FEB	2020	22	1					1	10		10.1007/s40815-019-00764-1													
J								Fuzzy Smooth Equilibrium Method for Clustering	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Spectral clustering; Maximum margin clustering; Fuzzy clustering; Equilibrium regularization; Nearest neighbor relationships	C-MEANS; BIG DATA; ALGORITHMS; KERNEL	Clustering model plays an indispensable role in exploring data structures. To extend supervised learning to unsupervised, the maximum margin clustering model has been proposed. Maximum margin-based frameworks develop a powerful tool for supervised learning. It could yield good results by combining with some fuzzy clustering models. However, such methods characterized by high computational cost and are sensitive to the nearest neighbor relationships between data objects. Sometimes, they could lead to degenerate solutions. By reconstructing the Laplacian matrix with different similarity measurements, a new fuzzy smooth equilibrium clustering (FSEC) model is proposed. This model combines MMC with spectral clustering, but there is no need to solve the eigenvalue decomposition problem. Using the equilibrium regularization term can avoid degenerate solutions. Numerous experiments have established the effectiveness of the newly FSEC model.																	1562-2479	2199-3211				FEB	2020	22	1					11	21		10.1007/s40815-019-00787-8													
J								Training High-Order Takagi-Sugeno Fuzzy Systems Using Batch Least Squares and Particle Swarm Optimization	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy systems; Least squares approximation; Particle swarm optimization	REGRESSION MODEL ALGORITHM; FUNCTION APPROXIMATION; IDENTIFICATION; PSO	This paper proposes two methods for training Takagi-Sugeno (T-S) fuzzy systems using batch least squares (BLS) and particle swarm optimization (PSO). The T-S system is considered with triangular and Gaussian membership functions in the antecedents and higher-order polynomials in the consequents of fuzzy rules. In the first method, the BLS determines the polynomials in a system in which the fuzzy sets are known. In the second method, the PSO algorithm determines the fuzzy sets, whereas the BLS determines the polynomials. In this paper, the ridge regression is used to stabilize the solution when the problem is close to the singularity. Thanks to this, the proposed methods can be applied when the number of observations is less than the number of predictors. Moreover, the leave-one-out cross-validation is used to avoid overfitting and this way to choose the structure of a fuzzy model. A method of obtaining piecewise linear regression by means of the zero-order T-S system is also presented.																	1562-2479	2199-3211				FEB	2020	22	1					22	34		10.1007/s40815-019-00747-2													
J								Practical Finite-Time Fuzzy Control for Hamiltonian Systems via Adaptive Event-Triggered Approach	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Semi-global practical finite-time stable; Nonlinear Hamiltonian systems; Fuzzy systems; Adaptive event-triggered approach	FAULT-TOLERANT CONTROL; H-INFINITY CONTROL; NONLINEAR-SYSTEMS; CONSENSUS CONTROL; STABILIZATION; STABILITY; TRACKING	This paper is to present our new results on practical finite-time fuzzy control scheme for a class of Hamiltonian systems by an adaptive event-triggered approach. An unknown function of the system is approximated by an adaptive fuzzy system. According to a semi-global practical finite-time stability criterion, a novel adaptive fuzzy finite-time controller is presented. In the interest of saving resources, an event-triggered approach is developed where the controller is updated under the respective triggering conditions. Based on the special structure of Hamiltonian systems and Lyapunov theory, a sufficient condition is obtained so that the states of original systems converge to a small neighborhood containing the origin in a finite time. Meanwhile, with the proposed controller, there exists a positive lower bound for the interexecution time, and the Zeno phenomenon is avoided. The design processes of the proposed controller, adaptive law and event-triggered conditions are also proved by a circuit system simulation example.																	1562-2479	2199-3211				FEB	2020	22	1					35	45		10.1007/s40815-019-00773-0													
J								Fuzzy Optimization Techniques by Hidden Markov Model with Interval Type-2 Fuzzy Parameters	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Aggregation operators; Fuzzy set; Frank triangular norms; Fuzzy hidden Markov model; Trapezoidal interval type-2 fuzzy number (TpIT2FN); Viterbi algorithm	AGGREGATION OPERATORS; LOGIC SYSTEMS; SPEECH; UNINORMS; FRANK; SETS	Fuzzy hidden Markov model is the efficient way of finding an optimized path among the states where uncertainty exists. Aggregation operators replaced the conventional operators in the fuzzy environment and play a vital role in real-world problems. Here, the aggregation operators namely trapezoidal interval type-2 weighted arithmetic (TpIT2FFWA) and trapezoidal interval type-2 weighted geometric (TpIT2FFWG) operators have been derived and their desired properties also have been proved based on Frank triangular norms. Using the proposed operators and Viterbi algorithm, decision-making process has been analyzed to choose the best medicine company.																	1562-2479	2199-3211				FEB	2020	22	1					62	76		10.1007/s40815-019-00738-3													
J								Finite-Time Consensus of Stochastic Nonlinear Multi-agent Systems	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Adaptive fuzzy control; Stochastic multi-agent systems; Finite-time consensus; Square stability	OUTPUT-FEEDBACK CONTROL; ADAPTIVE CONSENSUS; TRACKING CONTROL; STABILITY; SYNCHRONIZATION; INPUT	This article studies the finite-time consensus of the stochastic nonlinear multi-agent systems under a directed communication topology. Since the inherent nonlinear dynamics and stochastic disturbances in multi-agent systems are completely unknown, the existing finite-time stability criterion becomes unavailable. To handle this difficulty, by applying the mean value theorem of integrals, a key finite-time stability criterion in integral form is first established. Then, based on the approximation property of the fuzzy logic systems, a distributed adaptive fuzzy control scheme is presented. Under the presented control strategy, the finite-time consensus of the stochastic nonlinear multi-agent systems is achieved. By applying Jessen's inequality and Theorem 1, the finite-time stability of the closed system is proved. Finally, the simulation result shows the validity of the distributed controller.																	1562-2479	2199-3211				FEB	2020	22	1					77	88		10.1007/s40815-019-00769-w													
J								Observer-Based Fuzzy Control for Four-Wheel Independently Driven Electric Vehicles with Active Steering Systems	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Active front-steering systems; Fuzzy model; Observer-based control	NONLINEAR-SYSTEMS; STABILIZATION; DESIGN; DELAY	This paper presents an observer-based control strategy to improve the maneuverability and stability performance of four-wheel independently driven electric vehicles with active front-wheel steering systems. Since the system states are difficult to be measured directly, a novel observer is designed to estimate the vehicle yaw rate and lateral velocity simultaneously. Takagi-Sugeno fuzzy model is used to handle the time-varying parameters of the vehicle model. Based on Lyapunov function theory, stability conditions of the closed-loop system are derived. The fuzzy \begin{document}$$H_{\infty }$$\end{document} controller is designed to make the resulting T-S fuzzy system asymptotically stable and satisfy																	1562-2479	2199-3211				FEB	2020	22	1					89	100		10.1007/s40815-019-00770-3													
J								Finite-Time Fault Tracking Control for T-S Fuzzy Systems Using Intermediate Estimator	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										T-S fuzzy system; Fault estimation; Intermediate estimator; Finite-time stable	INFINITY CONTROL; TOLERANT CONTROL; STABILIZATION	This paper investigates the problem of finite-time stability for Takagi-Sugeno (T-S) fuzzy system with intermediate estimator. Based on intermediate estimator, a fuzzy fault-tolerant controller is designed for the considered fuzzy system to solve the tracking problem of time-varying fault. In particular, H infinity\documentclass[12pt]{minimal}																	1562-2479	2199-3211				FEB	2020	22	1					101	110		10.1007/s40815-019-00760-5													
J								Observer-Based Fuzzy Fault-Tolerant Control for Nonlinear Parabolic PDEs	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy systems; Observer; Parabolic PDEs; Actuator fault	DISTRIBUTED-PARAMETER SYSTEMS; TRACKING CONTROL; DESIGN	This paper investigates fault-tolerant control design for a class of nonlinear parabolic distributed parameter systems (DPSs) with actuator faults. Under the averaged measurements, an observer-based fuzzy fault-tolerant control law is constructed. Sufficient conditions in terms of bilinear matrix inequalities conditions are derived to ensure internal exponential stability and disturbance attenuation performance of system simultaneously by using Lyapunov-Krasovskii method. An iterative optimization algorithm is proposed to find feasible solutions. An example is given to illustrate the efficiency of main results.																	1562-2479	2199-3211				FEB	2020	22	1					111	121		10.1007/s40815-019-00778-9													
J								Evaluating the Regulatory Environment of Overseas Electric Power Market Based on a Hybrid Evaluation Model	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Regulatory environment of OEPM; Fuzzy Delphi method; AHP-IGRA approach; Improved fuzzy comprehensive evaluation; Non-compensatory principle	DECISION-MAKING; DELPHI METHOD; FUZZY; INDICATORS; NETWORK; VIKOR; RISK; SELECTION; SUPPORT; QUALITY	This paper develops a hybrid model for evaluating the regulatory environment of overseas electric power market (OEPM), which is of great theoretical and practical significance for power grid enterprises. Power regulation and investment environment evaluation theories as well as fuzzy Delphi method (FDM) are referenced to identify the final evaluation indicators. Owing to the presence of qualitative indicators in the index system, the analytic hierarchy process (AHP) and improved gray relational analysis (IGRA) approaches are combined to determine the indicator weights so as to ensure the credibility of the weights. Considering the non-compensatory principle among primary indicators, the improved fuzzy comprehensive evaluation method (IFCEM) based on multiplicative synthesis technique is applied to evaluate the alternatives. The empirical results indicate that "Return on Investment" and "Bilateral Relationship" are the main perspectives that greatly affect the regulatory environment of OEPM, and that UK and Greece are the best and worst alternatives in terms of the regulatory environment of OEPM in the analyzed countries. Totally, the proposed hybrid framework expressed great capacity to evaluate and rank the regulatory environment of OEPM and can be also popularized in other fields to support enterprises in making decisions by evaluating the alternatives with ambiguity and uncertainty.																	1562-2479	2199-3211				FEB	2020	22	1					138	155		10.1007/s40815-019-00774-z													
J								A Hybrid Short-Term Building Electrical Load Forecasting Model Combining the Periodic Pattern, Fuzzy System, and Wavelet Transform	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Building electrical load forecasting; Fuzzy method; Periodic pattern; Wavelet transform; Least square estimation; Subtraction clustering	ARTIFICIAL NEURAL-NETWORKS; CONSUMPTION PREDICTION; INFERENCE MODEL; ENERGY; ALGORITHM; SVR; PERFORMANCE	Accurate forecasting and scientific analysis of building electrical load can improve the level of building energy management to meet the requirements of energy saving. To further strengthen the forecasting accuracy, this study presents a hybrid model for building electrical load forecasting. The proposed method combines the fuzzy inference system and the periodicity knowledge together to generate accurate forecasting results. In this method, in order to better reflect the actual characteristic of the electrical load, the wavelet transform method is firstly utilized to filter the original building electrical load data. Then, the daily periodic pattern is extracted from such filtered electrical load data, and the residual data are obtained through removing the daily periodic pattern. Further, the residual data-driven forecasting model is constructed by the functionally weighted single-input-rule-modules connected fuzzy inference system (FWSIRM-FIS). This FWSIRM-FIS model is used to provide the compensation to the periodic component. In other words, the daily periodic component and the residual forecasting are combined to achieve the final forecasting result. Specifically, in order to assure the forecasting performance of the FWSIRM-FIS model, the subtraction clustering method is employed to construct the SIRMs while the least square estimation is utilized to optimize the parameters in the functional weights of the FWSIRM-FIS. Finally, in this paper, two real-world experiments are made and detailed comparisons with four traditional models are given. Experimental and comparison results demonstrate that the proposed hybrid model has the smallest forecasting errors and can achieve the best performance.																	1562-2479	2199-3211				FEB	2020	22	1					156	171		10.1007/s40815-019-00783-y													
J								Functional Observer-Based T-S Fuzzy Systems for Quadratic Stability of Power System Synchronous Generator	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										T-S fuzzy system; Quadratic stability; Functional observer-based controller; Synchronous generator fuzzy model; Power system dynamic	H-INFINITY; CONTROLLER-DESIGN; DELAY; EXISTENCE; STATE	This paper presents the functional observer-based Takagi-Sugeno fuzzy controller to enhance the dynamic response of the synchronous generator infinite bus power system under low-frequency oscillations. The unmeasurable states of the synchronous generator are estimated by using minimum order functional observer. The T-S fuzzy controller rules are a function of the estimated states in which the functional observer based on T-S fuzzy conditions presented in rank equality form. The Lyapunov theory in the form of linear matrix inequalities (LMIs) represented here in this paper to synthesis the functional observer stability. Small disturbances are taken to simulate the synchronous generator oscillations. The results clearly show that our scheme is a better response when compared with the full observer-based T-S fuzzy system.																	1562-2479	2199-3211				FEB	2020	22	1					172	180		10.1007/s40815-019-00784-x													
J								General Type-2 Fuzzy Gain Scheduling PID Controller with Application to Power-Line Inspection Robots	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										General type-2 fuzzy gain scheduling PID controller; Balance control; Inspection robot; Nonlinear under-actuated system	LOGIC SYSTEMS; TRACKING CONTROL; SETS; REDUCTION; PENDULUM; DESIGN	In this paper, a general type-2 fuzzy gain scheduling PID (GT2FGS-PID) controller is presented to achieve self-balance adjustment of the power-line inspection (PLI) robot system. As the PLI robot system is an under-actuated nonlinear system, obtaining the full information of the four-state variables is necessary to balance the PLI robot. However, as the number of input variables increases, the number of control rules increases exponentially, making the design of the fuzzy controller extremely complex. Therefore, the proposed controller prevents the problem of rule explosion using information fusion and then simplifies the control design. Moreover, the particle swarm optimization algorithm is used to select improved controller parameters and make the controller achievable. In this paper, the control performance and anti-interference ability of the traditional PID control, type-1 fuzzy control, interval type-2 fuzzy control, and general type-2 fuzzy control methods are compared. By means of numerical simulation, we can conclude that the GT2FGS-PID controller exhibits superior stability and robustness over other controllers for the PLI robot system.																	1562-2479	2199-3211				FEB	2020	22	1					181	200		10.1007/s40815-019-00780-1													
J								A Study of a Backorder EOQ Model for Cloud-Type Intuitionistic Dense Fuzzy Demand Rate	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Backorder EOQ model; Intuitionistic dense fuzzy set; Nonlinearity of (non)membership grade; Score function; Optimization	DECISION-MAKING; QUANTITY MODEL	This paper deals with a backorder inventory problem under intuitionistic dense fuzzy environment. In fuzzy set theory, the concept of dense fuzzy set is quite new that depends upon the number of negotiations/turnovers made by the decision makers (DMs) of any kind of industrial setup. Moreover, we have discussed the preliminary concept on intuitionistic dense fuzzy set (IDFS) with their corresponding (non)membership functions and defuzzification methods. The graphical overview resembles the graphs obtained from a cloud aggregation model developed by Mao et al. in 2018. The basic difference is that they considered interval-valued hesitant fuzzy model with unsharp boundary but the content of present study is solely associated with nonrandom uncertainty having proper boundary. Finally, numerical examples, comparative study, sensitivity analysis, graphical illustration, and conclusion are made for justification of the new approach.																	1562-2479	2199-3211				FEB	2020	22	1					201	211		10.1007/s40815-019-00756-1													
J								Information Structures and Uncertainty measures in a Hybrid Information System: Gaussian Kernel Method	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Hybrid information system; Granular computing; Hybrid distance; Information structure; Gaussian kernel; Uncertainty measure; Optimal selection	FUZZY ROUGH SETS; KNOWLEDGE GRANULATION; GRANULARITY MEASURES; ENTROPY MEASURES; INTERVAL; SELECTION; MODEL	A hybrid information system is an information system where there exist varieties of data, and its information structures reflect the internal features of this kind of information system. This paper researches information structures and uncertainty measurement in an HIS based on Gaussian kernel. According to the viewpoint, an HIS is seen as a multi-source information system, and the distance under each attribute is proposed which is combined into a hybrid distance. Then, the fuzzy tau cos\documentclass[12pt]{minimal}																	1562-2479	2199-3211				FEB	2020	22	1					212	231		10.1007/s40815-019-00779-8													
J								Fault Estimator and Diagnosis for Generalized Linear Discrete-Time System via Self-constructing Fuzzy UKF Method	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Self-constructing fuzzy system; Unscented Kalman filter (UKF); State estimation; Fault information; Generalized linear discrete-time system	ESTIMATION FILTER DESIGN; STOCHASTIC-SYSTEMS; TOLERANT CONTROL; KALMAN FILTER; TAKAGI-SUGENO; STATE; IDENTIFICATION	This study investigated fault estimation and diagnosis using a novel approach based on an integrated fault estimator and state estimator for generalized linear discrete-time systems. The proposed scheme uses a self-constructing fuzzy unscented Kalman filter (UKF) system to simultaneously estimate the system state and approximate the fault information. To achieve this, a generalized linear discrete-time system without faults was first transformed into an equivalent standard state-space system with faults. Then, the self-constructing fuzzy UKF system was designed in order to obtain the fault information. According to fault information obtained using the proposed scheme, fault detection experiments based on fuzzy clustering were performed and the fault feature parameters required for fault isolation were determined. Finally, the scheme was applied to a direct current (DC) motor to demonstrate the effectiveness of the proposed fault estimation and diagnosis approach. Results of the simulation illustrate the effectiveness of the proposed method.																	1562-2479	2199-3211				FEB	2020	22	1					232	241		10.1007/s40815-019-00750-7													
J								Novel Approach of Obtaining Dynamic Multi-attribute Weight for Intuitionistic Fuzzy Environment Based on Fractional Integrals	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Dynamic multi-attribute decision-making; Value function; Multi-stage dynamic reference point; Dynamic psychological distance measure; Intuitionistic fuzzy set	DECISION-MAKING; PROSPECT-THEORY; PSYCHOLOGICAL DISTANCE; SIMILARITY; SYNCHRONIZATION; ATTENTION; SETS	Although there are many methods to obtain attribute weights in dynamic fuzzy environment, most of them assume attribute weights to obey predetermined distribution functions or constraints, which make them impossible to accurately describe the decision-making process and get reasonable results. In order to solve this problem, fractional integral with memory and heredity is introduced. Decision-makers' risk preference information and the amount of useful information given by attributes are both considered to effectively address dynamic multi-attribute decision-making problems in intuitionistic fuzzy. Then, a value function is designed to accurately describe the decision-makers' risk preference information and a multi-stage dynamic reference point setting method for intuitionistic fuzzy environment is proposed. Next, a method for obtaining dynamic attribute weights for intuitionistic fuzzy environment is given. By considering the background information of alternatives, a dynamic psychological distance measure for intuitionistic fuzzy set is produced. Based on the proposed dynamic psychological distance measure and TOPSIS, a dynamic multi-attribute decision-making method for intuitionistic fuzzy environment is given. Finally, two examples are given to illustrate the effectiveness of the method and the influence of the parameters is analyzed.																	1562-2479	2199-3211				FEB	2020	22	1					242	256		10.1007/s40815-019-00765-0													
J								Sustainable Public Transportation System Evaluation: A Novel Two-Stage Hybrid Method Based on IVIF-AHP and CODAS	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										MCDM; IVIF; AHP; CODAS; Public transportation	INTUITIONISTIC FUZZY-SETS; MULTIPLE CRITERIA; SELECTION; SCHOOL; INFORMATION; EXTENSION; FRAMEWORK; CHILDREN; MODEL; CITY	As a multi-disciplinary process, planning of public transportation systems needs special attention from several groups of stakeholders such as passengers, transportation planners, system providers, and so on. Since each stakeholder has dissimilar viewpoints on the evaluation of the public transportation systems, they have contradictory goal and objectives. In this sense, multi-criteria decision-making (MCDM) provides an important procedural outline for the evaluation of public transportation alternatives. This paper presents an application of MCDM method to assess the public transportation alternatives designed for a public university in a large-sized metropolitan area. Two alternatives of MCDM methods, named Interval-Valued Intuitionistic Fuzzy Analytical Hierarchy Process & COmbinative Distance-based Assessment (IVIF-AHP & CODAS), are integrated in the evaluation process. The proposed method ensures consistent and reasonable results and provides suggestions for the forthcoming progresses of public transportation service quality. In order to validate robustness of the proposed method, sensitivity analyses are implemented. Also, at the end of the study, to prove the superiority of the proposed approach, a comparative analysis is employed.																	1562-2479	2199-3211				FEB	2020	22	1					257	272		10.1007/s40815-019-00785-w													
J								m-Polar Neutrosophic Topology with Applications to Multi-criteria Decision-Making in Medical Diagnosis and Clustering Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										m-Polar neutrosphic set; Score functions for MPNNs; m-Polar neutrosphic topological space; Similarity measures for MPNSs; Multi-criteria decision-making for medical diagnosis; Multi-criteria decision-making for clustering analysis	GENERALIZED AGGREGATION OPERATORS; FUZZY INFORMATION AGGREGATION; PYTHAGOREAN MEMBERSHIP GRADES; SIMILARITY MEASURES; SOFT SETS	In this paper, we first introduce novel concepts of m-polar neutrosophic set (MPNS) and topological structure on m-polar neutrosophic set by combining the m-polar fuzzy set (MPFS) and neutrosophic set. Then, we investigate several characterizations of m-polar neutrosophic set and establish its various operations with the help of examples. We propose score functions for the comparison of m-polar neutrosophic numbers (MPNNs). We establish m-polar neutrosophic topology and define interior, closure, exterior, and frontier for m-polar neutrosophic sets (MPNSs) with illustrative examples. We discuss some results with counter examples, which hold for classical set theory, but do not hold for m-polar neutrosophic set theory. We introduce a cosine similarity measure and a set theoretic similarity measure for m-polar neutrosophic sets (MPNSs). Furthermore, we present three algorithms for multi-criteria decision-making (MCDM) in medical diagnosis and clustering analysis under uncertainty by using m-polar neutrosophic sets (MPNSs) and m-polar neutrosophic topology. Lastly, we present advantages, validity, flexibility, and comparison of our proposed algorithms with the existing techniques.																	1562-2479	2199-3211				FEB	2020	22	1					273	292		10.1007/s40815-019-00763-2													
J								Trapezoidal Interval Type-2 Fuzzy TOPSIS Using Alpha-Cuts	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Trapezoidal interval type-2 fuzzy sets (IT2 FSs); TOPSIS; Alpha-cut; Fuzzy multi-criteria decision-making; Ordered weighted averaging (OWA) operator	GROUP DECISION-MAKING; MODEL; EXTENSION; ENTROPY; SETS; DESIGN; MCDM	Fuzzy multi-criteria decision-making (FMCDM) provides solutions to the problems involving multiple criteria for decision-makers under uncertain environments. The Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) is one of the most popular methods to address FMCDM problems. In this paper, we propose an extension of the TOPSIS method with trapezoidal interval type-2 fuzzy sets (IT2 FSs) using the concept of alpha-cut. We first propose a new method to calculate the distance between two trapezoidal IT2 FSs with the tool of alpha-cut and ordered weighted averaging (OWA) operator. Next, based on the distance method, we extend the TOPSIS method to the context of trapezoidal IT2 FSs and utilize it to solve FMCDM problems. Finally, an illustrative example is used to demonstrate the feasibility of the proposed method, and some comparisons with other existing works are presented to show the highlights of the proposed method. The proposed method provides a flexible solution for the FMCDM problems by taking the decision-makers' attitudes into consideration.																	1562-2479	2199-3211				FEB	2020	22	1					293	309		10.1007/s40815-019-00777-w													
J								Utilizing Linguistic Picture Fuzzy Aggregation Operators for Multiple-Attribute Decision-Making Problems	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Linguistic picture fuzzy numbers; Linguistic picture fuzzy aggregation operators; Multiple-attribute decision-making	TERM SETS	The linguistic picture fuzzy set (LPFS) is an extension of the linguistic intuitionistic fuzzy set (LIFS), and can contain more information than the LIFS. In this paper, the degrees of positive, neutral and non-membership of PFSs are expressed in linguistic terms, which can more easily describe the uncertain and vague information existing in the real world. By combining the PFS and the linguistic term, we define the LPFS and propose operational rules for linguistic picture fuzzy numbers (LPFNs). We further propose weighted averaging and weighted geometric operators and discuss their properties. Additionally, we propose an approach to deal with a multiple-attribute group decision-making (MAGDM) problem based on the developed aggregation operators. Finally, we present an illustrative example to demonstrate the effectiveness and advantages of the developed method by comparing it with existing methods. In addition, our method can be utilized not only to solve problems with linguistic intuitionistic fuzzy numbers (LIFNs), but also to deal with problems with LPFNs, and is a generalization of a number of existing methods.																	1562-2479	2199-3211				FEB	2020	22	1					310	320		10.1007/s40815-019-00726-7													
J								A Normalized Weighted Bonferroni Mean Aggregation Operator Considering Shapley Fuzzy Measure Under Interval-valued Neutrosophic Environment for Decision-Making	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Interval-valued neutrosophic set; Bonferroni mean; Aggregation operator; Decision-making	CORRELATION-COEFFICIENT; PREFERENCE RELATIONS; NUMBERS; SETS; CONSENSUS; 2-TUPLE; DEMATEL	Previous theories have suggested that Bonferroni mean (BM) and its extensions can fulfil the desired properties to become a good aggregation operator in managing interrelationship between arguments under fuzzy decision-making environment. However, along with this growth, there are concerns regarding the limitation of the BM and its extensions where interrelationship between arguments is limited to a pair of input arguments. In contrast to previous works, a novel normalized weighted Bonferroni mean aggregation operator considering Shapley fuzzy measure has been introduced, where the overall interactions of input arguments are combined. Unlike other extensions of BM that are mostly considered under fuzzy environment, this aggregation operation introduces the Shapley fuzzy measure to deal with interactions of all arguments under the interval-valued neutrosophic environment. Specifically, the interval-valued neutrosophic Shapley normalized weighted Bonferroni mean (INSNWBM) is proposed in this paper. The properties of INSNWBM such as reducibility, idempotency, monotonicity, commutativity, and boundedness are also presented as to reflect the interrelationship among multiple input arguments. In addition, we have also proposed successive steps of a decision-making procedure in which the proposed INSNWBM is included. Together included is a numerical example as to illustrate the applicability of the INSNWBM in decision-making. The consistency of the ranking results is confirmed by variations of parameters of INSNWBM. It is shown that the ranking results are almost consistent despite the different usages of parameter values. Results obtained appear to support the idea that the proposed aggregation operator is able to address the interrelationship between arguments in decision-making.																	1562-2479	2199-3211				FEB	2020	22	1					321	336		10.1007/s40815-019-00752-5													
J								Fuzzy Mediation Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Mediator variable; Mediation analysis; Psychological data; Fuzzy mediation analysis; LR fuzzy number; Fuzzy data	LEAST-SQUARES ESTIMATION; BEHAVIOR; MEMBERS	A mediator variable is a variable that causes mediation in the dependent and the independent variables. The mediator variables play important roles in data analysis which involve several variables, especially when the dependent and independent variables are affected by other variables. Thus, mediation analysis is needed in almost all areas that need regression analysis especially in psychology, business, education, science, engineering area, etc. Mediation analysis has been proposed in many studies. However, sometimes it is much more reasonable to express the data using fuzzy theory when the variables are not clearly defined. For example, it is better to express the mood of a person "bad", "moderate", "good" using fuzzy numbers than using real numbers (crisp numbers). In this paper, several fuzzy mediation analysis models have been proposed. And confidence intervals and hypothesis tests are also provided. Several psychological data have been applied to find the total, direct and indirect effect when the mediator and confounding variable exist.																	1562-2479	2199-3211				FEB	2020	22	1					338	349		10.1007/s40815-019-00727-6													
J								Ensemble with estimation: seeking for optimization in class noisy data	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Class Noise; Ensemble Learning; Machine Learning	CLASSIFICATION; DISCOVERY; NETWORK	Class noise, as know as the mislabeled data in training set, can lead to poor accuracy in classification no matter what machine learning methods are used. A reasonable estimation of class noise has a significant impact on the performance of learning methods. However, the error in existing estimation is inevitable theoretically and infer the performance of optimal classifier trained on noisy data. Instead of seeking a single optimal classifier on noisy data, in this work, we use a set of weak classifiers, which are caused by negative impacts of noisy data, to learn an ensemble strong classifier which is based on the training error and estimation of class noise. By this strategy, the proposed ensemble with estimation method overcomes the gap between the estimation and true distribution of class noise. Our proposed method does not require any a priori knowledge about class noises. We prove that the optimal ensemble classifier on the noisy distribution can approximate the optimal classifier on the clean distribution when the training set grows. Comparisons with existing algorithms show that our methods outperform state-of-the-art approaches on a large number of benchmark datasets in different domains. Both the theoretical analysis and the experimental result reveal that our method can improve the performance, works well on clean data and is robust on the algorithm parameter.																	1868-8071	1868-808X				FEB	2020	11	2					231	248		10.1007/s13042-019-00969-8													
J								Integration search strategies in tree seed algorithm for high dimensional function optimization	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Swarm intelligence; Metaheuristic algorithms; Withering process; Nonlinear global optimization	PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION; DESIGN	The tree-seed algorithm, TSA for short, is a new population-based intelligent optimization algorithm developed for solving continuous optimization problems by inspiring the relationship between trees and their seeds. The locations of trees and seeds correspond to the possible solutions of the optimization problem on the search space. By using this model, the continuous optimization problems with lower dimensions are solved effectively, but its performance dramatically decreases on solving higher dimensional optimization problems. In order to address this issue in the basic TSA, an integration of different solution update rules are proposed in this study for solving high dimensional continuous optimization problems. Based on the search tendency parameter, which is a peculiar control parameter of TSA, five update rules and a withering process are utilized for obtaining seeds for the trees. The performance of the proposed method is investigated on basic 30-dimensional twelve numerical benchmark functions and CEC (congress on evolutionary computation) 2015 test suite. The performance of the proposed approach is also compared with the artificial bee colony algorithm, particle swarm optimization algorithm, genetic algorithm, pure random search algorithm and differential evolution variants. Experimental comparisons show that the proposed method is better than the basic method in terms of solution quality, robustness and convergence characteristics.																	1868-8071	1868-808X				FEB	2020	11	2					249	267		10.1007/s13042-019-00970-1													
J								Type-2 fuzzy cerebellar model articulation control system design for MIMO uncertain nonlinear systems	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Adaptive control; Interval type-2 fuzzy system; Cerebellar model articulation controller; Uncertain nonlinear system	CMAC; HELICOPTER	This paper aims to propose a more efficient neural network and applies it as an adaptive controller for the multi-input multi-output (MIMO) uncertain nonlinear systems. First, a more efficient fuzzy neural network named as fuzzy cerebellar model articulation controller (CMAC) is introduced, then an adaptive controller is proposed using a novel interval type-2 fuzzy CMAC (T2FCMAC). The T2FCMAC realizes an interval type-2 fuzzy logic system based on the structure of the CMAC. Due to the better ability of handling uncertainties provided by type-2 fuzzy sets, it can solve some complicated problems with outstanding effectiveness than type-1 fuzzy sets. In addition, an intelligent control system is proposed; this control system is comprised of a T2FCMAC and an auxiliary compensation controller. The T2FCMAC is utilized to approximate a perfect controller and the parameters of T2FCMAC are on-line tuned by the derived adaptive laws based on a Lyapunov function. The auxiliary compensation controller is designed to suppress the influence of residual approximation error between the perfect controller and the T2FCMAC. Finally, two MIMO uncertain nonlinear systems, a Chua's chaotic circuit and a mass-spring-damper mechanical system, are performed to verify the effectiveness of the proposed control scheme. The simulation results confirm that the proposed intelligent adaptive control system can achieve favorable tracking performance with desired robustness.																	1868-8071	1868-808X				FEB	2020	11	2					269	286		10.1007/s13042-019-00972-z													
J								Effective spatio-temporal semantic trajectory generation for similar pattern group identification	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Mobility data; Semantic enrichment; Trajectory semantic; Similar behaviors; Group identification	CUCKOO SEARCH ALGORITHM; BAT ALGORITHM; OPTIMIZATION; LOCATIONS; DISCOVERY; SIZE; GPS	The daily trajectories of individual movements convey a concise overview of their behaviors, with different social roles having different trajectory patterns. Therefore, we can identify users or groups based on the similar of their trajectory patterns. However, most existing trajectory analysis focuses only on the spatial and temporal analyses of the raw trajectory data and misses essential semantic information concerning behaviors. In this paper, we propose a new trajectory semantics calculation method to identify groups with similar behaviors. We first propose a fast and efficient two-phase method for identifying stay regions within daily trajectories and enriching the stay regions with semantic labels based on points of interest to generate semantic trajectories. Furthermore, we design a semantic similarity measure model using geographic and semantic similarity factors to measure the similarity between semantic trajectories. We also propose a pruning strategy using time entropy to decrease the number of complex calculations and comparisons to improve performance. The results of our extensive experiments on the real trajectory dataset of the Geolife project show that our proposed method is both effective and efficient.																	1868-8071	1868-808X				FEB	2020	11	2					287	300		10.1007/s13042-019-00973-y													
J								Improved variational inference with dynamic routing flow	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Variational inference; Normalizing flow; Dynamic routing flow		How to transform a family of simple distributions to approximate an intractable posterior distribution in a scalable manner is a key problem in variational inference. Recent researches have been studied to generate a flexible approximate posterior distribution by utilizing a flow-based model with a long flow structure. However, when the dimension of the data increases, a long flow structure brings the problem of computational complexity and large variance. Therefore, we propose a variational inference with dynamic routing flow (DRF), which ensures the multiformity of the flows with shorter flow structure in this paper. The proposed model consists of a series of iterative sub-modules transformations, and each sub-module is enabled with a greater expression power by routing-by-agreement to achieve a group of weighted mixture of invertible transformations. These sub-modules route can be computed parallelly and they share the same group of invertible functions, which makes the inference more efficiency. The experimental results show that the proposed DRF model achieves significant performance on the posterior distribution estimation both in accuracy and precision.																	1868-8071	1868-808X				FEB	2020	11	2					301	312		10.1007/s13042-019-00974-x													
J								Selectivity analysis of parameters in soft set and its effect on decision making	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Soft set; Fuzzy parameterized soft set; Pseudo fuzzy soft set; Parameter selectivity; Decision making	REDUCTION; PRODUCTS; MATRIX	Binary relations between alternatives and parameters in a soft set have a vital role in the analysis of configuration of this soft set. All of the studies on the soft set approach focus on the parameters and their images under the approximate function. Recently, by approaching the soft set from a different perspective, a pseudo soft set has been introduced. This approach associates the alternatives and their images under the approximate function. In this paper, we first discuss the transition from a soft set to a pseudo soft set and vice versa. Later on, we endeavor to analyze the selectivity of parameters in the structure of a (fuzzy parameterized) soft set. This analysis focuses on the binary relations with boolean values between a parameter and its associated alternatives rather than on the specific values of alternatives with respect to a parameter. Relatedly, the concepts of selectivity ratio and coverage selectivity ratio of parameters under the (fuzzy parameterized) soft sets are introduced and some basic properties are presented. Also, by using the transition between the soft set and the pseudo soft set, it is investigated the effect of selectivity analysis of parameters on decision making. As a result of this attempt, new decision making algorithms are proposed. The outputs of these algorithms are compared with those of some of the existing decision making algorithms based on the (fuzzy parameterized) soft sets. Thus, the performance of each of the proposed algorithms is displayed.																	1868-8071	1868-808X				FEB	2020	11	2					313	324		10.1007/s13042-019-00975-w													
J								Non-fragile control protocol for finite-time consensus of stochastic multi-agent systems with input time-varying delay	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Stochastic multi-agent system; Non-fragile control; Finite-time consensus; Switching topology	LEADER-FOLLOWING CONSENSUS; RANDOMLY OCCURRING UNCERTAINTIES; H-INFINITY CONTROL; RELIABLE CONTROL; NETWORKS; SYNCHRONIZATION; ROBUST; NONLINEARITIES	The existence of gain variations in control design often disrupts most of the control system performance. By considering this point, as a first attempt in the literature, a robust non-fragile state feedback control design is proposed in this paper for achieving finite-time consensus in a class of stochastic nonlinear multi-agent systems with randomly occurring uncertainty and randomly occurring nonlinearity. Specifically, the randomness phenomena are characterized with the aid of stochastic variables that satisfy the Bernoulli distribution properties. To design the non-fragile control protocol, the communication graph is chosen to be directed and connected subject to switching topologies. On the basis of the Lyapunov-Krasovskii stability theory and stochastic analysis techniques, a new set of sufficient conditions is established to guarantee that the states of all agents can reach an agreement over a given finite-time period via the proposed non-fragile switched control law. The effectiveness of the designed consensus protocol is demonstrated through an academic example.																	1868-8071	1868-808X				FEB	2020	11	2					325	337		10.1007/s13042-019-00976-9													
J								An empirical study to estimate the stability of random forest classifier on the hybrid features recommended by filter based feature selection technique	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Dynamic features; Feature selection technique; Machine learning; Malware detection; Portable executable files; Static features	MALWARE DETECTION; DYNAMIC-ANALYSIS; API CALLS; DETECT; BEHAVIOR; RELEVANCE; FRAMEWORK; WRAPPER	The emergence of advanced malware is a serious threat to information security. A prominent technique that identifies sophisticated malware should consider the runtime behaviour of the source file to detect malicious intent. Although the behaviour-based malware detection technique is a substantial improvement over the traditional signature-based detection technique, current malware employs code obfuscation techniques to elude detection. This paper presents the Hybrid Features-based malware detection system (HFMDS) that integrates static and dynamic features of the portable executable (PE) files to discern malware. The HFMDS is trained with prominent features advised by the filter-based feature selection technique (FST). The detection ability of the proposed HFMDS has evaluated with the random forest (RF) classifier by considering two different datasets that consist of real-world Windows malware samples. In-depth analysis is carried out to determine the optimal number of decision trees (DTs) required by the RF classifier to achieve consistent accuracy. Besides, four popular FSTs performance is also analyzed to determine which FST recommends the best features. From the experimental analysis, we can infer that increasing the number of DTs after 160 within the RF classifier does not make a significant difference in attaining better detection accuracy.																	1868-8071	1868-808X				FEB	2020	11	2					339	358		10.1007/s13042-019-00978-7													
J								A hybrid optimization approach based on clustering and chaotic sequences	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Hybrid optimization techniques; Meta-heuristic; Chaos; Clustering	PARTICLE SWARM OPTIMIZATION; EVOLUTIONARY ALGORITHM; GENETIC ALGORITHM; DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION; NEURAL-NETWORK; SEARCH; EXPLORATION/EXPLOITATION; EXPLORATION; MECHANISM	Evolutionary computation algorithms represent a class of stochastic methods that can be applied to a wide set of different complex optimization problems. Recently, the combination of approaches extracted from different computation techniques represents one of the most successful trends in evolutionary optimization. With this integration, the idea is to overcome the limitations of each single method and to reach a synergetic effect through their integration. In this paper, a hybrid optimization algorithm for solving optimization problems is introduced. The approach, called cluster-chaotic-optimization, combines the classification characteristics of a clustering method with the randomness of chaotic sequences to conduct its search strategy. Under the proposed method, at each generation, the population is divided into different clusters according to its space distribution. Then, individuals are modified considering two kinds of operators: intra-cluster and extra-cluster. In the intra-cluster operation, individuals of the same cluster are locally adjusted considering the position of the best element of the cluster in terms of its fitness value. On the other hand, in the extra-cluster operation, the best individual of each cluster is globally attracted to the best element of the complete population. In both operations, the adjustment on each individual position is produced by using deterministic rules and chaotic sequences. With such mechanisms, the proposed method efficiently examines the search space based on the spatial associations produced by the individuals during the optimization process. To exhibit the performance and robustness of the proposed method, different comparisons to other well-known evolutionary methods and hybrid approaches are conducted. The comparison considers several standard benchmark functions and real-world engineering problems which are typically found in the literature of evolutionary algorithms. The results suggest a high performance of the proposed methodology.																	1868-8071	1868-808X				FEB	2020	11	2					359	401		10.1007/s13042-019-00979-6													
J								An augmented Lagrangian alternating direction method for overlapping community detection based on symmetric nonnegative matrix factorization	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Augmented Lagrangian function; Alternating direction method; Symmetric nonnegative matrix factorization; Overlapping community detection	ALGORITHMS; DUALITY	In this paper, we present an augmented Lagrangian alternating direction algorithm for symmetric nonnegative matrix factorization. The convergence of the algorithm is also proved in detail and strictly. Then we present a modified overlapping community detection method which is based on the presented symmetric nonnegative matrix factorization algorithm. We apply the modified community detection method to several real world networks. The obtained results show the capability of our method in detecting overlapping communities, hubs and outliers. We find that our experimental results have better quality than several competing methods for identifying communities.																	1868-8071	1868-808X				FEB	2020	11	2					403	415		10.1007/s13042-019-00980-z													
J								A two-stage hybrid probabilistic topic model for refining image annotation	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Refining image annotation; Semantic gap; Expectation-maximization; PLSA; Max-bisection; Image retrieval	SCENE CLASSIFICATION; RELEVANCE; REPRESENTATION; RECOGNITION; EFFICIENT; PLSA	Refining image annotation has become one of the core research topics in computer vision and pattern recognition due to its great potentials in image retrieval. However, it is still in its infancy and is not sophisticated enough to extract perfect semantic concepts just according to the image low-level features. In this paper, we propose a two-stage hybrid probabilistic topic model to improve the quality of automatic image annotation. To start with, a probabilistic latent semantic analysis model with asymmetric modalities is learned to estimate the posterior probabilities of each annotation keyword, during which the image-to-word relation can be well established. Next, a label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity of images associated with the corresponding labels. By this way, the information from image low-level visual features and high-level semantic concepts can be seamlessly integrated by fully taking into account the word-to-word and image-to-image relations. Finally, the rank-two relaxation heuristics is exploited to further mine the correlation of the candidate annotations so as to capture the refining results, which plays a critical role in semantic based image retrieval. Extensive experiments show that the proposed model achieves not only superior annotation accuracy but also better retrieval performance.																	1868-8071	1868-808X				FEB	2020	11	2					417	431		10.1007/s13042-019-00983-w													
J								DCSVM: fast multi-class classification using support vector machines	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Multiclass classification; SVM; Divide and conquer		Using binary classification techniques to perform multi-class classification of data is still of great practical interest due to the robustness and simplicity of binary classifiers. These techniques produce a single multi-class classification decision based on many binary decisions. Our work relies on the simple observation that as dimensionality increases so does the data sparsity and, consequently, a single binary classifier may separate multiple classes. Therefore, we claim that the number of binary decisions can be significantly reduced. We present Divide and Conquer Support Vector Machines (DCSVM), an efficient algorithm for multi-class classification using Support Vector Machines. DCSVM is a divide and conquer algorithm which relies on data sparsity in high dimensional space and performs a smart partitioning of the whole training data set into disjoint subsets that are easily separable. A single prediction performed between two partitions eliminates at once one or more classes in one partition, leaving only a reduced number of candidate classes for subsequent steps. The algorithm continues recursively, reducing the number of classes at each step, until a final binary decision is made between the last two classes left in the competition. In the best case scenario, our algorithm makes a final decision between k classes in O(log k) decision steps and in the worst case scenario DCSVM makes a final decision in k-1 steps, which is not worse than the existent techniques.																	1868-8071	1868-808X				FEB	2020	11	2					433	447		10.1007/s13042-019-00984-9													
J								Interactive learning for joint event and relation extraction	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Event detection; Relation extraction; Interactive learning		We tackle the problems of both event and entity relation extraction, and come up with a novel method to implement joint extraction: iteratively interactive learning. This method is motivated by the empirical findings as below: the extracted event attributes (e.g., trigger and event type) can be used as the reliable features for the recognition of entity relation types, and vice versa. Accordingly, on one hand, we utilize the predicted event attributes (by a certain event extraction system) to remodel the distributed representations of features for entity relation extraction, and on the other hand, we use entity relations (recognized by a certain relation extraction system) to remodel the features for event extraction. This enables a double-channel task-independent joint model with an interactive learning: learning events for relation extraction, and meanwhile learning relations for event extraction. In practice, we perform the interactive learning in an iterative manner, so as to boost the joint model progressively. Methodologically, we take the neural network of bidirectional long short-term memory (Bi-LSTM) for learning event and relation respectively. And as usual, the attention mechanism is used. In our experiments, the automatic content extraction corpus is used for the evaluation of the proposed method. Such a corpus consists of event, entity and relation samples with gold-standard attribute tags. Experimental results show that our method outperforms the baselines (Bi-LSTMs with attention without interactive learning) in both event and relation extraction tasks, yielding performance gains of about 1.6% and 1.8% F-scores respectively, at the condition of low-resource setting.																	1868-8071	1868-808X				FEB	2020	11	2					449	461		10.1007/s13042-019-00985-8													
J								Adaptive feature weighting for robust Lp-norm sparse representation with application to biometric image classification	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Biometrics; Feature weighting; Self-paced learning; Sparse representation	FACE RECOGNITION; ALGORITHMS	Sparse representation has attracted much attention in the field of biometrics, such as face recognition and palmprint recognition. Although the l(p)-norm (0 < p < 1) based sparse representation can obtain more sparse solution than the widely used l(1)-norm based method, it needs to solve a non-convex optimization problem, which leads to poor robustness in real application. In this paper, we propose a robust l(p)-norm sparse representation method with adaptive feature weighting. We derive the adaptive feature weighting method by self-paced learning (SPL), and utilize it to guide the features of l(p)-norm sparse representation in the easy-to-hard learning process. Differing from existing SPL methods, feature weighted SPL in our method dynamically evaluates the learning difficulty of each feature rather than sample. For the advantages of the proposed method, it can avoid l(p)-norm sparse minimization failing into bad local minima and reduce the effects of noise feature in the early learning stage. Experiments on several biometric image datasets show that our proposed method is superior to conventional l(p)-norm based method and the state-of-the-art classification methods.																	1868-8071	1868-808X				FEB	2020	11	2					463	474		10.1007/s13042-019-00986-7													
J								Unlabelled text mining methods based on two extension models of concept lattices	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Formal concept analysis; Three-way concept lattice; Fuzzy concept lattice; Text clustering; Text classification	FORMAL CONCEPT ANALYSIS; ASSOCIATION RULES; 3-WAY; ONTOLOGY	Concept lattice is a useful tool for text extraction. The common text clustering method fails to generate hierarchical relationships among categories and realize soft clustering simultaneously, while the concept lattice ignores the negative correlation between an object subset and an attribute subset. Motivated by the problems, we propose unlabelled text mining methods based on fuzzy concept lattice and three-way concept lattice. Firstly, we excavate hierarchical text categories to construct a classification system based on fuzzy concept lattice, and the labelled samples are obtained by the word matching method. Then, we construct a three-way concept lattice to get positive and negative classification rules based on the labelled samples, and the classifier is constructed to predict the new samples. Finally, Sogou laboratory news corpus is used to evaluate the efficiency of text clustering and classification methods. The results demonstrate that the improved clustering method has a higher average cluster goodness than earlier procedures and the classification model based on three-way concept lattice achieves a higher accuracy.																	1868-8071	1868-808X				FEB	2020	11	2					475	490		10.1007/s13042-019-00987-6													
J								Objective scaling ensemble approach for integer linear programming	JOURNAL OF HEURISTICS										Integer programming; Heuristics; Neighborhood search	NETWORK FLOW; COMBINATORIAL OPTIMIZATION; SCHEDULING PROBLEMS; TABU SEARCH; FEASIBILITY; FORMULATIONS; STRATEGIES; PIVOT; CUT	The objective scaling ensemble approach is a novel two-phase heuristic for integer linear programming problems shown to be effective on a wide variety of integer linear programming problems. The technique identifies and aggregates multiple partial solutions to modify the problem formulation and significantly reduce the search space. An empirical analysis on publicly available benchmark problems demonstrate the efficacy of our approach by outperforming standard solution strategies implemented in modern optimization software.																	1381-1231	1572-9397				FEB	2020	26	1					1	19		10.1007/s10732-019-09418-9													
J								A heuristic for fair dynamic resource allocation in overloaded OFDMA systems	JOURNAL OF HEURISTICS										Stochastic dynamic optimisation; Local search; OFDMA systems; Mobile wireless communications	POWER ALLOCATION; MULTIUSER OFDM; JOINT SUBCARRIER; COMPLEXITY; FREQUENCY	OFDMA is a popular coding scheme for mobile wireless communications. In OFDMA, one must allocate the available resources (bandwidth and power) dynamically, as user requests arrive and depart in a stochastic manner. Several exact and heuristic methods exist to do this, but they all perform poorly in the "over-loaded" case, in which the user demand is close to or exceeds the system capacity. To address this case, we present a dynamic local search heuristic. A particular feature of our heuristic is that it takes fairness into consideration. Simulations on realistic data show that our heuristic is fast enough to be used in real-time, and consistently delivers allocations of good quality.																	1381-1231	1572-9397				FEB	2020	26	1					21	32		10.1007/s10732-019-09422-z													
J								A coordinated production and transportation scheduling problem with minimum sum of order delivery times	JOURNAL OF HEURISTICS										Supply chain coordination; Production scheduling; Vehicle routing problem; Variable neighborhood search	VARIABLE NEIGHBORHOOD SEARCH; VEHICLE-ROUTING PROBLEM; INTEGRATED PRODUCTION; MEMETIC ALGORITHM; AIR-TRANSPORTATION; PRICE ALGORITHM; DECISIONS; PICKUP; CUT	In this paper, a coordinated production scheduling and vehicle routing problem aiming at minimizing the sum of order delivery times is considered, where there are a single machine for production and limited number of homogenous capacitated vehicles for transportation. Given the complexity of the studied problem, a variable neighborhood search (VNS) algorithm is proposed to address this problem. To construct initial solution, vehicle routing is determined with nearest insertion first, whereby the order batch production sequence is determined based on three propositions. Moreover, ten neighborhood structures are designed and a local search algorithm based on tabu search algorithm is proposed for intensification. The effectiveness of the proposed VNS algorithm is validated by comparing it with CPLEX and two heuristic algorithms in the existing literature. The computational results show that the proposed VNS algorithm can obtain optimal or near optimal solutions of the problem and is superior to the two heuristic algorithms proposed in the existing literature.																	1381-1231	1572-9397				FEB	2020	26	1					33	58		10.1007/s10732-019-09420-1													
J								MIQP model and improvement heuristic for power loss minimization in distribution system with network reconfiguration	JOURNAL OF HEURISTICS										Distribution system reconfiguration; Loss reduction; Optimization; Exact methods; Heuristic; Real approach	FEEDER RECONFIGURATION; FIX; ALGORITHM; REPRESENTATION; COST	The problem of reconfiguration in electrical power distribution systems deals with changes in the network topology using maneuvers switches. This is an optimization problem where one of the goals is to minimize losses following constraints such as faults isolation, load feeders balancing and voltage profile improvement. The present paper solves such problem by introducing a mixed-integer quadratic program (MIQP) model, which aims to return optimal configurations. An improvement heuristic, based on the solution of MIQP sub models, is also introduced. The MIQP model and improvement heuristic are validated over eight benchmark power systems, and the results achieved are compared against those recently reported by literature. A new set of 10 large sized bus-systems is also defined as replication of a benchmark bus system from literature. The computational results show that our MIQP model and heuristic are able to find optimal configurations for those benchmark systems, as well as to provide good quality solution for the large sized bus-systems within a reduced computational time.																	1381-1231	1572-9397				FEB	2020	26	1					59	81		10.1007/s10732-019-09421-0													
J								Hybrid adaptive large neighborhood search algorithm for the mixed fleet heterogeneous dial-a-ride problem	JOURNAL OF HEURISTICS										Dial-a-ride problem; Alternative fuel station; Adaptive large neighborhood search algorithm; Mixed vehicle fleet	VEHICLE-ROUTING PROBLEM; SCHEDULING PROBLEM; ALTERNATIVE-FUEL; CUT ALGORITHM; TABU SEARCH; MODELS	The mixed fleet heterogeneous dial-a-ride problem (MF-HDARP) consists of designing vehicle routes for a set of users by using a mixed fleet including both heterogeneous conventional and alternative fuel vehicles. In addition, a vehicle is allowed to refuel from a fuel station to eliminate the risk of running out of fuel during its service. We propose an efficient hybrid adaptive large neighborhood search (hybrid ALNS) algorithm for the MF-HDARP. The computational experiments show that the algorithm produces high quality solutions on our generated instances and on HDARP benchmarks instances. Computational experiments also highlight that the newest components added to the standard ALNS algorithm enhance intensification and diversification during the search process.																	1381-1231	1572-9397				FEB	2020	26	1					83	118		10.1007/s10732-019-09424-x													
J								A comparative study of multi-objective machine reassignment algorithms for data centres	JOURNAL OF HEURISTICS										Machine reassignment; Metaheuristics; Multi-objective	2-DIMENSIONAL VECTOR PACKING; LOWER BOUNDS; BIN PACKING; OPTIMIZATION; HEURISTICS; SEARCH; CLOUDS	At a high level, data centres are large IT facilities hosting physical machines (servers) that often run a large number of virtual machines (VMs)-but at a lower level, data centres are an intricate collection of interconnected and virtualised computers, connected services, complex service-level agreements. While data centre managers know that reassigning VMs to the servers that would best serve them and also minimise some cost for the company can potentially save a lot of money-the search space is large and constrained, and the decision complicated as they involve different dimensions. This paper consists of a comparative study of heuristics and exact algorithms for the multi-objective machine reassignment problem. Given the common intuition that the problem is too complicated for exact resolutions, all previous works have focused on various (meta)heuristics such as First-Fit, GRASP, NSGA-II or PLS. In this paper, we show that the state-of-art solution to the single objective formulation of the problem (CBLNS) and the classical multi-objective solutions fail to bridge the gap between the number, quality and variety of solutions. Hybrid metaheuristics, on the other hand, have proven to be more effective and efficient to address the problem-but as there has never been any study of an exact resolution, it was difficult to qualify their results. In this paper, we present the most relevant techniques used to address the problem, and we compare them to an exact resolution (epsilon-Constraints). We show that the problem is indeed large and constrained (we ran our algorithm for 30 days on a powerful node of a supercomputer and did not get the final solution for most instances of our problem) but that a metaheuristic (GeNePi) obtains acceptable results: more (+ 188%) solutions than the exact resolution and a little more than half (52%) the hypervolume (measure of quality of the solution set).																	1381-1231	1572-9397				FEB	2020	26	1					119	150		10.1007/s10732-019-09427-8													
J								Online social network analysis: detection of communities of interest	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Social networks; Graphs and networks; Clustering; Community of interest; Algorithms	INTERNET; MODELS; MEDIA	The second generation of World Wide Web, supplied with the platforms of Social Networks, proves to be a revealing source of knowledge. It has led to the emergence of online communities of interest. In fact, the interactions of users through web usages allow the exchange of information and the dissemination of innovation; thereby the formation of cohesive groups of individuals sharing goals, interests, semantics and services. Reflection on the evolution of those groups and their detection is a fundamental topic of interest in the field of Social Network Analysis. This problem is very challenging and hard to solve despite the huge interdisciplinary research over the past years. In this paper, we will attempt an indepth comparative review of the proposed approaches for clustering Social Network actors into communities of interests and propose a new classification of these approaches.																	0925-9902	1573-7675				FEB	2020	54	1			SI		5	21		10.1007/s10844-018-0522-7													
J								Data-driven decision making in critique-based recommenders: from a critique to social media data	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Data-driven decision making; Recommender systems; Critique-based recommendations; User modeling	SYSTEMS; SEARCH; TESTS	In the last decade there have been a large number of proposals in the field of Critique-based Recommenders. Critique-based recommenders are data-driven in their nature since they use a conversational cyclical recommendation process to elicit user feedback. In the literature, the proposals made differ mainly in two aspects: in the source of data and in how this data is analyzed to extract knowledge for providing users with recommendations. In this paper, we propose new algorithms that address these two aspects. Firstly, we propose a new algorithm, called HOR, which integrates several data sources, such as current user preferences (i.e., a critique), product descriptions, previous critiquing sessions by other users, and users' opinions expressed as ratings on social media web sites. Secondly, we propose adding compatibility and weighting scores to turn user behavior into knowledge to HOR and a previous state-of-the-art approach named HGR to help both algorithms make smarter recommendations. We have evaluated our proposals in two ways: with a simulator and with real users. A comparison of our proposals with state-of-the-art approaches shows that the new recommendation algorithms significantly outperform previous ones.																	0925-9902	1573-7675				FEB	2020	54	1			SI		23	44		10.1007/s10844-018-0520-9													
J								Exploiting recommendation confidence in decision-aware recommender systems	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Confidence; Decision-aware; Evaluation; Accuracy; Coverage; Novelty; Diversity		The main goal of a Recommender System is to suggest relevant items to users, although other utility dimensions - such as diversity, novelty, confidence, possibility of providing explanations - are often considered. In this work, we investigate about confidence but from the perspective of the system: what is the confidence a system has on its own recommendations; more specifically, we focus on different methods to embed awareness into the recommendation algorithms about deciding whether an item should be suggested. Sometimes it is better not to recommend than fail because failure can decrease user confidence in the system. In this way, we hypothesise the system should only show the more reliable suggestions, hence, increasing the performance of such recommendations, at the expense of, presumably, reducing the number of potential recommendations. Different from other works in the literature, our approaches do not exploit or analyse the input data but intrinsic aspects of the recommendation algorithms or of the components used during prediction are considered. We propose a taxonomy of techniques that can be applied to some families of recommender systems allowing to include mechanisms to decide if a recommendation should be generated. In particular, we exploit the uncertainty in the prediction score for a probabilistic matrix factorisation algorithm and the family of nearest-neighbour algorithms, the support of the prediction score for nearest-neighbour algorithms, and a method independent of the algorithm. We study how the performance of a recommendation algorithm evolves when it decides not to recommend in some situations. If the decision of avoiding a recommendation is sensible - i.e., not random but related to the information available to the system about the target user or item -, the performance is expected to improve at the expense of other quality dimensions such as coverage, novelty, or diversity. This balance is critical, since it is possible to achieve a very high precision recommending only one item to a unique user, which would not be a very useful recommender. Because of this, on the one hand, we explore some techniques to combine precision and coverage metrics, an open problem in the area. On the other hand, a family of metrics (correctness) based on the assumption that it is better to avoid a recommendation rather than providing a bad recommendation is proposed herein. In summary, the contributions of this paper are twofold: a taxonomy of techniques that can be applied to some families of recommender systems allowing to include mechanisms to decide if a recommendation should be generated, and a first exploration to the combination of evaluation metrics, mostly focused on measures for precision and coverage. Empiric results show that large precision improvements are obtained when using these approaches at the expense of user and item coverage and with varying levels of novelty and diversity.																	0925-9902	1573-7675				FEB	2020	54	1			SI		45	78		10.1007/s10844-018-0526-3													
J								Engagement in proactive recommendations The role of recommendation accuracy, information privacy concerns and personality traits	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Information privacy; Concerns for information privacy; Proactive recommendation delivery; Personality-aware recommendations; Human-computer interaction	USER ACCEPTANCE; 5-FACTOR MODEL; E-COMMERCE; PARADOX; ONLINE; ANTECEDENTS; NEUROTICISM; DIMENSIONS; BEHAVIOR; SYSTEMS	The present research explored to what extent user engagement in proactive recommendation scenarios is influenced by the accuracy of recommendations, concerns with information privacy, and trait personality. We hypothesized that people's self-reported information privacy concerns would matter more when they received accurate (vs. inaccurate) proactive recommendations, because these pieces of advice would seem fair to them. We further hypothesized that this would particularly be the case for people high on the social personality trait Extraversion, who are by inclination prone to behaving in a more socially engaging manner. We put this to the test in a controlled experiment, in which users received manipulated proactive recommendations of high or low accuracy on their smartphone. Results indicated that information privacy concerns positively influenced a user's engagement with proactive recommendations. Recommendation accuracy influenced user engagement in interaction with information privacy concerns and personality traits. Implications for the design of human-computer interaction for recommender systems are addressed.																	0925-9902	1573-7675				FEB	2020	54	1			SI		79	100		10.1007/s10844-018-0529-0													
J								Predicting future personal life events on twitter via recurrent neural networks	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Life event prediction; Recurrent neural networks; Social networks; Twitter		Social network users publicly share a wide variety of information with their followers and the general public ranging from their opinions, sentiments and personal life activities. There has already been significant advance in analyzing the shared information from both micro (individual user) and macro (community level) perspectives, giving access to actionable insight about user and community behaviors. The identification of personal life events from user's profiles is a challenging yet important task, which if done appropriately, would facilitate more accurate identification of users' preferences, interests and attitudes. For instance, a user who has just broken his phone, is likely to be upset and also be looking to purchase a new phone. While there is work that identifies tweets that include mentions of personal life events, our work in this paper goes beyond the state of the art by predicting a future personal life event that a user will be posting about on Twitter solely based on the past tweets. We propose two architectures based on recurrent neural networks, namely the classification and generation architectures, that determine the future personal life event of a user. We evaluate our work based on a gold standard Twitter life event dataset and compare our work with the state of the art baseline technique for life event detection. While presenting performance measures, we also discuss the limitations of our work in this paper.																	0925-9902	1573-7675				FEB	2020	54	1			SI		101	127		10.1007/s10844-018-0519-2													
J								Topic and sentiment aware microblog summarization for twitter	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Microblogging; Twitter; Summarization; Topic Modeling		Recent advances in microblog content summarization has primarily viewed this task in the context of traditional multi-document summarization techniques where a microblog post or their collection form one document. While these techniques already facilitate information aggregation, categorization and visualization of microblog posts, they fall short in two aspects: i) when summarizing a certain topic from microblog content, not all existing techniques take topic polarity into account. This is an important consideration in that the summarization of a topic should cover all aspects of the topic and hence taking polarity into account (sentiment) can lead to the inclusion of the less popular polarity in the summarization process. ii) Some summarization techniques produce summaries at the topic level. However, it is possible that a given topic can have more than one important aspect that need to have representation in the summarization process. Our work in this paper addresses these two challenges by considering both topic sentiments and topic aspects in tandem. We compare our work with the state of the art Twitter summarization techniques and show that our method is able to outperform existing methods on standard metrics such as ROUGE-1.																	0925-9902	1573-7675				FEB	2020	54	1			SI		129	156		10.1007/s10844-018-0521-8													
J								From mobility patterns to behavioural change: leveraging travel behaviour and personality profiles to nudge for sustainable transportation	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Behavioural change; Mobility patterns; Personality; Data-driven profile; Sustainable transportation	TRIAL	Rendering transport behaviours more sustainable is a pressing issue of our times. In this paper, we rely on the deep penetration of mobile phones in order to influence citizens' behavior through data-driven mobility and persuasive profiles. Our proposed approach aims to nudge users on a personalized level in order to change their mobility behavior and make more sustainable choices. To achieve our goal, first we leverage pervasive mobile sensing to uncover users' mobility patterns and use of transportation modes. Second, we construct users' persuadability profiles by considering their personality and mobility behavior. With the use of the aforementioned information we generate personalized interventions that nudge users to adopt sustainable transportation habits. These interventions rely on persuasive technologies and are embedded in a route planning application for smartphones. A pilot study with 30 participants using the system for 6 weeks provided fairly positive evaluation results in terms of the acceptance of our approach and revealed instances of behavioural change.																	0925-9902	1573-7675				FEB	2020	54	1			SI		157	178		10.1007/s10844-018-0528-1													
J								A knowledge-based multi-criteria collaborative filtering approach for discovering services in mobile cloud computing platforms The case of MobiCloUP!	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Recommender system; Multi-criteria rating; Collaborative filtering; Semantic web; Knowledge base; Mobile cloud computing	RECOMMENDER; RETRIEVAL; SYSTEM	In the context of Cloud-based development of mobile applications, third-party services to be integrated by applications often have to be manually selected among many categories and providers at design time. Over the years, recommender systems have proven effective in overcoming the challenges related to the incredible growth of the information on the Web. In an effort to better address this problem, the use of Semantic Web technologies in the development of recommender systems has been gaining momentum in recent years. In this paper, we propose a knowledge-based Collaborative Filtering recommendation approach for the discovery of services in a mobile Cloud computing platform for services-based development. Our approach employs a knowledge-based technique that takes advantage of Semantic Web rule-based reasoning capabilities. A major contribution of this work is a multi-criteria collaborative service evaluation mechanism that is based on a standard service quality framework and is built on top of an ontology-based domain model. A two-part evaluation method that is intended to evaluate the proposed recommendation approach not only from a Computer Science perspective but also from an Information Systems perspective is also presented.																	0925-9902	1573-7675				FEB	2020	54	1			SI		179	203		10.1007/s10844-018-0527-2													
J								Privacy-preserving shared collaborative web services QoS prediction	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Collaborative QoS prediction; Privacy-preserving; Differential privacy; Data sharing	DIFFERENTIAL PRIVACY	Collaborative Web services QoS prediction (CQoSP) has been proved to be an effective tool to predict unknown QoS values of services. Recently a number of efforts have been made in this area, focusing on improving the accuracy of prediction. In this paper, we consider a novel kind of CQoSP, shared CQoSP, where multiple parties share their data with each other in order to provide more accurate prediction than a single party could do. To encourage data sharing, we propose a privacy-preserving framework which enables shared collaborative QoS prediction without leaking the private information of the involved party. Our framework is based on differential privacy, a rigorous and provable privacy model. We conduct extensive experiments on a real Web services QoS dataset. Experimental results show the proposed framework increases prediction accuracy while ensuring the privacy of data owners.																	0925-9902	1573-7675				FEB	2020	54	1			SI		205	224		10.1007/s10844-018-0525-4													
J								Human-in-the-Loop Control Using Euler Angles	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Human-in-the-loop control; Euler angles; Admittance control	ADAPTIVE ADMITTANCE CONTROL; IMPEDANCE CONTROL; MANIPULATORS; FORCE	In this paper, we proposed a Human-in-the-loop (HITL) control based on the Euler angles solution of the robot end-effector. When humans are in the control loop, we can linearize the Euler angles such that they have direct relation with the joint angles and they are also decoupled. So the Jacobian matrix and the inverse kinematics are not needed. We simplify the admittance control using the Euler angles. The stability of those controllers is proven. The experiments, with a two-degree-of-freedom (2-DOF) pan and tilt robot and a four-degree-of-freedom exoskeleton, show that our Euler angles based controllers are simple and effective.																	0921-0296	1573-0409				FEB	2020	97	2					271	285		10.1007/s10846-019-01058-2													
J								A Control Strategy for Maintaining Gait Stability and Reducing Body-Exoskeleton Interference Force in Load-Carrying Exoskeleton	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Load-carrying Exoskeleton; ZMP; Gait stability; Body-exoskeleton interference		A key issue of load-carrying exoskeleton is to maintain the stability of gait during walking and prevent the wearer from falling over. Some of current strategies were to maintain ZMP (zero-moment point) in the support area, which had been widely used in humanoid robot. However, this method would cause serious interference between body and exoskeleton. because the body often gets energy-saving and rapid walking through unstable conditions during human walking. A control strategy for load-carrying exoskeleton was presented in this paper, which maintained the consistency of body ZMP and exoskeleton ZMP. This control strategy could reduce body-exoskeleton interference while maintaining the stability of walking. In this paper, we firstly introduced the experimental environment and the ZMP detection method, and then designed a computational model of the body-exoskeleton interaction force and evaluation criterion for gait stability. Then, a control strategy based on ZMP was designed. Finally, experiments showed that the control strategy could effectively reduce the body-exoskeleton interference, and maintained the stability of wearer's walking.																	0921-0296	1573-0409				FEB	2020	97	2					287	298		10.1007/s10846-019-01043-9													
J								Efficient Hybrid-Supervised Deep Reinforcement Learning for Person Following Robot	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Person following robot; Deep reinforcement learning; Integration method; Efficient data collection; Real-world situations	TRACKING	Traditional person following robots usually need hand-crafted features and a well-designed controller to follow the assigned person. Normally it is difficult to be applied in outdoor situations due to variability and complexity of the environment. In this paper, we propose an approach in which an agent is trained by hybrid-supervised deep reinforcement learning (DRL) to perform a person following task in end-to-end manner. The approach enables the robot to learn features autonomously from monocular images and to enhance performance via robot-environment interaction. Experiments show that the proposed approach is adaptive to complex situations with significant illumination variation, object occlusion, target disappearance, pose change, and pedestrian interference. In order to speed up the training process to ensure easy application of DRL to real-world robotic follower controls, we apply an integration method through which the agent receives prior knowledge from a supervised learning (SL) policy network and reinforces its performance with a value-based or policy-based (including actor-critic method) DRL model. We also utilize an efficient data collection approach for supervised learning in the context of person following. Experimental results not only verify the robustness of the proposed DRL-based person following robot system, but also indicate how easily the robot can learn from mistakes and improve performance.																	0921-0296	1573-0409				FEB	2020	97	2					299	312		10.1007/s10846-019-01030-0													
J								Visual Object Categorization Based on Hierarchical Shape Motifs Learned From Noisy Point Cloud Decompositions	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Object shape categorization; Shape reasoning; Shape motifs; Hierarchical shape representation; Shape decomposition	SEGMENTATION; RECOGNITION	Object shape is a key cue that contributes to the semantic understanding of objects. In this work we focus on the categorization of real-world object point clouds to particular shape types. Therein surface description and representation of object shape structure have significant influence on shape categorization accuracy, when dealing with real-world scenes featuring noisy, partial and occluded object observations. An unsupervised hierarchical learning procedure is utilized here to symbolically describe surface characteristics on multiple semantic levels. Furthermore, a constellation model is proposed that hierarchically decomposes objects. The decompositions are described as constellations of symbols (shape motifs) in a gradual order, hence reflecting shape structure from local to global, i.e., from parts over groups of parts to entire objects. The combination of this multi-level description of surfaces and the hierarchical decomposition of shapes leads to a representation which allows to conceptualize shapes. An object discrimination has been observed in experiments with seven categories featuring instances with sensor noise, occlusions as well as inter-category and intra-category similarities. Experiments include the evaluation of the proposed description and shape decomposition approach, and comparisons to Fast Point Feature Histograms, a Vocabulary Tree and a neural network-based Deep Learning method. Furthermore, experiments are conducted with alternative datasets which analyze the generalization capability of the proposed approach.																	0921-0296	1573-0409				FEB	2020	97	2					313	338		10.1007/s10846-019-01016-y													
J								An AEKF-SLAM Algorithm with Recursive Noise Statistic Based on MLE and EM	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										SLAM; EKF; Adaptive; MLE; EM; ICE	EXTENDED KALMAN FILTER; SIMULTANEOUS LOCALIZATION	Extended Kalman Filter (EKF) has been popularly utilized for solving Simultaneous Localization and Mapping (SLAM) problem. Essentially, it requires the accurate system model and known noise statistic. Nevertheless, this condition can be satisfied in simulation case. Hence, EKF has to be enhanced when it is applied in the real-application. Mainly, this improvement is known as adaptive-based approach. In many different cases, it is indicated by some manners of estimating for either part or full noise statistic. This paper present a proposed method based on the adaptive-based solution used for improving classical EKF namely An Adaptive Extended Kalman Filter. Initially, the classical EKF was improved based on Maximum Likelihood Estimation (MLE) and Expectation-Maximization (EM) Creation. It aims to equips the conventional EKF with ability of approximating noise statistic and its covariance matrices recursively. Moreover, EKF was modified and improved to tune the estimated values given by MLE and EM creation. Besides that, the recursive noise statistic estimators were also estimated based on the unbiased estimation. Although it results high quality solution but it is followed with some risks of non-positive definite matrices of the process and measurement noise statistic covariances. Thus, an addition of Innovation Covariance Estimation (ICE) was also utilized to depress this possibilities. The proposed method is applied for solving SLAM problem of autonomous wheeled mobile robot. Henceforth, it is termed as AEKF-SLAM Algorithm. In order to validate the effectiveness of proposed method, some different SLAM-Based algorithm were compared and analyzed. The different simulation has been showing that the proposed method has better stability and accuracy compared to the conventional filter in term of Root Mean Square Error (RMSE) of Estimated Map Coordinate (EMC) and Estimated Path Coordinate (EPC).																	0921-0296	1573-0409				FEB	2020	97	2					339	355		10.1007/s10846-019-01044-8													
J								Experimental Study on Shared-Control of a Mobile Robot via a Haptic Device with an Optimal Velocity Obstacle Based Receding Horizon Control Approach	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Shared control; Obstacle avoidance; Mobile robots; Haptic device; Receding horizon concept; Convex optimization	TRAJECTORY LENGTH CONCEPT; BILATERAL TELEOPERATION; SYNCHRONIZATION CONTROL; PERFORMANCE; DESIGN; INTERFACE; SYSTEM	This paper addresses shared-control of a single mobile robot in an unknown environment via a Haptic device in order to have a collision-free motion and damp the system's oscillations. Employing the receding horizon concept in order to meet the controlling criteria and using the approximated non-convex constraints to ensure the near-optimality of the proposed method lead to introducing an applicable algorithm. In this regard, the velocity obstacle concept is considered as avoiding constraint for the employed receding horizon method in the motion planning unite and the proposed optimization problem is solved by the mixed integer linear programming approach. Along with the aforementioned unite, the impedance methodology is employed in order to control the Haptic device as the master controller. For the sake of tuning the controller parameters and alleviating the plausible oscillations in the control states, the oscillation number index is utilized. The obtained experimental and simulation results reveal the fact that the proposed algorithm in the fully autonomous manner outperforms its prior counterparts such as conventional potential field with genetic algorithm. The implementation results of the extended algorithm in order to perform a shared-control of a Falcon Haptic device and an Epuck mobile robot are presented.																	0921-0296	1573-0409				FEB	2020	97	2					357	372		10.1007/s10846-019-01023-z													
J								A Revised Monte Carlo Method for Target Location with UAV	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Monte Carlo; Target location; UAV; Bias	SEARCH	Target location using UAV equipped with vision system has played an important role in many applications but there remain challenges. One of the principal difficulties is to position a target with a high accuracy, particularly in some specific conditions. There are many factors impacting location accuracies, such as turret setup process, sensors intrinsic properties, movement noise and GPS data precision. The most common and notable factors are the movement noise and sensors noise, which are tricky to be eliminated or compensated. Solutions to dealing with noise are mainly from methods such as recursive least square method, least square and Kalman filtering methods. But these routine methods will meet their bottlenecks when locating some plane based targets, a common scenario in target location applications. In this case, the usual methods are subject to target pointing bias of line of sight owing to the specific geometric condition. To eliminate this kind of location bias, an improved Monte Carlo method is proposed in this paper which first estimates the bias of pointing deviation for each measurement with statistical methods and then subtracts the estimated biases in a variance optimization process. Relevant experiments are conducted showing an obvious advantage of the proposed method over the other methods.																	0921-0296	1573-0409				FEB	2020	97	2					373	386		10.1007/s10846-019-01011-3													
J								An Intelligent Hybrid Artificial Neural Network-Based Approach for Control of Aerial Robots	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Artificial neural networks; Sliding mode control; Unmanned aerial vehicles; Fault tolerant control; Fast and agile manoeuvres	MODEL-PREDICTIVE CONTROL; TRAJECTORY GENERATION; AGGRESSIVE MANEUVERS; QUADROTOR HELICOPTER; LEARNING ALGORITHM; FLIGHT; DESIGN; FTC	In this work, a learning model-free control method is proposed for accurate trajectory tracking and safe landing of unmanned aerial vehicles (UAVs). A realistic scenario is considered where the UAV commutes between stations at high-speeds, experiences a single motor failure while surveying an area, and thus requires to land safely at a designated secure location. The proposed challenge is viewed solely as a control problem. A hybrid control architecture - an artificial neural network (ANN)-assisted proportional-derivative controller - is able to learn the system dynamics online and compensate for the error generated during different phases of the considered scenario: fast and agile flight, motor failure, and safe landing. Firstly, it deals with unmodelled dynamics and operational uncertainties and demonstrates superior performance compared to a conventional proportional-integral-derivative controller during fast and agile flight. Secondly, it behaves as a fault-tolerant controller for a single motor failure case in a coaxial hexacopter thanks to its proposed sliding mode control theory-based learning architecture. Lastly, it yields reliable performance for a safe landing at a secure location in case of an emergency condition. The tuning of weights is not required as the structure of the ANN controller starts to learn online, each time it is initialised, even when the scenario changes - thus, making it completely model-free. Moreover, the simplicity of the neural network-based controller allows for the implementation on a low-cost low-power onboard computer. Overall, the real-time experiments show that the proposed controller outperforms the conventional controller.																	0921-0296	1573-0409				FEB	2020	97	2					387	398		10.1007/s10846-019-01031-z													
J								Space Occupancy Representation Based on A Bayesian Model for Unmanned Aerial Vehicles	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Unmanned Aerial Vehicles (UAVs); Collision avoidance; Bayesian network; Space occupancy	UAV COLLISION-AVOIDANCE; VISION; NAVIGATION	Collision avoidance for unmanned aerial vehicles is a main task for autonomous aerial systems. One of the major challenges facing such technology is the existence of a high level of uncertainty in moving objects. In this research study, we chose to work with object's classification and probabilistic models to deal with the system's uncertainty. First, a classification takes place through detecting an object, identifying it using a trained convolutional neural network, and analyzing its velocity. Afterwards, a Bayesian probabilistic model takes inputs of the detected object's type, orientation, and velocity along with the host unmanned aerial vehicle's velocity. It gives an output of the detected object's space occupancy. The simulation results show that the space occupancy clearly changes with respect to the available inputs of the Bayesian model as a function of time; hence, optimizing the space occupancy around the detected object.																	0921-0296	1573-0409				FEB	2020	97	2					399	410		10.1007/s10846-019-01042-w													
J								Stochastic Multi-Robot Patrolling with Limited Visibility	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Multi-robot patrolling; Distributed and centralized patrolling; Visibility; Markov chain; Convex optimization	PERFORMANCE	Patrolling an environment with multiple robots is a problem with applicability to both military activities and other areas requiring security. In an adversarial environment, wireless communication between the robots may be jammed, and their sensor ranges may be limited to visibility. This increases the difficulty of the problem, but solutions will be widely applicable regardless of the environment. Robot paths that are deterministic can be observed and predicted by an adversary, permitting exploitation of known gaps in coverage. We also wish to avoid requirements for synchronization or a particular form of the environment. We, therefore, propose a method of finding patrolling policies for multiple robots that monitor any polygonal environment using limited visibility regions and non-deterministic patrolling paths. First, visibility regions are calculated for a subset of locations that cover the whole environment or a part of the environment. Then, we find distributed patrolling policies in the form of Markov chains, using convex optimization to minimize the average expected commute time for the subset of the locations permitting each robot to cover the whole environment independently. We also find centralized and Markov chain based patrolling policies that minimize the average expected commute time for the subset of locations permitting each robot to cover a part of the environment while communicating with a central base station. Finally, we evaluate the vulnerability of our patrolling policies by finding the probability of capturing an adversary and the maximum unguarded time for a location in our proposed patrolling scenarios. We present multiple simulation results and a physical implementation to show the effectiveness of our visibility-based non-deterministic patrolling method.																	0921-0296	1573-0409				FEB	2020	97	2					411	429		10.1007/s10846-019-01039-5													
J								Mechanism and Control of a One-Actuator Mobile Robot Incorporating a Torque Limiter	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Mobile robot; Mechanism; Control; Torque limiter; Single actuator		This study presents a novel mechanism for the control of a wheeled robot maneuvering with a single actuator. Elements of snakeboard and two-wheeled skateboard propulsion are applied to the design. Two passive wheels, i.e., casters whose orientation can be controlled, are attached in the back and front of the robot body, and a rotor rotates above the body to induce body propulsion using its counter torque. Three degrees of freedom of motion, i.e., the orientation of the rotor and each of the two casters, are mechanically coupled to the single actuator via a torque limiter. The stoppers are set to restrict the angle of the caster orientation, and a torque limiter allows the rotor to continue rotating without being affected by the stopper's restriction to the range of motion. Experiments demonstrate that the sinusoidal rotor rotation can propel this robot forward and that adding the increasing or decreasing offset to the sinusoidal rotor rotation can curve the robot's motion. Next, a method to position the robot at a specified goal position is proposed, assuming that the current position of the robot is detectable in every control cycle. This method adjusts the rate of increase or decrease of the offset in sinusoidal rotor rotation depending on the direction of the goal position. Introducing the motion capture system enables the robot to successfully reach the specified goal positions.																	0921-0296	1573-0409				FEB	2020	97	2					431	448		10.1007/s10846-019-01036-8													
J								Homography Estimation from Ellipse Correspondences Based on the Common Self-polar Triangle	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Homography; Ellipse correspondence; Common self-polar triangle; Quasi-affine transformation; Analytical solution	MOTION	This paper presents new implementation algorithms for estimating the homography from ellipse correspondences based on the common self-polar triangle. Firstly, we propose an analytical solution with a fourfold ambiguity to homography based on converting two ellipse correspondences to three common pole correspondences. Secondly, after exploring the position information of the common poles, we propose the analytical algorithms for estimating the homography from only two ellipse correspondences. We also propose an analytical linear algorithm for estimating the homography by using the common pole correspondences with the known projective scale factors when given three or more ellipse correspondences. Unlike the previous methods, our algorithms are very easy to implement and furthermore may usually provide a unique solution (at most two solutions). Experimental results in synthetic data and real images show the accuracy advantage and the usefulness of our proposed algorithms.																	0924-9907	1573-7683				FEB	2020	62	2					169	188		10.1007/s10851-019-00928-6													
J								Optimizing Excitation Coil Currents for Advanced Magnetorelaxometry Imaging	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Condition number; Imaging; Inverse problem; Magnetic nanoparticles; Magnetorelaxometry; Optimization	MAGNETIC NANOPARTICLES; THRESHOLDING ALGORITHM; INVERSE; FIELDS	Magnetorelaxometry imaging is a highly sensitive technique enabling noninvasive, quantitative detection of magnetic nanoparticles. Electromagnetic coils are sequentially energized, aligning the nanoparticles' magnetic moments. Relaxation signals are recorded after turning off the coils. The forward model describing this measurement process is reformulated into a severely ill-posed inverse problem that is solved for estimating the particle distribution. Typically, many activation sequences employing different magnetic fields are required to obtain reasonable imaging quality. We seek to improve the imaging quality and accelerate the imaging process using fewer activation sequences by optimizing the applied magnetic fields. Minimizing the Frobenius condition number of the system matrix, we stabilize the inverse problem solution toward model uncertainties and measurement noise. Furthermore, our sensitivity-weighted reconstruction algorithms improve imaging quality in lowly sensitive areas. The optimization approach is employed to real measurement data and yields improved reconstructions with fewer activation sequences compared to non-optimized measurements.																	0924-9907	1573-7683				FEB	2020	62	2					238	252		10.1007/s10851-019-00934-8													
J								Bioacoustic detection with wavelet-conditioned convolutional neural networks	NEURAL COMPUTING & APPLICATIONS										Convolutional neural networks; Spectrograms; Short-time Fourier transform; Wavelets; Acoustic signal processing; Classification and detection	AUTOMATED IDENTIFICATION; ACOUSTIC IDENTIFICATION; MALARIA CONTROL; CLASSIFICATION; TRANSFORM; INSECTS	Many real-world time series analysis problems are characterized by low signal-to-noise ratios and compounded by scarce data. Solutions to these types of problems often rely on handcrafted features extracted in the time or frequency domain. Recent high-profile advances in deep learning have improved performance across many application domains; however, they typically rely on large data sets that may not always be available. This paper presents an application of deep learning for acoustic event detection in a challenging, data-scarce, real-world problem. We show that convolutional neural networks (CNNs), operating on wavelet transformations of audio recordings, demonstrate superior performance over conventional classifiers that utilize handcrafted features. Our key result is that wavelet transformations offer a clear benefit over the more commonly used short-time Fourier transform. Furthermore, we show that features, handcrafted for a particular dataset, do not generalize well to other datasets. Conversely, CNNs trained on generic features are able to achieve comparable results across multiple datasets, along with outperforming human labellers. We present our results on the application of both detecting the presence of mosquitoes and the classification of bird species.																	0941-0643	1433-3058				FEB	2020	32	4			SI		915	927		10.1007/s00521-018-3626-7													
J								Automatic chord label personalization through deep learning of shared harmonic interval profiles	NEURAL COMPUTING & APPLICATIONS										Automatic chord estimation; Personalization; Harmony	MUSIC	Current automatic chord estimation systems are trained and tested using datasets that contain single reference annotations, i.e., for each corresponding musical segment (e.g., audio frame or section), the reference annotation contains a single chord label. Nevertheless, theoretical insights on harmonic ambiguity from harmony theory, experimental studies on annotator subjectivity in harmony annotations, and the availability of vast amounts of heterogeneous (subjective) harmony annotations in crowd-sourced repositories make the notion of a single-harmonic "ground truth" reference annotation a tenuous one. Recent studies suggest that subjectivity is intrinsic to harmonic reference annotations that should be embraced in automatic chord estimation rather than resolved. We introduce the first approach to automatic chord label personalization by modeling annotator subjectivity through harmonic interval-based chord representations. We integrate these representations from multiple annotators and deep learn them from audio. From a single trained model and the annotators' chord-label vocabulary, we can accurately personalize chord labels for individual annotators. Furthermore, we show that chord personalization using multiple reference annotations outperforms using just a single reference annotation. Our results show that annotator subjectivity should inform future research on automatic chord estimation to improve the state of the art.																	0941-0643	1433-3058				FEB	2020	32	4			SI		929	939		10.1007/s00521-018-3703-y													
J								Basic filters for convolutional neural networks applied to music: Training or design?	NEURAL COMPUTING & APPLICATIONS										Machine learning; Convolutional neural networks; Adaptive filters; Gabor multipliers; Mel-spectrogram; End-to-end learning	OPERATORS	When convolutional neural networks are used to tackle learning problems based on music or other time series, raw one-dimensional data are commonly preprocessed to obtain spectrogram or mel-spectrogram coefficients, which are then used as input to the actual neural network. In this contribution, we investigate, both theoretically and experimentally, the influence of this pre-processing step on the network's performance and pose the question whether replacing it by applying adaptive or learned filters directly to the raw data can improve learning success. The theoretical results show that approximately reproducing mel-spectrogram coefficients by applying adaptive filters and subsequent time-averaging on the squared amplitudes is in principle possible. We also conducted extensive experimental work on the task of singing voice detection in music. The results of these experiments show that for classification based on convolutional neural networks the features obtained from adaptive filter banks followed by time-averaging the squared modulus of the filters' output perform better than the canonical Fourier transform-based mel-spectrogram coefficients. Alternative adaptive approaches with center frequencies or time-averaging lengths learned from training data perform equally well.																	0941-0643	1433-3058				FEB	2020	32	4			SI		941	954		10.1007/s00521-018-3704-x													
J								This time with feeling: learning expressive musical performance	NEURAL COMPUTING & APPLICATIONS										Music generation; Deep learning; Recurrent neural networks; Artificial intelligence	MODELS; PERCEPTION	Music generation has generally been focused on either creating scores or interpreting them. We discuss differences between these two problems and propose that, in fact, it may be valuable to work in the space of direct performance generation: jointly predicting the notes and also their expressive timing and dynamics. We consider the significance and qualities of the dataset needed for this. Having identified both a problem domain and characteristics of an appropriate dataset, we show an LSTM-based recurrent network model that subjectively performs quite well on this task. Critically, we provide generated examples. We also include feedback from professional composers and musicians about some of these examples.																	0941-0643	1433-3058				FEB	2020	32	4			SI		955	967		10.1007/s00521-018-3758-9													
J								Towards a Deep Improviser: a prototype deep learning post-tonal free music generator	NEURAL COMPUTING & APPLICATIONS										Deep learning; Music; Post-tonal; Post-metrical; Improvisation	ALGORITHMIC COMPOSITION; SEGMENTATION; EXPECTATION; CONTEXT	Two modest-sized symbolic corpora of post-tonal and post-metrical keyboard music have been constructed: one algorithmic and the other improvised. Deep learning models of each have been trained. The purpose was to obtain models with sufficient generalisation capacity that in response to separate fresh input seed material, they can generate outputs that are statistically distinctive, neither random nor recreative of the learned corpora or the seed material. This objective has been achieved, as judged by k-sample Anderson-Darling and Cramer tests. Music has been generated using the approach, and preliminary informal judgements place it roughly on a par with an example of composed music in a related form. Future work will aim to enhance the model such that it deserves to be fully evaluated in relation to expression, meaning and utility in real-time performance.																	0941-0643	1433-3058				FEB	2020	32	4			SI		969	979		10.1007/s00521-018-3765-x													
J								Deep learning for music generation: challenges and directions	NEURAL COMPUTING & APPLICATIONS										Deep learning; Music; Generation; Challenges; Directions; Control; Structure; Creativity; Interactivity		In addition to traditional tasks such as prediction, classification and translation, deep learning is receiving growing attention as an approach for music generation, as witnessed by recent research groups such as Magenta at Google and CTRL (Creator Technology Research Lab) at Spotify. The motivation is in using the capacity of deep learning architectures and training techniques to automatically learn musical styles from arbitrary musical corpora and then to generate samples from the estimated distribution. However, a direct application of deep learning to generate content rapidly reaches limits as the generated content tends to mimic the training set without exhibiting true creativity. Moreover, deep learning architectures do not offer direct ways for controlling generation (e.g., imposing some tonality or other arbitrary constraints). Furthermore, deep learning architectures alone are autistic automata which generate music autonomously without human user interaction, far from the objective of interactively assisting musicians to compose and refine music. Issues such as control, structure, creativity and interactivity are the focus of our analysis. In this paper, we select some limitations of a direct application of deep learning to music generation and analyze why the issues are not fulfilled and how to address them by possible approaches. Various examples of recent systems are cited as examples of promising directions.																	0941-0643	1433-3058				FEB	2020	32	4			SI		981	993		10.1007/s00521-018-3813-6													
J								Anticipation-RNN: enforcing unary constraints in sequence generation, with application to interactive music generation	NEURAL COMPUTING & APPLICATIONS										Automatic symbolic music generation; Recurrent neural networks; Interactive models; Unary constraints		Recurrent neural networks (RNNs) are now widely used on sequence generation tasks due to their ability to learn long-range dependencies and to generate sequences of arbitrary length. However, their left-to-right generation procedure only allows a limited control from a potential user which makes them unsuitable for interactive and creative usages such as interactive music generation. This article introduces a novel architecture called anticipation-RNN which possesses the assets of the RNN-based generative models while allowing to enforce user-defined unary constraints. We demonstrate its efficiency on the task of generating melodies satisfying unary constraints in the style of the soprano parts of the J.S. Bach chorale harmonizations. Sampling using the anticipation-RNN is of the same order of complexity than sampling from the traditional RNN model. This fast and interactive generation of musical sequences opens ways to devise real-time systems that could be used for creative purposes.																	0941-0643	1433-3058				FEB	2020	32	4			SI		995	1005		10.1007/s00521-018-3868-4													
J								Understanding auditory representations of emotional expressions with neural networks	NEURAL COMPUTING & APPLICATIONS										Auditory emotion categorization; Affect analysis; Dimensional emotions; Deep neural network	RECOGNITION	In contrast to many established emotion recognition systems, convolutional neural networks do not rely on handcrafted features to categorize emotions. Although achieving state-of-the-art performances, it is still not fully understood what these networks learn and how the learned representations correlate with the emotional characteristics of speech. The aim of this work is to contribute to a deeper understanding of the acoustic and prosodic features that are relevant for the perception of emotional states. Firstly, an artificial deep neural network architecture is proposed that learns the auditory features directly from the raw and unprocessed speech signal. Secondly, we introduce two novel methods for the analysis of the implicitly learned representations based on data-driven and network-driven visualization techniques. Using these methods, we identify how the network categorizes an audio signal as a two-dimensional representation of emotions, namely valence and arousal. The proposed approach is a general method to enable a deeper analysis and understanding of the most relevant representations to perceive emotional expressions in speech.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1007	1022		10.1007/s00521-018-3869-3													
J								From context to concept: exploring semantic relationships in music with word2vec	NEURAL COMPUTING & APPLICATIONS										Word2vec; Music; Semantic vector space model	FORMAL THEORY; LANGUAGE; EXPECTATION; SEQUENCES; MODELS	We explore the potential of a popular distributional semantics vector space model, word2vec, for capturing meaningful relationships in ecological (complex polyphonic) music. More precisely, the skip-gram version of word2vec is used to model slices of music from a large corpus spanning eight musical genres. In this newly learned vector space, a metric based on cosine distance is able to distinguish between functional chord relationships, as well as harmonic associations in the music. Evidence, based on cosine distance between chord-pair vectors, suggests that an implicit circle-of-fifths exists in the vector space. In addition, a comparison between pieces in different keys reveals that key relationships are represented in word2vec space. These results suggest that the newly learned embedded vector representation does in fact capture tonal and harmonic characteristics of music, without receiving explicit information about the musical content of the constituent slices. In order to investigate whether proximity in the discovered space of embeddings is indicative of 'semantically-related' slices, we explore a music generation task, by automatically replacing existing slices from a given piece of music with new slices. We propose an algorithm to find substitute slices based on spatial proximity and the pitch class distribution inferred in the chosen subspace. The results indicate that the size of the subspace used has a significant effect on whether slices belonging to the same key are selected. In sum, the proposed word2vec model is able to learn music-vector embeddings that capture meaningful tonal and harmonic relationships in music, thereby providing a useful tool for exploring musical properties and comparisons across pieces, as a potential input representation for deep learning models, and as a music generation device.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1023	1036		10.1007/s00521-018-3923-1													
J								Singing voice separation using a deep convolutional neural network trained by ideal binary mask and cross entropy	NEURAL COMPUTING & APPLICATIONS										Singing voice separation; Convolutional neural network; Ideal binary mask; Cross entropy; Pixel-wise image classification	NONNEGATIVE MATRIX FACTORIZATION; INFORMATION; CONTINUITY; ROBUST	Separating a singing voice from its music accompaniment remains an important challenge in the field of music information retrieval. We present a unique neural network approach inspired by a technique that has revolutionized the field of vision: pixel-wise image classification, which we combine with cross entropy loss and pretraining of the CNN as an autoencoder on singing voice spectrograms. The pixel-wise classification technique directly estimates the sound source label for each time-frequency (T-F) bin in our spectrogram image, thus eliminating common pre- and postprocessing tasks. The proposed network is trained by using the Ideal Binary Mask (IBM) as the target output label. The IBM identifies the dominant sound source in each T-F bin of the magnitude spectrogram of a mixture signal, by considering each T-F bin as a pixel with a multi-label (for each sound source). Cross entropy is used as the training objective, so as to minimize the average probability error between the target and predicted label for each pixel. By treating the singing voice separation problem as a pixel-wise classification task, we additionally eliminate one of the commonly used, yet not easy to comprehend, postprocessing steps: the Wiener filter postprocessing. The proposed CNN outperforms the first runner up in the Music Information Retrieval Evaluation eXchange (MIREX) 2016 and the winner of MIREX 2014 with a gain of 2.2702-5.9563 dB global normalized source to distortion ratio when applied to the iKala dataset. An experiment with the DSD100 dataset on the full-tracks song evaluation task also shows that our model is able to compete with cutting-edge singing voice separation systems which use multi-channel modeling, data augmentation, and model blending.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1037	1050		10.1007/s00521-018-3933-z													
J								Applying visual domain style transfer and texture synthesis techniques to audio: insights and challenges	NEURAL COMPUTING & APPLICATIONS										Style transfer; Texture synthesis; Sound modelling; Convolutional neural networks		Style transfer is a technique for combining two images based on the activations and feature statistics in a deep learning neural network architecture. This paper studies the analogous task in the audio domain and takes a critical look at the problems that arise when adapting the original vision-based framework to handle spectrogram representations. We conclude that CNN architectures with features based on 2D representations and convolutions are better suited for visual images than for time-frequency representations of audio. Despite the awkward fit, experiments show that the Gram matrix determined "style" for audio is more closely aligned with timbral signatures without temporal structure, whereas network layer activity determining audio "content" seems to capture more of the pitch and rhythmic structures. We shed insight on several reasons for the domain differences with illustrative examples. We motivate the use of several types of one-dimensional CNNs that generate results that are better aligned with intuitive notions of audio texture than those based on existing architectures built for images. These ideas also prompt an exploration of audio texture synthesis with architectural variants for extensions to infinite textures, multi-textures, parametric control of receptive fields and the constant-Q transform as an alternative frequency scaling for the spectrogram.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1051	1065		10.1007/s00521-019-04053-8													
J								One deep music representation to rule them all? A comparative analysis of different representation learning strategies	NEURAL COMPUTING & APPLICATIONS										Representation learning; Music Information Retrieval; Multitask learning		Inspired by the success of deploying deep learning in the fields of Computer Vision and Natural Language Processing, this learning paradigm has also found its way into the field of Music Information Retrieval. In order to benefit from deep learning in an effective, but also efficient manner, deep transfer learning has become a common approach. In this approach, it is possible to reuse the output of a pre-trained neural network as the basis for a new learning task. The underlying hypothesis is that if the initial and new learning tasks show commonalities and are applied to the same type of input data (e.g., music audio), the generated deep representation of the data is also informative for the new task. Since, however, most of the networks used to generate deep representations are trained using a single initial learning source, their representation is unlikely to be informative for all possible future tasks. In this paper, we present the results of our investigation of what are the most important factors to generate deep representations for the data and learning tasks in the music domain. We conducted this investigation via an extensive empirical study that involves multiple learning sources, as well as multiple deep learning architectures with varying levels of information sharing between sources, in order to learn music representations. We then validate these representations considering multiple target datasets for evaluation. The results of our experiments yield several insights into how to approach the design of methods for learning widely deployable deep data representations in the music domain.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1067	1093		10.1007/s00521-019-04076-1													
J								Exploiting time-frequency patterns with LSTM-RNNs for low-bitrate audio restoration	NEURAL COMPUTING & APPLICATIONS										Audio restoration; LSTM; MP3; Deep learning	BANDWIDTH EXTENSION; TELEPHONE SPEECH	Perceptual audio coding is heavily and successfully applied for audio compression. However, perceptual audio coders may inject audible coding artifacts when encoding audio at low bitrates. Low-bitrate audio restoration is a challenging problem, which tries to recover a high-quality audio sample close to the uncompressed original from a low-quality encoded version. In this paper, we propose a novel data-driven method for audio restoration, where temporal and spectral dynamics are explicitly captured by a deep time-frequency-LSTM recurrent neural networks. Leveraging the captured temporal and spectral information can facilitate the task of learning a nonlinear mapping from the magnitude spectrogram of low-quality audio to that of high-quality audio. The proposed method substantially attenuates audible artifacts caused by codecs and is conceptually straightforward. Extensive experiments were carried out and the experimental results show that for low-bitrate audio at 96 kbps (mono), 64 kbps (mono), and 96 kbps (stereo), the proposed method can efficiently generate improved-quality audio that is competitive or even superior in perceptual quality to the audio produced by other state-of-the-art deep neural network methods and the LAME-MP3 codec.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1095	1107		10.1007/s00521-019-04158-0													
J								A disaster relief operations management model: a hybrid LP-GA approach	NEURAL COMPUTING & APPLICATIONS										Relief logistics; LP-metric; Robust optimization; Genetic algorithm	ROBUST OPTIMIZATION MODEL; GENETIC ALGORITHM; LOGISTICS; LOCATION	People are always threatened by natural disasters which usually cause significant losses. Therefore, planning for confronting such situations is a vast dilemma. In this paper, a general model is proposed to address the uncertain demand of disaster-stricken areas. Demand from injured people relates to the vulnerability of regions that depends on the quality of buildings and severity of damage. In the studied problem, the commodities collected from relief centers, donations and storage warehouses are distributed to the shelters. It aims at minimizing the total cost, and unfulfilled demand and maximizing the coverage and accessibility of relief centers. The LP-metric approach is utilized to solve the multi-objective model, and a scenario-based optimization is used to incorporate the uncertainty in the proposed model. Moreover, an LP-GA method is proposed for optimizing large-scale instances. Several problems in different scales are solved to show its flexibility and time-efficiency. Finally, a case study of an earthquake disaster in Amol city in Iran is presented. The obtained results suggest better service in the distressed urban areas.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1173	1194		10.1007/s00521-018-3762-0													
J								A possibilistic closed-loop supply chain: pricing, advertising and remanufacturing optimization	NEURAL COMPUTING & APPLICATIONS										Closed-loop supply chain; Pricing; Advertising; Stackelberg game; Fuzzy theory	CHANNEL; COORDINATION; COMPETITION; INVENTORY; PERFORMANCE; SELECTION; PRODUCTS	This paper addresses pricing and reverse channel selection decisions in a closed-loop supply chain (CLSC) under fuzziness of demand function's parameters. Despite numerous studies in which the demand is sensitive to selling price, in this paper demand function is considered as a function of both selling price and advertising level. Decisions are made in a CLSC consisting of a manufacturer, a retailer and a third party under centralized and decentralized decision making structures. In the decentralized structure, three different models are examined which differ on the member who collects used products from customers. Collection process is conducted by the manufacturer, the retailer or the third party. The problem is formulated as a Stackelberg game model in which the manufacturer acts as a leader. Moreover, various collection structures are deeply studied through a numerical analysis in which a real case study is provided and useful managerial insights are presented based on numerical results. The results show that the centralized structure outperforms the decentralized one in achieving the highest total expected profit, attaining highest demand by setting lowest selling price, and also by considering the environmental viewpoint and resource usage (achieving highest collection rate). Finally, sensitivity analysis on triangular fuzzy parameters is conducted to examine impact of triangular fuzzy parameters on model's outputs.																	0941-0643	1433-3058				FEB	2020	32	4			SI		1195	1215		10.1007/s00521-018-3646-3													
J								Using Well-Founded Relations for Proving Operational Termination	JOURNAL OF AUTOMATED REASONING										Declarative languages; Logical models; Operational termination; Program analysis; Well-foundedness	LOGICAL MODELS; DEPENDENCY	In this paper, we study operational termination, a proof theoretical notion for capturing the termination behavior of computational systems. We prove that operational termination can be characterized at different levels by means of well-founded relations on specific formulas which can be obtained from the considered system. We show how to obtain such well-founded relations from logical models which can be automatically generated using existing tools.																	0168-7433	1573-0670				FEB	2020	64	2					167	195		10.1007/s10817-019-09514-2													
J								Blocking and Other Enhancements for Bottom-Up Model Generation Methods	JOURNAL OF AUTOMATED REASONING										Automated reasoning; Model generation; Blocking; First-order logic; Bernays-Schonfinkel class	DESCRIPTION LOGICS; SYSTEM DESCRIPTION; HYPER TABLEAUX; FINITE-MODELS; MODAL-LOGICS; THEOREM; HYPERRESOLUTION; DEDUCTION; CALCULUS; PROVER	Model generation is a problem complementary to theorem proving and is important for fault analysis and debugging of formal specifications of security protocols, programs and terminological definitions, for example. This paper discusses several ways of enhancing the paradigm of bottom-up model generation, with the two main contributions being a new range-restriction transformation and generalized blocking techniques. The range-restriction transformation refines existing transformations to range-restricted clauses by carefully limiting the creation of domain terms. The blocking techniques are based on simple transformations of the input set together with standard equality reasoning and redundancy elimination techniques, and allow for finding small, finite models. All possible combinations of the introduced techniques and a classical range-restriction technique were tested on the clausal problems of the TPTP Version 6.0.0 with an implementation based on the SPASS theorem prover using a hyperresolution-like refinement. Unrestricted domain blocking gave best results for satisfiable problems, showing that it is an indispensable technique for bottom-up model generation methods, that yields good results in combination with both new and classical range-restricting transformations. Limiting the creation of terms during the inference process by using the new range-restricting transformation has paid off, especially when using it together with a shifting transformation. The experimental results also show that classical range restriction with unrestricted blocking provides a useful complementary method. Overall, the results show bottom-up model generation methods are good for disproving theorems and generating models for satisfiable problems, but less efficient for unsatisfiable problems.																	0168-7433	1573-0670				FEB	2020	64	2					197	251		10.1007/s10817-019-09515-1													
J								Combining Induction and Saturation-Based Theorem Proving	JOURNAL OF AUTOMATED REASONING										Inductive theorem proving; Saturation-based theorem proving; Inductive lemma generation		A method is devised to integrate reasoning by mathematical induction into saturation-based proof procedures based on resolution or superposition. The obtained calculi are capable of handling formulas in which some of the quantified variables range over inductively defined domains (which, as is well-known, cannot be expressed in first-order logic). The procedure is defined as a set of inference rules that generate inductive invariants incrementally and prove their validity. Although the considered logic itself is incomplete, it is shown that the invariant generation rules are complete, in the sense that if an invariant (of some specific form) is deducible from the considered clauses, then it is eventually generated.																	0168-7433	1573-0670				FEB	2020	64	2					253	294		10.1007/s10817-019-09519-x													
J								Solving Quantifier-Free First-Order Constraints Over Finite Sets and Binary Relations	JOURNAL OF AUTOMATED REASONING										Set constraints; Binary relations; Set relation algebra; Satisfiability solver; {log}; Automated theorem proving	LOGIC; CALCULUS	In this paper we present a solver for a first-order logic language where sets and binary relations can be freely and naturally combined. The language can express, at least, any full set relation algebra on finite sets. It provides untyped, hereditarily finite sets, whose elements can be variables, and basically all the classic set and relational operators used in formal languages such as B and Z. Sets are first-class entities in the language, thus they are not encoded in lower level theories. Relations are just sets of ordered pairs. The solver exploits set unification and set constraint solving as primitive features. The solver is proved to be a sound semi-decision procedure for the accepted language. A Prolog implementation is presented and an extensive empirical evaluation provides evidence of its usefulness.																	0168-7433	1573-0670				FEB	2020	64	2					295	330		10.1007/s10817-019-09520-4													
J								Evaluating Winding Numbers and Counting Complex Roots Through Cauchy Indices in Isabelle/HOL	JOURNAL OF AUTOMATED REASONING										Interactive theorem proving; Isabelle; HOL; Computer algebra; Cauchy index; Winding number; Root counting; The Routh-Hurwitz stability criterion	PROOF	In complex analysis, the winding number measures the number of times a path (counter-clockwise) winds around a point, while the Cauchy index can approximate how the path winds. We formalise this approximation in the Isabelle theorem prover, and provide a tactic to evaluate winding numbers through Cauchy indices. By further combining this approximation with the argument principle, we are able to make use of remainder sequences to effectively count the number of complex roots of a polynomial within some domains, such as a rectangular box and a half-plane.																	0168-7433	1573-0670				FEB	2020	64	2					331	360		10.1007/s10817-019-09521-3													
J								SO-CovSel: A novel method for variable selection in a multiblock framework	JOURNAL OF CHEMOMETRICS										classification; covariance selection (CovSel); multiblock; sequential and orthogonalized partial least-squares (SO-PLS); variable selection	PLS; REGRESSION	With the development of technology and the relatively higher availability of new instrumentations, having multiblock data sets (eg, a set of samples analyzed by different analytical techniques) is becoming more and more common and, as a consequence, how to handle this kind of outcomes is a widely discussed topic. In such a context, where the number of involved variables is relatively high, selecting the most significant features is obviously relevant. For this reason, the possibility of joining a multiblock regression method, the sequential and orthogonalized partial least-squares (SO-PLS), with a variable selection approach called covariance selection (CovSel), has been investigated. The resulting method, sequential and orthogonalized covariance selection (SO-CovSel) is similar to SO-PLS, but the feature reduction provided by PLS is performed by CovSel. Finally, predictions are made by applying multiple linear regression on the subset of selected variables. The novel approach has been tested on different multiblock data sets both in regression and in classification (by combination with LDA), and it has been compared with another state-of-the-art multiblock method. SO-CovSel has demonstrated to be suitable for its purpose: It has provided good predictions (both in regression and in classification) and, from the interpretation point of view, it has led to a meaningful selection of the original variables.																	0886-9383	1099-128X				FEB	2020	34	2			SI				e3120	10.1002/cem.3120													
J								Four-dimensional quantitative structure-activity analysis of 1,4-naphthoquinone derivatives tested against HL-60 human promyelocytic leukemia cells	JOURNAL OF CHEMOMETRICS										4D-QSAR; cancer; field descriptors; molecular dynamics; quinones	TRYPANOTHIONE REDUCTASE; 4D-QSAR ANALYSIS; LQTA-QSAR; MODELS; PACKAGE; DESIGN	Four-dimensional quantitative structure-activity relationship (4D-QSAR) models were developed to predict biological activity of 1,4-naphthoquinones derivatives tested against human HL-60 leukemic cells, in order to better investigate the action mode of these compounds. Quinones can generate reactive oxygen species (ROS) through the activation by the cytochrome P450 and P450 reductase enzymes acting as anticancer agents. Molecular dynamics (MD) simulations were performed in the 3D optimized geometries, and the field descriptors were calculated. Partial least squares (PLS) regression method was applied to build the QSAR model, which presented the following statistics, with two factors and explaining 51.11% of total variance: R-2 = 0.83; SEC = 0.28; Q(2) = 0.77; SEV = 0.31. For external validation, the results were R-pred(2) = 0.76 and SEP = 0.30. Among the nine Coulomb (C) and Lennard-Jones (LJ) descriptors selected by the model, one of them, C13838, is located close to quinone oxygens involved in the production of radical anions (O-2(-center dot)) and to hydroxyl in position 5 that may stabilize catalytically important water molecules. The negative LJ descriptors around R-1 and R-2 substituents might indicate that apolar substituents in these regions are unfavorable to the activity. Coulomb descriptors located at the vicinities of the substituent R-2 gave information about the bioactive conformation.																	0886-9383	1099-128X				FEB	2020	34	2			SI				e3131	10.1002/cem.3131													
J								Online discrimination of chemical substances using standoff laser-induced fluorescence signals	JOURNAL OF CHEMOMETRICS										chemical agents; classification algorithms; laser-induced fluorescence; machine learning; standoff detection		Chemical contamination of objects and surfaces, caused by accident or on purpose, is a common security issue. Immediate countermeasures depend on the class of risk and consequently on the characteristics of the substances. Laser-based standoff detection techniques can help to provide information about the thread without direct contact of humans to the hazardous materials. This article explains a data acquisition and classification procedure for laser-induced fluorescence spectra of several chemical agents. The substances are excited from a distance of 3.5 m by laser pulses of two UV wavelengths (266 and 355 nm) with less than 0.1 mJ per laser pulse and a repetition rate of 100 Hz. Each pair of simultaneously emitted laser pulses is separated using an optical delay line. Every measurement consists of a dataset of 100 spectra per wavelength containing the signal intensities in the spectral range from 250 to 680 nm, recorded by a 32-channel photo multiplying tube array. Based on this dataset, three classification algorithms are trained which can distinguish the samples by their single spectra with an accuracy of over 98%. These predictive models, generated with decision trees, support vector machines, and neural networks, can identify all agents (eg, benzaldehyde, isoproturon, and piperine) within the current set of substances.																	0886-9383	1099-128X				FEB	2020	34	2			SI				e3121	10.1002/cem.3121													
J								Spatial-spectral analysis method using texture features combined with PCA for information extraction in hyperspectral images	JOURNAL OF CHEMOMETRICS										classification; hyperspectral image; PCA; spatial; spectral integration; texture analysis	CLASSIFICATION; SEMIVARIOGRAM; RESOLUTION	This work proposes a new method to treat spatial and spectral information interactively. The method extracts spatial features, ie, variogram, gray-level co-occurrence matrix (GLCM), histograms of oriented gradients (HOG), and local binary pattern (LBP) features, from each wavelength image of hypercube and principal component analysis (PCA) is applied on this spatial feature matrix to identify wavelength-dependent variation in spatial patterns. Resultant image is obtained by projecting the score values to the original data. Three datasets, including a synthetic hyperspectral image (Dataset 1), a set of real hyperspectral images of salmon fillets (Dataset 2), and remote-sensing images (Dataset 3), were utilized to evaluate the performance of the proposed method. Results from Dataset 1 showed that the spatial-spectral methods had the potential of reducing baseline offset noise. Dataset 2 revealed that spatial-spectral methods can alleviate noisy pixels with strong signal and reduce shadow effects. In addition, substantial improvements were obtained in case of classification between white stripe and red muscle pixels by using the HOG-based approach with correct classification rate (CCR) of 0.97 compared with the models directly built from raw and standard normal variate (SNV) preprocessed spectra (CCR = 0.94). Samson image of Dataset 3 suggested the flexibility and effectiveness of the proposed method by improving CCR of 0.96 using conventional PCA on SNV pretreated spectra to 0.98 using GLCM-based approach on SNV preprocessed spectra. Overall, experimental results demonstrated that the spatial-spectral methods can improve the results found by using the spectral information alone because of the spatial information provided.																	0886-9383	1099-128X				FEB	2020	34	2			SI				e3132	10.1002/cem.3132													
J								DCADE: divide and conquer alignment with dynamic encoding for full page data extraction	APPLIED INTELLIGENCE										Deep web data extraction; Divide-conquer alignment; Dynamic encoding; Full-schema induction; Multiple template pages	WEB DATA EXTRACTION; INFORMATION EXTRACTION	In this paper, we consider the problem of full schema induction from either multiple list pages or singleton pages with the same template. Existing approaches do not work well for this problem because they use fixed abstraction schemes that are suitable for data-rich detection, but they are not appropriate for small records and complex data found in other sections. We propose an unsupervised full schema web data extraction via Divide-and-Conquer Alignment with Dynamic Encoding (DCADE for short). We define the Content Equivalence Class (CEC) and Typeset Equivalence Class (TEC) based on leaf node content. We then combine HTML attributes (i.e., id and class) in the paths for various levels of encoding, so that the proposed algorithm can align leaf nodes by exploring patterns at various levels from specific to general. We conducted experiments on 49 real-world websites used in TEX and ExAlg. The proposed DCADE achieved a 0.962 F1 measure for non-recordset data extraction (denoted by F-D), and a 0.936 F1 measure for recordset data extraction (denoted by F-S), which outperformed other page-level web data extraction methods, i.e., DCA (F-D= 0.660), TEX (F-D= 0.454 and F-S= 0.549), RoadRunner (F-D= 0.396 and F-S= 0.330), and UWIDE (F-D= 0.260 and F-S= 0.081).																	0924-669X	1573-7497				FEB	2020	50	2					271	295		10.1007/s10489-019-01499-0													
J								Robust expected model change for active learning in regression	APPLIED INTELLIGENCE										Active learning; Expected model change maximization; Local outlier probability; Stochastic gradient descent	QUERY	Active learning methods have been introduced to reduce the expense of acquiring labeled data. To solve regression problems with active learning, several expected model change maximization strategies have been developed to select the samples that are likely to greatly affect the current model. However, some of the selected samples may be outliers, which can result in poor estimation performance. To address this limitation, this study proposes an active learning framework that adopts an expected model change that is robust for both linear and nonlinear regression problems. By embedding local outlier probability, the learning framework aims to avoid outliers when selecting the samples that result in the greatest change to the current model. Experiments are conducted on synthetic and benchmark data to compare the performance of the proposed method with that of existing methods. The experimental results demonstrate that the proposed active learning algorithm outperforms its counterparts.																	0924-669X	1573-7497				FEB	2020	50	2					296	313		10.1007/s10489-019-01519-z													
J								Learning adaptive trust strength with user roles of truster and trustee for trust-aware recommender systems	APPLIED INTELLIGENCE										Recommender system; Trust relationships; Trust strength; Matrix factorization; User similarities	SELECTIVE UNDO; SOCIAL MEDIA; ALGORITHM; TRACKING; MODEL	There are two key characteristics of users in trust relationships that have been well studied: (1) users trust their friends with different trust strengths and (2) users play multiple roles of trusters and trustees in trust relationships. However, few studies have considered both of these factors. Indeed, it is quite common for someone to respond to his/her friend that they trusted him/her, which indicates that there exist two kinds of information between each pair of users: the trust influence of trustee on truster and the feedback influence of truster on trustee. Considering this problem, we propose a novel adaptive method to learn the trust influence between users with multiple roles of truster and trustee for recommendation. First, we propose to introduce the concept of latent trust strength to learn adaptive role-based trust strength with limited values for each trust relationship between users. Second, because there is only one training example to learn each parameter of latent trust strength, we further propose two regularization methods by building relations between latent trust strength and user preferences to guide the training process of latent trust strength. After that, we develop a new recommendation method, RoleTS, by integrating the role-based trust strength into a previous recommendation model, TrustSVD, which considers both explicit and implicit information of trust and ratings. We also conduct a series of experiments to study the performance of the proposed method. Experimental results on two public real datasets demonstrate that the proposed method performs better than several state-of-the-art algorithms.																	0924-669X	1573-7497				FEB	2020	50	2					314	327		10.1007/s10489-019-01542-0													
J								A local community detection algorithm based on internal force between nodes	APPLIED INTELLIGENCE										Complex network; Local community detection; Seed-extension algorithm; Internal force	COMPLEX NETWORKS; MODEL	Community structure is an important characteristic of complex networks. Uncovering communities in complex networks is currently a hot research topic in the field of network analysis. Local community detection algorithms based on seed-extension are widely used for addressing this problem because they excel in efficiency and effectiveness. Compared with global community detection methods, local methods can uncover communities without the integral structural information of complex networks. However, they still have quality and stability deficiencies in overlapping community detection. For this reason, a local community detection algorithm based on internal force between nodes is proposed. First, local degree central nodes and Jaccard coefficient are used to detect core members of communities as seeds in the network, thus guaranteeing that the selected seeds are central nodes of communities. Second, the node with maximum degree among seeds is pre-extended by the fitness function every time. Finally, the top k nodes with the best performance in pre-extension process are extended by the fitness function with internal force between nodes to obtain high-quality communities in the network. Experimental results on both real and artificial networks show that the proposed algorithm can uncover communities more accurately than all the comparison algorithms.																	0924-669X	1573-7497				FEB	2020	50	2					328	340		10.1007/s10489-019-01541-1													
J								Using deep learning to preserve data confidentiality	APPLIED INTELLIGENCE										Data confidentiality; Generative model; Statistical evaluation metric	SIMULATION	Preserving data confidentiality is crucial when releasing microdata for public-use. There are a variety of proposed approaches; many of them are based on traditional probability theory and statistics. These approaches mainly focus on masking the original data. In practice, these masking techniques, despite covering part of the data, risk leaving sensitive data open to release. In this paper, we approach this problem using a deep learning-based generative model which generates simulation data to mask the original data. Generating simulation data that holds the same statistical characteristics as the raw data becomes the key idea and also the main challenge in this study. In particular, we explore the statistical similarities between the raw data and the generated data, given that the generated data and raw data are not obviously distinguishable. Two statistical evaluation metrics, Absolute Relative Residual Values and Hellinger Distance, are the evaluation methods we have decided upon to evaluate our results. We also conduct extensive experiments to validate our idea with two real-world datasets: the Census Dataset and the Environmental Dataset.																	0924-669X	1573-7497				FEB	2020	50	2					341	353		10.1007/s10489-019-01515-3													
J								Community-based influence maximization in attributed networks	APPLIED INTELLIGENCE										Attributed networks; Influence maximization; Influence strength; Community detection		Influence Maximization, aiming at selecting a small set of seed users in a social network to maximize the spread of influence, has attracted considerable attention recently. Most existing influence maximization algorithms focus on pure networks, while in many real-world social networks, nodes are often associated with a rich set of attributes or features, aka attributed networks. Moreover, most of existing influence maximization methods suffer from the problems of high computational cost and no performance guarantee, as these methods heavily depend on analysis and exploitation of network structure. In this paper, we propose a new algorithm to solve community-based influence maximization problem in attributed networks, which consists of three steps: community detection, candidate community generation and seed node selection. Specifically, we first propose the candidate community generation process, which utilizes information of community structure as well as node attribute to narrow down possible community candidates. We then propose a model to predict influence strength between nodes in attributed network, which takes advantage of topology structure similarity and attribute similarity between nodes in addition to social interaction strength, thus improve the prediction accuracy comparing to the existing methods significantly. Finally, we select seed nodes by proposing the computation method of influence set, through which the marginal influence gain of nodes can be calculated directly, avoiding tens of thousands of Monte Carlo simulations and ultimately making the algorithm more efficient. Experiments on four real social network datasets demonstrate that our proposed algorithm outperforms state-of-the-art influence maximization algorithms in both influence spread and running time.																	0924-669X	1573-7497				FEB	2020	50	2					354	364		10.1007/s10489-019-01529-x													
J								Plan merging by reuse for multi-agent planning	APPLIED INTELLIGENCE										Multi-agent planning; Plan reuse; Automated planning; Centralized planning; Distributed planning	COMPLEXITY; GENERATION; SYSTEM	Multi-Agent Planning deals with the task of generating a plan for/by a set of agents that jointly solve a planning problem. One of the biggest challenges is how to handle interactions arising from agents' actions. The first contribution of the paper is Plan Merging by Reuse, pmr, an algorithm that automatically adjusts its behaviour to the level of interaction. Given a multi-agent planning task, pmr assigns goals to specific agents. The chosen agents solve their individual planning tasks and the resulting plans are merged. Since merged plans are not always valid, pmr performs planning by reuse to generate a valid plan. The second contribution of the paper is rrpt-plan, a stochastic plan-reuse planner that combines plan reuse, standard search and sampling. We have performed extensive sets of experiments in order to analyze the performance of pmr in relation to state of the art multi-agent planning techniques.																	0924-669X	1573-7497				FEB	2020	50	2					365	396		10.1007/s10489-019-01429-0													
J								A novel method based on deep learning for aligned fingerprints matching	APPLIED INTELLIGENCE										Fingerprint matching; Deep learning; Finger ConvNet; Fast matching method	SINGULAR POINTS; NEURAL-NETWORKS; ALGORITHM	In this study, a novel method based on deep learning for aligned fingerprints matching is proposed. According to the characteristics of fingerprint images, a convolutional network, Finger ConvNet, is designed. In addition, a new joint supervision signal is used to train Finger ConvNet to obtain deep features. Experimental studies are performed on public fingerprint datasets, the ID Card fingerprint dataset and the Ten-Finger Fingerprint Card fingerprint dataset. Furthermore, four performance indicators, the false matching rate (FMR), false non-matching rate (FNMR), equal error rate (EER) and receiver operating characteristic (ROC) curve, are measured. The experimental results demonstrate the effectiveness of the proposed method, which achieved a competitive effect in comparison with conventional fingerprint matching algorithms in fingerprint verification tasks using the FVC2000, FVC2002, and FVC2004 datasets. Moreover, the matching speed of the proposed method was almost 5 times faster than the fastest conventional fingerprint matching algorithms. In addition, it can be used as a fast matching method to filter out many templates with low scores by setting a threshold according to the matching scores and thus accelerate the process in identification tasks.																	0924-669X	1573-7497				FEB	2020	50	2					397	416		10.1007/s10489-019-01530-4													
J								An algorithm for influence maximization in competitive social networks with unwanted users	APPLIED INTELLIGENCE										Influence maximization; Independent Cascade model; Unwanted users	POSITIVE INFLUENCE; DIFFUSION; MODELS	With the rapid development of online social networks, the problem of influence maximization (IM) has attracted tremendous attention motivated by widespread application scenarios. However, there is less research focusing on the information spreading with the existence of some unwanted users. Such problem has a wide range of applications since there always exist conflicts of interest between competing businesses. In this paper, we formally define the problem of influence maximization with limited unwanted users (IML) under the independent cascade model. In order to avoid the time-consuming process of simulating the propagation in the traditional method of influence maximization, we propose a propagation path based strategy to compute the activation probabilities between the node pairs. Based on the activation probability, we define a propagation increment function to avoid simulating the influence spreading process on the candidate seed nodes. To select the optimal seed set, we present a greedy algorithm to sequentially select the nodes which can maximize the influence increment to join the seed set. Experimental results in real social networks have shown that the algorithm proposed not only outperforms the existing methods but also consumes much less computation time.																	0924-669X	1573-7497				FEB	2020	50	2					417	437		10.1007/s10489-019-01506-4													
J								Adaptive graph regularized nonnegative matrix factorization for data representation	APPLIED INTELLIGENCE										Nonnegative matrix factorization; Graph regularization; Manifold learning; Image clustering	FEATURE-SELECTION; PROJECTION	As a classical data representation method, nonnegative matrix factorization (NMF) can well capture the global structure information of the observed data, and it has been successfully applied in many fields. It is generally known that the local manifold structures will have a better effect than the global structures in image recognition and clustering. The local structure information can well be preserved by the neighbor graph in the manifold learning methods. The traditional neighbor graph constructed relies heavily on the original observed data. However, the original data usually contain a lot of noise and outliers in practical application, which results in obtaining inaccurate neighbor graph, and ultimately leads to performance degradation. How to get the ideal local structure information becomes more and more important. By combing the manifold learning into NMF, we propose an adaptive graph regularized nonnegative matrix factorization (AGNMF). In AGNMF, the neighbor graph is obtained by adaptive iteration. Both the global information and the local manifold can be well captured in AGNMF, and the better data representation can be obtained. A large number of experiments on different data sets show that our AGNMF has good clustering ability.																	0924-669X	1573-7497				FEB	2020	50	2					438	447		10.1007/s10489-019-01539-9													
J								Extracting relations of crime rates through fuzzy association rules mining	APPLIED INTELLIGENCE										Crime data mining; Crime rate; Fuzzy association rule; fp-growth	MEMBERSHIP FUNCTIONS; FRAMEWORK; IMPACT; MODEL	Data mining is an important technology to reveal the patterns from crime data. Although there are many researches about this topic, less work models the relations between rates of different kinds of crime. In this paper, an algorithm based on fuzzy association rules (AR) mining is proposed to discover these relations. Two datasets, which are crimes in Chicago from 2012 to 2017 and crimes in NSW from 2008 to 2012, are used for case studies. At first, crime data is preprocessed, where every kind of crime occurring in every district during every month is counted. For a crime in a combination of district and month, the membership function, which is based on hypothesis testing, is designed to evaluate the degree to which its rate is high, normal or low, and the fuzzy transactional dataset is formed. A bridge between fuzzy transactional dataset and binary AR mining algorithm is built, so those mature tools of binary AR mining can be applied to generate fuzzy ARs. In the results of case studies, the strong relations between rates of different crime can be found. There are many interesting and surprise rules, which are worthy to be further studied by domain experts.																	0924-669X	1573-7497				FEB	2020	50	2					448	467		10.1007/s10489-019-01531-3													
J								Novel grey wolf optimization based on modified differential evolution for numerical function optimization	APPLIED INTELLIGENCE										Grey wolf optimization algorithm; Global optimization; Opposition-based learning; Leader moving-rate strategy; Benchmark functions	ARTIFICIAL BEE COLONY; GLOBAL OPTIMIZATION; ALGORITHM; JADE; HERD	Grey wolf optimization algorithm (GWO) is a new swarm intelligence optimization algorithm proposed in recent years. Because of few control parameters and easy implementation, GWO is widely used in many fields. Compared with other common swarm optimization algorithms, it is more suitable for the global optimization problems. Nevertheless, the algorithm still has the shortcoming of low accuracy and slow convergence speed. In this paper, a novel hybrid optimization algorithm named MDE-GWO is proposed. Firstly, a JADE with opposition-based learning strategy algorithm (MDE) is embedded in GWO to enhance the ability of avoiding a local optimum. Notably, by introducing the opposition-based learning strategy, the search ability of the improved algorithm is increased greatly. Additionally, in order to balance the global and local search capabilities and speed up the convergence of the GWO algorithm, a leader moving-rate strategy is put forward. 28 typical benchmark functions are utilized to test the performance of the improved algorithm. The experimental results show that MDE-GWO has stronger advantages in search accuracy, stability and convergence speed in most cases.																	0924-669X	1573-7497				FEB	2020	50	2					468	486		10.1007/s10489-019-01521-5													
J								Feature subset selection combining maximal information entropy and maximal information coefficient	APPLIED INTELLIGENCE										Feature subset selection; BPSO; MIC; SFS	CLASSIFICATION	Feature subset selection is an efficient step to reduce the dimension of data, which remains an active research field in decades. In order to develop highly accurate and fast searching feature subset selection algorithms, a filter feature subset selection method combining maximal information entropy (MIE) and the maximal information coefficient (MIC) is proposed in this paper. First, a new metric mMIE-mMIC is defined to minimize the MIE among features while maximizing the MIC between the features and the class label. The mMIE-mMIC algorithm is designed to evaluate whether a candidate subset is valid for classification. Second, two searching strategies are adopted to identify a suitable solution in the candidate subset space, including the binary particle swarm optimization algorithm (BPSO) and sequential forward selection (SFS). Finally, classification is performed on UCI datasets to validate the performance of our work compared to 9 existing methods. Experimental results show that in most cases, the proposed method behaves equally or better than the other 9 methods in terms of classification accuracy and F1-score.																	0924-669X	1573-7497				FEB	2020	50	2					487	501		10.1007/s10489-019-01537-x													
J								Skill based transfer learning with domain adaptation for continuous reinforcement learning domains	APPLIED INTELLIGENCE										Reinforcement learning; Transfer learning; Domain adaptation	ACQUISITION; FRAMEWORK; ABSTRACTION	Although reinforcement learning is known as an effective machine learning technique, it might perform poorly in complex problems, especially real-world problems, leading to a slow rate of convergence. This issue magnifies when facing continuous domains where the curse of dimensionality is inevitable, and generalization is mostly desired. Transfer learning is a successful technique to remedy such a problem which results in significant improvements in learning performance by providing generalization not only within a task but also across different but related or similar tasks. The critical issue in transfer learning is how to incorporate the knowledge acquired from learning in a different but related task in the past. Domain adaptation is an exciting paradigm that seeks to address this challenge. In this paper, we propose a novel skill based Transfer Learning with Domain Adaptation (TLDA) approach suitable for continuous RL problems. TLDA discovers and learns skills as high-level knowledge from source task and then uses domain adaptation technique to help agent discover state-action mapping as a relation between the source and target tasks. With such mapping, TLDA can adapt source skills and speed up learning on a new target task. The experimental results verify the achievement of an effective transfer learning method for continuous reinforcement learning problems.																	0924-669X	1573-7497				FEB	2020	50	2					502	518		10.1007/s10489-019-01527-z													
J								Optimizing shapelets quality measure for imbalanced time series classification	APPLIED INTELLIGENCE										Imbalanced time series data; Feature selection; Shapelets; Quality measure	SMOTE	Time series classification has been considered as one of the most challenging problems in data mining and is widely used in a broad range of fields. A biased distribution leads to classification on minority time series objects more severe. A commonly taken approach is to extract or select the representative features to retain the structure of a time series object. However, when the data distribution is imbalanced, the traditional features cannot represent time series effectively, especially in multi-class environment. In this paper, Shapelets - a primitive time series mining technology - is applied to extract the most representative subsequences. Especially, we verify that IG (Information Gain) is unsuitable as a shapelet quality measure for imbalanced data sets. Nevertheless, we propose two quality measures for shapelets on imbalanced binary and multi-class problem respectively. Based on extracted shapelet features, we select the diversified top-k shapelets based on new quality measure to represent the top-k best features and achieve this procedure on map-reduce framework. Lastly, two oversampling methods based on shapelet features are proposed to re-balance the binary and multi-class time series data sets. We validated our methods on the benchmark data sets by comparing with the canonical classifiers and the state-of-the-art time series algorithms. It is verified that the proposed algorithms perform more competitive than the compared methods in statistical significance.																	0924-669X	1573-7497				FEB	2020	50	2					519	536		10.1007/s10489-019-01535-z													
J								Multi-criteria decision making in Pythagorean fuzzy environment	APPLIED INTELLIGENCE										Multi-criteria decision making (MCDM); Pythagorean fuzzy number; Interval-valued Pythagorean fuzzy number; Distance measure; Closeness index; Aggregation	HAMACHER AGGREGATION OPERATORS; HESITANT FUZZY; FUNDAMENTAL PROPERTIES; DIVERGENCE MEASURE; MEMBERSHIP GRADES; INFORMATION; MODEL; SETS; UNCERTAINTY; EXTENSION	Pythagorean fuzzy set, initially extended by Yager from intuitionistic fuzzy set, is capable of modeling information with more uncertainties in the process of multi-criteria decision making (MCDM), thus can be used on wider range of conditions. The fuzzy decision analysis of this paper is mainly built upon two expressions in Pythagorean fuzzy environment, named Pythagorean fuzzy number (PFN) and interval-valued Pythagorean fuzzy number (IVPFN), respectively. We initiate a novel axiomatic definition of Pythagorean fuzzy distance measurement, including PFNs and IVPFNs. After that, corresponding theorems are put forward and then proved. Based on the defined distance measurements, the closeness indexes are developed for both expressions, inspired by the idea of technique for order preference by similarity to ideal solution (TOPSIS) approach. After these basic definitions have been established, the hierarchical decision approach is presented to handle MCDM problems under Pythagorean fuzzy environment. To address hierarchical decision issues, the closeness index-based score function is defined to calculate the score of each permutation for the optimal alternative. To determine criterion weights, a new method based on the proposed similarity measure and aggregation operator of PFNs and IVPFNs is presented according to Pythagorean fuzzy information from decision matrix, rather than being provided in advance by decision makers, which can effectively reduce human subjectivity. An experimental case is then conducted to demonstrate the applicability and flexibility of the proposed decision approach. Finally, extension forms of Pythagorean fuzzy decision approach for heterogeneous information are briefly introduced to show its potentials on further applications in other processing fields with information uncertainties.																	0924-669X	1573-7497				FEB	2020	50	2					537	561		10.1007/s10489-019-01532-2													
J								Unsupervised representation learning based on the deep multi-view ensemble learning	APPLIED INTELLIGENCE										Unsupervised feature learning; Deep learning; Ensemble learning; Fusion; Genetic algorithm	ALGORITHM; NETWORKS; MODELS	Deep networks have recently achieved great success in feature learning problem on various computer vision applications. Among different approaches in deep learning, unsupervised methods have attracted a lot of attention particularly to problems with limited training data. However, compared with supervised methods, unsupervised deep learning methods usually suffer from lower accuracy and higher computational time. To deal with these problems, we aim to restrict the number of connections between successive layers while enhancing discriminatory power using a data-driven approach. To this end, we propose a novel deep multi-view ensemble model. The structure of each layer is composed of an ensemble of encoders or decoders and mask operations. The multi-view ensemble of encoders or decoders enable the network to benefit from local complementary information and preserve local characteristics in final generated features, while mask operations determine the connections between successive layers. The experimental results on popular datasets indicate the effectiveness and validity of the method in clustering and classification tasks while the processing time is reduced.																	0924-669X	1573-7497				FEB	2020	50	2					562	581		10.1007/s10489-019-01526-0													
J								Sandpiper optimization algorithm: a novel approach for solving real-life engineering problems	APPLIED INTELLIGENCE										Optimization; Bio-inspired metaheuristic techniques; Machine-learning; Benchmark test problems	PARTICLE SWARM OPTIMIZATION; SPOTTED HYENA OPTIMIZER; DESIGN; MODEL; PERFORMANCE; HOLE	This paper presents a novel bio-inspired algorithm called Sandpiper Optimization Algorithm (SOA) and applies it to solve challenging real-life problems. The main inspiration behind this algorithm is the migration and attacking behaviour of sandpipers. These two steps are modeled and implemented computationally to emphasize intensification and diversification in the search space. The comparison of proposed SOA algorithm is performed with nine competing optimization algorithms over 44 benchmark functions. The analysis of computational complexity and convergence behaviors of the proposed algorithm have been evaluated. Further, SOA algorithm is hybridized with decision tree machine-learning algorithm to solve real-life applications. The experimental results demonstrated that the proposed algorithm is able to solve challenging constrained optimization problems and outperforms the other state-of-the-art optimization algorithms.																	0924-669X	1573-7497				FEB	2020	50	2					582	619		10.1007/s10489-019-01507-3													
J								Exploring duality on ontology debugging	APPLIED INTELLIGENCE										Ontology debugging; MUPS; MCPS; Duality	DIAGNOSIS	Ontology debugging is an important and intractable reasoning task. Minimal unsatisfiability-preserving subset (MUPS) which is a minimal subset of an ontology to debug an unsatisfiable concept, is an important concept in ontology debugging. Hitting set relation between conflict set and diagnosis is essential for computing all conflict sets. And there has been many successful explorations about hitting set duality between conflict set and diagnosis in many fields. So in this paper, we will explore the duality between MUPS and minimal correctness-preserving subset (MCPS) which denotes the minimal diagnosis of a concept to debug unsatisfiable concepts on ontology debugging domain. Then several methods for computing all MUPSes will be devised based on the duality between MUPS and MCPS, meanwhile parallel strategies are also applied to newly proposed methods. And we show, by an empirical evaluation, that performances of different methods on real world ontologies from different domains. And it is proved that it is meaningful to explore duality on ontology debugging, as it really boosts the efficiency when applied to complex ontologies compared to the previous methods.																	0924-669X	1573-7497				FEB	2020	50	2					620	633		10.1007/s10489-019-01528-y													
J								User correlation model for question recommendation in community question answering	APPLIED INTELLIGENCE										Question recommendation; User correlation model; Community question answering		In this paper, we address the problem of question recommendation that automatically recommends a new question to suitable users to answer in community question answering (CQA). The major challenge of question recommendation is the accurate selection of suitable users to answer. Most of the existing approaches attempt to find suitable users in CQA by estimating user's existing capability, user's interest or blending both for the question. However, these methods ignore correlation among users (askers and answerers) in terms of topic preference. In this study, we propose a user correlation model (UCM) to effectively estimate degree of correlation among users in terms of topic preference. Furthermore, we present the UCM-based approach to question recommendation, which provides a mechanism to naturally integrate the correlation between answerer and asker in terms of topic preference with content relevance between the answerer and the question into a unified probabilistic framework. Experiments using real-world data from Stack Overflow show that our UCM-based approach consistently and significantly improves the performance of question recommendation. Hence, our approach can increase question recommendation accuracy in CQA according to utilize the correlation between answerer and asker in terms of topic preference.																	0924-669X	1573-7497				FEB	2020	50	2					634	645		10.1007/s10489-019-01544-y													
J								How corporate social responsibility activities influence employer reputation: The role of social media capability	DECISION SUPPORT SYSTEMS										Corporate social responsibility activities; Social media capability; Employer reputation; Business value of information technology	INFORMATION-TECHNOLOGY; FIRM PERFORMANCE; BUSINESS TRANSFORMATION; INNOVATION PERFORMANCE; COMPETITIVE ADVANTAGE; IMPACT; SYSTEMS; PROFITABILITY; IDENTITY; ATTRACTIVENESS	This study analyzes the relation between the firm's corporate social responsibility (CSR) activities, employer reputation, and social media in the academic conversation on business value of technology. Motivated by the controversy over the function of social media in the firm's generation of value from CSR activities, this study hypothesizes that firms that perform CSR activities may become better employers and that this positive relationship may be stronger when firms leverage social media technologies. We explain this effect of social media by arguing that these social technologies enable higher social visibility and exposure/credibility. We tested our research model with data from 100 organizations in Spain. The results provided two key insights: 1) CSR activities enable firms to build greater employer reputation; and 2) social media capability amplifies the effect of CSR activities on employer reputation. This study contributes to Information Systems and Business Ethics research by arguing theoretically and demonstrating empirically that leveraging a technology such as social media generates business value through maximization of the positive impact of CSR activities on employer reputation of the firm.																	0167-9236	1873-5797				FEB	2020	129								113223	10.1016/j.dss.2019.113223													
J								Multivariate data quality assessment based on rotated factor scores and confidence ellipsoids	DECISION SUPPORT SYSTEMS										Data quality assessment; Decision-making; Multivariate measurement system; Factor analysis; Varimax rotation; Confidence ellipsoid	R-AND-R; INFORMATION QUALITY; OPTIMIZATION; MODEL	This study explores the nature of the correlation in data to estimate the data quality to be used in decision-making processes. The main contribution of this research is the introduction of a new multivariate method based on rotated factor scores by varimax strategy for the repeatability and reproducibility study to effectively identify possible data of poor quality leading to measurement errors. In addition, a new confidence ellipsoid-based decision support method is developed. The efficiency of the proposed method was demonstrated using the metallographic measurements of the geometric characteristics of the resistance spot welding process. To prove the efficiency of the proposed method, it was compared with other consolidated techniques such as the analysis of variance, weighted principal components method, and factor analysis without rotation. Thus, we verified that the proposed method performed better interpretation of the latent information, minimizing the dimensionality of the data, and separating the quality attributes analyzed by clusters. One response group was classified as acceptable, and the other as marginal. These results were verified by the confidence ellipsoids, in which the proposed method obeyed the Bonferroni bilateral limits, outlining the factors which demonstrated superior discriminatory power with non-overlapping ellipsoids avoiding the confounding and favoring the better data quality analysis for multicriteria decision-making. When compared with the other approaches, the proposed method demonstrated more reliable and robust results without such deficiencies as inversion of the groupings, neglection of the variance-covariance structure, and the variability attributed to the data within the measurement system.																	0167-9236	1873-5797				FEB	2020	129								113173	10.1016/j.dss.2019.113173													
J								Preferences stability: A measure of preferences changes over time	DECISION SUPPORT SYSTEMS										Preference stability; Decision stability; Complete pre-orders; Loss memory effect	SOCIAL PREFERENCES; ELICITING RISK; TASK	Traditionally, preferences have been considered stable although there are growing evidences that such stability is a mere theoretical assumption. Attending to this fact, it should be interesting to measure how much stability preferences provide in order to improve decision making processes. Surprisingly, no research has been found on measuring preferences stability. To overcome this drawback, this paper proposes a novel approach for measuring the stability of preferences and also for improving understanding of current and future decisions. In order to be faithful to reality, this research considers decisions like complete pre-orders on a set of alternatives. Following this reasoning, this paper provides the general concept of decision stability measure as well as two specific measures: the local and the global decision stability measure. Moreover, the main features of the novel approach are examined, including several mathematical results on the behaviour of the proposed measure. And eventually, this contribution develops two real cases of study, with in-depth analysis of preferences behaviour and their stability over time. Specifically, the first one explores into the characteristics of Spanish citizens' voting behaviour and the second one attempts to analyse European citizens' preferences about passenger car market.																	0167-9236	1873-5797				FEB	2020	129								113169	10.1016/j.dss.2019.113169													
J								Preference enhanced hybrid expertise retrieval system in community question answering services	DECISION SUPPORT SYSTEMS										Community question answering; Expertise retrieval; Hybrid systems; Social network analysis		Here, we propose a preference enhanced hybrid expertise retrieval (PEHER) system in community question answering services. PEHER consists of three segments, namely, preferability estimator, authority estimator, and expertise estimator. The preferability estimator utilizes the textual information to determine both intra-profile and inter-profile preferences of answerers for each term. The intra-profile preferences consider the preference of a term using the answering history of a given answerer. The inter-profile preferences incorporate the preferences of all answerers for a term. These preferences are then used to determine the preferability of each answerer for each of the archived questions. The authority estimator considers the textual familiarity between each archived question and the profile of each answerer as the weight of the associated link in the network. The expertise estimator is composed of three blocks, namely, question similarity finder, proficiency estimator, and expert list generator. The question similarity finder finds the similarities between the new question and each of the archived questions. The proficiency estimator uses the said similarities of the archived questions along with their preferabilities to decide the proficiencies of answerers for the new question. Finally, the expert list generator considers the authorities and proficiencies to generate a list of experts for a given question. We compare PEHER with twenty existing methods on four real-world datasets using five performance measures. We find that PEHER outperforms the comparing algorithms in 92.00% (368 out of 400) cases.																	0167-9236	1873-5797				FEB	2020	129								113164	10.1016/j.dss.2019.113164													
J								A social fundraising mechanism for charity crowdfunding	DECISION SUPPORT SYSTEMS										Crowdfunding; Philanthropy; Social networking; Social fundraising; Social recommendations	MEDIA; NETWORKING; SELECTION; BEHAVIOR; IMPROVE; IMPACT	In recent years, as the world has witnessed many social issues and environmental disasters, philanthropic giving has become widespread. Today, crowdfunding platforms have also become popular, and charities often use these to fundraise. However, they rarely utilize the power of social networking to assist a fundraiser in discovering potential donors, and this is especially true for small organizations and individuals. In this research, we propose a recommendation mechanism for social fundraising that analyzes the donor's preferences, the relationship between the donor and fundraiser, and the characteristics of the fundraising dynamics to promote the spread of philanthropic fundraising. The proposed mechanism can effectively discover appropriate donors and relevant campaigns to expedite the fundraising process and improve its success rate.																	0167-9236	1873-5797				FEB	2020	129								113170	10.1016/j.dss.2019.113170													
J								Veracity assessment of online data	DECISION SUPPORT SYSTEMS										Veracity assessment; Credibility; Data quality; Online data; Social media; Fake news	INFORMATION CREDIBILITY; SOCIAL NETWORKS	Fake news, malicious rumors, fabricated reviews, generated images and videos, are today spread at an unprecedented rate, making the task of manually assessing data veracity for decision-making purposes a daunting task. Hence, it is urgent to explore possibilities to perform automatic veracity assessment. In this work we review the literature in search for methods and techniques representing state of the art with regard to computerized veracity assessment. We study what others have done within the area of veracity assessment, especially targeted towards social media and open source data, to understand research trends and determine needs for future research. The most common veracity assessment method among the studied set of papers is to perform text analysis using supervised learning. Regarding methods for machine learning much has happened in the last couple of years related to the advancements made in deep learning. However, very few papers make use of these advancements. Also, the papers in general tend to have a narrow scope, as they focus on solving a small task with only one type of data from one main source. The overall veracity assessment problem is complex, requiring a combination of data sources, data types, indicators, and methods. Only a few papers take on such a broad scope, thus, demonstrating the relative immaturity of the veracity assessment domain.																	0167-9236	1873-5797				FEB	2020	129								113132	10.1016/j.dss.2019.113132													
J								Determinants of writing positive and negative electronic word-of-mouth: Empirical evidence for two types of expectation confirmation	DECISION SUPPORT SYSTEMS										Expectation confirmation model (ECM); Electronic word-of-mouth (eWOM); Online review; Online community; Dissatisfaction; Disconfirmation; Smart tourism; TripAdvisor	SOCIAL-INFLUENCE MODEL; INFORMATION ADOPTION; ONLINE REVIEWS; PERCEIVED EASE; PARTICIPATION; SATISFACTION; ACCEPTANCE; DISCONFIRMATION; DISSATISFACTION; CONSEQUENCES	While many studies focus on how electronic word-of-mouth (eWOM) affects the readers of eWOM, this study examines what influences the writers of eWOM. We analyze survey results from 438 TripAdvisor hotel reviewers to reveal that two distinct types of expectation confirmation influence the writing of eWOM, as do satisfaction and consumers' personal characteristics. Thus, this study makes two primary contributions, first by identifying and describing consumers' two types of expectation confirmation, and second by noting that one set of antecedents leads consumers to write negative eWOM while a different set of antecedents leads consumers to write positive eWOM.																	0167-9236	1873-5797				FEB	2020	129								113168	10.1016/j.dss.2019.113168													
J								Predicting performances in business processes using deep neural networks	DECISION SUPPORT SYSTEMS										Process mining; Process management; Online operational support; Process performance prediction; Deep neural networks	TIME	Online operational support is gaining increasing interest due to the availability of real-time data and sufficient computing power, such as predictive business process monitoring. Predictive business process monitoring aims at providing timely information that enables proactive and corrective actions to improve process enactments and mitigate risks. There are a handful of research works focusing on the predictions at the instance level. However, it is more practical to predict the performance of processes at the process model level and detect potential weaknesses in the process to facilitate the proactive actions that will improve the process execution. Thus, in this paper, we propose a novel method to predict the future performances of a business process at the process model level. More in detail, we construct an annotated transition system and generate a process representation matrix from it. Based on the process representation matrix, we build performance prediction models using deep neural networks that consider both spatial and temporal dependencies present in the underlying business process. To validate the proposed method, we performed case studies on three real-life logs.																	0167-9236	1873-5797				FEB	2020	129								113191	10.1016/j.dss.2019.113191													
J								On addressing RFID/NFC-based relay attacks: An overview	DECISION SUPPORT SYSTEMS										RFID; Relay attack; Cryptography; Ambient conditions		Relay attacks generally occur between two entities that communicate with each other through wireless means. When a relay attack between a honest prover and a honest verifier occurs, an adversary tricks the prover and verifier into believing that they are indeed communicating with each other. Such attacks are rather difficult to identify and prevent since a passive adversary does not modify any of the communicated messages between prover and verifier. RFID/NFC-based applications are particularly vulnerable to such attacks. We provide an overview of RFID-based relay attacks and evaluate various streams of research that have attempted to address these attacks. Specifically, we consider distance-bounding techniques and the use of artificial or natural ambient conditions, with specific emphasis on the latter.																	0167-9236	1873-5797				FEB	2020	129								113194	10.1016/j.dss.2019.113194													
J								Directed disease networks to facilitate multiple-disease risk assessment modeling	DECISION SUPPORT SYSTEMS										Multiple-disease risk prediction; Health risk assessment; Disability adjusted life year; Directed network; Disease temporal relations	ENGINE	We investigate multiple disease risk prediction modeling, aimed at assessing future disease risks for an individual who is ready for discharge after hospitalization. We propose a novel framework that combines directed disease network and recommendation system techniques to substantially enhance multiple disease risk predictive modeling. Firstly, a directed disease network considering temporal information is developed. Then based on this directed disease network, we look into different disease risk score computing approaches. We validate the proposed approaches with two real-world datasets from two independent hospitals. The predicted results can be promisingly utilized as a reference for medical experts to offer effective healthcare guidance for both inpatients and outpatients. The proposed framework can also be utilized for developing an innovative tool that helps individuals create and maintain a better healthcare plan over time.																	0167-9236	1873-5797				FEB	2020	129								113171	10.1016/j.dss.2019.113171													
J								A tour-guide robot: Moving towards interaction with humans	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Fuzzy systems; Emotions; Indoor localization and navigation; Task planning; Social robotics; Human-machine interaction	PROGRAMMING LANGUAGE; BRANCH; ALGORITHMS	The aim of this research project is to develop a smart social robot showing sufficient intelligence to work as a tour-guide in different environments. In doing so, both a software and a hardware architecture are proposed, the different modules of which, such as a laser, cameras, platform, face, and voice, among others, control the different components of the robot. Those components are in turn used by other modules designed for navigation and interaction. A sensor fusion for the purposes of localization is implemented by means of an Extended Kalman Filter, which is one of the navigation module components, together with the proposed fuzzy controllers needed for path following. A fuzzy emotion system that controls the face and the voice modules also forms part of this architecture for assisting interaction. Finally, all the modules are controlled with a customized programming language that is a mixture of C, Pascal, and JavaScript. The modules are optimized for immediate execution to achieve realistic human machine interaction.																	0952-1976	1873-6769				FEB	2020	88								103356	10.1016/j.engappai.2019.103356													
J								Optimal capacity allocation under random passenger demands in the high-speed rail network	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										High-speed rail network; Capacity allocation; Two-stage stochastic integer program; Heuristic algorithm	TIME	The capacity allocation is a practically significant factor to influence the quality of the train timetables in the rail operations, especially under the fluctuation of passenger demands. This paper aims to investigate a detailed description for the structure and characteristics of the capacity allocation problem under random demand in the high-speed rail network. A two-stage stochastic integer programming model is provided to get the capacity allocation solutions to meet random fluctuations of passenger demands in the daily operations, which incorporates demand uncertainty and makes no assumptions for the rail network structure and distribution of passenger demands. Given the inherent complexity for solving this problem, we provide a solution framework including a heuristic algorithm based on tabu search in order to obtain a near-optimal solution and strategies to obtain an efficient timetable and train formation adjustment. Finally, two sets of examples, in which a sample rail network with 5 stations and the Beijing-Shanghai high-speed rail network data are adopted as the experimental environments to illustrate the performance and effectiveness of the proposed methods.																	0952-1976	1873-6769				FEB	2020	88								103363	10.1016/j.engappai.2019.103363													
J								Improved stochastic fractal search algorithm and modified cost function for automatic generation control of interconnected electric power systems	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Multi-area power system; Automatic generation control; Governor dead band nonlinearity; Generation rate constraint; Stochastic fractal search; PID controller; Optimization	LOAD-FREQUENCY CONTROL; DIFFERENTIAL EVOLUTION ALGORITHM; OPTIMIZATION ALGORITHM; PID CONTROLLER; DESIGN; MATTER; STATES	y An improved stochastic fractal search algorithm (ISFS) and a modified cost function are proposed in this paper to skillfully handle the issue of automatic generation control (AGC) of power systems. Most employed power system models namely two-area non-reheat thermal power system with and without governor dead band nonlinearity, and three-area hydro-thermal power plant with generation rate constraints are considered to be controlled by a PID controller. Then the gains of this controller are optimized with SFS and ISFS individually by minimizing the value of cost function proposed. This function consists in minimizing the integral time absolute error (ITAE) and also the time rates of frequency and tie-line power deviations. After recognizing the supremacy of SFS tuned PID controller over some existing methods in improving settling time and oscillations of frequency and tie-line power deviations, ISFS tuned PID controller is shown to promote the system performance further to compete with some other control schemes of higher degree and complexity available in the literature. This outcome has unveiled the superior tuning ability of ISFS over the original version of SFS. Also, convergence curves of the algorithms are analyzed from which it is observed that the speed of convergence for ISFS is remarkable.																	0952-1976	1873-6769				FEB	2020	88								103407	10.1016/j.engappai.2019.103407													
J								A population-based iterated greedy algorithm for no-wait job shop scheduling with total flow time criterion	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Scheduling; Job shop; Flow shop; No-wait; Metaheuristics; Evolutionary algorithms	BEE COLONY ALGORITHM; GENETIC ALGORITHM; TABU SEARCH; MACHINE; MAKESPAN; BLOCKING; MINIMIZE; OPTIMIZATION	The no-wait job shop where no waiting time is allowed between two successive operations of a job has a strong industrial background, especially in steel-making industry and concrete manufacturing. This study formulates the no-wait job shop problem with a total flow time criterion based on time difference and decomposes the problem into timetabling and sequencing subproblems. Several timetabling methods are designed for the total flow time criterion to generate a sequence timetable. By adopting favourable features of the iterated greedy algorithm, the population-based iterated greedy (PBIG) algorithm for the sequencing subproblem is proposed. The individuals in the population evolve by means of a destruction and construction perturbator and an insertion-based local search. In each iteration, a tournament selection is designed to replace a relatively worse solution. In order to generate starting solutions with a certain quality and diversity, the Nawaz-Enscore-Ham-based heuristics for flow shop scheduling are extended in no-wait job shops. In computational experiments based on well-known benchmark instances, timetabling methods are investigated, and it is shown that the left timetabling is superior to other timetabling methods for the total flow time minimisation. Computational results also show that the proposed algorithm significantly outperforms several state-of-the-art metaheuristics, and it could be applicable to practical production environment.																	0952-1976	1873-6769				FEB	2020	88								103369	10.1016/j.engappai.2019.103369													
J								Picture fuzzy time series: Defining, modeling and creating a new forecasting method	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Picture fuzzy sets; Picture fuzzy time series; Picture fuzzy C-means; Pi-sigma artificial neural networks	SYSTEM	The extant literature has shown that fuzzy sets can be applied to solve forecasting problems. A fuzzy time series is a kind of time series whose observations are fuzzy sets or fuzzy numbers. A picture fuzzy set is a generalized form of fuzzy and intuitionistic fuzzy sets that is also referred to as a standard neutrosophic set. In this study, a picture fuzzy time series and a single variable high order picture fuzzy time series forecasting model are defined based on picture fuzzy sets. We also propose a new picture fuzzy time series forecasting method. The proposed method solves the issues inherent in the high order single variable picture fuzzy time series forecasting model. The proposed method has three basic steps: (1) picture fuzzification, (2) model construction, and (3) forecasting. In the proposed method, picture fuzzification is accomplished via picture fuzzy clustering, and positive, neutral and negative membership values are obtained. The model construction step consists of estimating a function. This study employed a pi-sigma artificial neural network for this estimation. The proposed method is applied to a meteorological data set with an expanding window approach. The proposed method outperforms recent fuzzy time series and classical methods found in the extant literature.																	0952-1976	1873-6769				FEB	2020	88								103367	10.1016/j.engappai.2019.103367													
J								A robust neural network approximation-based prescribed performance output-feedback controller for autonomous underwater vehicles with actuators saturation	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Actuator saturation; Adaptive robust controller; Autonomous underwater vehicles; High-gain observer; Prescribed performance technique; Multi-layer neural networks	DYNAMIC SURFACE CONTROL; TRAJECTORY TRACKING CONTROL; NONLINEAR-SYSTEMS; MODEL; TARGET	A robust neural network approximation-based output-feedback tracking controller is proposed for autonomous underwater vehicles (AUVs) in six degrees-of-freedom in this paper. The prescribed performance technique is employed to obtain some pre-defined maximum overshoot/undershoot, convergence speed and ultimate tracking accuracy for the tracking errors. A high-gain observer is used to approximate unavailable velocity vector which is crucial to design the output-feedback controller. A robust multi-layer neural network and adaptive robust techniques are combined to simultaneously compensate for the unmodeled dynamics, system nonlinearities, exogenous kinematic and dynamic disturbances, and reduce the risk of the actuator saturation. Then, the uniform ultimate boundedness stability of the closed-loop control system is proved via a Lyapunov-based stability synthesis. It is demonstrated that the posture tracking errors converge to a vicinity of the origin with a guaranteed prescribed performance during the tracking mission without velocity measurements. Finally, simulation results with a comparative study verify the theoretical findings.																	0952-1976	1873-6769				FEB	2020	88								103382	10.1016/j.engappai.2019.103382													
J								Performance analysis of Chaotic Multi-Verse Harris Hawks Optimization: A case study on solving engineering problems	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Multi-Verse Optimizer; Chaotic maps; Harris Hawks Optimization; Meta-heuristic optimization; Engineering problems	PARTICLE SWARM OPTIMIZATION; MOTH-FLAME OPTIMIZATION; DIFFERENTIAL EVOLUTION; DESIGN OPTIMIZATION; ALGORITHM; SEARCH; INTEGER	In recent years, several optimization algorithms are proposed, one of them is Multi-Verse Optimizer (MVO). In this paper, a modified version of MVO is proposed, called CMVHHO, which uses the chaos theory and the Harris Hawks Optimization (HHO). The main aim of using the chaotic maps in the proposed method is to determine the optimal value for the parameters of the basic MVO. Besides, the HHO is used as a local search to improve the ability of the MVO to exploit the search space. The performance of the CMVHHO is conducted using a set of chaotic maps to determine the most suitable map, as well as, the different experiments are performed to determine which parameter has the largest effect on the effectiveness of the MVO. Moreover, the performance of the CMVHHO is compared with a set of state-of-the-art algorithms to find the best solution for global optimization problems. Furthermore, the proposed CMVHHO with the best map is applied to solve four well-known engineering problems. The experimental results illustrate that the chaotic Circle map is the best map among all maps because it improved the performance of the CMVHHO, as well as the HHO, affected positively in the behavior of the proposed algorithm. The CMVHHO showed the best results than other algorithms in terms of the performance measures as well as in engineering problems and it outperformed the state-of-the-art algorithms in all problems.																	0952-1976	1873-6769				FEB	2020	88								103370	10.1016/j.engappai.2019.103370													
J								Teaching a humanoid robot to walk faster through Safe Reinforcement Learning	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Safe Reinforcement Learning; Biped walking		Teaching a humanoid robot to walk is an open and challenging problem. Classical walking behaviors usually require the tuning of many control parameters (e.g., step size, speed). To find an initial or basic configuration of such parameters could not be so hard, but optimizing them for some goal (for instance, to walk faster) is not easy because, when defined incorrectly, may produce the fall of the humanoid, and the consequent damages. In this paper we propose the use of Safe Reinforcement Learning for improving the walking behavior of a humanoid that permits the robot to walk faster than with a pre-defined configuration. Safe Reinforcement Learning assumes the existence of a safe baseline policy that permits the humanoid to walk, and probabilistically reuse such a policy to learn a better one, which is represented following a case based approach. The proposed algorithm has been evaluated in a real humanoid robot proving that it drastically increases the learning speed while reduces the number of falls during learning when compared with state-of-the-art algorithms.																	0952-1976	1873-6769				FEB	2020	88								103360	10.1016/j.engappai.2019.103360													
J								Estimating cement compressive strength using three-dimensional microstructure images and deep belief network	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Cement compressive strength; Microstructure images; Deep belief network; Graphics processing units	FEATURE-EXTRACTION; NEURAL-NETWORKS; PREDICTION; CLASSIFICATION; HYDRATION; FEATURES; CONCRETE; SIGNALS; MODEL; SIZE	The estimation of cement compressive strength is of great significance in the quality inspections, technological designs, and engineering applications for cement. Compared to destructive methods, the nondestructive estimation approaches save the cost in the manpower and material. However, the existing nondestructive methods have the large error because the used influence factors are difficult to control and the used two-dimensional microstructure images can not reflect the specific spatial structure of the entire cement. In this paper, a novel model is proposed to estimate the cement compressive strength using three-dimensional microstructure images and deep belief network. To reduce the computation consumption induced by three-dimensional images with abundant information, this method extracts image features that reflect the cement hydration state to estimate cement compressive strength. Deep belief network is applied to build the estimation model. Its unique training pattern and flexibility of parameters improve the ability to learn nonlinear relationships between microstructure images and cement compressive strength. Furthermore, the training processes are accelerated on the graphics processing units. The experimental results prove that the proposed method estimates cement compressive strength nondestructively and improves the efficiency.																	0952-1976	1873-6769				FEB	2020	88								103378	10.1016/j.engappai.2019.103378													
J								Stochastic topic models for large scale and nonstationary data	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Online topic model; Beta-Liouville prior; Topic correlation; Nonstationary datasets	DIRICHLET; RECOGNITION; SPACE	Many traditional database's processing schemes are batch-based with their abilities to utilize the entire information available at a time. Though, their limitations include storage (memory issues) and computational speed (often slow) for large scale applications. Another major disadvantage of the batch processing is that any small change or update in the database often requires a reevaluation using all the data at a time. This is not efficient as it is time consuming and exhausting. So, the approach seems to be a little obsolete in this new generation of fast computation. Furthermore and recently, the decrease in the cost of performing computations online promoted the increase in streaming and online-based models. In other words, new systems are taking advantage of the online setting to build models that are able to perform in real time and handle fast computations with real time updates. Traditional models could no longer scale to very large applications. So, much support has been given to online framework as these massive and nonstationary data could not keep up with the available storage. In the case of generative models, usually, the lack of flexible priors and sometimes the high complexities in the methods often hindered their performances. In addition and most importantly, many online-based models still use traditional inference approaches such as variational Bayes (VB) and Markov chain Monte Carlo (MCMC) which individually are not flexible enough as they suffer from either accuracy or efficiency. As a result, we propose in this paper, a new model that operates in online fashion with BL (Beta-Liouville) prior due to its flexibilities in topic correlation analysis. Carrying only very few parameters (compared to the generalized Dirichlet distribution, for instance), the BL is now coupled with a robust and stochastic generative process within a new hybrid inference that combines only the advantages of the VB and Gibbs sampling in the collapsed space. This insures an efficient, fast, and accurate processing. Experimental results with nonstationary datasets for face detection, image classification, and text documents processing show the merits of the new stochastic approach.																	0952-1976	1873-6769				FEB	2020	88								103364	10.1016/j.engappai.2019.103364													
J								A feature extraction based trajectory segmentation approach based on multiple movement parameters	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Trajectory segmentation; Trajectory clustering; Movement parameter; Sliding window	WAVELET; CONTEXT; POINTS	Analyzing the trajectories of movements among moving objects is of interest in many fields to understand the dynamics and behavior of those objects. In this paper, a cluster-centric trajectory segmentation approach is proposed to reveal and visualize segments of trajectories among moving objects. Characteristics such as position, direction, and speed of moving objects (called movement parameters) are considered for this purpose. First, profiles generated for different movement parameters are divided into several portions using sliding windows of different length. Next, changes with respect to each particular movement parameter profile in the sliding windows are extracted as features. Finally, by clustering the extracted features, subsequences of trajectories with similar movement characteristics are detected. Some cluster-validity indices were used to find the (near) optimal number of clusters. The performance of the proposed segmentation technique is evaluated through a trajectory clustering as well as a movement pattern detection case study over some real-word datasets.																	0952-1976	1873-6769				FEB	2020	88								103394	10.1016/j.engappai.2019.103394													
J								Network-based direction of movement prediction in financial markets	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Graph-based semi-supervised learning; Mixture of experts; Network modeling; Time series prediction	STOCK; HYPOTHESIS; PRICES; MODEL	Market prediction has been an important research problem for decades. Having better predictive models that are both more accurate and faster has been attractive for both researchers and traders. Among many approaches, semi-supervised graph-based prediction has been used as a solution in recent researches. Based on this approach, we present two prediction models. In the first model, a new network structure is introduced that can capture more information about markets' direction of movements compared to the previous state of the art methods. Based on this novel network, a new algorithm for semi-supervised label propagation is designed that is able to prediction the direction of movement faster and more accurately. The second model is a mixture of experts system that decides between supervised or semi-supervised approaches. Besides this, the model gives us the ability to identify the markets that their data are helpful in constructing the network. Our models are shown to be both faster regarding computational complexity and running time and more accurate in prediction comparing to best rival models in literature of graph-based semi-supervised prediction. The results are also tested to be statistically significant.																	0952-1976	1873-6769				FEB	2020	88								103340	10.1016/j.engappai.2019.103340													
J								Generalized elastic net Lp-norm nonparallel support vector machine	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Support vector machine; Nonparallel support vector machine; Lp-norm; Generalized elastic net; Regularization	PRINCIPAL COMPONENT ANALYSIS; CLASSIFICATION	Generalized eigenvalue proximal support vector machine (GEPSVM) is the first nonparallel support vector machine. Compared to standard support vector machine (SVM), GEPSVM coped with the "Xor" problem well. In this paper, by defining a generalized elastic net regularization which is the combination of the L2-norm and Lq-norm, we propose a generalized elastic net Lp-norm nonparallel proximal support vector machine (GLpNPSVM), where p, q > 0. GLpNPSVM measures the distance of a sample to each hyperplane by the Lp-norm, and hence can achieve desired performance by choosing appropriate p. In addition, the generalized elastic net regularization makes GLpNPSVM own good generalization ability. GLpNPSVM is a generalized formulation, and GEPSVM and some of its improvements are special cases of GLpNPSVM. A simple but effective iterative technique is introduced to solve GLpNPSVM, and we prove its convergence for certain p, q > 0. Experimental results on different types of contaminated data sets show the effectiveness of GLpNPSVM.																	0952-1976	1873-6769				FEB	2020	88								103397	10.1016/j.engappai.2019.103397													
J								Meta-cognitive recurrent kernel online sequential extreme learning machine with kernel adaptive filter for concept drift handling	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Concept drift; Multi-step prediction; Recurrent algorithm; Kernel method; Time series prediction	TIME-SERIES PREDICTION; NEURAL-NETWORKS; REGRESSION; ALGORITHM; MODELS	This paper proposes a multi-step prediction model for time series prediction, i.e. Meta-cognitive Recurrent Kernel Online Sequential Extreme Learning Machine with Drift Detector Mechanism (Meta-RKOS-ELMALD). Recurrent multi-step algorithm is applied to release the limitation in the number of prediction steps, and Drift Detector Mechanism (DDM) is used to overcome the problem of concept drift in the prediction model. The new meta-cognitive strategy decides the way of the incoming data during training, which decreases the training computation of prediction model and solves the parameter dependency. In our evaluation, we use a total of six artificial data sets and three real-world data sets (Standard & Poor's 500 Index, Shanghai Stock Exchange Composite Index, and Ozone Concentration in Toronto) to prove the ability of kernel filters, the detecting ability of concept drift detector, and situation of applying meta-cognitive strategy in our proposed model. Experiments results indicate that the Meta-KOS-ELMALD with DDM has better forecasting ability in various predicting periods with the shortest learning time, as compared with other algorithms.																	0952-1976	1873-6769				FEB	2020	88								103327	10.1016/j.engappai.2019.103327													
J								Robust nonnegative matrix factorization with local coordinate constraint for image clustering	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Nonnegative matrix factorization; Correntropy; Local coordinate constraint; Graph regularization; Outliers	CORRENTROPY; MINIMIZATION; SPARSE; SIGNAL	Nonnegative matrix factorization (NMF) has attracted increasing attention in data mining and machine learning. However, existing NMF methods have some limitations. For example, some NMF methods seriously suffer from noisy data contaminated by outliers, or fail to preserve the geometric information of the data and guarantee the sparse parts-based representation. To overcome these issues, in this paper, a robust and sparse NMF method, called correntropy based dual graph regularized nonnegative matrix factorization with local coordinate constraint (LCDNMF) is proposed. Specifically, LCDNMF incorporates the geometrical information of both the data manifold and the feature manifold, and the local coordinate constraint into the correntropy based objective function. The half-quadratic optimization technique is utilized to solve the nonconvex optimization problem of LCDNMF, and the multiplicative update rules are obtained. Furthermore, some properties of LCDNMF including the convergence, relation with gradient descent method, robustness, and computational complexity are analyzed. Experiments of clustering demonstrate the effectiveness and robustness of the proposed LCDNMF method in comparison to several state-of-the-art methods on six real world image datasets.																	0952-1976	1873-6769				FEB	2020	88								103354	10.1016/j.engappai.2019.103354													
J								Online prediction of time series with assumed behavior	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Time series; Online learning; Human-agent interaction	ADVICE PROVISION	The prediction of future time series values is essential for many fields and applications. In some settings, the time series behavior is expected to follow distinct patterns which in turn may change over time due to a change in the user's preferences/behavior or a change in the environment itself. In this article, we propose to leverage the assumed time series behavior by developing specialized novel online machine learning algorithms. To demonstrate the potential benefits of our approach compared to existing practices we focus on two commonly assumed time series behaviors: exponential decay and sigmoidal. We present two innovative online learning algorithms, Exponentron for the prediction of exponential decay time series and Sigmoidtron for the prediction of sigmoidal time series. We provide an extensive evaluation of both algorithms both theoretically and empirically using synthetic and real-world data. Our results show that the proposed algorithms compare favorably with the classic time series prediction methods commonly deployed today by providing a substantial improvement in prediction accuracy. Furthermore, we demonstrate the potential applicative benefit of our approach for the design of a novel automated agent for the improvement of the communication process between a driver and its automotive climate control system. Through an extensive human study with 24 drivers we show that our agent improves the communication process and increases drivers' satisfaction.																	0952-1976	1873-6769				FEB	2020	88								103358	10.1016/j.engappai.2019.103358													
J								Fault location estimation for series-compensated double-circuit transmission line using EWT and weighted RVFLN	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Field programmable gate array (FPGA); Empirical wavelet transform (EWT); Hilbert transform (HT); Fault location estimation; Fault classification; Series compensation; Double circuit transmission line; Weighted random vector functional link network (WRVFLN)	EXTREME LEARNING-MACHINE; PROTECTION SCHEME; COMBINED WAVELET; IDENTIFICATION	In this paper, empirical Wavelet transform (EWT), Hilbert transform (HT) and weighted random vector functional link network (WRVFLN) are integrated for fault detection, classification, and location estimation in a series capacitor compensated double circuit transmission line (SCCDCTL). The full cycle current signals from the point of fault inception are decomposed using EWT to extract three band-limited modes (BLMs). The four efficacious instantaneous features namely energy, Shannon entropy, the standard deviation of the magnitude, and crest factor are computed from the Hilbert transformed array of the BLMs to construct the feature vector. A diagonal matrix W is computed from the zero sequence current of original six current signals as a weighting factor to categorize the ground fault accurately. Numerous faults are generated with a wide variation of the system conditions such as fault resistance, fault inception angle, fault distance, percentage compensation level, source impedance, line parameters, load angle, and inter-circuit fault in MATLAB/Simulink environments. An efficient WRVFLN computational intelligence technique is proposed to recognize and estimate the location of the faults by taking the extracted suitable feature vector with weight factor as an input. The performances of WRVFLN are compared with the recently developed advanced classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM) in the MATLAB interface. The lesser computational complexity, faster learning speed, superior classification accuracy, accurate fault location estimation, and short event detection time prove that the proposed EWTHT WRVFLN method can be implemented in the real power system for online fault diagnosis. Finally, the developed system architecture is implemented on the reconfigurable digital field programmable gate array (FPGA) in ISE design suite 14.5 environments to verify the cogency of the proposed method in real-time. The feasibility of the proposed method is tested and validated by using the fast FPGA digital circuitry in a loop.																	0952-1976	1873-6769				FEB	2020	88								103336	10.1016/j.engappai.2019.103336													
J								Veracity handling and instance reduction in big data using interval type-2 fuzzy sets	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Instance reduction; Big data veracity; Interval type-2 fuzzy sets; Cluster centroid; Footprint of uncertainty	DYNAMIC PARAMETER ADAPTATION; SUPPORT VECTOR MACHINES; LOGIC SYSTEMS; CLUSTERING-ALGORITHM; VISUAL ASSESSMENT; DECISION-MAKING; OPTIMIZATION; UNCERTAINTY; GENERATION; PREDICTION	Within the aspect of big data, veracity refers to the existing uncertainty in the dataset. The continuous flow of unstructured data with unwanted noise may bring abnormality in the dataset making them unusable. In this paper, we propose a novel method to handle the veracity characteristic of the big data using the concept of footprint of uncertainty (FOU) in interval type-2 fuzzy sets (IT2 FSs). The proposed method helps in handling the veracity issue in big data and reduces the instances to a manageable extent. We have compared the results with the existing clustering based methods and examined the relationship between the clusters and the FOUs by comparing their centroids and defuzzified values. To scrutinize the validity of our results, we have also performed a number of additional experiments by appending extra instances to the datasets. To check its consistency and efficacy, the proposed methodology is assessed from three different aspects. Experimental result validates that the proposed method can suitably handle the veracity issue in big datasets and is efficient in reducing the instances.																	0952-1976	1873-6769				FEB	2020	88								103315	10.1016/j.engappai.2019.103315													
J								Fuzzy functional dependencies and linguistic interpretations employed in knowledge discovery tasks from relational databases	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Knowledge discovery; Data mining; Fuzzy functional dependency; Linguistic interpretation; Fuzzy logic; Fuzzy adverb	DATA MINING TECHNIQUES; SYSTEMS; LOGIC; OPERATORS; SUMMARIES; MODEL; SETS	Knowledge discovery from databases copes with several problems including the heterogeneity of data and interpreting the solution in an understandable and convenient form for domain experts. Fuzzy logic approaches based on the computing with words paradigm are very appealing since they offer the possibility to express useful knowledge from a large volume of data by linguistic terms, which are easily understandable for diverse users. In this paper, the novel descriptive data mining algorithm based on fuzzy functional dependencies has been proposed. In the first step, data are fuzzified, which ensures the same manipulation of crisp and fuzzy data. The data mining step is based on revealing fuzzy functional dependencies among considered attributes. In the final step, the mined knowledge is interpreted linguistically by the fuzzy modifiers and quantifiers. The proposed algorithm has been explained on illustrative data and tested on real-world dataset. Finally, its benefits, weak points and possible future research topics are discussed.																	0952-1976	1873-6769				FEB	2020	88								103395	10.1016/j.engappai.2019.103395													
J								A new grey model for traffic flow mechanics	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Traffic flow mechanics; Grey prediction model; Short-term traffic flow forecasting; Vehicle inflow rate; Vehicle jam flow rate	FORECASTING-MODEL; PREDICTION; CONSUMPTION	Accurate and real-time short-term traffic flow prediction is the core technology of an intelligent transportation system. In this paper, the vehicle conservation principle of traffic flow mechanics is applied to study the differential equation of traffic flow is established by analysing traffic flow parameters. Using the principle of grey difference information, and a grey model of traffic flow in a road section is proposed. This model obtains traffic flow information about traffic flow inflow and congestion via matrix least squares technology and obtains the time response function and modelling steps of the model using a mathematical analysis method, which is applied to short-term traffic flow prediction. The results of three short-term traffic flow cases show that the simulation and prediction results of the new model are better than those of other grey models and two machine learning methods. Relevant information about the traffic flow parameters obtained by the new model is consistent with an actual situation of traffic flow.																	0952-1976	1873-6769				FEB	2020	88								103350	10.1016/j.engappai.2019.103350													
J								A point-of-interest suggestion algorithm in Multi-source geo-social networks	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Location-based social networks; POI suggestion; Geo-social networks; Probabilistic graphical model; Gibbs sampling	MODEL	Newly emerging location-based social network (LBSN) services provide us with new platforms to share interests and individual experience based on their activity history. The problems of data sparsity and user distrust in LBSNs create a severe challenge for traditional recommender systems. Moreover, users' behaviors in LBSNs show an obvious spatio-temporal pattern. Valuable extra information from microblog-based social networks (MBSNs) can be utilized to improve the effectiveness of POI suggestion. In this study, we propose a latent probabilistic generative model called MTAS, which can accurately capture the underlying information in users' words extracted from both LBSNs and MBSNs by taking into consideration the decision probability, a latent variable indicating a user's tendency to publish a review in LBSNs or MBSNs. Then, the parameters of the MTAS model can be inferred by the Gibbs sampling method in an effective manner. Based on MTAS, we design an effective framework to fulfill the top-k suggestion. Extensive experiments on two real geo-social networks show that MTAS achieves better performance than existing state-of-the-art methods.																	0952-1976	1873-6769				FEB	2020	88								103374	10.1016/j.engappai.2019.103374													
J								Lazy reinforcement learning for real-time generation control of parallel cyber-physical-social energy systems	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Lazy reinforcement learning; Real-time generation control; Parallel cyber physical social energy systems; Artificial societies-computational experiments-parallel execution; Unified time scale	LOAD FREQUENCY CONTROL; ECONOMIC-DISPATCH; POWER; ALGORITHM; OPTIMIZATION; AWARENESS	To learn human intelligence, the social system/human system is added to a cyber-physical energy system in this paper. To accelerate the configuration process of the parameters of the cyber-physical energy system, parallel systems based on artificial societies-computational experiments-parallel execution are added to the cyber-physical energy system, i.e., a parallel cyber-physical-social energy system is proposed in this paper. This paper proposes a real-time generation control framework to replace the conventional generation control framework with multiple time scales, which consist of long-term time scale, short-term time scale, and real-time scale. Since a lazy operator employed into reinforcement learning, a lazy reinforcement learning is proposed for the real-time generation control framework. To reduce the real simulation time, multiple virtual parallel cyber-physical-social energy systems and a real parallel cyber-physical-social energy system are built for the real-time generation control of large-scale multi-area interconnected power systems. Compared with a total of 146016 conventional generation control algorithms and a relaxed artificial neural network in the simulation of IEEE 10-generator 39-bus New-England power system, the proposed lazy reinforcement learning based real-time generation control controller can obtain the highest control performance. The active power between two areas and the systemic frequency deviation can be reduced by the lazy reinforcement learning, and the simulation results verify the effectiveness and feasibility of the proposed lazy reinforcement learning based real-time generation control controller for the parallel cyber-physical-social energy systems.																	0952-1976	1873-6769				FEB	2020	88								103380	10.1016/j.engappai.2019.103380													
J								A segmentation-based approach for polyp counting in the wild	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Circular object detection; Semantic segmentation; Automated counting; Jellyfish polyp; Convolutional neural network	IMAGE-ANALYSIS; DENSE	We address the problem of jellyfish polyp counting in underwater images. Modern methods utilize convolutional neural networks for feature extraction and work in two stages. First, hypothetical regions are proposed at potential locations, the features of the regions are extracted and classified according to the contained object. Such methods typically require a dense grid for region proposals, explicitly test various scales and are prone to failure in densely populated regions. We propose a segmentation-based polyp counter - SegCo. A convolutional neural network is trained to produce locally-circular segmentation masks on the polyps, which are then detected by localizing circularly symmetric areas in the segmented image. Detection stage is efficient and avoids a greedy search over position and scales. SegCo outperforms the current state-of-the-art object detector RetinaNet (Lin et al., 2017) and the recent specialized polyp detection method PoCo (Vodopivec et al., 2018) by 2% and 24% in F-score, respectively, and sets a new state-of-the-art in polyp detection.																	0952-1976	1873-6769				FEB	2020	88								103399	10.1016/j.engappai.2019.103399													
J								SCH-GAN: Semi-Supervised Cross-Modal Hashing by Generative Adversarial Network	IEEE TRANSACTIONS ON CYBERNETICS										Semantics; Data models; Correlation; Generative adversarial networks; Training data; Predictive models; Gallium nitride; Cross-modal hashing; generative adversarial network (GAN); semi-supervised	CODES	Cross-modal hashing maps heterogeneous multimedia data into a common Hamming space to realize fast and flexible cross-modal retrieval. Supervised cross-modal hashing methods have achieved considerable progress by incorporating semantic side information. However, they heavily rely on large-scale labeled cross-modal training data which are hard to obtain, since multiple modalities are involved. They also ignore the rich information contained in the large amount of unlabeled data across different modalities, which can help to model the correlations between different modalities. To address these problems, in this paper, we propose a novel semi-supervised cross-modal hashing approach by generative adversarial network (SCH-GAN). The main contributions can be summarized as follows: 1) we propose a novel generative adversarial network for cross-modal hashing, in which the generative model tries to select margin examples of one modality from unlabeled data when given a query of another modality (e.g., giving a text query to retrieve images and vice versa). The discriminative model tries to distinguish the selected examples and true positive examples of the query. These two models play a minimax game so that the generative model can promote the hashing performance of the discriminative model and 2) we propose a reinforcement learning-based algorithm to drive the training of proposed SCH-GAN. The generative model takes the correlation score predicted by discriminative model as a reward, and tries to select the examples close to the margin to promote a discriminative model. Extensive experiments verify the effectiveness of our proposed approach, compared with nine state-of-the-art methods on three widely used datasets.																	2168-2267	2168-2275				FEB	2020	50	2					489	502		10.1109/TCYB.2018.2868826													
J								Scaling Up Dynamic Optimization Problems: A Divide-and-Conquer Approach	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Heuristic algorithms; Benchmark testing; Resource management; Power system dynamics; Sociology; Statistics; Computational resource allocation; cooperative coevolutionary (CC); decomposition; dynamic optimization problems; large-scale optimization problems; multipopulation	PARTICLE SWARM OPTIMIZER; COOPERATIVE COEVOLUTION; DIFFERENTIAL EVOLUTION; ROBUST OPTIMIZATION; EXPLOITING PROBLEM; ENVIRONMENTS; ALGORITHM; STRATEGY; TIME; FRAMEWORK	Scalability is a crucial aspect of designing efficient algorithms. Despite their prevalence, large-scale dynamic optimization problems are not well studied in the literature. This paper is concerned with designing benchmarks and frameworks for the study of large-scale dynamic optimization problems. We start by a formal analysis of the moving peaks benchmark (MPB) and show its nonseparable nature irrespective of its number of peaks. We then propose a composite MPB suite with exploitable modularity covering a wide range of scalable partially separable functions suitable for the study of large-scale dynamic optimization problems. The benchmark exhibits modularity, heterogeneity, and imbalance features to resemble real-world problems. To deal with the intricacies of large-scale dynamic optimization problems, we propose a decomposition-based coevolutionary framework which breaks a large-scale dynamic optimization problem into a set of lower-dimensional components. A novel aspect of the framework is its efficient bi-level resource allocation mechanism which controls the budget assignment to components and the populations responsible for tracking multiple moving optima. Based on a comprehensive empirical study on a wide range of large-scale dynamic optimization problems with up to 200-D, we show the crucial role of problem decomposition and resource allocation in dealing with these problems. The experimental results clearly show the superiority of the proposed framework over three other approaches in solving large-scale dynamic optimization problems.																	1089-778X	1941-0026				FEB	2020	24	1					1	15		10.1109/TEVC.2019.2902626													
J								Self-Regulated Evolutionary Multitask Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Evolutionary algorithm (EA); knowledge transfer; multitask optimization (MTO); multitasking		Evolutionary multitask optimization (EMTO) is a newly emerging research area in the field of evolutionary computation. It investigates how to solve multiple optimization problems (tasks) at the same time via evolutionary algorithms (EAs) to improve on the performance of solving each task independently, assuming if some component tasks are related then the useful knowledge (e.g., promising candidate solutions) acquired during the process of solving one task may assist in (and also benefit from) solving the other tasks. In EMTO, task relatedness is typically unknown in advance and needs to be captured via EA's population. Since the population of an EA can only cover a subregion of the solution space and keeps evolving during the search, thus captured task relatedness is local and dynamic. The multifactorial EA (MFEA) is one of the most representative EMTO techniques, inspired by the bio-cultural model of multifactorial inheritance, which transmits both biological and cultural traits from the parents to the offspring. MFEA has succeeded in solving various multitask optimization (MTO) problems. However, the intensity of knowledge transfer in MFEA is determined via its algorithmic configuration without considering the degree of task relatedness, which may prevent the effective sharing and utilization of the useful knowledge acquired in related tasks. To address this issue, we propose a self-regulated EMTO (SREMTO) algorithm to automatically adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared, and utilized to a great extent. We compare SREMTO with MFEA and its variants as well as the single-task optimization counterpart of SREMTO on two MTO test suites, which demonstrates the superiority of SREMTO.																	1089-778X	1941-0026				FEB	2020	24	1					16	28		10.1109/TEVC.2019.2904696													
J								Utilizing the Correlation Between Constraints and Objective Function for Constrained Evolutionary Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Linear programming; Optimization; Correlation; Sociology; Humanoid robots; Indexes; Constrained optimization; constraints; correlation; evolutionary algorithms (EAs); humanoid robots; objective function	DIFFERENTIAL EVOLUTION; MULTIOBJECTIVE OPTIMIZATION; PENALTY-FUNCTION; ADAPTATION; ALGORITHMS; STRATEGY; RANKING	When solving constrained optimization problems by evolutionary algorithms, the core issue is to balance constraints and objective function. This paper is the first attempt to utilize the correlation between constraints and objective function to keep this balance. First of all, the correlation between constraints and objective function is mined and represented by a correlation index. Afterward, a weighted sum updating approach and an archiving and replacement mechanism are proposed to make use of this correlation index to guide the evolution. By the above process, a novel constrained optimization evolutionary algorithm is presented. Experiments on a broad range of benchmark test functions indicate that the proposed method shows better or at least competitive performance against other state-of-the-art methods. Moreover, the proposed method is applied to the gait optimization of humanoid robots.																	1089-778X	1941-0026				FEB	2020	24	1					29	43		10.1109/TEVC.2019.2904900													
J								Tackling Large-Scale and Combinatorial Bi-Level Problems With a Genetic Programming Hyper-Heuristic	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Bi-level optimization; genetic programming; hyper-heuristics; pricing in the cloud; Stackelberg games	EVOLUTIONARY ALGORITHMS; GRAMMATICAL EVOLUTION; BILEVEL MODEL; OPTIMIZATION	Combinatorial bi-level optimization remains a challenging topic, especially when the lower-level is an NP-hard problem. In this paper, we tackle large-scale and combinatorial bi-level problems using GP hyper-heuristics, i.e., an approach that permits to train heuristics like a machine learning model. Our contribution aims at targeting the intensive and complex lower-level optimizations that occur when solving a large-scale and combinatorial bi-level problem. For this purpose, we consider hyper-heuristics through heuristic generation. Using a GP hyper-heuristic approach, we train greedy heuristics in order to make them more reliable when encountering unseen lower-level instances that could be generated during bi-level optimization. To validate our approach referred to as GA+AGH, we tackle instances from the bi-level cloud pricing optimization problem (BCPOP) that model the trading interactions between a cloud service provider and cloud service customers. Numerical results demonstrate the abilities of the trained heuristics to cope with the inherent nested structure that makes bi-level optimization problems so hard. Furthermore, it has been shown that training heuristics for lower-level optimization permits to outperform human-based heuristics and metaheuristics which constitute an excellent outcome for bi-level optimization.																	1089-778X	1941-0026				FEB	2020	24	1					44	56		10.1109/TEVC.2019.2906581													
J								A Theoretical Guideline for Designing an Effective Adaptive Particle Swarm	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Particle swarm optimization; Convergence; Acceleration; Linear programming; Guidelines; Correlation; Indexes; Correlation; covariance; particle swarm optimization (PSO); stability	OPTIMIZATION ALGORITHM; CONVERGENCE ANALYSIS; STRATEGIES	In this paper, the underlying assumptions that have been used for designing adaptive particle swarm optimization (PSO) algorithms in the past years are theoretically investigated. I relate these assumptions to the movement patterns of particles controlled by coefficient values (inertia weight and acceleration coefficients) and introduce three factors, namely the autocorrelation of the particle positions, the average movement distance of the particle in each iteration, and the focus of the search, that describe these movement patterns. I show how these factors represent movement patterns of a particle within a swarm and how they are affected by particle coefficients (i.e., inertia weight and acceleration coefficients). I derive equations that provide exact coefficient values to guarantee to achieve the desired movement pattern defined by these three factors within a swarm. I then relate these movements to the searching capability of particles and provide a guideline for designing potentially successful adaptive methods to control coefficients in particle swarm. Finally, I propose a new simple time adaptive particle swarm and compare its results with previous adaptive particle swarm approaches. Experiments show that the theoretical findings indeed provide a beneficial guideline for the successful adaptation of the coefficients in the PSO algorithm.																	1089-778X	1941-0026				FEB	2020	24	1					57	68		10.1109/TEVC.2019.2906894													
J								Multifactorial Evolutionary Algorithm With Online Transfer Parameter Estimation: MFEA-II	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Task analysis; Multitasking; Evolutionary computation; Knowledge transfer; Bayes methods; Machine learning; Evolutionary multitasking; general optimization intelligence (GOI); intertask synergies; multifactorial optimization; online similarity learning	BUILDING-BLOCKS; OPTIMIZATION; MULTITASKING	Humans rarely tackle every problem from scratch. Given this observation, the motivation for this paper is to improve optimization performance through adaptive knowledge transfer across related problems. The scope for spontaneous transfers under the simultaneous occurrence of multiple problems unveils the benefits of multitasking. Multitask optimization has recently demonstrated competence in solving multiple (related) optimization tasks concurrently. Notably, in the presence of underlying relationships between problems, the transfer of high-quality solutions across them has shown to facilitate superior performance characteristics. However, in the absence of any prior knowledge about the intertask synergies (as is often the case with general black-box optimization), the threat of predominantly negative transfer prevails. Susceptibility to negative intertask interactions can impede the overall convergence behavior. To allay such fears, in this paper, we propose a novel evolutionary computation framework that enables online learning and exploitation of the similarities (and discrepancies) between distinct tasks in multitask settings, for an enhanced optimization process. Our proposal is based on the principled theoretical arguments that seek to minimize the tendency of harmful interactions between tasks, based on a purely data-driven learning of relationships among them. The efficacy of our proposed method is validated experimentally on a series of synthetic benchmarks, as well as a practical study that provides insights into the behavior of the method in the face of several tasks occurring at once.																	1089-778X	1941-0026				FEB	2020	24	1					69	83		10.1109/TEVC.2019.2906927													
J								Toward a Matrix-Free Covariance Matrix Adaptation Evolution Strategy	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Covariance matrices; Sociology; Optimization; History; Gaussian distribution; Indexes; Black-box optimization; covariance matrix adaptation evolution strategy (CMA-ES); differential evolution (DE)	DIFFERENTIAL EVOLUTION; CMA	In this paper, we discuss a method for generating new individuals such that their mean vector and the covariance matrix are defined by formulas analogous to the covariance matrix adaptation evolution strategy (CMA-ES). In contrast to CMA-ES, which generates new individuals using multivariate Gaussian distribution with an explicitly defined covariance matrix, the introduced method uses combinations of difference vectors between archived individuals and univariate Gaussian random vectors along directions of past shifts of the population midpoints. We use this method to formulate the differential evolution strategy (DES)-an algorithm that is a crossover between differential evolution (DE) and CMA-ES. The numerical results presented in this paper indicate that DES is competitive against CMA-ES in performing both local and global optimization.																	1089-778X	1941-0026				FEB	2020	24	1					84	98		10.1109/TEVC.2019.2907266													
J								A Many-Objective Evolutionary Algorithm With Pareto-Adaptive Reference Points	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Shape; Optimization; Sociology; Statistics; Convergence; Evolutionary computation; Estimation; Dominance resistant solutions; many-objective optimization; nadir point estimation; Pareto-adaptive reference points	NONDOMINATED SORTING APPROACH; OPTIMIZATION PROBLEMS; DECOMPOSITION; SELECTION; MOEA/D; VALUES	We propose a new many-objective evolutionary algorithm with Pareto-adaptive reference points. In this algorithm, the shape of the Pareto-optimal front (PF) is estimated based on a ratio of Euclidean distances. If the estimated shape is likely to be convex, the nadir point is used as the reference point to calculate the convergence and diversity indicators for individuals. Otherwise, the reference point is set to the ideal point. In addition, the estimation of the nadir point is different from what was widely used in the literature. The nadir point, together with the ideal point, provides a feasible way to deal with dominance resistant solutions, which are difficult to be detected and eliminated in Pareto-based algorithms. The proposed algorithm is compared with the state-of-the-art many-objective optimization algorithms on a number of unconstrained and constrained test problems with up to 15 objectives. The experimental results show that it performs better than other algorithms in most of the test instances. Moreover, the new algorithm shows good performance on problems whose PFs are irregular (being discontinuous, degenerated, bent, or mixed). The observed high performance and inherent good properties (such as being free of weight vectors and control parameters) make the new proposal a promising tool for other similar problems.																	1089-778X	1941-0026				FEB	2020	24	1					99	113		10.1109/TEVC.2019.2909636													
J								Automatic Niching Differential Evolution With Contour Prediction Approach for Multimodal Optimization Problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Affinity propagation clustering (APC); contour prediction approach (CPA); differential evolution (DE); multimodal optimization problems (MMOPs); niching techniques	PARTICLE SWARM OPTIMIZATION; MULTIOBJECTIVE OPTIMIZATION; GENETIC ALGORITHM; ENSEMBLE; MUTATION	Niching techniques have been widely incorporated into evolutionary algorithms (EAs) for solving multimodal optimization problems (MMOPs). However, most of the existing niching techniques are either sensitive to the niching parameters or require extra fitness evaluations (FEs) to maintain the niche detection accuracy. In this paper, we propose a new automatic niching technique based on the affinity propagation clustering (APC) and design a novel niching differential evolution (DE) algorithm, termed as automatic niching DE (ANDE), for solving MMOPs. In the proposed ANDE algorithm, APC acts as a parameter-free automatic niching method that does not need to predefine the number of clusters or the cluster size. Also, it can facilitate locating multiple peaks without extra FEs. Furthermore, the ANDE algorithm is enhanced by a contour prediction approach (CPA) and a two-level local search (TLLS) strategy. First, the CPA is a predictive search strategy. It exploits the individual distribution information in each niche to estimate the contour landscape, and then predicts the rough position of the potential peak to help accelerate the convergence speed. Second, the TLLS is a solution refine strategy to further increase the solution accuracy after the CPA roughly predicting the peaks. Compared with the other state-of-the-art DE and non-DE multimodal algorithms, even the winner of competition on multimodal optimization, the experimental results on 20 widely used benchmark functions illustrate the superiority of the proposed ANDE algorithm.																	1089-778X	1941-0026				FEB	2020	24	1					114	128		10.1109/TEVC.2019.2910721													
J								A Graph-Based Fuzzy Evolutionary Algorithm for Solving Two-Echelon Vehicle Routing Problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Satellites; Routing; Vehicle routing; Sociology; Statistics; Evolutionary computation; Optimization; Assignment graph; evolutionary algorithm (EA); fuzzy subset; two-echelon vehicle routing problem (2E-VRP)	SATELLITE LOCATION; MODELS; DEPOT	Two-echelon vehicle routing problem (2E-VRP) is a challenging problem that involves both the strategic and tactical planning decisions on both echelons. The satellite locations and the customer distribution affect the cost of different components on the second echelon, thus the possibilities of satellite-to-customer assignment complicates the problem. In this paper, we propose a graph-based fuzzy evolutionary algorithm for solving 2E-VRP. The proposed method integrates a graph-based fuzzy assignment scheme into an iteratively evolutionary learning process to minimize the total cost. To resolve the possibilities of the satellite-to-customer assignment, graph-based fuzzy operator is used to take advantage of population evolution and avoid excessive fitness evaluations of unpromising moves in different satellites. Each offspring is produced via graph-based fuzzy assignment procedure out of an assignment graph from parent individuals, and fuzzy local search procedure is used to further improve the offspring. The experimental results on the public test sets demonstrate the competitiveness of the proposed method.																	1089-778X	1941-0026				FEB	2020	24	1					129	141		10.1109/TEVC.2019.2911736													
J								A Similarity-Based Cooperative Co-Evolutionary Algorithm for Dynamic Interval Multiobjective Optimization Problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Heuristic algorithms; Robots; Evolutionary computation; Programming; Probability distribution; Sociology; Cooperative co-evolutionary optimization; dynamic optimization; interval similarity; multiobjective optimization; response strategy	CLONAL COEVOLUTIONARY ALGORITHM; INTERACTIVE GENETIC ALGORITHM; SUPPLY CHAIN; POPULATION; PREDICTION; UNCERTAINTIES	Dynamic interval multiobjective optimization problems (DI-MOPs) are very common in real-world applications. However, there are few evolutionary algorithms (EAs) that are suitable for tackling DI-MOPs up to date. A framework of dynamic interval multiobjective cooperative co-evolutionary optimization based on the interval similarity is presented in this paper to handle DI-MOPs. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two subpopulations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem. The proposed algorithm is applied to eight benchmark optimization instances as well as a multiperiod portfolio selection problem and compared with five state-of-the-art EAs. The experimental results reveal that the proposed algorithm is very competitive on most optimization instances.																	1089-778X	1941-0026				FEB	2020	24	1					142	156		10.1109/TEVC.2019.2912204													
J								Toward Efficient Design Space Exploration for Fault-Tolerant Multiprocessor Systems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Bi-level optimization; cooperative co-evolutionary algorithm (CCEA); design space exploration (DSE); fault-tolerance; multiprocessor system; task mapping	EMBEDDED SYSTEMS; COOPERATIVE COEVOLUTION; MEMETIC ALGORITHMS; CO-SYNTHESIS; TIME; OPTIMIZATION	The design space exploration (DSE) of fault-tolerant multiprocessor systems is very complex, as it contains three interacting NP-hard problems: 1) task hardening; 2) task mapping; and 3) task scheduling. In addition, replication-based task hardening can introduce new tasks, called replicas, into the system, enlarging the design space further. As a population-based global optimization algorithm, evolutionary algorithms (EAs) have been widely used to explore this huge design space over the last decade. However, as analyzed in this paper, the search space of previous works is highly redundant, resulting in poor efficiency and scalability. This paper proposes an efficient EA-based DSE method for the design of large-scale fault-tolerant multiprocessor systems. The main novelties of this paper include: 1) mapping exploration is explicitly separated, i.e., task mapping is optimized during the evolutionary search, while replica mapping is constructed heuristically according to the current co-synthesis state; 2) the design space of task hardening and task mapping are explored independently by a cooperative co-EA; and 3) as a complement to global search of EA, problem-specific local search operators are designed for both task hardening and task mapping, reducing the number of fitness evaluations required. Compared with the most relevant state-of-the-art method, the superiority of the proposed method is demonstrated using extensive experiments on a large set of benchmarks, e.g., 1.75 x similar to 2.50 x better results can be obtained on the benchmarks of 300 tasks and 30 processors.																	1089-778X	1941-0026				FEB	2020	24	1					157	169		10.1109/TEVC.2019.2912726													
J								Multiple Reference Points-Based Decomposition for Multiobjective Feature Selection in Classification: Static and Dynamic Mechanisms	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Feature extraction; Heuristic algorithms; Optimization; Task analysis; Approximation algorithms; Sociology; Statistics; Classification; feature selection; multiobjective evolutionary algorithm based on decomposition (MOEA; D); multiobjective optimization; partially conflicting	DIFFERENTIAL EVOLUTION; GENETIC ALGORITHM; OPTIMIZATION; MOEA/D; PERFORMANCE	Feature selection is an important task in machine learning that has two main objectives: 1) reducing dimensionality and 2) improving learning performance. Feature selection can be considered a multiobjective problem. However, it has its problematic characteristics, such as a highly discontinuous Pareto front, imbalance preferences, and partially conflicting objectives. These characteristics are not easy for existing evolutionary multiobjective optimization (EMO) algorithms. We propose a new decomposition approach with two mechanisms (static and dynamic) based on multiple reference points under the multiobjective evolutionary algorithm based on decomposition (MOEA/D) framework to address the above-mentioned difficulties of feature selection. The static mechanism alleviates the dependence of the decomposition on the Pareto front shape and the effect of the discontinuity. The dynamic one is able to detect regions in which the objectives are mostly conflicting, and allocates more computational resources to the detected regions. In comparison with other EMO algorithms on 12 different classification datasets, the proposed decomposition approach finds more diverse feature subsets with better performance in terms of hypervolume and inverted generational distance. The dynamic mechanism successfully identifies conflicting regions and further improves the approximation quality for the Pareto fronts.																	1089-778X	1941-0026				FEB	2020	24	1					170	184		10.1109/TEVC.2019.2913831													
J								R2-Based Hypervolume Contribution Approximation	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Monte Carlo methods; Optimization; Nickel; Approximation methods; Sociology; Indexes; Evolutionary multiobjective optimization (EMO); hypervolume contribution; R2 indicator	ALGORITHM	In this letter, a new hypervolume contribution approximation method is proposed which is formulated as an R2 indicator. The basic idea of the proposed method is to use different line segments only in the hypervolume contribution region for the hypervolume contribution approximation. Comparing with a traditional method which is based on the R2 indicator to approximate the hypervolume, the new method can directly approximate the hypervolume contribution and will utilize all the direction vectors only in the hypervolume contribution region. The new method, the traditional method, and the Monte Carlo sampling method together with two exact methods are compared through comprehensive experiments. Our results show the advantages of the new method over the other methods. Comparing with the other two approximation methods, the new method achieves the best performance for comparing hypervolume contributions of different solutions and identifying the solution with the smallest hypervolume contribution. Comparing with the exact methods, the new method is computationally efficient in high-dimensional spaces where the exact methods are impractical to use.																	1089-778X	1941-0026				FEB	2020	24	1					185	192		10.1109/TEVC.2019.2909271													
J								New models for generating hard random boolean formulas and disjunctive logic programs	ARTIFICIAL INTELLIGENCE										Answer set programming; Random boolean formulas; Phase transition; Random logic programs	SAT	We propose two models of random quantified boolean formulas and their natural random disjunctive logic program counterparts. The models extend the standard models of random k-CNF formulas and the Chen-Interian model of random 2QBFs. The first model controls the generation of programs and QSAT formulas by imposing a specific structure on rules and clauses, respectively. The second model is based on a family of QSAT formulas in a non-clausal form. We provide theoretical bounds for the phase transition region in our models, and show experimentally the presence of the easy-hard-easy pattern and its alignment with the location of the phase transition. We show that boolean formulas and logic programs from our models are significantly harder than those obtained from the standard k-CNF and Chen-Interian models, and that their combination yields formulas and programs that are "super-hard" to evaluate. We also provide evidence suggesting that formulas from one of our models are well suited for assessing solvers tuned to real-world instances. Finally, it is noteworthy that, to the best of our knowledge, our models and results on random disjunctive logic programs are the first of their kind. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103185	10.1016/j.artint.2019.103185													
J								Mind the gaps: Assuring the safety of autonomous systems from an engineering, ethical, and legal perspective	ARTIFICIAL INTELLIGENCE										Safety; Autonomous systems; Artificial intelligence; Law; Ethics	RESPONSIBILITY; ROBOTS	This paper brings together a multi-disciplinary perspective from systems engineering, ethics, and law to articulate a common language in which to reason about the multifaceted problem of assuring the safety of autonomous systems. The paper's focus is on the "gaps" that arise across the development process: the semantic gap, where normal conditions for a complete specification of intended functionality are not present; the responsibility gap, where normal conditions for holding human actors morally responsible for harm are not present; and the liability gap, where normal conditions for securing compensation to victims of harm are not present. By categorising these "gaps" we can expose with greater precision key sources of uncertainty and risk with autonomous systems. This can inform the development of more detailed models of safety assurance and contribute to more effective risk control. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103201	10.1016/j.artint.2019.103201													
J								Governing convergence of Max-sum on DCOPs through damping and splitting	ARTIFICIAL INTELLIGENCE										Distributed Constraint Optimization; Incomplete inference algorithms; Max-sum	DECENTRALIZED COORDINATION; CONSTRAINT OPTIMIZATION; BELIEF PROPAGATION; ALGORITHMS; ADOPT	Max-sum is a version of Belief Propagation, used for solving DCOPs. In tree-structured problems, Max-sum converges to the optimal solution in linear time. Unfortunately, when the constraint graph representing the problem includes multiple cycles (as in many standard DCOP benchmarks), Max-sum does not converge and explores low quality solutions. Recent attempts to address this limitation proposed versions of Max-sum that guarantee convergence, while ignoring some of the problem's constraints. Damping is a method that is often used for increasing the chances that Belief Propagation will converge. That being said, it has not been suggested for inclusion in the algorithms that propose Max-sum for solving DCOPs. In this paper we advance the research on incomplete-inference DCOP algorithms by: 1) investigating the effect of damping on Max-sum. We prove that, while damping slows down the propagation of information among agents, on tree-structured graphs, Max-sum with damping is guaranteed to converge to the optimal solution in weakly polynomial time; and 2) proposing a novel method for adjusting the level of asymmetry in the factor graph, in order to achieve a balance between exploitation and exploration, when using Max-sum for solving DCOPs. By converting a standard factor graph to an equivalent split constraint factor graph (SCFG), in which each function-node is split into two function nodes, we can control the level of asymmetry for each constraint. Our empirical results demonstrate a drastic improvement in the performance of Max-sum when using damping (referred to herein as Damped Max-sum, DMS). However, in contrast to the common assumption that Max-sum performs best when converging, we demonstrate that non converging versions perform efficient exploration, and produce high quality results, when implemented within an anytime framework. On most standard benchmarks, the best results were achieved using versions with a high damping factor, which outperformed existing incomplete DCOP algorithms. In addition, our results imply that by applying DMS to SCFGs with a minor level of asymmetry, we can find high quality solutions within a small number of iterations, even without using an anytime framework. We prove that for a factor graph with a single constraint, if this constraint is split symmetrically, Max-sum applied to the resulting cycle is guaranteed to converge to the optimal solution. We further demonstrate that for an asymmetric split, convergence is not guaranteed. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103212	10.1016/j.artint.2019.103212													
J								Recursively modeling other agents for decision making: A research perspective	ARTIFICIAL INTELLIGENCE										Decision theory; Game theory; Hierarchical beliefs; Multiagent systems; Recursive modeling; Theory of mind	MULTIAGENT; COORDINATION	Individuals exhibit theory of mind, attributing beliefs, intent, and mental states to others as explanations of observed actions. Dennett's intentional stance offers an analogous abstraction for computational agents seeking to understand, explain, or predict others' behaviors. These recognized theories provide a formal basis to ongoing investigations of recursive modeling. We review and situate various frameworks for recursive modeling that have been studied in game- and decision-theories, and have yielded methods useful to Al researchers. Sustained attention given to these frameworks has produced new analyses and methods with an aim toward making recursive modeling practicable. Indeed, we also review some emerging uses and the insights these yielded, which are indicative of pragmatic progress in this area. The significance of these frameworks is that higher-order reasoning is critical to correctly recognizing others' intent or outthinking opponents. Such reasoning has been utilized in academic, business, military, security, and other contexts both to train and inform decision-making agents in organizational and strategic contexts, and also to more realistically predict and best respond to other agents' intent. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103202	10.1016/j.artint.2019.103202													
J								Design and results of the Second International Competition on Computational Models of Argumentation	ARTIFICIAL INTELLIGENCE										Abstract argumentation; Solver competition; Computational logic	SET PROGRAMMING ENCODINGS; ABSTRACT ARGUMENTATION; STRUCTURED ARGUMENTATION; SEMANTICS; ENUMERATION; COMPLEXITY; FRAMEWORK; SOLVERS	Argumentation is a major topic in the study of Artificial Intelligence. Since the first edition in 2015, advancements in solving (abstract) argumentation frameworks are assessed in competition events, similar to other closely related problem solving technologies. In this paper, we report about the design and results of the Second International Competition on Computational Models of Argumentation, which has been jointly organized by TU Dresden (Germany), TU Wien (Austria), and the University of Genova (Italy), in affiliation with the 2017 International Workshop on Theory and Applications of Formal Argumentation. This second edition maintains some of the design choices made in the first event, e.g. the I/O formats, the basic reasoning problems, and the organization into tasks and tracks. At the same time, it introduces significant novelties, e.g. three additional prominent semantics, and an instance selection stage for classifying instances according to their empirical hardness. (C) 2019 Published by Elsevier B.V.																	0004-3702	1872-7921				FEB	2020	279								103193	10.1016/j.artint.2019.103193													
J								Clause vivification by unit propagation in CDCL SAT solvers	ARTIFICIAL INTELLIGENCE										Satisfiability; Conflict-driven clause learning; Clause vivification; Redundant literal	SEARCH ALGORITHM; GRASP	Original and learnt clauses in Conflict-Driven Clause Learning (CDCL) SAT solvers often contain redundant literals. This may have a negative impact on solver performance, because redundant literals may deteriorate both the effectiveness of Boolean constraint propagation and the quality of subsequent learnt clauses. To overcome this drawback, we propose a clause vivification approach that eliminates redundant literals by applying unit propagation. The proposed clause vivification is activated before the SAT solver triggers some selected restarts, and only affects a subset of original and learnt clauses, which are considered to be more relevant according to metrics like the literal block distance (LBD). Moreover, we conducted an empirical investigation with instances coming from the hard combinatorial and application categories of recent SAT competitions. The results show that a significant number of additional instances are solved when the proposed approach is incorporated into five of the best performing CDCL SAT solvers (Glucose, TC_Glucose, COMiniSatPS, MapleCOMSPS and MapleCOMSPS_LRB). More importantly, the empirical investigation includes an in-depth analysis of the effectiveness of clause vivification. It is worth mentioning that one of the SAT solvers described here was ranked first in the main track of SAT Competition 2017 thanks to the incorporation of the proposed clause vivification. That solver was further improved in this paper and won the bronze medal in the main track of SAT Competition 2018. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103197	10.1016/j.artint.2019.103197													
J								Preference elicitation and robust winner determination for single- and multi-winner social choice	ARTIFICIAL INTELLIGENCE										Social choice; Voting; Preference elicitation; Robust optimization; Partial preferences; Minimax regret; Decision theory	PROPORTIONAL REPRESENTATION; OPTIMIZATION PROBLEMS; COMPLEXITY; DECISIONS; RANKING; DOMAINS	The use of voting schemes based on rankings of alternatives to solve social choice problems can often impose significant burden on voters, both in terms of communication and cognitive requirements. In this paper, we develop techniques for preference elicitation in voting settings (i.e., vote elicitation) that can alleviate this burden by minimizing the amount of preference information needed to find (approximately or exactly) optimal outcomes. We first describe robust optimization techniques for determining winning alternatives given partial preference information (i.e., partial rankings) using the notion of minimax regret. We show that the corresponding computational problem is tractable for some important voting rules, and intractable for others. We then use the solution to the minimax-regret optimization as the basis for vote elicitation schemes that determine appropriate preference queries for voters to quickly reduce potential regret. We apply these techniques to multi-winner social choice problems as well, in which a slate of alternatives must be selected, developing both exact and greedy robust optimization procedures. Empirical results on several data sets validate the effectiveness of our techniques. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103203	10.1016/j.artint.2019.103203													
J								Train-O-Matic: Supervised Word Sense Disambiguation with no (manual) effort	ARTIFICIAL INTELLIGENCE										Word Sense Disambiguation; Corpus Generation; Word Sense Distribution learning; Multilinguality	CORPUS STATISTICS; FRAMEWORK; KNOWLEDGE	Word Sense Disambiguation (WSD) is the task of associating the correct meaning with a word in a given context. WSD provides explicit semantic information that is beneficial to several downstream applications, such as question answering, semantic parsing and hypernym extraction. Unfortunately, WSD suffers from the well-known knowledge acquisition bottleneck problem: it is very expensive, in terms of both time and money, to acquire semantic annotations for a large number of sentences. To address this blocking issue we present Train-O-Matic, a knowledge-based and language-independent approach that is able to provide millions of training instances annotated automatically with word meanings. The approach is fully automatic, i.e., no human intervention is required, and the only type of human knowledge used is a task-independent WordNet-like resource. Moreover, as the sense distribution in the training set is pivotal to boosting the performance of WSD systems, we also present two unsupervised and language-independent methods that automatically induce a sense distribution when given a simple corpus of sentences. We show that, when the learned distributions are taken into account for generating the training sets, the performance of supervised methods is further enhanced. Experiments have proven that Train-O-Matic on its own, and also coupled with word sense distribution learning methods, lead a supervised system to achieve state-of-the-art performance consistently across gold standard datasets and languages. Importantly, we show how our sense distribution learning techniques aid Train-O-Matic to scale well over domains, without any extra human effort. To encourage future research, we release all the training sets in 5 different languages and the sense distributions for each domain of SemEval-13 and SemEval-15 at http://trainomatic.org. (C) 2019 The Authors. Published by Elsevier B.V.																	0004-3702	1872-7921				FEB	2020	279								103215	10.1016/j.artint.2019.103215													
J								Landmark-based approaches for goal recognition as planning	ARTIFICIAL INTELLIGENCE										Goal recognition; AI planning; Landmarks	STRIPS	Recognizing goals and plans from complete or partial observations can be efficiently achieved through automated planning techniques. In many applications, it is important to recognize goals and plans not only accurately, but also quickly. To address this challenge, we develop novel goal recognition approaches based on planning techniques that rely on planning landmarks. In automated planning, landmarks are properties (or actions) that cannot be avoided to achieve a goal. We show the applicability of a number of planning techniques with an emphasis on landmarks for goal recognition tasks in two settings: (1) we use the concept of landmarks to develop goal recognition heuristics; and (2) we develop a landmark-based filtering method to refine existing planning-based goal and plan recognition approaches. These recognition approaches are empirically evaluated in experiments over several classical planning domains. We show that our goal recognition approaches yield not only accuracy comparable to (and often higher than) other state-of-the-art techniques, but also result in substantially faster recognition time over existing techniques. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				FEB	2020	279								103217	10.1016/j.artint.2019.103217													
J								Confusion analysis in phoneme based speech recognition in Hindi	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Phoneme; Speech recognition; Hidden Markov Model; PLP	MODEL; FEATURES	Phoneme recognition is an essential step in the development of a speech recognition system (SRS), as phonemes are fundamental building blocks in a spoken language. This research work aimed to present phoneme recognition with systematic confusion analysis for the Hindi language. The accuracy of phoneme recognition is the foundation for developing an efficient SRS. Therefore, the systematic confusion analysis for phoneme recognition is essential to improve speech recognition performance. Experiments conducted on Continuous Hindi speech corpus for phoneme recognition with speaker-dependent mode using Hidden Markov Model (HMM) based tool kit HTK. Feature extraction technique Perceptual Linear Predictive Coefficient (PLP) was used with five states Monophones HMM model. Tests were performed for exploring the recognition of Hindi vowels and consonants. Confusion matrices were presented for both vowels and consonants with analysis and possible solutions. During systematic analysis, the vowels were divided into front, middle, and back vowels while consonants were categorized based on place of articulation and manner of articulation. Research findings show that some Hindi phonemes have significant effects on speech recognition. The investigations also reveal that some Hindi phonemes are mostly confused, and some phonemes have more deletions and insertions. The research further demonstrates that the words made of less number of phonemes show more insertion errors. It was also found that most of the Hindi sentences end with some specific words. These particular words can be used to reduce the search place in language modeling for improving speech recognition. The research findings can be utilized to enhance the performance of the speech recognition system by selecting suitable feature extraction techniques and classification techniques for phonemes. The outcome of the research can also be used to develop improved pronunciation dictionaries and designing the text for developing phonetically balanced speech corpus for improvement in speech recognition. Experimental results show an average corrected recognition score of 70% for vowel class and consonant categories, the maximum average corrected recognition score of 94% was obtained with palatal sounds, and the lowest average corrected recognition score of 54% was achieved with liquid sounds. The comparative analysis of the presented work was made to similar existing works.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4213	4238		10.1007/s12652-020-01703-x		FEB 2020											
J								Modified adaptive neuro fuzzy inference system based load balancing for virtual machine with security in cloud computing environment	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cloud computing; Firefly algorithm (FA); Load balancing and security		In a heterogeneous environment, computation over internet is provided by a popular paradigm called cloud computing. In a cloud heterogeneous environment, service providing has various difficulties. Based on service type, difficulties differ. On cloud server, high load is produced by huge amount of request from various users for accessing various applications. Security and balancing of load are major concerns. In cloud environment, NP-hard optimization problem corresponds to load balancing. Dynamic load balancing is handled by various methods. They are designed for enhancing workload distribution process between nodes. Overload avoidance, minimization of average response time, data processing time and optimum utilization of resources are the major aim of those methods. An optimal load balancing technique should improve the turnaround time and maximum CPU utilization. Because of its opaqueness nature of cloud, security is a biggest challenge. According to Forbes, with introduction of General Data Protection Regulation security in cloud continue to be an issue with cloud computing. In the existing system, a fuzzy based hybrid load balancing algorithm is utilized and the results provided are not satisfactory. There are opportunities for improving CPU utilization and turnaround time and in terms of security. In this proposed research work, dynamic load balancing in a heterogeneous environment is handled by Modified Adaptive Neuro Fuzzy Inference System (MANFIS). Parameters of MANFIS are optimized by introducing Fire-fly Algorithm. Security is imposed on user authentication by using the Enhanced Elliptic Curve Cryptography. This is a password-less mechanism to authenticate users. The proposed work attains satisfactory results by proper resource utilization. An experimental result shows that proposed work exhibits better performance by improving the turnaround time and maximizing the CPU utilization and providing secured access to data.																	1868-5137	1868-5145															10.1007/s12652-020-01728-2		FEB 2020											
J								Removal of high density salt and pepper noise in color image through modified cascaded filter	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Color image; MCF; DMF; UTMF; PSNR; IEF	IMPULSE NOISE; MEDIAN FILTERS; ALGORITHM	A modified cascaded filter (MCF) for the restoration of color pictures that are extremely corrupted by salt and pepper noise and random valued impulse noise are projected in this article. MCF algorithm restores the noisy pixel by trimmed median value while other pixel values, 0's and 255's are present in the selected window using decision based median filter (DMF) and when the pixel values are 0's and 255's then the noise pixel is replaced by mean value of all the elements present in the selected window using unsymmetrical trimmed mean filtering. This modified cascaded filter proves better results than the standard median filter, DMF, and alpha trimmed median filter, UTMF. The MCF is analyzed against various color images and it provides superior peak signal-to-noise ratio and image enhancement factor.																	1868-5137	1868-5145															10.1007/s12652-020-01737-1		FEB 2020											
J								Soft computing-based semi-automated test case selection using gradient-based techniques	SOFT COMPUTING										Software testing; Test cases (TC); Test case selection (TCS); Gradient descent (GD); Simulated annealing (SA); High gradient descending simulated annealing		Software testing has been one very time-consuming and expensive phases in the process of software development. It needs plenty of effort in the development of tools for the process to reduce both cost and time in the development of software. The test cases were the input parameters along with expected results and conditions of execution that are used for testing. The test case selection (TCS) is approaches that aim at the selection of subsets for the test cases in a particular domain based on the criterion of interest. The primary aim is the elimination of unwanted and redundant test data aside from maximizing fault detection. Optimization techniques are applied for TCS to efficient testing. A local method of search is very popular among algorithms for the performance of optimization which is known as the gradient descent. This makes use of structural information from the nonlinear model. Simulated annealing (SA), on the other hand, is one which is global heuristic that minimizes the cost function. This work has proposed a high level of gradient descent and simulated annealing for the selection of software test case. Experiments showed that the modified SA has a lower number of print tokens by 3.82% for the 10,000 cost, by about 2.5% for the 30,000 cost, by about 1.17% for the 50,000 cost and finally by about 1.14% for the 70,000 cost.																	1432-7643	1433-7479				SEP	2020	24	17					12981	12987		10.1007/s00500-020-04719-9		FEB 2020											
J								A new flower pollination algorithm for equalization in synchronous DS/CDMA multiuser communication systems	SOFT COMPUTING										DS; CDMA; Nature-inspired algorithms; Flower pollination algorithm; Channel estimation; Symbol detection; Multiuser detection; Population diversity	GENETIC-ALGORITHM; CHANNEL ESTIMATION; CDMA SYSTEMS; OPTIMIZATION; DETECTOR; SEARCH; BINARY; PERFORMANCE; RECEIVER; SIGNALS	This work proposes a modified version of an emerging nature-inspired technique, named flower pollination algorithm, for equalizing digital multiuser channels. This equalization involves two different tasks: (1) estimation of the channel impulse response, and (2) estimation of the users' transmitted symbols. The new algorithm is developed and applied in a direct sequence/code-division multiple-access multiuser communications system. Important issues such as robustness, convergence speed and population diversity control have been in deep investigated. A method based on the entropy of the flowers' fitness is proposed for in-service monitoring and adjusting population diversity. Numerical simulations analyze the performance, showing comparisons with well-known conventional multiuser detectors such as matched filter, minimum mean square error estimator or several Bayesian schemes, as well as with other nature-inspired strategies. Numerical analysis shows that the proposed algorithm enables transmission at higher symbol rates under stronger fading and interference conditions, constituting an attractive alternative to previous algorithms, both conventional and nature-inspired, whose performance is frequently sensible to near-far effects and multiple-access interference problems. These results have been validated by running hypothesis tests to confirm statistical significance.																	1432-7643	1433-7479				SEP	2020	24	17					13069	13083		10.1007/s00500-020-04725-x		FEB 2020											
J								Concordance as evidence in the Watson for Oncology decision-support system	AI & SOCIETY										Artificial intelligence; Decision support; Machine learning; Oncology; Watson for Oncology; IBM; Clinical trials	CANCER	Machine learning platforms have emerged as a new promissory technology that some argue will revolutionize work practices across a broad range of professions, including medical care. During the past few years, IBM has been testing its Watson for Oncology platform at several oncology departments around the world. Published reports, news stories, as well as our own empirical research show that in some cases, the levels of concordance over recommended treatment protocols between the platform and human oncologists have been quite low. Other studies supported by IBM claim concordance rates as high as 96%. We use the Watson for Oncology case to examine the practice of using concordance levels between tumor boards and a machine learning decision-support system as a form of evidence. We address a challenge related to the epistemic authority between oncologists on tumor boards and the Watson Oncology platform by arguing that the use of concordance levels as a form of evidence of quality or trustworthiness is problematic. Although the platform provides links to the literature from which it draws its conclusion, it obfuscates the scoring criteria that it uses to value some studies over others. In other words, the platform "black boxes" the values that are coded into its scoring system.																	0951-5666	1435-5655															10.1007/s00146-020-00945-9		FEB 2020											
J								Discrete selfish herd optimizer for solving graph coloring problem	APPLIED INTELLIGENCE										Discrete selfish herd optimizer; Graph coloring problem; Candidate solution update method; Conflict matrix of candidate solutions	LOCAL SEARCH ALGORITHM; CALLING BEHAVIOR	Selfish herd optimizer is a new and effective continuous optimization algorithm, but the algorithm cannot solve the specific discrete problem. Therefore, we design a discrete selfish herd optimizer (DSHO) specifically for solving graph coloring problems. At present, many existing methods cannot effectively solve graph coloring problems. To deal with this difficult problem, in DSHO, we propose an effective step-size updating method. This step-size update method is not random, but is updated based on the conflict matrix of candidate solutions. Moreover, we also add a mechanism to deal with potential color conflict areas. By using these methods, DSHO can effectively reduce the number of conflict areas when calculating the conflict matrix of candidate solutions. To verify DSHO's optimization performance, we use 83 test cases, they includes five simulated maps, six real maps (China, New York, America, Paris, France and Russia) and 72 test cases of minimum coloring number (They come from DIMACS Implementation Challenge). DSHO compare with the latest coloring algorithms, they are DABC, DFA, GETS, HACO, LGFPA, FROGSIM and SDGC, respectively. The experimental outcomes exhibit that DSHO has minimum number of conflict areas, smaller standard deviation, fewer iterations and higher coloring success rate. Discrete selfish herd optimizer is more competitive than other algorithms. Therefore, it is a new method for solving graph coloring problems effectively.																	0924-669X	1573-7497				MAY	2020	50	5					1633	1656		10.1007/s10489-020-01636-0		FEB 2020											
J								Modeling law search as prediction	ARTIFICIAL INTELLIGENCE AND LAW											INFORMATION-SEEKING BEHAVIOR; POSITIVISM; ENGINEERS	Law search is fundamental to legal reasoning and its articulation is an important challenge and open problem in the ongoing efforts to investigate legal reasoning as a formal process. This Article formulates a mathematical model that frames the behavioral and cognitive framework of law search as a sequential decision process. The model has two components: first, a model of the legal corpus as a search space and second, a model of the search process (or search strategy) that is compatible with that environment. The search space has the structure of a "multi-network"-an interleaved structure of distinct networks-developed in earlier work. In this Article, we develop and formally describe three related models of the search process. We then implement these models on a subset of the corpus of U.S. Supreme Court opinions and assess their performance against two benchmark prediction tasks. The first is to predict the citations in a document from its semantic content. The second is to predict the search results generated by human users. For both benchmarks, all search models outperform a null model with the learning-based model outperforming the other approaches. Our results indicate that through additional work and refinement, there may be the potential for machine law search to achieve human or near-human levels of performance.																	0924-8463	1572-8382															10.1007/s10506-020-09261-5		FEB 2020											
J								A practical method for the expert academic personas classification based on text classifier	EVOLUTIONARY INTELLIGENCE										Expert academic personas; Text classification; Personas; Support vector machine		The expert academic personas classification are indispensable for expert intelligent automatic recommendation. It can also be applied to academic evaluation, character knowledge base construction and so on. The paper introduces a text classifier trained for the personas of expert academic classification based on support vector machine. The problem of expert academic personas is converted into text classification. First, we automatically construct text training datasets based on seed expert database from Wikipedia. Then a unified model for Chinese-English expert classification is trained after text preprocessing and vectorization. Finally, we verified the effectiveness of our method on the real dataset acquired from the Internet. Experimental results show that the proposed method outperforms the baseline methods and achieves a F1-measure of 83.5% for expert academic classification.																	1864-5909	1864-5917															10.1007/s12065-019-00339-x		FEB 2020											
J								An Improved Method for Extrinsic Calibration of Tilting 2D LRF	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Calibration; Tilting 2D LRF; 3D point cloud; 6-degree-of-freedom	MOBILE ROBOT; LASER SCANNER; NAVIGATION	This paper proposes an improved calibration method to accurately estimate extrinsic calibration parameters of a tilting 2D Laser Range Finder (LRF). Tilting 2D LRF (a low cost 3D scanner device) with a unidirectional rotating platform has been widely used in robotics applications to scan the 3D environment. Ideally, the tilt axis of rotating mechanism should pass through the optical rotation centre of the 2D LRF. However, due to misalignment during assembling of 2D LRF with the rotating platform, the centres of rotation may not coincide with each other. Though, the system must be calibrated to align both the centres of rotation so as to improve the accuracy in building 3D point cloud of the environment. Unlike the previous calibration techniques, the main advantage of the proposed method is that it accurately estimates all 6-DOF calibration parameters, especially rotation and translation calibration parameters along motor rotation axis between 2D LRF and rotating platform without any additional hardware, camera or rolling/bidirectional rotation mechanism. The proposed method utilizes the normal vector to the calibration board plane and coordinates of laser points at the endpoints of the extracted calibration board line in the 2D scan to obtain these remaining calibration parameters. The obtained parameters are then refined using Levenberg-Marquardt non-linear optimization algorithm. The performance of the algorithm is validated on a range of real as well as synthetic data and the estimated parameters with the proposed approach exhibits 24.54% reduction in RMS (root mean square) error as compared to the conventional approach. Furthermore, qualitative and quantitative analysis shows that the proposed method produces accurate results and is able to reduce the artifacts along the rotation axis in the 3D point cloud which usually appear in the point cloud obtained from the conventional approach.																	0921-0296	1573-0409				SEP	2020	99	3-4			SI		693	712		10.1007/s10846-020-01147-7		FEB 2020											
J								A multi-breakpoints approach for symbolic discretization of time series	KNOWLEDGE AND INFORMATION SYSTEMS										Time series classification; Symbolic representation; Multi-breakpoints approach; Multi-objective optimization	CLASSIFICATION	Time series discretization is a technique commonly used to tackle time series classification problems. This manuscript presents an enhanced multi-objective approach for the symbolic discretization of time series called eMODiTS. The method proposed uses a different breakpoints vector, defined per each word segment, to increase the search space of the discretization schemes. eMODiTS' search mechanism is the well-known evolutionary multi-objective algorithm NSGA-II, which finds a set of possible solutions according to entropy, complexity, and information loss estimations. Final solutions were appraised depending on the misclassification rate computed through the decision tree classifier. The trees obtained also produce graphical and significant information from the regions, relationships, or patterns in each database. Our proposal was compared against ten state-of-the-art time symbolic discretization algorithms. The results suggest that our proposal finds a suitable discretization scheme regarding classification, dimensionality, cardinality reduction, and information loss.																	0219-1377	0219-3116				JUL	2020	62	7					2795	2834		10.1007/s10115-020-01437-4		FEB 2020											
J								The Ethics of AI Ethics: An Evaluation of Guidelines	MINDS AND MACHINES										Artificial intelligence; Machine learning; Ethics; Guidelines; Implementation	DIGITAL LABOR; INGROUP; SCIENCE	Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the "disruptive" potentials of new AI technologies. Designed as a semi-systematic evaluation, this paper analyzes and compares 22 guidelines, highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems-and how the effectiveness in the demands of AI ethics can be improved.																	0924-6495	1572-8641				MAR	2020	30	1					99	120		10.1007/s11023-020-09517-8		FEB 2020											
J								Evolving deep neural networks using coevolutionary algorithms with multi-population strategy	NEURAL COMPUTING & APPLICATIONS										Evolving deep neural networks; Neuroevolution; Evolutionary computation; Multi-population approach	EVOLUTIONARY ALGORITHM; GENE-EXPRESSION; CLASSIFICATION; AUTOENCODER	Deep learning (DL) has achieved state-of-the-art results on benchmark datasets and been most popular and widely accepted for both industrial and research problems. Since the success of deep learning, particularly across multiple domains, and successful implementations by tech giants like Apple, Microsoft, Facebook, etc., the research focus is now diverted towards optimising DL process by using various conventional and unconventional approaches. One such approach is using evolutionary computation techniques to improve the training and learning of DL. This paper, for the first time, proposes a novel multi-population competitive and cooperative neuroevolution approach for evolving optimised deep neural networks (DNNs) to provide a warm start to the DL process. Two separate coevolutionary strategies are used on two different populations that are collectively working towards producing optimised DNNs. Furthermore, three new parameters are proposed to avoid premature convergence and to maintain genetic diversity which is considered to be one of the major problems for population-based approaches. The proposed approach is tested on four different and diversified datasets, i.e. IRIS, MNIST, prostate cancer gene expression and synthetic hierarchical dataset. The experiments are carried out with four different strategies (of two different sizes) using standard DNNs, DNNs evolved with coevolution strategies and the proposed multi-population competitive and cooperative evolutionary (evolutionary deep neural networks or simply EDN) approach. The proposed EDN approach dominated the results by reducing the training and execution times while maintaining the best classification accuracy among all other approaches for all four datasets. The classification accuracy with the proposed approach is 98.3%, 98.7%, 82.2% and 89.1% for IRIS, MNIST, gene expression dataset and synthetic dataset, respectively. With the proposed EDN, the execution time for training and testing (including evolving DNNs) is considerably reduced by over 50% for MNIST and synthetic dataset, whereas it is 15% for IRIS and gene expression datasets when compared to standard deep neural networks with random weights and fixed topology.																	0941-0643	1433-3058				AUG	2020	32	16					13051	13064		10.1007/s00521-020-04749-2		FEB 2020											
J								Link-based multi-verse optimizer for text documents clustering	APPLIED SOFT COMPUTING										Multi-verse optimizer; Optimization; Test clustering; Data clustering; Neighborhood selection strategy	PARTICLE SWARM OPTIMIZATION; METAHEURISTIC ALGORITHM; FEATURE-SELECTION; GLOBAL OPTIMIZATION; KRILL HERD; CLASSIFICATION; PERFORMANCE; PARAMETERS; MODEL; SIZE	Text document clustering (TDC) represents a key task in text mining and unsupervised machine learning, which partitions a specific documents' collection into varied K-groups according to certain similarity/dissimilarity criterion. There exists a considerable amount of knowledge in the text clustering field and many attempts were carried out to resolve the TDC problem and improve the learning performance. The multi-verse optimizer algorithm (MVO) is a stochastic population-based algorithm, which was recently introduced and successfully utilized to tackle many optimization problems that are complex. The original MVO performance is limited to the utilization of only the best solution in the exploitation phase (local search capability), which makes it suffer from entrapment in local optima and low convergence rate. This paper aims to propose a novel method of modifying the MVO algorithm called link-based Multi-verse optimizer algorithm (LBMVO) to enhance the exploitation phase in the original MVO. The enhancement involves adding a neighbor operator to the MVO algorithm to enhance the search capability via a novel probability factor, namely neighborhood selection strategy (NSS). The proposed LBMVO's effectiveness was tested on six standard datasets, which are used in the text clustering domain in addition to five standard datasets, which are utilized in the data clustering domain. The experiments revealed that the modified MVO with NSS has boosted the results in terms of error rate, accuracy, recall, precision, F-measure, purity, entropy criteria, and high convergence rate. Generally, LBMVO has outperformed or at least showed that it is profoundly competitive compared with the original MVO algorithm and with widely known clustering techniques like Spectral, Agglomerative, Density-based spatial clustering of applications with noise (DBSCAN), K-means, K-means++ clustering techniques and the optimization algorithms like harmony search (HS), genetic algorithm (GA), particle swarm optimization (PSO), krill herd algorithm (KHA), covariance matrix adaptation evolution strategy (CMAES), coyote optimization algorithm (COA), as well as original MVO. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106002	10.1016/j.asoc.2019.106002													
J								Hybrid multi-objective evolutionary algorithm based on Search Manager framework for big data optimization problems	APPLIED SOFT COMPUTING										Big Data optimization; Hybrid multi-objective evolutionary algorithm; Search Manager framework; Evolutionary operators	DIFFERENTIAL EVOLUTION; SWARM OPTIMIZER; MULTI; OPERATOR	Big Data optimization (Big-Opt) refers to optimization problems which require to manage the properties of big data analytics. In the present paper, the Search Manager (SM), a recently proposed framework for hybridizing metaheuristics to improve the performance of optimization algorithms, is extended for multi-objective problems (MOSM), and then five configurations of it by combination of different search strategies are proposed to solve the EEG signal analysis problem which is a member of the big data optimization problems class. Experimental results demonstrate that the proposed configurations of MOSM are efficient in this kind of problems. The configurations are also compared with NSGA-III with uniform crossover and adaptive mutation operators (NSGA-III UCAM), which is a recently proposed method for Big-Opt problems. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105991	10.1016/j.asoc.2019.105991													
J								Designing a composite deep learning based differential protection scheme of power transformers	APPLIED SOFT COMPUTING										Differential protection; Power transformers; Inrush current; Internal fault; Deep learning; Convolutional neural network (CNN); Light gated recurrent unit (LGRU)	CONVOLUTIONAL NEURAL-NETWORKS; INTERNAL FAULTS; INRUSH CURRENT; MAGNETIZING INRUSH; DISCRIMINATION; IMAGE; IDENTIFICATION; CURRENTS; CLASSIFICATION; OPTIMIZATION	This paper proposes a novel differential protection scheme based on deep neural networks (DNN). The goal is to propose a fast, reliable, and independent protection scheme in distinguishing inrush current from internal fault in power transformers, as the most challenging issue in power transformers protection. Shallow-based techniques require spectral analysis and handcraft feature extraction to be proper methods in this major. However, they require a significant computational cost. In order to address this issue, in this paper, a novel DNN-based approach is proposed based on combining convolutional neural network (CNN) and light-gated recurrent unit (LGRU), namely CLGNN. The results show a more accurate and more reliable performance than three different shallow and three state-of-the-art DNN based techniques. Adaptability and robustness of the proposed scheme are evaluated considering CT saturation, superconducting fault current limiter (SFCL), and series compensation impacts. The obtained results prove the effectiveness and validity of the proposed DNN-based protection scheme in this paper. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105975	10.1016/j.asoc.2019.105975													
J								Applied improved RBF neural network model for predicting the broiler output energies	APPLIED SOFT COMPUTING										Broiler energy; Radial base function; Response surface method; Genetic algorithm	EFFICIENCY; HOUSES	The aim of this study is to optimize the Radial Base Function (RBF) parameters by combining the Response Surface Method (RSM) and Genetic Algorithm (GA) for modeling the output energies of broiler farms. For this purpose, data were collected from 210 broiler farms in Mazandaran province, Iran. The results showed that L-2 and sigma (RBF parameters) have a significant effect on RBF performance (p-value <0.05). The lack-of-fit in most cases was insignificant, except in the Trainlm algorithm. The results show that the RSM quadratic model can use for modeling based on L-2 and sigma. The R-2-adj and R-2 indexes for RSM coefficients at the test stage by using Trainbr algorithm for broiler meat and manure outputs were 97.13, 96.76 and 98.70, 98.53 and by using Trainlm algorithm were, 87.95, 86.41 and 96.90, 96.50, respectively. The mean and standard deviation of RMSE and MAPE in both two training algorithms (Trainbr and Trainlm) for manure and broiler meat outputs were used to compare them based on 100 random data sets of k-fold cross validation method. The results showed that Trainbr has the lowest error and can use for high accuracy modeling. The results of sensitivity analysis showed that one-day chicks (chi(c)), human labor (chi(l)), food (chi(f)), electricity (chi(e)), diesel fuel (chi(d)) and machinery (chi(m)) have the highest effect on chicken energy modeling and chi(f), chi(l), chi(m), chi(c), chi(d) and chi(d) have the most impact on manure energy modeling. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106006	10.1016/j.asoc.2019.106006													
J								Hybrid strategy for selecting compact set of clustering partitions	APPLIED SOFT COMPUTING										Multiobjective clustering; Pareto optimality; Clustering selection	OPTIMIZATION; CLASSIFICATION; ALGORITHMS; PREDICTION; DISCOVERY	The selection of the most appropriate clustering algorithm is not a straightforward task, given that there is no clustering algorithm capable of determining the actual groups present in any dataset. A potential solution is to use different clustering algorithms to produce a set of partitions (solutions) and then select the best partition produced according to a specified validation measure; these measures are generally biased toward one or more clustering algorithms. Nevertheless, in several real cases, it is important to have more than one solution as the output. To address these problems, we present a hybrid partition selection algorithm, HSS, which accepts as input a set of base partitions potentially generated from clustering algorithms with different biases and aims, to return a reduced and yet diverse set of partitions (solutions). HSS comprises three steps: (i) the application of a multiobjective algorithm to a set of base partitions to generate a Pareto Front (PF) approximation; (ii) the division of the solutions from the PF approximation into a certain number of regions; and (iii) the selection of a solution per region by applying the Adjusted Rand Index. We compare the results of our algorithm with those of another selection strategy, ASA. Furthermore, we test HSS as a post-processing tool for two clustering algorithms based on multiobjective evolutionary computing: MOCK and MOCLE. The experiments revealed the effectiveness of HSS in selecting a reduced number of partitions while maintaining their quality.																	1568-4946	1872-9681				FEB	2020	87								105971	10.1016/j.asoc.2019.105971													
J								A spatio-temporal decomposition based deep neural network for time series forecasting	APPLIED SOFT COMPUTING										Spatio-temporal data; Deep learning; Time series forecasting; Traffic flow prediction	TRAFFIC FLOW PREDICTION; SPEED PREDICTION; MULTIVARIATE	Spatio-temporal problems arise in a broad range of applications, such as climate science and transportation systems. These problems are challenging because of unique spatial, short-term and long-term patterns, as well as the curse of dimensionality. In this paper, we propose a deep learning framework for spatio-temporal forecasting problems. We explicitly design the neural network architecture for capturing various types of spatial and temporal patterns, and the model is robust to missing data. In a preprocessing step, a time series decomposition method is applied to separately feed short-term, longterm and spatial patterns into different components of the neural network. A fuzzy clustering method finds clusters of neighboring time series residuals, as these contain short-term spatial patterns. The first component of the neural network consists of multi-kernel convolutional layers which are designed to extract short-term features from clusters of time series data. Each convolutional kernel receives a single cluster of input time series. The output of convolutional layers is concatenated by trends and followed by convolutional-LSTM layers to capture long-term spatial patterns. To have a robust forecasting model when faced with missing data, a pretrained denoising autoencoder reconstructs the model's output in a fine-tuning step. In experimental results, we evaluate the performance of the proposed model for the traffic flow prediction. The results show that the proposed model outperforms baseline and state-of-the-art neural network models. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105963	10.1016/j.asoc.2019.105963													
J								A hierarchical Gamma Mixture Model-based method for estimating the number of clusters in complex data	APPLIED SOFT COMPUTING										Number of clusters; Initial cluster centers; Gamma Mixture Model (GMM); EM algorithm; Clustering algorithms	ALGORITHM; FIND	This paper proposes a new method for estimating the true number of clusters and initial cluster centers in a dataset with many clusters. The observation points are assigned to the data space to observe the clusters through the distributions of the distances between the observation points and the objects in the dataset. A Gamma Mixture Model (GMM) is built from a distance distribution to partition the dataset into subsets, and a GMM tree is obtained by recursively partitioning the dataset. From the leaves of the GMM tree, a set of initial cluster centers are identified and the true number of clusters is estimated. This method is implemented in the new GMM-Tree algorithm. Two GMM forest algorithms are further proposed to ensemble multiple GMM trees to handle high dimensional data with many clusters. The GMM-P-Forest algorithm builds GMM trees in parallel, whereas the GMM-S-Forest algorithm uses a sequential process to build a GMM forest. Experiments were conducted on 32 synthetic datasets and 15 real datasets to evaluate the performance of the new algorithms. The results have shown that the proposed algorithms outperformed the existing popular methods: Silhouette, Elbow and Gap Statistic, and the recent method I-nice in estimating the true number of clusters from high dimensional complex data. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105891	10.1016/j.asoc.2019.105891													
J								A novel learning cloud Bayesian network for risk measurement	APPLIED SOFT COMPUTING										Bayesian network; Uncertainty modeling; Machine learning; Cloud model; Risk measurement	DIAMETER SLURRY SHIELD; SAFETY RISK; STABILITY ANALYSIS; FACE STABILITY; TUNNEL; PARAMETERS; BUILDINGS; ALGORITHM; PRESSURE; ADJACENT	Bayesian network (BN) is a popularly used approach for risk analysis. Because it is a graphic model being able to deal with randomness yet unable to model ambiguity, the fuzzy set theory is often combined with it to create a so-called fuzzy BN. Instead of using the classical fuzzy set theory, this paper intends to combine a normal Cloud model with the BN. In the normal Cloud model, an element belonging to a certain qualitative concept is not certain and precise as well. The Cloud BN is a generalization of the fuzzy BN. It is more adaptive for the uncertainty description of linguistic concepts, for example, the risks. Using the normal Cloud model, the following numerical characteristics of the variables can be estimated: the expectation, the dispersion degree compared with the expectation, and the dispersion degree of entropy. Consequently, the risk assessment contains a richer set of analytical information. Cloud BNs attract growing research interests. Compared to its precedents, the Cloud BN in this paper has a learning capability. Since the risk factors may have a combined effect, the causal relationships among the variables can be very complex, and hidden variables may exist. The learning mechanism allows for automatic structure discovery from data, giving rise to a dynamically evolving network. The proposed learning Cloud BN is able to represent the real risk situation better than its precedents. Its effectiveness and applicability are demonstrated by an illustrative case for risk prediction of the face instability in an underground tunnel construction project. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105947	10.1016/j.asoc.2019.105947													
J								Sustainable supplier selection for smart supply chain considering internal and external uncertainty: An integrated rough-fuzzy approach	APPLIED SOFT COMPUTING										Smart supply chain; Sustainable management practices; Supplier selection; Rough-fuzzy DEMATEL; Rough-fuzzy TOPSIS	MANAGEMENT-PRACTICES; DEMATEL METHOD; INDUSTRY 4.0; TOPSIS; PERFORMANCE; FRAMEWORK; IMPACT; EVALUATE; SERVICE; MODEL	This study proposes a novel framework to identify smart-sustainable SCMP (supply chain management practices) as supplier selection criteria for a smart supply chain. Supplier selection consists of two parts: criteria weights determination and suppliers ranking. DEMATEL (Decision Making Trial and Evaluation Laboratory) has been acknowledged as a relatively feasible method for determining the criteria weights due to its effectiveness in acquiring the interrelationships between criteria. TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) has been identified as the most frequently used method for supplier ranking due to its superiority in quickly finding the best alternatives. However, most existing research contains scant study of the simultaneous manipulation of internal uncertainty (individual linguistic vagueness) and external uncertainty (group preference diversity), which are involved in the supplier selection process. Therefore, this study proposes a hybrid rough-fuzzy DEMATEL-TOPSIS approach to sustainable supplier selection for a smart supply chain. The proposed method combines the strength of the fuzzy set in handling internal uncertainty and the advantages of the rough set in manipulating external uncertainty. The effectiveness and accuracy of the proposed methodology are illustrated through its application in sustainable vehicle transmission supplier selection and through comparisons with other methods. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106004	10.1016/j.asoc.2019.106004													
J								The design of a new hybrid controller for fractional-order uncertain chaotic systems with unknown time-varying delays	APPLIED SOFT COMPUTING										Adaptive control; Fractional order chaotic systems; Hyperbolic tangential robust control; Neuro-fuzzy estimator; Soft computing techniques; Time-varying delay	GENERALIZED PROJECTIVE SYNCHRONIZATION; SLIDING MODE CONTROL; FUZZY CONTROL; NEURAL-NETWORKS; STABILITY; STABILIZATION; SUBJECT	In this paper, the combination of a soft computing technique, i.e., adaptive neuro-fuzzy inference system (ANFIS) with fractional-order robust adaptive control is used to control a class of fractional order uncertain chaotic nonlinear systems with uncertainty, external disturbances and unknown timevarying delays. At first, the fractional-order hyperbolic tangential robust adaptive intelligent controller (FHRAIC) is designed for the system, when the unknown time-varying heterogeneous delays and uncertainties and disturbances exist in system states. Next, the controller design is extended for the case of existence of unknown time-varying delay in the inputs of the system. The hyperbolic tangential sliding surface enables the closed-loop system to safely and effectively avoid large errors in tracking control. Adaptive control parameters are adjusted based on Lyapunov stability analysis ANFIS is used to approximate unknown functions. The stability analysis of this controller has been carried out based on Lyapunov-Krasovskii method and Barbalat's Lemma. Various simulation examples show the effectiveness of the proposed method for a vast range of systems. To demonstrate the effectiveness of ANFIS on FHRAIC controller, its performance has been compared with that of fractional-order hyperbolic tangential robust adaptive controller (FHRAC). (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106000	10.1016/j.asoc.2019.106000													
J								Data-driven symbolic ensemble models for wind speed forecasting through evolutionary algorithms	APPLIED SOFT COMPUTING										Ensemble weather forecast; Wind speed; Northeastern Brazil; Grammatical evolution; Machine learning; Data-driven modeling	PARTICLE SWARM OPTIMIZATION; ANN	Non-linear data-driven symbolic models have been gaining traction in many fields due to their distinctive combination of modeling expressiveness and interpretability. Despite that, they are still rather unexplored for ensemble wind speed forecasting, leaving behind new promising avenues for advancing the development of more accurate models which impact the efficiency of energy production. In this work, we develop a methodology based on the evolutionary algorithm known as grammatical evolution, and apply it to build forecasting models of near-surface wind speed over five locations in northeastern Brazil. Taking advantage of the symbolic nature of the models built, we conducted an extensive series of post-analyses. Overall, our models reduced the forecasting errors by 7%-56% when compared with other techniques, including a real-world operational ensemble model used in Brazil. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105976	10.1016/j.asoc.2019.105976													
J								DSCTool: A web-service-based framework for statistical comparison of stochastic optimization algorithms	APPLIED SOFT COMPUTING										Statistical tool; Benchmarking; Stochastic optimization algorithms; DSCTool; Web service	EVOLUTIONARY ALGORITHMS	DSCTool is a statistical tool for comparing performance of stochastic optimization algorithms on a single benchmark function (i.e. single-problem analysis) or a set of benchmark functions (i.e., multiple-problem analysis). DSCTool implements a recently proposed approach, called Deep Statistical Comparison (DSC), and its variants. DSC ranks optimization algorithms by comparing distributions of obtained solutions for a problem instead of using a simple descriptive statistic such as the mean or the median. The rankings obtained for an individual problem give the relations between the performance of the applied algorithms. To compare optimization algorithms in the multiple-problem scenario, an appropriate statistical test must be applied to the rankings obtained for a set of problems. The main advantage of DSCTool are its REST web services, which means all its functionalities can be accessed from any programming language. In this paper, we present the DSCTool in detail with examples for its usage. (C) 2019 The Author( s). Published by Elsevier B.V.																	1568-4946	1872-9681				FEB	2020	87								105977	10.1016/j.asoc.2019.105977													
J								Strong approximate Markov blanket and its application on filter-based feature selection	APPLIED SOFT COMPUTING										Strong approximate Markov blanket; Feature selection; Feature redundancy	FEATURE SUBSET-SELECTION; MUTUAL INFORMATION; ALGORITHM; RELEVANCE; KERNEL	In feature selection problems, strong relevant features may be misjudged as redundant by the approximate Markov blanket. To avoid this, a new concept called strong approximate Markov blanket is proposed. It is theoretically proved that no strong relevant feature will be misjudged as redundant by the proposed concept. To reduce computation time, we propose the concept of modified strong approximate Markov blanket, which still performs better than the approximate Markov blanket in avoiding misjudgment of strong relevant features. A new filter-based feature selection method that is applicable to high-dimensional datasets is further developed. It first groups features to remove redundant features, and then uses a sequential forward selection method to remove irrelevant features. Numerical results on four benchmark and seven real datasets suggest that it is a competitive feature selection method with high classification accuracy, moderate number of selected features, and above-average robustness. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105957	10.1016/j.asoc.2019.105957													
J								Data-driven two-stage distributionally robust optimization with risk aversion	APPLIED SOFT COMPUTING										Two-stage distributionally robust; optimization; Data-driven; Risk aversion; L-1 distance; Modified decomposition method	STOCHASTIC-PROGRAMMING APPROACH; SUPPLY CHAIN; MODEL; DECOMPOSITION; INEQUALITIES	This paper studies a two-stage distributionally robust optimization problem with risk aversion. We define an ambiguity set containing the true distribution function with L-1 distance. Taking a data-driven approach, we use a product kernel density to estimate the nominal distribution and provide the bounds of the estimation. For tractability, we transform the worst-case risk aversion problem into a linear programming problem. To handle the risk measure in the objective function, we propose a modified decomposition method. Numerical tests are utilized to validate the proposed method. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105978	10.1016/j.asoc.2019.105978													
J								Nonlinear black-box system identification through coevolutionary algorithms and radial basis function artificial neural networks	APPLIED SOFT COMPUTING										System identification; Nonlinear systems; Radial basis functions neural networks; Coevolutionary algorithms; Piezoelectric manipulator	DIFFERENTIAL EVOLUTION; HARMONY SEARCH; DESIGN; MODEL; OPTIMIZATION; SWARM; INPUT	The present work deals with the application of coevolutionary algorithms and artificial neural networks to perform input selection and related parameter estimation for nonlinear black-box models in system identification. In order to decouple the resolution of the input selection and parameter estimation, we propose a problem decomposition formulation and solve it by a coevolutionary algorithm strategy. The novel methodology is successfully applied to identify a magnetorheological damper, a continuous polymerization reactor and a piezoelectric robotic micromanipulator. The results show that the method provides valid models in terms of accuracy and statistical properties. The main advantage of the method is the joint input and parameter estimation, towards automating a tedious and error prone procedure with global optimization algorithms. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105990	10.1016/j.asoc.2019.105990													
J								A new multi-stable fractional-order four-dimensional system with self-excited and hidden chaotic attractors: Dynamic analysis and adaptive synchronization using a novel fuzzy adaptive sliding mode control method	APPLIED SOFT COMPUTING										Fractional-order four-dimensional chaotic system; Self-excited and hidden attractors; Multi-stability; Phase portraits; Bifurcation diagram; Adaptive sliding mode synchronization; Fuzzy adaptive sliding mode control	HYPERCHAOTIC SYSTEM; EXTREME MULTISTABILITY; OPTIMIZATION; REALIZATION; COEXISTENCE; OSCILLATOR; STABILITY; EXISTENCE; DESIGN	Four-dimensional chaotic systems are a very interesting topic for researchers, given their special features. This paper presents a novel fractional-order four-dimensional chaotic system with self-excited and hidden attractors, which includes only one constant term. The proposed system presents the phenomenon of multi-stability, which means that two or more different dynamics are generated from different initial conditions. It is one of few published works in the last five years belonging to the aforementioned category. Using Lyapunov exponents, the chaotic behavior of the dynamical system is characterized, and the sensitivity of the system to initial conditions is determined. Also, systematic studies of the hidden chaotic behavior in the proposed system are performed using phase portraits and bifurcation transition diagrams. Moreover, a design technique of a new fuzzy adaptive sliding mode control (FASMC) for synchronization of the fractional-order systems has been offered. This control technique combines an adaptive regulation scheme and a fuzzy logic controller with conventional sliding mode control for the synchronization of fractional-order systems. Applying Lyapunov stability theorem, the proposed control technique ensures that the master and slave chaotic systems are synchronized in the presence of dynamic uncertainties and external disturbances. The proposed control technique not only provides high performance in the presence of the dynamic uncertainties and external disturbances, but also avoids the phenomenon of chattering. Simulation results have been presented to illustrate the effectiveness of the presented control scheme. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105943	10.1016/j.asoc.2019.105943													
J								MOEA/D-based participant selection method for crowdsensing with social awareness	APPLIED SOFT COMPUTING										Crowdsensing; Social awareness; Participant selection; MOEA/D	MULTIOBJECTIVE EVOLUTIONARY ALGORITHM; DECOMPOSITION; BUDGET	With the explosive popularity of mobile terminal devices, crowdsensing has become a novel paradigm for thoroughly sensing the environment. A crucial issue in crowdsensing system involves that the selection of appropriate participants from a number of mobile users to guarantee completing the sensing tasks. The traditional participant selection methods only consider the profit of the task publisher, resulting in the loss of potential users. Base on this, a novel multi-objective participant selection model is built, with the purpose of guaranteeing the interests of the mobile users by maximizing the total reward of participants and the profit of task publisher by maximizing the overall sensing quality. To solve this combinatorial optimization problem, an improved multi-objective evolutionary algorithm based on decomposition (MOEA/D) is proposed. It utilizes a balance factor to uniform various scales between two objectives. The optimal solution for each objective obtained by greedy algorithm is incorporated into initial population, with the purpose of avoiding falling into the local optima. In addition, a novel mutation operator is developed to enhance the convergence of solutions. The simulation results show that the improved MOEA/D has a significant better performance than the other algorithms for our problem, and the proposed multi-objective participant selection model more fits for the crowdsensing based on social awareness. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105981	10.1016/j.asoc.2019.105981													
J								An improved feature extraction method using texture analysis with LBP for bearing fault diagnosis	APPLIED SOFT COMPUTING										Feature extraction; Texture analysis; Vibration signals; Local binary pattern	LOCAL BINARY PATTERNS; SEVERITY CLASSIFICATION; FEATURE-SELECTION; EPILEPTIC EEG; BALL-BEARING; RECOGNITION; ALGORITHM	Bearings are one of the most widespread components used for energy transformation in machines. Mechanical wear and faulty bearings reduce the efficiency of rotating machines and thus increase energy consumption. The feature extraction process is an essential part of fault diagnosis in bearings. In order to diagnose the fault caused by the bearing correctly, it is necessary to determine an effective feature extraction method that best describes the fault. In this study, a new approach based on texture analysis is proposed for diagnosing bearing vibration signals. Bearing vibration signals were first converted to gray scale images. It can be understood from the images that the signals of different bearing failures form different textures. Then, using these images, LBP (Local Binary Pattern) and texture features were obtained. Using these features, different machine learning models and bearing vibration signals are classified. Three different data sets were created to test the proposed approach. For the first data set, the signals composed of very close velocities were classified. 95.9% success rate was observed for the first data set. The second data set consists of faulty signals at different parts of the bearing (inner ring, outer ring and ball) measured in the same RPM. The type of fault has been determined, and a 100% success rate was obtained for this data set. The final data set is composed of the fault size dimensions (mm) of different ratios. With the proposed approach, a 100% success rate was obtained in the classification of these signals. As a result, it was observed that the obtained feature had promising results for three different data types and was more successful than the traditional methods. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106019	10.1016/j.asoc.2019.106019													
J								Hand-crafted and deep convolutional neural network features fusion and selection strategy: An application to intelligent human action recognition	APPLIED SOFT COMPUTING										Deep CNN features; Features fusion; Feature selection; HAR; Recognition; Shape features; Silhouette extraction	REPRESENTATION	Human action recognition (HAR) has gained much attention in the last few years due to its enormous applications including human activity monitoring, robotics, visual surveillance, to name but a few. Most of the previously proposed HAR systems have focused on using hand-crafted images features. However, these features cover limited aspects of the problem and show performance degradation on a large and complex datasets. Therefore, in this work, we propose a novel HAR system which is based on the fusion of conventional hand-crafted features using histogram of oriented gradients (HoG) and deep features. Initially, human silhouette is extracted with the help of saliency-based method - implemented in two phases. In the first phase, motion and geometric features are extracted from the selected channel, whilst, second phase calculates the Chi-square distance between the extracted and threshold-based minimum distance features. Afterwards, extracted deep CNN and hand-crafted features are fused to generate a resultant vector. Moreover, to cope with the curse of dimensionality, an entropy-based feature selection technique is also proposed to identify the most discriminant features for classification using multi-class support vector machine (M-SVM). All the simulations are performed on five publicly available benchmark datasets including Weizmann, UCF11 (YouTube), UCF Sports, IXMAS, and UT-Interaction. A comparative evaluation is also presented to show that our proposed model achieves superior performances in comparison to a few exiting methods. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105986	10.1016/j.asoc.2019.105986													
J								The laser-induced damage change detection for optical elements using siamese convolutional neural networks	APPLIED SOFT COMPUTING										Laser-induced damage; Change detection; Siamese convolutional neural network; Weighted softmax loss	DIFFERENCE; COVER; ERROR; POWER	Due to the fact that weak and fake laser-induced damages may occur in the surface of optical elements in high-energy laser facilities, it is still a challenging issue to effectively detect the real laser-induced damage changes of optical elements in optical images. Different from the traditional methods, in this paper, we put forward a similarity metric optimization driven supervised learning model to perform the laser-induced damage change detection task. In the proposed model, an end-toend siamese convolutional neural network is designed and trained which can integrate the difference image generating and difference image analysis into a whole network. Thus, the damage changes can be highlighted by the pre-trained siamese network that classifies the central pixel between input multi-temporal image patches into changed and unchanged classes. To address the problem of unbalanced distribution between positive and negative samples, a modified average frequency balancing based weighted softmax loss is used to train the proposed network. Experiments conducted on two real datasets demonstrate the effectiveness and superiority of the proposed model. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106015	10.1016/j.asoc.2019.106015													
J								A reversible privacy-preserving clustering technique based on k-means algorithm	APPLIED SOFT COMPUTING										Privacy invasion; Privacy-Preserving Data Mining; Reversible privacy-preserving clustering; k-means		Data mining techniques can efficiently extract valuable knowledge from the data. However, data publishing and mining may result in a potential threat: privacy invasion. Privacy-Preserving Data Mining (PPDM) aims at effectively protecting the privacy while retaining the knowledge contained in the original data, which has received much attention in recent years. PPDM techniques often use methods such as swap, modification, and deletion to protect the original data so that no correlation exists between the original data and the resultant protected data. As a result, it cannot recover the original data from the protected data. However, in certain applications, a reliance on the original data to perform precision analysis is necessary, and consequently the storage of the original data is of great importance. In this paper, we use the concept of the k-means algorithm and propose a Reversible Privacy-Preserving k-means Clustering (kRPP) algorithm for protecting the clustering knowledge of a dataset. The experimental results show that adding noises to a cluster with a minimum total distance in the kRPP algorithm, there is no significant effect on the movement of centroids, Precision, Recall, and F1 when the noise ratio or noise offset ratio increases. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105995	10.1016/j.asoc.2019.105995													
J								Lion swarm optimization algorithm for comparative study with application to optimal dispatch of cascade hydropower stations	APPLIED SOFT COMPUTING										Meta-heuristic algorithm; Lion swarm optimization (LSO) algorithm; Nature-inspired algorithm; Optimal dispatch; Cascade hydropower stations	ATOM SEARCH OPTIMIZATION; GLOBAL OPTIMIZATION; DIFFERENTIAL EVOLUTION; CROSSOVER OPERATOR; INSPIRED ALGORITHM; CUCKOO SEARCH; GSA	Lion swarm optimization (LSO) algorithm that based on the natural division of labor among lion king, lionesses and lion cubs in a pack of lions is recently introduced. To evaluate the exploration and the exploitation of the LSO algorithm comprehensively, an intensive study based on optimization problems is necessary. In this work, we firstly present the revised version of the LSO algorithm in detail. Secondly, the efficiency of LSO is evaluating using quantitative analysis, convergence analysis, statistical analysis, and robustness analysis on 60 classical numerical test problems, encompassing the Uni-modal, the Multi-modal, the Separable, the Non-separable, and the Multi-dimension problems. For comparison purposes, the results obtained by the LSO algorithm are compared against a large set of state-of-the-art optimization methods. The comparative results show that the LSO can provide significantly superior results for the US, the UN, and the MS problems regarding convergence speed, robustness, success rate, time complexity, and optimization accuracy compared with the other optimizers, and present very competitive results in terms of those indicators compared with the other optimizers. Finally, to check the applicability and robustness of the LSO algorithm, a case study on optimal dispatch problem of China's Wujiang cascade hydropower stations shows that the LSO can obtain well and reliable optimal results with average generation of 122.421180 10(8) kWh, 103.463636 10 8 kWh, and 99.3826340 10(8) kWh for three different scenarios (i.e. the wet year, the normal year and the dry year), which are satisfying compared with that of the GA, the improved CS, and the PSO in terms of optimization accuracy. Besides, regarding the convergence speed, the results are also competitive. Therefore, we can conclude that the LSO is an efficient method for solving complex problems with correlative decision variables with simple structure and excellent convergence speed. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105974	10.1016/j.asoc.2019.105974													
J								Hybrid whale optimization algorithm enhanced with Levy flight and differential evolution for job shop scheduling problems	APPLIED SOFT COMPUTING										Job shop scheduling problem; Whale optimization algorithm; Levy flight; Differential evolution	LEARNING-BASED OPTIMIZATION; BEE COLONY ALGORITHM; GREY WOLF OPTIMIZER; GENETIC ALGORITHM; LOCAL SEARCH; ANT COLONY; FLOW-SHOP; PARAMETER-ESTIMATION; GLOBAL OPTIMIZATION; TABU SEARCH	The job shop scheduling problem (JSSP) has been a hot issue in manufacturing. For the past few decades, scholars have been attracted to research JSSP and proposed many novel meta-heuristic algorithms to solve it. Whale optimization algorithm (WOA) is such a novel meta-heuristic algorithm and has been proven to be efficient in solving real-world optimization problems in the literature. This paper proposes a hybrid WOA enhanced with Levy flight and differential evolution (WOA-LFDE) to solve JSSP. By changing the expression of Levy flight and DE search strategy, Levy flight enhances the abilities of global search and convergence of WOA in iteration, while DE algorithm improves the exploitation and local search capabilities of WOA and keeps the diversity of solutions to escape local optima. It is then applied to solve 88 JSSP benchmark instances and compared with other state-of-art algorithms. The experimental results and statistical analysis show that the proposed algorithm has superior performance over contesting algorithms. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105954	10.1016/j.asoc.2019.105954													
J								Cooperative particle swarm optimization with reference-point-based prediction strategy for dynamic multiobjective optimization	APPLIED SOFT COMPUTING										Particle swarm optimization (PSO); Dynamic multiobjective optimization problems (DMOPs); Information reuse; Coevolutionary; Prediction	ALGORITHM; SYSTEMS	Dynamic multiobjective optimization problems (DMOPs) have received increasing attention in the evolutionary community in recent years. The problem environment of a DMOP dynamically changes over time, causing the movement of the Pareto front (PF). It is critical but challenging to find the new PF in a new environment by reusing historical information of past environments since the successive environments are often relevant. Thus, we propose a new cooperative particle swarm optimization with a reference-point-based prediction strategy to solve DMOPs. In the proposed method, multiple swarms cooperate to approximate the whole PF with a new learning strategy in dynamic environments. Specially, when the environment is changed, the outdated particles are relocated based on the PF subparts they belong to using the novel reference-point-based prediction strategy. The proposed algorithm has been evaluated on the very recent scalable dynamic problem test suite with different numbers of objectives and different change severity. Experimental results show that the proposed algorithm is competitive to other typical state-of-the-art dynamic multiobjective algorithms and can find well-diversified and well-converged solution sets in dynamic environments. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105988	10.1016/j.asoc.2019.105988													
J								A hybrid optimized error correction system for time series forecasting	APPLIED SOFT COMPUTING										Time series forecasting; Particle swarm optimization; Extreme learning machines; Hybrid intelligent systems; Artificial neural networks	ARTIFICIAL NEURAL-NETWORKS; ANN MODEL; ARIMA; PERFORMANCE; PREDICTION; FILTER	Time series forecasting is a challenging task in machine learning. Real world time series are often composed by linear and nonlinear structures which need to be mapped by some forecasting method. Linear methods such as autoregressive integrated moving average (ARIMA) and nonlinear methods such as artificial neural networks (ANNs) could be employed to handle such problems, however model misspecification hinders the forecasting process producing inaccurate models. Hybrid models based on error forecasting and combination can reduce the misspecification of single models and improve the accuracy of the system. This work proposes a hybrid system that is composed of three parts: a) linear modeling of the time series, b) nonlinear modeling of the error series, and c) combination of the forecasts using three distinct approaches. The system performs a search for the best parameters of the linear and nonlinear components, and of the combination approaches. Particle swarm optimization is used to find suitable architecture and weights. Experiments show that the proposed technique achieved promising results in time series forecasting. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105970	10.1016/j.asoc.2019.105970													
J								Likelihood-based hybrid ORESTE method for evaluating the thermal comfort in underground mines	APPLIED SOFT COMPUTING										Thermal comfort; Underground mines; ORESTE method; Picture fuzzy numbers; Likelihood	DECISION-MAKING; RISK ANALYSIS; FUZZY; SETS	A thermal environment has many adverse effects on the safety and health of workers. Especially in an underground mining context, thermal hazards become more serious as mining depth increases. This study aims to find a suitable method for evaluating the thermal comfort in underground mines. First, considering the ambiguity of human thinking, picture fuzzy numbers (PFNs) are adopted to indicate the subjective evaluation information. Then, the likelihood is defined to measure the priority degree of two PFNs. Subsequently, the Organisation, rangement et Synthese de donnees relarionnelles (in French) (ORESTE) is extended with hybrid evaluation information to solve the non-compensation problems of the indexes. Finally, the likelihood-based hybrid decision making framework is successfully implemented in a case study that assesses the thermal comfort in a copper mine in China. The evaluation results are reasonable and consistent with the field conditions. Additionally, the strengths of this methodology are validated through comparison analyses. The results show that the proposed decision-making framework is reliable and stable for evaluating the thermal comfort in underground mines and can provide references for the prevention and management of thermal hazards. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105983	10.1016/j.asoc.2019.105983													
J								Short-term forecasting of renewable energy consumption: Augmentation of a modified grey model with a Kalman filter	APPLIED SOFT COMPUTING										Grey model; Kalman filter; Genetic algorithm; Renewable energy	ECONOMIC-GROWTH EVIDENCE; CO2 EMISSIONS; RELATIONAL ANALYSIS; PREDICTION MODEL; STATE; CHINA; IMPACT; GMC(1; GDP	One of the important global trends in near future is to replace fossil-fuel energy with sustainable energy. The accurate predictions of the renewable energy consumption are seemingly crucial in both national and international levels. In the context of a limited number of historical data, grey prediction system of single variable is one of primary choices for such prediction. Nonetheless, this seems rather sceptical when the dynamics of a system relies on solely one variable. This paper presents a novel approach based on a modification of multivariable grey prediction model whereby the influences of exogenous variables are taken into account. Furthermore, instead of employing the least square method for parameter estimation, states and parameters in our proposed method are sequentially estimated by means of the traditional Kalman filtering. The genetic algorithm is additionally supplemented in the Kalman filter step in order to justify some unknown noise statistics. To validate the effectiveness of the proposed scheme, it is employed to estimate and predict the renewable energy consumption in Thailand along with its associated factors using the data from 1990 to 2015. Compared with the multivariable grey model using the least square method for estimation of model parameters, the results show that the hybrid approach provides a better estimation and prediction performance. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105994	10.1016/j.asoc.2019.105994													
J								Sparse feature selection: Relevance, redundancy and locality structure preserving guided by pairwise constraints	APPLIED SOFT COMPUTING										Sparse feature selection; l(1)-norm; Pairwise redundancy; Graph Laplacian; Locality structure preserving; Pairwise constraints	UNSUPERVISED FEATURE-SELECTION; VARIABLE SELECTION; CLASSIFICATION; REGULARIZATION; PREDICTION; REGRESSION; TUMOR; LASSO	Selection of features as a pre-processing stage is an essential issue in many machine learning tasks (such as classification) to reduce data dimensionality as there are many irrelevant and redundant features that can mislead the learning process. Graph-based sparse feature selection is developed to overcome this issue. In this paper, a novel graph-based sparse feature selection method is proposed that take into account both issues: relevancy and redundancy analysis. An empirical loss function joining with l(1)-norm regularization term is proposed to overcome the relevancy issue and the redundancy issue is overcome by introducing a regularization term that prefers uncorrelated features. Furthermore, the proposed learning procedure is guided by two different sets of supervision information as pairs of must-linked (positive) and cannot-linked (negative) constraint sets to select a discriminative feature subset. These guiding information besides the whole data points are encoded in the graph Laplacian matrix that preserves the locality structure of the original data. The graph Laplacian matrix is constructed by two different approaches. Our first approach tries to preserve the structure of the original data guided just by the positive data points (unique samples in the must-linked constraints), and our second approach applies a normalized adapted affinity matrix to embed the pairwise must-linked and cannot-linked constraints as well as the neighborhood relationships information, all together. The experimental results on a number of several datasets from the University of California-Irvine machine learning repository, in addition to several high dimensional gene expression datasets show the efficacy of the proposed methods in the classification tasks compared to several powerful feature selection methods. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105956	10.1016/j.asoc.2019.105956													
J								Community detection in networks using bio-inspired optimization: Latest developments, new results and perspectives with a selection of recent meta-heuristics	APPLIED SOFT COMPUTING										Bio-inspired computation; Community detection; Network partition; Evolutionary computation; Swarm intelligence	MULTIOBJECTIVE EVOLUTIONARY ALGORITHM; PARTICLE SWARM OPTIMIZATION; CUCKOO SEARCH ALGORITHM; DYNAMIC SOCIAL NETWORKS; WATER CYCLE ALGORITHM; GENETIC ALGORITHM; MEMETIC ALGORITHM; BAT ALGORITHM; FIREFLY ALGORITHM; DISCRETE	Detecting groups within a set of interconnected nodes is a widely addressed problem that can model a diversity of applications. Unfortunately, detecting the optimal partition of a network is a computationally demanding task, usually conducted by means of optimization methods. Among them, randomized search heuristics have been proven to be efficient approaches. This manuscript is devoted to providing an overview of community detection problems from the perspective of bio-inspired computation. To this end, we first review the recent history of this research area, placing emphasis on milestone studies contributed in the last five years. Next, we present an extensive experimental study to assess the performance of a selection of modern heuristics over weighted directed network instances. Specifically, we combine seven global search heuristics based on two different similarity metrics and eight heterogeneous search operators designed ad-hoc. We compare our methods with six different community detection techniques over a benchmark of 17 Lancichinetti-Fortunato-Radicchi network instances. Ranking statistics of the tested algorithms reveal that the proposed methods perform competitively, but the high variability of the rankings leads to the main conclusion: no clear winner can be declared. This finding aligns with community detection tools available in the literature that hinge on a sequential application of different algorithms in search for the best performing counterpart. We end our research by sharing our envisioned status of this area, for which we identify challenges and opportunities which should stimulate research efforts in years to come. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106010	10.1016/j.asoc.2019.106010													
J								A fuzzy Full Consistency Method-Dombi-Bonferroni model for prioritizing transportation demand management measures	APPLIED SOFT COMPUTING										Transport demand management; Sustainable mobility; Pull-push measures; Urban transport; Fuzzy FUCOM; Multi-criteria decision making	CONGESTION; POLICY; OPERATORS	The selection and prioritization of appropriate Transportation Demand Management (TDM) measures is a common problem faced by transport planners and decision makers. The problem involves many uncertainties due to changing economic conditions, uncertainty in project success, changes in mobility and population characteristics etc. In this study, the multi-criteria decision making (MCDM) based fuzzy Full Consistency Method-Dombi-Bonferroni (fuzzy FUCOM-D'Bonferroni) model is proposed for a case study in Istanbul's urban mobility system. Istanbul's historical peninsula is considered to be a pilot area for the implementation of TDM projects by the local government. The proposed model is compared with other well-known four MCDM methods in order to show its validity and consistency. The results show that public transport capacity improvements is the best alternative among the other TDM measures. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105952	10.1016/j.asoc.2019.105952													
J								An efficient feature selection based Bayesian and Rough set approach for intrusion detection	APPLIED SOFT COMPUTING										Intrusion detection system; CICIDS2017 dataset evaluation; Dataset realism; Feature selection; Rough set theory; Bayes theorem	NAIVE BAYES; CLASSIFICATION; SVM	The exponential growth of network size leads to increase attacks and intrusions. Detection of these attacks from the network has turned into a noteworthy issue of security. An intrusion detection system is an important approach to achieves high detection rate. A high dimensional dataset increase complexities of detection systems. In this paper, we have designed a novel intelligent system that comprises the feature selection with a hybrid approach of the Rough set theory and the Bayes theorem. The proposed feature selection computed core features and ranked them based on estimated probability. In a decision system, an object may belong to a single or multiple decision, and a feature contains a set of objects that occurrences compute an estimated probability. The rough set theory is being applied to classify information into lower and upper approximations. Uncertain information is distinguished using rough set approximations and solved by the Bayes theorem. In this research work, it has also been highlighted the quantitative realism of recently generated dataset and compared to publicly available datasets. This approach reduces false alarm rate, computational complexity, training complexity and increases detection rate. Comparisons with relevant classifiers are also tabled that show proposed method performs better than existing classifiers. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105980	10.1016/j.asoc.2019.105980													
J								Representing complex intuitionistic fuzzy set by quaternion numbers and applications to decision making	APPLIED SOFT COMPUTING										Quaternion number; Intuitionistic fuzzy set; Complex intuitionistic fuzzy set	DISTANCE MEASURE; INFORMATION; CONSENSUS	Intuitionistic fuzzy sets are useful for modeling uncertain data of realistic problems. In this paper, we generalize and expand the utility of complex intuitionistic fuzzy sets using the space of quaternion numbers. The proposed representation can capture composite features and convey multi-dimensional fuzzy information via the functions of real membership, imaginary membership, real non-membership, and imaginary non-membership. We analyze the order relations and logic operations of the complex intuitionistic fuzzy set theory and introduce new operations based on quaternion numbers. We also present two quaternion distance measures in algebraic and polar forms and analyze their properties. We apply the quaternion representations and measures to decision-making models. The proposed model is experimentally validated in medical diagnosis, which is an emerging application for tackling patient's symptoms and attributes of diseases. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105961	10.1016/j.asoc.2019.105961													
J								Using pairwise precedences for solving the linear ordering problem	APPLIED SOFT COMPUTING										Linear ordering problem; Variable neighborhood search; Construction heuristic; Precedences	SEARCH; METAHEURISTICS; ALGORITHMS	It is an old claim that, in order to design a (meta)heuristic algorithm for solving a given optimization problem, algorithm designers need first to gain a deep insight into the structure of the problem. Nevertheless, in recent years, we have seen an incredible rise of "new" meta-heuristic paradigms that have been applied to any type of optimization problem without even considering the features of these problems. In this work, we put this initial claim into practice and try to solve a classical permutation problem: the Linear Ordering Problem (LOP). To that end, first, we study the structure of the LOP by focusing on the relation between the pairwise precedences of items in the solution and its objective value. In a second step, we design a new meta-heuristic scheme, namely CD-RVNS, that incorporates critical information about the problem in its three key algorithmic components: a variable neighborhood search algorithm, a construction heuristic, and a destruction procedure. Conducted experiments, on the most challenging LOP instances available in the literature, reveal an outstanding performance when compared to existing algorithms. Moreover, we also demonstrate (experimentally) that the developed heuristic procedures perform individually better than their state-of-the-art counterparts. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105998	10.1016/j.asoc.2019.105998													
J								Uncertain demand estimation with optimization of time and cost using Facebook disaster map in emergency relief operation	APPLIED SOFT COMPUTING										Disaster relief; Social media; Facebook disaster map; Intensity of demand; LINGO; Genetic algorithm	SOCIAL MEDIA; TRANSPORTATION MODEL; DECISION-MAKING; OR/MS RESEARCH; ALLOCATION; MULTICOMMODITY; MANAGEMENT; LOCATION	When a disaster disrupts a society within a moment without a little warning, the living people of those areas face the deprivation due to demolition. Facebook, one of the most popular social media plays a vital role in response to the victims. The authority of Facebook has launched safety check feature to know about the requirement after the disruption of disaster and based on the information, a intensity factor is defined for requirement of relief products in this research work. Estimating the amount of relief products through intensity measure, our research work has introduced a mathematical model for initiation of humanitarian logistic operation plan. The research has focused on two objective functions through the mathematical model which are minimization of total cost and response time. The model with two objective functions is converted to a equivalent compromise model with neutrosophic compromise programming approach. Deterministic and non-deterministic both algorithms are implemented in the solution process of the compromise mathematical model. In deterministic approach, mathematical model is varified with different methods to obtain compromise results. For non-deterministic approach, a genetic algorithm is proposed to solve the model. The model is experienced with a numerical example and hereby statistical investigation is performed considering different dimension varying the parameters of the model. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105992	10.1016/j.asoc.2019.105992													
J								A novel method for constructing the optimal hierarchical structure based on fuzzy granular space	APPLIED SOFT COMPUTING										Granular computing; Fuzzy hierarchical evaluation index; Optimization model; Multi-level structure	DECISION-MAKING; INFORMATION; CONSENSUS; NUMBER; VIRUS	Granular computing serves as a general framework for complex problem solving in broad scopes and at various levels. The granularity was constructed via many ways, however, for complex systems there remain two challenges including determining a reasonable granularity and extracting the hierarchical information. In this paper, a new method is presented for constructing the optimal hierarchical structure based on fuzzy granular space. Firstly, the inter-class deviations and intra-class deviations were introduced, whose properties were investigated in depth and approved mathematically. Secondly, the fuzzy hierarchical evaluation index is developed, followed with a novel model for extracting the global optimal hierarchical structure established. An algorithm is then proposed, which reliably constructs the multi-level structure of complex system. Finally, to reduce the complexity, the granular signatures are extracted according to the nearest-to-center principle; with the use of the signatures, a classifier is designed for verifying our method. The validation of this method is approved by an application to the H1N1 influenza virus system. The theories and methodologies on granular computing presented here are helpful for capturing the structural information of complex system, especially for data mining and knowledge discovery. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105962	10.1016/j.asoc.2019.105962													
J								Fuzzy C-Means clustering through SSIM and patch for image segmentation	APPLIED SOFT COMPUTING										Image segmentation; Fuzzy C-Means (FCM) clustering; Structural similarity (SSIM); Image patch	LOCAL INFORMATION; MEANS ALGORITHM	In this study, we propose a new robust Fuzzy C-Means (FCM) algorithm for image segmentation called the patch-based fuzzy local similarity c-means (PFLSCM). First of all, the weighted sum distance of image patch is employed to determine the distance of the image pixel and the cluster center, where the comprehensive image features are considered instead of a simple level of brightness (gray value). Second, the structural similarity (SSIM) index takes into account similar degrees of luminance, contrast, and structure of image. The DSSIM (distance for structural similarity) metric is developed on a basis of SSIM in order to characterize the distance between two pixels in the whole image. Next a new similarity measure is proposed. Furthermore, a new fuzzy coefficient is proposed via the new similarity measure together with the weighted sum distance of image patch, and then the PFLSCM algorithm is put forward based on the idea of image patch and this coefficient. Through a collection of experimental studies using synthetic and publicly available images, we demonstrate that the proposed PFLSCM algorithm achieves improved segmentation performance in comparison with the results produced by some related FCM-based algorithms. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105928	10.1016/j.asoc.2019.105928													
J								Artificial bee colony directive for continuous optimization	APPLIED SOFT COMPUTING										Artificial bee colony; Continuous optimization; Search regions; Search strategies	PARTICLE SWARM OPTIMIZATION; ALGORITHM; STRATEGY; HEAT	The artificial bee colony (ABC) algorithm, a relatively new swarm intelligence optimization technique, has been shown to be a competitive alternative to other population-based algorithms. This paper fundamentally modifies the solution search equations of the ABC in a manner that sends bee agents in search of three types of search regions that improve convergence speeds and proposes an innovative artificial bee colony directive (ABCD) algorithm. Moreover, this paper validates the ABCD algorithm by showing better performance by improving two familiar ABC variants in experimental tests. In addition, 10 applicable search strategies that adopt the proposed three search-region types are presented. The proposed ABCD not only improves the original ABC and its subsequently improved versions but is also useful for setting the search regions of other swarm intelligence algorithms. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105982	10.1016/j.asoc.2019.105982													
J								A bi-projection model based on linguistic terms with weakened hedges and its application in risk allocation	APPLIED SOFT COMPUTING										Bi-projection method; Linguistic terms with weakened hedges; Qualitative decision-making; Risk allocation	QUALITATIVE DECISION-MAKING; SUPPLIER SELECTION; PPP; ENVIRONMENT; OPERATORS; VIKOR; SETS; AHP	Risk allocation is a key point to improve the efficiency of the public private partnership (PPP) project. During the process of risk allocation, qualitative information cannot be avoided. A bi-projection model is proposed to resolve the qualitative decision-making (QDM) problem in the process of risk allocation when qualitative information is represented by linguistic terms with weakened hedges (LTWHs). The semantics and syntax of LTWHs are discussed firstly, then the basic conceptions of the bi-projection model are defined afterwards. Secondly, we develop the process of bi-projection model based on LTWHs. Then, a case study of risk allocation is used to illustrate the availability and effectiveness of the proposed model. Moreover, the proposed method is compared with the TOPSIS and VIKOR methods. The result shows that the proposed method not only takes the weakened hedges as a component, but also reduces the problem of lacking information, along with increasing the objectivity of the decision-making process. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105996	10.1016/j.asoc.2019.105996													
J								Local feature selection based on artificial immune system for classification	APPLIED SOFT COMPUTING										Local feature selection; Artificial immune system; Clonal selection algorithm; Dimensionality reduction; Classification	OPTIMIZATION ALGORITHM; MUTUAL INFORMATION; RELEVANCE	Conventional feature selection algorithms select a global feature subset for the entire sample space. In contrast, in this paper we propose an efficient filter local feature selection algorithm based on artificial immune system, which assigns a locally relevant feature subset for each neighboring region of the sample space. This algorithm introduces a clonal selection algorithm to explore the search space for the optimal feature subsets, and adopts local clustering idea as an evaluation criterion that maximizes the inter-class distance and minimizes the intra-class distance in the small region of each sample. Experimental results on a wide variety of synthetic and UCI datasets demonstrates that our proposed method achieves better performance than both state-of-the-art global feature selection algorithms and local feature selection algorithms. In addition, a main parameter analysis of the proposed method is carried out. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105989	10.1016/j.asoc.2019.105989													
J								Classification of power loads based on an improved denoising deconvolutional auto-encoder	APPLIED SOFT COMPUTING										Deconvolution; Denoising auto-encoder; Unsupervised pre-training; Power load recognition; Power quality	TRANSFORM	Machine learning has a wide range of applications in the recognition of power loads (PLs). In the light of the problems, such as poor generalization and the ease of falling into the local optima existing in the current PL classification algorithms, an improved algorithm based on the denoising deconvolutional auto-encoder was proposed to classify the field PL data. With the mirror symmetric structure of the network, the convolutional module can extract the distinctive features, while the deconvolutional module can reduce data redundancy and maintain high activation pixels. The data preprocessing accomplishes data dimensionality reduction. In order to accelerate convergence and improve classification accuracy, the unsupervised pre-training and l(2), regularization were used. The experimental results in the field data of a provincial power grid demonstrate that the proposed algorithm has a better generalization performance and a higher recognition rate than other algorithms, thus providing an efficient and objective way for PLs recognition. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105959	10.1016/j.asoc.2019.105959													
J								A novel combined forecasting system for air pollutants concentration based on fuzzy theory and optimization of aggregation weight	APPLIED SOFT COMPUTING										Fuzzy theory; Combined forecasting; Model selection and aggregation; Cross validation; Air pollution	TIME-SERIES ANALYSIS; ELECTRICITY CONSUMPTION; CROSS-VALIDATION; MODEL; POLLUTION; CHINA; ALGORITHM; MACHINE; CITIES	Effective forecasting of the air pollutant concentration is crucial for a robust air quality early-warning system and has both theoretical and practical significance. However, the accidental and cognitive uncertainty in the model selection or parameter setting of a single system will result in inaccurate and unstable forecasting results. Thus, in this paper, a novel fuzzy combination forecasting system based on the data preprocessing, fuzzy theory, and advanced optimization algorithm is proposed to improve the accuracy and stability of forecasting results. Based on the fuzzy theory and decorrelation maximization method, our proposed forecasting system can considering more information and maintaining the diversity of models. Moreover, Cuckoo Search algorithm applied in the system can determine the optimal weights for models aggregation. Several experiments based on PM2.5 and PM10 datasets in three cities are analyzed and discussed to verify the excellent performance of our proposed forecasting system, and the results indicate that the forecasting system outperforms others with respect to the accuracy, stability and generalization capabilities which are the basis of a robust air quality early-warning system in practice. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105972	10.1016/j.asoc.2019.105972													
J								An enhanced multi-objective grey wolf optimizer for service composition in cloud manufacturing	APPLIED SOFT COMPUTING										Cloud manufacturing; Service composition; Multi-objective optimization; Energy consumption; Grey wolf optimizer	ARTIFICIAL BEE COLONY; ENERGY-CONSUMPTION; SCHEDULING PROBLEM; GENETIC ALGORITHM; SELECTION; ALLOCATION; RESOURCES; FRAMEWORK; INTERNET; DESIGN	This paper presents an enhanced multi-objective grey wolf optimizer (EMOGWO) for multi-objective service composition and optimal selection (MO-SCOS) problem in cloud manufacturing, wherein both the quality of service and the energy consumption are considered from the perspectives of sustainable manufacturing. Given that there are still deficiencies in local optimum and diversity for the original multi-objective grey wolf optimizer (MOGWO). in response, the backward learning strategy is employed to heighten the exploration of initial population, so as to increase the search efficiency. Then, in order to improve the diversity, a nonlinear adjustment strategy for control parameter is proposed to enhance the global exploration of the algorithm. Besides, an enhanced search strategy, which strengthens the exploration of leaders, is designed to avoid the local optimum. Finally, the comparative study with typical multi-objective algorithms for MO-SCOS problems and benchmark problems are carried out to verify the proposed approach. simulation results suggest that the improvements for MOGWO are effective, and the proposed EMOGWO obtains better performance over other compared algorithms. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								106003	10.1016/j.asoc.2019.106003													
J								SPCM: Image quality assessment based on symmetry phase congruency	APPLIED SOFT COMPUTING										Image quality assessment; Phase congruency; Symmetry phase congruency; Symmetry phase congruency metric	INFORMATION; REDUCTION	Phase congruency (PC) algorithm is a frequency based algorithm. Instead of processing image spatially, the PC algorithm calculates the phase and amplitude of individual frequency components in the frequency domain. As one of the successful algorithm of image feature detection, PC has some advantages in the image quality assessment, however it has some inherent limitations. This paper studies the applications of symmetry phase in image quality assessment (IQA) and proposes a metric based on symmetry phase congruency (SPC). Symmetry phase congruency overcomes the limitations of phase congruency during the feature detection of image. This paper proposes a new IQA metric which is named as the symmetry phase congruency metric (SPCM). The sign responses of neighboring pixels are used to find the location of symmetry phases and then the symmetry phase congruency is used to detect image features and assess image quality. The experimental results show that SPCM is more sensitive to structural features of image and more robust to noises, and SPCM can achieve a higher consistency with the subjective evaluation of image quality. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105987	10.1016/j.asoc.2019.105987													
J								Clustering-based method for large group decision making with hesitant fuzzy linguistic information: Integrating correlation and consensus	APPLIED SOFT COMPUTING										Large group decision making (LGDM); Clustering; Correlation; Consensus; Hesitant fuzzy linguistic term sets (HFLTSs)	TERM SETS; CORRELATION-COEFFICIENTS; SIMILARITY MEASURES; MODEL; DISTANCE; MAKERS	Aiming at the large-scale experts and the lower consensus in large group decision making, a novel clustering-based method integrating correlation and consensus of hesitant fuzzy linguistic information is proposed. Firstly, develop a new hesitant degree function for hesitant fuzzy linguistic element considering its scale. Secondly, put forward the correlation measure and consensus measure models combining the hesitant degree. And then present a clustering method integrating the correlation and consensus to divide the large-scale experts into several clusters. The clustering method simultaneously ensures the cohesion of clusters and the gradual increasing of the collective consensus level. After clustering, activate the selection process to update the weights of clusters combining the number of experts in clusters and the consensus level of clusters and use the score function considering the hesitant degree to rank the alternatives. Finally, a case and some comparisons are studied and analyzed to verify the rationality and effectiveness of the method. (C) 2019 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				FEB	2020	87								105973	10.1016/j.asoc.2019.105973													
J								Accuracy of approximation operators during covering evolutions	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Covering evolution; Covering-based rough set; Neighborhood operator; Core system; Accuracy of approximation operator	ROUGH SETS; NEIGHBORHOOD OPERATORS	We express our concern over two issues in this paper: one is which characters are foundational for multitudinous covering-based rough models as generalizations of Pawlak's rough sets, i.e., which properties of covering-based rough sets guarantee the consistency of them and Pawlak's over partitions; the other is how to utilize this equivalence in simplifying diverse covering-based approximation operators. We demonstrate that covering-based rough models are equivalent to Pawlak's on partitions if they satisfy granule selection principles, which are weaker than a combination of contraction, extension, monotonicity, addition and granularity. In order to take advantage of their equivalence, we illustrate a method named "covering evolution" to change granules from given coverings to corresponding partitions for covering-based approximation operators. The evolutions can be divided into three steps: at the beginning, coverings are transformed into 1-neighborhood systems based on some quintessential neighborhood operators, then in the middle, more-refined 1-neighborhood systems are built by using "cores" from general topology, and at last, core systems (in fact, partitions) are extracted from these more-refined 1-neighborhood systems. We lay a strong emphasis on the variations in accuracy of six representative covering-based approximation operators during three evolutions, two of which preserve the accuracy of approximation operators. The investigation carried on covering evolutions helps us to establish the corresponding mapping relationship from covering spaces to partition spaces directly, and therefore provides a convenient method for making choice of covering-based approximation operators as they are consistent with the classical Pawlak's rough sets over partitions. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						1	14		10.1016/j.ijar.2019.10.012													
J								A bias-variance based heuristic for constructing a hybrid logistic regression-naive Bayes model for classification	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Logistic regression; Naive Bayes; Hybrid discriminative-generative model; Bias-variance strategy; Model construction heuristic	VS. GENERATIVE CLASSIFIERS	Discriminative classifiers tend to have lower asymptotic classification errors, while generative classifiers can be more accurate when the training set size is small. In this paper, we examine the construction of hybrid models from categorical data, where we use logistic regression (LR) as a discriminative component, and naive Bayes (NB) as a generative component. We adopt a bias-variance tradeoff based strategy, with the objective of minimizing the sum of these two errors. Specifically, the proposed heuristic consists of functions of training sample size and conditional dependence among features. These functions serve as proxies for model variance and model bias. We implement our method on 25 different classification datasets, and find that the hybrid model does better than pure LR and pure NB. Our proposed method is competitive with random forest. Although the hybrid model fails to beat LASSO in predictive performance, as suggested by the experimental results, the difference appears to be insignificant when the number of features is small. Also, the hybrid model requires less training time than LASSO, which makes it more attractive when the training time is a big concern. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						15	28		10.1016/j.ijar.2019.09.007													
J								Discovering causal graphs with cycles and latent confounders: An exact branch-and-bound approach	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Graphical models; Structure learning; Causal discovery; Branch and bound; Optimization	BAYESIAN NETWORKS; MODELS	Understanding causal relationships is a central challenge in many research endeavours. Recent research has shown the importance of accounting for feedback (cycles) and latent confounding variables, as they are prominently present in many data analysis settings. However, allowing for cycles and latent confounders makes the structure learning task especially challenging. The constraint-based approach is able to learn causal graphs even over such general search spaces, but to obtain high accuracy, the conflicting (in)dependence information in sample data need to be resolved optimally. In this work, we develop a new practical algorithmic approach to solve this computationally challenging combinatorial optimization problem. While recent advances in exact algorithmic approaches for constraint-based causal discovery build upon off-the-shelf declarative optimization solvers, we propose a first specialized branch-and-bound style exact search algorithm. Our problem-oriented approach enables directly incorporating domain knowledge for developing a wider range of specialized search techniques for the problem, including problem-specific propagators and reasoning rules, and branching heuristics together with linear programming based bounding techniques, as well as directly incorporating different constraints on the search space, such as sparsity and acyclicity constraints. We empirically evaluate our implementation of the approach, showing that it outperforms current state of art in exact constraint-based causal discovery on real-world instances. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						29	49		10.1016/j.ijar.2019.10.009													
J								Copulas and fuzzy implications	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Copula; Fuzzy implication		We introduce a new method for constructing fuzzy implications based on arbitrary two copulas and some fuzzy implication. Our approach covers two well-known constructions of fuzzy implications based on an arbitrary single copula. We also discuss some properties of the proposed method and provide several interesting examples. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						52	59		10.1016/j.ijar.2019.11.006													
J								Preference disaggregation for multiple criteria sorting with partial monotonicity constraints: Application to exposure management of nanomaterials	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Multiple criteria sorting; Incomplete information; Preference disaggregation; Non-monotonicity; Nanomaterials; Exposure management	WISE ELICITATION QUESTIONS; ADDITIVE VALUE-FUNCTIONS; ORDINAL REGRESSION; FRAMEWORK; NANOTECHNOLOGY; HEURISTICS; RANKING; SET	We propose a novel approach to multiple criteria sorting incorporating a threshold-based value-driven procedure. The parameters deciding upon the shape of marginal value functions and separating class thresholds are inferred through preference disaggregation from the Decision Maker's incomplete assignment examples and partial requirements on the type of (non-)monotonicity for each marginal value function. These types include standard monotonic shapes, level-monotonic functions, A- and V-types combining increasing and decreasing value trends, and unknown monotonicity constraints. A representative instance of the sorting model compatible with the preference information is constructed by solving a dedicated Mixed-Integer Linear Programming problem. Its complexity is controlled by minimizing the number of changes in monotonicity between all subsequent sub-intervals of marginal value functions. The assignments derived using the constructed representative model are validated against the outcomes of robustness analysis. The proposed method is applied to a real-world problem of exposure management of engineered nanomaterials. We develop a model for predicting precaution level while handling nanomaterials in certain conditions using a respirator. The model captures interrelations between ten accounted evaluation criteria, including both monotonic and non-monotonic criteria, and the recommended class assignment. This makes it suitable for the management of exposure scenarios, which have not been directly judged by the experts. (C) 2019 The Authors. Published by Elsevier Inc.																	0888-613X	1873-4731				FEB	2020	117						60	80		10.1016/j.ijar.2019.11.007													
J								A novel T-S fuzzy particle filtering algorithm based on fuzzy C-regression clustering	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										T-S fuzzy model; Particle filtering; Fuzzy C-regression clustering	TRACKING; INFORMATION; STATE	In this paper, a novel Takagi-Sugeno (T-S) fuzzy model particle filtering algorithm (TSF-PF) based on fuzzy C-regression clustering is proposed for uncertainty modeling of the target dynamic model with non-Gaussian noise. In the proposed algorithm, a generic semantic framework of the T-S fuzzy model is constructed to incorporate spatial feature information of a target into the particle filter, in which the spatial feature information is characterized by several semantic fuzzy sets. Meanwhile, a fuzzy C-regression clustering method based on correntropy is proposed to adaptively identify the premise parameters of the T-S fuzzy model, which is used to adjust the weight of models, and a Kalman filter is used to identify the consequent parameters. And then an efficient importance density function is constructed by using the proposed T-S fuzzy model, which can efficiently improve the robust and diversity of the sampling particles. Furthermore, in order to improve the real-time performance of the proposed algorithm, two improved T-S fuzzy model particle filtering algorithms are presented. The simulation results show that the tracking performance of the proposed algorithms are better than that of the traditional interacting multiple model (IMM), interacting multiple model unscented Kalman filter (IMMUKF), interacting multiple model particle filter (IMMPF) and interacting multiple model Rao-Blackwellized particle filter (IMMRBPF). Particularly, the proposed algorithms can accurately track the maneuvering target when the moving direction abruptly changes or the prior information of the target dynamic model is inaccuracy. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						81	95		10.1016/j.ijar.2019.11.005													
J								Quantitative three-way class-specific attribute reducts based on region preservations	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Rough sets; Probabilistic rough sets; Attribute reduction; Class-specific attribute reducts; Three-way decisions	DECISION-MAKING; UNCERTAINTY MEASURES; ROUGH; ENTROPY	Attribute reduction of rough set theory is effective for intelligent information processing, and class-specific attribute reducts are beneficial for pattern recognition and rule reasoning. According to three-way decisions, class-specific reducts already have three-way types (namely, positive, negative, and positive-negative) of qualitative optimization, which adhere to classical rough sets. In terms of region preservations, there are no corresponding three-way types of quantitative optimization that match probabilistic rough sets. Thus, this paper constructs and investigates quantitative three-way class-specific attribute reducts based on region preservations. First, the uncertainty/nonmonotonicity of quantitative region change is revealed, and it naturally induces the reduction criteria of quantitative region preservations. Then, quantitative three-way class-specific reducts are constructed, and their basic properties regarding their necessary conditions, attribute cores, and reduct algorithms are achieved. Furthermore, their interrelation regarding equivalence and strengthening/balance are obtained for consistent and inconsistent decision classes, respectively, and their expansions for qualitative three-way class-specific reducts are proved. Finally, relevant concepts and obtained results are effectively verified by decision tables and data experiments. By virtue of sure region preservations, quantitative three-way class-specific attribute reducts robustly extend the existing qualitative three-way class-specific reducts and facilitate the optimal identification and quantitative reasoning of class-specific patterns. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						96	121		10.1016/j.ijar.2019.11.003													
J								Multi-attribute group decision-making method based on multi-granulation weights and three-way decisions	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Multi-attribute group decision-making; Interval-valued intuitionistic uncertain; linguistic variable; Multi-granulation weight; Three-way decisions; Risk attitude	THEORETIC ROUGH SETS; LINGUISTIC ASSESSMENT; AGGREGATION OPERATORS; SCIENTOMETRICS; INFORMATION; DEVIATION; CONSENSUS; FUSION	With the increasing complexity of decision-making problems and environment, the integration and fusion of three-way decisions, rough set and multi-attribute group decision-making (MAGDM) have become a major trend in the field of decision analysis. Although many researchers have presented various MAGDM methods under different environments, there are still some imperfections, such as the weight information is not comprehensive or flexible enough, the decision results lack interpretability, and the impact of risk attitude is not fully taken into account. In order to overcome the above shortcomings and improve the scientificity and rationality of decision-making, a novel data-driven MAGDM method under interval-valued intuitionistic uncertain linguistic environment is established based on the idea of multi-granulation and three-way decisions. Our contributions can be identified as follows: (1) The multi-granulation weight mining and fusion methods for experts and attributes are proposed, respectively; (2) The coarse-granulation grading information based on three-way decisions is developed to enhance the interpretability and reference value of decision results; (3) The expected value with risk attitude factor is defined to compare interval-valued intuitionistic uncertain linguistic variables (IVIULVs) and then is used to grade and rank alternatives under different risk attitudes. To illustrate the feasibility and practicality of the proposed method, a case of logistics supplier selection in e-commerce enterprises is demonstrated. Furthermore, the advantages and characteristics of the proposed method are highlighted via detailed comparison and thorough analysis. (C) 2019 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				FEB	2020	117						122	147		10.1016/j.ijar.2019.11.008													
J								Capturing the Geometry of Object Categories from Video Supervision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Geometry; Shape; Solid modeling; Estimation; Image reconstruction; Training; Monocular pose estimation; monocular depth estimation; point-cloud estimation; geometry reconstruction		We propose an unsupervised method to learn the 3D geometry of object categories by looking around them. Differently from traditional approaches, this method does not require CAD models or manual supervision. Instead, using only video sequences showing object instances from a moving viewpoint, the method learns a deep neural network that can predict several aspects of the 3D geometry of such objects from single images. The network has three components. The first is a Siamese viewpoint factorization network that robustly aligns the input videos and learns to predict the absolute viewpoint of the object from a single image. The second is a depth estimation network that performs monocular depth prediction. The third is a shape completion network that predicts the full 3D shape of the object from the output of the monocular depth prediction module. While the three modules solve very different task, we show that they all benefit significantly from allowing networks to perform probabilistic predictions. This results in a self-assessment mechanism which is crucial for obtaining high quality predictions. Our network achieves state-of-the-art results on viewpoint prediction, depth estimation, and 3D point cloud estimation on public benchmarks.																	0162-8828	1939-3539				FEB	2020	42	2					261	275		10.1109/TPAMI.2018.2871117													
J								Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Measurement; Training; Boosting; Correlation; Feature extraction; Robustness; Task analysis; Metric learning; deep learning; convolutional neural network		Learning similarity functions between image pairs with deep neural networks yields highly correlated activations of embeddings. In this work, we show how to improve the robustness of such embeddings by exploiting the independence within ensembles. To this end, we divide the last embedding layer of a deep network into an embedding ensemble and formulate the task of training this ensemble as an online gradient boosting problem. Each learner receives a reweighted training sample from the previous learners. Further, we propose two loss functions which increase the diversity in our ensemble. These loss functions can be applied either for weight initialization or during training. Together, our contributions leverage large embedding sizes more effectively by significantly reducing correlation of the embedding and consequently increase retrieval accuracy of the embedding. Our method works with any differentiable loss function and does not introduce any additional parameters during test time. We evaluate our metric learning method on image retrieval tasks and show that it improves over state-of-the-art methods on the CUB-200-2011, Cars-196, Stanford Online Products, In-Shop Clothes Retrieval and VehicleID datasets. Therefore, our findings suggest that by dividing deep networks at the end into several smaller and diverse networks, we can significantly reduce overfitting.																	0162-8828	1939-3539				FEB	2020	42	2					276	290		10.1109/TPAMI.2018.2848925													
J								Distributed Very Large Scale Bundle Adjustment by Global Camera Consensus	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Bundle adjustment; Optimization; Convex functions; Convergence; Merging; Bundle adjustment; structure-from-motion; 3D reconstruction; distributed computing	ALTERNATING DIRECTION METHOD; PROXIMAL POINT ALGORITHM; NONCONVEX; CONVERGENCE	The increasing scale of Structure-from-Motion is fundamentally limited by the conventional optimization framework for the all-in-one global bundle adjustment. In this paper, we propose a distributed approach to coping with this global bundle adjustment for very large scale Structure-from-Motion computation. First, we derive the distributed formulation from the classical optimization algorithm ADMM, Alternating Direction Method of Multipliers, based on the global camera consensus. Then, we analyze the conditions under which the convergence of this distributed optimization would be guaranteed. In particular, we adopt over-relaxation and self-adaption schemes to improve the convergence rate. After that, we propose to split the large scale camera-point visibility graph in order to reduce the communication overheads of the distributed computing. The experiments on both public large scale SfM data-sets and our very large scale aerial photo sets demonstrate that the proposed distributed method clearly outperforms the state-of-the-art method in efficiency and accuracy.																	0162-8828	1939-3539				FEB	2020	42	2					291	303		10.1109/TPAMI.2018.2840719													
J								Globally-Optimal Inlier Set Maximisation for Camera Pose and Correspondence Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Three-dimensional displays; Robustness; Optimization; Pose estimation; Geometry; Solid modeling; Camera pose estimation; registration; camera calibration; imaging geometry; global optimisation; branch-and-bound	EFFICIENT	Estimating the 6-DoF pose of a camera from a single image relative to a 3D point-set is an important task for many computer vision applications. Perspective-n-point solvers are routinely used for camera pose estimation, but are contingent on the provision of good quality 2D-3D correspondences. However, finding cross-modality correspondences between 2D image points and a 3D point-set is non-trivial, particularly when only geometric information is known. Existing approaches to the simultaneous pose and correspondence problem use local optimisation, and are therefore unlikely to find the optimal solution without a good pose initialisation, or introduce restrictive assumptions. Since a large proportion of outliers and many local optima are common for this problem, we instead propose a robust and globally-optimal inlier set maximisation approach that jointly estimates the optimal camera pose and correspondences. Our approach employs branch-and-bound to search the 6D space of camera poses, guaranteeing global optimality without requiring a pose prior. The geometry of SE(3) is used to find novel upper and lower bounds on the number of inliers and local optimisation is integrated to accelerate convergence. The algorithm outperforms existing approaches on challenging synthetic and real datasets, reliably finding the global optimum, with a GPU implementation greatly reducing runtime.																	0162-8828	1939-3539				FEB	2020	42	2					328	342		10.1109/TPAMI.2018.2848650													
J								Hierarchical Binary CNNs for Landmark Localization with Limited Resources	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Pose estimation; Computer architecture; Face; Task analysis; Quantization (signal); Neural networks; Training; Binary convolutional neural networks; residual learning; landmark localization; human pose estimation; face alignment	POSE ESTIMATION; FACE ALIGNMENT	Our goal is to design architectures that retain the groundbreaking performance of Convolutional Neural Networks (CNNs) for landmark localization and at the same time are lightweight, compact and suitable for applications with limited computational resources. To this end, we make the following contributions: (a) we are the first to study the effect of neural network binarization on localization tasks, namely human pose estimation and face alignment. We exhaustively evaluate various design choices, identify performance bottlenecks, and more importantly propose multiple orthogonal ways to boost performance. (b) Based on our analysis, we propose a novel hierarchical, parallel and multi-scale residual architecture that yields large performance improvement over the standard bottleneck block while having the same number of parameters, thus bridging the gap between the original network and its binarized counterpart. (c) We perform a large number of ablation studies that shed light on the properties and the performance of the proposed block. (d) We present results for experiments on the most challenging datasets for human pose estimation and face alignment, reporting in many cases state-of-the-art performance. (e) We further provide additional results for the problem of facial part segmentation. Code can be downloaded from https://www.adrianbulat.com/binary-cnn-landmarks.																	0162-8828	1939-3539				FEB	2020	42	2					343	356		10.1109/TPAMI.2018.2866051													
J								Leader-Based Multi-Scale Attention Deep Architecture for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Feature extraction; Cameras; Task analysis; Computer architecture; Computational modeling; Adaptation models; Clothing; Person re-identification; multi-scale deep learning; self-attention; domain generalization	NETWORK	Person re-identification (re-id) aims to match people across non-overlapping camera views in a public space. This is a challenging problem because the people captured in surveillance videos often wear similar clothing. Consequently, the differences in their appearance are typically subtle and only detectable at particular locations and scales. In this paper, we propose a deep re-id network (MuDeep) that is composed of two novel types of layers - a multi-scale deep learning layer, and a leader-based attention learning layer. Specifically, the former learns deep discriminative feature representations at different scales, while the latter utilizes the information from multiple scales to lead and determine the optimal weightings for each scale. The importance of different spatial locations for extracting discriminative features is learned explicitly via our leader-based attention learning layer. Extensive experiments are carried out to demonstrate that the proposed MuDeep outperforms the state-of-the-art on a number of benchmarks and has a better generalization ability under a domain generalization setting.																	0162-8828	1939-3539				FEB	2020	42	2					371	385		10.1109/TPAMI.2019.2928294													
J								Object Detection from Scratch with Deep Supervision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Object detection; Detectors; Task analysis; Training; Computational modeling; Linear programming; Data models; Object detection; deeply supervised networks; learning from scratch; densely connected layers		In this paper, we propose Deeply Supervised Object Detectors (DSOD), an object detection framework that can be trained from scratch. Recent advances in object detection heavily depend on the off-the-shelf models pre-trained on large-scale classification datasets like ImageNet and OpenImage. However, one problem is that adopting pre-trained models from classification to detection task may incur learning bias due to the different objective function and diverse distributions of object categories. Techniques like fine-tuning on detection task could alleviate this issue to some extent but are still not fundamental. Furthermore, transferring these pre-trained models across discrepant domains will be more difficult (e.g., from RGB to depth images). Thus, a better solution to handle these critical problems is to train object detectors from scratch, which motivates our proposed method. Previous efforts on this direction mainly failed by reasons of the limited training data and naive backbone network structures for object detection. In DSOD, we contribute a set of design principles for learning object detectors from scratch. One of the key principles is the deep supervision, enabled by layer-wise dense connections in both backbone networks and prediction layers, plays a critical role in learning good detectors from scratch. After involving several other principles, we build our DSOD based on the single-shot detection framework (SSD). We evaluate our method on PASCAL VOC 2007, 2012 and COCO datasets. DSOD achieves consistently better results than the state-of-the-art methods with much more compact models. Specifically, DSOD outperforms baseline method SSD on all three benchmarks, while requiring only 1/2 parameters. We also observe that DSOD can achieve comparable/slightly better results than Mask RCNN [1] + FPN [2] (under similar input size) with only 1/3 parameters, using no extra data or pre-trained models.																	0162-8828	1939-3539				FEB	2020	42	2					398	412		10.1109/TPAMI.2019.2922181													
J								Open Set Domain Adaptation for Image and Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Videos; Feature extraction; Image recognition; Training; Task analysis; Face recognition; Protocols; Domain adaptation; open set recognition; action recognition		Since annotating and curating large datasets is very expensive, there is a need to transfer the knowledge from existing annotated datasets to unlabelled data. Data that is relevant for a specific application, however, usually differs from publicly available datasets since it is sampled from a different domain. While domain adaptation methods compensate for such a domain shift, they assume that all categories in the target domain are known and match the categories in the source domain. Since this assumption is violated under real-world conditions, we propose an approach for open set domain adaptation where the target domain contains instances of categories that are not present in the source domain. The proposed approach achieves state-of-the-art results on various datasets for image classification and action recognition. Since the approach can be used for open set and closed set domain adaptation, as well as unsupervised and semi-supervised domain adaptation, it is a versatile tool for many applications.																	0162-8828	1939-3539				FEB	2020	42	2					413	429		10.1109/TPAMI.2018.2880750													
J								Revisiting Projective Structure from Motion: A Robust and Efficient Incremental Solution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Three-dimensional displays; Estimation; Robustness; Image reconstruction; Structure from motion; Optimization; Structure-from-motion; perspective cameras; projective reconstruction	MATRIX FACTORIZATION; MISSING DATA; RECONSTRUCTION; ALGORITHMS; AFFINE; SHAPE	This paper presents a solution to the Projective Structure from Motion (PSfM) problem able to deal efficiently with missing data, outliers and, for the first time, large scale 3D reconstruction scenarios. By embedding the projective depths into the projective parameters of the points and views, we decrease the number of unknowns to estimate and improve computational speed by optimizing standard linear Least Squares systems instead of homogeneous ones. In order to do so, we show that an extension of the linear constraints from the Generalized Projective Reconstruction Theorem can be transferred to the projective parameters, ensuring also a valid projective reconstruction in the process. We use an incremental approach that, starting from a solvable sub-problem, incrementally adds views and points until completion with a robust, outliers free, procedure. To prevent error accumulation, a refinement based on alternation between new estimations of views and points is used. This can also be done with constrained non-linear optimization. Experiments with simulated data shows that our approach is performing well, both in term of the quality of the reconstruction and the capacity to handle missing data and outliers with a reduced computational time. Finally, results on real datasets shows the ability of the method to be used in medium and large scale 3D reconstruction scenarios with high ratios of missing data (up to 98 percent).																	0162-8828	1939-3539				FEB	2020	42	2					430	443		10.1109/TPAMI.2018.2849973													
J								Unsupervised Generation of Free-Form and Parameterized Avatars	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Training; Gallium nitride; Avatars; Generative adversarial networks; Engines; Face; Three-dimensional displays; Deep learning; domain adaptation; neural network; cross-domain transfer; analysis by synthesis; domain transfer network; tied output synthesis		We study two problems involving the task of mapping images between different domains. The first problem, transfers an image in one domain to an analog image in another domain. The second problem, extends the previous one by mapping an input image to a tied pair, consisting of a vector of parameters and an image that is created using a graphical engine from this vector of parameters. Similar to the first problem, the mapping's objective is to have the output image as similar as possible to the input image. In both cases, no supervision is given during training in the form of matching inputs and outputs. We compare the two unsupervised learning problems to the problem of unsupervised domain adaptation, define generalization bounds that are based on discrepancy, and employ a GAN to implement network solutions that correspond to these bounds. Experimentally, our methods are shown to solve the problem of automatically creating avatars.																	0162-8828	1939-3539				FEB	2020	42	2					444	459		10.1109/TPAMI.2018.2863282													
J								SPFTN: A Joint Learning Framework for Localizing and Segmenting Objects in Weakly Labeled Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Videos; Task analysis; Reliability; Supervised learning; Object segmentation; Semantics; Feature extraction; Weakly labeled videos; object segmentation; video object localization; deep neural networks; self-paced learning	CO-SEGMENTATION; EXTRACTION	Object localization and segmentation in weakly labeled videos are two interesting yet challenging tasks. Models built for simultaneous object localization and segmentation have been explored in the conventional fully supervised learning scenario to boost the performance of each task. However, none of the existing works has attempted to jointly learn object localization and segmentation models under weak supervision. To this end, we propose a joint learning framework called Self-Paced Fine-Tuning Network (SPFTN) for localizing and segmenting objects in weakly labelled videos. Learning the deep model jointly for object localization and segmentation under weak supervision is very challenging as the learning process of each single task would face serious ambiguity issue due to the lack of bounding-box or pixel-level supervision. To address this problem, our proposed deep SPFTN model is carefully designed with a novel multi-task self-paced learning objective, which leverages the task-specific prior knowledge and the knowledge that has been already captured to infer the confident training samples for each task. By aggregating the confident knowledge from each single task to mine reliable patterns and learning deep feature representation for both tasks, the proposed learning framework can address the ambiguity issue under weak supervision with simple optimization. Comprehensive experiments on the large-scale YouTube-Objects and DAVIS datasets demonstrate that the proposed approach achieves superior performance when compared with other state-of-the-art methods and the baseline networks/models.																	0162-8828	1939-3539				FEB	2020	42	2					475	489		10.1109/TPAMI.2018.2881114													
J								Approximate Sparse Multinomial Logistic Regression for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Logistics; Hyperspectral imaging; Approximation algorithms; Taylor series; Standards; Estimation; Convergence; Sparse multinomial logistic regression; softmax; hyperspectral images; classification		We propose a new learning rule for sparse multinomial logistic regression (SMLR). The new rule is the generalization of the one proposed in the pioneering work by Krishnapuram et al. In our proposed method, the parameters of SMLR are iteratively estimated from log-posterior by using some approximations. The proposed update rule provides a faster convergence compared to the state-of the-art methods used for SMLR parameter estimation. The estimated parameters are tested on the pixel-based classification of hyperspectral images. The experimental results on real hyperspectral images show that the classification accuracy of proposed method is also better than those of the state-of-the-art methods.																	0162-8828	1939-3539				FEB	2020	42	2					490	493		10.1109/TPAMI.2019.2904062													
J								Feature Boosting Network For 3D Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Pose estimation; Two dimensional displays; Boosting; Logic gates; Reliability; Task analysis; 3D pose estimation; convolutional LSTM; long short-term dependency; context consistency gate		In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.																	0162-8828	1939-3539				FEB	2020	42	2					494	501		10.1109/TPAMI.2019.2894422													
J								Moments in Time Dataset: One Million Videos for Event Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Videos; Visualization; Feature extraction; Vocabulary; Animals; Three-dimensional displays; Convolution; Video dataset; action recognition; event recognition		We present the Moments in Time Dataset, a large-scale human-annotated collection of one million short videos corresponding to dynamic events unfolding within three seconds. Modeling the spatial-audio-temporal dynamics even for actions occurring in 3 second videos poses many challenges: meaningful events do not include only people, but also objects, animals, and natural phenomena; visual and auditory events can be symmetrical in time ("opening" is "closing" in reverse), and either transient or sustained. We describe the annotation process of our dataset (each video is tagged with one action or activity label among 339 different classes), analyze its scale and diversity in comparison to other large-scale video datasets for action recognition, and report results of several baseline models addressing separately, and jointly, three modalities: spatial, temporal and auditory. The Moments in Time dataset, designed to have a large coverage and diversity of events in both visual and auditory modalities, can serve as a new challenge to develop models that scale to the level of complexity and abstract reasoning that a human processes on a daily basis.																	0162-8828	1939-3539				FEB	2020	42	2					502	508		10.1109/TPAMI.2019.2901464													
J								A novel design of differential evolution for solving discrete traveling salesman problems	SWARM AND EVOLUTIONARY COMPUTATION										Discrete differential evolution; Combinatorial optimization problems; Traveling salesman problems; Local search; Mapping method	ANT COLONY OPTIMIZATION; COMBINATORIAL OPTIMIZATION; ACCEPTANCE CRITERION; ALGORITHM; CROSSOVER	Differential evolution is one of the most powerful and popular evolutionary algorithms, which is primarily used to solve continuous-based optimization problems. Although differential evolution has been considered unsuitable for solving many permutation-based real-world combinatorial problems, several efforts for designing an efficient discrete version of the differential evolution algorithm have occurred in recent years. This paper introduces a novel discrete differential evolution algorithm for improving the performance of the standard differential evolution algorithm when it is used to solve complex discrete traveling salesman problems. In this approach, we propose to use a combination of, 1) an improved mapping mechanism to map continuous variables to discrete ones and vice versa, 2) a k-means clustering-based repairing method for enhancing the solutions in the initial population, 3) an ensemble of mutation strategies for increasing the exploration capability of the algorithm. Finally, for improving the local capability of the proposed algorithm when solving discrete problems, two well-known local searches have also been adapted. To judge its performance, the proposed algorithm is compared with those of 27 state-of-the-art algorithms, for solving 45 instances of traveling salesman problems, with different numbers of cities. The experimental results demonstrated that our technique significantly outperforms most of the comparative methods, in terms of the average errors from the best-known solutions, and achieved very competitive results with better computational time than others.																	2210-6502	2210-6510				FEB	2020	52								100607	10.1016/j.swevo.2019.100607													
J								Handling bound constraints in CMA-ES: An experimental study	SWARM AND EVOLUTIONARY COMPUTATION										Bound constraints; CMA-ES	DIFFERENTIAL EVOLUTION; PARAMETER OPTIMIZATION; STRATEGY	Bound constraints are the lower and upper limits defined for each coordinate of the solution. There are many methods to deal with them, but there is no clear guideline for which of them should be preferred. This paper is devoted to handling bound constraints in the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) algorithm. It surveys 22 Bound Constraint Handling Methods (BCHMs). The experiments cover both unimodal and multimodal functions taken from the CEC 2017 and the BBOB benchmarks. The performance of CMA-ES was found to change when different BCHMs were used. The worst and the best BCHMs were identified. The results of CMA-ES with the best BCHM and restarts were compared on CEC 2017 with the results of recently published derivatives of Differential Evolution (DE).																	2210-6502	2210-6510				FEB	2020	52								100627	10.1016/j.swevo.2019.100627													
J								A benchmark for equality constrained multi-objective optimization	SWARM AND EVOLUTIONARY COMPUTATION										Evolutionary computation; Multi-objective optimization; Equality constraints; Benchmarking	ROUTING PROBLEM; PERFORMANCE; ALGORITHMS; SELECTION; PENALTY	Evolutionary multi-objective optimization (EMO) is certainly a story of great success considering the numerous contributions and their applications to different problems and fields during the last two decades. One issue, however, that has been almost neglected so far is the consideration of multi-objective optimization problems (MOPs) that contain equality constraints. Such constraints play a special role as the inclusion of each equality constraint typically reduces the dimension of the search space by one. Consequently, the probability for a randomly chosen candidate solution of an equality constrained MOP to be feasible is zero, which makes the treatment of such problems very hard for EMO algorithms. In this paper, we propose a new benchmark of equality constrained MOPs. The problems are derived from the well-known DTLZ and IDTLZ problems and hence inherit their properties. The new benchmarks, Eq-DTLZ and Eq-IDTLZ, are scalable both in decision and objective space as well as in the number of equality constraints. Furthermore, all Pareto sets differ from the solution sets of the unconstrained problems and can be expressed analytically which make them good candidates for testing EMO algorithms on this important problem class. Based on the new benchmark, we investigate the performance of some state-of-the-art evolutionary algorithms. The results show that the new problems are indeed hard to solve for all considered algorithms and that further investigation has to be done for the reliable treatment of equality constrained MOPs.																	2210-6502	2210-6510				FEB	2020	52								100619	10.1016/j.swevo.2019.100619													
J								An optimized model based on convolutional neural networks and orthogonal learning particle swarm optimization algorithm for plant diseases diagnosis	SWARM AND EVOLUTIONARY COMPUTATION										Deep learning; Convolutional neural networks (CNNs); Transfer learning; Hyperparameters optimization; Orthogonal learning particle swarm optimization (OLPSO); Ensemble learning; Plant disease classification; Imbalanced data	LUNG NODULES; CLASSIFICATION; IMAGES	The plant disease classification based on using digital images is very challenging. In the last decade, machine learning techniques and plant images classification tools such as deep learning can be used for recognizing, detecting and diagnosing plant diseases. Currently, deep learning technology has been used for plant disease detection and classification. In this paper, an ensemble model of two pre-trained convolutional neural networks (CNNs) namely VGG16 and VGG19 have been developed for the task plant disease diagnosis by classifying the leaves images of healthy and unhealthy. In this context, CNNs are used due to its capability of overcoming the technical problems which are associated with the classification problem of plant diseases. However, CNNs suffer from a great variety of hyperparameters with specific architectures which is considered as a challenge to identify manually the optimal hyperparameters. Therefore, orthogonal learning particle swarm optimization (OLPSO) algorithm is utilized in this paper to optimize a number of these hyperparameters by finding optimal values for these hyperparameters rather than using traditional methods such as the manual trial and error method. In this paper, to prevent CNNs from falling into the local minimum and to train efficiently, an exponentially decaying learning rate (EDLR) schema is used. In this paper, the problem of the imbalanced used dataset has been solved by using random minority oversampling and random majority undersampling methods, and some restrictions in terms of both the number and diversity of samples have been overcome. The obtained results of this work show that the accuracy of the proposed model is very competitive. The experimental results are compared with the performance of other pre-trained CNN models namely InceptionV3 and Xception, whose hyperparameters were selected using a non-evolutionary method. The comparison results demonstrated that the proposed diagnostic approach has achieved higher performance than the other models.																	2210-6502	2210-6510				FEB	2020	52								100616	10.1016/j.swevo.2019.100616													
J								Preference-based cone contraction algorithms for interactive evolutionary multiple objective optimization	SWARM AND EVOLUTIONARY COMPUTATION										Multiple objective optimization; Interactive evolutionary hybrids; Cone contraction; Pairwise comparisons; Interaction patterns	WISE ELICITATION QUESTIONS; MULTIOBJECTIVE OPTIMIZATION; GENETIC ALGORITHM; DECISION; DISAGGREGATION; MOEA/D; HEURISTICS; SET	We introduce a family of interactive evolutionary algorithms for Multiple Objective Optimization (MOO). In the phase of preference elicitation, a Decision Maker (DM) is asked to compare some pairs of solutions from the current population. Such holistic information is represented by a set of compatible instances of achievement scalarizing or quasi-convex preference functions, which contribute to the construction of preference cones in the objective space. These cones are systematically contracted during the evolutionary search, because an incremental specification of the DM's pairwise comparisons is progressively reducing the DM's most preferred region in the objective space. An inclusion of evolved solutions in this region is used along with the dominance relation to revise an elitism principle of the employed optimization algorithm. In this way, the evolutionary search is focused on a subset of Pareto optimal solutions that are particularly interesting to the DM. We investigate, moreover, how the convergence is influenced by the use of some pre-defined and newly proposed self-adjusting (dynamic) interaction patterns. We also propose a new way for visualizing the progress of an evolutionary search. It supports understanding the differences between effects of a selection pressure imposed by various optimization algorithms.																	2210-6502	2210-6510				FEB	2020	52								100602	10.1016/j.swevo.2019.100602													
J								Efficient multi-objective algorithm for the lot-streaming hybrid flowshop with variable sub-lots	SWARM AND EVOLUTIONARY COMPUTATION										Hybrid flowshop; Lot-streaming scheduling; Multi-objective optimization; Variable sub-lots	MIGRATING BIRDS OPTIMIZATION; SHOP SCHEDULING PROBLEM; BEE COLONY ALGORITHM; EVOLUTIONARY ALGORITHMS; TOTAL FLOWTIME; MINIMIZE	Recent years, the multi-objective evolutionary algorithm based on decomposition (MOEA/D) has been researched and applied for numerous optimization problems. In this study, we propose an improved version of MOEA/D with problem-specific heuristics, named PH-MOEAD, to solve the hybrid flowshop scheduling (HFS) lot-streaming problems, where the variable sub-lots constraint is considered to minimize four objectives, i.e., the penalty caused by the average sojourn time, the energy consumption in the last stage, as well as the earliness and the tardiness values. For solving this complex scheduling problem, each solution is coded by a two-vector-based solution representation, i.e., a sub-lot vector and a scheduling vector. Then, a novel mutation heuristic considering the permutations in the sub-lots is proposed, which can improve the exploitation abilities. Next, a problem-specific crossover heuristic is developed, which considered solutions with different sub-lot size, and therefore can make a solution feasible and enhance the exploration abilities of the algorithm as well. Moreover, several problem-specific lemmas are proposed and a right-shift heuristic based on them is subsequently developed, which can further improve the performance of the algorithm. Lastly, a population initialization mechanism is embedded that can assign a fit reference vector for each solution. Through comprehensive computational comparisons and statistical analysis, the highly effective performance of the proposed algorithm is favorably compared against several presented algorithms, both in solution quality and population diversity.																	2210-6502	2210-6510				FEB	2020	52								100600	10.1016/j.swevo.2019.100600													
J								A multi-objective adaptive evolutionary algorithm to extract communities in networks	SWARM AND EVOLUTIONARY COMPUTATION										Community detection; Genetic algorithm; Multi-objective; Complex networks; Adaptive	OPTIMIZATION ALGORITHM	Community structure is one of the most important attributes of complex networks, which reveals the hidden rules and behavior characteristics of complex networks. Existing works need to pre-set weight parameters to control the different emphasis on the objective function, and cannot automatically identify the number of communities. In the process of optimization, there will be some challenges, such as premature and inefficiency. This paper presents a multi-objective adaptive fast evolutionary algorithm (F-SGCD) for community detection in complex networks. Firstly, it transforms the problem of community detection into a multi-objective optimization problem and constructs two objective functions of community score and community fitness. Secondly, an external elite gene pool is introduced to store non-inferior solutions with high fitness. At the same time, an adaptive genetic operator is executed to return a set of non-dominant solutions compromised between the two objective functions. Finally, a Pareto optimal solution with the highest modularity is selected and decoded to generate a set of independent subnetworks. Experiments show that the multi-objective adaptive fast evolutionary algorithm greatly improves the accuracy of community detection in complex networks, and can discover the hierarchical structure of complex networks better.																	2210-6502	2210-6510				FEB	2020	52								100629	10.1016/j.swevo.2019.100629													
J								Unsupervised feature selection based on bio-inspired approaches	SWARM AND EVOLUTIONARY COMPUTATION										Unsupervised feature selection; Biased random-key genetic algorithm; Particle swarm optimization; Clustering; Data mining; Simulated datasets	HYBRID GENETIC ALGORITHM; K-MEANS; VARIABLE-SELECTION; OPTIMIZATION; IMPROVE	In recent years, the scientific community has witnessed an explosion in the use of pattern recognition algorithms. However, little attention has been paid to the tasks preceding the execution of these algorithms, the preprocessing activities. One of these tasks is dimensionality reduction, in which a subset of features that improves the performance of the mining algorithm is located and algorithm's runtime is reduced. Although there are many methods that address the problems in pattern recognition algorithms, effective solutions still need to be researched and explored. Hence, this paper aims to address three of the issues surrounding these algorithms. First, we propose adapting a promising meta-heuristic called biased random-key genetic algorithm, which considers a random initial population construction. We call this algorithm as unsupervised feature selection by biased random-key genetic algorithm I. Next, we propose an approach for building the initial population partly in a deterministic way. Thus, we applied this idea in two algorithms, named unsupervised feature selection by particle swarm optimization and unsupervised feature selection by biased random-key genetic algorithm II. Finally, we simulated different datasets to study the effects of relevant and irrelevant attributes, and of noisy and missing data on the performance of the algorithms. After the Wilcoxon rank-sum test, we can state that the proposed algorithms outperform all other methods in different datasets. It was also observed that the construction of the initial population in a partially deterministic way contributed to the better performance. It should be noted that some methods are more sensitive to noisy and missing data than others, as well as to relevant and irrelevant attributes.																	2210-6502	2210-6510				FEB	2020	52								100618	10.1016/j.swevo.2019.100618													
J								Multimodal Memetic Framework for low-resolution protein structure prediction	SWARM AND EVOLUTIONARY COMPUTATION										Protein structure prediction; Multimodality; Memetic algorithm	GENETIC ALGORITHM; EVOLUTIONARY ALGORITHMS; MODEL; LANDSCAPE; PATHWAYS	In this paper, we propose a systematic design of evolutionary optimization, namely Multimodal Memetic Framework (MMF), to effectively search the vast complex energy landscape. Our proposed memetic framework is implemented in hierarchical stages with the optimization of each stage performed in parallel in three different states: Exploratory, Exploitative and Central. Each state, with its own set of sub-populations, either explores or exploits by beneficial mixing of potential solutions to direct the search towards a global solution. Instead of implementing identical genetic operators, the proposed approach employs different selection and survival criteria in each state according to their designated task. The Exploratory state employs a knowledge-based initial population generation technique with appropriately tuned genetic operators to guide the search to the "nearest peak". The Exploitative state fine-tunes the individuals representing different regions by applying a building block based local search. Finally, by utilizing the imbibed knowledge from different peaks, the Central state carries out information-exchange among the highly fit solutions for exploring the undiscovered regions. The information exchange employs a novel non-random parental selection technique to distribute the reproduction opportunity intelligently among the individuals for making cross-over more effective. The method has been tested on a set of various benchmark protein sequences for 2D and 3D lattice models. The experimental results demonstrate the superiority of the proposed method over other state-of-the-art algorithms.																	2210-6502	2210-6510				FEB	2020	52								100608	10.1016/j.swevo.2019.100608													
J								Improved differential evolution for noisy optimization	SWARM AND EVOLUTIONARY COMPUTATION										Differential evolution; Stochastic noise; Learning automata; Crowding based niching; Fitness estimates	PARTICLE SWARM OPTIMIZATION; GENETIC ALGORITHMS; LEARNING AUTOMATA; ENVIRONMENTS; SEARCH; PARAMETERS	A novel approach is proposed in this paper to improve the optimization proficiency of the differential evolution (DE) algorithm in the presence of stochastic noise in the objective surface by utilizing the composite benefit of four strategies. The first strategy is devised with an aim to employ reinforcement learning scheme of stochastic learning automata for autonomous selection of the sample size of a trial solution (for its repeated fitness evaluation) based on the characteristics of the fitness landscape in its local neighborhood. The second stratagem is proposed to estimate the effective fitness measure from multiple fitness samples of a trial solution, resulting from sampling. The novelty of the second policy lies in considering the distribution of noisy samples during effective fitness evaluation, instead of their direct averaging. The third strategy deals with amelioration of the DE/current-to-best/1 mutation scheme to judiciously direct the search in promising region, even in prevailing existence of noise in the objective surface. Finally, the greedy selection policy of the traditional DE is modified by introducing the principle of probabilistic crowding induced niching to ensure both the population quality and the population diversity. Comparative analysis performed on simulation results for diverse noisy benchmark functions reveal the statistically significant superiority of the proposed algorithm to its contenders with respect to function error value.																	2210-6502	2210-6510				FEB	2020	52								100628	10.1016/j.swevo.2019.100628													
J								Dimensionality reduction in evolutionary algorithms-based feature selection for motor imagery brain-computer interface	SWARM AND EVOLUTIONARY COMPUTATION										Brain-computer interface; Evolutionary algorithms; Motor imagery; Dimensionality reduction; Feature selection	EEG; CLASSIFICATION; COMPUTATION	For the classification of motor imagery brain-computer interface (BCI) based on electroencephalography (EEG), appropriate features are crucial to obtain a high classification accuracy. Considering the characteristics of the EEG signals, the time-frequency-space three-dimensional features are extracted. Due to a considerable number of the extracted features, the performance of a classifier will degrade. Therefore, it is necessary to implement feature selection. However, existing feature selection methods are easy to fall into a local optimum of a high-dimensional feature selection problem. In this paper, a dimensionality reduction mechanism (called DimReM) is proposed, which gradually reduces the dimension of the search space by removing some unimportant features. In principle, DimReM transforms a high-dimensional feature selection problem into a low-dimensional one. DimReM does not introduce any additional parameters and its implementation is simple. To verify its effectiveness, DimReM is combined with different evolutionary algorithms and different classifiers to select features on various kinds of datasets. Compared with evolutionary algorithms without dimensionality reduction, their augmented versions equipped with DimReM can find feature subsets with higher classification accuracies while smaller numbers of selected features.																	2210-6502	2210-6510				FEB	2020	52								100597	10.1016/j.swevo.2019.100597													
J								On the efficient computation and use of multi-objective descent directions within constrained MOEAs	SWARM AND EVOLUTIONARY COMPUTATION										Evolutionary computation; Bi-objective optimization; Descent direction; Constraint handling	SEARCH METHOD; OPTIMIZATION; ALGORITHM	Multi-objective evolutionary algorithms (MOEAs) are a widely accepted choice for the numerical treatment of multi-objective optimization problems (MOPs). For constrained problems, however, these methods still have room for improvement to compute satisfactory approximations of the solution sets. A possible remedy is the hybridization of MOEAs with specialized local search mechanisms; which is not a simple task due to their high cost. In this work, we consider the information of the constraints when performing the local search, and propose a new and effective way to compute descent directions for constrained bi-objective optimization problems. Since the directions are computed via neighborhood sampling, the method is perfectly suited for the use within MOEAs or any other population based algorithm as the samples can be taken precisely from the populations. The new method can be used as local search engine within, in principle, any MOEA. As demonstrator, we will consider two particular hybrids. Numerical results on some benchmark problems support the benefits of the novel approach. Though this work focuses on the bi-objective case, this represents an important step to formalize gradient-free multi-objective descent directions and its efficient interleaving into MOEAs.																	2210-6502	2210-6510				FEB	2020	52								100617	10.1016/j.swevo.2019.100617													
J								A discrete-time switched linear model of the particle swarm optimization algorithm	SWARM AND EVOLUTIONARY COMPUTATION										Particle swarm optimization; Semistability; Paracontraction	ANT COLONY OPTIMIZATION; CONVERGENCE ANALYSIS; FUZZY-LOGIC; PSO; SEMISTABILITY; CONTROLLER; PREDICTION; STABILITY; STRENGTH; NETWORK	In this paper, the convergence issue of the Particle Swarm Optimization (PSO) algorithm is investigated. Most of the models of PSO algorithms are time-invariant linear models with the assumption the local and global best solutions do not change, i.e., the stagnation assumption. However, in this paper, a discrete-time switched linear model is introduced to study the stability and convergence of the PSO algorithm without the stagnation assumption. By considering the updates of local best positions and global best solutions, a sequence of state transform matrixes is generated during the searching process. The semistability of the proposed switched linear system is studied. The conditions of the convergence in mean and convergence in probability are derived by using the recently developed results in paracontraction. Moreover, numerical examples are provided to verify the results proposed in this paper.																	2210-6502	2210-6510				FEB	2020	52								100606	10.1016/j.swevo.2019.100606													
J								User Recruitment System for Efficient Photo Collection in Mobile Crowdsensing	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Mobile crowdsensing (MCS); photo collecting; semi-Markov; user recruitment		Mobile crowdsensing recruits a group of mobile users to cooperatively perform a common sensing job with their smart devices. As a special issue, photo crowdsensing allows users to utilize the built-in cameras of mobile devices to take photos for an event or a target. Then, the photos can be used in numerous application areas, such as target reconstruction, scenario reduction, and so on. Therefore, photo crowdsensing has attracted considerable attention recently due to the rich information that can be provided by images. In this paper, we focus on using the photos to make reconstructions for specific targets. Furthermore, we develop a user recruitment system for efficient photo collecting in mobile crowdsensing (RSMC), where the task requesters publish a sensing task to the users, and the map is gridded according to the locations of the sensing targets. Then, we use a semi-Markov model to calculate the users utility for the sensing task. Finally, a user recruitment strategy is devised to recruit the optimal $k$ users for finishing the sensing task. We conduct extensive simulations based on three widely used real-world traces: roma/taxi, epfl, and geolife. The results show that, compared with other recruitment strategies, RSMC takes the largest number of efficient photos for the sensing task.																	2168-2291	2168-2305				FEB	2020	50	1					1	12		10.1109/THMS.2019.2912509													
J								Annotation Generation From IMU-Based Human Whole-Body Motions in Daily Life Behavior	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Human motion; language; probabilistic modeling	LANGUAGE; PRIMITIVES	This article describes a stochastic framework for integrating human whole-body motions with natural language. Human whole-body motions in daily life are measured by inertial measurement units (IMU) and subsequently encoded into motion primitives. Sentences are manually attached to the human motion primitives for their descriptions. Two aspects of semantics and syntactics are represented by stochastic modules. One stochastic module trains the linking of motion primitives to words, and the other module represents word order in the sentence structure. These two modules are helpful toward converting human whole-body motions into descriptions, where multiple words are generated from the human motions by the first module, and the second module searches for syntactically consistent sentences consisting of the generated words. The proposed framework is tested on a large dataset of human whole-body motions and their descriptive sentences. The linking of human motions to natural language enables robots to understand observations of human behavior as sentences.																	2168-2291	2168-2305				FEB	2020	50	1					13	21		10.1109/THMS.2019.2960630													
J								A Novel Postprocessing Method for Robust Myoelectric Pattern-Recognition Control Through Movement Pattern Transition Detection	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Human-computer interface; movement pattern transition (MPT); myoelectric control; pattern recognition; postprocessing	UPPER-LIMB PROSTHESES; OF-THE-ART; EMG SIGNALS; SURFACE; FEATURES; SCHEME; SHIFT	Pattern-recognition-based myoelectric control systems are not yet widely available due to their limited robustness in real-life situations. Some postprocessing methods were introduced to improve the robustness in previous studies, but there is lack of investigation into movement transition phases. This article presents a novel postprocessing method based on movement pattern transition (MPT) detection. An image-based index is used to quantify the similarity of adjacent feature matrices from high-density surface electromyogram (EMG) signals. MPT detection is implemented by applying a double threshold to the calculated index. The proposed postprocessing method is used to rectify the EMG pattern recognition decisions from the classifier by incorporating the detected information. Two representative testing schemes are used to verify the robustness of the proposed method against force level variation and consecutive nonstop task performance. The proposed method achieved mean classification accuracy improvements of 7.33 and 10.91 with respect to the baseline performance of a raw classifier (without any postprocessing) in the two testing schemes. It also outperformed other common postprocessing methods (p < 0.05). Considering both the accuracy improvement and time efficiency for rapid responses to MPT, the proposed method could be a potential option for postprocessing to enhance the robustness of myoelectric control.																	2168-2291	2168-2305				FEB	2020	50	1					32	41		10.1109/THMS.2019.2953262													
J								Natural Human-Robot Interface Using Adaptive Tracking System with the Unscented Kalman Filter	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Adaptive tracking; adaptive velocity control (AVC); human-robot interface; leap motion (LM); unscented Kalman filter (UKF)	X-Y TABLE; TELEOPERATION; RECOGNITION; CONTROLLER; SPEECH	Traditional human-robot interfaces usually have limitations in accuracy andor operational space. This article proposes a natural human-robot interface using an adaptive tracking method, which can effectively expand the operational space while ensuring high accuracy. The natural interface allows the robot to directly reproduce the users hand movement, making the interaction more intuitive and natural. The leap motion is fixed on the Cartesian platform to capture the movement of the users hand. Because the Cartesian platform follows the hand and keeps the hand in the center of the detection area, the measurement accuracy is improved and the measurement space can be extended. During the process of acquiring gesture data, the measurement errors were found to increase over time because of the inherent noise of the sensor. To deal with this problem, the unscented Kalman filter is applied to estimate the position of the hand. Moreover, an adaptive velocity control method is proposed to improve the operation accuracy and reduce the task execution time with the consideration of users' habits and easiness of usage. The effectiveness of this interface is verified by a series of experiments, and the results show that the proposed interface can be used by nonprofessional users for object operation tasks and can provide users with superior interactive experiences.																	2168-2291	2168-2305				FEB	2020	50	1					42	54		10.1109/THMS.2019.2947576													
J								A New Mixed-Reality-Based Teleoperation System for Telepresence and Maneuverability Enhancement	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Force control; motion regulation; telerobotics; virtual reality	STABILITY ANALYSIS; BILATERAL TELEOPERATION; AUGMENTED REALITY; TRANSPARENCY; PERFORMANCE; FEEDBACK; INTERFACES; OBSERVER; DELAYS	Virtual reality (VR) is regarded as a useful tool for teleoperation systems and provides operators with immersive visual feedback on the robot and the environment. However, without any haptic feedback or physical constructions, VR-based teleoperation systems normally suffer from poor maneuverability, and operational faults may be caused in some fine movements. In this article, we employ mixed reality (MR), which combines real and virtual worlds, to develop a novel teleoperation system. A new system design and control algorithms are proposed. For the system design, an MR interface is developed based on a virtual environment augmented with real-time data from the task space with the goal of enhancing the operators visual perception. To allow the operator to be freely decoupled from the control loop and offload the operators burden, a new interaction proxy is proposed to control the robot. For the control algorithms, two control modes are introduced to improve the long-distance movements and fine movements of the MR-based teleoperation system. In addition, a set of fuzzy-logic-based methods are proposed to regulate the orientation, position, velocity, and force of the robot to enhance the systems maneuverability and address potential operational faults. A barrier Lyapunov function and a backstepping method are leveraged to design the control laws and simultaneously guarantee the systems stability under state constraints. Experiments conducted using a six-degree-of-freedom robotic arm prove the feasibility of the system.																	2168-2291	2168-2305				FEB	2020	50	1					55	67		10.1109/THMS.2019.2960676													
J								Effects of Target Trajectory Bandwidth on Manual Control Behavior in Pursuit and Preview Tracking	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Manual control; modeling; pursuit; preview; target trajectory bandwidth	IDENTIFICATION	The 1960s crossover model is widely applied to quantitatively predict a human controller's (HC's) manual control behavior. Unfortunately, the theory captures only compensatory tracking behavior and, as such, a limited range of real-world manual control tasks. This article finalizes recent advances in manual control theory toward more general pursuit and preview tracking tasks. It is quantified how HCs adapt their control behavior to a final crucial task variable: the target trajectory bandwidth. Beneficial adaptation strategies are first explored offline with computer simulations, using an extended crossover model theory for pursuit and preview tracking. The predictions are then verified with data from a human-in-the-loop experiment, in which participants tracked a target trajectory with bandwidths of 1.5, 2.5, and 4 rad/s, using compensatory, as well as pursuit and preview displays. In stark contrast to the crossover regression found in compensatory tasks, humans attenuate only their feedforward response when tracking higher-bandwidth trajectories in pursuit tasks, while their behavior is generally invariant in preview tasks. A full quantitative theory is now available to predict HC manual control behavior in tracking tasks, which includes HC adaptation to all key task variables.																	2168-2291	2168-2305				FEB	2020	50	1					68	78		10.1109/THMS.2019.2947577													
J								Supporting Multitracking Performance With Novel Visual, Auditory, and Tactile Displays	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Driving performance; multisensory display; multimodal information processing; tracking	MULTITASKING; MANAGEMENT; ATTENTION; WARNINGS; PITCH; TIME	This article investigates performance in multiple concurrent tracking tasks with multisensory displays in a driving context. In many work domains, such as driving, aviation, process control, and medicine, humans perform "tracking" tasks that involve observing continuous variables and providing a control input to achieve and maintain satisfactory levels in those variables. Performance in multiple concurrent tracking tasks ("multitracking") was studied in driving-like scenarios that challenged participants to track established targets for lateral (lane position) and longitudinal (speed) variables. Novel speed displays were developed to engage nontraditional sensory modalities (e.g., ambient-visual, auditory, or tactile) with relative speed conveyed through simple or multidimensional signal encoding methods. Participants' speed-tracking and lane-tracking performances were measured concurrently and compared across display configurations within-subjects. Results showed lane tracking performance to be unaffected by display configuration; however, speed tracking and overall performance were significantly improved with novel displays, compared to the baseline configuration. Redundantly encoded auditory displays best-supported multitracking performance, but redundantly encoded tactile displays were not as beneficial as were simple encodings. These results provide insight into the human information processing of semicontinuous multisensory displays and can inform display design in driving and other visually demanding work contexts.																	2168-2291	2168-2305				FEB	2020	50	1					79	88		10.1109/THMS.2019.2947580													
J								Efficacy of Incentive Structures for Boundedly Rational Dispatchers in Large-Scale Queueing Networks	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Disaster relief; dynamic decision making; queueing system; simulation	PERFORMANCE; TEAMS	This paper employs computational approaches to model and explore the efficacy of different incentive structures on the decision making behavior of dispatchers in complex queueing networks, and the subsequent effects of these decisions on teams working within the network and on network performance itself. Computational models that express network structure and function, as well as the decision making process of dispatchers operating within the network and the effect these decisions have on team performance, are presented. Performance of the network under status quo and other incentive structures and decision making processes is illustrated via simulation, validated against data from a large-scale debris removal mission that followed a series of tornadoes in the U.S. state of Alabama in 2011. Results of the simulation experiments suggest that the optimal incentive structure assuming a rational decision maker remains optimal under lower levels of rationality. Furthermore, a simple uniform reward structure is likely to produce performance improvements over the status quo incentive structure under most scenarios.																	2168-2291	2168-2305				FEB	2020	50	1					89	97		10.1109/THMS.2019.2906618													
J								Grasp Prediction Toward Naturalistic Exoskeleton Glove Control	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Exoskeleton; grasping; haptics; man-machine system; orthosis; upper limb	HAND; SYNERGIES	This paper presents accurate grasp prediction algorithms that can be used for naturalistic, synergistic control of exoskeleton gloves with minimal user input. Recent research in exoskeleton systems has focused mainly on the development of novel soft or hard mechanical designs and actuation systems for rehabilitative and assistive applications. On the other hand, estimating user intent for intelligent grasp assistance is a problem that has remained largely unaddressed. As demonstrated by existing studies, the complex motions of human hand can be mapped to a latent space, thereby reducing perceived noise in individual joint angles as well as the number of variables upon which the prediction must be performed. To this extent, we present two latent space grasp prediction algorithms for intelligent exoskeleton glove control. The first presented algorithm is based on a linear regression to determine the slope and prediction horizon. The second algorithm is based on a Gaussian process trajectory matching where the trajectory of the grasping motion is probabilistically compared to existing data in order to form a prediction. Both algorithms were tested on published motion data collected from healthy subjects. In addition, the experimental validation of the algorithms was done using the RML glove (Robotics and Mechatronics Lab), which yielded similar prediction accuracy as compared to the simulation results. The proposed prediction algorithm can act as the backbone for a shifting authority controller that simultaneously amplifies the user's motion while guiding them toward their desired grasp. Preliminary work in this direction is also described in the paper, with directions for future research.																	2168-2291	2168-2305				FEB	2020	50	1					22	31		10.1109/THMS.2019.2938139													
J								An Efficient Destination Prediction Approach Based on Future Trajectory Prediction and Transition Matrix Optimization	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Trajectory; Training; Markov processes; Sun; Bayes methods; Hidden Markov models; Task analysis; Destination prediction; Markov model; matrix multiplication; dynamic programming	LOCATIONS; SYSTEM; MODEL	Destination prediction is an essential task in various mobile applications and up to now many methods have been proposed. However, existing methods usually suffer from the problems of heavy computational burden, data sparsity, and low coverage. Therefore, a novel approach named DestPD is proposed to tackle the aforementioned problems. Differing from an earlier approach that only considers the starting and current location of a partial trip, DestPD first determines the most likely future location and then predicts the destination. It comprises two phases, the offline training and the online prediction. During the offline training, transition probabilities between two locations are obtained via Markov transition matrix multiplication. In order to improve the efficiency of matrix multiplication, we propose two data constructs, Efficient Transition Probability (ETP) and Transition Probabilities with Detours (TPD). They are capable of pinpointing the minimum amount of needed computation. During the online prediction, we design Obligatory Update Point (OUP) and Transition Affected Area (TAA) to accelerate the frequent update of ETP and TPD for recomputing the transition probabilities. Moreover, a new future trajectory prediction approach is devised. It captures the most recent movement based on a query trajectory. It consists of two components: similarity finding through Best Path Notation (BPN) and best node selection. Our novel BPN similarity finding scheme keeps track of the nodes that induces inefficiency and then finds similarity fast based on these nodes. It is particularly suitable for trajectories with overlapping segments. Finally, the destination is predicted by combining transition probabilities and the most probable future location through Bayesian reasoning. The DestPD method is proved to achieve one order of cut in both time and space complexity. Furthermore, the experimental results on real-world and synthetic datasets have shown that DestPD consistently surpasses the state-of-the-art methods in terms of both efficiency (approximately over 100 times faster) and accuracy.																	1041-4347	1558-2191				FEB 1	2020	32	2					203	217		10.1109/TKDE.2018.2883938													
J								Anomaly Detection Using Local Kernel Density Estimation and Context-Based Regression	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Anomaly detection; Kernel; Estimation; Saliency detection; Visualization; Data models; Computational modeling; Anomaly detection; local kernel density estimation; weighted neighborhood density; hierarchical context-based local kernel regression	SALIENT OBJECT DETECTION; OUTLIER DETECTION; MODEL; ALGORITHMS	Current local density-based anomaly detection methods are limited in that the local density estimation and the neighborhood density estimation are not accurate enough for complex and large databases, and the detection performance depends on the size parameter of the neighborhood. In this paper, we propose a new kernel function to estimate samples' local densities and propose a weighted neighborhood density estimation to increase the robustness to changes in the neighborhood size. We further propose a local kernel regression estimator and a hierarchical strategy for combining information from the multiple scale neighborhoods to refine anomaly factors of samples. We apply our general anomaly detection method to image saliency detection by regarding salient pixels in objects as anomalies to the background regions. Local density estimation in the visual feature space and kernel-based saliency score propagation in the image enable the assignment of similar saliency values to homogenous object regions. Experimental results on several benchmark datasets demonstrate that our anomaly detection methods overall outperform several state-of-art anomaly detection methods. The effectiveness of our image saliency detection method is validated by comparison with several state-of-art saliency detection methods.																	1041-4347	1558-2191				FEB 1	2020	32	2					218	233		10.1109/TKDE.2018.2882404													
J								BRIGHT-Drift-Aware Demand Predictions for Taxi Networks	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Time-series forecasting; concept drift; ensemble learning; global positioning system (GPS) data; mobility intelligence; taxi passenger demand; machine learning		Massive data broadcast by GPS-equipped vehicles provide unprecedented opportunities. One of the main tasks in order to optimize our transportation networks is to build data-driven real-time decision support systems. However, the dynamic environments where the networks operate disallow the traditional assumptions required to put in practice many off-the-shelf supervised learning algorithms, such as finite training sets or stationary distributions. In this paper, we propose BRIGHT: a drift-aware supervised learning framework to predict demand quantities. BRIGHT aims to provide accurate predictions for short-term horizons through a creative ensemble of time series analysis methods that handles distinct types of concept drift. By selecting neighborhoods dynamically, BRIGHT reduces the likelihood of overfitting. By ensuring diversity among the base learners, BRIGHT ensures a high reduction of variance while keeping bias stable. Experiments were conducted using three large-scale heterogeneous real-world transportation networks in Porto (Portugal), Shanghai (China), and Stockholm (Sweden), as well as with controlled experiments using synthetic data where multiple distinct drifts were artificially induced. The obtained results illustrate the advantages of BRIGHT in relation to state-of-the-art methods for this task.																	1041-4347	1558-2191				FEB 1	2020	32	2					234	245		10.1109/TKDE.2018.2883616													
J								Design and Implementation of SSD-Assisted Backup and Recovery for Database Systems	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Database systems; Tools; Performance evaluation; Reliability; Random access memory; Arrays; Solid state drives; database systems; backup and recovery; replication; redundant array of independent disks		As flash-based solid-state drive (SSD) becomes more prevalent because of the rapid fall in price and the significant increase in capacity, customers expect better data services than traditional disk-based systems. However, the order of magnitude performance provided and new characteristics of flash require a rethinking of data services. For example, backup and recovery is an important service in a database system since it protects data against unexpected hardware and software failures. To provide backup and recovery, backup/recovery tools or backup/recovery methods by operating systems can be used. However, the tools perform time-consuming jobs, and the methods may negatively affect run-time performance during normal operation even though high-performance SSDs are used. To handle these issues, we propose an SSD-assisted backup/recovery scheme for database systems. Our scheme is to utilize the characteristics (e.g., out-of-place update) of flash-based SSD for backup/recovery operations. To this end, we exploit the resources (e.g., flash translation layer and DRAM cache with supercapacitors) inside SSD, and we call our SSD with new backup/recovery functionality BR-SSD. We design and implement the functionality in the Samsung enterprise-class SSD (i.e., SM843Tn) for more realistic systems. Furthermore, we exploit and integrate BR-SSDs into database systems (i.e., MySQL) in replication and redundant array of independent disks (RAID) environments, as well as a database system in a single BR-SSD. The experimental result demonstrates that our scheme provides fast backup and recovery but does not negatively affect the run-time performance during normal operation.																	1041-4347	1558-2191				FEB 1	2020	32	2					260	274		10.1109/TKDE.2018.2884466													
J								Learning to Weight for Text Classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Training data; Task analysis; Training; Neural networks; Feature extraction; Time-frequency analysis; Information retrieval; Term weighting; supervised term weighting; text classification; neural networks; deep learning	TERM; SCHEMES	In information retrieval (IR) and related tasks, term weighting approaches typically consider the frequency of the term in the document and in the collection in order to compute a score reflecting the importance of the term for the document. In tasks characterized by the presence of training data (such as text classification) it seems logical that the term weighting function should take into account the distribution (as estimated from training data) of the term across the classes of interest. Although "supervised term weighting" approaches that use this intuition have been described before, they have failed to show consistent improvements. In this article, we analyze the possible reasons for this failure, and call consolidated assumptions into question. Following this criticism, we propose a novel supervised term weighting approach that, instead of relying on any predefined formula, learns a term weighting function optimized on the training set of interest; we dub this approach Learning to Weight (LTW). The experiments that we run on several well-known benchmarks, and using different learning methods, show that our method outperforms previous term weighting approaches in text classification.																	1041-4347	1558-2191				FEB 1	2020	32	2					302	316		10.1109/TKDE.2018.2883446													
J								QuickPoint: Efficiently Identifying Densest Sub-Graphs in Online Social Networks for Event Stream Dissemination	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Event stream dissemination; piggyback; densest sub-graph; online social networks	SUBGRAPH	Efficient event stream dissemination is a challenging problem in large-scale Online Social Network (OSN) systems due to the costly inter-server communications caused by the per-user view data storage. To solve the problem, previous schemes mainly explore the structures of social graphs to reduce the inter-server traffic. Based on the observation of high cluster coefficients in OSNs, a state-of-the-art social piggyback scheme can save redundant messages by exploiting an intrinsic hub-structure in an OSN graph for message piggybacking. Essentially, finding the best hub-structure for piggybacking is equivalent to finding a variation of the densest sub-graph. The existing scheme computes the best hub-structure by iteratively removing the node with the minimum weighted degree. Such a scheme incurs a worst computation cost of O(n(2)), making it not scalable to large-scale OSN graphs. Using alternative hub-structure instead of the best hub-structure can speed up the piggyback assignment. However, they greatly sacrifice the communication efficiency of the assignment schedule. Different from the existing designs, in this work, we propose a QuickPoint algorithm, which removes a fraction of nodes in each iteration in finding the best hub-structure. We mathematically prove that QuickPoint converges in O(log(a)n) (a > 1) iterations in finding the best hub-structure for efficient piggyback. We implement QuickPoint in parallel atop Pregel, a vertex-centric distributed graph processing platform. Comprehensive experiments using large-scale data from Twitter and Flickr show that our scheme is 38.8x more efficient compared to existing schemes.																	1041-4347	1558-2191				FEB 1	2020	32	2					332	346		10.1109/TKDE.2018.2881435													
J								r-HUMO: A Risk-Aware Human-Machine Cooperation Framework for Entity Resolution with Quality Guarantees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Erbium; Measurement; Crowdsourcing; Inspection; Risk analysis; Man-machine systems; Task analysis; Entity resolution; human-machine cooperation; risk analysis; quality guarantee		Even though many approaches have been proposed for entity resolution (ER), it remains very challenging to enforce quality guarantees. To this end, we propose a risk-aware HUman-Machine cOoperation framework for ER, denoted by r-HUMO. Built on the existing HUMO framework, r-HUMO similarly enforces both precision and recall guarantees by partitioning an ER workload between the human and the machine. However, r-HUMO is the first solution that optimizes the process of human workload selection from a risk perspective. It iteratively selects human workload by real-time risk analysis based on the human-labeled results as well as the pre-specified machine metric. In this paper, we first introduce the r-HUMO framework and then present the risk model to prioritize the instances for manual inspection. Finally, we empirically evaluate r-HUMOs performance on real data. Our extensive experiments show that r-HUMO is effective in enforcing quality guarantees, and compared with the state-of-the-art alternatives, it can achieve desired quality control with reduced human cost.																	1041-4347	1558-2191				FEB 1	2020	32	2					347	359		10.1109/TKDE.2018.2883532													
J								Scalable Dynamic Graph Summarization	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Graph summarization; dynamic graphs; clustering		Large-scale dynamic interaction graphs can be challenging to process and store, due to their size and the continuous change of communication patterns between nodes. In this work, we address the problem of summarizing large-scale dynamic graphs, while maintaining the evolution of their structure and interactions. Our approach is based on grouping the nodes of the graph in supernodes according to their connectivity and communication patterns. The resulting summary graph preserves the information about the evolution of the graph within a time window. We propose two online algorithms for summarizing this type of graphs. Our baseline algorithm $k$kC based on clustering is fast but rather memory expensive. The second method we propose, named $\mu$C, reduces the memory requirements by introducing an intermediate step that keeps statistics of the clustering of the previous rounds. Our algorithms are distributed by design, and we implement them over the Apache Spark framework, so as to address the problem of scalability for large-scale graphs and massive streams. We apply our methods to several dynamic graphs, and show that we can efficiently use the summary graphs to answer temporal and probabilistic graph queries.																	1041-4347	1558-2191				FEB 1	2020	32	2					360	373		10.1109/TKDE.2018.2884471													
J								Training Simplification and Model Simplification for Deep Learning : A Minimal Effort Back Propagation Method	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Neural network; back propagation; sparse learning; model pruning	NEURAL-NETWORKS	We propose a simple yet effective technique to simplify the training and the resulting model of neural networks. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-$k$k elements (in terms of magnitude) are kept. As a result, only $k$k rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction in the computational cost. Based on the sparsified gradients, we further simplify the model by eliminating the rows or columns that are seldom updated, which will reduce the computational cost both in the training and decoding, and potentially accelerate decoding in real-world applications. Surprisingly, experimental results demonstrate that most of the time we only need to update fewer than 5 percent of the weights at each back propagation pass. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The model simplification results show that we could adaptively simplify the model which could often be reduced by around 9x, without any loss on accuracy or even with improved accuracy.																	1041-4347	1558-2191				FEB 1	2020	32	2					374	387		10.1109/TKDE.2018.2883613													
J								XINA: Explainable Instance Alignment Using Dominance Relationship	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Logic gates; Computer science; Electronic mail; Feature extraction; Knowledge based systems; Medical diagnosis; Resource description framework; Knowledge base; KB integration; instance alignment; ontology matching; entity resolution; interpretability		Over the past few years, knowledge bases (KBs) like DBPedia, Freebase, and YAGO have accumulated a massive amount of knowledge from web data. Despite their seemingly large size, however, individual KBs often lack comprehensive information on any given domain. For example, over 70 percent of people on Freebase lack information on place of birth. For this reason, the complementary nature across different KBs motivates their integration through a process of aligning instances. Meanwhile, since application-level machine systems, such as medical diagnosis, have heavily relied on KBs, it is necessary to provide users with trustworthy reasons why the alignment decisions are made. To address this problem, we propose a new paradigm, explainable instance alignment (XINA), which provides user-understandable explanations for alignment decisions. Specifically, given an alignment candidate, XINA replaces existing scalar representation of an aggregated score, by decision- and explanation-vector spaces for machine decision and user understanding, respectively. To validate XINA, we perform extensive experiments on real-world KBs and show that XINA achieves comparable performance with state-of-the-arts, even with far less human effort.																	1041-4347	1558-2191				FEB 1	2020	32	2					388	401		10.1109/TKDE.2018.2881956													
J								Mining Mobile Intelligence for Wireless Systems: A Deep Neural Network Approach	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE											SLICE DESIGN; SENSOR-CLOUD; MACHINE; MODEL; REDUCTION; SERVICES	Wireless big data contain valuable information on users' behaviors and preferences, which can drive the design and optimization for wireless systems. The fundamental issue is how to mine mobile intelligence and further incorporate them into wireless systems. To this end, this article discusses two challenges on big data based wireless system design and optimization, and proposes a unified framework to tackle them with the help of Deep Neural Networks (DNNs) and online learning techniques. In particular, we propose a DNN architecture by incorporating an embedding layer to project different types of raw data to a latent space and utilize a regression or classification function to predict the mobile access pattern. It outperforms the best traditional machine learning algorithm (76% vs. 63%) significantly. Moreover, combining the proposed DNN architecture with online learning techniques, we show two cases on how to apply the mobile intelligence for wireless video applications, including video adaption and video pre-fetching. In the former case, we utilize the proposed DNN method to predict the dynamics of user count within the coverage of base stations, and adaptively adjust the bitrate for video streaming to improve the video watching experience. In the latter one, we utilize the proposed method to predict the user trajectory, i.e., the associated base stations, and conduct content prefetching to reduce the access latency. Evaluating the performance with a real wireless dataset, we show that the perceived video QoE and cache hit ratio are greatly improved (0.7db and 25% respectively).																	1556-603X	1556-6048				FEB	2020	15	1					24	31		10.1109/MCI.2019.2954641													
J								Enabling Computational Intelligence for Green Internet of Things: Data-Driven Adaptation in LPWA Networking	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE											SMART CITIES; IOT; CAPACITY; MANAGEMENT; SECURITY	With the exponential expansion of the number of Internet of Things (IoT) devices, many state-of-the-art communication technologies are being developed to use the lowerpower but extensively deployed devices. Due to the limits of pure channel characteristics, most protocols cannot allow an IoT network to be simultaneously large-scale and energy-efficient, especially in hybrid architectures. However, different from the original intention to pursue faster and broader connectivity, the daily operation of IoT devices only requires stable and low-cost links. Thus, our design goal is to develop a comprehensive solution for intelligent green IoT networking to satisfy the modern requirements through a data-driven mechanism, so that the IoT networks use computational intelligence to realize self-regulation of composition, size minimization, and throughput optimization. To the best of our knowledge, this study is the first to use the green protocols of LoRa and ZigBee to establish an ad hoc network and solve the problem of energy efficiency. First, we propose a unique initialization mechanism that automatically schedules node clustering and throughput optimization. Then, each device executes a procedure to manage its own energy consumption to optimize switching in and out of sleep mode, which relies on AI-controlled service usage habit prediction to learn the future usage trend. Finally, our new theory is corroborated through real-world deployment and numerical comparisons. We believe that our new type of network organization and control system could improve the performance of all green-oriented IoT services and even change human lifestyle habits.																	1556-603X	1556-6048				FEB	2020	15	1					32	43		10.1109/MCI.2019.2954642													
J								Artificial Intelligence Enabled Internet of Things: Network Architecture and Spectrum Access	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE											ALGORITHM; CLOUD	The explosive growth of wireless devices motivates the development of the internet-of-things (IoT), which is capable of interconnecting massive and diverse "things" via wireless communications. This is also called massive machine type communications (mMTC) as a part of the undergoing fifth generation (5G) mobile networks. It is envisioned that more sophisticated devices would be connected to form a hyperconnected world with the aids of the sixth generation (6G) mobile networks. To enable wireless accesses of such IoT networks, artificial intelligence (AI) can play an important role. In this article, the frameworks of centralized and distributed AI-enabled IoT networks are introduced. Key technical challenges, including random access and spectrum sharing (spectrum access and spectrum sensing), are analyzed for different network architectures. Deep reinforcement learning (DRL)-based strategies are introduced and neural networks-based approaches are utilized to efficiently realize the DRL strategies for system procedures such as spectrum access and spectrum sensing. Different types of neural networks that could be used in IoT networks to conduct DRL are also discussed.																	1556-603X	1556-6048				FEB	2020	15	1					44	51		10.1109/MCI.2019.2954643													
J								Ant Colony Optimization Algorithms for Dynamic Optimization: A Case Study of the Dynamic Travelling Salesperson Problem [Research Frontier]	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE											IMMIGRANTS SCHEMES; STRATEGIES; FRAMEWORK; SYSTEM	Ant colony optimization is a swarm intelligence metaheuristic inspired by the foraging behavior of some ant species. Ant colony optimization has been successfully applied to challenging optimization problems. This article investigates existing ant colony optimization algorithms specifically designed for combinatorial optimization problems with a dynamic environment. The investigated algorithms are classified into two frameworks: evaporation-based and population-based. A case study of using these algorithms to solve the dynamic traveling salesperson problem is described. Experiments are systematically conducted using a proposed dynamic benchmark framework to analyze the effect of important ant colony optimization features on numerous test cases. Different performance measures are used to evaluate the adaptation capabilities of the investigated algorithms, indicating which features are the most important when designing ant colony optimization algorithms in dynamic environments.																	1556-603X	1556-6048				FEB	2020	15	1					52	63		10.1109/MCI.2019.2954644													
J								How Intense Are You? Predicting Intensities of Emotions and Sentiments using Stacked Ensemble	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE												Emotions and sentiments are subjective in nature. They differ on a case-to-case basis. However, predicting only the emotion and sentiment does not always convey complete information. The degree or level of emotions and sentiments often plays a crucial role in understanding the exact feeling within a single class (e.g., 'good' versus 'awesome'). In this paper, we propose a stacked ensemble method for predicting the degree of intensity for emotion and sentiment by combining the outputs obtained from several deep learning and classical feature-based models using a multi-layer perceptron network. We develop three deep learning models based on convolutional neural network, long short-term memory and gated recurrent unit and one classical supervised model based on support vector regression. We evaluate our proposed technique for two problems, i.e., emotion analysis in the generic domain and sentiment analysis in the financial domain. The proposed model shows impressive results for both the problems. Comparisons show that our proposed model achieves improved performance over the existing state-of-the-art systems.																	1556-603X	1556-6048				FEB	2020	15	1					64	75		10.1109/MCI.2019.2954667													
J								EvoMSA: A Multilingual Evolutionary Approach for Sentiment Analysis	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE											CLASSIFICATION	Sentiment analysis (SA) is a task related to understanding people's feelings in written text; the starting point would be to identify the polarity level (positive, neutral or negative) of a given text, moving on to identify emotions or whether a text is humorous or not. This task has been the subject of several research competitions in a number of languages, e.g., English, Spanish, and Arabic, among others. In this contribution, we propose an SA system, namely EvoMSA, that unifies our participating systems in various SA competitions, making it domain-independent and multilingual by processing text using only language-independent techniques. EvoMSA is a classifier, based on Genetic Programming that works by combining the output of different text classifiers to produce the final prediction. We analyzed EvoMSA on different SA competitions to provide a global overview of its performance. The results indicated that EvoMSA is competitive obtaining top rankings in several SA competitions. Furthermore, we performed an analysis of EvoMSA's components to measure their contribution to the performance; the aim was to facilitate a practitioner or newcomer to implement a competitive SA classifier. Finally, it is worth to mention that EvoMSA is available as open-source software.																	1556-603X	1556-6048				FEB	2020	15	1					76	88		10.1109/MCI.2019.2954668													
J								Finite-Horizon Optimal Consensus Control for Unknown Multiagent State-Delay Systems	IEEE TRANSACTIONS ON CYBERNETICS										Mathematical model; Delays; Delay effects; Approximation algorithms; Adaptation models; Performance analysis; Multi-agent systems; Finite-horizon; multiagent systems (MASs); off-policy reinforcement learning (RL); optimal consensus control; state delays	DIFFERENTIAL GRAPHICAL GAMES; H-INFINITY CONTROL; NONLINEAR-SYSTEMS; AVERAGE CONSENSUS; SYNCHRONIZATION; TOPOLOGIES; DYNAMICS	This paper investigates finite-horizon optimal consensus control problem for unknown multiagent systems with state delays. It is well known that optimal consensus control is the solutions to the coupled Hamilton-Jacobi-Bellman (HJB) equations. An off-policy reinforcement learning (RL) algorithm is developed to learn the two-stage optimal consensus solutions to the coupled time-varying HJB equations using the measurable state data instead of the knowledge of the state-delayed system dynamics. Subsequently, for each agent, a single critic neural network (NN) is utilized to approximate the time-varying cost function and help to calculate optimal consensus control policy. Based on the method of weighted residuals, adaptive weight update laws for the critic NNs are proposed. Finally, the simulation results are provided to illustrate the effectiveness of the proposed off-policy RL method.																	2168-2267	2168-2275				FEB	2020	50	2					402	413		10.1109/TCYB.2018.2856510													
J								Fuzzy Broad Learning System: A Novel Neuro-Fuzzy Model for Regression and Classification	IEEE TRANSACTIONS ON CYBERNETICS										Broad learning system (BLS); classification; k-means; regression; Takagi-Sugeno (TS) fuzzy system	RESTRICTED BOLTZMANN MACHINE; INFERENCE SYSTEM; NETWORKS; RULE; IDENTIFICATION; APPROXIMATION; ALGORITHM; EQUIVALENCE; CONTROLLER	A novel neuro-fuzzy model named fuzzy broad learning system (BLS) is proposed by merging the Takagi-Sugeno (TS) fuzzy system into BLS. The fuzzy BLS replaces the feature nodes of BLS with a group of TS fuzzy subsystems, and the input data are processed by each of them. Instead of aggregating the outputs of fuzzy rules produced by every fuzzy subsystem into one value immediately, all of them are sent to the enhancement layer for further nonlinear transformation to preserve the characteristic of inputs. The defuzzification outputs of all fuzzy subsystem and the outputs of enhancement layer are combined together to obtain the model output. The k-means method is employed to determine the centers of Gaussian membership functions in antecedent part and the number of fuzzy rules. The parameters that need to be calculated in a fuzzy BLS are the weights connecting the outputs of enhancement layer to model output and the randomly initialized coefficients of polynomials in consequent part in fuzzy subsystems, which can be calculated analytically. Therefore, fuzzy BLS retains the fast computational nature of BLS. The proposed fuzzy BLS is evaluated by some popular benchmarks for regression and classification, and compared with some state-of-the-art nonfuzzy and neuro-fuzzy approaches. The results indicate that fuzzy BLS outperforms other models involved. Moreover, fuzzy BLS shows advantages over neuro-fuzzy models regarding to the number of fuzzy rules and training time, which can ease the problem of rule explosion to some extent.																	2168-2267	2168-2275				FEB	2020	50	2					414	424		10.1109/TCYB.2018.2857815													
J								Multiple Relevant Feature Ensemble Selection Based on Multilayer Co-Evolutionary Consensus MapReduce	IEEE TRANSACTIONS ON CYBERNETICS										Feature extraction; Rough sets; Prediction algorithms; Big Data; Data mining; Nash equilibrium; Heuristic algorithms; Cerebral cortex classification; co-evolutionary consensus MapReduce; consistency aggregation; multiple relevant feature selection; Nash equilibrium	BIG DATA; COOPERATIVE COEVOLUTION; ATTRIBUTE REDUCTION; MR-IMAGES; ROUGH; ALGORITHM; CLASSIFICATION	Although feature selection for large data has been intensively investigated in data mining, machine learning, and pattern recognition, the challenges are not just to invent new algorithms to handle noisy and uncertain large data in applications, but rather to link the multiple relevant feature sources, structured, or unstructured, to develop an effective feature reduction method. In this paper, we propose a multiple relevant feature ensemble selection (MRFES) algorithm based on multilayer co-evolutionary consensus MapReduce (MCCM). We construct an effective MCCM model to handle feature ensemble selection of large-scale datasets with multiple relevant feature sources, and explore the unified consistency aggregation between the local solutions and global dominance solutions achieved by the co-evolutionary memeplexes, which participate in the cooperative feature ensemble selection process. This model attempts to reach a mutual decision agreement among co-evolutionary memeplexes, which calls for the need for mechanisms to detect some noncooperative co-evolutionary behaviors and achieve better Nash equilibrium resolutions. Extensive experimental comparative studies substantiate the effectiveness of MRFES to solve large-scale dataset problems with the complex noise and multiple relevant feature sources on some well-known benchmark datasets. The algorithm can greatly facilitate the selection of relevant feature subsets coming from the original feature space with better accuracy, efficiency, and interpretability. Moreover, we apply MRFES to human cerebral cortex-based classification prediction. Such successful applications are expected to significantly scale up classification prediction for large-scale and complex brain data in terms of efficiency and feasibility.																	2168-2267	2168-2275				FEB	2020	50	2					425	439		10.1109/TCYB.2018.2859342													
J								Delay-Distribution-Dependent H-infinity State Estimation for Discrete-Time Memristive Neural Networks With Mixed Time-Delays and Fading Measurements	IEEE TRANSACTIONS ON CYBERNETICS										Delay-distribution-dependent stability; fading channels; H infinity state estimation; memristive neural networks (MNNs); mixed time-delays	GLOBAL ASYMPTOTIC STABILITY; EXPONENTIAL STABILITY; VARYING DELAYS; DISSIPATIVITY ANALYSIS; LAGRANGE STABILITY; PASSIVITY; SYSTEMS; SYNCHRONIZATION; STABILIZATION	This paper addresses the H-infinity state estimation issue for a sort of memristive neural networks in the discrete-time setting under randomly occurring mixed time-delays and fading measurements. The main purpose of the addressed issue is to propose a state estimator design algorithm that ensures the error dynamics of the state estimation to be stochastically stable with a prespecified H-infinity disturbance attenuation index. We put forward certain switching functions to account for the discrete-time yet state-dependent characteristics of the memristive connection weights. By resorting to the robust analysis theory and the Lyapunov-functional analysis theory, we derive some sufficient conditions to guarantee the desired estimation performance. The derived sufficient conditions rely not only on the size of discrete time-delays and the probability distribution law of the distributed time-delays but also on the statistics information of the coefficients of the adopted Rice fading model. Based on the established existence conditions, the gain matrices of the desired estimator are obtained by means of the feasibility of a set of matrix inequalities that can be checked efficiently via available software packages. Finally, the numerical simulation results are provided to show the validity of the main results.																	2168-2267	2168-2275				FEB	2020	50	2					440	451		10.1109/TCYB.2018.2862914													
J								Accelerating Convolutional Neural Networks by Removing Interspatial and Interkernel Redundancies	IEEE TRANSACTIONS ON CYBERNETICS										Convolutional neural networks (CNNs); deep learning application; image classification; network accelerating; network compression	CLASSIFICATION	Recently, the high computational resource demands of convolutional neural networks (CNNs) have hindered a wide range of their applications. To solve this problem, many previous works attempted to reduce the redundant calculations during the evaluation of CNNs. However, these works mainly focused on either interspatial or interkernel redundancy. In this paper, we further accelerate existing CNNs by removing both types of redundancies. First, we convert interspatial redundancy into interkernel redundancy by decomposing one convolutional layer to one block that we design. Then, we adopt rank-selection and pruning methods to remove the interkernel redundancy. The rank-selection method, which considerably reduces manpower, contributes to determining the number of kernels to be pruned in the pruning method. We apply a layer-wise training algorithm rather than the traditional end-to-end training to overcome the difficulty of convergence. Finally, we fine-tune the entire network to achieve better performance. Our method is applied on three widely used datasets of an image classification task. We achieve better results in terms of accuracy and compression rate compared with previous state-of-the-art methods.																	2168-2267	2168-2275				FEB	2020	50	2					452	464		10.1109/TCYB.2018.2873762													
J								Distributed H-infinity Estimation in Sensor Networks With Two-Channel Stochastic Attacks	IEEE TRANSACTIONS ON CYBERNETICS										Distributed estimation; H-infinity estimation; network attack	SYSTEMS; DELAY	This paper is concerned with the distributed estimation problem in sensor networks subjected to unknown attacks. Network attacks are considered to exist in two classes of channels: 1) communication channels from the plant to sensors and 2) communication channels among sensors. The status of an attack is viewed as a stochastic phenomenon, and the transmitted information will be affected when the attacker successfully carries out an attack on the related data packet. Based on the sensors' own measurements and their neighbors' local information, a novel distributed estimation model against two-channel stochastic attacks is presented. A sufficient condition on the existence of the desired distributed H-infinity estimators is derived and the distributed estimator gains are designed by solving a linear matrix inequality. Two illustrative examples are provided to demonstrate the effectiveness of the new design techniques.																	2168-2267	2168-2275				FEB	2020	50	2					465	475		10.1109/TCYB.2018.2865238													
J								Weighted Hierarchical Grammatical Evolution	IEEE TRANSACTIONS ON CYBERNETICS										Grammar; Standards; Production; Proposals; Genetics; Indexing; Benchmark testing; Genetic programming; genotype-phenotype mapping; representation	REGULAR EXPRESSIONS; OPTIMIZATION; ALGORITHMS; REDUNDANCY; PHENOTYPE; GENOTYPE; LOCALITY; SEARCH	Grammatical evolution (GE) is one of the most widespread techniques in evolutionary computation. Genotypes in GE are bit strings while phenotypes are strings, of a language defined by a user-provided context-free grammar. In this paper, we propose a novel procedure for mapping genotypes to phenotypes that we call weighted hierarchical GE (WHGE). WHGE imposes a form of hierarchy on the genotype and encodes grammar symbols with a varying number of bits based on the relative expressive power of those symbols. WHGE does not impose any constraint on the overall GE framework, in particular, WHGE may handle recursive grammars, uses the classical genetic operators, and does not need to define any bound in advance on the size of phenotypes. We assessed experimentally our proposal in depth on a set of challenging and carefully selected benchmarks, comparing the results of the standard GE framework as well as two of the most significant enhancements proposed in the literature: 1) position-independent GE and 2) structured GE. Our results show that WHGE delivers very good results in terms of fitness as well as in terms of the properties of the genotype-phenotype mapping procedure.																	2168-2267	2168-2275				FEB	2020	50	2					476	488		10.1109/TCYB.2018.2876563													
J								Alignment-Supervised Bidimensional Attention-Based Recursive Autoencoders for Bilingual Phrase Representation	IEEE TRANSACTIONS ON CYBERNETICS										Semantics; Linguistics; Task analysis; Cybernetics; Information processing; Training; Stochastic processes; Alignment supervision; attention network; bilingual phrase representation; machine translation; recursive autoencoder (RAE)		Exploiting semantic interactions between the source and target linguistic items at different levels of granularity is crucial for generating compact vector representations for bilingual phrases. To achieve this, we propose alignment-supervised bidimensional attention-based recursive autoencoders (ABattRAE) in this paper. ABattRAE first individually employs two recursive autoencoders to recover hierarchical tree structures of bilingual phrase, and treats the subphrase covered by each node on the tree as a linguistic item. Unlike previous methods, ABattRAE introduces a bidimensional attention network to measure the semantic matching degree between linguistic items of different languages, which enables our model to integrate information from all nodes by dynamically assigning varying weights to their corresponding embeddings. To ensure the accuracy of the generated attention weights in the attention network, ABattRAE incorporates word alignments as supervision signals to guide the learning procedure. Using the general stochastic gradient descent algorithm, we train our model in an end-to-end fashion, where the semantic similarity of translation equivalents is maximized while the semantic similarity of nontranslation pairs is minimized. Finally, we incorporate a semantic feature based on the learned bilingual phrase representations into a machine translation system for better translation selection. Experimental results on NIST Chinese-English and WMT English-German test sets show that our model achieves substantial improvements of up to 2.86 and 1.09 BLEU points over the baseline, respectively. Extensive in-depth analyses demonstrate the superiority of our model in learning bilingual phrase embeddings.																	2168-2267	2168-2275				FEB	2020	50	2					503	513		10.1109/TCYB.2018.2868982													
J								Relative Degrees and Implicit Function-Based Control of Discrete-Time Noncanonical Form Neural Network Systems	IEEE TRANSACTIONS ON CYBERNETICS										Neural networks; Nonlinear systems; Adaptive control; Uncertainty; Mathematical model; Control systems; Adaptation models; Adaptive control; implicit function; noncanonical form; output tracking; relative degree	OUTPUT-FEEDBACK CONTROL; BARRIER LYAPUNOV FUNCTIONS; ADAPTIVE-CONTROL; NONLINEAR-SYSTEMS; TRACKING CONTROL; VARYING SYSTEMS; STABILIZATION; DESIGN; STATE	This paper studies the relative degrees of discrete-time neural network systems in a general noncanonical form, and develops a new feedback control scheme for such systems, based on implicit function theory and feedback linearization. After time-advance operation on output of such systems, the output dynamics nonlinearly depends on the control input. To address this issue, we use implicit function theory to define the relative degrees, and to establish a normal form. Then, an implicit function equation solution-based control scheme and an iterative solution-based control scheme are proposed, which ensure not only the closed-loop stability but also the output tracking for the controlled plant. An adaptive control framework for the controlled plant with uncertainties is also presented to illustrate the basic design procedure. The simulation results are given to demonstrate the desired system performance.																	2168-2267	2168-2275				FEB	2020	50	2					514	524		10.1109/TCYB.2018.2869335													
J								(RBN)-B-2: An Adaptive Model for Keystroke-Dynamics-Based Educational Level Classification	IEEE TRANSACTIONS ON CYBERNETICS										Machine learning; Keyboards; Predictive models; Hidden Markov models; Computational modeling; Biometrics (access control); Data models; Data analytics; forensic analysis; keystroke dynamics; machine learning; user profiling		Over the past decade, keystroke-based pattern recognition techniques, as a forensic tool for behavioral biometrics, have gained increasing attention. Although a number of machine learning-based approaches have been proposed, they are limited in terms of their capability to recognize and profile a set of an individual's characteristics. In addition, up to today, their focus was primarily gender and age, which seem to be more appropriate for commercial applications (such as developing commercial software), leaving out from research other characteristics, such as the educational level. Educational level is an acquired user characteristic, which can improve targeted advertising, as well as provide valuable information in a digital forensic investigation, when it is known. In this context, this paper proposes a novel machine learning model, the randomized radial basis function network, which recognizes and profiles the educational level of an individual who stands behind the keyboard. The performance of the proposed model is evaluated by using the empirical data obtained by recording volunteers' keystrokes during their daily usage of a computer. Its performance is also compared with other well-referenced machine learning models using our keystroke dynamic datasets. Although the proposed model achieves high accuracy in educational level prediction of an unknown user, it suffers from high computational cost. For this reason, we examine ways to reduce the time that is needed to build our model, including the use of a novel data condensation method, and discuss the tradeoff between an accurate and a fast prediction. To the best of our knowledge, this is the first model in the literature that predicts the educational level of an individual based on the keystroke dynamics information only.																	2168-2267	2168-2275				FEB	2020	50	2					525	535		10.1109/TCYB.2018.2869658													
J								A Random Forest-Assisted Evolutionary Algorithm for Data-Driven Constrained Multiobjective Combinatorial Optimization of Trauma Systems	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Radio frequency; Computational modeling; Vegetation; Forestry; Training; Linear programming; Constrained multiobjective combinatorial optimization; data-driven optimization; evolutionary algorithm (EA); radial basis function (RBF) networks; random forest (RF); surrogate; trauma systems	INFILL SAMPLING CRITERIA; FITNESS APPROXIMATION; SURROGATE MODELS; DESIGN OPTIMIZATION; NEURAL-NETWORKS; REGRESSION; FRAMEWORK	Many real-world optimization problems can be solved by using the data-driven approach only, simply because no analytic objective functions are available for evaluating candidate solutions. In this paper, we address a class of expensive data-driven constrained multiobjective combinatorial optimization problems, where the objectives and constraints can be calculated only on the basis of a large amount of data. To solve this class of problems, we propose using random forests (RFs) and radial basis function networks as surrogates to approximate both objective and constraint functions. In addition, logistic regression models are introduced to rectify the surrogate-assisted fitness evaluations and a stochastic ranking selection is adopted to further reduce the influences of the approximated constraint functions. Three variants of the proposed algorithm are empirically evaluated on multiobjective knapsack benchmark problems and two real-world trauma system design problems. Experimental results demonstrate that the variant using RF models as the surrogates is effective and efficient in solving data-driven constrained multiobjective combinatorial optimization problems.																	2168-2267	2168-2275				FEB	2020	50	2					536	549		10.1109/TCYB.2018.2869674													
J								Containment Control for General Second-Order Multiagent Systems With Switched Dynamics	IEEE TRANSACTIONS ON CYBERNETICS										Switches; Multi-agent systems; Topology; Protocols; Forestry; Switched systems; Containment control; directed spanning forest; general second-order dynamics; switched multiagent systems	CONTINUOUS-TIME; SUFFICIENT CONDITIONS; CONSENSUS CONDITIONS; STABILITY ANALYSIS; TOPOLOGIES; NETWORKS; LEADERS; AGENTS	This paper investigates the distributed containment control problem for a class of general second-order multiagent systems with switched dynamics, which is composed of a continuous-time (CT) subsystem and a discrete-time (DT) subsystem. For this switched multiagent system under fixed directed topology, a distributed containment control protocol is proposed for each follower based on the relative local measurements of neighboring followers and leaders. Some necessary and sufficient conditions are derived under the condition that the network topology contains a directed spanning forest, and these conditions ensure that the general second-order containment control problem can be solved under arbitrary CT-DT switching. If the general second-order system is reduced to the double integrator system, some simpler containment conditions are presented. Furthermore, the similar results are also obtained under switching directed topology. Finally, some simulation examples are presented to show the efficiency of the theoretical results.																	2168-2267	2168-2275				FEB	2020	50	2					550	560		10.1109/TCYB.2018.2869706													
J								Fusion of Multiple Person Re-id Methods With Model and Data-Aware Abilities	IEEE TRANSACTIONS ON CYBERNETICS										Measurement; Task analysis; Robustness; Learning systems; Visualization; Benchmark testing; Computational modeling; Fusion; generative model of labels; abilities; difficulties (GLAD); person reidentification (person re-id)	REIDENTIFICATION	Person re-identification (person re-id) has attracted rapidly increasing attention in computer vision and pattern recognition research community in recent years. With the goal of providing match ranking results between each query person image and the gallery ones, the person re-id technique has been widely explored and a large number of person re-id methods have been developed. As these algorithms leverage different kinds of prior assumptions, image features, distance matching functions, et al., each of them has its own strengths and weaknesses. Inspired by these facts, this paper proposes a novel person re-id method based on the idea of inferring superior fusion results from a variety of previous base person re-id algorithms using different methodologies or features. To achieve this goal, we propose a novel framework which mainly consists of two steps: 1) a number of existing person re-id methods are implemented, and the ranking results are obtained in the test datasets. and 2) the robust fusion strategy is applied to obtain better re-ranked matching results by simultaneously considering the recognition abilities of various base re-id methods and the difficulties of different gallery person images to be correctly recognized under the generative model of labels, abilities, and difficulties framework. Comprehensive experiments show the effectiveness of our proposed method, and we have received state-of-the-art results on recent popular person re-id datasets.																	2168-2267	2168-2275				FEB	2020	50	2					561	571		10.1109/TCYB.2018.2869739													
J								Hyper-Laplacian Regularized Multilinear Multiview Self-Representations for Clustering and Semisupervised Learning	IEEE TRANSACTIONS ON CYBERNETICS										Tensile stress; Manifolds; Encoding; Laplace equations; Semisupervised learning; Correlation; Optimization; Manifold regularization; multilinear; multiview features; nonlinear subspace clustering; tensor singular-value decomposition (t-SVD)	SPARSE; CLASSIFICATION; RECOGNITION; FRAMEWORK; ALGORITHM; SCENE; GRAPH	In this paper, we address the multiview nonlinear subspace representation problem. Traditional multiview subspace learning methods assume that the heterogeneous features of the data usually lie within the union of multiple linear subspaces. However, instead of linear subspaces, the data feature actually resides in multiple nonlinear subspaces in many real-world applications, resulting in unsatisfactory clustering performance. To overcome this, we propose a hyper-Laplacian regularized multilinear multiview self-representation model, which is referred to as HLR-(MVS)-V-2, to jointly learn multiple views correlation and a local geometrical structure in a unified tensor space and view-specific self-representation feature spaces, respectively. In unified tensor space, a well-founded tensor low-rank regularization is adopted to impose on the self-representation coefficient tensor to ensure global consensus among different views. In view-specific feature space, hypergraph-induced hyper-Laplacian regularization is utilized to preserve the local geometrical structure embedded in a high-dimensional ambient space. An efficient algorithm is then derived to solve the optimization problem of the established model with theoretical convergence guarantee. Furthermore, the proposed model can be extended to semisupervised classification without introducing any additional parameters. An extensive experiment of our method is conducted on many challenging datasets, where a clear advance over state-of-the-art multiview clustering and multiview semisupervised classification approaches is achieved.																	2168-2267	2168-2275				FEB	2020	50	2					572	586		10.1109/TCYB.2018.2869789													
J								Adaptive Fuzzy Control of Stochastic Nonlinear Systems With Fuzzy Dead Zones and Unmodeled Dynamics	IEEE TRANSACTIONS ON CYBERNETICS										Fuzzy control; Adaptive systems; Stochastic processes; Nonlinear dynamical systems; Backstepping; Stochastic systems; Adaptive fuzzy control; backstepping; fuzzy dead zones; stochastic small-gain theorem	OUTPUT-FEEDBACK CONTROL; SMALL-GAIN APPROACH; TRACKING CONTROL; BACKSTEPPING CONTROL; CONTROL DESIGN; COMPENSATION; APPROXIMATION; NETWORK	This paper focuses on an input-to-state practical stability problem for a class of stochastic nonlinear systems with unmodeled dynamics and fuzzy dead zones. A feasible adaptive fuzzy control method is proposed for the developed stochastic system with the slope of dead zone being certain or fuzzy. Based on stochastic small-gain theorem and backstepping technique, the closed-loop system is guaranteed to be input-state-practically stable in probability. The main contributions of this paper lie in that the considered system is more general, and the modified Lemma 2 makes the presentation of the formulas in lemma consistent with their application forms. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed approach.																	2168-2267	2168-2275				FEB	2020	50	2					587	599		10.1109/TCYB.2018.2869922													
J								Finite-Time Synchronization and H-infinity Synchronization of Multiweighted Complex Networks With Adaptive State Couplings	IEEE TRANSACTIONS ON CYBERNETICS										Adaptive state couplings; complex network (CN); finite-time H-infinity synchronization; finite-time synchronization; multiweights	DYNAMICAL NETWORKS; NEURAL-NETWORKS; MULTI-WEIGHTS; DELAYS	In this paper, two kinds of multiweighted and adaptive state coupled complex networks (CNs) with or without coupling delays are presented. First, we develop the appropriate state feedback controller and adaptive law for the sake of guaranteeing that the proposed network models without coupling delays can be finite-timely synchronized and H-infinity synchronized. Furthermore, for the multiweighted CNs with coupling delays and adaptive state couplings, some finite-time synchronization and H-infinity synchronization criteria are presented by choosing the appropriate adaptive law and controllers. Eventually, we give two numerical simulations to verify the validity of the theoretical results.																	2168-2267	2168-2275				FEB	2020	50	2					600	612		10.1109/TCYB.2018.2870133													
J								Matsuoka's CPG With Desired Rhythmic Signals for Adaptive Walking of Humanoid Robots	IEEE TRANSACTIONS ON CYBERNETICS										Legged locomotion; Humanoid robots; Neurons; Shape; Limit-cycles; Artificial neural networks; Adaptive walking; central pattern generator (CPG); evolutionary algorithm; humanoid robots; neural network (NN)	DIFFERENTIAL EVOLUTION; BIPED LOCOMOTION; FREQUENCY; OPTIMIZATION; NETWORK; MODEL	The desired rhythmic signals for adaptive walking of humanoid robots should have proper frequencies, phases, and shapes. Matsuoka's central pattern generator (CPG) is able to generate rhythmic signals with reasonable frequencies and phases, and thus has been widely applied to control the movements of legged robots, such as walking of humanoid robots. However, it is difficult for this kind of CPG to generate rhythmic signals with desired shapes, which limits the adaptability of walking of humanoid robots in various environments. To address this issue, a new framework that can generate desired rhythmic signals for Matsuoka's CPG is presented. The proposed framework includes three main parts. First, feature processing is conducted to transform the Matsuoka's CPG outputs into a normalized limit cycle. Second, by combining the normalized limit cycle with robot feedback as the feature inputs and setting the required learning objective, the neural network (NN) learns to generate desired rhythmic signals. Finally, in order to ensure the continuity of the desired rhythmic signals, signal filtering is applied to the outputs of NN, with the aim of smoothing the discontinuous parts. Numerical experiments on the proposed framework suggest that it can not only generate a variety of rhythmic signals with desired shapes but also preserve the frequency and phase properties of Matsuoka's CPG. In addition, the proposed framework is embedded into a control system for adaptive omnidirectional walking of humanoid robot NAO. Extensive simulation and real experiments on this control system demonstrate that the proposed framework is able to generate desired rhythmic signals for adaptive walking of NAO on fixed and changing inclined surfaces. Furthermore, the comparison studies verify that the proposed framework can significantly improve the adaptability of NAO's walking compared with the other methods.																	2168-2267	2168-2275				FEB	2020	50	2					613	626		10.1109/TCYB.2018.2870145													
J								Probabilistic Rank-One Discriminant Analysis via Collective and Individual Variation Modeling	IEEE TRANSACTIONS ON CYBERNETICS										Tensile stress; Probabilistic logic; Covariance matrices; Convergence; Principal component analysis; Tuning; Training; Discriminant analysis; multilinear subspace learning; probabilistic models	FEATURE-EXTRACTION; RECOGNITION; REGULARIZATION; PCA	Linear discriminant analysis (LDA) is a classical supervised subspace learning technique that has wide applications. However, it is designed for vector only, which cannot exploit the tensor structures and may lead to suboptimal results when dealing with tensorial data. To address this problem, several multilinear LDA (MLDA) methods have been proposed to learn the subspaces from tensors. By exploiting the tensor structures, they achieve compact subspace representations, reduced parameter sizes, and improved robustness against the small sample size problem. However, existing MLDA methods do not take data uncertainty into account, fail to converge properly, or have to introduce additional tuning parameters for good convergence properties. In this paper, we therefore solve these limitations by proposing a probabilistic MLDA method for matrix inputs. Specifically, we propose a new generative model to incorporate structural information into the probabilistic framework, where each observed matrix is represented as a linear combination of collective and individual rank-one matrices. This provides our method with both the expressiveness of capturing discriminative features and nondiscriminative noise, and the capability of exploiting the 2-D tensor structures. To overcome the convergence problem of existing MLDAs, we develop an EM-type algorithm for parameter estimation, which has closed-form solutions with convergence guarantees. Experimental results on real-world datasets show the superiority of the proposed method to other probabilistic and MLDA variants.																	2168-2267	2168-2275				FEB	2020	50	2					627	639		10.1109/TCYB.2018.2870440													
J								Distributed Output Feedback Leader-Following Control for High-Order Nonlinear Multiagent System Using Dynamic Gain Method	IEEE TRANSACTIONS ON CYBERNETICS										Distributed control; dynamic gain; leader-following; multiagent systems (MASs); output feedback	CONSENSUS TRACKING CONTROL; COOPERATIVE CONTROL; CONTAINMENT CONTROL	In this paper, the distributed output feedback leader-following control is investigated for high-order nonlinear multiagent systems (MASs) using the dynamic gain method. The linear-like distributed output feedback controller is designed without using the recursive method to overcome the "explosion of complexity" problem and further relax the conditions on the nonlinear functions of the MASs. First, the distributed reduced order dynamic gain observer is constructed for the ith agent to estimate its unmeasured state variables, in which the output information of its neighbors are used. Second, the linear-like output feedback controller is designed such that the outputs of the followers track the leader's output, and the tracking error could be arbitrarily small. Finally, the simulation examples are given to illustrate the effectiveness of the proposed method.																	2168-2267	2168-2275				FEB	2020	50	2					640	649		10.1109/TCYB.2018.2870543													
J								Multiobjective Rule-Based Cooperative Continuous Ant Colony Optimized Fuzzy Systems With a Robot Control Application	IEEE TRANSACTIONS ON CYBERNETICS										Ant colony optimization (ACO); evolutionary fuzzy systems (FSs); multiobjective optimization; robot wall-following control	PARTICLE-SWARM OPTIMIZATION; MOBILE-ROBOT; EVOLUTIONARY ALGORITHMS; NEURAL-NETWORK; DESIGN; NAVIGATION	This paper proposes a new rule-based cooperative framework for multiobjective evolutionary fuzzy systems (FSs). Based on the framework, a multiobjective rule-based cooperative continuous ant-colony optimization (MO-RCCACO) algorithm is proposed to optimize all of the free parameters in FSs. Instead of optimization using a single colony of FSs (solutions), the MO-RCCACO consists of r subcolonies of size N cooperatively optimizing an FS that consists of r rules, with a subcolony optimizing only a single fuzzy rule. In addition, an auxiliary colony is created to store all of the fuzzy rules in the best-so-far N FSs to enhance the optimization ability of MO-RCCACO. The performance ranking of different fuzzy rules in the same subcolony is performed based on the multiobjective function values of their participating FSs by using Pareto nondominated sorting and the crowding distance. The MO-RCCACO is applied to find the Pareto-optimal fuzzy controllers (FCs) of a mobile robot for wall following with multiple control objectives. The optimization ability of the MO-RCCACO is verified through comparisons with various multiobjective population-based optimization algorithms in the robot wall-following control problem. Experimental results verify the effectiveness of the MO-RCCACO-based FCs for the boundary following control of a real robot.																	2168-2267	2168-2275				FEB	2020	50	2					650	663		10.1109/TCYB.2018.2870981													
J								Online Tool Condition Monitoring Based on Parsimonious Ensemble	IEEE TRANSACTIONS ON CYBERNETICS										Tools; Complexity theory; Merging; Machining; Sensors; Condition monitoring; Monitoring; Concept drifts; ensemble classifier; lifelong learning; nonstationary environments; online learning; prognostic health management	FUZZY INFERENCE SYSTEM; FAULT-DETECTION; FEATURE-SELECTION; IDENTIFICATION; DIAGNOSIS	Existing methodologies for tool condition monitoring (TCM) still rely on batch approaches which cannot cope with a fast sampling rate of a metal cutting process. Furthermore, they require a retraining process to be completed from scratch when dealing with a new set of machining parameters. This paper presents an online TCM approach based on Parsimonious Ensemble+; (pENsemble+;). The unique feature of pENsemble+; lies in its highly flexible principle where both the ensemble structure and base-classifier structure can automatically grow and shrink on the fly based on the characteristics of data streams. Moreover, the online feature selection scenario is integrated to actively sample relevant input attributes. This paper presents advancement of a newly developed ensemble learning algorithm, pENsemble, where the online active learning scenario is incorporated to reduce the operator's labeling effort. The ensemble merging scenario is proposed which allows reduction of ensemble complexity while retaining its diversity. Experimental studies utilizing two real-world manufacturing data streams: 1) metal turning and 2) 3-D-printing processes and comparisons with well-known algorithms were carried out. Furthermore, the efficacy of pENsemble+; was examined using benchmark concept drift data streams. It has been found that pENsemble+; incurs low structural complexity and results in a significant reduction of the operator's labeling effort.																	2168-2267	2168-2275				FEB	2020	50	2					664	677		10.1109/TCYB.2018.2871120													
J								Integrated Fault Estimation and Fault-Tolerant Tracking Control for Lipschitz Nonlinear Multiagent Systems	IEEE TRANSACTIONS ON CYBERNETICS										Fault estimation (FE); fault-tolerant tracking control (FTTC); integrated design; Lipschitz nonlinear multiagent systems (MASs)	FIXED-TIME CONSENSUS; STRATEGY	An integrated fault estimation (FE) and fault-tolerant tracking control (FTTC) strategy is developed for Lipschitz nonlinear multiagent systems subject to actuator faults, external disturbance, and uncertainties. First, for each agent, a corresponding unknown input observer with reduced/full order is constructed to obtain the FE. Then, a state/output feedback FTTC strategy is proposed based on the integral sliding-mode technique and adaptive super-twisting algorithm. The observer and controller gains are obtained simultaneously via H-infinity optimization with a linear matrix inequality formulation. Finally, the comparison simulations are provided to demonstrate the effectiveness of the proposed algorithm.																	2168-2267	2168-2275				FEB	2020	50	2					678	688		10.1109/TCYB.2018.2871243													
J								A Multipopulation-Based Multiobjective Evolutionary Algorithm	IEEE TRANSACTIONS ON CYBERNETICS										Sociology; Statistics; Optimization; Mathematical model; Genetic algorithms; Evolutionary computation; Markov processes; Evolutionary algorithm; genetic algorithms (GAs); Markov chain; multiobjective optimization; multipopulation	POPULATION GENETIC ALGORITHM; OPTIMIZATION	Multipopulation is an effective optimization component often embedded into evolutionary algorithms to solve optimization problems. In this paper, a new multipopulation-based multiobjective genetic algorithm (MOGA) is proposed, which uses a unique cross-subpopulation migration process inspired by biological processes to share information between subpopulations. Then, a Markov model of the proposed multipopulation MOGA is derived, the first of its kind, which provides an exact mathematical model for each possible population occurring simultaneously with multiple objectives. Simulation results of two multiobjective test problems with multiple subpopulations justify the derived Markov model, and show that the proposed multipopulation method can improve the optimization ability of the MOGA. Also, the proposed multipopulation method is applied to other multiobjective evolutionary algorithms (MOEAs) for evaluating its performance against the IEEE Congress on Evolutionary Computation multiobjective benchmarks. The experimental results show that a single-population MOEA can be extended to a multipopulation version, while obtaining better optimization performance.																	2168-2267	2168-2275				FEB	2020	50	2					689	702		10.1109/TCYB.2018.2871473													
J								A Network Reduction-Based Multiobjective Evolutionary Algorithm for Community Detection in Large-Scale Complex Networks	IEEE TRANSACTIONS ON CYBERNETICS										Complex networks; Detection algorithms; Optimization; Feature extraction; Evolutionary computation; Density measurement; Scalability; Community detection; complex network; evolutionary algorithm; large-scale network; multiobjective optimization	GENETIC ALGORITHM; OPTIMIZATION	Evolutionary algorithms have been demonstrated to be very competitive in the community detection for complex networks. They, however, show poor scalability to large-scale networks due to the exponential increase of search space. In this paper, we suggest a network reduction-based multiobjective evolutionary algorithm for community detection in large-scale networks, where the size of the networks is recursively reduced as the evolution proceeds. In each reduction of the network, the local communities found by the elite individuals in the population are identified as nodes of the reduced network for further evolution, thereby considerably reducing the search space. A local community repairing strategy is also suggested to correct the misidentified nodes after each network reduction during the evolution. Experimental results on synthetic and real-world networks demonstrate the superiority of the proposed algorithm over several state-of-the-art community detection algorithms for large-scale networks, in terms of both computational efficiency and detection performance.																	2168-2267	2168-2275				FEB	2020	50	2					703	716		10.1109/TCYB.2018.2871673													
J								Identifying Key Opinion Leaders in Social Media via Modality-Consistent Harmonized Discriminant Embedding	IEEE TRANSACTIONS ON CYBERNETICS										Social network services; Task analysis; Clustering algorithms; Learning systems; Correlation; Manuals; Computational modeling; Harmonized discrimination preserving; key opinion leader (KOL) identification; local geometry preserving; modality consistency preserving; modality-consistent harmonized discriminant embedding (MCHDE); multimodal learning; social media; subspace learning	MULTIVIEW; FRAMEWORK; MODEL	The digital age has empowered brands with new and more effective targeted marketing tools in the form of key opinion leaders (KOLs). Because of the KOLs' unique capability to draw specific types of audience and cultivate long-term relationship with them, correctly identifying the most suitable KOLs within a social network is of great importance, and sometimes could govern the success or failure of a brand's online marketing campaigns. However, given the high dimensionality of social media data, conducting effective KOL identification by means of data mining is especially challenging. Owing to the generally multiple modalities of the user profiles and user-generated content (UGC) over the social networks, we can approach the KOL identification process as a multimodal learning task, with KOLs as a rare yet far more important class over non-KOLs in our consideration. In this regard, learning the compact and informative representation from the high-dimensional multimodal space is crucial in KOL identification. To address this challenging problem, in this paper, we propose a novel subspace learning algorithm dubbed modality-consistent harmonized discriminant embedding (MCHDE) to uncover the low-dimensional discriminative representation from the social media data for identifying KOLs. Specifically, MCHDE aims to find a common subspace for multiple modalities, in which the local geometric structure, the harmonized discriminant information, and the modality consistency of the dataset could be preserved simultaneously. The above objective is then formulated as a generalized eigendecomposition problem and the closed-form solution is obtained. Experiments on both synthetic example and a real-world KOL dataset validate the effectiveness of the proposed method.																	2168-2267	2168-2275				FEB	2020	50	2					717	728		10.1109/TCYB.2018.2871765													
J								False Data Injection Attack for Cyber-Physical Systems With Resource Constraint	IEEE TRANSACTIONS ON CYBERNETICS										Sensors; Cyberattack; Multidimensional systems; Covariance matrices; Optimization; State estimation; Kalman filters; Convex optimization; cyber-physical systems (CPSs); false data injection attack; remote estimator estimation		Cyber-security is of the fundamental importance for cyber-physical systems (CPSs), since CPSs are vulnerable to cyber attack. In order to make the defensive measures better, one needs to understand the behavior from the view of an attacker. In this paper, the problem of false data injection attack on remote state estimation with resource constraints is studied in two cases, where the first case is that the attacker adds a Gaussian noise to the innovation, while the other is that the attacker employs a Gaussian noise to replace the innovation. In addition, the attacker is assumed to has a resource constraint, i.e., he/she cannot attack all the sensors, at the same time should decide which sensors to attack. By using the matrix theory, the optimal attack strategy problem, which aims to maximize the trace of the remote estimation error covariance, is converted into a convex optimization problem that can be solved. Thus, an optimal attack strategy is given to illustrate which sensors should be attacked. An example is given to show the effectiveness of the theoretical results.																	2168-2267	2168-2275				FEB	2020	50	2					729	738		10.1109/TCYB.2018.2871951													
J								A Transfer-Based Additive LS-SVM Classifier for Handling Missing Data	IEEE TRANSACTIONS ON CYBERNETICS										Classification; data cleaning; missing data; support vector machine (SVM); transfer learning	DOMAIN ADAPTATION; STATISTICAL COMPARISONS; IMPUTATION; REGRESSION; EM	The performance of a classifier might greatly deteriorate due to missing data. Many different techniques to handle this problem have been developed. In this paper, we solve the problem of missing data using a novel transfer learning perspective and show that when an additive least squares support vector machine (LS-SVM) is adopted, model transfer learning can be used to enhance the classification performance on incomplete training datasets. A novel transfer-based additive LS-SVM classifier is accordingly proposed. This method also simultaneously determines the influence of classification errors caused by each incomplete sample using a fast leave-one-out cross validation strategy, as an alternative way to clean the training data to further improve the data quality. The proposed method has been applied to seven public datasets. The experimental results indicate that the proposed method achieves at least comparable, if not better, performance than case deletion, mean imputation, and k-nearest neighbor imputation methods, followed by the standard LS-SVM and support vector machine classifiers. Moreover, a case study on a community healthcare dataset using the proposed method is presented in detail, which particularly highlights the contributions and benefits of the proposed method to this real-world application.																	2168-2267	2168-2275				FEB	2020	50	2					739	752		10.1109/TCYB.2018.2872800													
J								Evolutionary Many-Objective Optimization Based on Adversarial Decomposition	IEEE TRANSACTIONS ON CYBERNETICS										Sociology; Statistics; Optimization; Convergence; Computer science; Evolutionary computation; Shape; Adversarial decomposition; evolutionary algorithm; many-objective optimization; stable matching theory	NONDOMINATED SORTING APPROACH; MATCHING-BASED SELECTION; ALGORITHM; DIVERSITY; PERFORMANCE; PROXIMITY; BALANCE; MOEA/D	The decomposition-based evolutionary algorithm has become an increasingly popular choice for posterior multiobjective optimization. Facing the challenges of an increasing number of objectives, many techniques have been developed which help to balance the convergence and diversity. Nevertheless, according to a recent study by Ishibuchi et al., due to the predefined search directions toward the ideal point, their performance strongly depends on the Pareto front (PF) shapes, especially the orientation of the PFs. To balance the convergence and diversity for decomposition-based methods and to alleviate their performance dependence on the orientation of the PFs, this paper develops an adversarial decomposition method for many-objective optimization, which leverages the complementary characteristics of different subproblem formulations within a single paradigm. More specifically, two populations are co-evolved by two subproblem formulations with different contours and adversarial search directions. To avoid allocating redundant computational resources to the same region of the PF, the two populations are matched into one-to-one solution pairs according to their working regions upon the PF. Each solution pair can at most contribute one principal mating parent during the mating selection process. When comparing nine state-of-the-art many-objective optimizers, we have witnessed the competitive performance of our proposed algorithm on 130 many-objective test problems with various characteristics, including regular and inverted PFs.																	2168-2267	2168-2275				FEB	2020	50	2					753	764		10.1109/TCYB.2018.2872803													
J								An Accelerated Physarum Solver for Network Optimization	IEEE TRANSACTIONS ON CYBERNETICS										Bio-inspired algorithm; network optimization; Physarum solver; shortest path problem	SLIME-MOLD; ALGORITHM; MODEL; DESIGN; USA	As a novel computational paradigm, Physarum solver has received increasing attention from the researchers in tackling a plethora of network optimization problems. However, the convergence of Physarum solver is grounded by solving a system of linear equations iteratively, which often leads to low computational performance. Two factors have been highlighted along the process: 1) high time complexity in solving the system of linear equations and 2) extensive iterations required for convergence. Thus, Physarum solver has been largely restricted by its unsatisfactory computational performance. In this paper, we aim to address these two issues by developing two enhancement strategies: 1) pruning inactive nodes and 2) terminating Physarum solver in advance. First, extensive nodes and edges become and stay inactive after a few iterations in identifying the shortest path. Removing these inactive nodes and edges significantly decreases the graph size, thereby reducing computational complexity. Second, we define a transition phase for edges. All of the paths experiencing such a transition phase are dynamically aggregated to form a set of near-optimal paths among which the optimal path is included. Depth-first search is then leveraged to identify the optimal path from the near-optimal paths set. Earlier termination of Physarum solver saves considerable iterations while guaranteeing the optimality of the found solution. Empirically, 20 randomly generated sparse and complete graphs with network sizes ranging from 50 to 2000 as well as two real-world traffic networks are used to compare the performance of accelerated Physarum solver to the other two state-of-the-art algorithms.																	2168-2267	2168-2275				FEB	2020	50	2					765	776		10.1109/TCYB.2018.2872808													
J								Importance of Vertices in Complex Networks Applied to Texture Analysis	IEEE TRANSACTIONS ON CYBERNETICS										Web pages; Level measurement; Complex networks; Topology; Computational modeling; Cybernetics; Computer vision; Complex networks (CNs); importance of vertices; pagerank; texture analysis	GRAY-SCALE; CLASSIFICATION; ROTATION; PAGERANK; FEATURES; PATTERN; IMAGES	Texture analysis has attracted increasing attention in computer vision due to its power in describing images and the physical properties of objects. Among the methods for texture analysis, complex network (CN)-based ones have emerged to model images because of their flexibility. In image modeling, each pixel is mapped to a vertex of the CN and two vertices are connected if they are spatially close in the image. Then measurements are extracted from the CN to characterize its topology and therefore characterize the image content. Despite the promising results, the accuracy of these methods depends on the suitability of the measurement for the application. In texture analysis, simple measurements have been used, such as those based on vertex degree and shortest paths. Motivated by these issues, this paper proposes a new method for texture analysis based on the CN and a new measurement that calculates the importance of each vertex within its neighborhood. For calculating the importance of vertices, we extend the pagerank to CN in order to correlate the vertex importance with its degree and show that this new measurement extracts texture properties. Experimental results on well-known datasets and in the recognition of soybean diseases using leaf texture show the effectiveness of the proposed method for texture recognition.																	2168-2267	2168-2275				FEB	2020	50	2					777	786		10.1109/TCYB.2018.2873135													
J								Context-Aware Deep Spatiotemporal Network for Hand Pose Estimation From Depth Images	IEEE TRANSACTIONS ON CYBERNETICS										Feature extraction; Pose estimation; Spatiotemporal phenomena; Image sequences; Context modeling; Adaptation models; Data mining; Adaptive fusion; context-aware deep spatiotemporal network (CADSTN); hand pose estimation	3D HAND	As a fundamental and challenging problem in computer vision, hand pose estimation aims to estimate the hand joint locations from depth images. Typically, the problems are modeled as learning a mapping function from images to hand joint coordinates in a data-driven manner. In this paper, we propose a context-aware deep spatiotemporal network, a novel method to jointly model the spatiotemporal properties for hand pose estimation. Our proposed network is able to learn the representations of the spatial information and the temporal structure from the image sequences. Moreover, by adopting the adaptive fusion method, the model is capable of dynamically weighting different predictions to lay emphasis on sufficient context. Our method is examined on two common benchmarks, the experimental results demonstrate that our proposed approach achieves the best or the second-best performance with the state-of-the-art methods and runs in 60 fps.																	2168-2267	2168-2275				FEB	2020	50	2					787	797		10.1109/TCYB.2018.2873733													
J								Cooperative Moving-Target Enclosing of Networked Vehicles With Constant Linear Velocities	IEEE TRANSACTIONS ON CYBERNETICS										Orbits; Angular velocity; Target tracking; Vehicle dynamics; Robot sensing systems; Cooperative control; nonholonomic vehicles; target enclosing; velocity constraint	COLLECTIVE CIRCULAR MOTION; COORDINATED STANDOFF TRACKING; NONHOLONOMIC MOBILE ROBOTS; CYCLIC PURSUIT; TRAJECTORY TRACKING; CIRCUMNAVIGATION; STABILIZATION; CONSENSUS	This paper investigates the cooperative moving-target enclosing control problem of networked unicycle-type nonholonomic vehicles with constant linear velocities. The information of the target is only known to some of the vehicles, and the topology of the vehicle network is described by a directed graph. A dynamic control law is proposed to steer the vehicles, such that they can get close to orbiting around the target while the target is moving with a time-vary velocity. Besides, the constraint of bounded angular velocity for the vehicles can always be satisfied. The proposed control law is distributed in the sense that each vehicle only uses its own information and the information of its neighbors in the network. Finally, simulation results of an example validate the effectiveness of the proposed control law.																	2168-2267	2168-2275				FEB	2020	50	2					798	809		10.1109/TCYB.2018.2873904													
J								Generalized Conditional Domain Adaptation: A Causal Perspective With Low-Rank Translators	IEEE TRANSACTIONS ON CYBERNETICS										Conditional distribution; domain adaptation (DA); invariant components; low-rank representation; unsupervised learning	FACE RECOGNITION; KERNEL; ILLUMINATION	Learning domain adaptive features aims to enhance the classification performance of the target domain by exploring the discriminant information from an auxiliary source set. Let X denote the feature and Y as the label. The most typical problem to be addressed is that P-XY has a so large variation between different domains that classification in the target domain is difficult. In this paper, we study the generalized conditional domain adaptation (DA) problem, in which both P-Y and P-X vertical bar Y change across domains, in a causal perspective. We propose transforming the class conditional probability matching to the marginal probability matching problem, under a proper assumption. We build an intermediate domain by employing a regression model. In order to enforce the most relevant data to reconstruct the intermediate representations, a low-rank constraint is placed on the regression model for regularization. The low-rank constraint underlines a global algebraic structure between different domains, and stresses the group compactness in representing the samples. The new model is considered under the discriminant subspace framework, which is favorable in simultaneously extracting the classification information from the source domain and adaptation information across domains. The model can be solved by an alternative optimization manner of quadratic programming and the alternative Lagrange multiplier method. To the best of our knowledge, this paper is the first to exploit low-rank representation, from the source domain to the intermediate domain, to learn the domain adaptive features. Comprehensive experimental results validate that the proposed method provides better classification accuracies with DA, compared with well-established baselines.																	2168-2267	2168-2275				FEB	2020	50	2					821	834		10.1109/TCYB.2018.2874219													
J								Primal Averaging: A New Gradient Evaluation Step to Attain the Optimal Individual Convergence	IEEE TRANSACTIONS ON CYBERNETICS										Convergence; Convex functions; Machine learning; Optimization methods; Linear programming; Cybernetics; Individual convergence; machine learning; mirror descent (MD) methods; regularized learning problems; stochastic gradient descent (SGD); stochastic optimization	NEURAL-NETWORK; OPTIMIZATION; PERFORMANCE; ALGORITHMS	Many well-known first-order gradient methods have been extended to cope with large-scale composite problems, which often arise as a regularized empirical risk minimization in machine learning. However, their optimal convergence is attained only in terms of the weighted average of past iterative solutions. How to make the individual convergence of stochastic gradient descent (SGD) optimal, especially for strongly convex problems has now become a challenging problem in the machine learning community. On the other hand, Nesterov's recent weighted averaging strategy succeeds in achieving the optimal individual convergence of dual averaging (DA) but it fails in the basic mirror descent (MD). In this paper, a new primal averaging (PA) gradient operation step is presented, in which the gradient evaluation is imposed on the weighted average of all past iterative solutions. We prove that simply modifying the gradient operation step in MD by PA strategy suffices to recover the optimal individual rate for general convex problems. Along this line, the optimal individual rate of convergence for strongly convex problems can also be achieved by imposing the strong convexity on the gradient operation step. Furthermore, we extend PA-MD to solve regularized nonsmooth learning problems in the stochastic setting, which reveals that PA strategy is a simple yet effective extra step toward the optimal individual convergence of SGD. Several real experiments on sparse learning and SVM problems verify the correctness of our theoretical analysis.																	2168-2267	2168-2275				FEB	2020	50	2					835	845		10.1109/TCYB.2018.2874332													
J								Robust Second-Order Consensus Using a Fixed-Time Convergent Sliding Surface in Multiagent Systems	IEEE TRANSACTIONS ON CYBERNETICS										Convergence; Multi-agent systems; Symmetric matrices; Stability analysis; Robustness; Control systems; Vehicle dynamics; Consensus; fixed-time convergence; multiagent systems; robustness; sliding mode control (SMC)	FINITE-TIME; COOPERATIVE CONTROL; DESIGN; STABILIZATION; TRACKING	Faster convergence is always sought in many applications. Designing fixed-time control has recently gained much attention since, for this type of control structure, the convergence time of the states does not depend on initial conditions, unlike other control methods providing faster convergence. This paper proposes a new distributed algorithm for second-order consensus in multiagent systems by using a full-order fixed-time convergent sliding surface. The stability analysis is performed using the Lyapunov function and bi-homogenous property. Moreover, the proposed control is smooth and free from any singularity. The robustness of the proposed scheme is verified both in the presence of Lipschitz disturbances and uncertainties in the network. The proposed method is compared with a state-of-the-art method to show the effectiveness.																	2168-2267	2168-2275				FEB	2020	50	2					846	855		10.1109/TCYB.2018.2875362													
J								A Hybrid Strategy for Target Search Using Static and Mobile Sensors	IEEE TRANSACTIONS ON CYBERNETICS										Robot sensing systems; Planning; Robot kinematics; Search problems; Object detection; Hybrid search planning; mobile-target search; multirobot coordination; wilderness search and rescue (WiSAR); wireless sensor networks	WILDERNESS SEARCH; BAYESIAN SEARCH; NETWORKS; TRACKING; LOCALIZATION; COVERAGE; LOST; UAVS	Locating a mobile target, untrackable in real-time, is pertinent to numerous time-critical applications, such as wilderness search and rescue. This paper proposes a hybrid approach to this dynamic problem, where both static and mobile sensors are utilized for the goal of detecting a target. The approach is novel in that a team of robots utilized to deploy a static-sensor network also actively searches for the target via on-board sensors. Synergy is achieved through: 1) optimal deployment planning of static-sensor networks and 2) optimal routing and motion planning of the robots for the deployment of the network and target search. The static-sensor network is planned first to maximize the likelihood of target detection while ensuring (temporal and spatial) unbiasedness in target motion. Robot motions are, subsequently, planned in two stages: 1) route planning and 2) trajectory planning. In the first stage, given a static-sensor network configuration, robot routes are planned to maximize the amount of spare time available to the mobile agents/sensors, for target search in between (just-in-time) static-sensor deployments. In the second stage, given robot routes (i.e., optimal sequences of sensor delivery locations and times), the corresponding robot trajectories are planned to make effective use of any spare time the mobile agents may have to search for the target. The proposed search strategy was validated through extensive simulations, some of which are given in detail here. An analysis of the method's performance in terms of target-search success is also included.																	2168-2267	2168-2275				FEB	2020	50	2					856	868		10.1109/TCYB.2018.2875625													
J								Are living beings extended autopoietic systems? An embodied reply	ADAPTIVE BEHAVIOR										Autopoiesis; extended autopoietic systems; enactivism; body; multiple realizability		Building on the original formulation of the autopoietic theory (AT), extended enactivism argues that living beings are autopoietic systems that extend beyond the spatial boundaries of the organism. In this article, we argue that extended enactivism, despite having some basis in AT's original formulation, mistakes AT's definition of living beings as autopoietic entities. We offer, as a reply to this interpretation, a more embodied reformulation of autopoiesis, which we think is necessary to counterbalance the (excessively) disembodied spirit of AT's original formulation. The article aims to clarify and correct what we take to be a misinterpretation of AT as a research program. AT, contrary to what some enactivists seem to believe, did not (and does not) intend to motivate an extended conception of living beings. AT's primary purpose, we argue, was (and is) to provide a universal individuation criterion for living beings, these understood as discrete bodies that are embedded in, but not constituted by, the environment that surrounds them. However, by giving a more explicitly embodied definition of living beings, AT can rectify and accommodate, so we argue, the enactive extended interpretation of autopoiesis, showing that although living beings do not extend beyond their boundaries as autopoietic unities, they do form part, in normal conditions, of broader autopoietic systems that include the environment.																	1059-7123	1741-2633				FEB	2020	28	1					3	13		10.1177/1059712318823723													
J								Reflections in relation to the article of Villalobos and Razeto	ADAPTIVE BEHAVIOR										Autopoiesis; system; unity; living; organism		This is a very interesting article, and I would like to make a few epistemological and operational reflective commentaries that it evokes in me.																	1059-7123	1741-2633				FEB	2020	28	1					15	17		10.1177/1059712319841740													
J								The necessity of extended autopoiesis	ADAPTIVE BEHAVIOR										Autopoiesis; embodiment; extended autopoiesis; origins of life; organism = network		The theory of autopoiesis holds that an organism can be defined as a network of processes. However, an organism also has a physical body. The relationship between these two things-network and body-has been raised in this issue of Adaptive Behaviour, with reference to an extended interpretation of autopoiesis. This perspective holds that the network and the body are distinct things, and that the network should be thought of as extending beyond the boundaries of the body. The relationship between body and network is subtle, and I revisit it here from the extended perspective. I conclude that from an organism = network perspective, the body is a biological solution to the problem of maintaining both the distinctness of an organism, separate from but engaged with its environment and other organisms, and its distinctiveness as a particular individual.																	1059-7123	1741-2633				FEB	2020	28	1					23	26		10.1177/1059712319841557													
J								ADAPTIVE TUNING NOISE ESTIMATION FOR MEDICAL IMAGES USING MAXIMUM ELEMENT CONVOLUTION LAPLACIAN	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Image noise estimation; Rician noise; Medical imaging; Image processing		Noise in medical images can adversely affect the outcome of clinical diagnosis. In analyzing medical images, noise estimation is necessary to ensure consistency and performance quality of image processing techniques. In this study, we present a noise estimation method, namely Adaptive Tuning Noise Estimation (ATNE) that implements convolution Laplacian noise estimation. ATNE is based on subtraction of Gabor wavelet detected edges of images, and involves the relation element based on the parameters of the input image. This method allows a fast estimation of the image noise variance without a heavy computational cost. To assess the effectiveness of ATNE, 1000 mammograms are used. We pre-process these images to be Rician distributed with various noise variances. ATNE is used to estimate the noise level of the resulting images. We compare ATNE with other noise estimation methods, and the results show that ATNE outperforms other related methods with a lower percentage of error for noise variance estimation.																	1349-4198	1349-418X				FEB	2020	16	1					1	14		10.24507/ijicic.16.01.1													
J								DAYLIGHT FACTOR DISTRIBUTION OPTIMIZATION BASED ON SKY COMPONENT ON THE ROOM FOR WINDOW OPENINGS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Distribution; Daylight Factor (DF); Sky Component (SC); Window openings; Optimization		Architectural design is a building system that has room composition and design products that take into account environmental conditions. The thing that most influences the environment and user comfort is lighting, where the more evenly distributed light in the room, the better the level of comfort. The importance of this lighting, so in designing, must think about the process of lighting quantitation in the room. One method of lighting quantitation in the room is the calculation of the Daylight Factor (DF). The value of DF is affected by Sky Component (SC). On the DF, the object used is a window and outside lighting factors. Based on the quantitation process, this research has the idea of analyzing three different variants of space in the character of the wall. In this paper, the best window position is obtained based on the value of the largest number of DF distributions in the room. Optimization in this study can be obtained by calculating the standard deviation value of the DF distribution for each window opening shift. The window position is considered optimal or the best in the DF distribution in the room, if it has the highest DF mean value and the smallest DF variant value.																	1349-4198	1349-418X				FEB	2020	16	1					15	28		10.24507/ijicic.16.01.15													
J								SECOND-ORDER SLIDING MODE FOR POSITION AND ATTITUDE TRACKING CONTROL OF QUADCOPTER UAV: SUPER-TWISTING ALGORITHM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Quadcopter UAV; Full trajectory tracking; Nonlinear control; Second-order sliding mode control; Super-twisting algorithm		Currently, tracking control of UAVs type quadcopter is a hot spot for researchers. In order to solve this control problem, the choice of the appropriate controller, according to the desired objectives, is a fundamental concern. Regardless of the harmful chattering phenomena, sliding mode control (SMC) has shown acceptable performance. In this paper, trajectory tracking control of the quadcopter is carried out through second-order sliding mode control (2-SMC). It is one of the alternative solutions that preserves the advantages of the conventional SMC while avoiding the undesirable chattering effect. Specifically, the super-twisting algorithm, which is modified 2-SMC that prevents the need for any sliding variable derivative, is adopted. For the sake of ensuring stability and enhancing the quadcopter tracking trajectory, a global block control based on the super-twisting algorithm is designed. The proposed technique offers high stability since it allows the derivation of the appropriate control law for each position and attitude state. Simulation results illustrate the efficiency of this approach in terms of stability and tracking control. A comparison study with classical SMC and type-2 fuzzy logic controller is given to clarify the effectiveness of the proposed 2-SMC.																	1349-4198	1349-418X				FEB	2020	16	1					29	43		10.24507/ijicic.16.01.29													
J								A VISUAL SURFACE DEFECT DETECTION METHOD BASED ON LOW RANK AND SPARSE REPRESENTATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Surface defect detection; Visual saliency; Low rank and sparse representation; Computer vision; Robust principal component analysis	SALIENCY DETECTION; INSPECTION; QUALITY; MODEL	Surface defect detection is very crucial for product quality control. A visual detection method based on low rank and sparse representation for surface defect detection of the wind turbine blade is brought forward in this paper. Two terms, which are the Laplacian regularization term and the noise term, were added into robust principal component analysis (RPCA). The noise term defined by F-norm is used to suppress uneven illumination and Gaussian noise, and the Laplacian regularization term is utilized to constrain the spatial relationship of superpixels. The defect image is considered to consist of a low rank matrix, a sparse matrix and a noise matrix, which corresponds with non-defect portion, defect portion and the noise portion of the image. At first, the proposed method segments the input image into a number of non-overlapping superpixels and extracts their features. Then, the optimal salient map is generated via the proposed method. Finally, the binary image is obtained by Otsu method. By quantitative and qualitative evaluation, experimental results illustrate that the proposed method is superior in terms of robustness and accuracy compared with 10 state-of-the-art methods on the synthetic and real images.																	1349-4198	1349-418X				FEB	2020	16	1					45	61		10.24507/ijicic.16.01.45													
J								IMPROVE THE STABILITY OF THE INTERNET OF THINGS USING DYNAMIC LOAD BALANCING CLUSTERING	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Internet of Things; Perceived layer; Wireless sensor networks; Load balance	IOT; SECURITY; WSN	Nowadays, Internet of Things (IoT) presents enormous capabilities in terms of connecting everyday objects to be accessible from the Internet. Wireless Sensor Networks (WSNs) have been integrated into the perceived layer of IoT where Sensor Nodes (SNs) dynamically join the Internet and use them to collaborate and accomplish their tasks. Due to it the issues of information collection play an important role in the perceived layer of IoT. Energy efficiency is affected by the number of data transmissions from the SN to the Sink. However, the SN is limited by the energy resource, the memory, the computation, the communication capability, etc. Therefore, the hierarchical clustering topology has been proposed to prolong the lifetime of WSNs by decreasing the energy consumption of SNs. Unfortunately, the network topology is still unstable due to the fact that the workload of the Cluster Managers (CMs) is overloaded. To solve the aforementioned issues, a Dynamic Load Balance Clustering Mechanism (DLBCM) is proposed to balance the workload of CM and reduce the energy consumption of CM. Then, the lifetime of WSN will be prolonged.																	1349-4198	1349-418X				FEB	2020	16	1					63	76		10.24507/ijicic.16.01.63													
J								CURVATURE GRAY FEATURE DECOMPOSITION BASED FINGER VEIN RECOGNITION WITH AN IMPROVED CONVOLUTIONAL NEURAL NETWORK	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Finger vein recognition; Finger vein image; Convolutional neural network; Curvature gray feature decomposition; Vein curvature gray feature image	PATTERNS	Finger vein recognition (FVR) is a technique for identity authentication based on finger vein images (FVIs) that are acquired using a specific device, which has become one of hot spots in the field of biometrics. The main idea of traditional FVR schemes is to directly extract features from FVIs or finger vein patterns (FVPs) and then compare features among FVIs to find the best match. However, the features extracted from FVIs contain much redundant data, while the features extracted from FVPs are greatly influenced by image segmentation methods. Recently, in order to improve the recognition rate and release the high complexity of image preprocessing, a finger vein recognition method based on deep belief network (DBN) with the features extracted from curvature gray images (CGI) has been proposed. However, the training process of DBN is somewhat time-consuming, and the background information of CGI may affect the recognition rate. In order to further improve the accuracy and speed up the training process, a new FVR algorithm based on the improved convolutional neural network (CNN) and curvature gray feature decomposition (CCFD) is proposed in this paper. First, we calculate the curvature of an FVI using a two-dimensional Gaussian template. Then we extract two gray images from the FVI with different scales and add these two images to obtain a CGI. Unlike the previous method, we further decompose this image into two components named vein curvature gray feature image (VCCFI) and background curvature gray feature image (BCGFI). Finally, using VCCFIs as input, an improved CNN is trained and used to recognize the identity of the input FVI. Experimental results show that our scheme is effective and better than traditional schemes and the previous DBN based method.																	1349-4198	1349-418X				FEB	2020	16	1					77	90		10.24507/ijicic.16.01.77													
J								UNSUPERVISED MONOCULAR DEPTH ESTIMATION OF DRIVING SCENES USING SIAMESE CONVOLUTIONAL LSTM NETWORKS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Monocular depth estimation; Disparity refinement; Siamese convolutional LSTM networks; Stereo vision; Unsupervised learning		Estimating depth from a single RGB image is an active research topic in computer vision because of its broad applications in scene understanding, autonomous driving, and traffic surveillance systems. This task involves estimating a pixel-wise depth map from a single image. Significant progress has been made on monocular depth estimation using deep learning-based techniques. Current approaches employ geometry-based image reconstruction methods instead of ground truth depth labels to perform depth estimation in an unsupervised manner. In this paper, we present a deep learning model to simultaneously learn and refine depth maps from a single RGB image and in an end-to-end manner by casting the monocular depth estimation as an image reconstruction problem. We propose an unsupervised framework for monocular depth estimation that trains a Siamese convolutional long short-term memory (Siamese convLSTM) network to jointly perform estimation and refinement of depth maps using rectified stereo image pairs and produce a depth map from a single RGB image at test time. Experimental results show that simultaneously performing these two tasks leads to improving depth estimation accuracy. In particular, using the KITTI 2015 driving dataset for evaluation, our proposed Siamese convLSTM network achieves excellent performance on monocular depth estimation, both quantitatively and qualitatively.																	1349-4198	1349-418X				FEB	2020	16	1					91	106		10.24507/ijicic.16.01.91													
J								AN IMPROVED WATER EVAPORATION OPTIMIZATION ALGORITHM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Water evaporation optimization; Evaporation probability matrix; Step size S; Elite individuals; Optimal individual	PARTICLE SWARM OPTIMIZATION; BEE COLONY ALGORITHM; SEARCH	The existing water evaporation optimization algorithm has some shortcomings, such as slow convergence speed, and low convergence accuracy. Therefore, this paper proposes an improved water evaporation optimization (IWEO) algorithm. In IWEO, firstly, in monolayer evaporation phase, the construction method of monolayer evaporation probability matrix (MEP) is improved to make up for the defect of slow updating of individuals, and thus speed up the convergence; at the same time, several elite individuals are introduced into the calculation of step size S to enhance the population learning of excellent evolutionary information, which contributes to balancing the global search and local search ability. Secondly, in droplet evaporation phase, the optimal individual and a new step size factor are used to guide and disturb the population respectively, which improves the convergence accuracy of the algorithm while maintaining the diversity of the population. To verify the performance of IWEO, a series of experiments is carried out on 15 benchmark functions. The experimental results show that compared with water evaporation optimization algorithm and the other state-of-the-art algorithms, the proposed algorithm has significant advantages in convergence accuracy and speed.																	1349-4198	1349-418X				FEB	2020	16	1					107	122		10.24507/ijicic.16.01.107													
J								l(2) - l(infinity) FILTERING FOR NETWORKED SWITCHED SYSTEMS WITH MULTIPLE PACKET DROPOUTS VIA RANDOM SWITCHED LYAPUNOV FUNCTION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Networked switched systems; l(2) - l(infinity) filtering; Multiple packet dropouts; Linear matrix inequalities (LMIs); Random switched Lyapunov function		This paper examines an l(2) - l(infinity ) filtering problem for a class of discrete-time networked switched systems with multiple packet dropouts, while the data packets include both the measurement output signal and the switching signal. The multiple packet dropouts phenomenon is described by Bernoulli binary sequences with known probabilities. Then, by constructing a novel switched Lyapunov function with the random missing of switching signal taken into account, a switched filter is designed such that the filtering error system is exponentially stable and satisfies the l(2) - l(infinity ) disturbance attenuation level. The parameters of the filter are obtained by solving an LMI. Finally, a practical example is presented to verify the effectiveness of the proposed approach.																	1349-4198	1349-418X				FEB	2020	16	1					123	135		10.24507/ijicic.16.01.123													
J								AN IMMUNITY-ENHANCING SECURITY MODULE FOR CLOUD SERVERS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Cloud server; Intrusion detection system; Adaptive machine learning; DNS; Gradient boosting	INTRUSION; DIVERSITY; SYSTEM	Cyberattacks on a vulnerability in a server application are threats to cloud servers. Advanced endpoint security techniques can detect and mitigate cyberattacks on known and unknown vulnerabilities, but their detection causes the server application to terminate, resulting in a denial of service. Intrusion detection systems with machine learning combine high accuracy and high speed of detection, but they require a wide variety of samples for learning. To solve these drawbacks, this paper proposes an immunity-enhancing module that adaptively acquires immunity to known and unknown cyberattacks without the need for prior learning of attack data. The module consists of innate and adaptive immune functions. The innate immune function detects known and unknown cyberattacks using advanced endpoint security techniques, whereas the adaptive immune function learns and detects the cyberattacks identified by the innate immune function using a gradient boosting classifier, thereby preventing a denial of service due to the innate immune function. This paper describes implementation of the module for a DNS server application. Its performance was evaluated by attacking vulnerabilities of CVE-2015-5477 and C VE-2016-2776. The module showed a detection accuracy of 99.9.4%, including a true negative rate of 100.00% and a true positive rate of 99.88%, and an overhead of 2.70%.																	1349-4198	1349-418X				FEB	2020	16	1					137	151		10.24507/ijicic.16.01.137													
J								MATHEMATICAL MODELING AND RISK MANAGEMENT OF PRODUCTION SYSTEMS WITH JUMP PROCESS VIA STOCHASTIC ANALYSIS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Jump process; Delta function; Stochastic differential equation; Lead time; Black-Scholes (BS) equation	LEAD-TIME; RETURN	The jump diffusion process is mathematically modeled in the field of finance such as US dollar to Japanese yen exchange rate fluctuations. In the field of small and medium-sized manufacturing, a significant increase in manufacturing costs has a significant impact on management. We propose a mathematical model with the jump in the rate of return, which is the stochastic diffusion model, and evaluate the system. A delta function is introduced to the jump process that is based on empirical data. We also propose the Black-Scholes model of mathematical finance as a business risk management strategy for the system evaluation. Finally, we show that the risk premium can be used to evaluate the target rate of return with a jump process.																	1349-4198	1349-418X				FEB	2020	16	1					153	171		10.24507/ijicic.16.01.153													
J								MULTIOBJECTIVE LEVY-FLIGHT FIREFLY ALGORITHM FOR OPTIMAL PIDA CONTROLLER DESIGN	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Multiobjective Levy-flight firefly algorithm; PIDA controller; Automatic voltage regulator; Modern optimization	EVOLUTIONARY ALGORITHMS; OPTIMIZATION; SEARCH	Firefly algorithm (FA) was proposed as one of the most powerful population-based metaheuristic optimization techniques for solving continuous and combinatorial optimization problems. The FA has been proved and applied to various real-world engineering problems in mostly single objective optimization manner. However, many real-world engineering problems are typically formulated as the multiobjective optimization problems with complex constraints. In this paper, the multiobjective Levy-flight firefly algorithm (mLFFA) is developed. The proposed mLFFA is validated against four standard multiobjective test functions. Then, the mLFFA is applied to optimally design the proportional-integral-derivative-accelerated (PIDA) controllers for the automatic voltage regulator (AVR) system in order to simultaneously minimize two particular objective functions, i.e., rise time and maximum overshoot. As simulation results, it was found that the mLFFA can provide very satisfactory solutions for all benchmark test functions. Moreover, the optimal PIDA controllers can be successfully obtained by the mLFFA according to the predefined objective and constraint functions to perform the optimal Pareto front containing the set of optimal PIDA controllers for the AVR system in the proposed control application.																	1349-4198	1349-418X				FEB	2020	16	1					173	187		10.24507/ijicic.16.01.173													
J								APPLICATION OF CUCKOO SEARCH TO ROBUST PIDA CONTROLLER DESIGN FOR LIQUID-LEVEL SYSTEM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Robust PIDA controller; Cuckoo search; Model uncertainty; Three-tank liquid-level system	LOOP SHAPING CONTROL	The cuckoo search (CS) is one of the most efficient nature-inspired metaheuristic algorithms for solving optimization problems. In this paper, the application of the CS to optimally design robust proportional-integral-derivative-accelerated (PIDA) controller for the three-tank (3-tank) liquid-level control system is presented. Such the 3-tank liquid-level control system commonly exists in industries under the proportional-integral-derivative (PID) control loop. However, the PIDA could provide better responses than the PID for higher order plant. Based on the modern optimization context, designing the robust PIDA controller for the 3-tank liquid-level control system with model uncertainty can be formulated by using the CS as an optimizer. The CS-based robust PIDA controller design framework can be considered as the constrained optimization problem. Model uncertainty occurs due to aging and environmental effects. Results obtained by the robust PIDA controller designed by the CS are compared with those obtained by the PID controller designed by Ziegler-Nichols (ZN) tuning rule and the CS, respectively. As simulation results, it was found that the responses of the 3-tank liquid-level controlled system with the robust PIDA controller designed by the CS are superior to those with the PID controller designed by ZN and CS. In addition, due to model uncertainty within +/- 10% of each lumped parameter of the nominal plant model, the robust PIDA controller designed by the CS could provide the satisfactory responses corresponding to inequality constraint functions. The robust performance and robust stability of the 3-tank liquid-level controlled system are elaborately assured.																	1349-4198	1349-418X				FEB	2020	16	1					189	205		10.24507/ijicic.16.01.189													
J								SMART HYDROCULTURE CONTROL SYSTEM BASED ON IOT AND FUZZY LOGIC	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Hydroponics; IoT; Smart controlling systems; Fuzzy logic; Urban farming		Limited agricultural land due to increasing development leads to a decline in agricultural production capacity. Therefore, a new solution for modern agriculture is needed to overcome this problem. Technology is useful for modern agriculture, such as the use of IoT for hydroponic farming systems. By using IoT with a smart controlling system, the hydroponic agriculture becomes easier. With the use of IoT in this research, nutrition, pH management, and temperature can be controlled easily. This research also uses fuzzy logic to make the decision making in the control system more efficient and precise. The results of experiments with bok choy and lettuce indicate that the system automatically measures the nutritional value and pH according to the time specified. Then, the system will immediately adjust the value of nutrient content and pH within the specified range. Smart control system shows better plant growth which can be seen from the growth of the leaves' width, length and plant's height.																	1349-4198	1349-418X				FEB	2020	16	1					207	221		10.24507/ijicic.16.01.207													
J								AIR CONDITIONING LOAD CONTROL BASED ON THE NETWORK COST AND ELECTRICITY MARKET PRICE UNDER DEMAND SIDE RESPONSE MODEL	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Demand side response; Energy cost; Minimize; Pre-cooling; Small consumer	CONTROL STRATEGY; THERMAL COMFORT; PEAK LOAD; MANAGEMENT STRATEGY; BIDDING STRATEGY; URGENT REQUESTS; ENERGY; OPTIMIZATION; BUILDINGS; SYSTEMS	Air conditioning (AC) is faced with a big problem to supply electricity demand and increased electricity prices to the consumer. This paper presents a new model development of demand side response (DSR) to assist small consumers particularly to optimize energy costs. The innovation of this paper is to assist small consumers to minimize energy costs. In this simulation, the consumer should undertake a pre-cooling mechanism to minimize the energy costs by anticipating the expensive cost. This model is applicable for residential homes in Makassar, South Sulawesi Indonesia. The results indicated the potential benefit of DSR to achieve energy saving for both consumers and aggregators.																	1349-4198	1349-418X				FEB	2020	16	1					223	239		10.24507/ijicic.16.01.223													
J								AN IMPROVED MEMETIC ALGORITHM FOR URBAN RAIL TRAIN OPERATION STRATEGY OPTIMIZATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Urban rail train; Memetic algorithm; Genetic algorithm; Opposition-based learning; Multi-objective optimization		The problem to be solved for the urban rail train operation strategy optimization is to find an optimal solution which can take account of various optimization indexes. Therefore, the multi-objective optimization model for the urban rail train operation is established with energy consumption, punctuality, comfort level and parking precision as optimization indexes. An improved Memetic Algorithm (MA) is used to solve the multiobjective optimization model under the operating constraints. In the framework of MA, its global search strategy adopts Genetic Algorithm (GA), and its local search strategy uses the predatory search mode based on the urban rail train's own characteristics. In GA, the convergence rate of the algorithm is improved by adjusting the selection pressure adaptively according to the number of iterations. Besides, to avoid MA falling into the local optimum in the optimization process as far as possible, the dynamic Opposition-Based Learning (OBL) mechanism is adopted to produce the opposite population, which expands the global search scope. The simulation results show that the improved MA has better optimization performance, compared with the classical MA and GA.																	1349-4198	1349-418X				FEB	2020	16	1					241	256		10.24507/ijicic.16.01.241													
