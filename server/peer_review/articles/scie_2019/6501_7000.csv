PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Predicting the causative pathogen among children with osteomyelitis using Bayesian networks - improving antibiotic selection in clinical practice	ARTIFICIAL INTELLIGENCE IN MEDICINE										Bone infection; Infectious disease; Bayesian belief network; Clinical decision support; Causal diagram; Probabilistic graph model	DECISION-SUPPORT-SYSTEM; ANTIMICROBIAL TREATMENT; EXPERT KNOWLEDGE; KINGELLA-KINGAE; TREAT; THERAPY; DELPHI; MODEL; RISK	Infection of bone, osteomyelitis (OM), is a serious bacterial infection in children requiring urgent antibiotic therapy. While biological specimens are often obtained and cultured to guide antibiotic selection, culture results may take several days, are often falsely negative, and may be falsely positive because of contamination by non-causative bacteria. This poses a dilemma for clinicians when choosing the most suitable antibiotic. Selecting an antibiotic which is too narrow in spectrum risks treatment failure; selecting an antibiotic which is too broad risks toxicity and promotes antibiotic resistance. We have developed a Bayesian Network (BN) model that can be used to guide individually targeted antibiotic therapy at point-of-care, by predicting the most likely causative pathogen in children with OM and the antibiotic with optimal expected utility. The BN explicitly models the complex relationship between the unobserved infecting pathogen, observed culture results, and clinical and demographic variables, and integrates data with critical expert knowledge under a causal inference framework. Development of this tool resulted from a multidisciplinary approach, involving experts in infectious diseases, modelling, paediatrics, microbiology, computer science and statistics. The model-predicted prevalence of causative pathogens among children with osteomyelitis were 56 % for Staphylococcus aureus, 17 % for 'other' culturable bacteria (like Streptococcus pyogenes), and 27 % for bacterial pathogens that are not culturable using routine methods (like Kingella kingae). Log loss cross-validation suggests that the model performance is robust, with the best fit to culture results achieved when data and expert knowledge were combined during parameterisation. AUC values of 0.68 - 0.77 were achieved for predicting culture results of different types of specimens. BN-recommended antibiotics were rated optimal or adequate by experts in 82-98% of 81 cases sampled from the cohort. We have demonstrated the potential use of BNs in improving antibiotic selection for children with OM, which we believe to be generalisable in the development of a broader range of decision support tools. With appropriate validation, such tools might be effectively deployed for real-time clinical decision support, to promote a shift in clinical practice from generic to individually-targeted antibiotic therapy, and ultimately improve the management and outcomes for a range of serious bacterial infections.																	0933-3657	1873-2860				JUL	2020	107								101895	10.1016/j.artmed.2020.101895													
J								Learning an expandable EMR-based medical knowledge network to enhance clinical diagnosis	ARTIFICIAL INTELLIGENCE IN MEDICINE										Incremental expansion framework; Link prediction; Knowledge integration; Medical knowledge network; Disease diagnosis; Electronic medical record	LINK-PREDICTION; COMPLEX NETWORKS; HEALTH-CARE; MODEL	Electronic medical records (EMRs) contain a wealth of knowledge that can be used to assist doctors in making clinical decisions like disease diagnosis. Constructing a medical knowledge network (MKN) to link medical concepts in EMRs is an effective way to manage this knowledge. The quality of the diagnostic result made by MKN-based clinical decision support system depends on the accuracy of medical knowledge and the completeness of the network. However, collecting knowledge is a long-lasting and cumulative process, which means it's hard to construct a complete MKN with limited data. This study was conducted with the objective of developing an expandable EMR-based MKN to enhance capabilities in making an initial clinical diagnosis. A network of symptom-indicate-disease knowledge in 992 Chinese EMRs (CEMRs) was manually constructed as Original-MKN, and an incremental expansion framework was applied to it to obtain an expandable MKN based on new CEMRs. The framework was composed by: (1) integrating external knowledge extracted from the medical information websites and (2) mining potential knowledge with new EMRs. The framework also adopts a diagnosis-driven learning method to estimate the effectiveness of each knowledge in clinical practice. Experimental results indicate that our expanded MKN achieves a precision of 0.837 for a recall of 0.719 in clinical diagnosis, which outperforms Original-MKN and four classical machine learning methods. Furthermore, both external medical knowledge and potential medical knowledge benefit MKN expansion and disease diagnosis. The proposed incremental expansion framework sustains the MKN learning new knowledge.																	0933-3657	1873-2860				JUL	2020	107								101927	10.1016/j.artmed.2020.101927													
J								Automated hematoma segmentation and outcome prediction for patients with traumatic brain injury	ARTIFICIAL INTELLIGENCE IN MEDICINE										Traumatic brain injury; Hematoma segmentation; Outcome prediction; Convolutional neural network; Deep learning	INTRACEREBRAL HEMORRHAGE; VOLUME; MANAGEMENT; DIAGNOSIS	Traumatic brain injury (TBI) is a major cause of death and disability worldwide. Automated brain hematoma segmentation and outcome prediction for patients with TBI can effectively facilitate patient management. In this study, we propose a novel Multi-view convolutional neural network with a mixed loss to segment total acute hematoma on head CT scans collected within 24h after the injury. Based on the automated segmentation, the volumetric distribution and shape characteristics of the hematoma were extracted and combined with other clinical observations to predict 6-month mortality. The proposed hematoma segmentation network achieved an average Dice coefficient of 0.697 and an intraclass correlation coefficient of 0.966 between the volumes estimated from the predicted hematoma segmentation and volumes of the annotated hematoma segmentation on the test set. Compared with other published methods, the proposed method has the most accurate segmentation performance and volume estimation. For 6-month mortality prediction, the model achieved an average area under the precision-recall curve (AUCPR) of 0.559 and area under the receiver operating characteristic curve (AUC) of 0.853 using 10-fold cross-validation on a dataset consisting of 828 patients. The average AUCPR and AUC of the proposed model are respectively more than 10% and 5% higher than those of the widely used IMPACT model.																	0933-3657	1873-2860				JUL	2020	107								101910	10.1016/j.artmed.2020.101910													
J								Breast ultrasound region of interest detection and lesion localisation	ARTIFICIAL INTELLIGENCE IN MEDICINE										Breast ultrasound; Breast cancer; Object detection; Region of interests	DEFORMABLE PART MODELS; COMPUTERIZED DETECTION; CANCER DETECTION; SEGMENTATION; CLASSIFICATION; MAMMOGRAPHY; IMAGES	In current breast ultrasound computer aided diagnosis systems, the radiologist preselects a region of interest (ROI) as an input for computerised breast ultrasound image analysis. This task is time consuming and there is inconsistency among human experts. Researchers attempting to automate the process of obtaining the ROIs have been relying on image processing and conventional machine learning methods. We propose the use of a deep learning method for breast ultrasound ROI detection and lesion localisation. We use the most accurate object detection deep learning framework - Faster-RCNN with Inception-ResNet-v2 - as our deep learning network. Due to the lack of datasets, we use transfer learning and propose a new 3-channel artificial RGB method to improve the overall performance. We evaluate and compare the performance of our proposed methods on two datasets (namely, Dataset A and Dataset B), i.e. within individual datasets and composite dataset. We report the lesion detection results with two types of analysis: (1) detected point (centre of the segmented region or the detected bounding box) and (2) Intersection over Union (IoU). Our results demonstrate that the proposed methods achieved comparable results on detected point but with notable improvement on IoU. In addition, our proposed 3-channel artificial RGB method improves the recall of Dataset A. Finally, we outline some future directions for the research.																	0933-3657	1873-2860				JUL	2020	107								101880	10.1016/j.artmed.2020.101880													
J								Integrative blockwise sparse analysis for tissue characterization and classification	ARTIFICIAL INTELLIGENCE IN MEDICINE										Sparse representation; Ensemble classifiers; Computer-aided diagnosis	CONVOLUTIONAL NEURAL-NETWORKS; FRAMEWORK; DATABASE; CANCER; PQCT	The topic of sparse representation of samples in high dimensional spaces has attracted growing interest during the past decade. In this work, we develop sparse representation-based methods for classification of clinical imaging patterns into healthy and diseased states. We propose a spatial block decomposition method to address irregularities of the approximation problem and to build an ensemble of classifiers that we expect to yield more accurate numerical solutions than conventional sparse analyses of the complete spatial domain of the images. We introduce two classification decision strategies based on maximum a posteriori probability (BBMAP), or a log likelihood function (BBLL) and an approach to adjusting the classification decision criteria. To evaluate the performance of the proposed approach we used cross-validation techniques on imaging datasets with disease class labels. We first applied the proposed approach to diagnosis of osteoporosis using bone radiographs. In this problem we assume that changes in trabecular bone connectivity can be captured by intensity patterns. The second application domain is separation of breast lesions into benign and malignant categories in mammograms. The object classes in both of these applications are not linearly separable, and the classification accuracy may depend on the lesion size in the second application. Our results indicate that the proposed integrative sparse analysis addresses the ill-posedness of the approximation problem and produces very good class separation for trabecular bone characterization and for breast lesion characterization. Our approach yields higher classification rates than conventional sparse classification and previously published convolutional neural networks (CNNs) that we fine-tuned for our datasets, or utilized for feature extraction. The BBLL technique also produced higher classification rates than learners using hand-crafted texture features, and the Bag of Keypoints, which is a sophisticated patch-based method. Furthermore, our comparative experiments showed that the BBLL function may yield more accurate classification than BBMAP, because BBLL accounts for possible estimation bias.																	0933-3657	1873-2860				JUL	2020	107								101885	10.1016/j.artmed.2020.101885													
J								Preserving User Privacy for Machine Learning: Local Differential Privacy or Federated Machine Learning?	IEEE INTELLIGENT SYSTEMS												The growing number of mobile and IoT devices has nourished many intelligent applications. In order to produce high-quality machine learning models, they constantly access and collect rich personal data such as photos, browsing history, and text messages. However, direct access to personal data has raised increasing public concerns about privacy risks and security breaches. To address these concerns, there are two emerging solutions to privacy-preserving machine learning, namely local differential privacy and federated machine learning. The former is a distributed data collection strategy where each client perturbs data locally before submitting to the server, whereas the latter is a distributed machine learning strategy to train models on mobile devices locally and merge their output (e.g., parameter updates of a model) through a control protocol. In this article, we conduct a comparative study on the efficiency and privacy of both solutions. Our results show that in a standard population and domain setting, both can achieve an optimal misclassification rate lower than 20% and federated machine learning generally performs better at the cost of higher client CPU usage. Nonetheless, local differential privacy can benefit more from a larger client population (> 1k). As for privacy guarantee, local differential privacy also has flexible control over the data leakage.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					5	14		10.1109/MIS.2020.3010335													
J								Joint Intelligence Ranking by Federated Multiplicative Update	IEEE INTELLIGENT SYSTEMS												The joint intelligence ranking of intelligent systems like autonomous driving is of great importance for building a more general, extensive, and universally accepted intelligence evaluation scheme. However, due to issues such as privacy security and industry or area competition, the integration of isolated test results may face large unimaginable difficulty in information security and encrypted model training. To address this, we derive the federated multiplicative update (FMU) algorithm with boundary constraints to solve the nonnegative matrix factorization based joint intelligence ranking. The encrypted learning process is developed to alternate original computation steps in multiplicative update algorithms. Owning feasible property for the fast convergence and secure exchange of variables, the proposed framework outperforms the previous work on both real and simulated data. Further experimental analysis reveals that the introduced federated mechanism does not harm the overall time efficiency.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					15	24		10.1109/MIS.2020.3006734													
J								Distributed Privacy-Preserving Iterative Summation Protocols	IEEE INTELLIGENT SYSTEMS												In this article, we study the problem of summation evaluation of secrets. The secrets are distributed over a network of nodes that form a ring graph. Privacy-preserving iterative protocols for computing the sum of the secrets are proposed, which are resilient against dynamic node join and leave situations. Theoretic bounds are derived regarding the utility and accuracy, and the proposed protocols are shown to comply with differential privacy requirements. Based on utility, accuracy, and privacy, we also provide guidance on appropriate selections of random noise parameters. Additionally, a few numerical examples that demonstrate their effectiveness and superiority are provided.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					25	36		10.1109/MIS.2020.3006081													
J								SMSS: Secure Member Selection Strategy in Federated Learning	IEEE INTELLIGENT SYSTEMS												Data security and user privacy-issue have become an important field. As federated learning (FL) could solve the problems from data security and privacy-issue, it starts to be applied in many different applied machine learning tasks. However, FL does not verify the quality of the data from different parties in the system. Hence, the low-quality datasets with fewer common entities can be cotrained with others. This could result in a huge amount of computing-resources waste, and the attack on the FL model from malicious clients as federal members. To solve this problem, this article proposes a secure member selection strategy (SMSS), which can evaluate the data qualities of members before training. With SMSS, only datasets share more common entities than a certain threshold can be selected for learning, whereas malicious clients with fewer common objects cannot acquire any information about the model. This article implements SMSS, and evaluate its performance via several extensive experiments. Experimental results demonstrate that SMSS is safe, efficient, and effective.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					37	49		10.1109/MIS.2020.3007207													
J								Federated Generative Privacy	IEEE INTELLIGENT SYSTEMS												We propose FedGP, a framework for privacy-preserving data release in the federated learning setting. We use generative adversarial networks, generator components of which are trained by FedAvg algorithm, to draw private artificial data samples and empirically assess the risk of information disclosure. Our experiments show that FedGP is able to generate labeled data of high quality to successfully train and validate supervised models. Finally, we demonstrate that our approach significantly reduces vulnerability of such models to model inversion attacks.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					50	57		10.1109/MIS.2020.2993966													
J								A Sustainable Incentive Scheme for Federated Learning	IEEE INTELLIGENT SYSTEMS												In federated learning (FL), a federation distributedly trains a collective machine learning model by leveraging privacy preserving technologies. However, FL participants need to incur some cost for contributing to the FL models. The training and commercialization of the models will take time. Thus, there will be delays before the federation could pay back the participants. This temporary mismatch between contributions and rewards has not been accounted for by existing payoff-sharing schemes. To address this limitation, we propose the FL incentivizer (FLI). It dynamically divides a given budget in a context-aware manner among data owners in a federation by jointly maximizing the collective utility while minimizing the inequality among the data owners, in terms of the payoff received and the waiting time for receiving payoffs. Comparisons with five state-of-the-art payoff-sharing schemes show that FLI attracts high-quality data owners and achieves the highest expected revenue for a federation.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					58	69		10.1109/MIS.2020.2987774													
J								A Secure Federated Transfer Learning Framework	IEEE INTELLIGENT SYSTEMS												Machine learning relies on the availability of vast amounts of data for training. However, in reality, data are mostly scattered across different organizations and cannot be easily integrated due to many legal and practical constraints. To address this important challenge in the field of machine learning, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical modeling under a data federation. FTL allows knowledge to be shared without compromising user privacy and enables complementary knowledge to be transferred across domains in a data federation, thereby enabling a target-domain party to build flexible and effective models by leveraging rich labels from a source domain. This framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the nonprivacy-preserving transfer learning. It is flexible and can be effectively adapted to various secure multiparty machine learning tasks.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					70	82		10.1109/MIS.2020.2988525													
J								FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare	IEEE INTELLIGENT SYSTEMS												With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					83	93		10.1109/MIS.2020.2988604													
J								Proxy Experience Replay: Federated Distillation for Distributed Reinforcement Learning	IEEE INTELLIGENT SYSTEMS												Traditional distributed deep reinforcement learning (RL) commonly relies on exchanging the experience replaymemory (RM) of each agent. Since the RM contains all state observations and action policy history, it may incur huge communication overhead while violating the privacy of each agent. Alternatively, this article presents a communication-efficient and privacy-preserving distributed RL framework, coined federated reinforcement distillation (FRD). In FRD, each agent exchanges its proxy experience RM (ProxRM), in which policies are locally averaged with respect to proxy states clustering actual states. To provide FRD design insights, we present ablation studies on the impact of ProxRM structures, neural network architectures, and communication intervals. Furthermore, we propose an improved version of FRD, coined mixup augmented FRD (MixFRD), in which ProxRM is interpolated using the mixup data augmentation algorithm. Simulations in a Cartpole environment validate the effectiveness of MixFRD in reducing the variance of mission completion time and communication cost, compared to the benchmark schemes, vanilla FRD, federated RL (FRL), and policy distillation.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					94	101		10.1109/MIS.2020.2994942													
J								Commonsense Knowledge Enhanced Memory Network for Stance Classification	IEEE INTELLIGENT SYSTEMS												Stance classification aims at identifying, in the text, the attitude toward the given targets as favorable, negative, or unrelated. In existing models for stance classification, only textual representation is leveraged, while commonsense knowledge is ignored. In order to better incorporate commonsense knowledge into stance classification, we propose a novel model named commonsense knowledge enhanced memory network, which jointly represents textual and commonsense knowledge representation of given target and text. The textual memory module in our model treats the textual representation as memory vectors, and uses attention mechanism to embody the important parts. For commonsense knowledge memory module, we jointly leverage the entity and relation embeddings learned by TransE model to take full advantage of constraints of the knowledge graph. Experimental results on the SemEval dataset show that the combination of the commonsense knowledge memory and textual memory can improve stance classification.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					102	109		10.1109/MIS.2020.2983497													
J								Computer-Centered Humans: Why Human-AI Interaction Research Will Be Critical to Successful AI Integration in the DoD	IEEE INTELLIGENT SYSTEMS												The technology development of Artificial Intelligence (AI) in the U.S. Department of Defense (DoD) is proceeding at an unprecedented pace, with record breaking levels of funding to support unprecedented breakthroughs. As these technologies progress through technology readiness levels and make their way into the hands of human beings, however, the need for human-centered design practices will become more evident. This article briefly illustrates the emerging need for more human-AI interaction research in the Department of Defense to ensure an appropriate and cohesive integration strategy of AI in warfighting and defense sectors.																	1541-1672	1941-1294				JUL-AUG	2020	35	4					112	116		10.1109/MIS.2020.3013133													
J								A New Adaptive Weighted Deep Forest and Its Modifications	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Classification; random forest; deep forest; decision tree; AdaBoost; transfer learning; metric learning		A new adaptive weighted deep forest algorithm which can be viewed as a modification of the confidence screening mechanism is proposed. The main idea underlying the algorithm is based on adaptive weigting of every training instance at each cascade level of the deep forest. The confidence screening mechanism for the deep forest proposed by Pang et al., strictly removes instances from training and testing processes to simplify the whole algorithm in accordance with the obtained random forest class probability distributions. This strict removal may lead to a very small number of training instances at the next levels of the deep forest cascade. The presented modification is more flexible and assigns weights to instances in order to differentiate their use in building decision trees at every level of the deep forest cascade. It overcomes the main disadvantage of the confidence screening mechanism. The proposed modification is similar to the AdaBoost algorithm to some extent. Numerical experiments illustrate the out-performance of the proposed modification in comparison with the original deep forest. It is also illustrated how the proposed algorithm can be extended for solving the transfer learning and distance metric learning problems.																	0219-6220	1793-6845				JUL	2020	19	4					963	986		10.1142/S0219622020500236													
J								Optimal Key Generation for Data Sanitization and Restoration of Cloud Data: Future of Financial Cyber Security	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Cyber security; financial data; cloud sector; privacy preservation; data sanitization; optimal key generation; crossover improved-lion algorithm; meta-heuristic algorithm; cloud security; data restoration	BIG DATA; PRIVACY PRESERVATION; DATA-STORAGE; ALGORITHM	Cloud security in finance is considered as the key importance, taking account of the aspect of critical data stored over cloud spaces within organizations all around the globe. They are chiefly relying on cloud computing to accelerate their business profitability and scale up their business processes with enhanced productivity coming through flexible work environments offered in cloud-run working systems. Hence, there is a prerequisite to contemplate cloud security in the entire financial service sector. Moreover, the main issue challenged by privacy and security is the presence of diverse chances to attack the sensitive data by cloud operators, which leads to double the user's anxiety on the stored data. For solving this problem, the main intent of this paper is to develop an intelligent privacy preservation approach for data stored in the cloud sector, mainly the financial data. The proposed privacy preservation model involves two main phases: (a) data sanitization and (b) data restoration. In the sanitization process, the sensitive data is hidden, which prevents sensitive information from leaking on the cloud side. Further, the normal as well as the sensitive data is stored in a cloud environment. For the sanitization process, a key should be generated that depends on the new meta-heuristic algorithm called crossover improved-lion algorithm (CI-LA), which is inspired by the lion's unique social behavior. During data restoration, the same key should be used for effectively restoring the original data. Here, the optimal key generation is done in such a way that the objective model involves the degree of modification, hiding rate, and information preservation rate, which effectively enhance the cyber security performance in the cloud.																	0219-6220	1793-6845				JUL	2020	19	4					987	1013		10.1142/S0219622020500200													
J								Hybrid Gaussian Process Inference Model for Construction Management Decision Making	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Gaussian process (GP); particle swarm optimization (PSO); construction management; hybrid Gaussian process inference model (HGPIM); machine-learning	PARTICLE SWARM; OPTIMIZATION; STRENGTH; PREDICTION; REGRESSION; NETWORKS; DESIGN	Construction decision-making often involves several indefinite factors, and wrong decisions usually lead to many losses and may even cause the construction to fail. Correct policy making is very important. Construction decision making used to depend on managerial staff' experience and subjective recognition, but this approach is likely to bring about wrong decisions because of an excessive number of factors involved or biased subjective recognition. To prevent such a situation, this study establishes a Hybrid Gaussian Process Inference Model (HGPIM), which uses a Gaussian process (GP) to sort out the mapping relationship between data input and output. It also uses Bayesian inference together with particle swarm optimization (PSO) to optimize the hyper-parameters of the covariance function in GP to obtain the best inference predictive ability. By predicting with the model and giving the events that need to be decided an expected value and a variance, we can establish the data's confidence interval as a reference for making decisions. This study collects data from three construction projects to conduct the experiment and uses HGPIM to train, predict and retest these cases to prove HGPIMs predictive ability. It also shows that the model can be applied to various cases and data and thus can be applied to construction engineering.																	0219-6220	1793-6845				JUL	2020	19	4					1015	1036		10.1142/S0219622020500212													
J								An Integration of Sentiment Analysis and MCDM Approach for Smartphone Recommendation	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Customer reviews; smartphone selection; opinion mining; recommendation; sentiment analysis; AHP; multi-criteria decision making; TOPSIS	DECISION-MAKING APPROACH; PROMETHEE METHOD; PRODUCT; ADOPTION; REVIEWS; AHP; SELECTION; SYSTEMS; DETERMINANTS; EFFICIENCY	Today, smartphones are being used to manage almost all aspects of our lives, ranging from personal to professional. Different users have different requirements and preferences while selecting a smartphone. There is 'no one-size fits all' remedy when it comes to smartphones. Additionally, the availability of a wide variety of smartphones in the market makes it difficult for the user to select the best one. The use of only product ratings to choose the best smartphone is not sufficient because the interpretation of such ratings can be quite vague and ambiguous. In this paper, reviews of products are incorporated into the decision-making process in order to select the best product for a recommendation. The top five different brands of smartphones are considered for a case study. The proposed system, then, analyses the customer reviews of these smartphones from two online platforms, Flipkart and Amazon, using sentiment analysis techniques. Next, it uses a hybrid MCDM approach, where characteristics of AHP and TOPSIS methods are combined to evaluate the best smartphones from a list of five alternatives and recommend the best product. The result shows that brand1 smartphone is considered to be the best smartphone among five smartphones based on four important decision criteria. The result of the proposed system is also validated by manually annotated customer reviews of the smartphone by experts. It shows that recommendation of the best product by the proposed system matches the experts' ranking. Thus, the proposed system can be a useful decision support tool for the best smartphone recommendation.																	0219-6220	1793-6845				JUL	2020	19	4					1037	1063		10.1142/S021962202050025X													
J								Improving Human Performance in Dynamic Tasks with Debriefing-Based Interactive Learning Environments: An Empirical Investigation	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Dynamic tasks; sustainable renewable resource management; interactive learning environments; the tragedy of the commons; task performance; decision time	SIMULATION; FEEDBACK; MISPERCEPTIONS; STRATEGY	Dynamic tasks are pervasive in organizational decision making. Improving managerial performance in dynamic tasks is an ongoing research endeavor. We report a laboratory experiment in which participants managed a dynamic task by playing the roles of fishing fleet managers. The two experimental groups used a computer simulation-based interactive learning environment (ILE) with an outcome-oriented debriefing and a process-oriented debriefing. To assess the users' learning and performance, a comprehensive five-dimensional model was used to evaluate subjects' task performance, decision time, decision strategy, structural knowledge, and heuristics knowledge. The results showed that process-oriented debriefing improved subjects' task performance, helped users gain task knowledge, develop heuristics, and adapt to systematic-variable consistent strategies. Contrary to our hypothesis, the process-oriented debriefing group did not use less decision time. In contrast to the cost-benefit approach to decision making, a relatively more systematic effort is needed to perform better in dynamic tasks such as fisheries management.																	0219-6220	1793-6845				JUL	2020	19	4					1065	1089		10.1142/S0219622020500224													
J								Fuzzy Numbers and Fractional Programming in Making Decisions	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Fuzzy numbers; fuzzy optimization; linear fractional programming	CRITERIA; OPTIMIZATION; OPTIMALITY; SET; MATRIX	This study surveys the use of fuzzy numbers in classic optimization models, and its effects on making decisions. In a wide sense, mathematical programming is a collection of tools used in mathematical optimization to make good decisions. There are many sectors of economy that employ it. Finance and government, logistics and manufacturing, the distribution of the electrical power are worth to be first mentioned. When real life problems are modeled mathematically, there is always a trade-off between model's accuracy and complexity. By this survey, we aim to present in a concise form some mathematical models from the literature together with the methods to solve them. We will focus mainly on fuzzy fractional programming problems. We will also refer to but not describe in detail the multi-criteria decision-making problems involving fuzzy numbers and linear fractional programming models.																	0219-6220	1793-6845				JUL	2020	19	4					1123	1147		10.1142/S0219622020300037													
J								An Extension-Based Classification System of Cloud Computing Patents	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING										Cloud computing; patent classification; feature selection; extension theory; classifiers; gray relational analysis	INTELLECTUAL STRUCTURE	Owing to the large number of professional glossaries and unknown patent classification, analysts usually fail to collect and analyze patents efficiently. One solution to this problem is to conduct patent analysis using a patent classification system. However, in a corpus such as cloud patents, many keywords are common among different classes, making it difficult to classify the unknown class documents using the machine learning techniques proposed by previous studies. To remedy this problem, this study aims to establish an efficient classification system with a special focus on features extraction and application of extension theory. We first propose a compound method to determine the features, and then, we propose an extension-based classification method to develop an efficient patent classification system. Using cloud computing patents as the database, the experimental results show that our proposed scheme can outperform the classification quality of the traditional classifiers.																	0219-6220	1793-6845				JUL	2020	19	4					1149	1172		10.1142/S0219622020500248													
J								Feature Selection Based Transfer Subspace Learning for Speech Emotion Recognition	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Feature selection; transfer learning; subspace learning; speech emotion recognition	FRAMEWORK	Cross-corpus speech emotion recognition has recently received considerable attention due to the widespread existence of various emotional speech. It takes one corpus as the training data aiming to recognize emotions of another corpus, and generally involves two basic problems, i.e., feature matching and feature selection. Many previous works study these two problems independently, or just focus on solving the first problem. In this paper, we propose a novel algorithm, called feature selection based transfer subspace learning (FSTSL), to address these two problems. To deal with the first problem, a latent common subspace is learnt by reducing the difference of different corpora and preserving the important properties. Meanwhile, we adopt the l(2,1)-norm on the projection matrix to deal with the second problem. Besides, to guarantee the subspace to be robust and discriminative, the geometric information of data is exploited simultaneously in the proposed FSTSL framework. Empirical experiments on cross-corpus speech emotion recognition tasks demonstrate that our proposed method can achieve encouraging results in comparison with state-of-the-art algorithms.																	1949-3045					JUL-SEP	2020	11	3					373	382		10.1109/TAFFC.2018.2800046													
J								A Case-Based Reasoning Model for Depression Based on Three-Electrode EEG Data	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Electroencephalography; Brain modeling; Feature extraction; Cognition; Medical services; Physiology; Electrodes; Affective computing; affect sensing and analysis; health care; health implications	INTEGRATION; PREDICTION; DISORDERS; ASYMMETRY	Depression, threatening the well-being of millions, has become one of the major diseases in the past decade. However, the current method of diagnosing depression is questionnaire-based interviews, which is labor-intensive and highly dependent on doctors' experience. Thus, objective and cost-efficient methods are needed. In this paper, we present a case-based reasoning model for identifying depression. Electroencephalography data were collected using a portable three-electrode EEG device, and then processed to remove artifacts and extract features. We applied multiple classifiers. The best performing k-Nearest Neighbor (KNN) was selected as the evaluation function to select the effective features which were then used to create the case base. Based on the weight set of standard deviations, the similarity was calculated using normalized Euclidean distance to get the optimal recognition rate of depression. The accuracy of optimal similarity identification of patients with depression was 91.25 percent, which was improved compared to the accuracy using KNN classifier (81.44 percent) or previously reported classifiers. Thus, we provide a novel pervasive and effective method for automatic detection of depression.																	1949-3045					JUL-SEP	2020	11	3					383	392		10.1109/TAFFC.2018.2801289													
J								Detecting Unipolar and Bipolar Depressive Disorders from Elicited Speech Responses Using Latent Affective Structure Model	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Mood; Databases; Speech; Videos; Emotion recognition; Mental disorders; Feature extraction; Mood disorder; speech emotion recognition; latent affective structure model	EMOTION RECOGNITION; RATING-SCALE	Mood disorders, including unipolar depression (UD) and bipolar disorder (BD) [1] , are reported to be one of the most common mental illnesses in recent years. In diagnostic evaluation on the outpatients with mood disorder, a large portion of BD patients are initially misdiagnosed as having UD [2] . As most previous research focused on long-term monitoring of mood disorders, short-term detection which could be used in early detection and intervention is thus desirable. This work proposes an approach to short-term detection of mood disorder based on the patterns in emotion of elicited speech responses. To the best of our knowledge, there is no database for short-term detection on the discrimination between BD and UD currently. This work collected two databases containing an emotional database (MHMC-EM) collected by the Multimedia Human Machine Communication (MHMC) lab and a mood disorder database (CHI-MEI) collected by the CHI-MEI Medical Center, Taiwan. As the collected CHI-MEI mood disorder database is quite small and emotion annotation is difficult, the MHMC-EM emotional database is selected as a reference database for data adaptation. For the CHI-MEI mood disorder data collection, six eliciting emotional videos are selected and used to elicit the participants' emotions. After watching each of the six eliciting emotional video clips, the participants answer the questions raised by the clinician. The speech responses are then used to construct the CHI-MEI mood disorder database. Hierarchical spectral clustering is used to adapt the collected MHMC-EM emotional database to fit the CHI-MEI mood disorder database for dealing with the data bias problem. The adapted MHMC-EM emotional data are then fed to a denoising autoencoder for bottleneck feature extraction. The bottleneck features are used to construct a long short term memory (LSTM)-based emotion detector for generation of emotion profiles from each speech response. The emotion profiles are then clustered into emotion codewords using the K-means algorithm. Finally, a class-specific latent affective structure model (LASM) is proposed to model the structural relationships among the emotion codewords with respect to six emotional videos for mood disorder detection. Leave-one-group-out cross validation scheme was employed for the evaluation of the proposed class-specific LASM-based approaches. Experimental results show that the proposed class-specific LASM-based method achieved an accuracy of 73.33 percent for mood disorder detection, outperforming the classifiers based on SVM and LSTM.																	1949-3045					JUL-SEP	2020	11	3					393	404		10.1109/TAFFC.2018.2803178													
J								Low-Level Characterization of Expressive Head Motion Through Frequency Domain Analysis	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Magnetic heads; Dynamics; Discrete Fourier transforms; Speech; Legged locomotion; Frequency-domain analysis; Emotion recognition; Human behavior; head motion; expression; emotion; conversation; frequency-domain; discrete fourier transform	BODY MOVEMENT; PERCEPTION	For the purpose of understanding how head motions contribute to the perception of emotion in an utterance, we aim to examine the perception of emotion based on Fourier transform-based static and dynamic features of head motion. Our work is to conduct intra-related objective analysis and perceptual experiments on the link between the perception of emotion and the static/dynamic features. The objective analysis outcome shows that the static and dynamic features are effective in characterizing and recognizing emotions. The perceptual experiments enable us to collect human perception of emotion through head motion. The collected perceptual data shows that humans are unable to reliably perceive emotion from head motion alone but reveals that humans are sensitive to the static feature (in reference to the averaged up-down rotation angle) and the dynamic features (which reflect the fluidity and speed of movement). It also indicates that humans perceive emotion carried in head motion and the naturalness of head motion in two different channels. Our work contributes to the understanding and the characterization of head motion in expressive speech through low-level descriptions of motion features, instead of commonly used high-level motion style (e.g., head nods, shakes, tilts, and raises).																	1949-3045					JUL-SEP	2020	11	3					405	418		10.1109/TAFFC.2018.2805892													
J								Unsupervised Adaptation of a Person-Specific Manifold of Facial Expressions	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Manifolds; Adaptation models; Face; Face recognition; Computational modeling; Feature extraction; Databases; Facial expression; person-specific model; unsupervised model	RECOGNITION; MACHINE; FACE	In order to analyze expressions that are different from the prototypic expressions defined by Ekman, manifold learning has been proposed to build person-specific continuous representations of facial expressions. Yet, it is still a challenging problem to build such a manifold with no prior knowledge on the morphology of the subject. Here, we propose a method to build a person-specific manifold of facial expressions able to adapt to the morphology of the subject in an unsupervised manner. The manifold is initialized with the facial landmarks of the neutral face and 5 synthesized basic expressions. Our first contribution is to detect automatically the neutral face of the subject so that we can build the manifold in an unsupervised manner. Our second and main contribution is to adapt in an unsupervised manner the initialized manifold to the morphology of the subject by detecting the real basic expressions of the subject while maintaining constraints in the manifold. Our third contribution is to perform the adaptation on spontaneous expressions with typical head pose variation for human-computer interaction. The experiments show that the adaptation works well on posed expressions and that the constraints for the adaptation on spontaneous expressions is efficient when head pose variation is considered.																	1949-3045					JUL-SEP	2020	11	3					419	432		10.1109/TAFFC.2018.2807430													
J								Emotion Recognition on Twitter: Comparative Study and Training a Unison Model	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Twitter; Tagging; Mood; Machine learning; Training; Emotion recognition; Convolutional neural networks; Emotion recognition; text mining; twitter; recurrent neural networks; convolutional neural networks		Despite recent successes of deep learning in many fields of natural language processing, previous studies of emotion recognition on Twitter mainly focused on the use of lexicons and simple classifiers on bag-of-words models. The central question of our study is whether we can improve their performance using deep learning. To this end, we exploit hashtags to create three large emotion-labeled data sets corresponding to different classifications of emotions. We then compare the performance of several word- and character-based recurrent and convolutional neural networks with the performance on bag-of-words and latent semantic indexing models. We also investigate the transferability of the final hidden state representations between different classifications of emotions, and whether it is possible to build a unison model for predicting all of them using a shared representation. We show that recurrent neural networks, especially character-based ones, can improve over bag-of-words and latent semantic indexing models. Although the transfer capabilities of these models are poor, the newly proposed training heuristic produces a unison model with performance comparable to that of the three single models.																	1949-3045					JUL-SEP	2020	11	3					433	446		10.1109/TAFFC.2018.2807817													
J								Pipelined Neural Networks for Phrase-Level Sentiment Intensity Prediction	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Artificial neural networks; Predictive models; Switches; Learning systems; Linear regression; Prediction algorithms; Sentiment analysis; sentiment intensity; modifier weight learning; neural network	VALENCE; CLASSIFICATION; AROUSAL; WORDS	Linguistic modifiers such as negators (e.g., not), intensifiers (e.g., very) and modals (e.g., would) are commonly used in expressing opinions. These modifiers play an important role in recognizing the sentiment intensity of multi-word phrases because they may lead to an intensity shift and polarity reversal for the words they modify. Appropriately modeling the effect of such modifiers on the intensity shift can greatly improve the performance of phrase-level sentiment intensity prediction. To this end, this paper proposes two neural network (NN) models organized in a pipelined fashion to determine 1) the intensity of individual words and 2) the shift weights of modifiers representing the degrees of intensity change for the words they modify. The intensity of a phrase can then be determined by combining the intensity of the constituent word and the shift weight of the modifier within the phrase. When measuring the word intensity, the first NN model introduces a hidden layer as a filter to select appropriate similar seed words in the prediction process. Automatic word intensity prediction can address the unknown intensities of words not covered in sentiment lexicons. In learning the modifier weights, the second NN model considers both the weights of individual modifiers and groups of modifiers to capture various intensity shift effects caused by them. Experiments on a SemEval-2016 dataset showed that the proposed method yielded better prediction performance for both single words and multi-word phrases.																	1949-3045					JUL-SEP	2020	11	3					447	458		10.1109/TAFFC.2018.2807819													
J								Classifying Affective Haptic Stimuli through Gender-Specific Heart Rate Variability Nonlinear Analysis	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Heart rate variability; Haptic interfaces; Force; Feature extraction; Nonlinear dynamical systems; Protocols; Physiology; Sense of touch; caress; haptic; affective haptics; heart rate variability; nonlinear analysis; lagged poincare plot; symbolic analysis	UNMYELINATED AFFERENTS; SEX-DIFFERENCES; TOUCH MASSAGE; HAIRY SKIN; HEALTHY; AROUSAL; DYNAMICS; INDEXES; CORTEX; PAIN	This study reports on how velocity and force levels of caress-like haptic stimuli can elicit different emotional responses, which can be identified through the analysis of Autonomic Nervous System (ANS) dynamics. Affective stimuli were administered on the forearm of 32 healthy volunteers (16 women) through a haptic device with two levels of force, 2 N and 6 N, and two levels of velocity, 9.4 mm/s and 37 mm/s. ANS dynamics was estimated through Heart Rate Variability (HRV) linear and nonlinear analysis on recordings gathered before and after each stimulus. To this extent, we here propose and assess novel features from HRV symbolic analysis and Lagged Poincare Plot. Classification was performed following a leave-one-subject-out procedure on nonlinear support vector machines. Pattern classification was split according to gender, significantly improving accuracies of recognition with respect to a "all-subjects" classification. Caressing force and velocity levels were recognized with up to 80 percent accuracy for men, and up to 84.38 percent for women. Our results demonstrate that changes in ANS control on cardiovascular dynamics, following emotional changes induced by caress-like haptic stimuli, can be effectively recognized by the proposed computational approach, considering that they occur in a gender-specific and nonlinear manner.																	1949-3045					JUL-SEP	2020	11	3					459	469		10.1109/TAFFC.2018.2808261													
J								Unobtrusive Inference of Affective States in Virtual Rehabilitation from Upper Limb Motions: A Feasibility Study	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Pain; Medical treatment; Games; Bayes methods; Support vector machines; Computer science; Fatigue; Affective issues in user interaction; posture; hand movements; fingers pressure; rehabilitation; stroke; semi-Naive Bayesian classifier	MOTOR REHABILITATION; EMOTION; RECOGNITION; REALITY; FUSION; BAYES; VIDEO	Virtual rehabilitation environments may afford greater patient personalization if they could harness the patient's affective state. Four states: anxiety, pain, engagement and tiredness (either physical or psychological), were hypothesized to be inferable from observable metrics of hand location and gripping strength-relevant for rehabilitation. Contributions are; (a) multiresolution classifier built from Semi-Naive Bayesian classifiers, and (b) establishing predictive relations for the considered states from the motor proxies capitalizing on the proposed classifier with recognition levels sufficient for exploitation. 3D hand locations and gripping strength streams were recorded from 5 post-stroke patients whilst undergoing motor rehabilitation therapy administered through virtual rehabilitation along 10 sessions over 4 weeks. Features from the streams characterized the motor dynamics, while spontaneous manifestations of the states were labelled from concomitant videos by experts for supervised classification. The new classifier was compared against baseline support vector machine (SVM) and random forest (RF) with all three exhibiting comparable performances. Inference of the aforementioned states departing from chosen motor surrogates appears feasible, expediting increased personalization of virtual motor neurorehabilitation therapies.																	1949-3045					JUL-SEP	2020	11	3					470	481		10.1109/TAFFC.2018.2808295													
J								Predicting Personality from Book Preferences with User-Generated Content Labels	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Facebook; Psychology; Data collection; User-generated content; Robustness; Personality profiling; narrative preferences; social media; behavioral footprints	TRAITS; JUDGMENTS; GEOGRAPHY; PROFILES; PATTERNS; RELIGION; BIG-5; ART	Psychological studies have shown that personality traits are associated with book preferences. However, past findings based on questionnaires are limited to conventional book genres and do not capture niche content (e.g., family drama) and reading behaviors (e.g., backburners). For a more comprehensive measure of book content, this study harnesses a massive archive of content labels, also known as 'tags', created by users of a book review website, Goodreads.com. Combined with data on preferences and personality scores collected from Facebook users, the tag labels achieve high accuracy in personality prediction by psychological standards. Additionally, we group tags into broader genres to check their validity against past findings. Our results are robust across both tag-level and genre-level analyses and are consistent with existing literature. Moreover, user-generated tag labels reveal unexpected insights, such as cultural differences, book reading behaviors, and other non-content factors affecting preferences. To our knowledge, this is currently the largest study that explores the relationship between personality and book content preferences.																	1949-3045					JUL-SEP	2020	11	3					482	492		10.1109/TAFFC.2018.2808349													
J								Objectivity and Subjectivity in Aesthetic Quality Assessment of Digital Photographs	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Quality assessment; Photography; Databases; Visualization; Semantics; Computational modeling; Image processing; Photograph; subjectivity; aesthetic quality assessment; user comment analysis	PHOTO; IMAGE; PERCEPTION	Automatic prediction of the aesthetic quality of a photograph has been an important research problem in image processing and computer vision. While assessing the aesthetic quality of a photograph by human is highly subjective, most existing studies have considered only objective (or general) opinion of multiple viewers. In this paper, we provide a comprehensive investigation of the issue of subjectivity in aesthetic quality assessment using a large-scale database containing photos, user ratings, and user comments. First, we analyze how the mean aesthetic quality level and the level of subjectivity have evolved over time. Second, we examine the feasibility of automatic prediction of the level of subjectivity based on visual features, and identify which features are effective for the prediction. Third, we analyze the users' comments given to photos to understand the sources of subjectivity of aesthetic quality rating. Our results show that several factors are simultaneously involved in determining the level of subjectivity of a photo, but it can be predicted with reasonable accuracy. We believe that our results provide insight toward personalized aesthetic photo applications.																	1949-3045					JUL-SEP	2020	11	3					493	506		10.1109/TAFFC.2018.2809752													
J								Realistic Transformation of Facial and Vocal Smiles in Real-Time Audiovisual Streams	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Face; Real-time systems; Visualization; Mouth; Strain; Avatars; Lips; Smiling; facial expressions; vocal emotions; audiovisual; real-time; video and audio signal processing	PERCEPTION; EMOTION; DUCHENNE; SIZE	Research in affective computing and cognitive science has shown the importance of emotional facial and vocal expressions during human-computer and human-human interactions. But, while models exist to control the display and interactive dynamics of emotional expressions, such as smiles, in embodied agents, these techniques can not be applied to video interactions between humans. In this work, we propose an audiovisual smile transformation algorithm able to manipulate an incoming video stream in real-time to parametrically control the amount of smile seen on the user's face and heard in their voice, while preserving other characteristics such as the user's identity or the timing and content of the interaction. The transformation is composed of separate audio and visual pipelines, both based on a warping technique informed by real-time detection of audio and visual landmarks. Taken together, these two parts constitute a unique audiovisual algorithm which, in addition to providing simultaneous real-time transformations of a real person's face and voice, allows to investigate the integration of both modalities of smiles in real-world social interactions.																	1949-3045					JUL-SEP	2020	11	3					507	518		10.1109/TAFFC.2018.2811465													
J								Gaming Away Stress: Using Biofeedback Games to Learn Paced Breathing	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Games; Stress; Biological control systems; Task analysis; Training; Medical treatment; Physiology; Biofeedback; relaxation games; stress management; wearable sensors; paced breathing		Biofeedback games are an attractive alternative to standard techniques for learning short-term relaxation skills. In this paper, we present the design, implementation, and evaluation of three respiratory biofeedback games. To validate these games, we compared breathing rate across 100 male participants (23 years +/- 3.2 years) playing biofeedback and audio pacing versions of these games as well as a paced breathing app. The games were placed between repeat runs of a cognitively stressful Stroop-based task and the impact of the games on breathing and cognitive performance in the task also assessed. Our results showed that 1) differences in gameplay did not impact player performance; 2) biofeedback not only led to better breath control during play but also during the subsequent cognitively stressful task; and 3) biofeedback led to better attentional-cognitive performance in the subsequent task. Our multi-game experiments show that using respiratory biofeedback in video games is an effective strategy to learn paced breathing-on par with the standalone technique of paced breathing-and to self-regulate stress levels in later stressful scenarios. Furthermore, owing to its entertainment value, our relaxation solution has the potential to be more engaging and accessible than standalone paced breathing, for use over longer durations.																	1949-3045					JUL-SEP	2020	11	3					519	531		10.1109/TAFFC.2018.2816945													
J								EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Electroencephalography; Emotion recognition; Brain modeling; Feature extraction; Convolutional neural networks; Convolution; Biological neural networks; EEG emotion recognition; adjacency matrix; graph convolutional neural networks (GCNN); dynamical convolutional neural networks (DGCNN)	EXPRESSION	In this paper, a multichannel EEG emotion recognition method based on a novel dynamical graph convolutional neural networks (DGCNN) is proposed. The basic idea of the proposed EEG emotion recognition method is to use a graph to model the multichannel EEG features and then perform EEG emotion classification based on this model. Different from the traditional graph convolutional neural networks (GCNN) methods, the proposed DGCNN method can dynamically learn the intrinsic relationship between different electroencephalogram (EEG) channels, represented by an adjacency matrix, via training a neural network so as to benefit for more discriminative EEG feature extraction. Then, the learned adjacency matrix is used to learn more discriminative features for improving the EEG emotion recognition. We conduct extensive experiments on the SJTU emotion EEG dataset (SEED) and DREAMER dataset. The experimental results demonstrate that the proposed method achieves better recognition performance than the state-of-the-art methods, in which the average recognition accuracy of 90.4 percent is achieved for subject dependent experiment while 79.95 percent for subject independent cross-validation one on the SEED database, and the average accuracies of 86.23, 84.54 and 85.02 percent are respectively obtained for valence, arousal and dominance classifications on the DREAMER database.																	1949-3045					JUL-SEP	2020	11	3					532	541		10.1109/TAFFC.2018.2817622													
J								Visually Interpretable Representation Learning for Depression Recognition from Facial Images	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Visualization; Feature extraction; Videos; Face recognition; Face; Computer architecture; Image recognition; Depression recognition; face recognition; deep convolutional neural network; depression activation map	DISEASE	Recent evidence in mental health assessment have demonstrated that facial appearance could be highly indicative of depressive disorder. While previous methods based on the facial analysis promise to advance clinical diagnosis of depressive disorder in a more efficient and objective manner, challenges in visual representation of complex depression pattern prevent widespread practice of automated depression diagnosis. In this paper, we present a deep regression network termed DepressNet to learn a depression representation with visual explanation. Specifically, a deep convolutional neural network equipped with a global average pooling layer is first trained with facial depression data, which allows for identifying salient regions of input image in terms of its severity score based on the generated depression activation map (DAM). We then propose a multi-region DepressNet, with which multiple local deep regression models for different face regions are jointly leaned and their responses are fused to improve the overall recognition performance. We evaluate our method on two benchmark datasets, and the results show that our method significantly boosts state-of-the-art performance of the visual-based depression recognition. Most importantly, the DAM induced by our learned deep model may help reveal the visual depression pattern on faces and understand the insights of automated depression diagnosis.																	1949-3045					JUL-SEP	2020	11	3					542	552		10.1109/TAFFC.2018.2828819													
J								Defining Laughter Context for Laughter Synthesis with Spontaneous Speech Corpus	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Speech; Hidden Markov models; Databases; Speech synthesis; Acoustics; Context modeling; Man-machine systems; Laughter; spontaneous speech corpus; HMM-based speech synthesis		In this paper, conversational laughter was synthesized by a statistical model-based speech synthesis framework using spontaneous speech corpora. The phonetic transcriptions of natural laughter in these corpora were annotated, and the context required to synthesize the laughter that accompanies speech sounds was defined from the perspective of the (1) phonetic properties of the current segment, (2) phonetic properties of previous and succeeding segments, and (3) positional factors of the current segment or laughter bout. Laughter was synthesized using the defined context and the framework of HMM-based speech synthesis. To confirm the influence of the contextual factors on the naturalness of speech, a subjective evaluation was performed. As the result of the evaluation, the naturalness of the entire utterance was improved by using the contextual factors defined in this study. This result confirmed the importance of defining the appropriate context to synthesize natural conversational laughter.																	1949-3045					JUL-SEP	2020	11	3					553	559		10.1109/TAFFC.2018.2813381													
J								Approximate Triangulations of Grassmann Manifolds	ALGORITHMS										Grassmannian; persistent homology; Vietoris-Rips complex; witness complex; triangulation	EMBEDDINGS	We define the notion of an approximate triangulation for a manifold M embedded in Euclidean space. The basic idea is to build a nested family of simplicial complexes whose vertices lie in M and use persistent homology to find a complex in the family whose homology agrees with that of M. Our key examples are various Grassmann manifolds G(k) (R-n).																		1999-4893				JUL	2020	13	7							172	10.3390/a13070172													
J								A perspective on modeling evolution	JOURNAL OF CHEMOMETRICS										hard-modeling; hybrid hard- and soft-modeling; soft-modeling	MULTIVARIATE CURVE RESOLUTION; ALTERNATING LEAST-SQUARES; SITU SPECTROSCOPIC MEASUREMENTS; TRANSFORMATION FACTOR-ANALYSIS; AREA CORRELATION CONSTRAINT; FEASIBLE SOLUTIONS; EQUILIBRIUM-CONSTANTS; LIQUID-CHROMATOGRAPHY; ROTATIONAL AMBIGUITY; HYBRID HARD	Data modeling is a wide concept that exists since long and encompasses all possible ways to interpret the information associated with a process, analytical measurement or set of related parameters that presents a systematic variation. Data modeling can follow the path of knowledge and be based on first principles or can focus on measurements and empirical models. These different approaches are known as hard- and soft-modeling, respectively. It seemed to us very appropriate to dedicate this article to Paul Gemperline, a person who has significantly contributed to the worlds of hard- and soft-modeling, presumably acknowledging the value of looking at data from all possible perspectives. The following pages do not intend to be an extensive review, but a personal perspective on values, milestones and progress of hard- and soft-modeling and on the necessary existence and valuable combination of both ways to interpret chemical information.																	0886-9383	1099-128X				JUL	2020	34	7			SI				e3205	10.1002/cem.3205													
J								Simulation of1/f(alpha)noise for analytical measurements	JOURNAL OF CHEMOMETRICS										error covariance matrix; error simulation; measurement errors; noise simulation; pink noise	MEASUREMENT PRECISION; DEDUCTIVE PREDICTION; 1/F NOISE; CALIBRATION; FIGURES; SIGNAL; LIMITS; MERIT	A simple procedure is described that can be used to generate 1/f(alpha)noise, also known as power law noise, in simulated analytical measurement vectors. Certain types of power law noise, such as pink noise (alpha=1), dominate many types of analytical signals, so its simulation is important in optimizing data processing strategies. In this work, simulated 1/f(alpha)error sequences are created directly from white noise via the theoretical measurement error covariance matrix (ECM) by rotation and scaling. The 1/f(alpha)ECM is obtained from the coefficients of a finite impulse response filter and is easily adapted to generate multiplicative 1/f(alpha)noise that is probably more common for analytical systems exhibiting proportional noise characteristics. Simulating 1/f(alpha)noise directly from the ECM offers two main advantages. First, 1/f(alpha)noise can be easily simulated in the presence of other common analytical measurement errors by additive combination of the ECMs. Second, the theoretical ECM can be used to model real experimental measurement noise. It is shown that the power spectral density function of measurement error sequences generated by the proposed method closely approximates the theoretical behaviour of 1/f(alpha)noise. To demonstrate the utility of this method in evaluating data processing methods, simulated data exhibiting 1/f(pink) noise is analyzed by maximum likelihood principal component analysis (MLPCA) that takes measurement error structure into account, and baseline noise is simulated using brown noise to test baseline fitting by asymmetric least squares (AsLS).																	0886-9383	1099-128X				JUL	2020	34	7			SI				e3137	10.1002/cem.3137													
J								Localized and adaptive soft sensor based on an extreme learning machine with automated self-correction strategies	JOURNAL OF CHEMOMETRICS										extreme learning machine; intelligent systems; online prediction; recursive partial least squares; soft sensor	PARTIAL LEAST-SQUARES; MIXTURE; MODEL; PREDICTION; ALGORITHM	A novel, nonlinear soft sensor based on a localized, adaptive single-layer feedforward neural network with random hidden layer weights, also called an extreme learning machine, combined with the recursive partial least squares algorithm to update the linear output layer weights, is explored. The soft sensor is highly adaptive with minimal operator input, and automated mechanisms are included to self-correct numerous aspects of the underlying model. For instance, mechanisms are put in place to automatically select an optimized local model region describing the current process dynamics from the historical data when the current prediction error reaches an adaptively computed threshold. Additionally, the new soft sensor simultaneously employs an ensemble of models with diverse recursive partial least squares forgetting factors with automated and adaptive reweighting of the models in the ensemble, thus enabling real-time model memory adjustment. The validity of the method is shown by comparison with numerous other soft sensor methods for the prediction of the activity of a polymerization catalyst.																	0886-9383	1099-128X				JUL	2020	34	7			SI				e3088	10.1002/cem.3088													
J								An Algorithm for Density Enrichment of Sparse Collaborative Filtering Datasets Using Robust Predictions as Derived Ratings	ALGORITHMS										recommender systems; collaborative filtering; sparse datasets; density enrichment; robust predictions; derived ratings; rating prediction coverage; rating prediction accuracy	MATRIX FACTORIZATION; INFORMATION; ACCURACY; QUALITY; SHIFTS; MODEL	Collaborative filtering algorithms formulate personalized recommendations for a user, first by analysing already entered ratings to identify other users with similar tastes to the user (termed as near neighbours), and then using the opinions of the near neighbours to predict which items the target user would like. However, in sparse datasets, too few near neighbours can be identified, resulting in low accuracy predictions and even a total inability to formulate personalized predictions. This paper addresses the sparsity problem by presenting an algorithm that uses robust predictions, that is predictions deemed as highly probable to be accurate, as derived ratings. Thus, the density of sparse datasets increases, and improved rating prediction coverage and accuracy are achieved. The proposed algorithm, termed as CFDR, is extensively evaluated using (1) seven widely-used collaborative filtering datasets, (2) the two most widely-used correlation metrics in collaborative filtering research, namely the Pearson correlation coefficient and the cosine similarity, and (3) the two most widely-used error metrics in collaborative filtering, namely the mean absolute error and the root mean square error. The evaluation results show that, by successfully increasing the density of the datasets, the capacity of collaborative filtering systems to formulate personalized and accurate recommendations is considerably improved.																		1999-4893				JUL	2020	13	7							174	10.3390/a13070174													
J								Nonparametric Estimation of Continuously Parametrized Families of Probability Density Functions-Computational Aspects	ALGORITHMS										nonparametric estimation; FFT; family of probability density functions	REGRESSION FUNCTION; FOURIER-SERIES; CONVERGENCE; IDENTIFICATION	We consider a rather general problem of nonparametric estimation of an uncountable set of probability density functions (p.d.f.'s) of the form:f(x;r), whereris a non-random real variable and ranges from R-1 to R-2. We put emphasis on the algorithmic aspects of this problem, since they are crucial for exploratory analysis of big data that are needed for the estimation. A specialized learning algorithm, based on the 2D FFT, is proposed and tested on observations that allow for estimate p.d.f.'s of a jet engine temperatures as a function of its rotation speed. We also derive theoretical results concerning the convergence of the estimation procedure that contains hints on selecting parameters of the estimation algorithm.																		1999-4893				JUL	2020	13	7							164	10.3390/a13070164													
J								Image Edge Detector with Gabor Type Filters Using a Spiking Neural Network of Biologically Inspired Neurons	ALGORITHMS										edge detection; spiking neural networks; bio-inspired image processing; computational photography; machine learning and classification	MODEL	We report the design of a Spiking Neural Network (SNN) edge detector with biologically inspired neurons that has a conceptual similarity with both Hodgkin-Huxley (HH) model neurons and Leaky Integrate-and-Fire (LIF) neurons. The computation of the membrane potential, which is used to determine the occurrence or absence of spike events, at each time step, is carried out by using the analytical solution to a simplified version of the HH neuron model. We find that the SNN based edge detector detects more edge pixels in images than those obtained by a Sobel edge detector. We designed a pipeline for image classification with a low-exposure frame simulation layer, SNN edge detection layers as pre-processing layers and a Convolutional Neural Network (CNN) as a classification module. We tested this pipeline for the task of classification with the Digits dataset, which is available in MATLAB. We find that the SNN based edge detection layer increases the image classification accuracy at lower exposure times, that is, for 1<t<T/4, wheretis the number of milliseconds in a simulated exposure frame andTis the total exposure time, with reference to a Sobel edge or Canny edge detection layer in the pipeline. These results pave the way for developing novel cognitive neuromorphic computing architectures for millisecond timescale detection and object classification applications using event or spike cameras.																		1999-4893				JUL	2020	13	7							165	10.3390/a13070165													
J								TBRNet: Two-Stream BiLSTM Residual Network for Video Action Recognition	ALGORITHMS										action recognition; bidirectional long short-term memory; residual connection; temporal attention mechanism; two-stream networks		Modeling spatiotemporal representations is one of the most essential yet challenging issues in video action recognition. Existing methods lack the capacity to accurately model either the correlations between spatial and temporal features or the global temporal dependencies. Inspired by the two-stream network for video action recognition, we propose an encoder-decoder framework named Two-Stream Bidirectional Long Short-Term Memory (LSTM) Residual Network (TBRNet) which takes advantage of the interaction between spatiotemporal representations and global temporal dependencies. In the encoding phase, the two-stream architecture, based on the proposed Residual Convolutional 3D (Res-C3D) network, extracts features with residual connections inserted between the two pathways, and then the features are fused to become the short-term spatiotemporal features of the encoder. In the decoding phase, those short-term spatiotemporal features are first fed into a temporal attention-based bidirectional LSTM (BiLSTM) network to obtain long-term bidirectional attention-pooling dependencies. Subsequently, those temporal dependencies are integrated with short-term spatiotemporal features to obtain global spatiotemporal relationships. On two benchmark datasets, UCF101 and HMDB51, we verified the effectiveness of our proposed TBRNet by a series of experiments, and it achieved competitive or even better results compared with existing state-of-the-art approaches.																		1999-4893				JUL	2020	13	7							169	10.3390/a13070169													
J								Generalized Polynomial Chaos Expansion for Fast and Accurate Uncertainty Quantification in Geomechanical Modelling	ALGORITHMS										geomechanical modelling; polynomial chaos expansion; bayesian update	GLOBAL SENSITIVITY-ANALYSIS; DATA ASSIMILATION; BAYESIAN-INFERENCE; RESERVOIR; COMPRESSIBILITY; PARAMETERS	Geomechanical modelling of the processes associated to the exploitation of subsurface resources, such as land subsidence or triggered/induced seismicity, is a common practice of major interest. The prediction reliability depends on different sources of uncertainty, such as the parameterization of the constitutive model characterizing the deep rock behaviour. In this study, we focus on a Sobol'-based sensitivity analysis and uncertainty reduction via assimilation of land deformations. A synthetic test case application on a deep hydrocarbon reservoir is considered, where land settlements are predicted with the aid of a 3-D Finite Element (FE) model. Data assimilation is performed via the Ensemble Smoother (ES) technique and its variation in the form of Multiple Data Assimilation (ES-MDA). However, the ES convergence is guaranteed with a large number of Monte Carlo (MC) simulations, that may be computationally infeasible in large scale and complex systems. For this reason, a surrogate model based on the generalized Polynomial Chaos Expansion (gPCE) is proposed as an approximation of the forward problem. This approach allows to efficiently compute the Sobol' indices for the sensitivity analysis and greatly reduce the computational cost of the original ES and MDA formulations, also enhancing the accuracy of the overall prediction process.																		1999-4893				JUL	2020	13	7							156	10.3390/a13070156													
J								Computational model for generating interactions in conversational recommender system based on product functional requirements	DATA & KNOWLEDGE ENGINEERING										Recommender systems; Conversational recommender system; Knowledge-based recommendation; User modeling; Ontology-based knowledge; User interaction	DOMAIN ONTOLOGY; KNOWLEDGE; QUALITY	Conversational recommender system is a tool to help customer in deciding products they are going to buy, by conversational mechanism. By this mechanism, the system is able to imitate natural conversation between customer and professional sales support, for eliciting customer preference. However, many customers are not familiar with the technical features of multifunction and multi-feature products. A more natural way to explore customer preferences is by asking what they want to use with the product they are looking for (product functional requirements). Therefore, this paper proposes a computational model incorporating product functional requirements for interaction. The proposed model covers ontology and its structure as well as algorithms for generating interaction that comprises asking question, recommending products and presenting explanation of why a product is recommended. Based on our user studies, both expert users (familiar with product technical features) and novice users (not familiar with product technical feature) prefer our proposed interaction model than that of the flat interaction model (interaction model based on technical features). Meanwhile, functional requirements-based explanation is able to improve user trust in recommended products by 30% for novice users and 17% for expert users.																	0169-023X	1872-6933				JUL	2020	128								101813	10.1016/j.datak.2020.101813													
J								A linear programming-based framework for handling missing data in multi-granular data warehouses	DATA & KNOWLEDGE ENGINEERING											CONCEPTUAL-MODEL; DISAGGREGATION; EXPLORATION; DESIGN	Data Warehouse (DW) and OLAP systems are first citizens of Business Intelligence tools. They are widely used in the academic and industrial communities for numerous different fields of application. Despite the maturity of DW and OLAP systems, with the advent of Big Data, more and more sources of data are available, and warehousing this data can lead to important quality issues. In this work, we focus on missing numerical and categorical in presence of aggregated facts. Motivated by the lack of a formal approach for the imputation of this kind of data taking into account all type of aggregation functions (distributive, algebraic and holistic), we propose an new methodology based on linear programming. Our methodology allows dealing with the relaxed constraints over classical SQL aggregation functions. The proposed approach is tested on two well-known datasets. Experiments show the effectiveness of the proposed approach.																	0169-023X	1872-6933				JUL	2020	128								101832	10.1016/j.datak.2020.101832													
J								Search-by-example over SQL repositories using structural and intent-driven similarity	DATA & KNOWLEDGE ENGINEERING										SQL; Structural search; Intention-driven search; Semantic search; Syntactic search; Query similarity; Tree edit distance; SQL vector model	JOIN QUERIES; DISTANCE; REUSE	Searching the query log of a database system has a variety of applications. In a complex database, relevant queries in the log can serve as an initial example for query formulation, or may elucidate how to query the data in an optimized manner. Searching for queries that may cause a security or a privacy breach could be used to detect leaks of sensitive data. In general, queries in the query log can provide valuable information about how data have been accessed and used. Finding relevant queries requires conducting search over a repository of SQL queries. However, expressing the information need, to specify which queries should be retrieved, is not easy. In this paper we study the approach of search-by-example, where, given an SQL query Q, the goal is to retrieve queries that are similar to... We distinguish between two types of search-structural search and intent-driven search. In structural search, queries are considered similar if their textual formulations are similar, i.e., a small number of edit operations transform one query into the other. In intent-driven search, two queries are deemed similar if they were written for the same task. We illustrate these two types of similarity and the differences between them. We present four heuristics for testing query similarity. Two of the methods are exhaustive and two are less accurate and efficient. We explain how to utilize the efficient methods to boost a search using the exhaustive methods. An experimental evaluation and a user study illustrate the effectiveness of the methods.																	0169-023X	1872-6933				JUL	2020	128								101811	10.1016/j.datak.2020.101811													
J								Natural language processing-enhanced extraction of SBVR business vocabularies and business rules from UML use case diagrams	DATA & KNOWLEDGE ENGINEERING										SBVR business vocabulary and rules; UML use case diagram; Model-to-model transformation; Controlled natural language; Natural language processing; Information extraction	PROCESS MODELS	Discovery, specification and proper representation of various aspects of business knowledge plays crucial part in model-driven information systems engineering, especially when it comes to the early stages of systems development. Being among the most applicable and advanced features of model-driven development, model transformation could help improving one of the most time- and resource-consuming efforts in this process, namely, discovery and specification of business vocabularies and business rules within the problem domain. One of our latest developments in this area was the solution for the automatic extraction of SBVR business vocabularies and business rules from UML use case diagrams, which was arguably one of the most comprehensive developments of this kind currently available in public. In this paper, we present an enhancement to our previous development by introducing a novel natural language processing component to it. This enhancement provides more advanced extraction capabilities (such as recognition of entities, entire noun and verb phrases, multinary associations) and better quality of the extraction results compared to our previous solution. The main contributions presented in this paper are pre- and post-processing algorithms, and two extraction algorithms using custom-trained POS tagger. Based on the related work findings, it is safe to state that the presented solution is novel and original in its approach of combining together M2M transformation of UML and SBVR models with natural language processing techniques in the field of model-driven information systems engineering.																	0169-023X	1872-6933				JUL	2020	128								101822	10.1016/j.datak.2020.101822													
J								PRESS: A personalised approach for mining top-k groups of objects with subspace similarity	DATA & KNOWLEDGE ENGINEERING										Subspace mining; Similarity search; Association rules; Mining methods and algorithms; Personalisation	SKYLINE; ALGORITHMS; RETRIEVAL	Personalised analytics is a powerful technology that can be used to improve the career, lifestyle, and health of individuals by providing them with an in-depth analysis of their characteristics as compared to other people. Existing research has often focused on mining general patterns or clusters, but without the facility for customisation to an individual's needs. It is challenging to adapt such approaches to the personalised case, due to the high computational overhead they require for discovering patterns that are good across an entire dataset, rather than with respect to an individual. In this paper, we tackle the challenge of personalised pattern mining and propose a query-driven approach to mine objects with subspace similarity. Given a query object in a categorical dataset, our proposed algorithm, PRESS (Personalised Subspace Similarity), determines the top-k groups of objects, where each group has high similarity to the query for some particular subspace. We evaluate the efficiency and effectiveness of our approach on both synthetic and real datasets.																	0169-023X	1872-6933				JUL	2020	128								101833	10.1016/j.datak.2020.101833													
J								Incremental clustering techniques for multi-party Privacy-Preserving Record Linkage	DATA & KNOWLEDGE ENGINEERING										Data linkage; Privacy; Scalability; Graph matching; Multiple databases; Subset matching		Privacy-Preserving Record Linkage (PPRL) supports the integration of sensitive information from multiple datasets, in particular the privacy-preserving matching of records referring to the same entity. PPRL has gained much attention in many application areas, with the most prominent ones in the healthcare domain. PPRL techniques tackle this problem by conducting linkage on masked (encoded) values. Employing PPRL on records from multiple (more than two) parties/sources (multi-party PPRL, MP-PPRL) is an increasingly important but challenging problem that so far has not been sufficiently solved. Existing MP-PPRL approaches are limited to finding only those entities that are present in all parties thereby missing entities that match only in a subset of parties. Furthermore, previous MP-PPRL approaches face substantial scalability limitations due to the need of a large number of comparisons between masked records. We thus propose and evaluate new MP-PPRL approaches that find matches in any subset of parties and still scale to many parties. Our approaches maintain all matches within clusters, where these clusters are incrementally extended or refined by considering records from one party after the other. An empirical evaluation using multiple real datasets ranging from 3 to 26 parties each containing up to 5 million records validates that our protocols are efficient, and significantly outperform existing MP-PPRL approaches in terms of linkage quality and scalability.																	0169-023X	1872-6933				JUL	2020	128								101809	10.1016/j.datak.2020.101809													
J								An Interval Type-2 Fuzzy Risk Analysis Model (IT2FRAM) for Determining Construction Project Contingency Reserve	ALGORITHMS										risk analysis; contingency reserve; aggregation; interval type-2 fuzzy set; principle of justifiable granularity; Fuzzy Risk Analyzer (c)(FRA (c))	MEMBERSHIP FUNCTIONS; SYSTEM DYNAMICS; SETS; FUZZISTICS; PRINCIPLE; WORDS; GERT	Determining contingency reserve is critical to project risk management. Classic methods of determining contingency reserve significantly rely on historical data and fail to effectively incorporate certain types of uncertainties such as vagueness, ambiguity, and subjectivity. In this paper, an interval type-2 fuzzy risk analysis model (IT2FRAM) is introduced in order to determine the contingency reserve. In IT2FRAM, the membership functions for the linguistic terms used to describe the probability, impact of risk and the opportunity events are developed, optimized, and aggregated using interval type-2 fuzzy sets and the principle of justifiable granularity. IT2FRAM is an extension of a fuzzy arithmetic-based risk analysis method which considers such uncertainties and addresses the limitations of probabilistic and deterministic techniques of contingency determination methods. The contribution of IT2FRAM is that it considers the opinions of several subject matter experts to develop the membership functions of linguistic terms. Moreover, the effect of outlier opinions in developing the membership functions of linguistic terms are reduced. IT2FRAM also enables the aggregation of non-linear membership functions into trapezoidal membership functions. A hypothetical case study is presented in order to illustrate the application of IT2FRAM in Fuzzy Risk Analyzer (c)(FRA (c)), a risk analysis software.																		1999-4893				JUL	2020	13	7							163	10.3390/a13070163													
J								Polyhedral DC Decomposition and DCA Optimization of Piecewise Linear Functions	ALGORITHMS										DC function; abs-linearization; DCA	CONVERGENCE	For piecewise linear functionsf:R(n)bar right arrow R we show how their abs-linear representation can be extended to yield simultaneously their decomposition into a convex f and a concave part (f) over cap, including a pair of generalized gradients g is an element of R-n (g) over cap. The latter satisfy strict chain rules and can be computed in the reverse mode of algorithmic differentiation, at a small multiple of the cost of evaluating f itself. It is shown how f and (f) over cap can be expressed as a single maximum and a single minimum of affine functions, respectively. The two subgradients g and -(g) over cap are then used to drive DCA algorithms, where the (convex) inner problem can be solved in finitely many steps, e.g., by a Simplex variant or the true steepest descent method. Using a reflection technique to update the gradients of the concave part, one can ensure finite convergence to a local minimizer of f, provided the Linear Independence Kink Qualification holds. For piecewise smooth objectives the approach can be used as an inner method for successive piecewise linearization.																		1999-4893				JUL	2020	13	7							166	10.3390/a13070166													
J								Exact Method for Generating Strategy-Solvable Sudoku Clues	ALGORITHMS										Sudoku; constraint satisfaction problem; strategy-solvability; exact method; mathematics of Sudoku; constraints of clue geometry; strategy-solvable minimum Sudoku		A Sudoku puzzle often has a regular pattern in the arrangement of initial digits and it is typically made solvable with known solving techniques called strategies. In this paper, we consider the problem of generating such Sudoku instances. We introduce a rigorous framework to discuss solvability for Sudoku instances with respect to strategies. This allows us to handle not only known strategies but also general strategies under a few reasonable assumptions. We propose an exact method for determining Sudoku clues for a given set of clue positions that is solvable with a given set of strategies. This is the first exact method except for a trivial brute-force search. Besides the clue generation, we present an application of our method to the problem of determining the minimum number of strategy-solvable Sudoku clues. We conduct experiments to evaluate our method, varying the position and the number of clues at random. Our method terminates within 1 min for many grids. However, as the number of clues gets closer to 20, the running time rapidly increases and exceeds the time limit set to 600 s. We also evaluate our method for several instances with 17 clue positions taken from known minimum Sudokus to see the efficiency for deciding unsolvability.																		1999-4893				JUL	2020	13	7							171	10.3390/a13070171													
J								The RONO (Rank-Order-Normalization) Procedure for Power-Spectrum Analysis of Datasets with Non-Normal Distributions	ALGORITHMS										rank-order normalization; spectral analysis	TIME-SERIES ANALYSIS	Standard (Lomb-Scargle, likelihood, etc.) procedures for power-spectrum analysis provide convenient estimates of the significance of any peak in a power spectrum, based-typically-on the assumption that the measurements being analyzed have a normal (i.e., Gaussian) distribution. However, the measurement sequence provided by a real experiment or a real observational program may not meet this requirement. The RONO (rank-order normalization) procedure generates a proxy distribution that retains the rank-order of the original measurements but has a strictly normal distribution. The proxy distribution may then be analyzed by standard power-spectrum analysis. We show by an example that the resulting power spectrum may prove to be quite close to the power spectrum obtained from the original data by a standard procedure, even if the distribution of the original measurements is far from normal. Such a comparison would tend to validate the original analysis.																		1999-4893				JUL	2020	13	7							157	10.3390/a13070157													
J								Fuzzy C-Means Clustering Algorithm with Multiple Fuzzification Coefficients	ALGORITHMS										clustering technique; fuzzy clustering; fuzzy C-means clustering; fuzzification coefficient; objective function; performance indices; clustering efficiency; machine learning		Clustering is an unsupervised machine learning technique with many practical applications that has gathered extensive research interest. Aside from deterministic or probabilistic techniques, fuzzy C-means clustering (FCM) is also a common clustering technique. Since the advent of the FCM method, many improvements have been made to increase clustering efficiency. These improvements focus on adjusting the membership representation of elements in the clusters, or on fuzzifying and defuzzifying techniques, as well as the distance function between elements. This study proposes a novel fuzzy clustering algorithm using multiple different fuzzification coefficients depending on the characteristics of each data sample. The proposed fuzzy clustering method has similar calculation steps to FCM with some modifications. The formulas are derived to ensure convergence. The main contribution of this approach is the utilization of multiple fuzzification coefficients as opposed to only one coefficient in the original FCM algorithm. The new algorithm is then evaluated with experiments on several common datasets and the results show that the proposed algorithm is more efficient compared to the original FCM as well as other clustering methods.																		1999-4893				JUL	2020	13	7							158	10.3390/a13070158													
J								Biologically Inspired Visual System Architecture for Object Recognition in Autonomous Systems	ALGORITHMS										computer vision; object recognition; contextual processing; top-down predictions; visual cortex; reinforcement learning; convolutional neural networks	PREDICT; GO	Computer vision is currently one of the most exciting and rapidly evolving fields of science, which affects numerous industries. Research and development breakthroughs, mainly in the field of convolutional neural networks (CNNs), opened the way to unprecedented sensitivity and precision in object detection and recognition tasks. Nevertheless, the findings in recent years on the sensitivity of neural networks to additive noise, light conditions, and to the wholeness of the training dataset, indicate that this technology still lacks the robustness needed for the autonomous robotic industry. In an attempt to bring computer vision algorithms closer to the capabilities of a human operator, the mechanisms of the human visual system was analyzed in this work. Recent studies show that the mechanisms behind the recognition process in the human brain include continuous generation of predictions based on prior knowledge of the world. These predictions enable rapid generation of contextual hypotheses that bias the outcome of the recognition process. This mechanism is especially advantageous in situations of uncertainty, when visual input is ambiguous. In addition, the human visual system continuously updates its knowledge about the world based on the gaps between its prediction and the visual feedback. CNNs are feed forward in nature and lack such top-down contextual attenuation mechanisms. As a result, although they process massive amounts of visual information during their operation, the information is not transformed into knowledge that can be used to generate contextual predictions and improve their performance. In this work, an architecture was designed that aims to integrate the concepts behind the top-down prediction and learning processes of the human visual system with the state-of-the-art bottom-up object recognition models, e.g., deep CNNs. The work focuses on two mechanisms of the human visual system: anticipation-driven perception and reinforcement-driven learning. Imitating these top-down mechanisms, together with the state-of-the-art bottom-up feed-forward algorithms, resulted in an accurate, robust, and continuously improving target recognition model.																		1999-4893				JUL	2020	13	7							167	10.3390/a13070167													
J								Embedded Bayesian Network Contribution for a Safe Mission Planning of Autonomous Vehicles	ALGORITHMS										Bayesian networks; fault detection isolation and recovery; failure mode and effects analysis; embedded diagnosis; error mitigation; unmanned aerial vehicles; mission planning; Markov Decision Process; high level synthesis design tool; field programmable gate array; System-On-Chip		Bayesian Networks (BN) are probabilistic models that are commonly used for the diagnosis in numerous domains (medicine, finance, transport, robotics, horizontal ellipsis ). In the case of autonomous vehicles, they can contribute to elaborate intelligent monitors that can take the environmental context into account. We show in this paper some main abilities of BN that can help in the elaboration of fault detection isolation and recovery (FDIR) modules. One of the main difficulty with the BN model is generally to elaborate these ones according to the case of study. Then, we propose some automatic generation techniques from failure mode and effects analysis (FMEA)-like tables using the pattern design approach. Once defined, these modules have to operate online for autonomous vehicles. In a second part, we propose a design methodology to embed the real-time and non-intrusive implementations of the BN modules using FPGA-SoC support. We show that the FPGA implementation can offer an interesting speed-up with very limited energy cost. Lastly, we show how these BN modules can be incorporated into the decision-making model for the mission planning of unmanned aerial vehicles (UAVs). We illustrate the integration by means of two models: the Decision Network model that is a straightforward extension of the BN model, and the BFM model that is an extension of the Markov Decision Process (MDP) decision-making model incorporating a BN. We illustrate the different proposals with realistic examples and show that the hybrid implementation on FPGA-SoC can offer some benefits.																		1999-4893				JUL	2020	13	7							155	10.3390/a13070155													
J								Text Semantic Annotation: A Distributed Methodology Based on Community Coherence	ALGORITHMS										text annotation; word sense disambiguation; ontologies; Wikification; community detection; Louvain algorithm; Clauset-Newman-Moore algorithm		Text annotation is the process of identifying the sense of a textual segment within a given context to a corresponding entity on a concept ontology. As the bag of words paradigm's limitations become increasingly discernible in modern applications, several information retrieval and artificial intelligence tasks are shifting to semantic representations for addressing the inherent natural language polysemy and homonymy challenges. With extensive application in a broad range of scientific fields, such as digital marketing, bioinformatics, chemical engineering, neuroscience, and social sciences, community detection has attracted great scientific interest. Focusing on linguistics, by aiming to identify groups of densely interconnected subgroups of semantic ontologies, community detection application has proven beneficial in terms of disambiguation improvement and ontology enhancement. In this paper we introduce a novel distributed supervised knowledge-based methodology employing community detection algorithms for text annotation with Wikipedia Entities, establishing the unprecedented concept of community Coherence as a metric for local contextual coherence compatibility. Our experimental evaluation revealed that deeper inference of relatedness and local entity community coherence in the Wikipedia graph bears substantial improvements overall via a focus on accuracy amelioration of less common annotations. The proposed methodology is propitious for wider adoption, attaining robust disambiguation performance.																		1999-4893				JUL	2020	13	7							160	10.3390/a13070160													
J								Design of Hopfield network for cryptographic application by spintronic memristors	NEURAL COMPUTING & APPLICATIONS										Associative behaviour; Cryptography; Hopfield neural network; MATLAB; Spintronic memristor bridge	NEURAL-NETWORKS; CIRCUIT	Memory being one of the essential credential in today's computer world seeks forward newer research interests in its types. Hopfield neural networks of artificial neural networks are one of its classes that can be modelled to form an associative memory. In this paper, we have shown the Hopfield neural network constructed with spintronic memristor bridges accounting to act as an associative memory unit. The memristors are nanoscaled, in terms of size, which possess synaptic behaviour in the artificial neuromorphic system. The associative behaviour is realised by the updation of synaptic weights of memristive Hopfield with single- and multiple-bit associativity which is simulated in MATLAB. The application of the hardware in the field of cryptography is also proposed.																	0941-0643	1433-3058				JUL	2020	32	13					9443	9452		10.1007/s00521-019-04454-9													
J								Knowledge-based reinforcement learning controller with fuzzy-rule network: experimental validation	NEURAL COMPUTING & APPLICATIONS										Model-free adaptive control; Reinforcement learning; Nonlinear discrete-time systems; Fuzzy neural network; DC-motor current control	DISCRETE-TIME-SYSTEMS; SLIDING MODE CONTROL; DYNAMIC-PROGRAMMING ALGORITHM; IF-THEN RULES; ADAPTIVE CONTROLLER; NONLINEAR-SYSTEMS; TRACKING CONTROL; DESIGN	A model-free controller for a general class of output feedback nonlinear discrete-time systems is established by action-critic networks and reinforcement learning with human knowledge based on IF-THEN rules. The action network is designed by a single input fuzzy-rules emulated network with the set of IF-THEN rules utilized by the relation between control effort and plant's output such as IF the output is high THEN the control effort should be reduced. The critic network is constructed by a multi-input FREN (MiFREN) for estimating an unknown long-term cost function. The set of IF-THEN rules for MiFREN is defined by the general knowledge of optimization such that IF the quadratic values of control effort and tracking error are high THEN the cost function should be high. The convergence of tracking error and bounded external signals can be guaranteed by Lyapunov direct method under general assumptions which are reasonable for practical plants. A computer simulation system is firstly provided to demonstrate the design method and the performance of the proposed controller. Furthermore, an experimental system with the prototype of DC-motor current control is conducted to show the effectiveness of the control scheme.																	0941-0643	1433-3058				JUL	2020	32	13					9761	9775		10.1007/s00521-019-04509-x													
J								Stream-Based Lossless Data Compression Applying Adaptive Entropy Coding for Hardware-Based Implementation	ALGORITHMS										lossless data compression; data stream; entropy; adaptive; hardware		Toward strong demand for very high-speed I/O for processors, physical performance growth of hardware I/O speed was drastically increased in this decade. However, the recent Big Data applications still demand the larger I/O bandwidth and the lower latency for the speed. Because the current I/O performance does not improve so drastically, it is the time to consider another way to increase it. To overcome this challenge, we focus on lossless data compression technology to decrease the amount of data itself in the data communication path. The recent Big Data applications treat data stream that flows continuously and never allow stalling processing due to the high speed. Therefore, an elegant hardware-based data compression technology is demanded. This paper proposes a novel lossless data compression, called ASE coding. It encodes streaming data by applying the entropy coding approach. ASE coding instantly assigns the fewest bits to the corresponding compressed data according to the number of occupied entries in a look-up table. This paper describes the detailed mechanism of ASE coding. Furthermore, the paper demonstrates performance evaluations to promise that ASE coding adaptively shrinks streaming data and also works on a small amount of hardware resources without stalling or buffering any part of data stream.																		1999-4893				JUL	2020	13	7							159	10.3390/a13070159													
J								Equivalence of the Frame and Halting Problems	ALGORITHMS										artificial intelligence; entanglement; heuristic search; Multiprover Interactive Proof*(MIP); robotics; separability; system identification	COGNITION; ROBOTS	The open-domain Frame Problem is the problem of determining what features of an open task environment need to be updated following an action. Here we prove that the open-domain Frame Problem is equivalent to the Halting Problem and is therefore undecidable. We discuss two other open-domain problems closely related to the Frame Problem, the system identification problem and the symbol-grounding problem, and show that they are similarly undecidable. We then reformulate the Frame Problem as a quantum decision problem, and show that it is undecidable by any finite quantum computer.																		1999-4893				JUL	2020	13	7							175	10.3390/a13070175													
J								Sensitivity Analysis for Microscopic Crowd Simulation	ALGORITHMS										sensitivity analysis; activity scores; Sobol' indices; pedestrian dynamics	MATHEMATICAL-MODELS; EVACUATION; FLOW; UNCERTAINTY; INDEXES; CHOICE	Microscopic crowd simulation can help to enhance the safety of pedestrians in situations that range from museum visits to music festivals. To obtain a useful prediction, the input parameters must be chosen carefully. In many cases, a lack of knowledge or limited measurement accuracy add uncertainty to the input. In addition, for meaningful parameter studies, we first need to identify the most influential parameters of our parametric computer models. The field of uncertainty quantification offers standardized and fully automatized methods that we believe to be beneficial for pedestrian dynamics. In addition, many methods come at a comparatively low cost, even for computationally expensive problems. This allows for their application to larger scenarios. We aim to identify and adapt fitting methods to microscopic crowd simulation in order to explore their potential in pedestrian dynamics. In this work, we first perform a variance-based sensitivity analysis using Sobol' indices and then crosscheck the results by a derivative-based measure, the activity scores. We apply both methods to a typical scenario in crowd simulation, a bottleneck. Because constrictions can lead to high crowd densities and delays in evacuations, several experiments and simulation studies have been conducted for this setting. We show qualitative agreement between the results of both methods. Additionally, we identify a one-dimensional subspace in the input parameter space and discuss its impact on the simulation. Moreover, we analyze and interpret the sensitivity indices with respect to the bottleneck scenario.																		1999-4893				JUL	2020	13	7							162	10.3390/a13070162													
J								Modeling Hourly Soil Temperature Using Deep BiLSTM Neural Network	ALGORITHMS										soil temperature; machine learning; weather forecasting data; BiLSTM; soil depths	SHORT-TERM-MEMORY; PREDICTION; LSTM; CLASSIFICATION; RESPIRATION; PERFORMANCE; MOISTURE; MACHINE; SEASON	Soil temperature (ST) plays a key role in the processes and functions of almost all ecosystems, and is also an essential parameter for various applications such as agricultural production, geothermal development, and their utilization. Although numerous machine learning models have been used in the prediction of ST, and good results have been obtained, most of the current studies have focused on daily or monthly ST predictions, while hourly ST predictions are scarce. This paper presents a novel scheme for forecasting the hourly ST using weather forecast data. The method considers the hourly ST prediction to be the superposition of two parts, namely, the daily average ST prediction and the ST amplitude (the difference between the hourly ST and the daily average ST) prediction. According to the results of correlation analysis, we selected nine meteorological parameters and combined two temporal parameters as the input vectors for predicting the daily average ST. For the task of predicting the ST amplitude, seven meteorological parameters and one temporal parameter were selected as the inputs. Two submodels were constructed using a deep bidirectional long short-term memory network (BiLSTM). For the task of hourly ST prediction at five different soil depths at 30 sites, which are located in 5 common climates in the United States, the results showed the method proposed in this paper performs best at all depths for 30 stations (100% of all) for the root mean square error (RMSE), 27 stations (90% of all) for the mean absolute error (MAE), and 30 stations (100% of all) for the coefficient of determination (R-2), respectively. Moreover, the method adopted in this study displays a stronger ST prediction ability than the traditional methods under all climate types involved in the experiment, the hourly ST produced by it can be used as a driving parameter for high-resolution biogeochemical models, land surface models and hydrological models and can provide ideas for an analysis of other time series data.																		1999-4893				JUL	2020	13	7							173	10.3390/a13070173													
J								On the Well-Posedness of A High Order Convective Cahn-Hilliard Type Equations	ALGORITHMS										existence; uniqueness; stability; higher order convective Cahn-Hilliard type equation; Cauchy problem	NONHOMOGENEOUS INITIAL-BOUNDARY; KURAMOTO-SIVASHINSKY EQUATION; TERNARY AMPHIPHILIC SYSTEMS; GINZBURG-LANDAU THEORY; NONLINEAR SATURATION; CONVERGENCE; WAVES; STABILITY; DIFFUSION; STABILIZATION	High order convective Cahn-Hilliard type equations describe the faceting of a growing surface, or the dynamics of phase transitions in ternary oil-water-surfactant systems. In this paper, we prove the well-posedness of the classical solutions for the Cauchy problem, associated with this equation.																		1999-4893				JUL	2020	13	7							170	10.3390/a13070170													
J								TeKET: a Tree-Based Unsupervised Keyphrase Extraction Technique	COGNITIVE COMPUTATION										Candidate keyphrase; Unsupervised machine learning; Automatic keyphrase extraction; Document processing; Recommender system; Binary tree	OF-THE-ART; INFORMATION; SYSTEM; WEB	Automatic keyphrase extraction techniques aim to extract quality keyphrases for higher level summarization of a document. Majority of the existing techniques are mainly domain-specific, which require application domain knowledge and employ higher order statistical methods, and computationally expensive and require large train data, which is rare for many applications. Overcoming these issues, this paper proposes a new unsupervised keyphrase extraction technique. The proposed unsupervised keyphrase extraction technique, namedTeKETorTree-based Keyphrase Extraction Technique, is a domain-independent technique that employs limited statistical knowledge and requires no train data. This technique also introduces a new variant of a binary tree, calledKeyPhrase Extraction(KePhEx) tree, to extract final keyphrases from candidate keyphrases. In addition, a measure, calledCohesiveness IndexorCI, is derived which denotes a given node's degree of cohesiveness with respect to the root. The CI is used in flexibly extracting final keyphrases from the KePhEx tree and is co-utilized in the ranking process. The effectiveness of the proposed technique and its domain and language independence are experimentally evaluated using available benchmark corpora, namely SemEval-2010 (a scientific articles dataset), Theses100 (a thesis dataset), and aGerman Research Articledataset, respectively. The acquired results are compared with other relevant unsupervised techniques belonging to both statistical and graph-based techniques. The obtained results demonstrate the improved performance of the proposed technique over other compared techniques in terms of precision, recall, and F1 scores.																	1866-9956	1866-9964				JUL	2020	12	4					811	833		10.1007/s12559-019-09706-3													
J								A Method of Restoring Fuzzy Remote Sensing Image Based on Dark Pixel Prior	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Remote sensing image deblurring; dark pixel prior; image restoration; nonsparse feature		Remote sensing image deblurring is a long-term and challenging inverse problem. Among them, the ability to find the correct image prior is the key to recovering high-quality and clear images. Therefore, in order to recover high-quality clear images, this paper has found a new and effective image prior: The dark pixel a priori in remote sensing images and a fuzzy remote sensing image restoration method based on dark pixel prior is proposed. Since the dark pixels in the clear remote sensing image will increase the pixel value of the dark pixels in the blurred remote sensing image due to the weighted balance with the bright pixels around it, the sparsity of the dark pixels in the blurred remote sensing image is reduced. Therefore, by using this nonsparse feature of dark pixels in fuzzy remote sensing images, fuzzy remote sensing images and clear remote sensing images can be effectively distinguished, thus realizing the restoration of fuzzy remote sensing images. The experimental results show that the proposed method has obvious effects on the restoration effect and time.																	0218-0014	1793-6381				JUL	2020	34	8							2054020	10.1142/S0218001420540208													
J								Recognition of Mobile Robot Navigation Path Based on K-Means Algorithm	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										K-means algorithm; mobile robot; visual navigation; path recognition	VISION; GUIDANCE	With the rapid development of computer technology and electronics industry, computer processing capability and image processing technology have been greatly improved, making robots based on computer processing and image processing have entered a new development in the field of navigation path recognition research. As an indispensable carrier for intelligent manufacturing and industrial development, robots are expanding their applications. The key to the successful execution of the mobile robot is to move according to the planned path and to avoid obstacles autonomously. These two points depend on the validity and accuracy of navigation path identification. At present, research on mobile robot navigation path recognition mainly uses visual navigation as the main method, which uses visual sensors to simulate human eye functions, obtains relevant information from external environment images, and processes them to realize related functions that the system needs to complete. The two major problems in visual navigation are poor recognition ability and insufficient ability to resist light source interference. The main purpose of this paper is to improve the recognition ability of mobile robot navigation path and the ability to resist light source interference. It mainly uses the K-means algorithm for visual navigation research. By simulating the acquired image and the selected color space, the results show that the average time taken to complete a path identification method is 152 ins. Under different illumination environments, the information extraction rate of mobile robot navigation path can reach 90%, and the effect of strong light on navigation path recognition is effectively reduced under strong illumination environment. The results show that the recognition of the visual navigation path of a mobile robot using the K-means algorithm is more precise than the conventional method, and it takes less time to better meet the timeliness requirements of mobile robots.																	0218-0014	1793-6381				JUL	2020	34	8							2059028	10.1142/S0218001420590284													
J								The Accuracy of Low-Altitude Photogrammetry of Drones	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Drone; digital photogrammetry; digital orthophoto map; accuracy analysis		This paper uses the Haida iFLY-U3 fixed-wing UAV for image data acquisition. Based on UAV low-altitude photogrammetry technology, field control measurement method, such as Agisoft PhotoScan and Pix4D Mapper software, can process and produce DEM and DOM. Practical research on the processes and key technologies of digital products is under process. The field checkpoint measurement for the accuracy of DOM digital products made by low-altitude digital photogrammetry technology creates a basis for the practical application and development of digital products. The main contents of this paper are as follows: (a) The basic principles and processes of digital products for drone remote sensing image production, such as control point layout and measurement methods. (b) Based on the UAV photography technology, the digital product DOM and the field measurement control point accuracy evaluation are generated. (c). The polynomial curve digital model method is used to solve the elevation correction value, and the quadratic polynomial fitting model of the elevation point of the internal digital product is established, and the precision analysis is carried out.																	0218-0014	1793-6381				JUL	2020	34	8							2059029	10.1142/S0218001420590296													
J								Acquisition and its Basic Processing Technology of Multimedia Vocal Signal	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Multimedia; audio processing; filter; MATLAB	ACTIVE NOISE-CONTROL	This paper briefly studies the method of collecting audio signals and the method of adding noise to audio signals. It comprehensively applies various basic knowledge of digital signal processing, and then performs spectrum analysis on noise-free frequency signals and spectral analysis of noise-added frequency signals, and filtering processing. Through theoretical derivation, the corresponding conclusions are drawn, and then MATLAB is used as a programming tool to carry out computer implementation to verify the conclusions derived. In the research process, the filter processing was completed by designing the IIR digital filter and the FIR digital filter, and MATLAB was used to draw the graphics and calculate and simulate some data in the whole design.																	0218-0014	1793-6381				JUL	2020	34	8							2058009	10.1142/S0218001420580094													
J								A Novel Strategy for Retrieving Large Scale Scene Images Based on Emotional Feature Clustering	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Scene images; image retrieval; MapReduce; feature clustering	COLOR	Due to complicated data structure, image can present rich information, and so images are applied widely at different fields. Although the image can offer a lot of convenience, handling such data consume much time and multi-dimensional space. Especially when users need to retrieve some images from larger-scale image datasets, the disadvantage is more obvious. So, in order to retrieve larger-scale image data effectively, a scene images retrieval strategy based on the MapReduce parallel programming model is proposed. The proposed strategy first, investigates how to effectively store large-scale scene images under a Hadoop cluster parallel processing architecture. Second, a distributed feature clustering algorithm MeanShift is introduced to implement the clustering process of emotional feature of scene images. Finally, several experiments are conducted to verify the effectiveness and efficiency of the proposed strategy in terms of different aspects such as retrieval accuracy, speedup ratio and efficiency and data scalability.																	0218-0014	1793-6381				JUL	2020	34	8							2054019	10.1142/S0218001420540191													
J								Image Processing and Splicing Method for 3D Optical Scanning Surface Reconstruction of Wood Grain	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Wood texture 3D scanning; environmental compensation; avoid overlapping marked points; image processing; curved surface reverse reconstruction	ALGORITHM	Based on environment compensation, scanning image processing technology was employed to investigate point cloud data and space matching method for wood grain. Collision avoidance recognition algorithm was used to collocate mark points, when remarkably reduced the error matching of distance coincidence mark points. The proposed method used marking of flag sample points based on weight to compensate for the marking points ambiguity of distinguishing information in scanning environment, and select the optimal path for the weighted results. The same splicing points in different images was identified, solving the problem of fuzzy splicing by distance matching. Experimental results and three-dimensional (3D) printing wood cross-section model reconstructed by surface fitting were compared. Results showed that the 3D scanning image mosaic of wood growth texture at the cross-section had no obvious stereo characteristics. The proposed method has improved the accuracy of surface mosaic in reverse scanning imaging for wood grain. This method can be applied to support the application needs of reverse surface reconstruction.																	0218-0014	1793-6381				JUL	2020	34	8							2054021	10.1142/S021800142054021X													
J								Deep Spatio-Temporal Modified-Inception with Dilated Convolution Networks for Citywide Crowd Flows Prediction	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Deep learning; dilated convolution; MINet; flow prediction; modified-inception		Traffic flow prediction has great significance for improving road traffic capacity and traffic safety. However, traffic flow in a certain area is usually affected by some factors such as weather, holidays and neighboring areas. So, traffic situation is complicated and traffic flow prediction is difficult. How to use existing traffic data information to predict future traffic flow is the key to this problem. In this paper, we develop an accurate prediction model based on dilated convolution - ST-MINet (Deep Spatio-Temporal Modified-Inception with Dilated convolution Networks). We fully consider the complexity, nonlinearity and uncertainly of traffic network by summarizing various network models such as ResNet and Inception. So, we use the deep space-time residual network to ensure the convolution accuracy of the information's position distribution on the basis of existing networks. Then, we add the cavity convolution to the model, which can effectively control the field of view of the convolution kernel. In the experimental part, we compare ten classical algorithms with our ST-MINet, it shows that our model has higher accuracy than others.																	0218-0014	1793-6381				JUL	2020	34	8							2052003	10.1142/S0218001420520035													
J								Weld Image Recognition Algorithm Based on Deep Learning	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Weld image recognition; adaptive threshold; deep convolutional neural network; Adam algorithm	IDENTIFICATION	As an important part of metal processing, welding is widely used in industrial manufacturing activities, and its application scenarios are very extensive. Due to technical limitations, the welding process always unavoidably leaves weld defects. Weld defects are extremely hazardous, and the work used must be guaranteed to be defect-free, regardless of the field. However, manual weld inspection has subjective factors such as inefficiency and easy missed detection, and although some automatic weld inspection methods have appeared, these traditional methods still do not meet actual demand in terms of detection time and detection accuracy. Therefore, there is a need for a higher quality weld image automatic detection method to replace the manual method and the traditional automatic detection method. In view of the above, this paper proposes a weld seam image recognition algorithm based on deep learning. The Adam adaptive moment estimation algorithm is chosen as the backpropagation optimization algorithm to accelerate the training of convolutional neural networks and design an independent adaptive learning rate. Through the simulation of the collected 4500 tube images, the adaptive threshold-based method is used for weld seam extraction. The algorithm proposed in this paper is compared with the weld seam recognition method based on image texture feature value distribution (ITFVD) and the SUSAN-based weld defect target detection method. The results show that the proposed method can identify weld defects in a short time on different sizes of weld images, and can further detect the type of weld defects. In addition, the method in this paper is better than the other two methods in the false detection rate, recall rate and overall recognition accuracy, which shows that the experimental results have achieved the expected results.																	0218-0014	1793-6381				JUL	2020	34	8							2052004	10.1142/S0218001420520047													
J								Two Subpopulations Cuckoo Search Algorithm Based on Mean Evaluation Method for Function Optimization Problems	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										CS algorithm; functions optimization; dynamic inertia weight; targeted mutation; differential mutation	DESIGN	In order to better apply the cuckoo search (CS) algorithm in solving the problem of function extremism optimization, and further improve the phenomenon of low precision and slow convergence in the optimization process of algorithm, the two subpopulations CS algorithm based on mean value evaluation is proposed. On the one hand, the algorithm introduces dynamic inertia weight to adjust the levy flight mechanism, thus dynamically constraining the moving step-size of each generation of population, so that the algorithm has certain self-adaptability. On the other hand, the algorithm changes the way of mutation in the preference random walk. First, the average fitness evaluation mechanism is used to divide the current population into two subpopulations: good and bad. Then, it adopts a directional mutation strategy for the better population, so that the individual can search purposefully. The worse population uses differential mutation mechanism of the disturbance items with the t-distribution characteristics, and makes the individual to search in the best orientation of current, so as to enhance the local search performance and accelerate the convergence rate of the algorithm. Theoretical analysis proves the convergence and time complexity of the algorithm in this paper. The simulation results show that the improved algorithm has good applicability in solving the function optimization problem, and the optimization results and convergence speed have been significantly improved in the algorithm.																	0218-0014	1793-6381				JUL	2020	34	8							2059027	10.1142/S0218001420590272													
J								Identification of Brain Functional Networks Using a Model-Based Approach	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										FMRI data analysis; Resting State Networks; regression mixture models; MRF prior; sparseness	FMRI DATA; ALZHEIMERS-DISEASE; MIXTURE MODEL; RESTING BRAIN; CONNECTIVITY; SPARSE; ARCHITECTURE; CORTEX	Functional MRI (fMRI) is a valuable brain imaging technique. A significant problem, when analyzing fMRI time series, is the finding of functional brain networks when the brain is at rest, i.e. no external stimulus is applied to the subject. In this work, we present a probabilistic method to estimate the Resting State Networks (RSNs) using a model-based approach. More specifically, RSNs are assumed to be the result of a clustering procedure. In order to perform the clustering, a mixture of regression models are used. Furthermore, special care has been given in order to incorporate important functionalities, such as spatial and embedded sparsity enforcing properties, through the use of informative priors over the model parameters. Another interesting feature of the proposed scheme is the flexibility to handle all the brain time series at once, allowing more robust solutions. We provide comparative experimental results, using an artificial fMRI dataset and two real resting state fMRI datasets, that empirically illustrate the efficiency of the proposed regression mixture model.																	0218-0014	1793-6381				JUL	2020	34	8							2057004	10.1142/S0218001420570049													
J								Human-Vehicle Collision Detection Algorithm Based on Image Processing	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Image processing; edge detection; model construction; collision detection		In recent years, with the growth of China's economy and the development of the automobile manufacturing industry, the number of various vehicles has continuously increased, and the incidence of traffic accidents has also increased. Especially in traffic blind areas, right-turning areas of vehicles, etc., traffic accidents such as vehicle collisions are extremely easy to occur, which poses a serious threat to people's lives and property, and is extremely harmful. Therefore, related research on collision detection of people and vehicles has been traffic-safe and has received extensive attention from field researchers. At present, the research on human-vehicle collision detection is to detect human-vehicle collision accidents by tracking the track of vehicles and pedestrians, but there are problems such as poor tracking effect, low accuracy of collision discrimination and complex algorithms. Aiming at these problems, this paper studies the human-vehicle collision detection algorithm based on image processing. Through the image processing of traffic monitoring video, the vehicle and pedestrian contour information is extracted. Based on this, a mathematical model for collision detection is constructed to realize human-vehicle collision detection. The results show that the proposed method can effectively distinguish the collision between pedestrians and vehicles, and the algorithm for image processing is simpler than the traditional tracking algorithm, and the time is shorter. The results show that the image-based collision detection algorithm based on image processing can effectively and quickly identify the traffic accidents in which people and vehicles collide, and then can issue alarm signals in time, shortening the accident processing time and reducing the accident time. The possibility of a secondary accident has a high practicability in the detection of traffic accidents in which people and vehicles collide.																	0218-0014	1793-6381				JUL	2020	34	8							2055015	10.1142/S0218001420550150													
J								Deep Learning Classification on Optical Coherence Tomography Retina Images	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Deep learning; image classification; transfer learning; convolutional neural network; OCT retinal images	CONVOLUTIONAL NEURAL-NETWORKS	This paper presents a novel deep learning classification technique applied on optical coherence tomography (OCT) retinal images. We propose the deep neural networks based on Vgg16 pretrained network model. The OCT retinal image dataset consists of four classes, including three most common retina diseases and one normal retina scan. Because the scale of training data is not sufficiently large, we use the transfer learning technique. Since the convolutional neural networks are sensitive to a little data change, we use data augmentation to analyze the classified results on retinal images. The input grayscale OCT scan images are converted to RGB images using colormaps. We have evaluated different types of classifiers with variant parameters in training the network architecture. Experimental results show that testing accuracy of 99.48% can be obtained as combined on all the classes.																	0218-0014	1793-6381				JUL	2020	34	8							2052002	10.1142/S0218001420520023													
J								Fractional-pel Interpolation Algorithm Based on Adaptive Filter	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Adaptive filter; resolution; computation complexity; peak signal noise ratio; code rate	VIDEO; OPTIMIZATION	In order to further improve fractional-pel interpolation image quality of video sequence with different resolutions and reduce algorithm complexity, the fractional-pel interpolation algorithm based on adaptive filter (AF_FIA) is proposed. This algorithm adaptively selects the interpolation filters with different orders according to the three video sequence regions with different resolutions; in the three video sequence regions with different resolutions, the high-order interpolation filter is replaced by low-order interpolation filter according to the correlation between pixels to realize the adaptive selection of filter. The complexity analysis results show that compared with other algorithms, this algorithm reduces space complexity and computation complexity, thus reducing the storage access and coding time. The simulation results indicate that compared with other algorithms, this algorithm has good coding performance and robustness for video sequences with different resolutions.																	0218-0014	1793-6381				JUL	2020	34	8							2054022	10.1142/S0218001420540221													
J								Implementation of Classification and Recognition Algorithm for Text Information Based on Support Vector Machine	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Text categorization; support vector machine; public security information	FEATURE-SELECTION; CATEGORIZATION; SVM	At present, Internet data is the world's largest data resource database. In order to realize fast and automatic intelligent classification, it is of great significance to develop automatic classification of public security intelligent data systems. This paper studies the actual needs of public security information text classification, analyzes the text automatic classification technology support vector machine (SVM) theory and designs and implements SVM-based public security information, and also realizes the classification system of public security information. Automatic classification provides support for subsequent text mining systems and text searches and designs the performance of the system. After optimization and testing, the system was found to have good practical application results.																	0218-0014	1793-6381				JUL	2020	34	8							2053005	10.1142/S0218001420530055													
J								Intelligent Control of Flexible Joint Manipulator Based on Dynamic Pattern Recognition	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE										Dynamic pattern recognition; flexible joint manipulator; intelligent control method; GA-RBF	ADAPTIVE CONTROLLER	With the rapid development of intelligent manufacturing and Internet technology, the industrial system has entered a new stage of development. As an indispensable carrier for intelligent manufacturing and industrial development, robots are expanding their applications. Among them, the flexible mechanical arm has the advantages of light weight, low energy consumption and low inertia compared with the bulky rigid mechanical arm, and has been increasingly valued. The flexible manipulator is a very complex dynamic system whose dynamic equations are characterized by nonlinearity, strong coupling and time-varying. Therefore, this paper uses the most common and effective method to establish the dynamic model of the flexible manipulator using the Lagrange equation. Due to the uncertain system parameters, lack of control of the trajectory and the influence of load changes and external disturbances, the flexible manipulator has great uncertainty in its control process, and the traditional control methods have not very good control effect. Based on this, this paper proposes a combination of dynamic pattern recognition theory and flexible joint manipulator intelligent control method for the two-link flexible manipulator, and uses the new GA-RBF neural network closed-loop adaptive control method to achieve high precision. Trajectory tracking ensures stability in a shorter time. The simulation results show that the intelligent joint control method based on dynamic pattern recognition has better trajectory tracking and autonomous fast recognition dynamic mode.																	0218-0014	1793-6381				JUL	2020	34	8							2050021	10.1142/S0218001420500214													
J								Detection Effectiveness Estimation Based on Multi-Angle Data and Visualization Analysis	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										intelligent confrontation game; detection effectiveness estimation of EWD SoS; multi-angle data; visualization analysismethod; running characteristics of detection work		In intelligent confrontation games, how to estimate the detection effectiveness of the early-warning detection (EWD) system of systems (SoS) is the most important issue that has been studied in hopes of a breakthrough for the long time. The conventional approaches to effectiveness estimation have been reductionism or the linear estimation methods, which are not suitable for the estimation of the effectiveness of EWD SoS. Effectiveness estimation methods and ideas based on complex networks have been proposed and studied, which can inspire that the logic relationship in the SoS can be analyzed by using the network thoughts. As a development of some research based on the Data mode, data and visualization analysis methods have been proposed. In these approaches, the multi-angle data and visualization analysis methods can be utilized to directly show some significant relationships in the SoS from the different aspects, especially from different angles of sight. These statistics and suggested results can be employed to analyze the situation of SoS, so they have potentially important capabilities in terms of the estimation of EWD SoS. Therefore, in this paper, these new ideas are introduced into the study and solution of the problem of the detection effectiveness estimation of EWD SoS. On the basis that the running characteristics of the detecting work of the EWD SoS are described, the data method and idea with multi-angles for EWD SoS are proposed and discussed, and the visualization analysis method and ideas about EWD SoS are suggested and analyzed. Furthermore, a typical application is employed to estimate the detection effectiveness of EWD SoS, based on the data and visualization analysis methods stated in this paper. As the results of the estimate are generally consistent with the actual situation, the validity of the proposed methods is considered proven. The main work in this paper can provide new ideas on the study of the issue of the detection effectiveness estimation of EWD SoS, and it also helpful for SoS analysis and other estimations of effectiveness.																	1343-0130	1883-8014				JUL	2020	24	4					441	452		10.20965/jaciii.2020.p0441													
J								Anomaly Detection Algorithm Based on CFSFDP	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										anomaly detection; density clustering; generating profiles; profiles precision	INTRUSION DETECTION	Clustering by fast search and find of density peak (CFSFDP) is a simple and crisp density-clustering algorithm. The original algorithm is not suitable for direct application to anomaly detection. Its clustering results have a high level of redundant density information. If used directly as behavior profiles, the computation and storage costs of anomaly detection are high. Therefore, an improved algorithm based on CFSFDP is proposed for anomaly detection. The improved algorithm uses a few data points and their radius to support behavior profiles, and deletes the redundant data points without supporting profiles. This method not only reduces the large amount of data storage and distance calculation in the process of generating profiles, but also reduces the search space of profiles in the detection process. Numerous experiments show that the improved algorithm generates profiles faster than density-based spatial clustering of application with noise (DBSCAN), and has better profile precision than adaptive real-time anomaly detection with incremental clustering (ADWICE). The improved algorithm inherits the arbitrary shape clusters of CFSFDP, and improves the storage and computation performance. Compared with DBSCAN and ADWICE, the improved anomaly-detection algorithm based on CFSFDP has more balanced detection precision and real-time performance.																	1343-0130	1883-8014				JUL	2020	24	4					453	460		10.20965/jaciii.2020.p0453													
J								The Study on the Influence of Terms of Trade on Regional Inflation - Based on the Mixed NKPC Model Under the Opening Economy Condition	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										the price terms of trade; the income terms of trade; inflation; regional difference; New Keynesian Phillips Curve	MONETARY-POLICY	Based on the panel data from 1990 to 2018, this paper analyzes the regional difference in the impact of changes in price terms of trade and changes in income terms of trade on inflation by establishing the Hybrid NKPC model under the open economy. The empirical results show that the changes in price terms of trade and the changes in expected price have a significant negative and positive impact on the current inflation rate for each region. The changes in income terms of trade and the changes in expected income terms of trade have significant negative and positive effects on the inflation for each region. There is a significant difference in the degree of impact on the regional inflation and the degree of impact will further strengthen. Therefore, the change in terms of trade is an important determinant of the level and trend of domestic inflation in both the short term and long term.																	1343-0130	1883-8014				JUL	2020	24	4					461	467															
J								Psychological Trends in the Achievement Goals of College and University Athletes	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										3 x 2 achievement goal model; passion; psychological well-being; fuzzy data; coach	MOTIVATION; HAPPINESS; MODEL	Objectives: This study aimed to validate the application of the 3 x 2 achievement goal model in sports. Motivations: In order to offer new perspectives on achievement goals, this study explores 3 x 2 achievement goals used in competitive sports, and the prediction of passion and psychological well-being for sports. Methods: The study sample consists of 406 college and university athletes, including 230 males and 176 females. Average age of the subjects was 20.34 years. Average length of years of sports participation was 8.23 years. Data were collected with a questionnaire that incorporated a 3 x 2 achievement goal scale, a sports passion scale, and the Psychological Well-Being Scale. Statistical Methods: Data were analyzed using descriptive statistics for fuzzy data, fuzzy correlation coefficients, and fuzzy regression models. Finding: 1. There was a correlation between every two of task-approach, task-avoidance, self-approach, self-avoidance, other-approach, other-avoidance, harmonious passion, obsessive passion, and psychological well-being. 2. Among college and university athletes, task-approach and self-approach positively influence harmonious passion; task-approach, self-approach, other-approach, and other-avoidance positively influence obsessive passion; task-avoidance negatively influences obsessive passion; task-approach and self-approach positively influence psychological well-being, and task-avoidance negatively influences psychological well-being. Innovations: Use of the 3 x 2 achievement goal scale is applicable to college sportsmen in Taiwan, and the research method uses fuzzy statistical analysis, which breaks through the barriers of traditional psychological survey methods, and will improve the research quality of the sample survey. This study provides new techniques for research on psychological trends in sports. Value: In the future, coaches and athletes should focus on task-approach and self-approach goals in order to enhance the college or university athletes' harmonious passion for a positive impact on their psychological well-being when they engage in sports through their own free will.																	1343-0130	1883-8014				JUL	2020	24	4					468	476		10.20965/jaciii.2020.p0468													
J								Predictability of China's Stock Market Returns Based on Combination of Distribution Forecasting Models	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										predictability; distribution forecasting; model combination; GARCH; nonparametric	CONTINUOUS-TIME MODELS; DENSITY FORECASTS; TERM STRUCTURE; ASSET RETURNS; SAMPLE; PREDICTION	No consensus exists in the literature on whether stock prices can be predicted, with most existing studies employing point forecasting to predict returns. By contrast, this study adopts the new perspective of distribution forecasting to investigate the predictability of the stock market using the model combination strategy. Specifically, the Shanghai Composite Index and the Shenzhen Component Index are selected as research objects. Seven models - GARCH-norm, GARCH-sstd, EGARCH-sstd, EGARCH-sstdM, one-component Beta-t-EGARCH, two-component Beta-t-EGARCH, and the EWMA-based non-parametric model - are employed to perform distribution forecasting of the returns. The results of out-of-sample forecasting evaluation show that none of the individual models is "qualified" in terms of predictive power. Therefore, three combinations of individual models were constructed: equal weight combination, log-likelihood score combination, and continuous ranked probability score combination. The latter two combinations were found to always have significant directional predictability and excess profitability, which indicates that the two combined models may be closer to the real data generation process; from the perspective of economic evaluation, they may have a predictive effect on the conditional return distribution in China's stock market.																	1343-0130	1883-8014				JUL	2020	24	4					477	487		10.20965/jaciii.2020.p0477													
J								Route Optimization of Aquatic Product Transportation Based on an Improved Ant Colony Algorithm	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										aquatic products; time window; improved ant colony algorithm; path planning		In this paper, the time window in which aquatic products must be delivered and the uncertainty of road conditions that affect the time at which customers are able to receive the goods are added as constraints in the optimization model of the Vehicle Routing Problem. The use of pheromones in the original ant colony algorithm was improved, and the waiting factor was added into the state transition rules to limit the information range. The improved ant colony algorithm was used to simulate the model with the example of aquatic product transportation route planning in Zhoushan city. The results show that this algorithm can optimize the transportation and distribution routes of aquatic products more effectively.																	1343-0130	1883-8014				JUL	2020	24	4					488	493		10.20965/jaciii.2020.p0488													
J								Optimization Design of Oven Shape Based on Heat Distribution Model	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										heat distribution; Fourier's law; optimization; shape design		We developed two models in this study: one to show the distribution of heat for pans of different shapes, and the other to select the best type of pan to maximize the number of pans that can fit in the oven and to maximize even heat distribution in the pans. We constructed a model of heat distribution. The uneven distribution of heat is mainly caused by heat conduction. We established a differential equation for heat conduction according to Fourier's law. The finite-difference method and Gauss-Seidel iteration were used to solve the equation, and MATLAB was used to draw the corresponding heat-distribution chart. We built a quantitative model of the shape optimization with an evaluation equation. Using the permutation and combination method, we calculated the maximum number of pans and the utilization rate of area. Finally, we determined that the optimal pan type is a round square, which achieved the best state.																	1343-0130	1883-8014				JUL	2020	24	4					494	501															
J								The Influence of Factor Price Distortions on Economic Structure - Based on Time-Varying Elasticity Production Function Model	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										factors price distortion; industrial structural upgrading; time-varying elasticity production function model		Based on the time-varying elasticity production function model, we calculate factor price distortions, and study their influence on the rationalization and optimization of industrial structure. We find that the impact coefficient of capital, and labor factor price distortions on the rationalization of industrial structure are -1.2087 and -0.3147 respectively. Additionally, the impact coefficients on the optimization of industrial structure are -0.2333 and -0.0718 respectively. These results demonstrate that capital and labor factor price distortions are significantly negative for the rationalization and optimization of industrial structure. Therefore, it is imperative to reduce factor price distortions, and support industrial structure upgrades to promote supply-side structural reform.																	1343-0130	1883-8014				JUL	2020	24	4					502	508															
J								An ERP Experimental Study About the Effect of Authorization Cue Characteristics on the Privacy Behavior of Recommended Users	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										privacy authorization; characteristics of cues; information boundary theory; cognitive style; event-related potential2	INFORMATION PRIVACY; PARADOX; PERCEPTIONS; SELECTION; ADOPTION	At the present time, consumers often disclose their privacy when using online platforms to receive personalized recommendation information and services, but they are also highly concerned whether their privacy is being violated. "Privacy paradox" is becoming a hot topic of research. What are the potential impacts of individual cognitive differences and situational cues on privacy decision-making? How to balance the internal causes of the "privacy paradox" so that consumers are more willing to accept personalized recommendation services based on users' privacy data? Can the transparency of privacy rights ease user conflict perceptions and promote disclosure intentions? These questions are inconclusive. Therefore, the purpose of this our research was to explore consumer privacy paradoxical behaviors from a novel perspective of the characteristics of authorization cues, and to clarify the internal relationship between individual cognitive processing and privacy authorization cues. This study suggests that the big data platform, when collecting or using user information, should try to reduce the behaviors that induce users' resistance. It also provides a reference for how to better achieve benign interaction in personalized recommendation between Internet companies and users. The event-related potential technique is adopted to explore the matching relationship between individual cognitive processing and privacy authorization cues and to analyze the internal neural mechanism of the personalized recommendation user in the authorization decision. The experiment simulated the privacy authorization situation, and adopted a 2 x 2 x 2 hybrid experimental design: authority sensitivity (high/low) * authorization transparency (with/without permission) * cognitive style (field dependent/field independent). The experimental results show that: (1) Authorization transparency, authority sensitivity and their interactions will affect the user's privacy authorization behaviors, and the interaction of the two cues has a greater impact on the behavior than the role of a single cue; (2) The cognitive style will affect the individual's attention resource allocation in the authorization scenario, which, limited by cognitive resources, will result in selective attention to contextual cues: Compared with the field-independent group with self-characterization as a reference, the field-dependent group induced a greater P2 amplitude; (3) When the two-cue valences in the authoritative scenario are inconsistent, the amplitude of the N2 component is greater than that when the valences are consistent, and the amplitude of the N2 induced by the field-dependent group is more affected by the scenario cue valence; (4) Regardless of whether it is a field-dependent group or a field-independent group, there is no salient difference in the amplitude of LPP components induced in each scenario. According to the results of this study, even if privacy authorization involves high risks, individuals tend to selectively seek supportive cues or avoid obtaining information that is inconsistent with their cognition. This research reveals the differences of neural mechanisms in users' actual decision-making, provides the possibility for further exploration of the black box behind users' attitudes and behaviors, and opens up new ideas for the study of the "privacy paradox."																	1343-0130	1883-8014				JUL	2020	24	4					509	523															
J								The Dynamic Correlation Between Capital Deepening and Total Factor Productivity in China	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										capital deepening; total factor productivity; Bayesian quantile; adaptive Lasso	ADAPTIVE LASSO	The impact of capital deepening on total factor productivity (TFP) is a significant and controversial issue. Based on the calculation of relevant indicators, this study adopts a Bayesian time-varying parameter model, Bayesian quantile regression, and adaptive Bayesian quantile models for in-depth statistical analysis. TFP was found to have a complex non-linear structure, and physical and human capital deepening indicators show a significant upward trend. The deepening of physical capital has a negative impact on TFP, while the deepening of human capital has a positive impact. In the capital deepening structure, the level of TFP has been improved and its structure optimized. Primary human and non-production physical capital deepening has no significant effect on TFP, while secondary human capital deepening has some significant effects on TFP. Tertiary and productive human capital deepening of TFP present two different forms of significant effect: the influence coefficient of the former declines in the increasing quantile and the change is larger, while the latter has a stable negative impact. The results of this study provide insights in terms of the improvement of China's productivity.																	1343-0130	1883-8014				JUL	2020	24	4					524	531															
J								Terrain Hazard Risk Analysis for Flood Disaster Management in Chaohu Basin, China, Based on Two-Dimensional Cloud	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										cloud model; risk assessment; terrain hazard; two-dimensional cloud reasoning; Chaohu Basin		Terrain analysis is essential to flood disaster risk evaluation. It is a complicated evaluation process, involving both quantitative and qualitative data analysis. However, quantitative and qualitative data cannot be put into operation directly. Based on stochastic and fuzzy mathematics, cloud models allow interchange between qualitative and quantitative data, dealing with randomness and ambiguity. Two- or multi-dimensional cloud models can solve the problem of multivariable analysis. This study used absolute elevation and neighborhood elevation standard deviation as main factors. Using the model, it demonstrated the construction of qualitative conditions and risk evaluation clouds and established a set of two-dimensional cloud reasoning rules to calculate the joint certainties with all the grids in reasoning rules. By selecting the highest certainty of cloud reasoning, preliminary evaluation results were obtained. For more accurate results, the model algorithm was improved, and further iterations were performed. The results of two-dimensional cloud reasoning showed better dispersion and precision than traditional methods did. The terrain risk distribution of Chaohu Basin, China, agreed with reality with great detail. A newmethod regarding the risk assessment of flood disaster was also proposed.																	1343-0130	1883-8014				JUL	2020	24	4					532	542		10.20965/jaciii.2020.p0532													
J								Determining the Most Effective Way of Ensuring a Tidying-Up Behavior: Comparison of Effects of Reminders Using Oral Instruction, Posters, and Robots	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										tidying up; human-robot interaction; encouragement		A common method for encouraging a user to tidy up his/her office or school desk is to provide oral instructions or displaying posters. Some researchers have proposed a robot system to encourage users to tidy up. However, little attention has been paid to performing a comparative analysis of the various methods for motivating users to tidy up. In this study, we investigated the effects of motivating participants using verbal reminders, posters, and robots. Our results showed that urging users using vibrations produced by a robot is more effective than using oral instructions or posters. Particularly, using a robot is effective in reducing microslips and maintaining the motivation for tidying up.																	1343-0130	1883-8014				JUL	2020	24	4					543	548															
J								Bifurcation Analysis of a Class Fractional-Oder Nonlinear Chua's Circuit System	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										bifurcation; Chua's circuit system; fractional-order system; stability	STABILITY ANALYSIS; OSCILLATOR; CHAOS	In recent years, with the rapid development of science and technology, dynamic characterization and control of the research circuit system has become not only theoretical but also practical consideration in academic research and practical engineering applications. Therefore, the complex behavior of a research circuit system has become a hot spot in the theoretical field. This thesis is aimed toward the stability criterion and bifurcation of the fractional-order Chua's circuit system. Despite numerous studies relating to the Chua's system, most of them focus on its sum of delays. Different from traditional bifurcation analysis of Chua's circuit system, the parameters are chosen as the bifurcation parameters in this paper such that the stability and bifurcation of the fractional-order Chua's system is analyzed from a new angle. Then, the conditions of the existence for Hopf bifurcations are achieved by analyzing its characteristic equation. Finally, the validity and rationality of the theory are verified by numerical simulation.																	1343-0130	1883-8014				JUL	2020	24	4					549	556		10.20965/jaciii.2020.p0549													
J								An Approach to NMT Re-Ranking Using Sequence-Labeling for Grammatical Error Correction	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										grammatical error correction; neural machine translation; transformer; sequence-labeling	NETWORK	An approach to N-best hypotheses re-ranking using a sequence-labeling model is applied to resolve the data deficiency problem in Grammatical Error Correction (GEC). Multiple candidate sentences are generated using a Neural Machine Translation (NMT) model; thereafter, these sentences are re-ranked via a stacked Transformer following a Bidirectional Long Short-Term Memory (BiLSTM) with Conditional Random Field (CRF). Correlations within the sentences are extracted using the sequence-labeling model based on the Transformer, which is particularly suitable for long sentences. Meanwhile, the knowledge from a large amount of unlabeled data is acquired through the pre-trained structure. Thus, completely revised sentences are adopted instead of partially modified sentences. Compared with conventional NMT, experiments on the NUCLE and FCE datasets demonstrate that the model improves the F-0.5 score by 8.22% and 2.09%, respectively. As an advantage, the proposed re-ranking method has the advantage of only requires a small set of easily computed features that do not need linguistic inputs.																	1343-0130	1883-8014				JUL	2020	24	4					557	567															
J								VGG-16 Convolutional Neural Network-Oriented Detection of Filling Flow Status of Viscous Food	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										filling flow; liquid-level detection; threshold segmentation; transfer learning		A method is proposed to detect the filling flow status for automatic filling of thick liquid food. The method is based on a convolutional neural network algorithm and it solves the problem of poor accuracy in traditional flow detection devices. An adaptive threshold segmentation algorithm was first used to extract the region of interest for the acquired level image. Next, normalization and augmentation treatment were performed on the extracted images to construct a flow status dataset. A VGG-16 network trained on an ImageNet dataset was then used for isomorphic data-oriented feature migration and parameter tuning to automatically extract features and train the model. The identification accuracy and error rate of the network were verified and the advantages and disadvantages of the proposed method were compared to those of other methods. The experimental results demonstrated that the algorithm effectively detects multi-category flow status information and complies with the requirements for actual production.																	1343-0130	1883-8014				JUL	2020	24	4					568	575															
J								Non-convex Total Variation Regularization for Convex Denoising of Signals	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Signal denoising; Total variation regularization; Forward-backward splitting algorithm; Convex non-convex regularization	MINIMAX-CONCAVE PENALTY; SPARSE REGULARIZATION; NOISE REMOVAL; ALGORITHM; OPTIMIZATION; MINIMIZATION; SELECTION; RECOVERY; MODEL	Total variation (TV) signal denoising is a popular nonlinear filtering method to estimate piecewise constant signals corrupted by additive white Gaussian noise. Following a 'convex non-convex' strategy, recent papers have introduced non-convex regularizers for signal denoising that preserve the convexity of the cost function to be minimized. In this paper, we propose a non-convex TV regularizer, defined using concepts from convex analysis, that unifies, generalizes, and improves upon these regularizers. In particular, we use the generalized Moreau envelope which, unlike the usual Moreau envelope, incorporates a matrix parameter. We describe a novel approach to set the matrix parameter which is essential for realizing the improvement we demonstrate. Additionally, we describe a new set of algorithms for non-convex TV denoising that elucidate the relationship among them and which build upon fast exact algorithms for classical TV denoising.																	0924-9907	1573-7683				JUL	2020	62	6-7			SI		825	841		10.1007/s10851-019-00937-5													
J								Stable Backward Diffusion Models that Minimise Convex Energies	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Inverse problem; Backward diffusion; Modelling; Convex energy; Gradient descent; Contrast enhancement; Image processing	HISTOGRAM SPECIFICATION; STABILITY ANALYSIS; IMAGE-ENHANCEMENT; ALGORITHMS; REGULARIZATION; EQUALIZATION; HUE	The inverse problem of backward diffusion is known to be ill-posed and highly unstable. Backward diffusion processes appear naturally in image enhancement and deblurring applications. It is therefore greatly desirable to establish a backward diffusion model which implements a smart stabilisation approach that can be used in combination with an easy-to-handle numerical scheme. So far, existing stabilisation strategies in the literature require sophisticated numerics to solve the underlying initial value problem. We derive a class of space-discrete one-dimensional backward diffusion as gradient descent of energies where we gain stability by imposing range constraints. Interestingly, these energies are even convex. Furthermore, we establish a comprehensive theory for the time-continuous evolution and we show that stability carries over to a simple explicit time discretisation of our model. Finally, we confirm the stability and usefulness of our technique in experiments in which we enhance the contrast of digital greyscale and colour images.																	0924-9907	1573-7683				JUL	2020	62	6-7			SI		941	960		10.1007/s10851-020-00976-3													
J								Multilayer Joint Segmentation Using MRF and Graph Cuts	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Multiple images; Markov random field; Segmentation; Graph cuts; Hyperspectral images	IMAGE SEGMENTATION; ENERGY MINIMIZATION	The problem of jointly segmenting objects, according to a set of labels (of cardinalityL), from a set of images (of cardinalityK) to produceKindividual segmentations plus one joint segmentation, can be cast as a Markov random field model. Coupling terms in the considered energy function enforce the consistency between the individual segmentations and the joint segmentation. However, neither optimality on the minimizer (at least for particular cases), nor the sensitivity of the parameters, nor the robustness of this approach against standard ones has been clearly discussed before. This paper focuses on the case whereL>1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$L>1$$\end{document},K>1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$K>1$$\end{document}and the segmentation problem is handled using graph cuts. Noticeably, some properties of the considered energy function are demonstrated, such as global optimality whenL=2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$L=2$$\end{document}andK>1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$K>1$$\end{document}, the link with majority voting and the link with naive Bayes segmentation. Experiments on synthetic and real images depict superior segmentation performance and better robustness against noisy observations.																	0924-9907	1573-7683				JUL	2020	62	6-7			SI		961	981		10.1007/s10851-019-00938-4													
J								Unsupervised Assignment Flow: Label Learning on Feature Manifolds by Spatially Regularized Geometric Assignment	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Assignment flow; Divergence function; Feature manifolds; Unsupervised learning; Information geometry	MEAN SHIFT; DIVERGENCE	This paper introduces theunsupervised assignment flowthat couples the assignment flow for supervised image labeling (angstrom strom et al. in J Math Imaging Vis 58(2):211-238,2017) with Riemannian gradient flows for label evolution on feature manifolds. The latter component of the approach encompasses extensions of state-of-the-art clustering approaches to manifold-valued data. Coupling label evolution with the spatially regularized assignment flow induces a sparsifying effect that enables to learn compact label dictionaries in an unsupervised manner. Our approach alleviates the requirement for supervised labeling to have proper labels at hand, because an initial set of labels can evolve and adapt to better values while being assigned to given data. The separation between feature and assignment manifolds enables the flexible application which is demonstrated for three scenarios with manifold-valued features. Experiments demonstrate a beneficial effect in both directions: adaptivity of labels improves image labeling, and steering label evolution by spatially regularized assignments leads to proper labels, because the assignment flow for supervised labeling is exactly used without any approximation for label learning.																	0924-9907	1573-7683				JUL	2020	62	6-7			SI		982	1006		10.1007/s10851-019-00935-7													
J								Correcting the Side Effects of ADC Filtering in MR Image Reconstruction	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Sampling theory; Analog-to-Digital Converter; Magnetic resonance imaging; Filtering effect; Model-based image restoration	RECEIVER; SCHEMES; DESIGN; SENSE	This work investigates the role of the filters implemented on analog-to-digital converters for the reconstruction of magnetic resonance images. We analyze the effects of these filters both from a theoretical and an experimental point of view and demonstrate how it may lead to severe degradation of the reconstructed images when the distance between consecutive samples is larger than Shannon's limit. Based on these findings, we propose a mathematical model and a numerical algorithm that allow to mitigate such filtering effects both for linear and nonlinear reconstructions. Experiments on simulated and real data on a 7 Tesla scanner show that the proposed ideas allow to significantly improve the overall image quality. These findings are particularly relevant for high resolution imaging and for recent sampling schemes saturating the maximum gradient amplitude. They also open new challenges in sampling theory.																	0924-9907	1573-7683				JUL	2020	62	6-7			SI		1034	1047		10.1007/s10851-019-00940-w													
J								Detection of Compromised Online Social Network Account with an Enhanced Knn	APPLIED ARTIFICIAL INTELLIGENCE										Online Social Network; Compromised Account; WE-KNN		The primary threat to online social network (OSN) users is account compromisation. The challenge in detecting a compromised account is due to the trusted relationship established between the account owners, their friends, and the service providers. The available research which focuses on using machine learning has limitations with human experts involved in feature selection and a standardized dataset. The paper discusses users` various behaviors of users of OSN and the up-to-date approaches in detecting a compromised OSN account with emphasis on the limitations and challenges. Furthermore, we propose an enhanced machine learning approach Word Embedding and KNN (WE-KNN), which addresses the limitations faced by the previous techniques used. We detailed our proposed WE-KNN for feature extraction, selection of behavior of OSN users, and classification. Our proposed model is evaluated using the standard benchmark datasets, namely KDD Cup '99 and NSL-KDD and implemented it in WEKA. Besides, we used state-of-the-art evaluation metrics to assess the performance of our model. The results obtained depicts that the proposed approach in compromise account detection performs better.																	0883-9514	1087-6545				SEP 18	2020	34	11					777	791		10.1080/08839514.2020.1782002		JUL 2020											
J								Robust speed prediction of high-speed trains based on improved echo state networks	NEURAL COMPUTING & APPLICATIONS										High-speed train; Speed prediction model; Echo state networks; Scaling random weights; Temporal scale selection	FAULT-TOLERANT CONTROL; UNIFORM STABILITY; NEURAL-NETWORKS; PARTICLE SWARM; MODEL ORDER; OPTIMIZATION; SYSTEMS; CONVERGENCE; EXISTENCE; SELECTION	The accurate and robust speed prediction of high-speed trains (HSTs) is a challenging task in the automatic train operation (ATO) because HSTs operate in an open-air situation with much noise and many uncertainties. This paper contributes to the development of robust speed prediction methods for the ATO of HSTs based on improved echo state networks (ESNs). Firstly, an adaptive temporal scale selection approach is introduced to improve the accuracy and efficiency of ESN modeling, due to the importance of proper temporal scale selection in relation to the sound prediction performance of ESNs. Also, a random weight scaling mechanism is employed to enhance the feasibility and robustness of the proposed method, as the learning ability of ESNs lies in the constrained random connection weights. Furthermore, several conditions for the stability of the closed-loop control system are given. Our experiment results demonstrate that the proposed method successfully achieves sound performance in terms of speed prediction accuracy, efficiency and robustness.																	0941-0643	1433-3058															10.1007/s00521-020-05096-y		JUL 2020											
J								A permutation entropy-based EMD-ANN forecasting ensemble approach for wind speed prediction	NEURAL COMPUTING & APPLICATIONS										Wind speed prediction; Ensemble learning; Empirical mode decomposition; Permutation entropy; Artificial neural networks	EMPIRICAL MODE DECOMPOSITION; NEURAL-NETWORK; TIME-SERIES; ALGECIRAS; POWER; BAY; REGION; SPAIN; CO	Accurate wind speed prediction is critical for many tasks, especially for air pollution modelling. Data-driven approaches are particularly interesting but the stochastic nature of wind renders prediction tasks difficult. Therefore, a combination of methods could be useful to obtain better results. To overcome this difficulty, a hybrid wind speed forecasting approach is proposed in this work. The Bay of Algeciras, Spain, was used as a case study, and the database was collected from a weather monitoring station. The study consists of combining a pre-processing method, the empirical mode decomposition (EMD), an information-based method, the permutation entropy (PE), and a machine learning technique (artificial neural networks, ANNs), using an ensemble learning methodology. Different prediction horizons were considered: ph-hours (ph = 1, 2, 8, 24) ahead and 8-h and 24-h average. The introduction of PE significantly reduces the computational cost and the predictive risk in comparison with traditional EMD methodology, by reducing the number of the decomposed components to be predicted. Moreover, the experimental results demonstrated that the EMD-PE-ANN approach outperforms the prediction performance of the single ANN models in all the prediction horizons tested. The EMD-PE-ANN model is capable to achieve a correlation coefficient of 0.981 and 0.807 for short-term (1 h) and medium-term (24 h) predictions, respectively, significantly overcoming those obtained by a single ANN model (0.929 and 0.503). These results show that the proposed model reaches significant improvements when the prediction horizon increases, where forecasting models tend to worsen their prediction performance. Therefore, the proposed EMD-PE-ANN approach may become a powerful tool for wind speed forecasting.																	0941-0643	1433-3058															10.1007/s00521-020-05141-w		JUL 2020											
J								An improved evolution fruit fly optimization algorithm and its application	NEURAL COMPUTING & APPLICATIONS										Fruit fly optimization algorithm; Evolution mechanism; Swarm intelligence	PARTICLE SWARM OPTIMIZATION; ENGINEERING OPTIMIZATION; NEURAL-NETWORK; DESIGN; MODEL; CONTROLLER; INTEGER; PERFORM	Fruit fly optimization algorithm (FOA) is a kind of swarm intelligence optimization algorithm, which has been widely applied in science and engineering fields. The aim of this study is to design an improved FOA, namely evolution FOA (EFOA), which can overcome some shortcomings of basic FOA, including difficulty in local optimization, slow convergence speed, and lack of robustness. EFOA applies a few new strategies which adaptively control the search steps and swarm numbers of the fruit flies. The evolution mechanism used in EFOA can preserve dominant swarms and remove inferior swarms. Comprehensive comparison experiments are performed to compare EFOA with other swarm intelligence algorithms through 14 benchmark functions and a constrained engineering problem. Experimental results suggest that EFOA performs well both in global search ability and in robustness, and it can improve convergence speed.																	0941-0643	1433-3058				JUL	2020	32	14					9897	9914		10.1007/s00521-019-04512-2													
J								Insights Into Multiple/Single Lower Bound Approximation for Extended Variational Inference in Non-Gaussian Structured Data Modeling	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Bayes methods; Linear programming; Convergence; Computational modeling; Data models; Maximum likelihood estimation; Beyesian estimation; extended variational inference (EVI); lower bound approximation; non-Gaussian statistical models; structured data	INVERTED DIRICHLET MIXTURES; OBJECT DETECTION; BAYESIAN-INFERENCE; FEATURE-SELECTION; TEXT; ALGORITHM; CLASSIFICATION; GENERATION	For most of the non-Gaussian statistical models, the data being modeled represent strongly structured properties, such as scalar data with bounded support (e.g., beta distribution), vector data with unit length (e.g., Dirichlet distribution), and vector data with positive elements (e.g., generalized inverted Dirichlet distribution). In practical implementations of non-Gaussian statistical models, it is infeasible to find an analytically tractable solution to estimating the posterior distributions of the parameters. Variational inference (VI) is a widely used framework in Bayesian estimation. Recently, an improved framework, namely, the extended VI (EVI), has been introduced and applied successfully to a number of non-Gaussian statistical models. EVI derives analytically tractable solutions by introducing lower bound approximations to the variational objective function. In this paper, we compare two approximation strategies, namely, the multiple lower bounds (MLBs) approximation and the single lower bound (SLB) approximation, which can be applied to carry out the EVI. For implementation, two different conditions, the weak and the strong conditions, are discussed. Convergence of the EVI depends on the selection of the lower bound, regardless of the choice of weak or strong condition. We also discuss the convergence properties to clarify the differences between MLB and SLB. Extensive comparisons are made based on some EVI-based non-Gaussian statistical models. Theoretical analysis is conducted to demonstrate the differences between the weak and strong conditions. Experimental results based on real data show advantages of the SLB approximation over the MLB approximation.																	2162-237X	2162-2388				JUL	2020	31	7					2240	2254		10.1109/TNNLS.2019.2899613													
J								Multioutput Convolution Spectral Mixture for Gaussian Processes	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Kernel; Convolution; Delays; Correlation; Gaussian processes; Frequency-domain analysis; Delay effects; Convolution; Gaussian processes (GPs); multioutput; spectral mixture (SM); time and phase delay	LIBRARY	Multioutput Gaussian processes (MOGPs) are an extension of Gaussian processes (GPs) for predicting multiple output variables (also called channels/tasks) simultaneously. In this article, we use the convolution theorem to design a new kernel for MOGPs by modeling cross-channel dependencies through cross convolution of time-and phase-delayed components in the spectral domain. The resulting kernel is called multioutput convolution spectral mixture (MOCSM) kernel. The results of extensive experiments on synthetic and real-life data sets demonstrate the advantages of the proposed kernel and its state-of-the-art performance. MOCSM enjoys the desirable property to reduce to the well-known spectral mixture (SM) kernel when a single channel is considered. A comparison with the recently introduced multioutput SM kernel reveals that this is not the case for the latter kernel, which contains quadratic terms that generate undesirable scale effects when the spectral densities of different channels are either very close or very far from each other in the frequency domain.																	2162-237X	2162-2388				JUL	2020	31	7					2255	2266		10.1109/TNNLS.2019.2946082													
J								Learning With Interpretable Structure From Gated RNN	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Logic gates; Recurrent neural networks; Clustering methods; Task analysis; Predictive models; Machine learning; Semantics; Finite-state automata (FSAs); gated unit; interpretability; machine learning; recurrent neural network (RNN); structured output	NEURAL-NETWORKS; MACHINE; EXTRACTION	The interpretability of deep learning models has raised extended attention these years. It will be beneficial if we can learn an interpretable structure from deep learning models. In this article, we focus on recurrent neural networks (RNNs), especially gated RNNs whose inner mechanism is still not clearly understood. We find that finite-state automaton (FSA) that processes sequential data have a more interpretable inner mechanism according to the definition of interpretability and can be learned from RNNs as the interpretable structure. We propose two methods to learn FSA from RNN based on two different clustering methods. With the learned FSA and via experiments on artificial and real data sets, we find that FSA is more trustable than the RNN from which it learned, which gives FSA a chance to substitute RNNs in applications involving humans' lives or dangerous facilities. Besides, we analyze how the number of gates affects the performance of RNN. Our result suggests that gate in RNN is important but the less the better, which could be a guidance to design other RNNs. Finally, we observe that the FSA learned from RNN gives semantic aggregated states, and its transition graph shows us a very interesting vision of how RNNs intrinsically handle text classification tasks.																	2162-237X	2162-2388				JUL	2020	31	7					2267	2279		10.1109/TNNLS.2020.2967051													
J								Distributed Selection of Continuous Features in Multilabel Classification Using Mutual Information	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Entropy; Redundancy; Learning systems; Mutual information; Computational modeling; Cluster computing; Apache spark; distributed computing; feature selection; multilabel learning; mutual information (MI)	LABEL FEATURE-SELECTION; TRANSFORMATION	Multilabel learning is a challenging task demanding scalable methods for large-scale data. Feature selection has shown to improve multilabel accuracy while defying the curse of dimensionality of high-dimensional scattered data. However, the increasing complexity of multilabel feature selection, especially on continuous features, requires new approaches to manage data effectively and efficiently in distributed computing environments. This article proposes a distributed model for mutual information (MI) adaptation on continuous features and multiple labels on Apache Spark. Two approaches are presented based on MI maximization, and minimum redundancy and maximum relevance. The former selects the subset of features that maximize the MI between the features and the labels, whereas the latter additionally minimizes the redundancy between the features. Experiments compare the distributed multilabel feature selection methods on 10 data sets and 12 metrics. Results validated through statistical analysis indicate that our methods outperform reference methods for distributed feature selection for multilabel data, while MIM also reduces the runtime in orders of magnitude.																	2162-237X	2162-2388				JUL	2020	31	7					2280	2293		10.1109/TNNLS.2019.2944298													
J								Reconstruction Regularized Deep Metric Learning for Multi-Label Image Classification	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Measurement; Correlation; Image reconstruction; Learning systems; Deep learning; Neural networks; Semantics; Deep metric learning; multi-label image classification; reconstruction regularization		In this paper, we present a novel deep metric learning method to tackle the multi-label image classification problem. In order to better learn the correlations among images features, as well as labels, we attempt to explore a latent space, where images and labels are embedded via two unique deep neural networks, respectively. To capture the relationships between image features and labels, we aim to learn a two-way deep distance metric over the embedding space from two different views, i.e., the distance between one image and its labels is not only smaller than those distances between the image and its labels' nearest neighbors but also smaller than the distances between the labels and other images corresponding to the labels' nearest neighbors. Moreover, a reconstruction module for recovering correct labels is incorporated into the whole framework as a regularization term, such that the label embedding space is more representative. Our model can be trained in an end-to-end manner. Experimental results on publicly available image data sets corroborate the efficacy of our method compared with the state of the arts.																	2162-237X	2162-2388				JUL	2020	31	7					2294	2303		10.1109/TNNLS.2019.2924023													
J								RoSeq: Robust Sequence Labeling	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Noise measurement; Task analysis; Hidden Markov models; Labeling; Twitter; Training; Data models; Label imbalance; named entity recognition (NER); sequence labeling		In this paper, we mainly investigate two issues for sequence labeling, namely, label imbalance and noisy data that are commonly seen in the scenario of named entity recognition (NER) and are largely ignored in the existing works. To address these two issues, a new method termed robust sequence labeling (RoSeq) is proposed. Specifically, to handle the label imbalance issue, we first incorporate label statistics in a novel conditional random field (CRF) loss. In addition, we design an additional loss to reduce the weights of overwhelming easy tokens for augmenting the CRF loss. To address the noisy training data, we adopt an adversarial training strategy to improve model generalization. In experiments, the proposed RoSeq achieves the state-of-the-art performances on CoNLL and English Twitter NER-88.07% on CoNLL-2002 Dutch, 87.33% on CoNLL-2002 Spanish, 52.94% on WNUT-2016 Twitter, and 43.03% on WNUT-2017 Twitter without using the additional data.																	2162-237X	2162-2388				JUL	2020	31	7					2304	2314		10.1109/TNNLS.2019.2911236													
J								Does Tail Label Help for Large-Scale Multi-Label Learning?	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Predictive models; Measurement; Training; Prediction algorithms; Correlation; Sparse matrices; Learning systems; Large-scale multi-label learning (LMLL); performance metric; scalability; tail label		Large-scale multi-label learning (LMLL) annotates relevant labels for unseen data from a huge number of candidate labels. It is perceived that labels exhibit a long tail distribution in which a significant number of labels are tail labels. Most previous studies consider that the performance would benefit from incorporating tail labels. Nonetheless, it is not quantified how tail labels impact the performance. In this article, we disclose that whatever labels are randomly missing or misclassified, the impact of labels on commonly used LMLL evaluation metrics (Propensity Score Precision (PSP)@k and Propensity Score nDCG (PSnDCG)@k) is directly related to the product of the label weights and the label frequencies. In particular, when labels share equal weights, tail labels impact much less than common labels due to the scarcity of relevant examples. Based on such observation, we propose to develop low-complexity LMLL methods with the goal of facilitating fast prediction time and compact model size by restraining less performance-influential labels. With the consideration that discarding labels may cause the loss of predictive capability, we further propose to preserve dominant model parameters for the less performance-influential labels. Experiments clearly justify that both the prediction time and the model size are significantly reduced without sacrificing much predictive performance.																	2162-237X	2162-2388				JUL	2020	31	7					2315	2324		10.1109/TNNLS.2019.2935143													
J								GANE: A Generative Adversarial Network Embedding	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Task analysis; Generators; Generative adversarial networks; Predictive models; Machine learning; Linear programming; Gallium nitride; Generative adversarial model; link prediction; network alignment; network embedding; Wasserstein distance		Network embedding is capable of providing low-dimensional feature representations for various machine learning applications. Current work focuses on: 1) designing the embedding as an unsupervised learning task to explicitly preserve the structural connectivity in the network or 2) generating the embedding as a by-product during the supervised learning of a specific discriminative task in a deep neural network. In this paper, we aim to take advantage of these two lines of research in the view of multi-output learning. That is, we propose a generative adversarial network embedding (GANE) model to adapt the generative adversarial framework to achieve the network embedding learning during the specific machine learning tasks. GANE has a generator to generate link edges, and a discriminator to distinguish the generated link edges from real connections (edges) in the network. Wasserstein-1 distance is adopted to train the generator to gain better stability. GANE is further extended by utilizing the pairwise connectivity of vertices to preserve the structural information in the original network. Experiments with real-world network data sets demonstrate that our models constantly outperform state-of-the-art solutions with significant improvements for the tasks of link prediction, clustering, and network alignment.																	2162-237X	2162-2388				JUL	2020	31	7					2325	2335		10.1109/TNNLS.2019.2921841													
J								Dynamically Spatiotemporal Regularized Correlation Tracking	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Visualization; Spatiotemporal phenomena; Correlation; Target tracking; Learning systems; Object tracking; Alternative direction method; correlation filter (CF); spatiotemporal regularization; visual tracking	VISUAL TRACKING	Recently, due to the high performance, spatially regularized strategy has been widely applied to addressing the issue of boundary effects existed in correlation filter (CF)-based visual tracking. Specifically, it introduces a spatially regularized term to penalize the coefficients of the CFs to be learned depending on their spatial locations. However, the regularization weights are often formed as a fixed Gaussian function, and hence may cause the learned model degenerate due to the inflexible constraints on the ever-changing CFs to be learned over time during tracking. To address this issue, in this paper, we develop a dynamically spatiotemporal regularization model to constrain the CFs to be learned with the ever-changing regularization weights learned from two consecutive frames. The proposed method jointly learns the CFs along with the dynamically spatiotemporal constraint term, which can be efficiently solved in the Fourier domain by the alternative direction method. Extensive evaluations on the popular data sets OTB-100 and VOT-2016 demonstrate that the proposed tracker performs favorably against the baseline tracker and several recently proposed state-of-the-art methods.																	2162-237X	2162-2388				JUL	2020	31	7					2336	2347		10.1109/TNNLS.2019.2929407													
J								Exploiting Web Images for Multi-Output Classification: From Category to Subcategories	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Noise measurement; Manuals; Labeling; Learning systems; Visualization; Task analysis; Annotations; Image categorization; subcategorization; untagged corpora; Web images		Studies present that dividing categories into subcategories contributes to better image classification. Existing image subcategorization works relying on expert knowledge and labeled images are both time-consuming and labor-intensive. In this article, we propose to select and subsequently classify images into categories and subcategories. Specifically, we first obtain a list of candidate subcategory labels from untagged corpora. Then, we purify these subcategory labels through calculating the relevance to the target category. To suppress the search error and noisy subcategory label-induced outlier images, we formulate outlier images removing and the optimal classification models learning as a unified problem to jointly learn multiple classifiers, where the classifier for a category is obtained by combining multiple subcategory classifiers. Compared with the existing subcategorization works, our approach eliminates the dependence on expert knowledge and labeled images. Extensive experiments on image categorization and subcategorization demonstrate the superiority of our proposed approach.																	2162-237X	2162-2388				JUL	2020	31	7					2348	2360		10.1109/TNNLS.2020.2966644													
J								A Probabilistic Zero-Shot Learning Method via Latent Nonnegative Prototype Synthesis of Unseen Classes	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Prototypes; Visualization; Training; Artificial neural networks; Probabilistic logic; Semantics; Covariance matrices; Nonnegative matrix factorization (NMF); prototype synthesis; triplet network; zero-shot learning (ZSL)		Zero-shot learning (ZSL), a type of structured multioutput learning, has attracted much attention due to its requirement of no training data for target classes. Conventional ZSL methods usually project visual features into semantic space and assign labels by finding their nearest prototypes. However, this type of nearest neighbor search (NNS)-based method often suffers from great performance degradation because of the nonuniform variances between different categories. In this article, we propose a probabilistic framework by taking covariance into account to deal with the above-mentioned problem. In this framework, we define a new latent space, which has two characteristics. The first is that the features in this space should gather within the classes and scatter between the classes, which is implemented by triplet learning; the second is that the prototypes of unseen classes are synthesized with nonnegative coefficients, which are generated by nonnegative matrix factorization (NMF) of relations between the seen classes and the unseen classes in attribute space. During training, the learned parameters are the projection model for triplet network and the nonnegative coefficients between the unseen classes and the seen classes. In the testing phase, visual features are projected into latent space and assigned with the labels that have the maximum probability among unseen classes for classic ZSL or within all classes for generalized ZSL. Extensive experiments are conducted on four popular data sets, and the results show that the proposed method can outperform the state-of-the-art methods in most circumstances.																	2162-237X	2162-2388				JUL	2020	31	7					2361	2375		10.1109/TNNLS.2019.2955157													
J								Adaptive Kernel Value Caching for SVM Training	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Training; Support vector machines; Kernel; Libraries; Learning systems; Adaptive systems; Runtime; Caching; efficiency; kernel values; support vector machines (SVMs)		Support vector machines (SVMs) can solve structured multioutput learning problems such as multilabel classification, multiclass classification, and vector regression. SVM training is expensive, especially for large and high-dimensional data sets. The bottleneck of the SVM training often lies in the kernel value computation. In many real-world problems, the same kernel values are used in many iterations during the training, which makes the caching of kernel values potentially useful. The majority of the existing studies simply adopt the least recently used (LRU) replacement strategy for caching kernel values. However, as we analyze in this article, the LRU strategy generally achieves high hit ratio near the final stage of the training but does not work well in the whole training process. Therefore, we propose a new caching strategy called EFU (less frequently used), which replaces the EFU kernel values that enhance least frequently used (LFU). Our experimental results show that EFU often has 20% higher hit ratio than LRU in the training with the Gaussian kernel. To further optimize the strategy, we propose a caching strategy called hybrid caching for the SVM training (HCST), which has a novel mechanism to automatically adapt the better caching strategy in different stages of the training. We have integrated the caching strategy into ThunderSVM, a recent SVM library on many-core processors. Our experiments show that HCST adaptively achieves high hit ratios with little runtime overhead among different problems including multilabel classification, multiclass classification, and regression problems. Compared with other existing caching strategies, HCST achieves 20% more reduction in training time on average.																	2162-237X	2162-2388				JUL	2020	31	7					2376	2386		10.1109/TNNLS.2019.2944562													
J								Domain Adaptation With Neural Embedding Matching	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptation models; Data models; Neural networks; Predictive models; Nanoelectromechanical systems; Analytical models; Kernel; Distribution matching; domain adaptation; neural embedding; progressive learning; semisupervised learning	REGULARIZATION	Domain adaptation aims to exploit the supervision knowledge in a source domain for learning prediction models in a target domain. In this article, we propose a novel representation learning-based domain adaptation method, i.e., neural embedding matching (NEM) method, to transfer information from the source domain to the target domain where labeled data is scarce. The proposed approach induces an intermediate common representation space for both domains with a neural network model while matching the embedding of data from the two domains in this common representation space. The embedding matching is based on the fundamental assumptions that a cross-domain pair of instances will be close to each other in the embedding space if they belong to the same class category, and the local geometry property of the data can be maintained in the embedding space. The assumptions are encoded via objectives of metric learning and graph embedding techniques to regularize and learn the semisupervised neural embedding model. We also provide a generalization bound analysis for the proposed domain adaptation method. Meanwhile, a progressive learning strategy is proposed and it improves the generalization ability of the neural network gradually. Experiments are conducted on a number of benchmark data sets and the results demonstrate that the proposed method outperforms several state-of-the-art domain adaptation methods and the progressive learning strategy is promising.																	2162-237X	2162-2388				JUL	2020	31	7					2387	2397		10.1109/TNNLS.2019.2935608													
J								Robust Deep Co-Saliency Detection With Group Semantic and Pyramid Attention	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Semantics; Visualization; Feature extraction; Robustness; Saliency detection; Learning systems; Machine learning; Co-saliency; deep learning; group semantic; pyramid attention	MODEL	High-level semantic knowledge in addition to low-level visual cues is essentially crucial for co-saliency detection. This article proposes a novel end-to-end deep learning approach for robust co-saliency detection by simultaneously learning high-level groupwise semantic representation as well as deep visual features of a given image group. The interimage interaction at the semantic level and the complementarity between the group semantics and visual features are exploited to boost the inferring capability of co-salient regions. Specifically, the proposed approach consists of a co-category learning branch and a co-saliency detection branch. While the former is proposed to learn a groupwise semantic vector using co-category association of an image group as supervision, the latter is to infer precise co-salient maps based on the ensemble of group-semantic knowledge and deep visual cues. The group-semantic vector is used to augment visual features at multiple scales and acts as a top-down semantic guidance for boosting the bottom-up inference of co-saliency. Moreover, we develop a pyramidal attention (PA) module that endows the network with the capability of concentrating on important image patches and suppressing distractions. The co-category learning and co-saliency detection branches are jointly optimized in a multitask learning manner, further improving the robustness of the approach. We construct a new large-scale co-saliency data set COCO-SEG to facilitate research of the co-saliency detection. Extensive experimental results on COCO-SEG and a widely used benchmark Cosal2015 have demonstrated the superiority of the proposed approach compared with state-of-the-art methods.																	2162-237X	2162-2388				JUL	2020	31	7					2398	2408		10.1109/TNNLS.2020.2967471													
J								Survey on Multi-Output Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Task analysis; Data models; Crowdsourcing; Supervised learning; Machine learning; Social networking (online); Tools; Crowdsourcing; extreme classification; label distribution; multi-output learning; output label representation; structured output prediction	NEURAL-NETWORK; CONCEPT DRIFT; IMAGE; SEGMENTATION; RECOGNITION; CLASSIFICATION; CONSISTENCY; MODEL; TEXT; SUPERRESOLUTION	The aim of multi-output learning is to simultaneously predict multiple outputs given an input. It is an important learning problem for decision-making since making decisions in the real world often involves multiple complex factors and criteria. In recent times, an increasing number of research studies have focused on ways to predict multiple outputs at once. Such efforts have transpired in different forms according to the particular multi-output learning problem under study. Classic cases of multi-output learning include multi-label learning, multi-dimensional learning, multi-target regression, and others. From our survey of the topic, we were struck by a lack in studies that generalize the different forms of multi-output learning into a common framework. This article fills that gap with a comprehensive review and analysis of the multi-output learning paradigm. In particular, we characterize the four Vs of multi-output learning, i.e., volume, velocity, variety, and veracity, and the ways in which the four Vs both benefit and bring challenges to multi-output learning by taking inspiration from big data. We analyze the life cycle of output labeling, present the main mathematical definitions of multi-output learning, and examine the field's key challenges and corresponding solutions as found in the literature. Several model evaluation metrics and popular data repositories are also discussed. Last but not least, we highlight some emerging challenges with multi-output learning from the perspective of the four Vs as potential research directions worthy of further studies.																	2162-237X	2162-2388				JUL	2020	31	7					2409	2429		10.1109/TNNLS.2019.2945133													
J								Label-less Learning for Emotion Cognition	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Labeling; Cognition; Data models; Feature extraction; Deep learning; Learning systems; Emotion recognition; Deep learning; emotion detection; label-less learning; multimodal emotion cognition	RECOGNITION	In this paper, we propose a label-less learning for emotion cognition (LLEC) to achieve the utilization of a large amount of unlabeled data. We first inspect the unlabeled data from two perspectives, i.e., the feature layer and the decision layer. By utilizing the similarity model and the entropy model, this paper presents a hybrid label-less learning that can automatically label data without human intervention. Then, we design an enhanced hybrid label-less learning to purify the automatic labeled data. To further improve the accuracy of emotion detection model and increase the utilization of unlabeled data, we apply enhanced hybrid label-less learning for multimodal unlabeled emotion data. Finally, we build a real-world test bed to evaluate the LLEC algorithm. The experimental results show that the LLEC algorithm can improve the accuracy of emotion detection significantly.																	2162-237X	2162-2388				JUL	2020	31	7					2430	2440		10.1109/TNNLS.2019.2929071													
J								Effective Data-Aware Covariance Estimator From Compressed Data	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Covariance matrices; Sparse matrices; Silicon; Estimation; Distributed databases; Learning systems; Dimensionality reduction; Covariance estimation; dimension reduction; randomized algorithms; unsupervised learning	ALGORITHMS; MATRICES	Estimating covariance matrix from massive high-dimensional and distributed data is significant for various real-world applications. In this paper, we propose a data-aware weighted sampling-based covariance matrix estimator, namely DACE, which can provide an unbiased covariance matrix estimation and attain more accurate estimation under the same compression ratio. Moreover, we extend our proposed DACE to tackle multiclass classification problems with theoretical justification and conduct extensive experiments on both synthetic and real-world data sets to demonstrate the superior performance of our DACE.																	2162-237X	2162-2388				JUL	2020	31	7					2441	2454		10.1109/TNNLS.2019.2929106													
J								Robust Student Network Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Perturbation methods; Convolution; Neural networks; Training; Redundancy; Feature extraction; Learning systems; Deep learning; knowledge distillation (KD); teacher-student learning		Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher-student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.																	2162-237X	2162-2388				JUL	2020	31	7					2455	2468		10.1109/TNNLS.2019.2929114													
J								Deep Reinforcement Learning for Sequence-to-Sequence Models	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Actor-critic (AC) methods; deep learning; policy gradients (PGs); Q-learning; reinforcement learning (RL); sequence-to-sequence (seq2seq) learning		In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder-decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.																	2162-237X	2162-2388				JUL	2020	31	7					2469	2489		10.1109/TNNLS.2019.2929141													
J								A Generic Improvement to Deep Residual Networks Based on Gradient Flow	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Deep residual networks; dense-reshape; gradient flow; Image Net-classification; post-activation		Preactivation ResNets consistently outperforms the original postactivation ResNets on the CIFAR10/100 classification benchmark. However, these results surprisingly do not carry over to the standard ImageNet benchmark. First, we theoretically analyze this incongruity in terms of how the two variants differ in handling the propagation of gradients. Although identity shortcuts are critical in both variants for improving optimization and performance, we show that postactivation variants enable early layers to receive a diverse dynamic composition of gradients from effectively deeper paths in comparison to preactivation variants, enabling the network to make maximal use of its representational capacity. Second, we show that downsampling projections (while only a few in number) have a significantly detrimental effect on performance. We show that by simply replacing downsampling projections with identitylike dense-reshape shortcuts, the classification results of standard residual architectures such as ResNets, ResNeXts, and SE-Nets improve by up to 1.2% on ImageNet, without any increase in computational complexity (FLOPs).																	2162-237X	2162-2388				JUL	2020	31	7					2490	2499		10.1109/TNNLS.2019.2929198													
J								Learning Semisupervised Multilabel Fully Convolutional Network for Hierarchical Object Parsing	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Image segmentation; Head; Training; Manifolds; Semantics; Computer science; Neural networks; Fully convolutional network (FCN); hierarchical models; semisupervised learning	SEGMENTATION; FRAMEWORK; MODELS	This article presents a semisupervised multilabel fully convolutional network (FCN) for hierarchical object parsing of images. We consider each object part (e.g., eye and head) as a class label and learn to assign every image pixel to multiple coherent part labels. Different from previous methods that consider part labels as independent classes, our method explicitly models the internal relationships between object parts, e.g., that a pixel highly scored for eyes should be highly scored for heads as well. Such relationships directly reflect the structure of the semantic space and thus should be respected while learning the deep representation. We achieve this objective by introducing a multilabel softmax loss function over both labeled and unlabeled images and regularizing it with two pairwise ranking constraints. The first constraint is based on a manifold assumption that image pixels being visually and spatially close to each other should be collaboratively classified as the same part label. The other constraint is used to enforce that no pixel receives significant scores from more than one label that are semantically conflicting with each other. The proposed loss function is differentiable with respect to network parameters and hence can be optimized by standard stochastic gradient methods. We evaluate the proposed method on two public image data sets for hierarchical object parsing and compare it with the alternative parsing methods. Extensive comparisons showed that our method can achieve state-of-the-art performance while using 50% less labeled training samples than the alternatives.																	2162-237X	2162-2388				JUL	2020	31	7					2500	2509		10.1109/TNNLS.2019.2931183													
J								Semi-Supervised Non-Negative Matrix Factorization With Dissimilarity and Similarity Regularization	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Optimization; Dimensionality reduction; Matrix decomposition; Data models; Numerical models; Kernel; Analytical models; Dimensionality reduction; Karush-Kuhn-Tucker (KKT) conditions; non-negative matrix factorization (NMF); semi-supervised	ROBUST; MODEL	In this article, we propose a semi-supervised non-negative matrix factorization (NMF) model by means of elegantly modeling the label information. The proposed model is capable of generating discriminable low-dimensional representations to improve clustering performance. Specifically, a pair of complementary regularizers, i.e., similarity and dissimilarity regularizers, is incorporated into the conventional NMF to guide the factorization. And, they impose restrictions on both the similarity and dissimilarity of the low-dimensional representations of data samples with labels as well as a small number of unlabeled ones. The proposed model is formulated as a well-posed constrained optimization problem and further solved with an efficient alternating iterative algorithm. Moreover, we theoretically prove that the proposed algorithm can converge to a limiting point that meets the Karush-Kuhn-Tucker conditions. Extensive experiments as well as comprehensive analysis demonstrate that the proposed model outperforms the state-of-the-art NMF methods to a large extent over five benchmark data sets, i.e., the clustering accuracy increases to 82.2% from 57.0%.																	2162-237X	2162-2388				JUL	2020	31	7					2510	2521		10.1109/TNNLS.2019.2933223													
J								Benchmarking Neural Networks For Quantum Computations	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Quantum computing; Computers; Quantum entanglement; Benchmark testing; Biological neural networks; Benchmarking; complex neural network; complexity; entanglement; quantum computation; quantum machine learning; quantum neural network	ENTANGLEMENT; ALGORITHM	The power of quantum computers is still somewhat speculative. Although they are certainly faster than classical ones at some tasks, the class of problems they can efficiently solve has not been mapped definitively onto known classical complexity theory. This means that we do not know for which calculations there will be a "quantum advantage," once an algorithm is found. One way to answer the question is to find those algorithms, but finding truly quantum algorithms turns out to be very difficult. In previous work, over the past three decades, we have pursued the idea of using techniques of machine learning to develop algorithms for quantum computing. Here, we compare the performance of standard real- and complex-valued classical neural networks with that of one of our models for a quantum neural network, on both classical problems and on an archetypal quantum problem: the computation of an entanglement witness. The quantum network is shown to need far fewer epochs and a much smaller network to achieve comparable or better results.																	2162-237X	2162-2388				JUL	2020	31	7					2522	2531		10.1109/TNNLS.2019.2933394													
J								Adaptive Neural Network Finite-Time Control for Multi-Input and Multi-Output Nonlinear Systems With Positive Powers of Odd Rational Numbers	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Nonlinear systems; Adaptive systems; MIMO communication; Artificial neural networks; Control systems; Stability criteria; Adaptive neural network (NN) control; adding a power integrator technique; backstepping design; finite-time stability; nonlinear systems; powers of odd rational numbers	DYNAMIC SURFACE CONTROL; VARYING DELAY SYSTEMS; UNKNOWN DEAD-ZONES; TRACKING CONTROL; OUTPUT TRACKING; STABILIZATION; STATE; EXOSKELETON	This article investigates the adaptive neural network (NN) finite-time output tracking control problem for a class of multi-input and multi-output (MIMO) uncertain nonlinear systems whose powers are positive odd rational numbers. Such designs adopt NNs to approximate unknown continuous system functions, and a controller is constructed by combining backstepping design and adding a power integrator technique. By constructing new iterative Lyapunov functions and using finite-time stability theory, the closed-loop stability has been achieved, which further verifies that the entire system possesses semiglobal practical finite-time stability (SGPFS), and the tracking errors converge to a small neighborhood of the origin within finite time. Finally, a simulation example is given to elaborate the effectiveness and superiority of the developed.																	2162-237X	2162-2388				JUL	2020	31	7					2532	2543		10.1109/TNNLS.2019.2933409													
J								Pay Attention to Them: Deep Reinforcement Learning-Based Cascade Object Detection	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Detectors; Object detection; Proposals; Image resolution; Intelligent agents; Benchmark testing; Attention; convolutional neural network (CNN); object detection; reinforcement learning (RL)	TOP-DOWN MODULATION	This paper proposes a novel and effective approach, namely pay attention to them (PAT), to general object detection, which integrates the bottom-up single-shot convolutional neural networks (CNNs) and a top-down operating strategy. PAT starts by routinely applying a CNN regression detector to the entire input image. It then conducts refinement, which locates a sub-region that probably contains relevant objects through an intelligent agent built with an attentional mechanism and zooms it in to launch the detector again. This refining step is repeated in a cascaded way, where all the bounding boxes produced are scaled according to the original resolution and the sub-marginal and overlapping parts are wiped out to generate the final output. Due to such progressive processing, PAT improves the detection accuracy, especially for the objects of small sizes. Extensive experiments are conducted on the Pascal VOC and MS COCO benchmarks, and the results show that PAT is able to improve the representative baseline detectors, i.e., single shot multibox detector, YOLOv2, and Faster regions with CNN features, with remarkable accuracy gains [about 2%-5% mean Average Precision (mAP)], which demonstrates its competency.																	2162-237X	2162-2388				JUL	2020	31	7					2544	2556		10.1109/TNNLS.2019.2933451													
J								The Strength of Nesterov's Extrapolation in the Individual Convergence of Nonsmooth Optimization	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convergence; Extrapolation; Optimization; Acceleration; Machine learning; Task analysis; Machine learning algorithms; Individual convergence; machine learning; Nesterov's extrapolation; nonsmooth optimization; sparsity		The extrapolation strategy raised by Nesterov, which can accelerate the convergence rate of gradient descent methods by orders of magnitude when dealing with smooth convex objective, has led to tremendous success in training machine learning tasks. In this article, the convergence of individual iterates of projected subgradient (PSG) methods for nonsmooth convex optimization problems is theoretically studied based on Nesterov's extrapolation, which we name individual convergence. We prove that Nesterov's extrapolation has the strength to make the individual convergence of PSG optimal for nonsmooth problems. In light of this consideration, a direct modification of the subgradient evaluation suffices to achieve optimal individual convergence for strongly convex problems, which can be regarded as making an interesting step toward the open question about stochastic gradient descent (SGD) posed by Shamir. Furthermore, we give an extension of the derived algorithms to solve regularized learning tasks with nonsmooth losses in stochastic settings. Compared with other state-of-the-art nonsmooth methods, the derived algorithms can serve as an alternative to the basic SGD especially in coping with machine learning problems, where an individual output is needed to guarantee the regularization structure while keeping an optimal rate of convergence. Typically, our method is applicable as an efficient tool for solving large-scale l(1)-regularized hinge-loss learning problems. Several comparison experiments demonstrate that our individual output not only achieves an optimal convergence rate but also guarantees better sparsity than the averaged solution.																	2162-237X	2162-2388				JUL	2020	31	7					2557	2568		10.1109/TNNLS.2019.2933452													
J								Debiasing and Distributed Estimation for High-Dimensional Quantile Regression	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Estimation; Distributed databases; Convergence; Learning systems; Parallel processing; Numerical models; Standards; Debiased estimator; distributed estimator; divide and conquer; high-dimensional model	VARIABLE SELECTION; CONFIDENCE-REGIONS; INFERENCE; TESTS	Distributed and parallel computing is becoming more important with the availability of extremely large data sets. In this article, we consider this problem for high-dimensional linear quantile regression. We work under the assumption that the coefficients in the regression model are sparse; therefore, a LASSO penalty is naturally used for estimation. We first extend the debiasing procedure, which is previously proposed for smooth parametric regression models to quantile regression. The technical challenges include dealing with the nondifferentiability of the loss function and the estimation of the unknown conditional density. In this article, the main objective is to derive a divide-and-conquer estimation approach using the debiased estimator which is useful under the big data setting. The effectiveness of distributed estimation is demonstrated using some numerical examples.																	2162-237X	2162-2388				JUL	2020	31	7					2569	2577		10.1109/TNNLS.2019.2933467													
J								Adversarial Examples: Opportunities and Challenges	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Artificial intelligence; Biological neural networks; Neurons; Robots; Perturbation methods; Security; Training; Adversarial examples (AEs); artificial intelligence (AI); deep neural networks (DNNs)	ROBUSTNESS	Deep neural networks (DNNs) have shown huge superiority over humans in image recognition, speech processing, autonomous vehicles, and medical diagnosis. However, recent studies indicate that DNNs are vulnerable to adversarial examples (AEs), which are designed by attackers to fool deep learning models. Different from real examples, AEs can mislead the model to predict incorrect outputs while hardly be distinguished by human eyes, therefore threaten security-critical deep-learning applications. In recent years, the generation and defense of AEs have become a research hotspot in the field of artificial intelligence (AI) security. This article reviews the latest research progress of AEs. First, we introduce the concept, cause, characteristics, and evaluation metrics of AEs, then give a survey on the state-of-the-art AE generation methods with the discussion of advantages and disadvantages. After that, we review the existing defenses and discuss their limitations. Finally, future research opportunities and challenges on AEs are prospected.																	2162-237X	2162-2388				JUL	2020	31	7					2578	2593		10.1109/TNNLS.2019.2933524													
J								Large Margin Partial Label Machine	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Phase locked loops; Training; Support vector machines; Supervised learning; Estimation; Face; Task analysis; Cutting plane (CP); large margin (LM); partial label learning (PLL); weakly supervised learning		Partial label learning (PLL) is a multi-class weakly supervised learning problem where each training instance is associated with a set of candidate labels but only one label is the ground truth. The main challenge of PLL is how to deal with the label ambiguities. Among various disambiguation techniques, large margin (LM)-based algorithms attract much attention due to their powerful discriminative performance. However, existing LM-based algorithms either neglect some potential candidate labels in constructing the margin or introduce auxiliary estimation of class capacities which is generally inaccurate. As a result, their generalization performances are deteriorated. To address the above-mentioned drawbacks, motivated by the optimistic superset loss, we propose an LM Partial LAbel machiNE (LM-PLANE) by extending multi-class support vector machines (SVM) to PLL. Compared with existing LM-based disambiguation algorithms, LM-PLANE considers the margin of all potential candidate labels without auxiliary estimation of class capacities. Furthermore, an efficient cutting plane (CP) method is developed to train LM-PLANE in the dual space. Theoretical insights into the effectiveness and convergence of our CP method are also presented. Extensive experiments on various PLL tasks demonstrate the superiority of LM-PLANE over existing LM based and other representative PLL algorithms in terms of classification accuracy.																	2162-237X	2162-2388				JUL	2020	31	7					2594	2608		10.1109/TNNLS.2019.2933530													
J								A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Anomaly detection; Feature extraction; Neural networks; Training; Event detection; Testing; Optical imaging; Anomaly detection; deep one-class (DeepOC) classifier; learning representation; neural networks; video surveillance	SUPPORT-VECTOR; REPRESENTATION	How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations' diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.																	2162-237X	2162-2388				JUL	2020	31	7					2609	2622		10.1109/TNNLS.2019.2933554													
J								Neural Probabilistic Graphical Model for Face Sketch Synthesis	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Face; Graphical models; Learning systems; Probabilistic logic; Neural networks; Databases; Security; Common structure; face sketch synthesis; neural probabilistic graphical model (NPGM); specific structure	REPRESENTATION	Neural network learning for face sketch synthesis from photos has attracted substantial attention due to its favorable synthesis performance. However, most existing deep-learning-based face sketch synthesis models stacked only by multiple convolutional layers without structured regression often lose the common facial structures, limiting their flexibility in a wide range of practical applications, including intelligent security and digital entertainment. In this article, we introduce a neural network to a probabilistic graphical model and propose a novel face sketch synthesis framework based on the neural probabilistic graphical model (NPGM) composed of a specific structure and a common structure. In the specific structure, we investigate a neural network for mapping the direct relationship between training photos and sketches, yielding the specific information and characteristic features of a test photo. In the common structure, the fidelity between the sketch pixels generated by the specific structure and their candidates selected from the training data are considered, ensuring the preservation of the common facial structure. Experimental results on the Chinese University of Hong Kong face sketch database demonstrate, both qualitatively and quantitatively, that the proposed NPGM-based face sketch synthesis approach can more effectively capture specific features and recover common structures compared with the state-of-the-art methods. Extensive experiments in practical applications further illustrate that the proposed method achieves superior performance.																	2162-237X	2162-2388				JUL	2020	31	7					2623	2637		10.1109/TNNLS.2019.2933590													
J								Backpropagation With N-D Vector-Valued Neurons Using Arbitrary Bilinear Products	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neurons; Artificial neural networks; Tensors; Backpropagation; Quaternions; Fans; Convolution; Backpropagation; bilinear products; vector neural learning; vector neural network (NN); vector products	NEURAL-NETWORKS; DECISION BOUNDARIES; COMPLEX; ALGORITHM; MODELS; SPARSE	Vector-valued neural learning has emerged as a promising direction in deep learning recently. Traditionally, training data for neural networks (NNs) are formulated as a vector of scalars; however, its performance may not be optimal since associations among adjacent scalars are not modeled. In this article, we propose a new vector neural architecture called the Arbitrary BIlinear Product NN (ABIPNN), which processes information as vectors in each neuron, and the feedforward projections are defined using arbitrary bilinear products. Such bilinear products can include circular convolution, 7-D vector product, skew circular convolution, reversed-time circular convolution, or other new products that are not seen in the previous work. As a proof-of-concept, we apply our proposed network to multispectral image denoising and singing voice separation. Experimental results show that ABIPNN obtains substantial improvements when compared to conventional NNs, suggesting that associations are learned during training.																	2162-237X	2162-2388				JUL	2020	31	7					2638	2652		10.1109/TNNLS.2019.2933882													
J								Mask Dynamic Routing to Combined Model of Deep Capsule Network and U-Net	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Routing; Prediction algorithms; Image reconstruction; Clustering algorithms; Data models; Computational modeling; Heuristic algorithms; Capsule network; DCN-UN model; equivariance; mask dynamic routing (DR); reconstruction		The capsule network is a novel architecture to encode feature attributes and spatial relationships of an image. By using the dynamic routing (DR) algorithm, a capsule network (CapsNet) model can be trained. However, the original three-layer CapsNet with the DR algorithm performs poorly on complex data sets, such as FashionMNIST, CIFAR-10, and CIFAR-100. This deficiency limits the wider application of capsule networks. In this article, we propose a deep capsule network model combined with a U-Net preprocessing module (DCN-UN). Local connection and weight-sharing strategies are adopted from convolutional neural networks to design a convolutional capsule layer in the DCN-UN model. This allows considerably reducing the number of parameters in the network model. Moreover, a greedy strategy is incorporated into the design of a mask DR (MDR) algorithm to improve the performance of network models. DCN-UN requires up to five times fewer parameters compared with the original CapsNet and other CapsNet-based models. The performance improvement achieved by the DCN-UN model with the MDR algorithm over the original CapsNet model with the DR algorithm is approximately 12% and 17% on the CIFAR-10 and CIFAR-100 data sets, respectively. The experimental results confirm that the proposed DCN-UN model allows preserving advantages of image reconstruction and equivariance mechanism in capsule networks. Moreover, an efficient initialization method is explored to enhance training stability and avoid gradient explosion.																	2162-237X	2162-2388				JUL	2020	31	7					2653	2664		10.1109/TNNLS.2020.2984686													
J								Deep Model Compression and Inference Speedup of Sum-Product Networks on Tensor Trains	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Computational modeling; Brain modeling; Semantics; Probabilistic logic; Learning systems; Biological neural networks; Model compression; sum-product network (SP); tensor train (TT)	DECOMPOSITIONS; MATRIX	Sum-product networks (SPNs) constitute an emerging class of neural networks with clear probabilistic semantics and superior inference speed over other graphical models. This brief reveals an important connection between SPNs and tensor trains (TTs), leading to a new canonical form which we call tensor SPNs (tSPNs). Specifically, we demonstrate the intimate relationship between a valid SPN and a TT. For the first time, through mapping an SPN onto a tSPN and employing specially customized optimization techniques, we demonstrate improvements up to a factor of 100 on both model compression and inference speedup for various data sets with negligible loss in accuracy.																	2162-237X	2162-2388				JUL	2020	31	7					2665	2671		10.1109/TNNLS.2019.2928379													
J								Exploring Duality in Visual Question-Driven Top-Down Saliency	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Task analysis; Visualization; Feature extraction; Training; Pipelines; Learning systems; Knowledge discovery; Dual learning; saliency; visual question answering (VQA); visual question generation (VQG)		Top-down, goal-driven visual saliency exerts a huge influence on the human visual system for performing visual tasks. Text generations, like visual question answering (VQA) and visual question generation (VQG), have intrinsic connections with top-down saliency, which is usually involved in both VQA and VQG processes in an unsupervised manner. However, it is shown that the regions that humans choose to look at to answer questions are very different from the unsupervised attention models. In this brief, we aim to explore the intrinsic relationship between top-down saliency and text generations, and to figure out whether an accurate saliency response benefits text generation. To this end, we propose a dual supervised network with dynamic parameter prediction. Dual-supervision explicitly exploits the probabilistic correlation between the primal task top-down saliency detection and the dual task text generation, while dynamic parameter prediction encodes the given text (i.e., question or answer) into the fully convolutional network. Extensive experiments show the proposed top-down saliency method achieves the best correlation with human attention among various baselines. In addition, the proposed model can be guided by either questions or answers, and output the counterpart. Furthermore, we show that combining human-like visual question-saliency improves the performance of both answer and question generations.																	2162-237X	2162-2388				JUL	2020	31	7					2672	2679		10.1109/TNNLS.2019.2933439													
J								Optimizing for Measure of Performance in Max-Margin Parsing	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Grammar; Training; Loss measurement; Inference algorithms; Computational modeling; Task analysis; Dynamic programming; graphical models; high-order potentials; inference; margin scaling; slack scaling; structural support vector machines (SVMs); structured output		Many learning tasks in the field of natural language processing including sequence tagging, sequence segmentation, and syntactic parsing have been successfully approached by means of structured prediction methods. An appealing property of the corresponding training algorithms is their ability to integrate the loss function of interest into the optimization process improving the final results according to the chosen measure of performance. Here, we focus on the task of constituency parsing and show how to optimize the model for the F-1-score in the max-margin framework of a structural support vector machine (SVM). For reasons of computational efficiency, it is a common approach to binarize the corresponding grammar before training. Unfortunately, this introduces a bias during the training procedure as the corresponding loss function is evaluated on the binary representation, while the resulting performance is measured on the original unbinarized trees. Here, we address this problem by extending the inference procedure presented by Bauer et al. Specifically, we propose an algorithmic modification that allows evaluating the loss on the unbinarized trees. The new approach properly models the loss function of interest resulting in better prediction accuracy and still benefits from the computational efficiency due to binarized representation. The presented idea can be easily transferred to other structured loss functions.																	2162-237X	2162-2388				JUL	2020	31	7					2680	2684		10.1109/TNNLS.2019.2934225													
J								Legal dilemmas of Estonian artificial intelligence strategy: in between of e-society and global race	AI & SOCIETY										Artificial intelligence; Robot judge; Automated decision making; Liability; EU competition law; EU state aid	AGENTS	Estonia has successfully created a digital society within the past 2 decades. It is best known for its eGovernment achievements, but it is also home for four unicorn star-ups. While the state is aiming to attract tech investments with e-Residency program and has recently started to invest into protecting national IP and safeguarding data from cybercrime by applying blockchain technology and creating its "digital embassy" in Luxembourg, emerging technologies such as and applications of artificial intelligence but also internet of things have posed the question on legal regulation and standardization. The dilemma, however, seems to be that since the new technologies, such artificial intelligence is much more overwhelming phenomenon than e-governance and presumably, before deciding the legal standards, the political and economic strategies that go beyond the e-governance should be set.																	0951-5666	1435-5655															10.1007/s00146-020-01009-8		JUL 2020											
J								Privacy stochastic games in distributed constraint reasoning	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Privacy; Constraint reasoning; Distributed systems; Utilitarian agents	TRUST	In this work, we approach the issue of privacy in distributed constraint reasoning by studying how agents compromise solution quality for preserving privacy, using utility and game theory. We propose a utilitarian definition of privacy in the context of distributed constraint reasoning, detail its different implications, and present a model and solvers, as well as their properties. We then show how important steps in a distributed constraint optimization with privacy requirements can be modeled as a planning problem, and more specifically as a stochastic game. We present experiments validating the interest of our approach, according to several criteria.																	1012-2443	1573-7470				JUL	2020	88	7			SI		691	715		10.1007/s10472-019-09628-8													
J								Optimal probability aggregation based on generalized brier scoring	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Probability aggregation; Brier score; Meta-induction; Machine learning; No regret algorithms		In this paper we combine the theory of probability aggregation with results of machine learning theory concerning the optimality of predictions under expert advice. In probability aggregation theory several characterization results for linear aggregation exist. However, in linear aggregation weights are not fixed, but free parameters. We show how fixing such weights by success-based scores, a generalization of Brier scoring, allows for transferring the mentioned optimality results to the case of probability aggregation.																	1012-2443	1573-7470				JUL	2020	88	7			SI		717	734		10.1007/s10472-019-09648-4													
J								Statistical learning based on Markovian data maximal deviation inequalities and learning rates	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Concentration inequality; Empirical process; Generalization bound; Harris positive Markov chain; Minimum volume set; Novelty detection; Regenerative method; Stationary probability distribution; Unsupervised learning	MINIMUM VOLUME SETS; LIMIT-THEOREMS; PARTIAL-SUMS; CONVERGENCE; FUNCTIONALS; SEQUENCES; BOOTSTRAP	In statistical learning theory, numerous works established non-asymptotic bounds assessing the generalization capacity of empirical risk minimizers under a large variety of complexity assumptions for the class of decision rules over which optimization is performed, by means of sharp control of uniform deviation of i.i.d. averages from their expectation, while fully ignoring the possible dependence across training data in general. It is the purpose of this paper to show that similar results can be obtained when statistical learning is based on a data sequence drawn from a (Harris positive) Markov chainX, through the running example of estimation ofminimum volume sets(MV-sets) related toX's stationary distribution, an unsupervised statistical learning approach to anomaly/novelty detection. Based on novel maximal deviation inequalities we establish, using theregenerative method, learning rate bounds that depend not only on the complexity of the class of candidate sets but also on the ergodicity rate of the chainX, expressed in terms of tail conditions for the length of the regenerative cycles. In particular, this approach fully tailored to Markovian data permits to interpret the rate bound results obtained in frequentist terms, in contrast to alternative coupling techniques based onmixingconditions: the larger the expected number of cycles over a trajectory of finite length, the more accurate the MV-set estimates. Beyond the theoretical analysis, this phenomenon is supported by illustrative numerical experiments.																	1012-2443	1573-7470				JUL	2020	88	7			SI		735	757		10.1007/s10472-019-09670-6													
J								The price to pay for forgoing normalization in fair division of indivisible goods	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Fair division; Indivisible goods; Social welfare; Computational complexity	SOCIAL-WELFARE OPTIMIZATION; APPROXIMABILITY; COMPLEXITY	We study the complexity of fair division of indivisible goods and consider settings where agents can have nonzero utility for the empty bundle. This is a deviation from a common normalization assumption in the literature, and we show that this inconspicuous change can lead to an increase in complexity: In particular, while an allocation maximizing social welfare by the Nash product is known to be easy to detect in the normalized setting whenever there are as many agents as there are resources, without normalization it can no longer be found in polynomial time, unless P = NP. The same statement also holds for egalitarian social welfare. Moreover, we show that it is NP-complete to decide whether there is an allocation whose Nash product social welfare is above a certain threshold if the number of resources is a multiple of the number of agents. Finally, we consider elitist social welfare and prove that the increase in expressive power by allowing negative coefficients again yields NP-completeness.																	1012-2443	1573-7470				JUL	2020	88	7			SI		817	832		10.1007/s10472-019-09659-1													
J								Continuous Technological Improvement Using Systems Engineering Principles to Achieve Sustainability: An Investigation Into Related Literature	INTERNATIONAL JOURNAL OF SYSTEM DYNAMICS APPLICATIONS										Continuous Improvement; Systems Engineering; Technology	PROJECT-MANAGEMENT; RISK-MANAGEMENT; DYNAMICS MODEL; PRODUCT DEVELOPMENT; FRAMEWORK; INNOVATION; KNOWLEDGE; CULTURE; IMPACT; IMPLEMENTATION	The design of a continuous plan would benefit society, as seen in systems engineering. To understand complex systems and to uphold the principles of stability, systems engineering has shown that it is a discipline of great importance. The principle of continuous technological improvement has augmented this idea, as the quality improvement of the design to meet inherent objectives would be the focus. This study aims to present the necessity of continuous technological improvement through systems engineering principles for socioeconomic and community-oriented growth. Thus, the context that would tackle global concerns and facilitate humanity's growth toward knowledge would be the application of technology. The context at hand, the design of systems thinking, and the overall approach taken to promote deeper perspectives has been illustrated in various literature. Healthcare, chemical production and organizational development are various fields of distinction that have shown evidence from the investigation into related literature. To streamline quality, as well as to maintain high quantities of production, all employed systems engineering have focused on technological improvements. In the field of industrial engineering, for a stable industry in which the system operates, this line of thinking is crucial.																	2160-9772	2160-9799				JUL-SEP	2020	9	3					1	25		10.4018/IJSDA.2020070101													
J								Fuzzy Modelling and Chaos Control in the Photogravitational Magnetic Binary Problem With Potential From a Belt	INTERNATIONAL JOURNAL OF SYSTEM DYNAMICS APPLICATIONS										Active Control; Chaos; Fuzzy control; Lyapunov stability; magnetic binary problem; Nonlinear system; Synchronization; Takagi-Sugeno fuzzy model	HYBRID SYNCHRONIZATION; SYSTEMS; STABILITY	Control of chaotic systems has led to many fruitful results, such as the famous OGY and feedback control. Of course, controlling chaos is not limited to the approaches above and is not specifically reviewed one by one here. The representation of chaotic systems using fuzzy models has a unified approach. The fuzzy logic controllers had been proposed for a long time and were successfully applied to control the chaos in many systems. The main purpose of this study is to presents the new fuzzy model for the photogravitational magnetic-binary problem (PMBP) where the bigger primary is a source of radiation and the smaller primary is an oblate body; and they are encompassed by a homogeneous circular cluster of material points centred at the mass centre of the system (belt). It was shown that using a new fuzzy controller, it is possible to control of chaotic behaviour of the photogravitational magnetic-binary problem (PMBP). The simulation results have demonstrated that the proposed method can satisfy the control object and enhanced stability.																	2160-9772	2160-9799				JUL-SEP	2020	9	3					26	39		10.4018/IJSDA.2020070102													
J								Health Insurance Claim Prediction Using Artificial Neural Networks	INTERNATIONAL JOURNAL OF SYSTEM DYNAMICS APPLICATIONS										Artificial; Backpropagation; Claims; Data Normalization; Feedforward; Health Insurance; Neural Network; Sigmoid; Time Series	RECOGNITION; FRAUD	A number of numerical practices exist that actuaries use to predict annual medical claim expense in an insurance company. This amount needs to be included in the yearly financial budgets. Inappropriate estimating generally has negative effects on the overall performance of the business. This study presents the development of artificial neural network model that is appropriate for predicting the anticipated annual medical claims. Once the implementation of the neural network models was finished, the focus was to decrease the mean absolute percentage error by adjusting the parameters, such as epoch, learning rate, and neurons in different layers. Both feed forward and recurrent neural networks were implemented to forecast the yearly claims amount. In conclusion, the artificial neural network model that was implemented proved to be an effective tool for forecasting the anticipated annual medical claims for BSP Life. Recurrent neural network outperformed the feed forward neural network in terms of accuracy and computation power required to carry out the forecasting.																	2160-9772	2160-9799				JUL-SEP	2020	9	3					40	57		10.4018/IJSDA.2020070103													
J								A Hybrid Hierarchical Heuristic-ACO With Local Search Applied to Travelling Salesman Problem, AS-FA-Ls	INTERNATIONAL JOURNAL OF SYSTEM DYNAMICS APPLICATIONS										ACO; Ant Supervised By FA ASFA; ANT Supervised By Firefly With Local Search; AS-FA-Ls; FA; Firefly Algorithm; Local Search; Travelling: Salesman Problem	PARTICLE SWARM OPTIMIZATION; FIREFLY ALGORITHMS; ANT COLONY	The combinatorial optimization problem is attracting research because they have a wide variety of applications ranging from route planning and supply chain optimization to industrial scheduling and the IoT. Solving such problems using heuristics and bio-inspired techniques is an alternative to exact solutions offering acceptable solutions at fair computational costs. In this article, a new hierarchical hybrid method is proposed as a hybridization of Ant Colony Optimization (ACO), Firefly Algorithm (FA), and local search (AS-FA-Ls). The proposed methods are compared to similar techniques on the traveling salesman problem, (TSP). ACO is used in a hierarchical collaboration schema together with FA which is used to adapt ACO parameters. A local search strategy is used which is the 2 option method to avoid suboptimal solutions. A comparative review and experimental investigations are conducted using the TSP benchmarks. The results showed that AS-FA-Ls returned better results than the listed works in the following cases: berlin52, st70, eil76, rat99, kroA100, and kroA200. Computational investigations allowed determining a set of recommended parameters to be used with ACO for the TSP instances of the study.																	2160-9772	2160-9799				JUL-SEP	2020	9	3					58	73		10.4018/IJSDA.2020070104													
J								Opposition based competitive grey wolf optimizer for EMG feature selection	EVOLUTIONARY INTELLIGENCE										Feature selection; Optimization; Competitive binary grey wolf optimizer; Electromyography; Classification; Opposition learning	PARTICLE SWARM OPTIMIZATION; FEATURE-EXTRACTION; ALGORITHM; CLASSIFICATION; CHANNEL	This paper proposes a competitive grey wolf optimizer (CGWO) to solve the feature selection problem in electromyography (EMG) pattern recognition. We model the recently established feature selection method, competitive binary grey wolf optimizer (CBGWO), into a continuous version (CGWO), which enables it to perform the search on continuous search space. Moreover, another new variant of CGWO, namely opposition based competitive grey wolf optimizer (OBCGWO), is proposed to enhance the performance of CGWO in feature selection. The proposed methods show superior results in several benchmark function tests. As for EMG feature selection, the proposed algorithms are evaluated using the EMG data acquired from the publicly access EMG database. Initially, several useful features are extracted from the EMG signals to construct the feature set. The proposed CGWO and OBCGWO are then applied to select the relevant features from the original feature set. Four state-of-the-art algorithms include particle swarm optimization, flower pollination algorithm, butterfly optimization algorithm, and CBGWO are used to examine the effectiveness of proposed methods in feature selection. The experimental results show that OBCGWO can provide optimal classification performance, which is suitable for rehabilitation and clinical applications.																	1864-5909	1864-5917															10.1007/s12065-020-00441-5		JUL 2020											
J								A Socially Aware SLAM Technique Augmented by Person Tracking Module	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Simultaneous localization and mapping; Person tracking; Socially assistive robots; Dynamic environment	MOBILE ROBOT LOCALIZATION; ALGORITHM; CANCER; PEOPLE	In recent years the development of Simultaneous Localization and Mapping (SLAM) techniques have enabled social robots to autonomously navigate in routine human workplaces. However, most common SLAM techniques are developed for mapping and localization in static worlds. In this paper, we have developed and analyzed a novel augmentation of the FastSLAM algorithm, including a person tracking module using 2D LiDAR sensor data. Utilizing this module, the SLAM algorithm is capable of filtering measurements coming from walking people who produce noises due to their intrinsic dynamic and unstableness. This augmentation was developed and then tested on our socially assistive mobile robot platform, Arash, while moving in populated environments utilizing Robotic Operating System (ROS) as a middleware. This new approach demonstrated a clearer representation of the mapped environment and therefore more accurate localization and navigation compared to its static SLAM predecessor.																	0921-0296	1573-0409				JUL	2020	99	1					3	12		10.1007/s10846-019-01120-z													
J								Bi-objective Motion Planning Approach for Safe Motions: Application to a Collaborative Robot	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Motion planning; Safe motion; Collaborative robot; Human-robot cooperation	PROBABILISTIC ROADMAPS; COLLISION CHECKING	This paper presents a new bi-objective safety-oriented path planning strategy for robotic manipulators. Integrated into a sampling-based algorithm, our approach can successfully enhance the task safety by guiding the expansion of the path towards the safest configurations. Our safety notion consists of avoiding dangerous situations, e.g. being very close to the obstacles, human awareness, e.g. being as much as possible in the human vision field, as well as ensuring human safety by being as far as possible from human with hierarchical priority between human body parts. Experimental validations are conducted in simulation and on the real Baxter research robot. They revealed the efficiency of the proposed method, mainly in the case of a collaborative robot sharing the workspace with humans.																	0921-0296	1573-0409				JUL	2020	99	1					45	63		10.1007/s10846-019-01110-1													
J								Hybrid Path Planning Based on Safe A* Algorithm and Adaptive Window Approach for Mobile Robot in Large-Scale Dynamic Environment	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Mobile robot; Hybrid path planning; Safe A* algorithm; Adaptive window approach; Key path points		When mobile robot used in large-scale dynamic environments, it face more challenging problems in real-time path planning and collision-free path tracking. This paper presents a new hybrid path planning method that combines A* algorithm with adaptive window approach to conduct global path planning, real-time tracking and obstacles avoidance for mobile robot in large-scale dynamic environments. Firstly, a safe A* algorithm is designed to simplify the calculation of risk cost function and distance cost. Secondly, key path points are extracted from the planned path which generated by the safe A* to reduce the number of the grid nodes for smooth path tracking. Finally, the real-time motion planning based on adaptive window approach is adopted to achieve the simultaneous path tracking and obstacle avoidance (SPTaOA) together the switching of the key path points. The simulation and practical experiments are conducted to verify the feasibility and performance of the proposed method. The results show that the proposed hybrid path planning method, used for global path planning, tracking and obstacles avoidance, can meet the application needs of mobile robots in complex dynamic environments.																	0921-0296	1573-0409				JUL	2020	99	1					65	77		10.1007/s10846-019-01112-z													
J								Velocity Obstacle Based on Vertical Ellipse for Multi-Robot Collision Avoidance	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Velocity obstacle (VO); Vertical ellipse; Multi-robot; Path planning; Localization uncertainty		Bounding volume based approaches in velocity obstacle (VO) provide a good solution for collision avoidance of mobile robots with uncertainty. However, the VO built with the bounding footprint always has over-constraining problems which may lead to conservative maneuvers of the mobile robots. Addressing this problem, a vertical ellipse based velocity obstacle (VEVO) collision avoidance method is proposed in this paper. The method mitigates the over-constraining situation by building the footprint probability ellipse whose minor axis is vertical to the direction of the obstacle to minimize the VO area. Based on VEVO, a DWA (Dynamic Window Approach) integrated method is proposed to provide a set of available velocities in speed selection. According to different collision avoidance objectives like collision safety, shortest time consumption and shortest trajectory length, a multi-objective velocity selecting strategy is proposed to provide optimal velocities for motion planning. Furthermore, a dynamic local path adjustment method is proposed to help robots react to the closest obstacle (dynamic or static) according to different collision safety requirements. We validate our methods in a simulated workspace with different numbers of robots going to their goal points. Experimental results show VEVO method could improve the collision avoidance performance in crowded multi-robot environment and robots could achieve their different objectives when suitable parameters are set in the velocity evaluation function. The proposed dynamic local path adjustment method only affects the trajectories in local areas and could ensure collision avoidance safety and performance at the same time.																	0921-0296	1573-0409				JUL	2020	99	1					183	208		10.1007/s10846-019-01127-6													
J								A Stochastic Multi-layer Algorithm for Semi-discrete Optimal Transport with Applications to Texture Synthesis and Style Transfer	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Optimal transport; Texture synthesis; Patch matching; Image inpainting; Style transfer	MODEL	This paper investigates a new stochastic algorithm to approximate semi-discrete optimal transport for large-scale problem, i.e., in high dimension and for a large number of points. The proposed technique relies on a hierarchical decomposition of the target discrete distribution and the transport map itself. A stochastic optimization algorithm is derived to estimate the parameters of the corresponding multi-layer weighted nearest neighbor model. This model allows for fast evaluation during synthesis and training, for which it exhibits faster empirical convergence. Several applications to patch-based image processing are investigated: texture synthesis, texture inpainting, and style transfer. The proposed models compare favorably to the state of the art, either in terms of image quality, computation time, or regarding the number of parameters. Additionally, they do not require any pixel-based optimization or training on a large dataset of natural images.																	0924-9907	1573-7683															10.1007/s10851-020-00975-4		JUL 2020											
J								Super-Resolution Based Automatic Diagnosis of Retinal Disease Detection for Clinical Applications	NEURAL PROCESSING LETTERS										Retinal image; Super-resolution; ROI; Fundus; KNN	DIABETIC-RETINOPATHY; IMAGES	In medical image processing, the automatic analysis of pathology localization and the anatomical segmentation steps are more important. The Fundus images of Low resolution (LR) are not applicable to detect the retinal disease. The main aim of this paper is to enhance the resolution of the low-resolution retinal images obtained from the cheap imaging devices within less computational time and high accuracy. So, we proposed the fundus image with Super-Resolution and its performance via the Diagnostically Significant Area (DSA). This approach focuses only on the region of Interest (ROI) instead of concentrating on the entire image leading to less computational time by reducing the time complexity. Therefore, the Eigen MR inter-band feature, Energy MR intra-band feature, Shannon entropy and Sensitive Contrast Interest (SCI) are used to capture the clinical data from the selected region. Therefore, the DSA is determined by using Levenshtein based KNN classifier. Because of better classification outcomes, the Bicubic method is employed in the selected region to reduce the loss of reconstruction error. Experimentally, the implementation works are carried out in the platform of MATLAB with DRIVE and STARE database images are chosen. The super-resolution image performances are compared with different start of art techniques such as PSM, GR-SR, LLE, and SpC-SR. Finally, higher efficiency with low computational super-resolution fundus images is collected.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1155	1170		10.1007/s11063-020-10292-x		JUL 2020											
J								A New Hybrid Improved Method for Measuring Concept Semantic Similarity in WordNet	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Information content; Semantic similarity; WordNet taxonomy; Hyponym	INFORMATION-CONTENT	Computing semantic similarity between concepts is an important issue in natural language processing, artificial intelligence, information retrieval and knowledge management. The measure of computing concept similarity is a fundament of semantic computation. In this paper, we analyze typical semantic similarity measures and note Wu and Palmer's measure which does not distinguish the similarities between nodes from a node to different nodes of the same level. Then, we synthesize the advantages of measure of path-based and IC-based, and propose a new hybrid method for measuring semantic similarity. By testing on a fragment of WordNet hierarchical free, the results demonstrate the proposed method accurately distinguishes the similarities between nodes from a node to different nodes of the same level and overcome the shortcoming of the Wu and Palmer's measure.																	1683-3198					JUL	2020	17	4					433	439		10.34028/iajit/17/4/1													
J								Multi Label Ranking Based on Positive Pairwise Correlations Among Labels	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Correlations among labels; multi-label classification; multi-label ranking; problem transformation methods	CLASSIFICATION	Multi-Label Classification (MLC) is a general type of classification that has attracted many researchers in the last few years. Two common approaches are being used to solve the problem of MLC: Problem Transformation Methods (PTMs) and Algorithm Adaptation Methods (AAA/Is). This Paper is more interested in the first approach; since it is more general and applicable to any domain. In specific, this paper aims to meet two objectives. The first objective is to propose a new multi-label ranking algorithm based on the positive pairwise correlations among labels, while the second objective aims to propose new simple PTMs that are based on labels correlations, and not based on labels frequency as in conventional PTMs. Experiments showed that the proposed algorithm overcomes the existing methods and algorithms on all evaluation metrics that have been used in the experiments. Also, the proposed PTMs show a superior performance when compared with the existing PTMs.																	1683-3198					JUL	2020	17	4					440	449		10.34028/iajit/17/4/2													
J								Privacy-Preserving Data Aggregation Framework for Mobile Service Based Multiuser Collaboration	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Differential privacy; Nash equilibrium; conditional filtering noise; adaptive Gaussian mechanism; PPDAF	DIFFERENTIAL PRIVACY; NOISE	Considering the untrusted server, differential privacy and local differential privacy has been used for privacy-preserving in data aggregation. Through our analysis, differential privacy and local differential privacy cannot achieve Nash equilibrium between privacy and utility for mobile service based multiuser collaboration, which is multiuser negotiating a desired privacy budget in a collaborative manner for privacy-preserving. To this end, we proposed a Privacy-Preserving Data Aggregation Framework (PPDAF) that reached Nash equilibrium between privacy and utility. Firstly, we presented an adaptive Gaussian mechanism satisfying Nash equilibrium between privacy and utility by multiplying expected utility factor with conditional filtering noise under expected privacy budget. Secondly, we constructed PPDAF using adaptive Gaussian mechanism based on negotiating privacy budget with heuristic obfuscation. Finally, our theoretical analysis and experimental evaluation showed that the PPDAF could achieve Nash equilibrium between privacy and utility. Furthermore, this framework can be extended to engineering instances in a data aggregation setting.																	1683-3198					JUL	2020	17	4					450	460		10.34028/iajit/17/4/3													
J								Design and Implementation of Inter-operable and Secure Agent Migration Protocol	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Information Security; Multi-Agent Systems; Inter-Platform Agent Mobility; JADE; Trusted Computing	MULTIAGENT; MOBILITY; CODE	Mobile agent technology is an active research topic and has found its uses in various diverse areas ranging from simple personal assistance to complex distributed big data systems. Its usage permits offline and autonomous execution as compared to classical distributed systems. The free roaming nature of agents makes it prone to several security threats during its transit state, with an added overhead in its interoperability among different types of platforms. To address these problems, both software and hardware based approaches have been proposed to ensure protection at various transit points. However, these approaches do not ensure interoperability and protection to agents during transit over a channel, simultaneously. In this regard, an agent requires a trustworthy, interoperable, and adaptive protocol for secure migration. In this paper, to answer these research issues, we first analyse security flaws in existing agent protection frameworks. Second, we implemented a novel migration architecture which is: 1) fully inter-operable compliance to the Foundation for Intelligent Physical Agents (FIPA) and 2) trustworthy based on Computing Trusted Platform Module (TPM). The proposed approach is validated by testing on software TPM of IBM, JSR321, and jTPMTools as TPM and Trusted Computing Software Stack (TSS) interfaces, JADE-agent framework and 7Mobility Service (JIPMS). Validation is also performed on systems bearing physical TPM-chips. Moreover, some packages of JIPMS are also modified by embedding our proposed approach into their functions. Our performance results show that our approach merely adds an execution overhead during the binding and unbinding phases.																	1683-3198					JUL	2020	17	4					461	470		10.34028/iajit/17/4/4													
J								3D Radon Transform for Shape Retrieval Using Bag-of-Visual-Features	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										3D radon transform; Bag-of-Visual-Features; 3D models retrieval; K-means algorithm	OBJECT RETRIEVAL; MODEL RETRIEVAL; RECOGNITION	In order to improve the accuracy and efficiency of extracting features for 3D models retrieval, a novel approach using 3D radon transform and Bag-of-Visual-Features is proposed in this paper. Firstly the 3D radon transform is employed to obtain a view image using the different features in different angels. Then a set of local descriptor vectors are extracted by the SURF algorithm from the local features of the view. The similarity distance between geometrical transformed models is evaluated by using K-means algorithm to verify the geometric invariance of the proposed method. The numerical experiments are conducted to evaluate the retrieval efficiency compared to other typical methods. The experimental results show that the change of parameters has small effect on the retrieval performance of the proposed method.																	1683-3198					JUL	2020	17	4					471	479		10.34028/iajit/17/4/5													
J								Swarm Intelligence Approach to QRS Detection	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										ECG; QRS detection; Pan-Tompkins algorithm; Particle Swarm Optimization	DETECTION ALGORITHM	The QRS detection is a crucial step in ECG signal analysis; it has a great impact on the beats segmentation and in the final classification of the ECG signal. The Pan-Tompkins is one of the first and best-performing algorithms for QRS detection. It performs filtering for noise suppression, differentiation for slope dominance, and thresholding for decision making. All of the parameters of the Pan-Tompkins algorithm are selected empirically. However, we think that the Pan-Tompkins method can achieve better performance if the parameters were optimized. Therefore, we propose an adaptive algorithm that looks for the best set of parameters that improves the Pan-Tompkins algorithm performance. For this purpose, we formulate the parameter design as an optimization problem within a particle swarm optimization framework. Experiments conducted on the 24 hours recording of the MIT/BIH arrhythmia benchmark dataset achieved an overall accuracy of 99.83% which outperforms the state-of-the-art time-domain algorithms.																	1683-3198					JUL	2020	17	4					480	487		10.34028/iajit/17/4/6													
J								Intelligent Association Classification Technique for Phishing Website Detection	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Data mining; Association Classification technique; Apriori algorithm; Phishing	ALGORITHM	Many critical applications need more accuracy and speed in the decision making process. Data mining scholars developed set of artificial automated tools to enhance the entire decisions based on type of application. Phishing is one of the most critical application needs for high accuracy and speed in decision making when a malicious webpage impersonates as legitimate webpage to acquire secret information from the user. In this paper, we proposed a new Association Classification (AC) algorithm as an artificial automated tool to increase the accuracy level of the classification process that aims to discover any malicious webpage. An Intelligent Association Classification (IAC) algorithm developed in this article by employing the Harmonic Mean measure instead of the support and confidence measure to solve the estimation problem in these measures and discovering hidden pattern not generated by the existing AC algorithms. Our algorithm compared with four well-known AC algorithm in terms of accuracy, Fl, Precision, Recall and execution time. The experiments and the visualization process show that the IAC algorithm outperformed the others in all cases and emphasize on the importance of the general and specific rules in the classification process.																	1683-3198					JUL	2020	17	4					488	496		10.34028/iajit/17/4/7													
J								Connectionist Temporal Classification Model for Dynamic Hand Gesture Recognition using RGB and Optical flow Data	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Connectionist temporal classification; Long-short term memory; Hand gesture; Convolutional neural network; VIVA		Automatic classification of dynamic hand gesture is challenging due to the large diversity in a different class of gesture, Low resolution, and it is performed by finger. Due to a number of challenges many researchers focus on this area. Recently deep neural network can be used for implicit feature extraction and Soft Max layer is used for classification. In this paper, we propose a method based on a two-dimensional convolutional neural network that performs detection and classification of hand gesture simultaneously from multimodal Red, Green, Blue, Depth (RGBD) and Optical flow Data and passes this feature to Long-Short Term Memory (LSTM) recurrent network for frame-to-frame probability generation with Connectionist Temporal Classification (CTC) network for loss calculation. We have calculated an optical flow from Red, Green, Blue (RGB) data for getting proper motion information present in the video. CTC model is used to efficiently evaluate all possible alignment of hand gesture via dynamic programming and check consistency via frame-to-frame for the visual similarity of hand gesture in the unsegmented input stream. CTC network finds the most probable sequence of a frame for a class of gesture. The frame with the highest probability value is selected from the CTC network by max decoding. This entire CTC network is trained end-to-end with calculating CTC loss for recognition of the gesture. We have used challenging Vision for Intelligent Vehicles and Applications (VIVA) dataset for dynamic hand gesture recognition captured with RGB and Depth data. On this VIVA dataset, our proposed hand gesture recognition technique outperforms competing state-of-the-art algorithms and gets an accuracy of 86%.																	1683-3198					JUL	2020	17	4					497	506		10.34028/iajit/17/4/8													
J								An Effective Framework for Speech and Music Segregation	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Ideal binary mask; source segregation; repeating pattern; spectrogram; speech intelligibility	SINGING VOICE SEPARATION; FACTORIZATION; CONTINUITY	Speech and music segregation from a single channel is a challenging task due to background interference and intermingled signals of voice and music channels. It is of immense importance due to its utility in wide range of applications such as music information retrieval, singer identification, lyrics recognition and alignment. This paper presents an effective method for speech and music segregation. Considering the repeating nature of music, we first detect the local repeating structures in the signal using a locally defined window for each segment. After detecting the repeating structure, we extract them and perform separation using a soft time frequency mask. We apply an ideal binary mask to enhance the speech and music intelligibility. We evaluated the proposed method on the mixtures set at -5 dB, 0 dB, 5 dB from Multimedia Information Retrieval-1000 clips (MIR-1K) dataset. Experimental results demonstrate that the proposed method for speech and music segregation outperforms the existing state-of-the-art methods in terms of Global-Normalized-Signal-to-Distortion Ratio (GNSDR) values.																	1683-3198					JUL	2020	17	4					507	514		10.34028/iajit/17/4/9													
J								Enhanced Bagging (eBagging): A Novel Approach for Ensemble Learning	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Bagging; boosting; classification algorithms; machine learning; random forest; supervised learning	CLASSIFICATION; CLASSIFIERS	Bagging is one of the well-known ensemble learning methods, which combines several classifiers trained on different subsamples of the dataset. However, a drawback of bagging is its random selection, where the classification performance depends on chance to choose a suitable subset of training objects. This paper proposes a novel modified version of bagging, named enhanced Bagging (eBagging), which uses a new mechanism (error-based bootstrapping) when constructing training sets in order to cope with this problem. In the experimental setting, the proposed eBagging technique was tested on 33 well-known benchmark datasets and compared with both bagging, random forest and boosting techniques using well-known classification algorithms: Support Vector Machines (SVM), decision frees (C4.5), k-Nearest Neighbour (kNN) and Naive Bayes (NB). The results show that eBagging outperforms its counterparts by classifying the data points more accurately while reducing the training error.																	1683-3198					JUL	2020	17	4					515	528		10.34028/iajit/17/4/10													
J								Conceptual Persian Text Summarizer: A New Model in Continuous Vector Space	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Extractive Text Summarization; Unsupervised Learning; Language Independent Summarization; Continuous Vector Space; Word Embedding; Natural Language Processing		Traditional methods of summarization are not cost-effective and possible today. Extractive summarization is a process that helps to extract the most important sentences from a text automatically, and generates a short informative summary. In this work, we propose a novel unsupervised method to summarize Persian texts. The proposed method adopt a hybrid approach that clusters the concepts of the text using deep learning and traditional statistical methods. First we produce a word embedding based on Hamshahri2 corpus and a dictionary of word frequencies. Then the proposed algorithm extracts the keywords of the document, clusters its concepts, and finally ranks the sentences to produce the summary. We evaluated the proposed method on Pasokh single-document corpus using the ROUGE evaluation measure. Without using any hand-crafted features, our proposed method achieves better results than the state-of-the-art related work results. We compared our unsupervised method with the best supervised Persian methods and we achieved an overall improvement of ROUGE-2 recall score of 7.5%.																	1683-3198					JUL	2020	17	4					529	538		10.34028/iajit/17/4/11													
J								Query Authentication of Outsourced Spatial Database	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Data Outsourcing; KNN; spatial database; cloud computing; query authentication	ASSURANCE	Outsourcing spatial database to a third party is becoming a common practice for more and more individuals and companies to save the cost of managing and maintaining database, where a data owner delegates its spatial data management tasks to a third party and grants it to provide query services. However, the third party is not full trusted. Thus, authentication information should be provided to the client for query authentication. In this paper, we introduce an efficient space authenticated data structure, called Verifiable Similarity Indexing tree (VSS-tree), to support authenticated spatial query. We build VSS-tree based on SS-tree which employs bounding sphere rather than bounding rectangle for region shape and extend it with authentication information. Based on VSS-tree, the third party finds query results and builds their corresponding verification object. The client performs query authentication using the verification object and the public key published. Finally, we evaluate the performance and validity of our algorithms, the experiment results show that VSS-tree can efficiently support spatial query and have better performance than Merkle R tree (MR-tree).																	1683-3198					JUL	2020	17	4					539	547		10.34028/iajit/17/4/12													
J								Generation of Chaotic Signal for Scrambling Matrix Content	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Chaotic signal; scrambling; image encryption		Very well evolved, information technology made so easy the transfer of all types of data over public channels. For this reason, ensuring data security is certainly a necessary requirement. Scrambling data is one solution to hide information from non authorized users. Presenting matrix content, image scrambling can be made by only adding a mask to the real content. A user, having the appropriate mask, can recognize the image content by only subtracting it. Chaotic function is recently used for image encryption. In this paper, an algorithm of image scrambling based on three logistic chaotic functions is proposed. Defined by its initial condition and parameter, each chaotic function will generate a random signal. The set of initial conditions and parameters is the encryption key. The performance of this technique is ensured for two great reasons. First, using masks on the image makes unintelligible its content. Second, using three successive encryption processes makes so difficult attacks. This point reflects, in one hand, a sufficient key length to resist to brute force attack. In the other hand, it reflects the random aspect of the pixel distribution in the scrambled image. That means, the randomness in one mask minimizes the correlations really existent between neighboring pixels. That makes our proposed approach resistant to known attacks and suitable for applications requiring secure data transfer such as medical image exchanged between doctors.																	1683-3198					JUL	2020	17	4					548	553		10.34028/iajit/17/4/13													
J								Finger Knuckle Print Recognition using MMDA with Fuzzy Vault	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Finger Knuckle Print (FKP); 2D Gabor filter; Multi-Manifold Discriminant analysis (MMDA); Fuzzy Vault		Currently frequent biometric scientific research such as with biometric applications like face, iris, voice, hand-based biometrics traits like palm print and fingerprint technique are utilized for spotting out the persons. These specific biometrics habits have their own improvement and weakness so that no particular biometrics can adequately opt for all terms like the accuracy and cost of all applications. In recent times, in addition, to distinct with the hand-based biometrics technique, Finger Knuckle Print (FKP) has been appealed to boom the attention among biometric researchers. The image template pattern formation of FKP embraces the report that is suitable for spotting the uniqueness of individuality. This FKP frail observes a person based on the knuckle print and the framework in the outer finger surface. This FKP feature determines the line anatomy and finger structures which are well established and persistent throughout the life of an individual. In this paper, a novel method for personal identification will be introduced, along with that data to be stored in a secure way has also been proposed. The authentication process includes the transformation of features using 2D Log Gabor filter and Eigen value representation of Multi Manifold Discriminant Analysis (MMDA) of FKP. Finally, these features are grouped using k-means clustering for both identification and verification process. This proposed system is initialized based on the FKP framework without a template based on the fuzzy vault. The key idea of fuzzy vault storing is utilized to safeguard the secret key in the existence of random numbers as chaff pints.																	1683-3198					JUL	2020	17	4					554	561		10.34028/iajit/17/4/14													
J								An Improved Framework for Modelling Data Warehouse Systems Using UML Profile	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										UML Profile; Data Warehouse; UML; MD Modelling	DESIGN; REQUIREMENTS; SCHEMAS	Data Warehouse (DW) applications provide past detail for judgment process for the companies. It is acknowledged that these systems depend on Multidimensional (MD) modelling different from traditional database modelling. MD modelling keeps data in the form of facts and dimensions. Some proposals have been presented to achieve the modelling of these systems, but none of them covers the MD modelling completely. There is no any approach which considers all the major components of MD systems. Some proposals provide their proprietary visual notations, which force the architects to gain knowledge of new precise model. This paper describes a framework which is in the form of an extension to Unified Modelling Language (UML). UML is worldwide known to design a variety of perspectives of software systems. Therefore, any method using the UML reduces the endeavour of designers in understanding the novel notations. Another exceptional characteristic of the UML is that it can be extended to bring in novel elements for different domains. In addition, the proposed UML profile focuses on the accurate representations of the properties of the MD systems based on domain specific information. The proposed framework is validated using a specific case study. Moreover, an evaluation and comparative analysis of the proposed framework is also provided to show the efficiency of the proposed work.																	1683-3198					JUL	2020	17	4					562	571		10.34028/iajit/17/4/15													
J								Persian Handwritten Digit Recognition Using Combination of Convolutional Neural Network and Support Vector Machine Methods	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY										Handwritten Digit Recognition; Convolutional Neural Network; Support Vector Machine	WORD RECOGNITION	Persian handwritten digit recognition is one of the important topics of image processing which significantly considered by researchers due to its many applications. The most important challenges in Persian handwritten digit recognition is the existence of various patterns in Persian digit writing that makes the feature extraction step to be more complicated.Since the handcraft feature extraction methods are complicated processes and their performance level are not stable, most of the recent studies have concentrated on proposing a suitable method for automatic feature extraction. In this paper, an automatic method based on machine learning is proposed for high-level feature extraction from Persian digit images by using Convolutional Neural Network (CNN). After that, a non-linear multi-class Support Vector Machine (SVM) classifier is used for data classification instead of fully connected layer in final layer of CNN. The proposed method has been applied to HODA dataset and obtained 99.56% of recognition rate. Experimental results are comparable with previous state-of-the-art methods.																	1683-3198					JUL	2020	17	4					572	578		10.34028/iajit/17/4/16													
J								Gene selection of non-small cell lung cancer data for adjuvant chemotherapy decision using cell separation algorithm	APPLIED INTELLIGENCE										Gene selection; Classification; Non-small cell lung cancer; Adjuvant chemotherapy decision; Cell separation algorithm	MICROARRAY DATA CLASSIFICATION; PARTICLE SWARM OPTIMIZATION; PREDICTING RESPONSE; EXPRESSION DATA; SIGNATURE	Since recommended treatment for Non-small cell lung cancer (NSCLC) after surgery is chemotherapy, the prediction of effectiveness or futileness of adjuvant chemotherapy (ACT) in early stage is important for future decision. Classification of NSCLC in gene expression data is performed to predict effectiveness or futileness of ACT. Selection of genes highly correlated with the class attribute, affects the classification accuracy. In this paper, a new cell separation algorithm is proposed which it imitates the action of cell separation using differential centrifugation process involving multiple centrifugation steps and increasing the rotor speed in each step. The CSA uses the application ofcentrifugal forceto separate the solutions based on their objective function in different steps while the velocity is increased in each step. The CSA contributes to automatic trade-off between exploration and exploitation by control of selection rate during the search process. To examine the CSA, 25 test functions were used first and then the CSA was applied to predict effectiveness or futileness of ACT. The number of genes in candidate subsets is handled by increasing the subset size if after a certain number of iterations there is no improvement in fitness of the subset. This contributes to less time consideration and memory usage. In this experiment, the NSCLC data contain 280 samples collected from four institutes are used. As results, the minimum number of five genes with dependency degree equal to one and classification accuracy of higher than 94% for SVM, KNN and MLP classifiers is obtained.																	0924-669X	1573-7497				NOV	2020	50	11					3822	3836		10.1007/s10489-020-01740-1		JUL 2020											
J								Anomaly Detection in Activities of Daily Living with Linear Drift	COGNITIVE COMPUTATION										Anomaly detection; Activities of Daily Living; Abrupt change; Linear drift; Circular normal distribution	STATISTICAL PROCESS-CONTROL; HUMAN ACTIVITY RECOGNITION; COGNITIVE DECLINE; CHANGE-POINT; CIRCULAR STATISTICS; BEHAVIORAL-CHANGE; OLDER-ADULTS; SENSOR; SLEEP; TIME	Anomalyq detection in Activities of Daily Living (ADL) plays an important role in e-health applications. An abrupt change in the ADL performed by a subject might indicate that she/he needs some help. Another important issue related with e-health applications is the case where the change in ADL undergoes a linear drift, which occurs in cognitive decline, Alzheimer's disease or dementia. This work presents a novel method for detecting a linear drift in ADL modelled as circular normal distributions. The method is based on techniques commonly used in Statistical Process Control and, through the selection of a convenient threshold, is able to detect and estimate the change point in time when a linear drift started. Public datasets have been used to assess whether ADL can be modelled by a mixture of circular normal distributions. Exhaustive experimentation was performed on simulated data to assess the validity of the change detection algorithm, the results showing that the difference between the real change point and the estimated change point was 4.90(+3.17)(-1.98) days on average. ADL can be modelled using a mixture of circular normal distributions. A new method to detect anomalies following a linear drift is presented. Exhaustive experiments showed that this method is able to estimate the change point in time for processes following a linear drift.																	1866-9956	1866-9964															10.1007/s12559-020-09740-6		JUL 2020											
J								Evolutionary multiobjective optimization: open research areas and some challenges lying ahead	COMPLEX & INTELLIGENT SYSTEMS										Pythagorean fuzzy value; Pythagorean fuzzy sets; Similarity	MANY-OBJECTIVE OPTIMIZATION; FITNESS INHERITANCE; HYPER-HEURISTICS; PARETO FRONT; DIFFERENTIAL EVOLUTION; GENETIC ALGORITHM; SMS-EMOA; SELECTION; SWARM; PERFORMANCE	Evolutionary multiobjective optimization has been a research area since the mid-1980s, and has experienced a very significant activity in the last 20 years. However, and in spite of the maturity of this field, there are still several important challenges lying ahead. This paper provides a short description of some of them, with a particular focus on open research areas, rather than on specific research topics or problems. The main aim of this paper is to motivate researchers and students to develop research in these areas, as this will contribute to maintaining this discipline active during the next few years.																	2199-4536	2198-6053				JUL	2020	6	2					221	236		10.1007/s40747-019-0113-4													
J								A modified particle swarm optimization based on decomposition with different ideal points for many-objective optimization problems	COMPLEX & INTELLIGENT SYSTEMS										Many-objective optimization; Decomposition; Different ideal points	MULTIOBJECTIVE OPTIMIZATION; EVOLUTIONARY ALGORITHM; SELECTION; CONVERGENCE; DIVERSITY; MOEA/D	Many evolutionary algorithms have been proposed for multi-/many-objective optimization problems; however, the tradeoff of convergence and diversity is still the challenge for optimization algorithms. In this paper, we propose a modified particle swarm optimization based on decomposition framework with different ideal points on each reference vector, called MPSO/DD, for many-objective optimization problems. In the MPSO/DD algorithm, the decomposition strategy is used to ensure the diversity of the population, and the ideal point on each reference vector can draw the population converge faster to the optimal front. The position of each individual will be updated by learning the demonstrators in its neighborhood that have less distance to the ideal point along the reference vector. Eight state-of-the-art evolutionary multi-/many-objective optimization algorithms are adopted to compare the performance with MPSO/DD for solving many-objective optimization problems. The experimental results on seven DTLZ test problems with 3, 5, 8, 10, 15 and 20 objectives, respectively, show the efficiency of our proposed method on solving problems with high-dimensional objective space.																	2199-4536	2198-6053				JUL	2020	6	2					263	274		10.1007/s40747-020-00134-7													
J								Generating multiple reference vectors for a class of many-objective optimization problems with degenerate Pareto fronts	COMPLEX & INTELLIGENT SYSTEMS										Evolutionary algorithm; Many-objective optimization; Irregular Pareto front; Mapping; Hierarchical clustering; Polyester filament	EVOLUTIONARY ALGORITHM; MOEA/D	Many-objective optimization problems with degenerate Pareto fronts are hard to solve for most existing many-objective evolutionary algorithms. This is particularly true when the shape of the degenerate Pareto front is very narrow, and there are many dominated solutions near the Pareto front. To solve this particular class of many-objective optimization problems, a new evolutionary algorithm is proposed in this paper. In this algorithm, a set of reference vectors is generated to locate the potential Pareto front and then generate a set of location vectors. With the help of the location vectors, the solutions near the Pareto front are mapped to the hyperplane and clustered to generate more reference vectors pointing to Pareto front. This way, the location vectors are able to efficiently guide the population to converge towards the Pareto front. The effectiveness of the proposed algorithm is examined on two typical test problems with degenerate Pareto fronts, namely DTLZ5 and DTLZ6 with 5-40 objectives. Our experimental results show that the proposed algorithm has a clear advantage in dealing with this class of many-objective optimization problems. In addition, the proposed algorithm has also been successfully applied to optimization of process parameters of polyester fiber filament melt-transportation.																	2199-4536	2198-6053				JUL	2020	6	2					275	285		10.1007/s40747-020-00136-5													
J								Extentions of neutrosophic cubic sets via complex fuzzy sets with application	COMPLEX & INTELLIGENT SYSTEMS										Fuzzy sets; Complex fuzzy sets; Cubic sets; Neutrosophic sets; Neutrosophic cubic sets; Complex neutrosophic cubic sets	DECISION	In this paper, we propose that the complex neutrosophic cubic set (internal and external) show, which is a blend of complex fuzzy sets, neutrosophic sets, and cubic sets. We characterize a few set theoretic activities of internal complex neutrosophic sets, for example, union, intersection and complement, and a while later the operational principles. A few ideas identified with the structure of this model are clarified. We present some accumulation administrators and talk about some basic leadership issue with genuine model.																	2199-4536	2198-6053				JUL	2020	6	2					309	320		10.1007/s40747-019-00120-8													
J								Predicting COVID-19 in China Using Hybrid AI Model	IEEE TRANSACTIONS ON CYBERNETICS										Epidemics; Viruses (medical); Predictive models; Market research; Analytical models; Natural language processing; Coronavirus disease 2019 (COVID-19) prediction; epidemic model; hybrid artificial-intelligence (AI) model; natural language processing (NLP)	OUTBREAK CONTROL; EPIDEMIC MODEL; EBOLA; SEIR	The coronavirus disease 2019 (COVID-19) breaking out in late December 2019 is gradually being controlled in China, but it is still spreading rapidly in many other countries and regions worldwide. It is urgent to conduct prediction research on the development and spread of the epidemic. In this article, a hybrid artificial-intelligence (AI) model is proposed for COVID-19 prediction. First, as traditional epidemic models treat all individuals with coronavirus as having the same infection rate, an improved susceptible-infected (ISI) model is proposed to estimate the variety of the infection rates for analyzing the transmission laws and development trend. Second, considering the effects of prevention and control measures and the increase of the public's prevention awareness, the natural language processing (NLP) module and the long short-term memory (LSTM) network are embedded into the ISI model to build the hybrid AI model for COVID-19 prediction. The experimental results on the epidemic data of several typical provinces and cities in China show that individuals with coronavirus have a higher infection rate within the third to eighth days after they were infected, which is more in line with the actual transmission laws of the epidemic. Moreover, compared with the traditional epidemic models, the proposed hybrid AI model can significantly reduce the errors of the prediction results and obtain the mean absolute percentage errors (MAPEs) with 0.52%, 0.38%, 0.05%, and 0.86% for the next six days in Wuhan, Beijing, Shanghai, and countrywide, respectively.																	2168-2267	2168-2275				JUL	2020	50	7					2891	2904		10.1109/TCYB.2020.2990162													
J								Command Filter-Based Adaptive NN Control for MIMO Nonlinear Systems With Full-State Constraints and Actuator Hysteresis	IEEE TRANSACTIONS ON CYBERNETICS										Nonlinear systems; MIMO communication; Hysteresis; Artificial neural networks; Actuators; Backstepping; Adaptive systems; Actuator hysteresis; command filter; full state constraints; multi-input and multioutput (MIMO) nonlinear systems; neural network (NN) control	BARRIER LYAPUNOV FUNCTIONS; OUTPUT-FEEDBACK CONTROL; NEURAL-CONTROL; FUZZY-SYSTEMS	This article studies the issue of adaptive neural network (NN) control for strict-feedback multi-input and multioutput (MIMO) nonlinear systems with full-state constraints and actuator hysteresis. Radial basis function NNs (RBFNNs) are introduced to approximate unknown nonlinear functions. The command filter is adopted to solve the issue of "explosion of complexity." By applying a one-to-one nonlinear mapping, the strict-feedback system with full-state constraints is converted into a new pure-feedback system without state constraints, and a novel NN control method is proposed. The stability of the closed-loop system is proved via the Lyapunov stability theory, and the tracking errors converge to small residual sets. The simulation results are given to confirm the validity of the proposed method.																	2168-2267	2168-2275				JUL	2020	50	7					2905	2915		10.1109/TCYB.2019.2944761													
J								Event-Triggered Consensus of Linear Multiagent Systems With Time-Varying Communication Delays	IEEE TRANSACTIONS ON CYBERNETICS										Delays; Switches; Multi-agent systems; Time-varying systems; Erbium; Switching systems; Event-triggered control (ETC); multiagent systems (MASs); switching controller; time-varying communication delays	H-INFINITY CONTROL	In this paper, the event-triggered consensus problem of linear multiagent systems with time-varying communication delays is addressed. Different from the existing event-triggered consensus results with communication delays, more general nonuniform time-varying communication delays are considered. To avoid the asynchronous phenomenon caused by nonuniform delays, a novel periodic switching controller is developed. Based on this controller, the resulting consensus error system can be modeled as a periodic switching system. Furthermore, the exponential stability of the consensus error system is derived by utilizing the Lyapunov approach and the dwell-time analysis method. Finally, an illustrative example is presented to demonstrate the effectiveness of the developed method.																	2168-2267	2168-2275				JUL	2020	50	7					2916	2925		10.1109/TCYB.2019.2922740													
J								Fully Distributed Synchronization of Dynamic Networked Systems With Adaptive Nonlinear Couplings	IEEE TRANSACTIONS ON CYBERNETICS										Couplings; Synchronization; Nonlinear dynamical systems; Vehicle dynamics; Eigenvalues and eigenfunctions; Power system dynamics; Topology; Adaptive control; dynamic networks; nonlinear coupling; synchronization problem	MULTIAGENT SYSTEMS; CONSENSUS; CONTROLLABILITY	In this article, we consider the distributed synchronization problem of dynamic networked systems with adaptive nonlinear couplings. Based on how the information is collected, the interactions between subsystems are characterized by nonlinear relative state couplings and nonlinear absolute state couplings. In both cases, we show that the considered nonlinear interactions can be used to simulate the couplings with disturbed relative or absolute states. In order to implement the nonlinear couplings in a fully distributed fashion, adaptive control laws are proposed for the adjustment of coupling strengths between connected subsystems. It is shown that the connected network topology is sufficient to ensure the synchronization of dynamic networked systems with the proposed adaptive nonlinear coupling methods. Different from many existing works, the sigma-modification technique is used to suppress the increase of the coupling strengths with an additional benefit of preventing the coupling strengths from increasing. Simulation examples are given to assess the performance of the proposed adaptive nonlinear couplings.																	2168-2267	2168-2275				JUL	2020	50	7					2926	2934		10.1109/TCYB.2019.2944971													
J								Memristor-Based Neural Network Circuit of Full-Function Pavlov Associative Memory With Time Delay and Variable Learning Rate	IEEE TRANSACTIONS ON CYBERNETICS										Associative memory; Memristors; Dogs; Biological neural networks; Delay effects; Integrated circuit modeling; Neurons; Circuit simulation; memristor; Pavlov associative memory; time delay	SYNCHRONIZATION; SYNAPSE; MODEL; GAME; GO	Most memristor-based Pavlov associative memory neural networks strictly require that only simultaneous food and ring appear to generate associative memory. In this article, the time delay is considered, in order to form associative memory when the food stimulus lags behind the ring stimulus for a certain period of time. In addition, the rate of learning can be changed with the length of time between the ring stimulus and food stimulus. A memristive neural network circuit that can realize Pavlov associative memory with time delay is designed and verified by the simulation results. The designed circuit consists of a synapse module, a voltage control module, and a time-delay module. The functions, such as learning, forgetting, fast learning, slow forgetting, and time-delay learning, are implemented by the circuit. The Pavlov associative memory neural network with time-delay learning provides a reference for further development of the brain-like systems.																	2168-2267	2168-2275				JUL	2020	50	7					2935	2945		10.1109/TCYB.2019.2951520													
J								Adaptive Neural Event-Triggered Control for Discrete-Time Strict-Feedback Nonlinear Systems	IEEE TRANSACTIONS ON CYBERNETICS										Artificial neural networks; Adaptive systems; Bandwidth; Closed loop systems; Nonlinear dynamical systems; Adaptive control; discrete-time systems; event-triggered (ET) condition; neural networks (NNs); strict-feedback systems	TRACKING CONTROL; MULTIAGENT SYSTEMS; NETWORK CONTROL; H-INFINITY; NN CONTROL; CONSENSUS; DESIGN	This paper proposes a novel event-triggered (ET) adaptive neural control scheme for a class of discrete-time nonlinear systems in a strict-feedback form. In the proposed scheme, the ideal control input is derived in a recursive design process, which relies on system states only and is unrelated to virtual control laws. In this case, the high-order neural networks (NNs) are used to approximate the ideal control input (but not the virtual control laws), and then the corresponding adaptive neural controller is developed under the ET mechanism. A modified NN weight updating law, nonperiodically tuned at triggering instants, is designed to guarantee the uniformly ultimate boundedness (UUB) of NN weight estimates for all sampling times. In virtue of the bounded NN weight estimates and a dead-zone operator, the ET condition together with an adaptive ET threshold coefficient is constructed to guarantee the UUB of the closed-loop networked control system through the Lyapunov stability theory, thereby largely easing the network communication load. The proposed ET condition is easy to implement because of the avoidance of: 1) the use of the intermediate ET conditions in the backstepping procedure; 2) the computation of virtual control laws; and 3) the redundant triggering of events when the system states converge to a desired region. The validity of the presented scheme is demonstrated by simulation results.																	2168-2267	2168-2275				JUL	2020	50	7					2946	2958		10.1109/TCYB.2019.2921733													
J								Lagrange Stability and Finite-Time Stabilization of Fuzzy Memristive Neural Networks With Hybrid Time-Varying Delays	IEEE TRANSACTIONS ON CYBERNETICS										Memristors; Stability analysis; Control theory; Neural networks; Delay effects; Synchronization; Finite-time stabilization; fuzzy logics; hybrid time delays; Lagrange stability; memristive neural networks (MNNs)	GLOBAL EXPONENTIAL STABILITY; GENERAL-CLASS; SYNCHRONIZATION; SYSTEMS; DESIGN; DISCRETE; FEEDBACK	This paper focuses on Lagrange exponential stability and finite-time stabilization of Takagi-Sugeno (T-S) fuzzy memristive neural networks with discrete and distributed time-varying delays (DFMNNs). By resorting to theories of differential inclusions and the comparison strategy, an algebraic condition is developed to confirm Lagrange exponential stability of the underlying DFMNNs in Filippov's sense, and the exponentially attractive set is estimated. When external input is not considered, global exponential stability of DFMNNs is derived directly, which includes some existing ones as special cases. Furthermore, finite-time stabilization of the addressed DFMNNs is analyzed by exploiting inequality techniques and the comparison approach via designing a nonlinear state feedback controller. The boundedness assumption of activation functions is removed herein. Finally, two simulations are presented to demonstrate the validness of the outcomes, and an application is performed in pseudorandom number generation.																	2168-2267	2168-2275				JUL	2020	50	7					2959	2970		10.1109/TCYB.2019.2912890													
J								Adaptive Neural Control of a Class of Stochastic Nonlinear Uncertain Systems With Guaranteed Transient Performance	IEEE TRANSACTIONS ON CYBERNETICS										Neural networks; Adaptive systems; Nonlinear systems; Backstepping; Transient analysis; Approximation error; Time-varying systems; Adaptive control; neutral network; nonlinear control; stochastic disturbance; transient performance	OUTPUT-FEEDBACK CONTROL; DYNAMIC SURFACE CONTROL; ACTUATOR FAILURE COMPENSATION; DISCRETE-TIME-SYSTEMS; TRACKING CONTROL; STABILIZATION	In this paper, an adaptive neural network control for stochastic nonlinear systems with uncertain disturbances is proposed. The neural network is considered to approximate an uncertain function in a nonlinear system. And computational burden in operation is reduced by handling the norm of the neural-network vector. However, it will arise chattering issue, which is a challenge to avoid it from the symbolic operation. Further, traditional schemes often view error of estimate as bounded constant, but it is a time-varying function exactly, which may lead control schemes cannot conform to practical situation and guarantee stability of systems. Thus, backstepping technology and the neural network technology combined to stabilize stochastic nonlinear systems together to handle the aforementioned issues. It is proved that the proposed control scheme can guarantee the satisfactory asymptotic convergence performance and predetermined transient tracking error performance. From simulation results, the proposed control scheme is verified that can guarantee the satisfactory effectiveness.																	2168-2267	2168-2275				JUL	2020	50	7					2971	2981		10.1109/TCYB.2019.2891265													
J								Tracking Performance Limitations of MIMO Networked Control Systems With Multiple Communication Constraints	IEEE TRANSACTIONS ON CYBERNETICS										MIMO communication; Control systems; Bandwidth; Poles and zeros; Power distribution; Resource management; Linear systems; Bandwidth; communication noise; encoder-decoder; performance limitation; power distribution; quantization noise; reference noise	DISCRETE-TIME-SYSTEMS; NONLINEAR-SYSTEMS; PACKET DROPOUTS; FEEDBACK; DESIGN; STABILIZATION; QUANTIZATION; CHANNELS	In this paper, the tracking performance limitation of networked control systems (NCSs) is studied. The NCSs are considered as continuous-time linear multi-input multioutput (MIMO) systems with random reference noises. The controlled plants include unstable poles and nonminimum phase (NMP) zeros. The output feedback path is affected by multiple communication constraints. We focus on some basic communication constraints, including additive white noise (AWN), quantization noise, bandwidth, as well as encoder-decoder. The system performance is evaluated with the tracking error energy, and used a two-degree-of-freedom (2DOF) controller. The explicit representation of the tracking performance is given in this paper. The results indicate the tracking performance limitations rely to internal characteristics of the plant (unstable poles and NMP zeros), reference noises [the reference noise power distribution (RNPD) and its directions], and the characteristics of communication constraints. The characteristics of communication constraints include communication noise power distribution (CNPD); quantization noise power distribution (QNPD), and their distribution directions; transform bandwidth allocation (TBA); transform encoder-decoder allocation (TEA), and their allocation directions; and NMP zeros and MP part of bandwidth. Moreover, the tracking performance limitations are also affected by the angles between the each transform NMP zero direction and RNPD direction, and these angles between each transform unstable poles direction and the direction of communication constraint distribution/allocation. In addition, for MIMO NCSs, bandwidth (there are not identical two channels) can always affect the direction of unstable poles, and the channel allocation of bandwidth and encode-decode may be used for a feasible method for the performance allocation of each channel. Finally, an instance is given for verifying the effectiveness of the theoretical outcomes.																	2168-2267	2168-2275				JUL	2020	50	7					2982	2995		10.1109/TCYB.2019.2912973													
J								Adaptive Consensus Control of Linear Multiagent Systems With Dynamic Event-Triggered Strategies	IEEE TRANSACTIONS ON CYBERNETICS										Multi-agent systems; Vehicle dynamics; Adaptive control; Measurement errors; Symmetric matrices; Protocols; Nonlinear dynamical systems; Adaptive control; consensus; dynamic event-triggered strategy; multiagent systems (MASs)	TRANSMISSION STRATEGY; SYNCHRONIZATION; STATE	This paper is concerned with event-triggered consensus of general linear multiagent systems (MASs) in leaderless and leader-following networks, respectively, in the framework of adaptive control. A distributed dynamic event-triggered strategy is first proposed, in which an auxiliary parameter is introduced for each agent to regulate its threshold dynamically. The time-varying threshold ensures less triggering instants, compared with the traditional static one. Then under the proposed event-triggered strategy, a distributed adaptive consensus protocol is formed including the updating law of the coupling strength for each agent. Some criteria are derived to guarantee leaderless or leader-following consensus for MASs with general linear dynamics, respectively. Moreover, it is proved that the triggering time sequences do not exhibit Zeno behavior. Finally, the effectiveness of the proposed dynamic event-triggered control mechanism combined with adaptive control is validated by two examples.																	2168-2267	2168-2275				JUL	2020	50	7					2996	3008		10.1109/TCYB.2019.2920093													
J								Echo State Network-Based Backstepping Adaptive Iterative Learning Control for Strict-Feedback Systems: An Error-Tracking Approach	IEEE TRANSACTIONS ON CYBERNETICS										Trajectory; Nonlinear systems; Lyapunov methods; Backstepping; Adaptive control; Iterative learning control; Adaptive control; backstepping designs; iterative learning control; neural networks (NNs); strict-feedback systems	NONLINEAR-SYSTEMS; OUTPUT-FEEDBACK; STABILIZATION; INPUT	In this article, an echo state network (ESN)-based backstepping adaptive iterative learning control scheme is proposed for nonlinear strict-feedback systems performing the same operation repeatedly over a finite-time interval. Different from most of the output tracking approaches, an error-tracking approach is presented using the backstepping technique, such that the tracking error can follow a prespecified error trajectory without any requirement on the initial value of system states. Then, a novel Lyapunov function is constructed to deal with the unknown state-dependent gain function of the controller design. The uncertain nonlinearities are approximated by employing ESNs with simple feedback structures, and the weight update laws are developed by combining the parameter adaptation in the time domain and iteration domain. Moreover, the proposed control scheme is further extended to handle the strict-feedback systems with input saturations. Through the Lyapunov-like synthesis, the closed-loop stability and error convergence of the proposed error-tracking control scheme are analyzed in the presence of the approximation errors. Numerical simulations are provided to verify the effectiveness of the proposed scheme.																	2168-2267	2168-2275				JUL	2020	50	7					3009	3022		10.1109/TCYB.2019.2931877													
J								Distributed Dynamic Event-Triggered Control for Cooperative Output Regulation of Linear Multiagent Systems	IEEE TRANSACTIONS ON CYBERNETICS										Eigenvalues and eigenfunctions; Multi-agent systems; Synchronization; Output feedback; Energy resources; Adaptive control; cooperative control; event-triggered control; multiagent systems (MASs); output regulation	CONSENSUS; TIME; SYNCHRONIZATION	This paper investigates the cooperative output regulation problem for heterogeneous linear multiagent systems under fixed communication graphs via event-triggered control. A fully distributed event-triggered dynamic output feedback control law is proposed based on the feedforward design approach. At the same time, a fully distributed dynamic event-triggering mechanism is designed so that each agent can determine when to broadcast its information to its neighbors. Compared with existing related results, both the control law and the event-triggering mechanism in this paper are independent of any global information. It is shown that with the proposed dynamic event-triggered control strategy, the cooperative output regulation problem can be solved in a fully distributed manner by intermittent communication. Moreover, Zeno behavior can be strictly ruled out for each agent. Finally, the effectiveness of the proposed dynamic event-triggered control strategy is validated by a numerical example.																	2168-2267	2168-2275				JUL	2020	50	7					3023	3032		10.1109/TCYB.2019.2905931													
J								Making Sense of Spatio-Temporal Preserving Representations for EEG-Based Human Intention Recognition	IEEE TRANSACTIONS ON CYBERNETICS										Electroencephalography; Electrodes; Brain modeling; Feature extraction; Biological neural networks; Recurrent neural networks; Brain-computer interface (BCI); electroencephalography (EEG); intention recognition; spatial information; temporal information	MOTOR-IMAGERY; CLASSIFICATION; ALGORITHM; NETWORK; SIGNALS; ICA	Brain-computer interface (BCI) is a system empowering humans to communicate with or control the outside world with exclusively brain intentions. Electroencephalography (EEG)-based BCI is one of the promising solutions due to its convenient and portable instruments. Despite the extensive research of EEG in recent years, it is still challenging to interpret EEG signals effectively due to its nature of noise and difficulties in capturing the inconspicuous relations between EEG signals and specific brain activities. Most existing works either only consider EEG as chain-like sequences while neglecting complex dependencies between adjacent signals or requiring complex preprocessing. In this paper, we introduce two deep learning-based frameworks with novel spatio-temporal preserving representations of raw EEG streams to precisely identify human intentions. The two frameworks consist of both convolutional and recurrent neural networks effectively exploring the preserved spatial and temporal information in either a cascade or a parallel manner. Extensive experiments on a large scale movement intention EEG dataset (108 subjects, 3 145 160 EEG records) have demonstrated that the proposed frameworks achieve high accuracy of 98.3% and outperform a set of state-of-the-art and baseline models. The developed models are further evaluated with a real-world brain typing BCI and achieve a recognition accuracy of 93% over five instruction intentions suggesting good generalization over different kinds of intentions and BCI systems.																	2168-2267	2168-2275				JUL	2020	50	7					3033	3044		10.1109/TCYB.2019.2905157													
J								Delayed Impulsive Control for Consensus of Multiagent Systems With Switching Communication Graphs	IEEE TRANSACTIONS ON CYBERNETICS										Delays; Switches; Multi-agent systems; Stochastic processes; Position measurement; Delayed impulsive control; directed spanning tree; intelligent agent; nonuniform communication delays; switching communication graph	ASYNCHRONOUS CONSENSUS; DYNAMICAL NETWORKS; SYNCHRONIZATION; ALGORITHMS; TOPOLOGY; TRACKING; LEADER	Delayed impulsive controllers are proposed in this paper to enable the agents in a class of second-order multiagent systems (MASs) to achieve state consensus, based, respectively, on the relative full-state and partial-state sampled-data measurements among neighboring agents. It is a challenging task to analyze the consensus behaviors of the considered MASs as the dynamics of such MASs will be subjected to joint effects from delay-dependent impulses, aperiodic sampling, and switchings among different communication graphs. A novel analytical approach, based upon the discretization method, state augmentation, and linear state transformation, is developed to establish the sufficient consensus criteria on the range of the impulsive intervals and the control parameters. Remarkably, it is found that consensus in the closed-loop MASs can be always ensured by skillfully selecting the control parameters as long as the nonuniform delays and the impulsive intervals are bounded. A numerical example is finally performed to validate the effectiveness of the proposed delayed impulsive controllers.																	2168-2267	2168-2275				JUL	2020	50	7					3045	3055		10.1109/TCYB.2019.2926115													
J								Digital Controller Design via LMIs for Direct-Driven Surface Mounted PMSG-Based Wind Energy Conversion System	IEEE TRANSACTIONS ON CYBERNETICS										Mathematical model; Analytical models; Stability analysis; Wind energy; Generators; Numerical models; Permanent magnets; Linear matrix inequalities (LMIs); permanent magnet synchronous generator (PMSG); sampled-data control; Takagi-Sugeno (T-S) fuzzy	ROBUST PREDICTIVE CONTROL; COORDINATED CONTROL; POWER EXTRACTION; CONTROL STRATEGY; TURBINE; MODEL	The main concern of this paper is to design the efficient sampled-data controller scheme that resolves the stabilization issue of a surface-mounted permanent magnet synchronous generator (PMSG)-based wind energy conversion system (WECS). Distinct to the existing controller schemes on WECS, the present scheme contains both continuous (plant) and discrete (control) type of signals which outperforms the traditional scheme with continuous or discrete signals. Besides that the fundamental analysis of the closed-loop system under the designed controllers explore the dynamical characteristics of the considered PMSG-based WECS. The stability and stabilization of the proposed closed-loop system have guaranteed through the Lyapunov stability theory and solvable linear matrix inequalities (LMIs). In detail, first, the nonlinear PMSG model has equivalently expressed into linear submodels via the Takagi-Sugeno (T-S) fuzzy approach based on suitable membership rules. Second, the sufficient conditions have been derived as LMIs that ensure the stability and stabilization of the formulated T-S fuzzy PMSG-based WECS. Finally, the effectiveness of the designed controller as well as the consistency of sufficient conditions has demonstrated through numerical evaluations of the closed-loop system.																	2168-2267	2168-2275				JUL	2020	50	7					3056	3067		10.1109/TCYB.2019.2923775													
J								Visual Object Tracking by Hierarchical Attention Siamese Network	IEEE TRANSACTIONS ON CYBERNETICS										Target tracking; Visualization; Object tracking; Training; Correlation; Task analysis; Nonhomogeneous media; Attention mechanism; hierarchical attention; matching discrimination; object tracking; Siamese network	SEGMENTATION	Visual tracking addresses the problem of localizing an arbitrary target in video according to the annotated bounding box. In this article, we present a novel tracking method by introducing the attention mechanism into the Siamese network to increase its matching discrimination. We propose a new way to compute attention weights to improve matching performance by a sub-Siamese network [Attention Net (A-Net)], which locates attentive parts for solving the searching problem. In addition, features in higher layers can preserve more semantic information while features in lower layers preserve more location information. Thus, in order to solve the tracking failure cases by the higher layer features, we fully utilize location and semantic information by multilevel features and propose a new way to fuse multiscale response maps from each layer to obtain a more accurate position estimation of the object. We further propose a hierarchical attention Siamese network by combining the attention weights and multilayer integration for tracking. Our method is implemented with a pretrained network which can outperform most well-trained Siamese trackers even without any fine-tuning and online updating. The comparison results with the state-of-the-art methods on popular tracking benchmarks show that our method achieves better performance. Our source code and results will be available at https://github.com/shenjianbing/HASN.																	2168-2267	2168-2275				JUL	2020	50	7					3068	3080		10.1109/TCYB.2019.2936503													
J								Data-Driven Cyber Security in Perspective-Intelligent Traffic Analysis	IEEE TRANSACTIONS ON CYBERNETICS										Computer crime; Feature extraction; Internet; Data models; Twitter; Cyber security; Internet traffic analysis; machine learning (ML); social spam detection	SPAM; INFORMATION; PERFORMANCE; SYSTEM; CLASSIFICATION; THREATS; DESIGN	Social and Internet traffic analysis is fundamental in detecting and defending cyber attacks. Traditional approaches resorting to manually defined rules are gradually replaced by automated approaches empowered by machine learning. This revolution is accelerated by huge datasets which support machine-learning models with outstanding performance. In the context of a data-driven paradigm, this article reviews recent analytic research on cyber traffic over social networks and the Internet by using a set of common concepts of similarity, correlation, and collective indication, and by sharing security goals for classifying network host or applications and users or Tweets. The ability to do so is not determined in isolation, but rather drawn for a wide use of many different network or social flows. Furthermore, the flows exhibit many characteristics, such as fixed sized and multiple messages between source and destination. This article demonstrates a new research methodology of data-driven cyber security (DDCS) and its application in social and Internet traffic analysis. The framework of the DDCS methodology consists of three components, that is, cyber security data processing, cyber security feature engineering, and cyber security modeling. Challenges and future directions in this field are also discussed.																	2168-2267	2168-2275				JUL	2020	50	7					3081	3093		10.1109/TCYB.2019.2940940													
J								Distributed Secure Control Against Denial-of-Service Attacks in Cyber-Physical Systems Based on K-Connected Communication Topology	IEEE TRANSACTIONS ON CYBERNETICS										Cyber-physical systems; denial-of-service (DoS) attacks; distributed control; k-connected graph	MULTIAGENT SYSTEMS; CONSENSUS CONTROL; ALGORITHM	In this article, the security problem in cyber-physical systems (CPSs) against denial-of-service (DoS) attacks is studied from the perspectives of the designs of communication topology and distributed controller. To resist the DoS attacks, a new construction algorithm of the k-connected communication topology is developed based on the proposed necessary and sufficient criteria of the k-connected graph. Furthermore, combined with the k-connected topology, a distributed event-triggered controller is designed to guarantee the consensus of CPSs under mode-switching DoS (MSDoS) attacks. Different from the existing distributed control schemes, a new technology, that is, the extended Laplacian matrix method, is combined to design the distributed controller independent on the knowledge and the dwell time of DoS attack modes. Finally, the simulation example illustrates the superiority and effectiveness of the proposed construction algorithm and a distributed control scheme.																	2168-2267	2168-2275				JUL	2020	50	7					3094	3103		10.1109/TCYB.2020.2973303													
J								Observer-Based Adaptive Fuzzy Decentralized Event-Triggered Control of Interconnected Nonlinear System	IEEE TRANSACTIONS ON CYBERNETICS										Nonlinear systems; Fuzzy logic; Adaptive systems; Control systems; Observers; Interconnected systems; Symmetric matrices; Backstepping; event-triggered control (ETC); fuzzy logic systems (FLSs); interconnected nonlinear systems; output feedback	OUTPUT-FEEDBACK CONTROL; TRACKING CONTROL; STATE; CONSENSUS	This paper addresses the decentralized output feedback problem of an interconnected nonlinear system subject to uncertain interactions. A decentralized event-triggered control scheme is presented so that the decentralized output feedback problem is solved with only event-sampling states. With the proposed triggering mechanism, each subsystem only uses local signals to construct the decentralized controller at its own triggering times or the switching times. It is proved that both the tracking performance and the closed-loop stability can be preserved via the presented approach. Moreover, a uniform positive lower bound for the interevent time is guaranteed. Simulation results are presented to illustrate the effectiveness of the proposed control design.																	2168-2267	2168-2275				JUL	2020	50	7					3104	3112		10.1109/TCYB.2019.2894024													
J								Active Full-Vehicle Suspension Control via Cloud-Aided Adaptive Backstepping Approach	IEEE TRANSACTIONS ON CYBERNETICS										Suspensions (mechanical systems); Backstepping; Cloud computing; Roads; Adaptation models; Adaptive systems; Springs; Adaptive backstepping control; full active suspension system; remote cloud; wireless network	NONLINEAR-SYSTEMS; TRACKING CONTROL	This paper is concerned with the adaptive backstepping control problem for a cloud-aided nonlinear active full-vehicle suspension system. A novel model for a nonlinear active suspension system is established, in which uncertain parameters, unknown friction forces, nonlinear springs and dampers, and performance requirements are considered simultaneously. In order to deal with the nonlinear characteristics, a backstepping control strategy is developed. Meanwhile, an adaptive control strategy is proposed to handle the uncertain parameters and unknown friction forces. In the cloud-aided vehicle suspension system framework, the adaptive backstepping controller is updated in a remote cloud based on the cloud storing information, such as road information, vehicle suspension information, and reference trajectories. Finally, simulation results for a full vehicle with 7-degree of freedom model are provided to demonstrate the effectiveness of the proposed control scheme, and it is shown that the addressed controller can improve the performances more than 80% compared with passive vehicle suspension systems.																	2168-2267	2168-2275				JUL	2020	50	7					3113	3124		10.1109/TCYB.2019.2891960													
J								An Improved Fuzzy Sampled-Data Control to Stabilization of T-S Fuzzy Systems With State Delays	IEEE TRANSACTIONS ON CYBERNETICS										Delays; Symmetric matrices; Switches; Delay effects; Fuzzy systems; Stability analysis; Linear matrix inequalities; Fuzzy sampled-data control; reciprocally convex combination; state delays; T-S fuzzy systems (TSFSs)	DEPENDENT ROBUST STABILIZATION; TIME-VARYING DELAY; STABILITY ANALYSIS; CHAOTIC SYSTEMS; NEURAL-NETWORKS; SYNCHRONIZATION; DISSIPATIVITY; CRITERIA	This paper deals with the issue of sampled-data stabilization for T-S fuzzy systems (TSFSs) with state delays and nonuniform sampling. First, a fuzzy membership function (FMFs)-dependent approach is proposed, which uses information not only on both the delayed state and actual sampling pattern but also on the FMFs. Second, the inner sampling interval is split into flexible terminals, and a novel FMFs-dependent Lyapunov-Krasovskii functional (LKF) is constructed. Meanwhile, a fuzzy sampled-data controller (FSDC) with a switched topology is designed to solve the tricky issue on the estimation of FMFs-dependent terms. Then, based on the LKF methodology, the extended Wirtinger's inequality, and an improved reciprocally convex combination strategy, some relaxed criteria with both a larger sampling period and upper bound of time delays for achieving the stabilization of TSFSs are derived. Two numerical examples are presented to demonstrate the superiority and applicability of the proposed scheme.																	2168-2267	2168-2275				JUL	2020	50	7					3125	3135		10.1109/TCYB.2019.2910520													
J								Quasi-Consensus of Heterogeneous-Switched Nonlinear Multiagent Systems	IEEE TRANSACTIONS ON CYBERNETICS										Multi-agent systems; Switches; Lyapunov methods; Complex networks; Synchronization; Switched systems; Nonlinear multiagent systems; quasi-consensus; switching systems	LEADER-FOLLOWING CONSENSUS; BOUNDED SYNCHRONIZATION; DYNAMICAL NETWORKS; NONIDENTICAL NODES; STABILITY ANALYSIS; STABILIZATION; CONVERGENCE; COOPERATION; TOPOLOGIES; CENTRALITY	In this paper, the quasi-consensus problem is investigated for a class of heterogeneous-switched nonlinear multiagent systems, in which both cooperation and competition interactions are considered simultaneously. By means of the Lyapunov function method, we show that quasi-consensus can be ensured for switched multiagent systems under the assumption that the activation time of cooperation interactions is sufficiently large. Moreover, a new Lyapunov function is considered to provide the lower and upper bounds of switching intervals explicitly. Thus, these bounds can be used to obtain less conservative stability results of switched systems. Furthermore, the established results are specialized to both the traditional consensus case and the stability of linear-switched systems. Finally, simulations are given to illustrate the theoretical results derived in this paper.																	2168-2267	2168-2275				JUL	2020	50	7					3136	3146		10.1109/TCYB.2018.2882191													
J								Optimal Output Regulation of Linear Discrete-Time Systems With Unknown Dynamics Using Reinforcement Learning	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Heuristic algorithms; Mathematical model; System dynamics; Optimal control; Automation; Reinforcement learning; Discrete-time (DT) systems; model-free; optimal output regulation; reinforcement learning (RL)	OPTIMAL TRACKING CONTROL; ADAPTIVE OPTIMAL-CONTROL; H-INFINITY CONTROL; ZERO-SUM GAMES; SERVOMECHANISM PROBLEM; ROBUST-CONTROL	This paper presents a model-free optimal approach based on reinforcement learning for solving the output regulation problem for discrete-time systems under disturbances. This problem is first broken down into two optimization problems: 1) a constrained static optimization problem is established to find the solution to the output regulator equations (i.e., the feedforward control input) and 2) a dynamic optimization problem is established to find the optimal feedback control input. Solving these optimization problems requires the knowledge of the system dynamics. To obviate this requirement, a model-free off-policy algorithm is presented to find the solution to the dynamic optimization problem using only measured data. Then, based on the solution to the dynamic optimization problem, a model-free approach is provided for the static optimization problem. It is shown that the proposed algorithm is insensitive to the probing noise added to the control input for satisfying the persistence of excitation condition. Simulation results are provided to verify the effectiveness of the proposed approach.																	2168-2267	2168-2275				JUL	2020	50	7					3147	3156		10.1109/TCYB.2018.2890046													
J								Exponential Stability of Fractional-Order Impulsive Control Systems With Applications in Synchronization	IEEE TRANSACTIONS ON CYBERNETICS										Synchronization; Neural networks; Control systems; Biological system modeling; Asymptotic stability; Stability criteria; Cohen-Grossberg neural network; exponential stability; exponential synchronization; generalized Caputo fractional derivative; impulsive control	MITTAG-LEFFLER STABILITY; GROSSBERG NEURAL-NETWORKS; PROJECTIVE SYNCHRONIZATION; ACTIVATION FUNCTIONS; GLOBAL STABILITY; STABILIZATION; EXISTENCE	This paper investigates exponential stability of fractional-order impulsive control systems (FICSs) and exponential synchronization of fractional-order Cohen-Grossberg neural networks (FCGNNs). First, under the framework of the generalized Caputo fractional-order derivative, some new results for fractional-order calculus are established by mainly using L'Hospital's rule and Laplace transform. Besides, FICSs are translated into impulsive differential equations with fractional-order via utilizing the definition of Dirac function, which reveals that the effect of impulsive control on fractional systems is dependent of the order of the addressed systems. Furthermore, exponential stability of FICSs is proposed and some novel criteria are obtained by applying average impulsive interval and the method of induction. As an application of the stability for FICSs, exponential synchronization of FCGNNs is considered and several synchronization conditions are established under impulsive control. Finally, several numerical examples are provided to illustrate the effectiveness of the derived results.																	2168-2267	2168-2275				JUL	2020	50	7					3157	3168		10.1109/TCYB.2019.2906497													
J								Distributed Event-Triggered Consensus of Multiagent Systems With Communication Delays: A Hybrid System Approach	IEEE TRANSACTIONS ON CYBERNETICS										Delays; Closed loop systems; Multi-agent systems; Nickel; Integrated circuits; Topology; Communication delays; hybrid systems; leader-following consensus; multiagent systems (MASs); Zeno-freeness	H-INFINITY; SYNCHRONIZATION; NETWORKS	This paper investigates the leader-following consensus problem for multiagent systems (MASs) with communication delays. A novel hybrid event-triggered control scheme is developed and a hybrid system approach is proposed to design the event-triggering condition. Meanwhile, by means of temporal regularization, a strictly positive lower bound on the interevent times can be guaranteed, that is, Zeno-freeness can be guaranteed. The MASs are first described as a closed-loop system with both flow dynamics and jump dynamics, where the jump dynamics is induced from the triggering events and communication delays. Then, a hybrid model of the MASs is constructed under a hybrid systems framework. Based on this hybrid model, how to construct the Lyapunov function is given and the event-triggering condition design is also developed, such that the asymptotic consensus is achieved. Finally, an example is provided to show the effectiveness of the proposed approach.																	2168-2267	2168-2275				JUL	2020	50	7					3169	3181		10.1109/TCYB.2019.2912403													
J								ADP-Based Online Tracking Control of Partially Uncertain Time-Delayed Nonlinear System and Application to Wheeled Mobile Robots	IEEE TRANSACTIONS ON CYBERNETICS										Delay effects; Nonlinear systems; Adaptive systems; Resistance; Delays; Mobile robots; Adaptive dynamic programming (ADP); neural network (NN); time delay; tracking control; wheeled mobile robot	ALGORITHM; DESIGN	In this paper, an adaptive dynamic programming-based online adaptive tracking control algorithm is proposed to solve the tracking problem of the partial uncertain time-delayed nonlinear affine system with uncertain resistance. Using the discrete-time Hamilton-Jacobi-Bellman function, the input time-delay separation lemma, and the Lyapunov-Krasovskii functionals, the partial state and input time delay can be determined. With the approximation of the action and critic, and resistance neural networks, a near-optimal controller and appropriate adaptive laws are defined to guarantee the uniform ultimate boundedness of all signals in the target system, and the tracking error convergence to a small compact set to zero. A numerical simulation of the wheeled mobile robotic system is presented to verify the validity of the proposed method.																	2168-2267	2168-2275				JUL	2020	50	7					3182	3194		10.1109/TCYB.2019.2900326													
J								A Finite-Time Convergent and Noise-Rejection Recurrent Neural Network and Its Discretization for Dynamic Nonlinear Equations Solving	IEEE TRANSACTIONS ON CYBERNETICS										Mathematical model; Nonlinear equations; Convergence; Numerical models; Computational modeling; Recurrent neural networks; Dynamic nonlinear equation; finite-time convergence; noise rejection; zeroing neural network (ZNN)	MANIPULATORS	The so-called zeroing neural network (ZNN) is an effective recurrent neural network for solving dynamic problems including the dynamic nonlinear equations. There exist numerous unperturbed ZNN models that can converge to the theoretical solution of solvable nonlinear equations in infinity long or finite time. However, when these ZNN models are perturbed by external disturbances, the convergence performance would be dramatically deteriorated. To overcome this issue, this paper for the first time proposes a finite-time convergent ZNN with the noise-rejection capability to endure disturbances and solve dynamic nonlinear equations in finite time. In theory, the finite-time convergence and noise-rejection properties of the finite-time convergent and noise-rejection ZNN (FTNRZNN) are rigorously proved. For potential digital hardware realization, the discrete form of the FTNRZNN model is established based on a recently developed five-step finite difference rule to guarantee a high computational accuracy. The numerical results demonstrate that the discrete-time FTNRZNN can reject constant external noises. When perturbed by dynamic bounded or unbounded linear noises, the discrete-time FTNRZNN achieves the smallest steady-state errors in comparison with those generated by other discrete-time ZNN models that have no or limited ability to handle these noises. Discrete models of the FTNRZNN and the other ZNNs are comparatively applied to redundancy resolution of a robotic arm with superior positioning accuracy of the FTNRZNN verified.																	2168-2267	2168-2275				JUL	2020	50	7					3195	3207		10.1109/TCYB.2019.2906263													
J								Distributed Algorithm Design for Nonsmooth Resource Allocation Problems	IEEE TRANSACTIONS ON CYBERNETICS										Resource management; Cost function; Convergence; Distributed algorithms; Eigenvalues and eigenfunctions; Cybernetics; Distributed optimization; nonsmooth analysis; resource allocation; subgradient-based algorithms; weight-balanced digraphs	CONTINUOUS-TIME ALGORITHMS; ECONOMIC-DISPATCH; GRADIENT-METHOD; OPTIMIZATION; NETWORK; CONSENSUS; COORDINATION	This paper investigates resource allocation problems, where the cost functions of agents are nonsmooth and the decisions of agents are constrained by heterogeneous local constraints and network resource constraints. We design a distributed subgradient-based algorithm to achieve the optimal resource allocation. Moreover, we analyze the convergence of the algorithm to the optimal solution. The algorithm can solve resource allocation problems with strongly convex cost functions and weight-balanced digraphs, as well as resource allocation problems with strictly convex cost functions and connected undirected graphs. With the algorithm, the decisions of all agents asymptotically converge to the optimal allocation. Simulation examples verify the effectiveness of the algorithm.																	2168-2267	2168-2275				JUL	2020	50	7					3208	3217		10.1109/TCYB.2019.2901256													
J								Neural-Network Vector Controller for Permanent-Magnet Synchronous Motor Drives: Simulated and Hardware-Validated Results	IEEE TRANSACTIONS ON CYBERNETICS										Artificial neural networks; Machine vector control; Permanent magnet motors; Mathematical model; Hardware; Synchronous motors; Current control; Approximate dynamic programming (ADP); neural network (NN); permanent-magnet synchronous motor (PMSM); vector control; voltage source inverter (VSI)	SPEED CONTROL	This paper focuses on current control in a permanent-magnet synchronous motor (PMSM). This paper has two main objectives: the first objective is to develop a neural-network (NN) vector controller to overcome the decoupling inaccuracy problem associated with the conventional proportional-integral-based vector-control methods. The NN is developed using the full dynamic equation of a PMSM, and trained to implement optimal control based on approximate dynamic programming. The second objective is to evaluate the robust and adaptive performance of the NN controller against that of the conventional standard vector controller under motor parameter variation and dynamic control conditions by: 1) simulating the behavior of a PMSM typically used in realistic electric vehicle applications and 2) building an experimental system for hardware validation as well as combined hardware and simulation evaluation. The results demonstrate that the NN controller outperforms conventional vector controllers in both simulation and hardware implementation.																	2168-2267	2168-2275				JUL	2020	50	7					3218	3230		10.1109/TCYB.2019.2897653													
J								Event-Triggered Reinforcement Learning-Based Adaptive Tracking Control for Completely Unknown Continuous-Time Nonlinear Systems	IEEE TRANSACTIONS ON CYBERNETICS										Artificial neural networks; Performance analysis; Nonlinear dynamical systems; Function approximation; Vehicle dynamics; Indexes; Adaptive tracking control; event-triggered control; neural network (NN); reinforcement learning (RL)		In this paper, event-triggered reinforcement learning-based adaptive tracking control is developed for the continuous-time nonlinear system with unknown dynamics and external disturbances. The critic and action neural networks are designed to approximate an unknown long-term performance index and controller, respectively. The dead-zone event-triggered condition is developed to reduce communication and computational costs. Rigorous theoretical analysis is provided to show that the closed-loop system can be stabilized. The weight errors and the filtered tracking error are all uniformly ultimately bounded. Finally, to demonstrate the developed controller, the simulation results are provided using an autonomous underwater vehicle model.																	2168-2267	2168-2275				JUL	2020	50	7					3231	3242		10.1109/TCYB.2019.2903108													
J								Robust Adaptive Control Scheme for Teleoperation Systems With Delay and Uncertainties	IEEE TRANSACTIONS ON CYBERNETICS										Uncertainty; Robots; Delays; Mathematical model; Adaptation models; Stability analysis; Adaptive control; Adaptive control; Internet-based teleoperation; robust control; time-varying delay; uncertainties	FINITE-TIME CONTROL; BILATERAL TELEOPERATION; ROBOTIC MANIPULATORS; DESIGN; INPUT	This paper proposes a robust adaptive algorithm that effectively copes with time-varying delay and uncertainties in Internet-based teleoperation systems. Time-delay induced by the communication network, as a major problem in teleoperation systems, along with uncertainties in modeling of robotic manipulators and remote environment warn the stability and performance of the system. A robust adaptive control algorithm is developed to deal with the system uncertainties and to provide a smooth estimation of delayed reference signals. The proposed control algorithm generates chattering-free torques which is one of the practical considerations for robotic applications. In addition, the achieved input-to-state stability gains do not necessarily require high gain control torques to retain the system's stability. Experimental simulation studies validate the effectiveness of the proposed control strategy on a teleoperation system consisting of a Phantom Omni Haptic device and SimMechanics model of the industrial manipulator UR10. The validation of the proposed control methodology was executed through a real-time Internet-based communication established over 4G mobile networks between Australia and Scotland.																	2168-2267	2168-2275				JUL	2020	50	7					3243	3253		10.1109/TCYB.2019.2891656													
J								Consensus-Based Odor Source Localization by Multiagent Systems Under Resource Constraints	IEEE TRANSACTIONS ON CYBERNETICS										Robot sensing systems; Task analysis; Multi-agent systems; Bandwidth; Decision making; Cooperative control; event-triggered sliding-mode control (SMC); heterogeneous nonlinear multiagent systems (MASs); inverse sine hyperbolic reaching law; odor source localization (OSL); robot olfaction	STIRRED-TANK REACTOR; TIME MOTION CONTROL; TRACKING; ROBOT; OPTIMIZATION; ADVECTION; STRATEGY	With advancements in mobile robot olfaction, networked multiagent systems (MASs) are used in odor source localization (OSL). These MASs are often equipped with small microprocessors that have limited computing capabilities, and they usually operate in a bandwidth and energy-constrained environment. The exigent need for a faster localizing algorithm under communication and computational resource constraints invites many design challenges. In this paper, we have designed a two-level hierarchical cooperative control strategy for heterogeneous nonlinear MASs for OSL. The agents are forced toward consensus expeditiously once the information on the whereabouts of the source is attained. The synthesis of the controller occurs in a hierarchical manner-obtaining a group decision, followed by resource-efficient robust control. Odor concentration and wind information have been used in a group decision-making layer to predict a probable location of the source as a tracking reference. This reference is then fed to the control layer that is synthesized using event-triggered sliding-mode control (SMC). The advantage of using event-triggered control scheduling in conjunction with the SMC is rooted in retaining the robustness of the SMC while lowering the resource utilization burden. Numerical simulations confirm the efficiency of the scheme put forth.																	2168-2267	2168-2275				JUL	2020	50	7					3254	3263		10.1109/TCYB.2019.2924328													
J								Necessary and Sufficient Conditions for Consensus of Continuous-Time Multiagent Systems With Markovian Switching Topologies and Communication Noises	IEEE TRANSACTIONS ON CYBERNETICS										Switches; Topology; Multi-agent systems; Markov processes; Laplace equations; Eigenvalues and eigenfunctions; Protocols; Consensus; Markovian switchings; multiagent systems; noises; partly unknown transition rate matrix; semi-Markovian switching		This paper investigates the mean square consensus problem for continuous-time multiagent systems with randomly switching topologies and noises. The switching is governed by a time-homogeneous Markov process, and each topology corresponds to a state of the process. Meanwhile, the communication noises are also considered for practical applications. We introduce a time-varying gain which can reduce the effect of communication noises. It is shown that the effect of Markovian switching topologies mainly depends on the union of topologies associated with the positive recurrent states of the Markov process. Then, necessary and sufficient conditions can be obtained under a control protocol with time-varying gain. Moreover, we extend our result to the cases where the topological structure is semi-Markovian switching and the elements of transition rate matrix are partly unknown. Finally, we give an example to illustrate the validity of our results.																	2168-2267	2168-2275				JUL	2020	50	7					3264	3270		10.1109/TCYB.2019.2919740													
J								Event-Triggered Synchronization Strategy for Multiple Neural Networks With Time Delay	IEEE TRANSACTIONS ON CYBERNETICS										Synchronization; Couplings; Artificial neural networks; Nickel; Neurons; Laplace equations; Event-triggered; multiple neural networks (NNs); sampling coupled; synchronization	GLOBAL EXPONENTIAL PERIODICITY; COMPLEX NETWORKS; STABILITY; SYSTEMS; COMMUNICATION; CRITERIA	This paper deals with global exponential synchronization of multiple neural networks (NNs) with time delay via a very broad class of event-triggered coupling, in which coupling matrix can be non-Laplacian. Some simple and convenient sufficient conditions are derived to guarantee global exponential synchronization of the coupling NNs under an event-triggered strategy. In particular, the effect of the common subsystem can be positive or negative on the synchronization scheme. Three examples are presented to test the results in theory analysis.																	2168-2267	2168-2275				JUL	2020	50	7					3271	3280		10.1109/TCYB.2019.2911029													
J								Multisource Transfer Learning for Cross-Subject EEG Emotion Recognition	IEEE TRANSACTIONS ON CYBERNETICS										Brain modeling; Electroencephalography; Emotion recognition; Data models; Training; Calibration; Training data; Brain-computer interface; emotion recognition; transfer learning (TL)	DIFFERENTIAL ENTROPY FEATURE; BRAIN	Electroencephalogram (EEG) has been widely used in emotion recognition due to its high temporal resolution and reliability. Since the individual differences of EEG are large, the emotion recognition models could not be shared across persons, and we need to collect new labeled data to train personal models for new users. In some applications, we hope to acquire models for new persons as fast as possible, and reduce the demand for the labeled data amount. To achieve this goal, we propose a multisource transfer learning method, where existing persons are sources, and the new person is the target. The target data are divided into calibration sessions for training and subsequent sessions for test. The first stage of the method is source selection aimed at locating appropriate sources. The second is style transfer mapping, which reduces the EEG differences between the target and each source. We use few labeled data in the calibration sessions to conduct source selection and style transfer. Finally, we integrate the source models to recognize emotions in the subsequent sessions. The experimental results show that the three-category classification accuracy on benchmark SEED improves by 12.72% comparing with the nontransfer method. Our method facilitates the fast deployment of emotion recognition models by reducing the reliance on the labeled data amount, which has practical significance especially in fast-deployment scenarios.																	2168-2267	2168-2275				JUL	2020	50	7					3281	3293		10.1109/TCYB.2019.2904052													
J								Efficient Robust Model Fitting for Multistructure Data Using Global Greedy Search	IEEE TRANSACTIONS ON CYBERNETICS										Data models; Computational modeling; Search problems; Sampling methods; Fuses; Computer vision; Mutual information; Computer vision; fusion strategy; global greedy search; multistructure data; robust model fitting	POINT SET REGISTRATION; SEGMENTATION	In this paper, a new robust model fitting method is proposed to efficiently segment multistructure data even when they are heavily contaminated by outliers. The proposed method is composed of three steps: first, a conventional greedy search strategy is employed to generate (initial) model hypotheses based on the sequential "fit-and-remove" procedure because of its computational efficiency. Second, to efficiently generate accurate model hypotheses close to the true models, a novel global greedy search strategy initially samples from the inliers of the obtained model hypotheses and samples subsequent data subsets from the whole input data. Third, mutual information theory is applied to fuse the model hypotheses of the same model instance. The conventional greedy search strategy is used to generate model hypotheses for the remaining model instances, if the number of retained model hypotheses is less than that of the true model instances after fusion. The second and the third steps are performed iteratively until an adequate solution is obtained. Experimental results demonstrate the effectiveness and efficiency of the proposed method for model fitting.																	2168-2267	2168-2275				JUL	2020	50	7					3294	3306		10.1109/TCYB.2019.2900096													
J								Lexicographic Multiobjective Scatter Search for the Optimization of Sequence-Dependent Selective Disassembly Subject to Multiresource Constraints	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Planning; Energy consumption; Genetic algorithms; Sequential analysis; Particle swarm optimization; Adaptation models; Disassembly sequence; multiobjective optimization; multiresource constraints; scatter search (SS); sequence-dependent	ANT COLONY OPTIMIZATION; GENETIC ALGORITHM; PATH-RELINKING; PRODUCTS; PLANNER; DESIGN	Industrial products' reuse, recovery, and recycling are very important because of their environmental and economic benefits. Effective product disassembly planning methods can improve their recovery efficiency and reduce their bad environmental impact. However, the existing approaches pay little attention to sequence-dependent disassembly with resource constraints, such as limited disassembly operators and tools, which makes the current planning methods ineffective in practice. This paper considers a multiobjective resource-constrained and sequence-dependent disassembly optimization problem with disassembly precedence constraints. Energy consumption is adopted to evaluate the disassembly efficiency. Its use with traditional optimization criterion leads to a novel multiobjective optimization model such that the energy consumption and disassembly time are minimized while disassembly profit is maximized. Since the problem complexity increases with the number of components in a product, a lexicographic multiobjective scatter search (SS) method is proposed to solve the proposed multiobjective optimization problem. Its effectiveness is verified by comparing the results of linear weight SS and genetic algorithms. The results show that it is able to provide a better solution in a short execution time and fulfills the precedence requirement in a product structure and resource constraints.																	2168-2267	2168-2275				JUL	2020	50	7					3307	3317		10.1109/TCYB.2019.2901834													
J								Generative Adversarial Networks and Conditional Random Fields for Hyperspectral Image Classification	IEEE TRANSACTIONS ON CYBERNETICS										Gallium nitride; Deep learning; Training; Generators; Generative adversarial networks; Data models; Hyperspectral imaging; Conditional random fields (CRFs); generative adversarial networks (GANs); hyperspectral image (HSI) classification; semisupervised deep learning	REPRESENTATION; FRAMEWORK	In this paper, we address the hyperspectral image (HSI) classification task with a generative adversarial network and conditional random field (GAN-CRF)-based framework, which integrates a semisupervised deep learning and a probabilistic graphical model, and make three contributions. First, we design four types of convolutional and transposed convolutional layers that consider the characteristics of HSIs to help with extracting discriminative features from limited numbers of labeled HSI samples. Second, we construct semisupervised generative adversarial networks (GANs) to alleviate the shortage of training samples by adding labels to them and implicitly reconstructing real HSI data distribution through adversarial training. Third, we build dense conditional random fields (CRFs) on top of the random variables that are initialized to the softmax predictions of the trained GANs and are conditioned on HSIs to refine classification maps. This semisupervised framework leverages the merits of discriminative and generative models through a game-theoretical approach. Moreover, even though we used very small numbers of labeled training HSI samples from the two most challenging and extensively studied datasets, the experimental results demonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved top-ranking accuracy for semisupervised HSI classification.																	2168-2267	2168-2275				JUL	2020	50	7					3318	3329		10.1109/TCYB.2019.2915094													
J								Enhancing Sketch-Based Image Retrieval by CNN Semantic Re-ranking	IEEE TRANSACTIONS ON CYBERNETICS										Semantics; Feature extraction; Image edge detection; Image retrieval; Bridges; Noise measurement; Data mining; Classification; convolutional neural network (CNN); re-ranking; sketch-based image retrieval (SBIR)		This paper introduces a convolutional neural network (CNN) semantic re-ranking system to enhance the performance of sketch-based image retrieval (SBIR). Distinguished from the existing approaches, the proposed system can leverage category information brought by CNNs to support effective similarity measurement between the images. To achieve effective classification of query sketches and high-quality initial retrieval results, one CNN model is trained for classification of sketches, another for that of natural images. Through training dual CNN models, the semantic information of both the sketches and natural images is captured by deep learning. In order to measure the category similarity between images, a category similarity measurement method is proposed. Category information is then used for re-ranking. Re-ranking operation first infers the retrieval category of the query sketch and then uses the category similarity measurement to measure the category similarity between the query sketch and each initial retrieval result. Finally, the initial retrieval results are re-ranked. The experiments on different types of SBIR datasets demonstrate the effectiveness of the proposed re-ranking method. Comparisons with other re-ranking algorithms are also given to show the proposed method's superiority. Further, compared to the baseline systems, the proposed re-ranking approach achieves significantly higher precision in the top ten different SBIR methods and datasets.																	2168-2267	2168-2275				JUL	2020	50	7					3330	3342		10.1109/TCYB.2019.2894498													
J								Local Binary Pattern-Based Adaptive Differential Evolution for Multimodal Optimization Problems	IEEE TRANSACTIONS ON CYBERNETICS										Sociology; Statistics; Optimization; Image processing; Cybernetics; Computer science; Indexes; Adaptive differential evolution (DE); DE; local binary pattern (LBP) strategy; multimodal optimization problems (MMOPs)	PARTICLE SWARM OPTIMIZATION; MULTIOBJECTIVE OPTIMIZATION; GLOBAL OPTIMIZATION; STRATEGY	The multimodal optimization problem (MMOP) requires the algorithm to find multiple global optima of the problem simultaneously. In order to solve MMOP efficiently, a novel differential evolution (DE) algorithm based on the local binary pattern (LBP) is proposed in this paper. The LBP makes use of the neighbors' information for extracting relevant pattern information, so as to identify the multiple regions of interests, which is similar to finding multiple peaks in MMOP. Inspired by the principle of LBP, this paper proposes an LBP-based adaptive DE (LBPADE) algorithm. It enables the LBP operator to form multiple niches, and further to locate multiple peak regions in MMOP. Moreover, based on the LBP niching information, we develop a niching and global interaction (NGI) mutation strategy and an adaptive parameter strategy (APS) to fully search the niching areas and maintain multiple peak regions. The proposed NGI mutation strategy incorporates information from both the niching and the global areas for effective exploration, while APS adjusts the parameters of each individual based on its own LBP information and guides the individual to the promising direction. The proposed LBPADE algorithm is evaluated on the extensive MMOPs test functions. The experimental results show that LBPADE outperforms or at least remains competitive with some state-of-the-art algorithms.																	2168-2267	2168-2275				JUL	2020	50	7					3343	3357		10.1109/TCYB.2019.2927780													
J								Angle-Closure Detection in Anterior Segment OCT Based on Multilevel Deep Network	IEEE TRANSACTIONS ON CYBERNETICS										Image segmentation; Deep learning; Feature extraction; Imaging; Iris; Visualization; Cornea; Angle-closure detection; anterior chamber angle (ACA); anterior segment optical coherence tomography (AS-OCT); deep learning	OPTICAL COHERENCE TOMOGRAPHY; DIABETIC-RETINOPATHY; ORIENTED GRADIENTS; NARROW ANGLES; GLAUCOMA; CLASSIFICATION; ASSOCIATION; VALIDATION; HISTOGRAMS; IMAGES	Irreversible visual impairment is often caused by primary angle-closure glaucoma, which could be detected via anterior segment optical coherence tomography (AS-OCT). In this paper, an automated system based on deep learning is presented for angle-closure detection in AS-OCT images. Our system learns a discriminative representation from training data that captures subtle visual cues not modeled by handcrafted features. A multilevel deep network is proposed to formulate this learning, which utilizes three particular AS-OCT regions based on clinical priors: 1) the global anterior segment structure; 2) local iris region; and 3) anterior chamber angle (ACA) patch. In our method, a sliding window-based detector is designed to localize the ACA region, which addresses ACA detection as a regression task. Then, three parallel subnetworks are applied to extract AS-OCT representations for the global image and at clinically relevant local regions. Finally, the extracted deep features of these subnetworks are concatenated into one fully connected layer to predict the angle-closure detection result. In the experiments, our system is shown to surpass previous detection methods and other deep learning systems on two clinical AS-OCT datasets.																	2168-2267	2168-2275				JUL	2020	50	7					3358	3366		10.1109/TCYB.2019.2897162													
J								Hyperplane Assisted Evolutionary Algorithm for Many-Objective Optimization Problems	IEEE TRANSACTIONS ON CYBERNETICS										Convergence; Sociology; Statistics; Optimization; Evolutionary computation; Cybernetics; Task analysis; Continuous optimization; evolutionary computations; hyperplane; many-objective optimization; selection pressure	MULTIOBJECTIVE OPTIMIZATION; DECOMPOSITION; SELECTION	In many-objective optimization problems (MaOPs), forming sound tradeoffs between convergence and diversity for the environmental selection of evolutionary algorithms is a laborious task. In particular, strengthening the selection pressure of population toward the Pareto-optimal front becomes more challenging, since the proportion of nondominated solutions in the population scales up sharply with the increase of the number of objectives. To address these issues, this paper first defines the nondominated solutions exhibiting evident tendencies toward the Pareto-optimal front as prominent solutions, using the hyperplane formed by their neighboring solutions, to further distinguish among nondominated solutions. Then, a novel environmental selection strategy is proposed with two criteria in mind: 1) if the number of nondominated solutions is larger than the population size, all the prominent solutions are first identified to strengthen the selection pressure. Subsequently, a part of the other nondominated solutions are selected to balance convergence and diversity and 2) otherwise, all the nondominated solutions are selected; then a part of the dominated solutions are selected according to the predefined reference vectors. Moreover, based on the definition of prominent solutions and the new selection strategy, we propose a hyperplane assisted evolutionary algorithm, referred here as hpaEA, for solving MaOPs. To demonstrate the performance of hpaEA, extensive experiments are conducted to compare it with five state-of-the-art many-objective evolutionary algorithms on 36 many-objective benchmark instances. The experimental results show the superiority of hpaEA which significantly outperforms the compared algorithms on 20 out of 36 benchmark instances.																	2168-2267	2168-2275				JUL	2020	50	7					3367	3380		10.1109/TCYB.2019.2899225													
J								Weakly Supervised Deep Learning for Brain Disease Prognosis Using MRI and Incomplete Clinical Scores	IEEE TRANSACTIONS ON CYBERNETICS										Magnetic resonance imaging; Diseases; Brain modeling; Feature extraction; Training; Deep learning; Prognostics and health management; Alzheimer's disease (AD); clinical score; disease prognosis; neural network; weakly supervised learning	VOXEL-BASED MORPHOMETRY; ALZHEIMERS-DISEASE; TUMOR SEGMENTATION; CLASSIFICATION; VOLUME; SCHIZOPHRENIA; SIMILARITY; NETWORKS; PATTERNS; ATROPHY	As a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (MRI) data helps to assess the stage of pathology and predict future development of the disease. Due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. This would result in limited training data for learning reliable and robust models. Also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of MRI data, and these features may not be well coordinated with prediction models. In this paper, we propose a weakly supervised densely connected neural network (wiseDNN) for brain disease prognosis using baseline MRI data and incomplete clinical scores. Specifically, we first extract multiscale image patches (located by anatomical landmarks) from MRI to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. A weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. The experimental results on 1469 subjects from both ADNI-1 and ADNI-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.																	2168-2267	2168-2275				JUL	2020	50	7					3381	3392		10.1109/TCYB.2019.2904186													
J								A Distributed Swarm Optimizer With Adaptive Communication for Large-Scale Optimization	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Adaptation models; Computational modeling; Computer science; Topology; Sociology; Statistics; Distributed evolutionary algorithms; elite-guided learning (EGL); high-dimensional problems; large-scale optimization; particle swarm optimization (PSO)	MODELING SELECTION INTENSITY; EVOLUTIONARY ALGORITHMS; COOPERATIVE COEVOLUTION; DIFFERENTIAL EVOLUTION; DECOMPOSITION; ENSEMBLE; SEARCH	Large-scale optimization with high dimensionality and high computational cost becomes ubiquitous nowadays. To tackle such challenging problems efficiently, devising distributed evolutionary computation algorithms is imperative. To this end, this paper proposes a distributed swarm optimizer based on a special master-slave model. Specifically, in this distributed optimizer, the master is mainly responsible for communication with slaves, while each slave iterates a swarm to traverse the solution space. An asynchronous and adaptive communication strategy based on the request-response mechanism is especially devised to let the slaves communicate with the master efficiently. Particularly, the communication between the master and each slave is adaptively triggered during the iteration. To aid the slaves to search the space efficiently, an elite-guided learning strategy is especially designed via utilizing elite particles in the current swarm and historically best solutions found by different slaves to guide the update of particles. Together, this distributed optimizer asynchronously iterates multiple swarms to collaboratively seek the optimum in parallel. Extensive experiments on a widely used large-scale benchmark set substantiate that the distributed optimizer could: 1) achieve competitive effectiveness in terms of solution quality as compared to the state-of-the-art large-scale methods; 2) accelerate the execution of the algorithm in comparison with the sequential one and obtain almost linear speedup as the number of cores increases; and 3) preserve a good scalability to solve higher dimensional problems.																	2168-2267	2168-2275				JUL	2020	50	7					3393	3408		10.1109/TCYB.2019.2904543													
J								Boosting Occluded Image Classification via Subspace Decomposition-Based Estimation of Deep Features	IEEE TRANSACTIONS ON CYBERNETICS										Training; Feature extraction; Estimation; Dictionaries; Computer vision; Deep learning; Task analysis; Convolutional neural networks (CNNs); deep learning; image classification; occluded image; subspace decomposition	ROBUST FACE RECOGNITION; SPARSE; OCCLUSION; REPRESENTATION; RECOVERY	Classification of partially occluded images is a highly challenging computer vision problem even for the cutting-edge deep learning technologies. To achieve a robust image classification for occluded images, this article proposes a novel scheme using the subspace decomposition-based estimation (SDBE). The proposed SDBE-based classification scheme first employs a base convolutional neural network to extract the deep feature vector (DFV) and then utilizes the SDBE to compute the DFV of the original occlusion-free image for classification. The SDBE is performed by projecting the DFV of the occluded image onto the linear span of a class dictionary (CD) along the linear span of an occlusion error dictionary (OED). The CD and OED are constructed, respectively, by concatenating the DFVs of a training set and the occlusion error vectors of an extra set of image pairs. Two implementations of the SDBE are studied in this article: 1) the l(1)-norm and 2) the squared l(2)-norm regularized least-squares estimates. By employing the ResNet-152, pretrained on the ImageNet Large-Scale Visual Recognition Challenge 2012 (ILSVRC2012) training set, as the base network, the proposed SBDE-based classification scheme is extensively evaluated on the Caltech-101 and ILSVRC2012 datasets. Extensive experimental results demonstrate that the proposed SDBE-based scheme dramatically boosts the classification accuracy for occluded images, and achieves around 22.25% increase in classification accuracy under 20% occlusion on the ILSVRC2012 dataset.																	2168-2267	2168-2275				JUL	2020	50	7					3409	3422		10.1109/TCYB.2019.2931067													
J								Data Preprocessing Technique for Neural Networks Based on Image Represented by a Fuzzy Function	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Data preprocessing; image classification; image fuzzification; image represented by fuzzy function (IRFF); neural network (NN)		Although data preprocessing is a universal technique that can be widely used in neural networks (NNs), most research in this area is focused on designing new NN architectures. This paper, we propose a preprocessing technique that enriches the original image data using local intensity information; this technique is motivated by human perception. To encode this information into an image, we introduce a new image structure named image represented by a fuzzy function. When using this structure, a crisp intensity value of each pixel is replaced by a fuzzy set given by a membership function constructed with the usage of extremal values from the particular neighborhood of that pixel. We describe this structure and its properties and propose a way in which it can he used as an input into existing NNs without any modifications. Based on our benchmark consisting of three well-known datasets and five NN architectures, we show that the proposed preprocessing can, in mast cases, decrease classification error compared with a baseline and two other preprocessing methods. To support our claim, we have also selected several publicly available projects and tested the impact of the preprocessing with a positive result.																	1063-6706	1941-0034				JUL	2020	28	7					1195	1204		10.1109/TFUZZ.2019.2911494													
J								Deep Fuzzy Echo State Networks for Machinery Fault Diagnosis	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Deep fuzzy echo state network (DFESN); deep learning; fault diagnosis; feature reinforcement; fuzzy tuning	ROTATING MACHINERY; BOLTZMANN MACHINE; BELIEF NETWORKS; NEURAL-NETWORKS; SYSTEM; TRANSFORM	An echo state network (ESN) is a recurrent neural network with low computational complexity. However, a single ESN cannot extract effective features from complex inputs, especially for dealing with low-cost condition signals in machinery fault diagnosis. A novel deep learning model, referred to as the deep fuzzy ESN (DFESN), was proposed to improve the feature extraction capability with less computational burden. In the present method, the output data of the previous ESN reservoir were regarded as abstract feature vectors for the next ESN input. The features were reinforced in each hidden layer by using fuzzy clustering as a tuning step for classification enhancement. In this way, layerwise fuzzy tuning was developed to replace traditional overall feedback fine tuning in deep models. This improved learning efficiency and robustness while overcoming the vanishing gradient problem for deep learning. The superiority of the proposed approach was evaluated by both theoretical analysis and experimental tests. The results showed that the present DFESN features improved classification accuracy and reduced the computational burden. In addition to machinery fault diagnosis, the proposed DFESN also has potential for other deep learning applications.																	1063-6706	1941-0034				JUL	2020	28	7					1205	1218		10.1109/TFUZZ.2019.2914617													
J								Passivity and Passification for Switched T-S Fuzzy Systems With Sampled-Data Implementation	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Feedback passification; min-switching; non-monotonous storage function; sampled-data implementation; switched T-S fuzzy systems	H-INFINITY CONTROL; FEEDBACK PASSIFICATION; LYAPUNOV-FUNCTION; LINEAR-SYSTEMS; NONLINEAR-SYSTEMS; NEURAL-NETWORKS; STABILIZATION; STABILITY; DESIGN; STATE	This article investigates the issues of passivity analysis and feedback passification for a class of switched Takagi-Sugeno (T-S) fuzzy systems with the sampled-data-dependent switching strategy and controllers. Different from the previous switching laws, the proposed switching law only requires the values of system state at the discrete sampling instants. More incisively, a dwell time constraint for all subsystems is produced, which reduces the switching frequency and avoids the occurrence of chattering phenomenon or Zeno behavior. Then, sufficient conditions for the existence of the sampled-data-dependent switching strategy and controllers are formulated, under which the switched T-S fuzzy systems is strictly passive without requiring the strict passivity of any subsystem. In addition, the storage function is only decreasing with respect to its value at the sampling times, which in turn implies that the storage function can be nonmonotonous. Finally, a numeral example and a room air regulating system are employed to demonstrate the effectiveness and applicability of the presented theoretical results.																	1063-6706	1941-0034				JUL	2020	28	7					1219	1229		10.1109/TFUZZ.2019.2930430													
J								Neural Network Approach to Solving Fuzzy Nonlinear Equations Using Z-Numbers	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Mathematical model; Neural networks; Nonlinear systems; Interpolation; Reliability; Nonhomogeneous media; Decision making; Fuzzy equation; multilayer neural network; uncertain nonlinear system; Z-number	ITERATIVE METHOD; SYSTEM	In this article, the fuzzy property is described by means of the Z-number as the coefficients and variables of the fuzzy equations. This alteration for the fuzzy equation is appropriate for system modeling with Z-number parameters. In this article, the fuzzy equation with Z-number coefficients and variables is tended to be used as the models for the uncertain systems. The modeling issue related to the uncertain system is to obtain the Z-number coefficients and variables of the fuzzy equation. Nevertheless, it is extremely hard to get the Z-number coefficients of the fuzzy equations. In this article, in order to model the uncertain nonlinear systems, a novel structure of the multilayer neural network is utilized in such a manner that it is able to obtain the Z-number coefficients of the fuzzy equation. The suggested technique is validated by some examples with applications.																	1063-6706	1941-0034				JUL	2020	28	7					1230	1241		10.1109/TFUZZ.2019.2940919													
J								Lip Image Segmentation Based on a Fuzzy Convolutional Neural Network	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Lips; Image segmentation; Image color analysis; Mouth; Convolutional neural networks; Image edge detection; Robustness; Convolutional neural network; fuzzy neural networks; lip region segmentation	EXTRACTION; FEATURES	Research has shown that the human lip and its movements are a rich source of information related to speech content and speaker's identity. Lip image segmentation, as a fundamental step in many lip-reading and visual speaker authentication systems, is of vital importance. Because of variations in lip color, lighting conditions and especially the complex appearance of an open mouth, accurate lip region segmentation is still a challenging task. To address this problem, this article proposes a new fuzzy deep neural network having an architecture that integrates fuzzy units and traditional convolutional units. The convolutional units are used to extract discriminative features at different scales to provide comprehensive information for pixel-level lip segmentation. The fuzzy logic modules are employed to handle various kinds of uncertainties and to provide a more robust segmentation result. An end-to-end training scheme is then used to learn the optimal parameters for both the fuzzy and the convolutional units. A dataset containing more than 48 000 images of various speakers, under different lighting conditions, was used to evaluate lip segmentation performance. According to the experimental results, the proposed method achieves state-of-the-art performance when compared with other algorithms.																	1063-6706	1941-0034				JUL	2020	28	7					1242	1251		10.1109/TFUZZ.2019.2957708													
J								A Fuzzy Deep Neural Network With Sparse Autoencoder for Emotional Intention Understanding in Human-Robot Interaction	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Feature extraction; Neural networks; Proposals; Emotion recognition; Gold; Robots; Brain modeling; Candide3 model; deep learning; fuzzy C-means; human-robot interaction; intention understanding	FACE RECOGNITION; REGRESSION	A fuzzy deep neural network with sparse autoencoder (FDNNSA) is proposed for intention understanding based on human emotions and identification information (i.e., age, gender, and region), in which the fuzzy C-means (FCM) is used to cluster the input data, and deep neural network with sparse autoencoder (DNNSA) is designed for emotional intention understanding in human-robot interaction. It aims to make robots capable of recognizing human emotions and understanding related emotional intention, the FCM is suitable for gathering similar information so that the calculations of dimensionality of DNNSA will be reduced, and the sparse autoencoder of DNNSA can make the neuron of DNNSA sparse to reduce the complexity of the network in such a way human-robot interaction is running smoothly. To validate the proposal, simulation experiments based on benchmark databases such as facial expression database of CK+, and speech emotion corpus of CASIA were completed. The experimental results show that the proposal outperforms the baseline algorithms of Softmax regression (SR), DNNSA, FCM-based SR (FSR), Softplus, Gath Geva-based DNNSA (GDNNSA), and ensemble DNNSA (EDNNSA). Preliminary application experiments are performed in the development of emotional social robot system, where volunteers experience the scenario of "drinking at the bar". The obtained results indicate that the proposed FDNNSA can promote robot understanding of emotional intention of human.																	1063-6706	1941-0034				JUL	2020	28	7					1252	1264		10.1109/TFUZZ.2020.2966167													
J								Hierarchical Fuzzy Opinion Networks: Top-Down for Social Organizations and Bottom-Up for Election	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Uncertainty; Fuzzy sets; Mathematical model; Standards; Organizations; Convergence; Psychology; Fuzzy opinion networks (FONs); opinion dynamics; social hierarchy	DYNAMICS; MODELS	A fuzzy opinion is a Gaussian fuzzy set with the center representing the opinion and the standard deviation representing the uncertainty about the opinion, and a fuzzy opinion network is a connection of a number of fuzzy opinions in a structured way. In this article, we propose a top-down hierarchical fuzzy opinion network to model how the opinion of a top leader is penetrated into the members in social organizations, and a bottom-up fuzzy opinion network to model how the opinions of a large number of agents are agglomerated layer-by-layer into a consensus or a few opinions in the social processes, such as an election. For the top-down hierarchical fuzzy opinion network, we prove that the opinions of all the agents converge to the leader's opinion but the uncertainties of the agents in different groups are generally converge to different values. We demonstrate that the speed of convergence is greatly improved by organizing the agents in a hierarchical structure of small groups. For the bottom-up hierarchical fuzzy opinion network, we simulate how a wide spectrum of opinions are negotiating and summarizing with each other, in a layer-by-layer fashion in some typical situations.																	1063-6706	1941-0034				JUL	2020	28	7					1265	1275		10.1109/TFUZZ.2020.2965864													
J								Biologically Plausible Fuzzy-Knowledge-Out and Its Induced Wide Learning of Interpretable TSK Fuzzy Classifiers	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Co-adaption; fuzzy classifier; fuzzy-knowledge-out; overfitting; Takagi-Sugeno-Kang (TSK); wide learning	NEURAL-NETWORKS; SYSTEM; MACHINE; ALGORITHMS	As an alternative to existing construction methods of Takagi-Sugeno-Kang (TSK) fuzzy classifiers, this paper presents a novel design methodology formulated by a new concept called fuzzy-knowledge-out and its induced wide learning way. Analogous to the "dropout" concept in deep learning, the concept of fuzzy-knowledge-out in TSK fuzzy classifiers is motivated by the firing pattern of knowledge in biological neural networks. Our theoretical analysis reveals that a fuzzy classifier built after fuzzy-knowledge-out from a complete set of highly interpretable fuzzy rules is distinctive in generalization and coadaption avoidance. As such, an ensemble called wide learning based TSK (WL-TSK), of highly interpretable zero-order TSK fuzzy subclassifiers constructed quickly by means of fuzzy-knowledge-out operations in a wide learning manner is proposed to achieve enhanced classification performance and high interpretability. With the use of the proposed halving or averaging operations, WL-TSK essentially behaves like only one zero-order TSK fuzzy classifier. Thus, the proposed method can be considered as a new design methodology of TSK fuzzy classifiers. Our experimental results on 15 datasets indicate the effectiveness of WL-TSK in terms of both enhanced classification performance and high interpretability.																	1063-6706	1941-0034				JUL	2020	28	7					1276	1290		10.1109/TFUZZ.2019.2907497													
J								Enabling Explainable Fusion in Deep Learning With Fuzzy Integral Neural Networks	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Artificial neural networks; Frequency modulation; Deep learning; Remote sensing; Sensors; Decision making; Choquet integral (ChI); data fusion; deep learning; explainable artificial intelligence (XAI); neural network (NN)	CLASSIFICATION; AGGREGATION	Information fusion is an essential part of numerous engineering systems and biological functions, e.g., human cognition. Fusion occurs at many levels, ranging from the low-level combination of signals to the high-level aggregation of heterogeneous decision-making processes. While the last decade has witnessed an explosion of research in deep learning, fusion in neural networks has not observed the same revolution. Specifically, most neural fusion approaches are ad hoc, are not understood, are distributed versus localized, and/or explainability is low (if present at all). Herein, we prove that the fuzzy Choquet integral (ChI), a powerful nonlinear aggregation function, can be represented as a multilayer network, referred to hereafter as ChIMP. We also put forth an improved ChIMP (iChIMP) that leads to a stochastic-gradient-descent-based optimization in light of the exponential number of ChI inequality constraints. An additional benefit of ChIMP/iChIMP is that it enables explainable artificial intelligence (XAI). Synthetic validation experiments are provided, and iChIMP is applied to the fusion of a set of heterogeneous architecture deep models in remote sensing. We show an improvement in model accuracy, and our previously established XAI indices shed light on the quality of our data, model, and its decisions.																	1063-6706	1941-0034				JUL	2020	28	7					1291	1300		10.1109/TFUZZ.2019.2917124													
J								Fast Training Algorithms for Deep Convolutional Fuzzy Systems With Application to Stock Index Prediction	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Fuzzy systems; Training; Input variables; Windows; Prediction algorithms; Computational modeling; Fuzzy sets; Deep learning; hierarchical fuzzy systems; stock index prediction; Wang-Mendel (WM) method	UNIVERSAL APPROXIMATION; NETWORKS; DESIGN; PRICES; MODELS; RULES	A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is a multilayer connection of many low-dimensional fuzzy systems, where the input variables to the low-dimensional fuzzy systems are selected through a moving window across the input spaces of the layers. To design the DCFS based on an input-output data pairs, we propose a bottom-up layer-by-layer scheme. Specifically, by viewing each of the first-layer fuzzy systems as a weak estimator of the output based only on a very small portion of the input variables, we design these fuzzy systems using the Wang-Mendel method. After the first-layer fuzzy systems are designed, we pass the data through the first layer to form a new dataset and design the second-layer fuzzy systems based on this new dataset in the same way as designing the first-layer fuzzy systems. Repeating this process layer-by-layer, we design the whole DCFS. We also propose a DCFS with parameter sharing to save memory and computation. We apply the DCFS models to predict a synthetic chaotic plus random time-series and the real Hang Seng Index of the Hong Kong stock market.																	1063-6706	1941-0034				JUL	2020	28	7					1301	1314		10.1109/TFUZZ.2019.2930488													
J								An Incremental Construction of Deep Neuro Fuzzy System for Continual Learning of Nonstationary Data Streams	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Fuzzy neural networks; Merging; Feature extraction; Buildings; Complexity theory; Training; Network architecture; Data streams; deep neural networks (DNNs); fuzzy neural network (FNN); online learning	DRIFT DETECTION METHODS; FEATURE-SELECTION; ONLINE; IDENTIFICATION; CLASSIFIER; NETWORKS	Existing fuzzy neural networks (FNNs) are mostly developed under a shallow network configuration having lower generalization power than those of deep structures. This article proposes a novel self-organizing deep FNN, namely deep evolving fuzzy neural network (DEVFNN). Fuzzy rules can be automatically extracted from data streams or removed if they play limited role during their lifespan. The structure of the network can be deepened on demand by stacking additional layers using a drift detection method, which not only detects the covariate drift, variations of input space, but also accurately identifies the real drift, dynamic changes of both feature space and target space. The DEVFNN is developed under the stacked generalization principle via the feature augmentation concept, where a recently developed algorithm, namely generic classifier, drives the hidden layer. It is equipped by an automatic feature selection method, which controls activation and deactivation of input attributes to induce varying subsets of input features. A deep network simplification procedure is put forward using the concept of hidden layer merging to prevent the uncontrollable growth of dimensionality of input space due to the nature of the feature augmentation approach in building a deep network structure. The DEVFNN works in the samplewise fashion and is compatible for data stream applications. The efficacy of the DEVFNN has been thoroughly evaluated using seven datasets with nonstationary properties under the prequential test-then-train protocol. It has been compared with four popular continual learning algorithms and its shallow counterpart, where the DEVFNN demonstrates improvement of classification accuracy. Moreover, it is also shown that the concept of the drift detection method is an effective tool to control the depth of the network structure, while the hidden layer merging scenario is capable of simplifying the network complexity of a deep network with negligible compromise of generalization performance.																	1063-6706	1941-0034				JUL	2020	28	7					1315	1328		10.1109/TFUZZ.2019.2939993													
J								DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Software; Machine learning; Feature extraction; Training data; Measurement; Security; Databases; Software vulnerability detection; class imbalance; machine learning (ML); deep learning (DL); feature learning		Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML)-based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for ML and the other is class imbalance between vulnerable code and nonvulnerable code. To overcome these challenges, this article develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with bidirectional long short-term memory to learn invariant and discriminative code representations from labeled vulnerable and nonvulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth dataset that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement is 15% in terms of F-measure.																	1063-6706	1941-0034				JUL	2020	28	7					1329	1343		10.1109/TFUZZ.2019.2958558													
J								A Fuzzy Deep Model Based on Fuzzy Restricted Boltzmann Machines for High-Dimensional Data Classification	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Data models; Training; Training data; Fuzzy neural networks; Databases; Neural networks; Classification; fuzzy deep model; fuzzy restricted Boltzmann machine (FRBM); hybrid learning	POSSIBILISTIC MEAN-VALUE; LEARNING ALGORITHMS; RECOGNITION; NETWORKS	We establish a fuzzy deep model called the fuzzy deep belief net (FDBN) based on fuzzy restricted Boltzmann machines (FRBMs) due to their excellent generative and discriminative properties. The learning procedure of an FDBN is divided into a pretraining phase and a subsequent fine-tuning phase. In the pretraining phase, a group of FRBMs is trained in a greedy layerwise way: the first FRBM is trained by original samples, and the average values of the left and right probabilities produced by its hidden units are treated as the training data for subsequent FRBMs. The resulting FDBN is either a generative or a discriminative model depending on the choice of training a generative or a discriminative type of FRBM on top. Then, a hybrid learning approach is proposed to fine-tune this novel fuzzy deep model: the well pretrained fuzzy parameters are first defuzzified, and the FDBN with defuzzified parameters is fine-tuned by the wake-sleep or stochastic gradient descent algorithm. This hybrid strategy not only avoids learning an intractable fuzzy neural network, but also greatly improves the classification capability of the FDBN. The experimental results on MNIST, NORB, and 15 Scene databases indicate that the FDBN with the hybrid learning approach can handle high-dimensional raw images directly. It inherits the fine nature of the FRBM and outperforms some state-of-the-art discriminative models in classification accuracy. Moreover, it shows better capability of robustness than a deep belief net when encountering noisy data.																	1063-6706	1941-0034				JUL	2020	28	7					1344	1355		10.1109/TFUZZ.2019.2902111													
J								Fuzzy Multilayer Clustering and Fuzzy Label Regularization for Unsupervised Person Reidentification	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Databases; Multilayer perceptrons; Nonhomogeneous media; Training; Feature extraction; Clustering algorithms; Cameras; Fuzzy multilayer clustering (FMC); fuzzy label regularization (FLR); unsupervised person reidentification	RECOGNITION	Unsupervised person reidentification has received more attention due to its wide real-world applications. In this paper, we propose a novel method named fuzzy multilayer clustering (FMC) for unsupervised person reidentification. The proposed FMC learns a new feature space using a multilayer perceptron for clustering in order to overcome the influence of complex pedestrian images. Meanwhile, the proposed FMC generates fuzzy labels for unlabeled pedestrian images, which simultaneously considers the membership degree and the similarity between the sample and each cluster. We further propose the fuzzy label regularization (FLR) to train the convolutional neural network (CNN) using pedestrian images with fuzzy labels in a supervised manner. The proposed FLR could regularize the CNN training process and reduce the risk of overfitting. The effectiveness of our method is validated on three large-scale person reidentification databases, i.e., Market-1501, DukeMTMC-reID, and CUHK03.																	1063-6706	1941-0034				JUL	2020	28	7					1356	1368		10.1109/TFUZZ.2019.2914626													
J								A Novel Deep Fuzzy Classifier by Stacking Adversarial Interpretable TSK Fuzzy Sub-Classifiers With Smooth Gradient Information	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Training; Task analysis; Deep learning; Stacking; Linguistics; Benchmark testing; Media; Adversarial attacks; deep learning; smooth gradients; stacked generalization; Takagi-Sugeno-Kang (TSK) fuzzy classifiers	SYSTEM; IDENTIFICATION; ALGORITHMS; MACHINE	Different from our previous stacked-structure-based deep fuzzy classifier, in this paper, we explore the distinctive role of adversarial outputs of training samples in enhancing the classification performance of a stacked-structure-based deep fuzzy classifier. In order to achieve such goals, an adversarial Takagi-Sugeno-Kang (TSK) fuzzy classifier, which is denoted as TSKa, is proposed. With the TSKa, interpretable IF parts of first-order fuzzy rules can be generated by the random selection of fixed linguistic terms along each feature. According to our theoretical analysis, adversarial outputs of training samples enhance TSKa's generalization capability, thereby, resulting in the potential feasibility of leveraging their smooth gradient information with respect to the inputs in the training input space to construct a stacked-structure-based deep fuzzy classifier. In this paper, a novel deep fuzzy classifier is devised by stacking a series of TSKa sub-classifiers and training them by a deep learning strategy. An advantage of the proposed deep fuzzy classifier is its easy yet fast training. The training of each layer consists of two basic steps: computation of the smooth gradient information of adversarial outputs with respect to the inputs, and fast training of each corresponding TSKa by the least learning machine method. Comprehensive experiments on both benchmark datasets and an industrial case demonstrate the promising performance and advantages of the proposed deep fuzzy classifier.																	1063-6706	1941-0034				JUL	2020	28	7					1369	1382		10.1109/TFUZZ.2019.2919481													
J								Time-Series Classification Using Fuzzy Cognitive Maps	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Time series analysis; Fuzzy cognitive maps; Computational modeling; Standards; Feature extraction; Biological system modeling; Task analysis; Deep learning; fuzzy cognitive maps (FCMs); fuzzy models; time-series classification	DISTANCE; FOREST; FCM	This paper presents a time-series classification method based on fuzzy cognitive maps. We advocate that fuzzy cognitive maps provide a sound representation of time series, and we can construct a classification mechanism based on them. The classifier has to distinguish maps constructed for time series belonging to different classes. The proposed classification procedure evaluates similarity of fuzzy cognitive maps, and it is done by comparing weight matrices based on the same set of concepts. A weight matrix describes relationships between concepts in a map. Concepts represent the underlying data, because they are extracted via a data-driven clustering procedure. Each data point of a time series is related to each concept, and we evaluate the strength of relationships with a membership function. This paper investigates performance of the proposed approach on a suite of real-world datasets. We compare classification accuracy of our method with 37 state-of-the-art time-series classification methods. Experiments show that the proposed method is performing well. In many cases, it is better than its competitors.																	1063-6706	1941-0034				JUL	2020	28	7					1383	1394		10.1109/TFUZZ.2019.2917126													
J								Deep Fuzzy Tree for Large-Scale Hierarchical Visual Classification	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Task analysis; Visualization; Deep learning; Feature extraction; Rough sets; Kernel; Discrete Fourier transforms; Deep learning; fuzzy rough set; hierarchical classification; label structure	CLASSIFIERS	Deep learning models often use a flat softmax layer to classify samples after feature extraction in visual classification tasks. However, it is hard to make a single decision of finding the true label from massive classes. In this scenario, hierarchical classification is proved to be an effective solution and can be utilized to replace the softmax layer. A key issue of hierarchical classification is to construct a good label structure, which is very significant for classification performance. Several works have been proposed to address the issue, but they have some limitations and are almost designed heuristically. In this article, inspired by fuzzy rough set theory, we propose a deep fuzzy tree model which learns a better tree structure and classifiers for hierarchical classification with theory guarantee. Experimental results show the effectiveness and efficiency of the proposed model in various visual classification datasets.																	1063-6706	1941-0034				JUL	2020	28	7					1395	1406		10.1109/TFUZZ.2019.2936801													
J								Interpretable Deep Convolutional Fuzzy Classifier	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Clustering algorithms; Feature extraction; Neurons; Deep learning; Convolution; Classification algorithms; Fuzzy systems; Deep learning; explainable artificial intelligence (XAI); fuzzy logic; neuro-fuzzy systems	NEURAL-NETWORKS; MACHINE	While deep learning has proven to be a powerful new tool for modeling and predicting a wide variety of complex phenomena, those models remain incomprehensible black boxes. This is a critical impediment to the widespread deployment of deep learning technology, as decades of research have found that users simply will not trust (i.e., make decisions based on) a model whose solutions cannot be explained. Fuzzy systems, on the other hand, are by design much more easily understood. In this article, we propose to create more comprehensible deep networks by hybridizing them with fuzzy logic. Our proposed architecture first employs a convolutional neural network as an automated feature extractor and then performs a fuzzy clustering in the derived feature space. After hardening the clusters, we employ Rocchio's algorithm to classify the data points. Experiments on three datasets show that the automated feature extraction substantially improves the accuracy of the fuzzy classifier, and while the substitution of a fuzzy classifier slightly decreases the network's performance, we are able to introduce an effective interpretation mechanism.																	1063-6706	1941-0034				JUL	2020	28	7					1407	1419		10.1109/TFUZZ.2019.2946520													
J								Deep Fuzzy Clustering-A Representation Learning Approach	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Neural networks; Clustering algorithms; Kernel; Data models; Deep learning; Clustering methods; Decoding; Deep learning; discriminative graph; fuzzy c-means (FCM); fuzzy compactness and separation (FCS); pseudolabel	C-MEANS; PATTERN-RECOGNITION; ALGORITHM; SETS	Fuzzy clustering is a classical approach to provide the soft partition of data. Although its enhancements have been intensively explored, fuzzy clustering still suffers from the difficulties in handling real high-dimensional data with complex latent distribution. To solve the problem, this article proposes a deep fuzzy clustering method by representing the data in a feature space produced by the deep neural network. From the perspective of representation learning, three constraints or objectives are imposed to the neural network to enhance the clustering-friendly representation. At first, as a good representation of data, the mapped data in the new feature space should support the reconstruction of original data. So, the autoencoder architecture is applied to ensure that the original data can be recovered by decoding the encoded representation with another neural network. Second, to solve the clustering problem efficiently, the intracluster compactness and the intercluster separability are to be minimized and maximized, respectively, in the new feature space. At last, considering that the data in the same class should be close to each other, the affinities between new representations are tuned in accordance with the discriminative information. Altogether, we design a graph-regularized deep normalized fuzzy compactness and separation clustering model to conduct representation learning and soft clustering simultaneously. The learning algorithm based on stochastic gradient descent is proposed to the model, and the comparative studies with baseline clustering algorithms on real-world data illustrate the superiority of the proposal.																	1063-6706	1941-0034				JUL	2020	28	7					1420	1433		10.1109/TFUZZ.2020.2966173													
J								Interval Type-2 Fuzzy Sampled-Data H-infinity Control for Nonlinear Unreliable Networked Control Systems	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Input delay approach; interval type-2 (IT2) system; networked control systems (NCSs); H-infinity control	STABILITY ANALYSIS; TRACKING CONTROL; DESIGN; MODEL; STABILIZATION	This paper is concerned with the problem of interval type-2 (IT2) fuzzy sampled-data H-infinity control for nonlinear networked control systems with parameter uncertainties, data dropout, and transmission delay. The IT2 fuzzy system used to describe the networked control systems and the IT2 networked sampled-data controller implemented by a zero-order holder is connected in the closed-loop system. By means of the input delay approach, the resulting closed-loop system is converted into a continuous-time delayed system. Subsequently, the continuous-time Lyapunov-Krasovskii functional theory is used to carry out the stability analysis. Some slack matrices and the bound information in membership functions are introduced to obtain the relaxed sufficient conditions formed by the linear matrix inequalities, which guarantee the anticipant H-infinity performance. Finally, the efficiency and merits of the proposed design method are verified by four practical systems.																	1063-6706	1941-0034				JUL	2020	28	7					1434	1448		10.1109/TFUZZ.2019.2911490													
J								A New Method for Group Decision Making With Hesitant Fuzzy Preference Relations Based on Multiplicative Consistency	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Indexes; Fuzzy sets; Additives; Decision making; Programming; Hafnium; Finance; Consensus; goal programming model; group decision making (GDM); hesitant fuzzy preference relation (HFPR); multiplicative consistency	INFORMATION; AGGREGATION; RANKING; MODEL; SETS	This paper develops a new method for group decision making with hesitant fuzzy preference relations (HFPRs) considering the multiplicative consistency and consensus simultaneously. A consistency index of HFPR is introduced and the acceptable consistent HFPR is defined. For improving the unacceptable consistent HFPR, a mathematical program is constructed to derive an acceptable consistent HFPR. Thus, an algorithm for checking and improving consistency of HFPR is proposed. A consensus index for the group is defined to measure the agreement among decision makers (DMs). To improve the consistency and consensus simultaneously, a new goal program is established to obtain a group of HFPRs with acceptable consistency and consensus. Subsequently, an interval-valued hesitant fuzzy group decision matrix (IVHFGDM) is elicited from the individual HFPRs. A positive ideal matrix, a left negative ideal matrix, and a right negative matrix are derived from the IVHFGDM. According to the relative closeness degrees, DMs' weights are determined objectively. Afterward, the individual HFPRs are integrated into a normalized collective HFPR. It is proven that the normalized collective HFPR is acceptable consistent if all individual HFPRs are acceptable consistent. The final ranking is generated by the collective overall values of alternatives. Some examples of fuzzy decision-making applications are provided to validate effectiveness of the method.																	1063-6706	1941-0034				JUL	2020	28	7					1449	1463		10.1109/TFUZZ.2019.2914008													
J								Fuzzy Fixed-Time Learning Control With Saturated Input, Nonlinear Switching Surface, and Switching Gain to Achieve Null Tracking Error	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Deep learning; fixed-time control; Lyapunov stability theory; nonlinear switching surface and gain; T-S fuzzy model	MODEL-BASED CONTROL; CONTROL DESIGN; SYSTEMS; STABILITY; CONSENSUS	A class of generalized nonlinear dynamic systems is first approximated by N fuzzy-based linear subsystems using the identification of input-output data or the linearizing system with respect to suitable operating points. To obtain null trajectory tracking error in fixed time, a fuzzy fixed-time control (FFTC) with nonlinear switching surface and switching gain is first designed. It can he said that the FYTC is based on a class of passive and distributive models with uncertainties. To compensate enormous uncertainties, a fuzzy fixed-time learning control (FFTLC) by learning two unknown coefficients for the upper bound of uncertainties in each subsystem is designed. As compared with radial basis function neural network, the computational complexity for the compensated uncertainties is much simple. It can be said that an FFTLC is based on a class of online active and distributive uncertain models. Due to the fixed-time control design, the transients often occur, particularly for the larger uncertainties or initial tracking error. Hence, the saturated input of nonlinear dynamic system is addressed and online compensated. Finally, the compared simulations and application to two-link robot manipulator confirm the effectiveness, robustness, and less computation as compared with previous studies.																	1063-6706	1941-0034				JUL	2020	28	7					1464	1476		10.1109/TFUZZ.2019.2917121													
J								EFMCDM: Evidential Fuzzy Multicriteria Decision Making Based on Belief Entropy	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Entropy; Uncertainty; Decision making; Fuzzy sets; Linguistics; Cognition; Measurement uncertainty; Belief entropy; Dempster-Shafer evidence theory; Deng entropy; fuzzy logic; multicriteria decision making; trapezoidal fuzzy numbers	DEMPSTER-SHAFER THEORY; SIMILARITY MEASURE; NETWORKS; UNCERTAINTY; MODEL; NUMBERS; SYSTEMS	Multicriteria decision making (MCDM) has become one of the most frequently applied decision making methodologies in various fields. However, uncertainty is inevitably involved in the process of MCDM due to the subjectivity of humans. To address this issue, a novel evidential fuzzy MCDM method, called EFMCDM, is proposed by integrating Dempster-Shafer theory with belief entropy. In particular, each criterion can be modeled as evidence, and all the alternatives compose the frame of discernment in the framework of Dempster-Shafer theory. To generate more appropriate basic probability assignments (BPAs) of the criteria, the EFMCDM method considers both the subjective and objective weighting of the criteria that are leveraged in MCDM problems. Thereafter, the classic Dempster's rule of combination is leveraged to fuse the multiple pieces of evidence into composite evidence. On this basis, the alternatives are ranked to determine the optimal alternative. In addition, the EFMCDM method can quantitatively model uncertainty and help to decrease the uncertainty caused by subjective human cognition to improve decision making. Finally, the rationality, effectiveness, and robustness of the EFMCDM method are demonstrated through experimental evaluations.																	1063-6706	1941-0034				JUL	2020	28	7					1477	1491		10.1109/TFUZZ.2019.2936368													
J								Online Deep Fuzzy Learning for Control of Nonlinear Systems Using Expert Knowledge	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Control systems; Training; Fuzzy logic; Neurons; Nonlinear systems; Fuzzy neural networks; Noise measurement; Adaptive process control; aerial robotics; deep learning; fuzzy logic; nonlinear systems	NETWORKS	This article presents an online learning method for improved control of nonlinear systems by combining deep learning and fuzzy logic. Given the ability of deep learning to generalize knowledge from training samples, the proposed method requires minimum amount of information about the system to be controlled. However, in robotics, particularly in aerial robotics where the operating conditions may vary, online learning is required. In this article, fuzzy logic is preferred to provide supervising feedback to the deep model for adapting to variations in the system dynamics as well as new operational conditions. The learning method is divided into two phases: offline pretraining and online posttraining. In the former, the system is controlled by a conventional controller and a deep fuzzy neural network (DFNN) is pretrained based on the recorded input-output dataset, in order to approximate the inverse dynamical model of the system. In the latter, only the pretrained DFNN is used to control the system. In this phase, the fuzzy logic, which encodes the expert knowledge, is utilized to observe the behavior of the system and to correct the action of DFNN instantaneously. The experimental results show that the proposed online learning-based approach improves the trajectory tracking performance of the unmanned aerial vehicle.																	1063-6706	1941-0034				JUL	2020	28	7					1492	1503		10.1109/TFUZZ.2019.2936787													
J								Robust Fuzzy Predictive Control for Discrete-Time Systems With Interval Time-Varying Delays and Unknown Disturbances	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Continuous stirred tank reactor; H-infinity; optimized control; robust fuzzy predictive control; Takagi-Sugeno (T-S); time-varying delays	ITERATIVE LEARNING CONTROL; H-INFINITY CONTROL; NONLINEAR-SYSTEMS; BATCH PROCESSES; MODEL; STATE; MPC	A robust fuzzy predictive control (RFPC) based on Takagi-Sugeno (T-S) fuzzy model is proposed for systems with uncertainties, time-varying delays, unknown disturbances, as well as strong nonlinearity. First, the T-S fuzzy model is built by a number of linear submodels and nonlinear membership functions. Then, by introducing the output tracking error to this fuzzy model, the novel augmented state space model is presented to independently regulate the process state variables and output tracking error. The control law of the proposed RFPC is further designed based on this extended model, which can guarantee the process state to be fast convergent and make the process output track the set-point well. Moreover, it increases the ability of adjustment for the proposed controller. Utilizing Lyapunov-Krasovskii method, optimized control theory, and control method, the stable sufficient conditions are given for the designed control law to make sure the asymptotical stability of the nonlinear uncertain system with the time-varying delay and unknown disturbances. The gains of the controller can he obtained by solving these stabilized conditions in form of linear matrix inequality constraints. At last, a case study of continuous stirred tank reactor manifests that the proposed RFPC method can bear a larger range of time delay, overcome the uncertainties and unknown disturbances well, and have better tracking performance.																	1063-6706	1941-0034				JUL	2020	28	7					1504	1516		10.1109/TFUZZ.2019.2959539													
J								Fuzzy Control for Uncertain Electric Vehicle Systems with Sensor Failures and Actuator Saturation	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Interval type-2 fuzzy model; Uncertain electric vehicle systems; Sensor failures; Actuator saturation	ACTIVE SUSPENSION SYSTEMS; FAULT-TOLERANT CONTROL; YAW MOMENT CONTROL; PARAMETER UNCERTAINTIES; STABILITY ANALYSIS; TIME-DELAY; DYNAMICS; SUBJECT	This paper considers the yaw-moment control issue for uncertain electric vehicle systems with sensor failures and actuator saturation. By employing the interval type-2 (IT2) fuzzy approach, the uncertain electric vehicle systems are constructed as an IT2 fuzzy model. In this model, the parameter uncertainties are described through the membership functions (MFs) with lower and upper bounds. Then, an IT2 fuzzy state-feedback controller, which can share different MFs with the IT2 fuzzy model, is designed. The sensor failures can be quantified by a variable varying in a given interval. Meanwhile, the saturation nonlinearities can be handled by employing a norm-bounded strategy. By means of the Lyapunov stability approach, sufficient conditions of the controller design are derived to achieve the desired performance. Finally, simulation results based on the electric vehicle systems are presented to demonstrate the effectiveness of the proposed control scheme.																	1562-2479	2199-3211				JUL	2020	22	5					1444	1453		10.1007/s40815-020-00869-y													
J								Generalized Correlation Coefficients of Intuitionistic Fuzzy Sets with Application to MAGDM and Clustering Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Intuitionistic fuzzy set; Correlation coefficient; Correlation efficiency; MAGDM; Clustering analysis	DECISION-MAKING; ALGORITHM; ENTROPY	Correlation coefficient between two variables plays an important role in statistics. Further, the perfection in quantification of correlation relies on data collected from the set of discourse. It is quite obvious that data collected for various statistical measures are full of ambiguity. In this communication, we propose one- and two-parametric generalization of correlation coefficient of intuitionistic fuzzy sets (IFSs). We show the application of one-parametric generalized correlation coefficient in multi-attribute group decision-making (MAGDM). We use normalized correlation efficiency as a measure of objective weights of the expertise of decision-experts in MAGDM problem. We also show the application of both generalized correlation coefficients in clustering analysis.																	1562-2479	2199-3211				JUL	2020	22	5					1582	1595		10.1007/s40815-020-00866-1													
J								Analytic Hierarchy Process for Hesitant Probabilistic Fuzzy Linguistic Set with Applications to Multi-criteria Group Decision-Making Method	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Group decision making; Analytic hierarchy process; Hesitant probabilistic fuzzy linguistic; Business climate potential; Real investment problem	AGGREGATION OPERATORS; CONSISTENCY; SELECTION; SYSTEM; MODEL; AHP	The aim of this study is to propose a novel multi-criteria group decision-making method using analytic hierarchy process and hesitant probabilistic fuzzy linguistic set to model uncertainties due to both fuzziness and randomness. The proposed multi-criteria group decision-making method first uses analytic hierarchy process to construct decision preference matrix. Then, it uses hesitant probabilistic fuzzy linguistic set to model both types of uncertainties with hesitancy using both qualitative and quantitative terms. The proposed decision-making method is applied to determine the ranking of three Indian states for business climate and potential using real criteria information from State's investment potential index. Since success or failure of real estate investment decisions depends on the assessment and management of the inherent risk and uncertainty, the proposed method is applied on a real estate investment problem and results are compared with a group consensus model for evaluating real estate investment alternatives.																	1562-2479	2199-3211				JUL	2020	22	5					1596	1606		10.1007/s40815-020-00874-1													
J								Stochastic Multiple Criteria Comprehensive Evaluation Based on Probabilistic Linguistic Preference Relations: A Case Study of Healthcare Insurance Audits in China	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Multiple criteria analysis; Probabilistic linguistic preference relation; Complex linguistic expression; Aspiration; Healthcare insurance audit	GROUP DECISION-MAKING; MULTICRITERIA EVALUATION; SAMPLING PLAN; TERM SETS; CONSISTENCY; FOUNDATION; AGENCIES; FUSION	As a typical multiple criteria comprehensive evaluation (MCCE) problem, healthcare insurance audits (HIA) play a vital role in governmental audits. To handle the HIA in an autonomous region in China, a systematic methodology in the framework of MCCE is presented. An evaluation system is constructed at first based on the specific auditing objective. The group of individual preferences is collected by a probabilistic linguistic preference relation (PLPR). Its consistency and prioritization are handled based on the idea of stochastic analysis and the widely acknowledged techniques of linguistic preference relations (LPRs). Specifically, the consistency degree is measured by the probability of stochastically generated LPRs being with acceptable consistency, and then improved by revising the probabilistic distributions involved in the PLPR. The priority is derived by the expected value of priorities of the stochastically generated LPRs. Moreover, the comprehensive evaluation is conducted based on aspiration-based utility functions. The proposed methodology enables decision makers to determine parameters intuitively, and presents interpretable and admissible results. It is effective even if the original individual preferences are with low consistency degree. Finally, the focused HIA problem is solved based on the proposed methodology.																	1562-2479	2199-3211				JUL	2020	22	5					1607	1623		10.1007/s40815-020-00865-2													
J								Credibilistic Bimatrix Games with Loss Aversion and Triangular Fuzzy Payoffs	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Loss aversion; Credibility theory; Credibilistic loss aversion Nash equilibrium; Triangular fuzzy payoffs	SOLVING MATRIX GAMES; ZERO-SUM GAMES; EQUILIBRIUM STRATEGY; PROGRAMMING APPROACH; PROSPECT-THEORY; EXPECTED VALUE; DECISION	Bimatrix games are reconsidered under assumption that players are loss averse and payoffs are fuzzy, where reference points are given exogenously. The impact of loss aversion on bimatrix game is investigated by applying credibility theory. Three solution concepts of credibilistic loss aversion Nash equilibria (i.e., expected loss aversion Nash equilibrium, optimistic loss aversion Nash equilibrium and pessimistic loss aversion Nash equilibrium) and their existence theorems are proposed. The sufficient and necessary conditions are presented to find three equilibria. It is found that three credibilistic loss aversion Nash equilibria are equivalent if confidence level is equal to 0.5. Furthermore, an analysis on credibilistic loss aversion equilibria with respect to loss aversion is performed in a 2 x 2 bimatrix game with triangular fuzzy payoffs. It is found that with a higher probability a more loss-averse player receives a preferred payoff in the mixed strategy Nash equilibrium in some situations, but receives the second highest payoff in other situations. Finally, a case study is shown to illustrate the validity of the bimatrix game with triangular fuzzy payoffs developed in this paper.																	1562-2479	2199-3211				JUL	2020	22	5					1635	1652		10.1007/s40815-020-00850-9													
J								Processing Online Massive Measuring Databases via Data-Uncertainty Quantifying Mechanism to Synthesize ANFIS	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Optimal data screening threshold; Kernel fuzzy C-means clustering; Impulse noise filtering; ANFIS; Applications of ANFIS	SLIDING MODE CONTROL; VIBRATION CONTROL; FUZZY; CONTROLLER; SUSPENSION; ALGORITHM; OBSERVER	Adaptive neuro-fuzzy inference systems (ANFISs) deriving from big data bring us the perspective in many fields. However, online performing both processing noisy and massive databases (NMDs) and training ANFISs is a challenge. Inspired by this aim, we propose a strategy with two phases, offline and online. The offline discovers an optimal data screening threshold (ODST) which is interpreted as an index to measure the uncertainty of the data in a data cluster. A new algorithm named A-ODST is proposed to estimate the ODST. Using the kernel fuzzy C-means clustering technique, a new filter named FbMU for blurring the ODST-based measured data-uncertainty is presented. An improved algorithm named NMD-ANFIS is presented to build the ANFIS from the NMD filtered by the FbMU. Based on the three main contributions of this paper to be the A-ODST, FbMU, and NMD-ANFIS, processing NMD and training ANFIS can be performed synchronously in the online phase. The combination of the solution to optimize the cluster data space via the NMD-ANFIS to simplify ANFIS's structure and the filtering strategy of the FbMU for removing all the data points belonging to the data clusters with the highest uncertainty allows both filtering noise and reducing the size of the database to improve the calculating cost. Surveys from two experimental systems were carried out to verify these aspects. The compared results showed that the predicting error and the calculating time of the ANFISs built by the proposed method were better than that from the other surveyed methods.																	1562-2479	2199-3211				JUL	2020	22	5					1679	1693		10.1007/s40815-020-00856-3													
J								Improved Fuzzy-Based SVM Classification System Using Feature Extraction for Video Indexing and Retrieval	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Multimedia technology; Video indexing; Feature extraction; Fuzzy-based SVM classifier; Multi-dimensional Histogram of Oriented Gradients (HOG) and Colour Feature Extraction	SHOT BOUNDARY DETECTION; OBJECT DETECTION; TRACKING	Various researches have been performed with video abstraction with the constant development of multimedia technology. However, there are some deficiencies that have been encountered in the pre-processing of video frames before attaining classified video archives. To overcome the drawbacks in pre-processing, feature extraction and classification approaches are considered. Here, video indexing has been anticipated with several features' extraction with dominant frame generation for the input video frame. Fuzzy-based SVM classifier is utilized to categorize frame set into dominant structures. Multi-dimensional Histogram of Oriented Gradients (HOG) and colour feature extraction are used to extract texture features from the video frame. Using the frame sequence, the vector space of structures is captured; dominant frameworks are utilized in video indexing. Shot transitions' classification is done with a fuzzy system. Experimental outcomes demonstrate that shot boundary detection accuracy increases with an increase in iterations. The simulation was carried out in MATLAB environment. This technique attains an accuracy of about 95.4%, the precision of 100%, and the F1 score of 100% and a recall of 100%. The misclassification rate is 4.6%. The proposed method shows better trade-off than the existing techniques.																	1562-2479	2199-3211				JUL	2020	22	5					1716	1729		10.1007/s40815-020-00884-z													
J								An effective technique for the creation of a video synopsis	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Condensation ratio; Foreground extraction; Human action; Video synopsis		Video synopsis involves making the content of a video brief without losing key content. The condensation ratio (CDR) is a key metric in the generation of a video synopsis. In this paper, we aim at creating a video synopsis with importance given to the CDR. Based on the CDR, many methods available in the literature have focused on the creation of a video synopsis. To generate a video synopsis with a better CDR, the proposed algorithm considers a background frame. Then, foreground information is extracted. Updating the foreground information of the initial frame is performed using the extracted foreground information of subsequent chosen frames. By adding every updated version of the initial frame, a video synopsis with an enhanced CDR is obtained. A class of methods were compared with the proposed method. Videos from standard databases, such as the UCF (University of Central Florida) Sports Action dataset, CAVIAR, and Video and Image Retrieval and Analysis Tool, were used for the evaluation of the proposed approach. The videos included highway, overpass, and sidewalk. The results demonstrated that the proposed method outperformed the other methods in terms of the CDR.																	1868-5137	1868-5145															10.1007/s12652-020-01914-2		JUL 2020											
J								Detecting counterfeit products by means of frequent pattern mining	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Frequent pattern mining; Supply chain management; Product traceability; Internet of things	TRACEABILITY; SYSTEM	Product traceability is one of the major issues in supply chains management (e.g., Food, cosmetics, pharmaceutical, etc.). Several studies has shown that traceability allows targeted product recalls representing a health risk (e.g.: counterfeit products), thus enhancing the communication and risks management. It can be defined as the ability to track and trace individual items throughout their whole lifecycle from manufacturing to recycling. This includes real-time data analytics about actual product behavior (ability to track) and product historical data (ability to trace). This paper presents a comparative study between several works on product traceability and proposes a standardized traceability system architecture. In order to implement a counterfeit/nonconforming product detection algorithm, we implement a cosmetic supply chain as a multi-agent system implemented in Anylogic (c). Data generated by this simulator are then used in order to identify genuine trajectories across the whole SC. The genuine product trajectories (behavior) are inferred using a frequent pattern mining algorithm (i.e., Apriori). This identified trajectories are used as a reference in order to identify counterfeit products and detect false alarms of product behavior																	1868-5137	1868-5145															10.1007/s12652-020-02237-y		JUL 2020											
J								Long range wide area network for agricultural wireless underground sensor networks	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Low power wide area network; Wireless underground sensor networks; LoRa; LoRaWAN; Internet of things; Agricultural sensor networks	DIELECTRIC-PROPERTIES; SOIL	Wireless underground sensor networks (WUSNs) enable large-scale agricultural monitoring for improving farming efficiency and reducing pollution. A WUSN system based on the long range wide area network (LoRaWAN) standard is proposed. A novel LoRaWAN-based simulator is developed to model wireless signal attenuation and path loss in an underground environment by incorporating the Peplinski and modified Friis models. The simulator incorporates the full network stack of the LoRa physical and MAC layers. Simulation results show LoRaWAN-based WUSNs (with a node burial depth of 50 cm) can maintain network connectivity with a range of over several kilometres. The simulation results also show the regional duty cycle restriction significantly reduces network scalability due to acknowledgements from end-devices. For agricultural applications where such frequent acknowledgements are not required, the results show a LoRaWAN WUSN is scalable. A field experiment to evaluate the accuracy of the theoretical path loss model was conducted and results were found to agree with the simulations.																	1868-5137	1868-5145															10.1007/s12652-020-02137-1		JUL 2020											
J								A multi-start local search algorithm for the Hamiltonian completion problem on undirected graphs	JOURNAL OF HEURISTICS										Metaheuristics; Matheuristics; Combinatorial optimisation; Hamiltonian completion problem; Minimum path partition problem	LINEAR ALGORITHM; NUMBER	This paper proposes a local search algorithm for a specific combinatorial optimisation problem in graph theory: the Hamiltonian completion problem (HCP) on undirected graphs. In this problem, the objective is to add as few edges as possible to a given undirected graph in order to obtain a Hamiltonian graph. This problem has mainly been studied in the context of various specific kinds of undirected graphs (e.g. trees, unicyclic graphs and series-parallel graphs). The proposed algorithm, however, concentrates on solving HCP for general undirected graphs. It can be considered to belong to the category of matheuristics, because it integrates an exact linear time solution for trees into a local search algorithm for general graphs. This integration makes use of the close relation between HCP and the minimum path partition problem, which makes the algorithm equally useful for solving the latter problem. Furthermore, a benchmark set of problem instances is constructed for demonstrating the quality of the proposed algorithm. A comparison with state-of-the-art solvers indicates that the proposed algorithm is able to achieve high-quality results.																	1381-1231	1572-9397				OCT	2020	26	5					743	769		10.1007/s10732-020-09447-9		JUL 2020											
J								Fuzzy adaptive dynamic programming-based optimal leader-following consensus for heterogeneous nonlinear multi-agent systems	NEURAL COMPUTING & APPLICATIONS										Optimal leader-following consensus; Precompensation technique; Adaptive dynamic programming (ADP); Generalized fuzzy hyperbolic model (GFHM); Policy iteration (PI)	ATTITUDE-CONTROL; SYNCHRONIZATION; DESIGN; COORDINATION; ALGORITHM; GAMES	In this paper, a novel online iterative scheme, based on fuzzy adaptive dynamic programming, is proposed for distributed optimal leader-following consensus of heterogeneous nonlinear multi-agent systems under directed communication graph. This scheme combines game theory, adaptive dynamic programming together with generalized fuzzy hyperbolic model (GFHM). Firstly, based on precompensation technique, an appropriate model transformation is proposed to convert the error system into augmented error system, and an exquisite performance index function is defined for this system. Secondly, on the basis of Hamilton-Jacobi-Bellman (HJB) equation, the optimal consensus control is designed and a novel policy iteration (PI) algorithm is put forward to learn the solutions of the HJB equation online. Here, the proposed PI algorithm is implemented on account of GFHMs. Compared with dual-network model including critic network and action network, the proposed scheme only requires critic network. Thirdly, the augmented consensus error of each agent and the weight estimation error of each GFHM are proved to be uniformly ultimately bounded, and the stability of our method has been verified. Finally, some numerical examples and application examples are conducted to demonstrate the effectiveness of the theoretical results.																	0941-0643	1433-3058				JUL	2020	32	13					8763	8781		10.1007/s00521-019-04263-0													
J								A real-time hourly ozone prediction system using deep convolutional neural network	NEURAL COMPUTING & APPLICATIONS										Deep learning; Real-time forecasting; Convolutional neural networks; Ozone; Air quality model	LEARNING-METHODS; SIMULATED NOX; MACHINE; IMPACT; MODEL; ALGORITHMS; EMISSIONS; AREA; O-3	This study uses a deep learning approach to forecast ozone concentrations over Seoul, South Korea for 2017. We use a deep convolutional neural network (CNN). We apply this method to predict the hourly ozone concentration on each day for the entire year using several predictors from the previous day, including the wind fields, temperature, relative humidity, pressure, and precipitation, along with in situ ozone and NO(2)concentrations. We refer to a history of all observed parameters between 2014 and 2016 for training the predictive models. Model-measurement comparisons for the 25 monitoring sites for the year 2017 report average indices of agreement (IOA) of 0.84-0.89 and a Pearson correlation coefficient of 0.74-0.81, indicating reasonable performance for the CNN forecasting model. Although the CNN model successfully captures daily trends as well as yearly high and low variations of the ozone concentrations, it notably underpredicts high ozone peaks during the summer. The forecasting results are generally more accurate for the stations located in the southern regions of the Han River, the result of more stable topographical and meteorological conditions. Furthermore, through two separate daytime and nighttime forecasts, we find that the monthly IOA of the CNN model is 0.05-0.30 higher during the daytime, resulting from the unavailability of some of the input parameters during the nighttime. While the CNN model can predict the next 24 h of ozone concentrations within less than a minute, we identify several limitations of deep learning models for real-time air quality forecasting for further improvement.																	0941-0643	1433-3058				JUL	2020	32	13					8783	8797		10.1007/s00521-019-04282-x													
J								A combined neurodynamic approach to optimize the real-time price-based demand response management problem using mixed zero-one programming	NEURAL COMPUTING & APPLICATIONS										Demand response; Neural network; Mixed zero-one programming; Particle swarm optimization	PROJECTION NEURAL-NETWORK	This paper presents a microgrid system model considering three types of load and the user's satisfaction function. The objective function with mixed zero-one programming is used to maximize every user's profit and satisfaction in the way of the demand response management under real-time price. An energy function is used to transform the constrained problem into an unconstrained problem, and two neural networks are used to find the local optimal solutions of the objective function with different rates of convergence. A neurodynamic approach is used to combine the neural networks with the particle swarm optimization to find the global optimal solution of the objective function. The simulation results show that the combined approach is effective in solving the optimal problem.																	0941-0643	1433-3058				JUL	2020	32	13					8799	8809		10.1007/s00521-019-04283-w													
J								Detection, localisation and tracking of pallets using machine learning techniques and 2D range data	NEURAL COMPUTING & APPLICATIONS										Pallet detection; Automated guided vehicle; 2D laser rangefinder; Faster R-CNN; Computer vision	CLASSIFICATION	The problem of autonomous transportation in industrial scenarios is receiving a renewed interest due to the way it can revolutionise internal logistics, especially in unstructured environments. This paper presents a novel architecture allowing a robot to detect, localise, and track (possibly multiple) pallets using machine learning techniques based on an on-board 2D laser rangefinder only. The architecture is composed of two main components: the first stage is a pallet detector employing a Faster Region-Based Convolutional Neural Network (Faster R-CNN) detector cascaded with a CNN-based classifier; the second stage is a Kalman filter for localising and tracking detected pallets, which we also use to defer commitment to a pallet detected in the first stage until sufficient confidence has been acquired via a sequential data acquisition process. For fine-tuning the CNNs, the architecture has been systematically evaluated using a real-world dataset containing 340 labelled 2D scans, which have been made freely available in an online repository. Detection performance has been assessed on the basis of the average accuracy overk-fold cross-validation, and it scored 99.58% in our tests. Concerning pallet localisation and tracking, experiments have been performed in a scenario where the robot is approaching the pallet to fork. Although data have been originally acquired by considering only one pallet as per specification of the use case we consider, artificial data have been generated as well to mimic the presence of multiple pallets in the robot workspace. Our experimental results confirm that the system is capable of identifying, localising and tracking pallets with a high success rate while being robust to false positives.																	0941-0643	1433-3058				JUL	2020	32	13					8811	8828		10.1007/s00521-019-04352-0													
J								Efficiency of optimization algorithms on the adjustment of process parameters for geometric accuracy enhancement of denture plate in single point incremental sheet forming	NEURAL COMPUTING & APPLICATIONS										Single point incremental forming; Denture plate; Geometric accuracy; GA; GODLIKE; GOA	TOOL PATH GENERATION; INTERNET; METAL; MODEL; ARCHITECTURE; METHODOLOGY; STRATEGIES; PREDICTION; SELECTION; DESIGN	Single point incremental forming is a sheet metal forming technique with great potential for use in prototyping and custom manufacture. Although this technology has undergone considerable development in recent years, it still suffers from low geometrical accuracy in terms of its application in the industry. Therefore, solutions for errors reduction or compensation are required to improve the process. In this paper, an optimization procedure of the geometric precision, based on genetic algorithm, global optimum determination by linking and interchanging kindred evaluators solver and newly developed algorithm called grasshopper optimization algorithm, is tested and doubly validated numerically and experimentally. The denture plate part simultaneously simulated and manufactured shows how it is possible to obtain sound component with reduced geometric errors such as springback, bending and pillow effect errors by properly chosen optimal process parameters. The results indicated that the reduction in the shape defects between the obtained geometry and the target model generated by computer-aided design can be achieved through coupling of numerical simulations and optimization techniques.																	0941-0643	1433-3058				JUL	2020	32	13					8829	8846		10.1007/s00521-019-04354-y													
J								A robust correlation coefficient for probabilistic dual hesitant fuzzy sets and its applications	NEURAL COMPUTING & APPLICATIONS										Probabilistic dual hesitant fuzzy sets; Correlation coefficient; Personnel selection; Multi-criteria decision-making	DECISION-MAKING; AGGREGATION; DISTANCE	As a generalization of the hesitant fuzzy sets (HFSs) and dual HFSs (DHFSs), probabilistic dual hesitant fuzzy sets (PDHFSs) are a strong and valuable tool to represent the imprecise information by embedding both the features of HFSs and probabilistic information instantaneously. Meanwhile, a correlation coefficient is a prominent measure to measure the relationship between two sets. Motivated by these primary characteristics, it is interesting to present some information measures to the PDHFSs and hence decision-making approach based on the correlation coefficient. In this paper, we develop a method to solve the multi-criteria decision-making (MCDM) problem under PDHFS environment. For it, firstly, we define the informational energy and the covariance between the two PDHFSs and study their properties. Secondly, we develop correlation coefficients and the weighted correlation coefficients for PDHFSs. In the formulation, DHFSs are able to represent the information in terms of their respective degrees, while the assigned probabilities give more details about the level of agreeness or disagreeness. Also, some properties of the proposed measures are also studied. Thirdly, a novel algorithm is developed based on the proposed operators to solve MCDM problems. A practical example is provided to verify the developed approach and to demonstrate its practicality and feasibility. Also, a comparative analysis with several existing studies reveals the proposed method is better during solving the decision-making problems.																	0941-0643	1433-3058				JUL	2020	32	13					8847	8866		10.1007/s00521-019-04362-y													
J								Convolutional neural networks for classification of music-listening EEG: comparing 1D convolutional kernels with 2D kernels and cerebral laterality of musical influence	NEURAL COMPUTING & APPLICATIONS										Electroencephalogram (EEG); Deep learning; Convolutional neural network (CNN); Kernel; Music; Brain lateralization	HUMAN BRAIN	This paper highlights the ability of convolutional neural networks (CNNs) at classifying EEG data listening to different kinds of music without the requirement for handcrafted features. Deep learning architectures presented in this paper include CNN of different depths and different convolutional kernels. Support vector machine (SVM) taking in EEG features describing the frequency spectrum, signal regularity, and cross-channel correlation has been applied for performance comparison with CNN. The best performing CNN model presented in this paper achieves the tenfold cross-validation (CV) binary classification average accuracy of 98.94% (validation) and 97.46% (test), and the tenfold CV three-class classification accuracy of 97.68% (validation) and 95.71% (test). In comparison, the SVM classifier achieves tenfold CV binary classification accuracy of 80.23% (validation). The CNN model presented is able to not only differentiate EEG of subjects listening to music from that of subjects without auditory input, but it is also capable of accurately differentiating the EEG of subjects listening to different music. In the context of designing neural computing models for EEG analysis, this paper shows that decomposing two-dimensional spatiotemporal convolutional kernels into separate one-dimensional spatial and one-dimensional temporal kernels significantly reduces the number of trainable parameters (size) of the model while retaining the classification performance. This finding is useful, especially in designing CNN for memory-critical embedded systems for EEG processing. In neurological aspect, auditory stimulus is found to have altered the EEG pattern of the frontal lobe and the left cerebral hemisphere more than the other brain regions.																	0941-0643	1433-3058				JUL	2020	32	13					8867	8891		10.1007/s00521-019-04367-7													
J								Robust3D: a robust 3D face reconstruction application	NEURAL COMPUTING & APPLICATIONS										3D face; Deblur; Super-resolution	SHAPE	In the process of reconstructing a historical event such as a rock concert only from video, the reconstruction of faces and expressions of the musicians is obviously important. However, in the process of rebuilding appearance, because of the low quality of the video of the recorded concert, the result of the reconstruction may be far from the real appearance. In this paper, a robust 3D face reconstruction application is described that can be applied to a video recording. The application first uses DeblurGAN program to run anti-ambiguity calculation and removes the ambiguity in the concert video. Then, the super-resolution program is used to enlarge every frame of the concert video by four times, thus making every frame of the video clearer. Finally, the 3D faces are obtained after 3D reconstruction of the processed video frames via the 3DMM_CNN program.																	0941-0643	1433-3058				JUL	2020	32	13					8893	8900		10.1007/s00521-019-04380-w													
J								Spatial context-based optimal multilevel energy curve thresholding for image segmentation using soft computing techniques	NEURAL COMPUTING & APPLICATIONS										Multilevel thresholding; Renyi's entropy; Spatial context sensitive; Energy-Otsu method; Gray-level co-occurrence matrix; Soft computing techniques	CUCKOO SEARCH ALGORITHM; MINIMUM CROSS-ENTROPY; OPTIMIZATION; EVOLUTIONARY; KAPURS; EDGE	Image segmentation using multilevel thresholding (MT) is one of the leading methods. Although, as most techniques are based on the image histogram to be segmented, MT approaches only include the occurrence frequency of particular intensity range disregarding each spatial information. Energy curve-based contextual information can help to improve the quality of the thresholded image as it computes not only the value of the pixel but also its vicinity. Therefore, the energy curve is intended to carry spatial information into a curve with the same properties as the histogram. In this paper, classical Otsu's method (between-class variance) is combined with energy curve for multilevel thresholding to perform segmentation of colored images. The energy curve-based Otsu (Energy-Otsu) uses an exhaustive search process to determine the optimal threshold values. However, due to the multidimensionality and multimodal nature of the color images, it becomes challenging and highly complex to obtain optimal thresholds. Therefore, the cuckoo search (CS) algorithm is coupled with Otsu thresholding criteria to perform MT over the energy curve. The proposed Energy-Otsu-CS method produces better-segmented results as compared to other well-known optimization algorithms such as differential evolution, particle swarm optimization, firefly algorithm, bacterial foraging optimization, and artificial bee colony algorithm. The proposed approach is examined intensively regarding quality, and the numerical parameter analysis is presented to compare the segmented results of the algorithms against closely related current approaches such as gray-level co-occurrence matrix and Renyi' entropy-based thresholding approaches.																	0941-0643	1433-3058				JUL	2020	32	13					8901	8937		10.1007/s00521-019-04381-9													
J								Multi-step time series prediction intervals using neuroevolution	NEURAL COMPUTING & APPLICATIONS										Prediction intervals; Time series; Multi-objective evolutionary algorithm; Multilayer perceptron; Evolutionary neural network	NEURAL-NETWORK APPROACH; ARCHITECTURES; OIL	Multi-step time series forecasting (TSF) is a crucial element to support tactical decisions (e.g., designing production or marketing plans several months in advance). While most TSF research addresses only single-point prediction, prediction intervals (PIs) are useful to reduce uncertainty related to important decision making variables. In this paper, we explore a large set of neural network methods for multi-step TSF and that directly optimize PIs. This includes multi-step adaptations of recently proposed PI methods, such as lower-upper bound estimation (LUBET), its ensemble extension (LUBEXT), a multi-objective evolutionary algorithm LUBE (MLUBET) and a two-phase learning multi-objective evolutionary algorithm (M2LUBET). We also explore two new ensemble variants for the evolutionary approaches based on two PI coverage-width split methods (radial slices and clustering), leading to the MLUBEXT, M2LUBEXT, MLUBEXT2 and M2LUBEXT2 methods. A robust comparison was held by considering the rolling window procedure, nine time series from several real-world domains and with different characteristics, two PI quality measures (coverage error and width) and the Wilcoxon statistic. Overall, the best results were achieved by the M2LUBET neuroevolution method, which requires a reasonable computational effort for time series with a few hundreds of observations.																	0941-0643	1433-3058				JUL	2020	32	13					8939	8953		10.1007/s00521-019-04387-3													
J								Improving learning and generalization capabilities of the C-Mantec constructive neural network algorithm	NEURAL COMPUTING & APPLICATIONS										Constructive neural network; Feed-forward network; Support vector machine; C-Mantec; Learning and generalization properties; Loading problem	FPGA IMPLEMENTATION; HIDDEN NEURONS; NUMBER; BACKPROPAGATION; BOUNDS	C-Mantec neural network constructive algorithm Ortega (C-Mantec neural network algorithm implementation on MATLAB.,2015) creates very compact architectures with generalization capabilities similar to feed-forward networks trained by the well-known back-propagation algorithm. Nevertheless, constructive algorithms suffer much from the problem of overfitting, and thus, in this work the learning procedure is first analyzed for networks created by this algorithm with the aim of trying to understand the training dynamics that will permit optimization possibilities. Secondly, several optimization strategies are analyzed for the position of class separating hyperplanes, and the results analyzed on a set of public domain benchmark data sets. The results indicate that with these modifications a small increase in prediction accuracy of C-Mantec can be obtained but in general this was not better when compared to a standard support vector machine, except in some cases when a mixed strategy is used.																	0941-0643	1433-3058				JUL	2020	32	13					8955	8963		10.1007/s00521-019-04388-2													
J								Automated detection of epileptic seizures using successive decomposition index and support vector machine classifier in long-term EEG	NEURAL COMPUTING & APPLICATIONS										EEG; Epilespy; Epileptic seizures; Real-time seizure detection; Successive decomposition index; SVM	COMPONENT ANALYSIS; SIGNALS; LOCALIZATION; RECOGNITION; RECORDINGS; PREDICTION; FEATURES	Epilepsy is a commonly observed long-term neurological disorder that impairs nerve cell activity in the brain and has a severe impact on people's daily lives. Accurate seizure detection in the long-term electroencephalogram (EEG) signals has gained vital importance in the diagnosis of patients with epilepsy. Visual interpretation and detection of epileptic seizures in long-term EEG is a time-consuming and burdensome task for neurologists. Therefore, in this study, we propose a computationally efficient automated seizure detection model using a novel feature called successive decomposition index (SDI). We observed that the SDI feature was significantly higher during the epileptic seizure as compared to normal EEG. The performance of the proposed method was evaluated using three databases, namely the Ramaiah Medical College and Hospital (DB1), CHB-MIT (DB2) and the Temple University Hospital (DB3) consisting of 58 h, 884 h, and 408 h of EEG, respectively. Experimental results revealed the sensitivity-false detection rate-median detection delay of 97.53%-0.4/h-1.5 s, 97.28%-0.57/h-1.7 s, and 95.80%-0.49/h-1.5 s for DB1, DB2, and DB3, respectively, using the support vector machine classifier. The proposed method significantly outperformed previously presented methods (wavelets and other feature extraction methods) while being computationally more efficient. Further, to the best of the author's knowledge, present study is the first study that was tested on three different EEG databases and showed consistent results leading to the generalization and robustness of the algorithm. Hence, the proposed method is an efficient tool for neurologists to detect epileptic seizures in long-term EEG.																	0941-0643	1433-3058				JUL	2020	32	13					8965	8984		10.1007/s00521-019-04389-1													
J								A novel approach based on soft computing techniques for unconfined compression strength prediction of soil cement mixtures	NEURAL COMPUTING & APPLICATIONS										Soil-cement mixtures; Jet grouting; Deep soil mixing; Soft computing; Data mining; Sensitivity analysis	DATA MINING TECHNIQUES; ORGANIC-MATTER; PARAMETERS; CLAY; BEHAVIOR; MODULUS	The prediction of the uniaxial compression strength (qu) of soil cement mixtures is of up most importance for design purposes. This is done traditionally by extensive laboratory tests which is time and resources consuming. In this paper, it is presented a new approach to assess qu over time based on the high learning capabilities of data mining techniques. A database of 444 records, encompassing cohesionless to cohesive and organic soils, different binder types, mixture conditions and curing time, were used to train three models based on support vector machines (SVMs), artificial neural networks (ANNs) and multiple regression. The results show a promising performance in qu prediction of laboratory soil cement mixtures, being the best results achieved with the SVM model (R2 1/4 0:94) and with an average of SVM and ANN model (R2 1/4 0:95), well reproducing the major effects of the input variables water/cement ratio, cement content, organic matter content and curing time, which are known as preponderant in soil cement mixtures behaviour.																	0941-0643	1433-3058				JUL	2020	32	13					8985	8991		10.1007/s00521-019-04399-z													
J								Alternative mathematical formulation and hybrid meta-heuristics for patient scheduling problem in health care clinics	NEURAL COMPUTING & APPLICATIONS										Patient scheduling; Prioritize optimization; Waiting time; Heuristic algorithms	OPERATING-ROOMS; APPOINTMENT	The proper management of patients' waiting time requires the use of reasonable decision logic and tool. Simulation and optimization techniques can support management decisions to reduce the risk of the decision process by evaluating and analyzing various patient flow control strategies. The purpose of this study is to propose mathematical models and algorithmic frameworks to minimize the waiting time of patients and to determine the timing of the services of an emergency center. The patient scheduling problem is formulated as integer programming models, and the large instances of the problem are solved by Tabu search method and L-shaped algorithm. This cross-sectional descriptive study is conducted on 150 patients referred to the emergency department of a government hospital, and the required data are collected through a questionnaire. A discrete-event simulation model is also designed using the Arena software. According to the results of this paper, to reduce the waiting time of patients, execution of the triage process of patients in the emergency department, the use of an emergency medicine specialist for medical diagnosis and ordering the diagnostic procedures in the early stages of the process-as well as a specialist laboratory for emergency patients-are suggested to accelerate the hospital process. In the secondary work, we extended a first come first serve algorithm using a fairness ratio. The extended system prioritized the entry patients and separated non-urgent from others in terms of frequency. The result of the numerical experiments shows that the implementation of the system in five scenarios results in 11% decrement in operation time.																	0941-0643	1433-3058				JUL	2020	32	13					8993	9008		10.1007/s00521-019-04405-4													
J								Deep-PHURIE: deep learning based hurricane intensity estimation from infrared satellite imagery	NEURAL COMPUTING & APPLICATIONS										Hurricane intensity estimation; Deep convolutional neural networks; Machine learning; Hurricanes	TROPICAL CYCLONE INTENSITY; OBJECTIVE SCHEME	Hurricanes are among the most destructive natural phenomena on Earth. Timely prediction and tracking of hurricane intensity is important as it can help authorities in emergency planning. Several manual, semi and fully automated techniques based on different principles have been developed for hurricane intensity estimation. In this paper, a deep convolutional neural network architecture is proposed for fully automated hurricane intensity estimation from satellite infrared (IR) images. The proposed architecture is robust to errors in annotation of the storm center with a smaller root-mean-squared error (RMSE) (8.82 knots) in comparison to the previous state of the art methods. A web server implementation of Deep-PHURIE and its pre-trained neural network model are available at the URL:.																	0941-0643	1433-3058				JUL	2020	32	13					9009	9017		10.1007/s00521-019-04410-7													
J								Applying several machine learning approaches for prediction of unconfined compressive strength of stabilized pond ashes	NEURAL COMPUTING & APPLICATIONS										Unconfined compressive strength; M5 model tree; Random forest; Artificial neural network; Support vector machines; Gaussian processes	ARTIFICIAL NEURAL-NETWORK; SUPPORT VECTOR MACHINE; MODEL TREES	This paper evaluates the potential of five modeling approaches, namely M5 model tree, random forest, artificial neural networks, support vector machines and Gaussian processes, for the prediction of unconfined compressive strength of stabilized pond ashes with lime and lime sludge. The study not only presents five models for the same set of data but also compares the overall performance of them. Dataset used consists of 255 samples acquired from laboratory experiments. Out of the total, 170 randomly chosen samples were used for training and remaining 85 were used for testing the models. Input dataset consists of eight parameters (uniformity coefficient, coefficient of curvature, maximum dry density, optimum moisture content, lime, lime sludge, curing period and 7-day soaked California bearing ratio), while the output is UCS value at 7, 28, 45, 90 and 180 days of curing. Comparisons of results propose that Gaussian processes modeling strategy works well and the overall performance was substantially nearer to the exact agreement line. As a result of GP model, higher value of CC = 0.997 and lower values of RMSE = 23.016 kPa and MAE = 16.455 were obtained for testing the dataset. Sensitivity analysis suggests that lime, lime sludge, curing period and California bearing ratio are the significant parameters for predicting the unconfined compressive strength of stabilized pond ashes. The results confirmed that GP models are in a position to predict the unconfined compressive strength of stabilized pond ashes with an excessive degree of accuracy; however, GP modeling approach proves that this approach is more economical and less difficult in comparison with tedious laboratory work.																	0941-0643	1433-3058				JUL	2020	32	13					9019	9028		10.1007/s00521-019-04411-6													
J								Object manipulation with a variable-stiffness robotic mechanism using deep neural networks for visual semantics and load estimation	NEURAL COMPUTING & APPLICATIONS										Deep neural networks; Object recognition; Robotic manipulation; Context awareness; Force estimation	PAYLOAD ESTIMATION; BRAIN	In recent years, the computer vision applications in the robotics have been improved to approach human-like visual perception and scene/context understanding. Following this aspiration, in this study, we explored the possibility of better object manipulation performance by connecting the visual recognition of objects to their physical attributes, such as weight and center of gravity (CoG). To develop and test this idea, an object manipulation platform is built comprising a robotic arm, a depth camera fixed at the top center of the workspace, embedded encoders in the robotic arm mechanism, and microcontrollers for position and force control. Since both the visual recognition and force estimation algorithms use deep learning principles, the test set-up was named asDeep-Table. The objects in the manipulation tests are selected from everyday life and are common to be seen on modern office desktops. The visual object localization and recognition processes are performed from two distinct branches by deep convolutional neural network architectures. We present five of the possible cases, having different levels of information availability on the object weight and CoG in the experiments. The results confirm that using our algorithm, the robotic arm can move different types of objects successfully varying from several grams (empty bottle) to around 250 g (ceramic cup) without failure or tipping. The proposed method also shows that connecting the object recognition with load estimation and contact point further improves the performance characterized by a smoother motion.																	0941-0643	1433-3058				JUL	2020	32	13					9029	9045		10.1007/s00521-019-04412-5													
J								Multi-view correlation tracking with adaptive memory-improved update model	NEURAL COMPUTING & APPLICATIONS										Visual tracking; Correlation filter; Multi-view learning; Scale estimation	ROBUST OBJECT TRACKING; VISUAL TRACKING	Recently, some researchers concentrate on applying multi-view learning to the correlation filter tracking to achieve both the efficiency and accuracy. However, most of them fail to effectively collaborate multiple views to deal with more complex environment. Moreover, their methods are prone to drift in case of long-term occlusion due to the memory loss. In this paper, we propose a novel multi-view correlation filters-based tracker for robust visual tracking. First, we present an adaptive multi-view collaboration strategy to highlight different contributions of different views by jointly considering the reliability and discrimination. Second, an effective memory-improved model update rule is introduced to avoid falling into a contaminated target model. Compared with the conventional linear interpolation update rule, it can effectively deal with long-term occlusion by improving the memory of historical models. Furthermore, instead of assigning a unified learning rate for all views in each frame, we design varying learning rates for different views according to their respective evaluations on the current tracking result, which can prevent the target models of all views from being contaminated at the same time. Finally, a failure-aware scale update scheme is developed to avoid noisy scale estimation in case of temporal tracking failure. Extensive experimental results on the recent benchmark demonstrate that our tracker performs favorably against other state-of-the-art trackers with a real-time performance.																	0941-0643	1433-3058				JUL	2020	32	13					9047	9063		10.1007/s00521-019-04413-4													
J								An ensemble tree-based machine learning model for predicting the uniaxial compressive strength of travertine rocks	NEURAL COMPUTING & APPLICATIONS										Uniaxial compressive strength; Tree-based machine learning; Travertine; Ensemble model; Iran	GROUNDWATER CONTAMINATION RISK; ADAPTIVE REGRESSION SPLINES; ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; REFERENCE EVAPOTRANSPIRATION; PAN EVAPORATION; ELASTIC-MODULUS; RANDOM FOREST; POINT LOAD; FUZZY	Estimating the uniaxial compressive strength (UCS) of travertine rocks with an indirect modeling approach and machine learning algorithms is useful as models can reduce the cost and time required to obtain accurate measurements of UCS, which is important for the prediction of rock failure. This approach can also address the limitations encountered in preparing detailed measured samples using direct measurements. The current paper developed and compared the performance of three standalone tree-based machine learning models (random forest (RF), M5 model tree, and multivariate adaptive regression splines (MARS)) for the prediction of UCS in travertine rocks from the Azarshahr area of northwestern Iran. Additionally, an ensemble committee-based artificial neural network (ANN) model was developed to integrate the advantages of the three standalone models and obtain further accuracy in UCS prediction. To date, an ensemble approach for estimating UCS has not been explored. To construct and validate the models, a set of rock test data includingp-wave velocity (V-p(Km/s)), Schmidt Hammer (R-n), porosity (n%), point load index (I-s(MPa)), and UCS (MPa) were acquired from 93 travertine core samples. To develop the ensemble tree-based machine learning model, the input matrix representingV(p),R-n,n%, andI(s)data with the corresponding target variable (i.e., UCS) was incorporated with a ratio of 70:15:15 (train: validate: test). Results indicated that a standalone MARS model outperformed all other standalone tree-based models in predicting UCS. The ANN-committee model, however, obtained the best performance with anr-value of approximately 0.890, an RMSE of 3.980 MPa, an MAE of 3.225 MPa, a WI of 0.931, and an LMI of 0.537, demonstrating the improved accuracy of the ensemble model for the prediction of UCS relative to the standalone models. The results suggest that the proposed ensemble committee-based model is a useful approach for predicting the UCS of travertine rocks with a limited set of model-designed datasets.																	0941-0643	1433-3058				JUL	2020	32	13					9065	9080		10.1007/s00521-019-04418-z													
J								Nonnegative discriminative encoded nearest points for image set classification	NEURAL COMPUTING & APPLICATIONS										Image set classification; Nonnegative coding; Sparse representation; Collaborative representation	FACE RECOGNITION; COLLABORATIVE REPRESENTATION; SPARSE	Image set classification has drawn much attention due to its rich set information. Recently, the most popular set-to-set distance-based representation methods have achieved interesting results by measuring the between-set distance. However, there are two intuitive assumptions, which are largely ignored: (1) The homogeneous samples should have positive contributions to approximate the nearest point in the probe set, while the heterogeneous samples should have no contributions and (2) the learned nearest points in each gallery set should have the lowest correlations. Therefore, this paper presents a novel method called nonnegative discriminative encoded nearest points for image set classification. Specifically, we use two explicit nonnegative constraints to ensure the coding coefficients sparse and discriminative simultaneously. Moreover, we additionally introduce a new class-wise discriminative term to further boost the discriminant ability of different sets. In this way, they can be boosted mutually so that the obtained coding coefficients are beneficial to the purpose of set classification. The results from extensive experiments and comparisons with some state-of-the-art methods on four challenging datasets demonstrate the superiority of our method.																	0941-0643	1433-3058				JUL	2020	32	13					9081	9092		10.1007/s00521-019-04419-y													
J								Microgrid management using hybrid inverter fuzzy-based control	NEURAL COMPUTING & APPLICATIONS										Diesel generator; DG; Photovoltaic; PV; Electrochemical battery; Power management; Mamdani fuzzy logic	ENERGY MANAGEMENT; SYSTEM; ALGORITHM	Microgrid systems are becoming a very promising solution to meet the power demand growth especially in remote areas where diesel generators (DG) are commonly used as a main energy source. Photovoltaic (PV) systems are commonly used as a sustainable energy source to economize DG fuel. Due to the intermittent and fluctuating behavior of PV generators, energy storage systems (ESS) such as electrochemical battery are suggested. PV and ESS are usually connected using one inverter/charger called hybrid inverter. The power management is crucial to optimize the fuel consumption and operate efficiently ESS. Additionally, in an off-grid operation, the microgrid frequency becomes sensible due to the slow dynamic of DG which requires an additional control tool to improve the frequency regulation. This paper proposes a new power management based on Mamdani fuzzy logic. The proposed controller considers the targets mentioned above by only controlling the hybrid inverter. Simulation results prove that fuzzy-based controller reduces the DG fuel consumption by more than 12% compared to classical hysteresis management control. Moreover, the proposed controller performs efficiently regarding the conventional frequency regulation, which is widely used in microgrid control.																	0941-0643	1433-3058				JUL	2020	32	13					9093	9111		10.1007/s00521-019-04420-5													
J								An outlier detection approach in large-scale data stream using rough set	NEURAL COMPUTING & APPLICATIONS										Relative information entropy; Outlier detection; Rough sets; Data mining; Indiscernible sets	INFORMATION-ENTROPY; UNCERTAINTY; REDUCTION	Outlier detection has become an important research area in the field of stream data mining due to its vast applications. In the literature, many methods have been proposed, but they work well for simple and positive regions of outliers, where boundary regions are not given much importance. Moreover, an algorithm which processes stream data must be effective and able to compute infinite data in one pass or limited number of passes. These problems have motivated us to propose an outlier detection approach for large-scale data stream. The proposed algorithm employs the concept of relative cardinality, entropy outlier factor theory of information-based system, and size-variant sliding window in stream data. In addition, we propose a new methodology for concept drift adaptation on evolving data streams. The proposed method is executed on nine benchmark datasets and compared with six existing methods that are EXPoSE, iForest, OC-SVM, LOF, KDE, and FastAbod. Experimental results show that the proposed method outperforms six existing methods in terms of receiver operating characteristic curve, precision recall, and computational time for positive regions as well as for boundary regions.																	0941-0643	1433-3058				JUL	2020	32	13					9113	9127		10.1007/s00521-019-04421-4													
J								Optimal operation of transmission power networks by using improved stochastic fractal search algorithm	NEURAL COMPUTING & APPLICATIONS										Stochastic fractal search; Diffusion process; Update process; Optimal power flow; Objective function; Operating limitations	DIFFERENTIAL EVOLUTION ALGORITHM; DISTRIBUTED GENERATORS; FLOW LITERATURE; OPTIMIZATION; COST; EMISSION; SOLVE	This paper presents the application of an improved stochastic fractal search algorithm (ISFSA) for optimizing five single objectives of optimal power flow (OPF) problem and satisfying all constraints consisting of operating limits of electric components, power balance and load voltage magnitude limits. The proposed ISFSA is formed by implementing three improvements on the conventional stochastic fractal search algorithm (SFSA). The first improvement cancels one ineffective formula but keeps another one in diffusion process. The second improvement selects some worst solutions in the first update and some best solutions in the second update for producing new solutions. In the third improvement, a proposed technique is applied for carrying out the update processes. Comparisons of obtained results from three standard IEEE power systems indicate that the proposed method is superior to SFSA in terms of optimal solution quality, execution speed as well as success rate. The performance comparisons with other existing methods available in previous studies also lead to the conclusions that the proposed method can reach lower generation fuel cost, smaller total power losses, less amount of emission, better voltage profile and faster execution process. As a result, it can be recommended that the proposed ISFSA should be used for OPF problem in high-voltage power system field.																	0941-0643	1433-3058				JUL	2020	32	13					9129	9164		10.1007/s00521-019-04425-0													
J								Sniffer-Net: quantitative evaluation of smoke in the wild based on spatial-temporal motion spectrum	NEURAL COMPUTING & APPLICATIONS										Smoke detection; Sniffer-Net; Optical flow; Concentration evaluation; Motion feature		Smoke detection plays an essential role in the wild video surveillance systems for abnormal events warning. In this paper, we introduced a dedicated neural network structure named Sniffer-Net to simultaneously extract smoke dynamic feature robustly and evaluate the smoke concentration accurately. Firstly, we utilize an improved LiteFlowNet to estimate the global optical flow from image sequence. Meanwhile, a Marr-Hildreth method is brought up and fused into this network to distinguish and eliminate occluded regions from global flow map. Then, an evaluation module based on Context-Encoder network is put forward specially to quantify smoke concentration levels. This network, following the improved LiteFlowNet, is modified through replacing the loss function and removing the multiscale scheme and trained to infer approximate smoke optical flow behind occlusion regions. Starting from the statistical view, the irregular RGB/HSV feature spaces are converted into a specific quantitative evaluation space. As a result, the whole evaluation system is responsible to transform the distribution of irregular smoke motion feature into a quantified form of representation. In turn, this transformation endows the system with a novel numerical standard for smoke concentration evaluation. Finally, an accuracy assessment method is applied to compare the results of detected smoke concentration with the human experience prior model, which feedback the accuracy and false detection rate of system algorithm. In the experiments of five smoke datasets, our proposed smoke detection approach is superior to other state-of-the-art methods, and concentration algorithm achieves the satisfactory performance of 97.3% accuracy on some specialized dataset.																	0941-0643	1433-3058				JUL	2020	32	13					9165	9180		10.1007/s00521-019-04426-z													
J								Adaptive segmentation-based feature extraction and S-STDM watermarking method for color image	NEURAL COMPUTING & APPLICATIONS										Image watermarking; Adaptive segmentation-based feature extraction; Simple linear iterative clustering; Stationary wavelet transform	DIGITAL WATERMARKING; FACE DETECTION; ROBUST; DECOMPOSITION	A local color image watermarking scheme using adaptive segmentation-based feature extraction (ASFE) and singular value decomposition-based spread transform dither modulation (S-STDM) is proposed in this paper. The proposed ASFE can adaptively extract feature regions from blocks segmented by the simple linear iterative clustering. In addition, the stationary wavelet transform is employed to decompose each of the extracted feature regions because of its shift invariance. Consequently, the novel S-STDM watermarking method is proposed, where we employ singular value decomposition to calculate the approximation coefficients and then select the generated diagonal elements from the decomposed diagonal matrix for watermark message embedding. The experimental results show that the proposed scheme is superior to the existing schemes under various attacks.																	0941-0643	1433-3058				JUL	2020	32	13					9181	9200		10.1007/s00521-019-04428-x													
J								Hybrid HMM/BLSTM system for multi-script keyword spotting in printed and handwritten documents with identification stage	NEURAL COMPUTING & APPLICATIONS										Script identification; Word spotting; BLSTM; HMM; Handwriting; Machine printed; Multi-script; Arabic; Latin	WORD; RECOGNITION; TEXT; DISCRIMINATION; FEATURES	In this paper, we propose a novel script-independent approach for word spotting in printed and handwritten multi-script documents. Since each writing type and script need to be processed using a specific spotting engine, the proposed system proceeds on two stages. The script identification is a preliminary stage that aims at recognizing on one level the writing type and the script of the input image document. Second, a specific word spotting method is used to spot query words in a large collection of documents. The proposed spotting system is based on deep bidirectional long short-term memory neural network and hidden Markov model (HMM) hybrid architecture. It takes advantage of DNN's strong representation learning power and HMM's sequential modeling ability. The global system has been evaluated on a mixed corpus of public databases such as KHATT, PKHATT for Arabic script and RIMES for Latin script. The experimental results on script identification and keyword spotting confirm the effectiveness of the proposed approach.																	0941-0643	1433-3058				JUL	2020	32	13					9201	9215		10.1007/s00521-019-04429-w													
J								Formulation and application of quantum-inspired tidal firefly technique for multiple-objective mixed cost-effective emission dispatch	NEURAL COMPUTING & APPLICATIONS										Economic power dispatch; Emission penalty cost; Firefly algorithm (FA); Max to max penalty factor; Quantum-inspired tidal firefly algorithm (QITFA); Tidal firefly algorithm (TFA)	PARTICLE SWARM OPTIMIZATION; GLOBAL WARMING POTENTIALS; DETAILED SURVEY; LOAD DISPATCH; ALGORITHM; COLONY	In this manuscript, a new quantum computing-based optimization algorithm is proposed to solve multiple-objective mixed cost-effective emission dispatch (MEED) problem of electrical power system. The MEED problem aims at maintaining proper balance between emission of pollutants and generation of power. The problem has been formulated here using cubic equation to reduce the nonlinearities of the system. It is transformed to single-objective problem by considering max to max penalty factor. The proposed optimization technique is inspired by the concept of quantum mechanics, gravitational force and firefly algorithm (FA) and is termed as quantum-inspired tidal FA (QITFA). The proposed QITFA is tested on IEEE 14-bus and IEEE 30-bus test system for four different load conditions. The obtained results are compared with the results yielded by some other state-of-the-art methods like Lagrangian relaxation method, particle swarm optimization (PSO), simulated annealing, quantum-behaved bat algorithm and quantum PSO. This paper proves the superiority of the proposed QITFA over all these methods. Further, the obtained results also suggest its effective and efficient implementation in MEED problem.																	0941-0643	1433-3058				JUL	2020	32	13					9217	9232		10.1007/s00521-019-04433-0													
J								Adversarial frontier stitching for remote neural network watermarking	NEURAL COMPUTING & APPLICATIONS										Watermarking; Neural network models; Black box interaction; Adversarial examples; Model decision frontiers		The state-of-the-art performance of deep learning models comes at a high cost for companies and institutions, due to the tedious data collection and the heavy processing requirements. Recently, Nagai et al. (Int J Multimed Inf Retr 7(1):3-16, 2018), Uchida et al. (Embedding watermarks into deep neural networks, ICMR, 2017) proposed to watermark convolutional neural networks for image classification, by embedding information into their weights. While this is a clear progress toward model protection, this technique solely allows for extracting the watermark from a network that oneaccesses locallyand entirely. Instead, we aim at allowing the extraction of the watermark from a neural network (or any other machine learning model) that is operatedremotely, and available through a service API. To this end, we propose to mark the model's action itself, tweaking slightly its decision frontiers so that a set of specific queries convey the desired information. In the present paper, we formally introduce the problem and propose a novel zero-bit watermarking algorithm that makes use ofadversarial model examples. While limiting the loss of performance of the protected model, this algorithm allows subsequent extraction of the watermark using only few queries. We experimented the approach on three neural networks designed for image classification, in the context of MNIST digit recognition task.																	0941-0643	1433-3058				JUL	2020	32	13					9233	9244		10.1007/s00521-019-04434-z													
J								Functional iterative approaches for solving support vector classification problems based on generalized Huber loss	NEURAL COMPUTING & APPLICATIONS										Support vector machine; Functional iterative scheme; Huber loss function; Quadratic programming problem	MACHINE	Classical support vector machine (SVM) and its twin variant twin support vector machine (TWSVM) utilize the Hinge loss that shows linear behaviour, whereas the least squares version of SVM (LSSVM) and twin least squares support vector machine (LSTSVM) uses L-2-norm of error which shows quadratic growth. The robust Huber loss function is considered as the generalization of Hinge loss and L-2-norm loss that behaves like the quadratic L-2-norm loss for closer error points and the linear Hinge loss after a specified distance. Three functional iterative approaches based on generalized Huber loss function are proposed in this paper to solve support vector classification problems of which one is based on SVM, i.e. generalized Huber support vector machine and the other two are in the spirit of TWSVM, namely generalized Huber twin support vector machine and regularization on generalized Huber twin support vector machine. The proposed approaches iteratively find the solutions and eliminate the requirements to solve any quadratic programming problem (QPP) as for SVM and TWSVM. The main advantages of the proposed approach are: firstly, utilize the robust Huber loss function for better generalization and for lesser sensitivity towards noise and outliers as compared to quadratic loss; secondly, it uses functional iterative scheme to find the solution that eliminates the need to solving QPP and also makes the proposed approaches faster. The efficacy of the proposed approach is established by performing numerical experiments on several real-world datasets and comparing the result with related methods, viz. SVM, TWSVM, LSSVM and LSTSVM. The classification results are convincing.																	0941-0643	1433-3058				JUL	2020	32	13					9245	9265		10.1007/s00521-019-04436-x													
J								An improved SIFT algorithm for robust emotion recognition under various face poses and illuminations	NEURAL COMPUTING & APPLICATIONS										Expression recognition; Feature point position; Scale-invariant feature transform (SIFT) descriptors; Principal component analysis (PCA); Support vector machine (SVM)	FACIAL EXPRESSION RECOGNITION; FEATURE-EXTRACTION; ROC CURVE; AREA; PCA	To address the variabilities of the number and position of extracted feature points for the traditional scale-invariant feature transform (SIFT) method, an improved SIFT algorithm is proposed for robust emotion recognition. Specifically, shape decomposition is first performed on the detected facial images by defining a weight vector. Then, a feature point constraint algorithm is developed to determine the optimum position of the feature points that can effectively represent the expression change regions. On this basis, the SIFT descriptors are applied to extract the regional gradient information as feature parameters. Finally, the support vector machine classifier combined with the principal component analysis method is used to reduce the feature dimensions and facial expression recognition. Experiments have been performed under different conditions, i.e., varied illuminations, face poses and facial moisture levels, using 15 participants. In the cases of frontal face and 5-degree face rotation views, the average recognition accuracies are 98.52% and 94.47% (no additional light sources), as well as 96.97% and 95.40% (two additional light sources), respectively. In addition, as an effective supplement to the problem of changes in illumination, the average recognition ratios are 96.23% and 96.20% under dry and wet face conditions, respectively. The experimental results reveal the robust performance of the proposed method in facial expression recognition.																	0941-0643	1433-3058				JUL	2020	32	13					9267	9281		10.1007/s00521-019-04437-w													
J								Multi-scale kernel Fisher discriminant analysis with adaptive neuro-fuzzy inference system (ANFIS) in fault detection and diagnosis framework for chemical process systems	NEURAL COMPUTING & APPLICATIONS										ANFIS classification; Chemical process systems; Fault detection and diagnosis system; Multi-scale KFDA	WAVELET TRANSFORM; FEATURE-EXTRACTION; INDUCTION-MOTOR; CLASSIFICATION; MODEL	Fault detection and diagnosis (FDD) framework is one of safety aspects that is important to the industrial sector to ensure its high-quality production and processes. However, the development of FDD system in chemical process systems could have difficulties, e.g. highly nonlinear correlation within the variables, highly complex process, and an enormous number of sensors to be monitored. These issues have encouraged the development of various approaches to increase the effectiveness and robustness of the FDD framework, such as the wavelet transform analysis, where it has the advantage in extracting the significant features in both time and frequency domain. It has motivated us to propose an extension work of the multi-scale KFDA method, where we have modified it with the implementation of Parseval's theorem and the application of ANFIS method to improve the performance of the fault classification. In this work, through the implementation of Parseval's theorem, the observation of fault features via the energy spectrum and effective reduction in DWT analysis data quantity can be accomplished. The extracted features from the multi-scale KFDA method are used for fault diagnosis and classification, where multiple ANFIS models were developed for each designated fault pattern to increase the classification accuracy and reduce the diagnosis error rate. The fault classification performance of the proposed framework has been evaluated using a benchmarked Tennessee Eastman process. The results indicated that the proposed multi-scale KFDA-ANFIS framework has shown the improvement with an average of 87.02% in classification accuracy over the multi-scale PCA-ANFIS (78.90%) and FDA-ANFIS (70.80%).																	0941-0643	1433-3058				JUL	2020	32	13					9283	9297		10.1007/s00521-019-04438-9													
J								Memetic quantum evolution algorithm for global optimization	NEURAL COMPUTING & APPLICATIONS										Quantum evolution; Memetic algorithm; Evolutionary computation; Gravitational search algorithm	PARTICLE SWARM OPTIMIZATION; SEARCH	Quantum-inspired heuristic search algorithms have attracted considerable research interest in recent years. However, existing quantum simulation methods are still limited on the basis of particle swarm optimizer. This paper explores the principle of memetic computing to develop a novel memetic quantum evolution algorithm for solving global optimization problem. First, we design a quantum theory-based memetic framework to handle multiple evolutionary operators, in which multiple units of different kinds of algorithmic information are harmoniously combined. Second, we propose the memetic evolutionary operator and the quantum evolutionary operator to complete the balance between the global search and the local search. The memetic evolutionary operator emphasizes meme diffusion by the shuffled process to enhance the global search ability. The quantum evolutionary operator utilizes an adaptive selection mechanism for different potential wells to tackle the local search ability. Furthermore, the Newton's gravity laws-based gravitational center and geometric center as two important components are introduced to improve the diversity of population. These units can be recombined by means of different evolutionary operators that are based on the synergistic coordination between exploitation and exploration. Through extensive experiments on various optimization problems, we demonstrate that the proposed method consistently outperforms 11 state-of-the-art algorithms.																	0941-0643	1433-3058				JUL	2020	32	13					9299	9329		10.1007/s00521-019-04439-8													
J								Forecasting hourly NO2 concentrations by ensembling neural networks and mesoscale models	NEURAL COMPUTING & APPLICATIONS										Neural networks; Deep learning; Air quality; Nitrogen dioxide; Forecasting; Madrid	PREDICTION; AIR; POLLUTION; OZONE; SYSTEM	In the framework of extreme pollution concentrations being more and more frequent in many cities nowadays, air quality forecasting is crucial to protect public health through the anticipation of unpopular measures like traffic restrictions. In this work, we develop the core of a 48 h ahead forecasting system which is being deployed for the city of Madrid. To this end, we investigate the predictive power of a set of neural network models, including several families of deep networks, applied to the task of predicting nitrogen dioxide concentrations in an urban environment. Careful feature engineering on a set of related magnitudes as meteorology and traffic has proven useful, and we have coupled these neural models with mesoscale numerical pollution forecasts, which improve precision by up to 10%. The experiments show that some neural networks and ensembles consistently outperform the reference models, particularly improving the Naive model's results from around (20%) up to (57%) for longer forecasting horizons. However, results also reveal that deeper networks are not particularly better than shallow ones in this setting.																	0941-0643	1433-3058				JUL	2020	32	13					9331	9342		10.1007/s00521-019-04442-z													
J								Cost estimation in road construction using artificial neural network	NEURAL COMPUTING & APPLICATIONS										Estimation; Costs; Road projects; Artificial neural network	MODEL	Road construction projects on the territory of the Republic of Croatia are characterized by the overrun of planned costs. The experience of the contractor on previous road projects is an important element that can help to prevent errors and increase the chances of success in similar future projects. Data on construction costs collected from past projects can be used to estimate costs at different stages of the project life cycle through artificial neural networks. In this paper, artificial neural networks (MLP, GRNN, RBFNN) for estimating road construction costs are modeled. During the modeling, the database of roads constructed on the territory of the Republic of Croatia was used. Comparison of performance of neural networks has shown that the GRNN has obtained the best accuracy with MAPE of 13% and coefficient of determination of 0.9595. The neural network has proven to be a promising approach to use in the initial design phase when there is usually a limited or incomplete set of data for cost analysis, and this method could yield much more accurate results and the estimation error could be reduced.																	0941-0643	1433-3058				JUL	2020	32	13					9343	9355		10.1007/s00521-019-04443-y													
J								Deep convolutional neural network designed for age assessment based on orthopantomography data	NEURAL COMPUTING & APPLICATIONS										Age assessment; Orthopantomography data; Image processing; Deep learning	CHILDREN	In this paper, we proposed an age assessment method evaluated on Malaysian children aged between 1 and 17. The approach is based on global fuzzy segmentation, local feature extraction using a projection-based feature transform and a designed deep convolutional neural networks (DCNNs) model. In the first step, a global labelling process was achieved based on fuzzy segmentation, and then, the first-to-third molar teeth were segmented. The deformation invariant features were next extracted based on an intensity projection technique. This technique provided high-order features which were invariant to rotation and partial deformation changes. Finally, the designed DCNN model extracts a large set of features in the hierarchical layers which provided scale, rotation and deformation invariance. The method using this approach was evaluated using a comprehensive and labelled orthopantomographs of 456 patients, which were captured in the Department of Dentistry and Research at Universiti Sains Islam Malaysia. The results from the analysis have suggested that the method can classify the images with high performance, which enabled automated age estimation with high accuracy.																	0941-0643	1433-3058				JUL	2020	32	13					9357	9368		10.1007/s00521-019-04449-6													
J								Neural network-supported patient-adaptive fall prevention system	NEURAL COMPUTING & APPLICATIONS										Fall prevention; Medical systems; Patient safety; Wearable sensors	PHYSICAL-ACTIVITY; SENSOR; TIME; CLASSIFICATION; ACCELEROMETER; COST	Patient falls due to unattended bed-exits are costly to patients, healthcare personnel and hospitals. Numerous researches based on up to three predetermined factors have been conducted for preventing falls. The present comprehensive proposal is based on four sub-systems that synthesize six factors. A parameter is assigned to each factor with a coefficient specifically determined for each individual patient and per admittance. The parameters are aggregated in equations that lead to an early warning about a probable bed-exit, or an alarm about an imminent bed-exit. The ultimate aim of our proposal is the generation of the earliest possible warning to grant the longest time for nurse intervention. Thus, the probable fall of high-risk patients can be prevented, by stopping the unattended bed-exits. The proposal is supported by a prototype multi-tier system design and the results of laboratory patient bed-exit scenarios, carried out using the design. Comparison of the obtained results with previous work shows that our proposed solution is unmatched in providing the longest time for nurse intervention (up to 15.7 +/- 1.1 s), because of the comprehensive six-factor synthesis, specific to each individual patient and each admittance.																	0941-0643	1433-3058				JUL	2020	32	13					9369	9382		10.1007/s00521-019-04451-y													
J								Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm	NEURAL COMPUTING & APPLICATIONS										Artificial ecosystem-based optimization; Global optimization; Constrained problems; Optimization algorithm; Engineering design; Hydrogeological parameter	PARTICLE SWARM OPTIMIZATION; ATOM SEARCH OPTIMIZATION; ENGINEERING OPTIMIZATION; DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION; DESIGN; COLONY; RULE	A novel nature-inspired meta-heuristic optimization algorithm, named artificial ecosystem-based optimization (AEO), is presented in this paper. AEO is a population-based optimizer motivated from the flow of energy in an ecosystem on the earth, and this algorithm mimics three unique behaviors of living organisms, including production, consumption, and decomposition. AEO is tested on thirty-one mathematical benchmark functions and eight real-world engineering design problems. The overall comparisons suggest that the optimization performance of AEO outperforms that of other state-of-the-art counterparts. Especially for real-world engineering problems, AEO is more competitive than other reported methods in terms of both convergence rate and computational efforts. The applications of AEO to the field of identification of hydrogeological parameters are also considered in this study to further evaluate its effectiveness in practice, demonstrating its potential in tackling challenging problems with difficulty and unknown search space. The codes are available at.																	0941-0643	1433-3058				JUL	2020	32	13					9383	9425		10.1007/s00521-019-04452-x													
J								A whale optimization algorithm-trained artificial neural network for smart grid cyber intrusion detection	NEURAL COMPUTING & APPLICATIONS										Smart grid; Cyber-attack; Whale optimization algorithm (WOA); Artificial neural network (ANN)	BAD DATA DETECTION; FEATURE-SELECTION APPROACH; POWER-SYSTEMS; STATE ESTIMATION; ATTACKS; SECURITY; EFFICIENT	The smart grid is a revolutionary, intelligent, next-generation power system. Due to its cyber infrastructure nature, it must be able to accurately and detect potential cyber-attacks and take appropriate actions in a timely manner. This paper creates a new intrusion detection model, which is able to classify the binary-class, triple-class, and multi-class cyber-attacks and power-system incidents. The intrusion detection model is based on a whale optimization algorithm (WOA)-trained artificial neural network (ANN). The WOA is applied to initialize and adjust the weight vector of the ANN to achieve the minimum mean square error. The proposed WOA-ANN model can address the challenges of attacks, failure prediction, and failure detection in a power system. We utilize the Mississippi State University and Oak Ridge National Laboratory databases of power-system attacks to demonstrate the proposed model and show the experimental results. The WOA is able to train the ANN to find the optimal weights. We compare the proposed model with other commonly used classifiers. The comparison results show the superiority of the proposed WOA-ANN model.																	0941-0643	1433-3058				JUL	2020	32	13					9427	9441		10.1007/s00521-019-04453-w													
J								A new spatio-temporal background-foreground bimodal for motion segmentation and detection in urban traffic scenes	NEURAL COMPUTING & APPLICATIONS										Motion segmentation; Background subtraction; Cumulative frame differencing; Sigma-delta filter; Vehicle detection	VEHICLE DETECTION; SUBTRACTION; ALGORITHM; TRACKING; SYSTEM; MODEL	Automatic vehicle detection in urban traffic surveillance is an important and urgent issue, since it provides necessary information for further processing. Conventional techniques utilize either motion segmentation or appearance-based detection, which involves either poor adaptation or high computation. The complexity of urban traffic scenarios lies in slow motion temporarily stopped or parked vehicles, dynamic background, and sudden illumination variations. In this paper, a new motion segmentation technique is proposed based on spatio-temporal background-foreground bimodal. The temporal background information is modeled using a weighted sigma-delta estimation, cumulative frame differencing is used to model the foreground pixels, and the spatial correlation between neighboring pixels is utilized to combine both background and foreground models. The median of consecutive frame difference adapts sudden illumination variation, update background model, and reinitialize foreground model. Comparative experimental results for typical urban traffic sequences show that the proposed technique achieves robust and accurate segmentation, which improves adaptation, reduce false detection, and satisfy real-time requirements.																	0941-0643	1433-3058				JUL	2020	32	13					9453	9469		10.1007/s00521-019-04458-5													
J								Adaptive finite-time congestion controller design of TCP/AQM systems based on neural network and funnel control	NEURAL COMPUTING & APPLICATIONS										TCP; AQM network; Congestion control; Funnel control; Finite-time adaptive NNs control	ACTIVE QUEUE MANAGEMENT; SLIDING MODE CONTROL; TRACKING CONTROL; PRESCRIBED PERFORMANCE; NONLINEAR-SYSTEMS; TCP/RED SYSTEMS; STABILITY; TCP; RED	This work investigates an adaptive finite-time congestion control problem of transmission control protocol/active queue management. By means of the funnel control, neural networks and sliding mode control, a new AQM algorithm is proposed to ensure that the tracking error e1otTHORN converges to the prescribed boundary in finite time and the transient and steady-state performances of e1otTHORN can be satisfied. The stability analysis is given to prove that all the signals of the closed-loop system are finite-time bounded. Finally, a comparison example is considered to demonstrate the feasibility and superiority of the presented scheme.																	0941-0643	1433-3058				JUL	2020	32	13					9471	9478		10.1007/s00521-019-04459-4													
J								A new discriminative collaborative representation-based classification method vial(2)regularizations	NEURAL COMPUTING & APPLICATIONS										Collaborative representation; Representation-based classification; Pattern recognition	ROBUST FACE RECOGNITION; SPARSE REPRESENTATION; DICTIONARY	Collaborative representation-based classification (CRC) is one of the famous representation-based classification methods in pattern recognition. However, a testing sample in most of the CRC variants is collaboratively reconstructed by a linear combination of all the training samples from all the classes, the training samples from the class that the testing sample belongs to have no advantage in discriminatively and competitively representing and classifying the testing sample. Moreover, the incorrect classification can easily come into being when the training samples from the different classes are very similar. To address the issues, we propose a novel discriminative collaborative representation-based classification (DCRC) method via l2 regularizations to enhance the power of pattern discrimination. In the proposed model, we consider not only the discriminative decorrelations among all the classes, but also the similarities between the reconstructed representation of all the classes and the class-specific reconstructed representations in the l2 regularizatiozns. The experiments on several public face databases have demonstrated that the proposed DCRC effectively and robustly outperforms the state-of-the-art representation-based classification methods.																	0941-0643	1433-3058				JUL	2020	32	13					9479	9493		10.1007/s00521-019-04460-x													
J								Reconciling predictive and interpretable performance in repeat buyer prediction via model distillation and heterogeneous classifiers fusion	NEURAL COMPUTING & APPLICATIONS										Model distillation; Heterogeneous classifier fusion; Interpretable models; Repeat buyer prediction		Repeat buyer prediction is crucial for e-commerce companies to enhance their customer services and product sales. In particular, being aware of which factors or rules drive repeat purchases is as significant as knowing the outcomes of predictions in the business field. Therefore, an interpretable model with excellent prediction performance is required. Many classifiers, such as the multilayer perceptron, have exceptional predictive abilities but lack model interpretability. Tree-based models possess interpretability; however, their predictive performances usually cannot achieve high levels. Based on these observations, we design an approach to balance the predictive and interpretable performance of a decision tree with model distillation and heterogeneous classifier fusion. Specifically, we first train multiple heterogeneous classifiers and integrate them through diverse combination operators. Then, classifier combination plays the role of teacher model. Subsequently, soft targets are obtained from the teacher and guide training of the decision tree. A real-world repeat buyer prediction dataset is utilized in this paper, and we adopt features with respect to three aspects: users, merchants, and user-merchant pairs. Our experimental results show that the accuracy and AUC of the decision tree are both improved, and we provide model interpretations of three aspects.																	0941-0643	1433-3058				JUL	2020	32	13					9495	9508		10.1007/s00521-019-04462-9													
J								Modelling and prediction of antibacterial activity of knitted fabrics made from silver nanocomposite fibres using soft computing approaches	NEURAL COMPUTING & APPLICATIONS										Antibacterial activity; Artificial neural network; Adaptive network-based fuzzy inference system; Polyester-cotton blend; Machine gauge	ARTIFICIAL NEURAL-NETWORK; ANTIMICROBIAL ACTIVITY; ANFIS; PARAMETERS; STRENGTH; OPTIMIZATION; RESISTANCE; POLYESTER	Antibacterial activity of knitted fabrics has been modelled and predicted by using two soft computing approaches, namely artificial neural network (ANN) and adaptive network-based fuzzy inference system (ANFIS). Four parameters, namely proportion of polyester-silver nanocomposite fibres in yarn, yarn count (diameter), machine gauge and type of fabric (100% polyester or 50:50 polyester-cotton), were used as input parameters for predicting antibacterial activity of knitted fabrics. For each of the input parameters, two fuzzy sets (low and high) were considered to reduce the complexity of ANFIS model. The sixteen linguistic fuzzy rules trained by ANFIS were able to explain the relationship between input parameters and antibacterial activity. A comparison between ANN and ANFIS models has also been presented. Both the models predicted the antibacterial activity of knitted fabrics with very good prediction accuracy in the training and testing data sets with coefficient of determination greater than 0.92 and mean absolute prediction error less than 5%. The robustness of the prediction results against data partitioning between training and testing sets has also been investigated. It is found that prediction accuracy of both the models was quite robust with ANFIS showing better performance with lesser number of training data.																	0941-0643	1433-3058				JUL	2020	32	13					9509	9519		10.1007/s00521-019-04463-8													
J								Hybrid sine cosine artificial bee colony algorithm for global optimization and image segmentation	NEURAL COMPUTING & APPLICATIONS										Optimization; Artificial bee colony (ABC) algorithm; Sine cosine algorithm (SCA); Hybrid algorithms; Multilevel thresholding	GREY WOLF OPTIMIZER; PARTICLE SWARM; STRATEGY; EFFICIENT	Artificial bee colony (ABC) algorithm is an efficient biological-inspired optimization method, which mimics the foraging behavior of honey bees to solve the complex and nonlinear optimization problems. However, in some cases, it suffers from inefficient exploration, low exploitation and slow convergence rate. These shortcomings cause the problem of stagnation at local optimum which is dangerous in determining the true solution (optima) of the problem. Therefore, in the present paper, an attempt has been made toward the removal of the drawbacks from the classical ABC by proposing a novel hybrid method called SCABC algorithm. The SCABC algorithm hybridizes the ABC with sine cosine algorithm (SCA) to upgrade the level of exploitation and exploration in the classical ABC algorithm. The SCA is a recently introduced algorithm, which uses the trigonometric functions sine and cosine to perform the search. The validation of the SCABC algorithm is performed on a well-known benchmark set of 23 optimization problems. The various analysis metrics such as statistical, convergence and performance index analysis verify the better search ability of the SCABC as compared to classical ABC, SCA. The comparison with some other optimization algorithms demonstrates a comparatively better state of exploitation and exploration in the SCABC algorithm. Moreover, the SCABC is also employed on multilevel thresholding problems. The various performance measures demonstrate the efficacy of the SCABC algorithm in determining the optimal thresholds of gray images.																	0941-0643	1433-3058				JUL	2020	32	13					9521	9543		10.1007/s00521-019-04465-6													
J								Multi-feature weighting neighborhood density clustering	NEURAL COMPUTING & APPLICATIONS										Clustering analysis; Multi-feature; Neighborhood density; Rough set; Granular computing	SUBSPACE; ALGORITHM	Clustering is an important data mining method to discover knowledge and patterns. Feature weighting is widely applied in high-dimensional data mining. In this paper, a multi-feature weighting neighborhood density clustering algorithm is proposed. It uses different dimension reduction algorithms to generate different features, and then, the weights of the features are determined by the discrimination ability. For the clustering algorithm, the center points can be selected by the upper approximation set and lower approximation set. At last, the final clustering result is from the fusion of multiple clustering results. The proposed algorithms and comparison algorithms are executed on the synthetic and real-world data sets. The test results show that the proposed algorithm outperforms the comparison algorithms on the most experimental data sets. The experimental results prove that the proposed algorithm is effective for data clustering.																	0941-0643	1433-3058				JUL	2020	32	13					9545	9565		10.1007/s00521-019-04467-4													
J								Factorized weight interaction neural networks for sparse feature prediction	NEURAL COMPUTING & APPLICATIONS										Neural network; Sparse data; Factorization machine; Feature interaction		Non-contiguous and categorical sparse feature data are widely existed on the Internet. To build a machine learning system with these data, it is important to properly model the interaction among features. In this paper, we propose a factorized weight interaction neural network (INN) with a new network structure called weight-interaction layer to learn patterns from feature interactions and factorized weight parameters of each feature interaction. The proposed INN can greatly reduce the dimension of sparse data via the weight-interaction layer, while the multi-layer neural network can be used to capture high-order feature latent patterns. Our experimental results on two real datasets show that the proposed method is able to effectively improve the prediction accuracy and generalization performance of the model, and consistently outperform related methods to be compared.																	0941-0643	1433-3058				JUL	2020	32	13					9567	9579		10.1007/s00521-019-04470-9													
J								Cross-modality earth mover's distance-driven convolutional neural network for different-modality data	NEURAL COMPUTING & APPLICATIONS										Deep learning; Convolutional neural network; Earth mover's distance; Malware detection		Cross-modality matching refers to the problem of comparing similarity/dissimilarity of a pair of data points of different modalities, such as an image and a text. Deep neural networks have been popular to represent data points of different modalities due to their ability to extract effective features. However, existing works use simple distance metrics to compare the deep features of multiple modalities, which do not fit the nature of cross-modality matching, because it imposes the features of different modalities to be of the same dimension and do not allow cross-feature matching. To solve this problem, we propose to use convolutional neural network (CNN) models with soft-max activation layer to represent a pair of different-modality data points to two histograms (not necessarily of the same dimensions) and compare their dissimilarity by using earth mover's distance (EMD). The EMD can match the features extracted by the two CNN models of different modalities freely. Moreover, we develop a joint learning framework to learn the CNN parameters specifically for the EMD-driven comparison, supervised by the relevance/irrelevance labels of the data pairs of different modalities. The experiments over applications such as image-text retrieval, and malware detection show its advantage over existing cross-modality matching methods.																	0941-0643	1433-3058				JUL	2020	32	13					9581	9592		10.1007/s00521-019-04471-8													
J								Virtual reality in the context of Internet of Things	NEURAL COMPUTING & APPLICATIONS										Virtual reality; Internet of Things; Human-Computer interaction; Modbus communication protocol; Spatial database	ENABLING TECHNOLOGIES; ENVIRONMENT; IOT; FUTURE	In order to improve the user experience and efficiency of human-computer interaction in virtual reality technology, a comprehensive technology combined with high-tech achievements of multi-field is studied under the background of Internet of Things to realize the interaction between human and computer in a natural and intelligent way. The research results show that the interactive, simulated natural-state and three-dimensional environment can be formed at the display terminal through the processing and operation of information by computer program, which can make people feel immersed. It can be seen that in the environment of Internet of Things, the research on virtual reality technology should not only lay out top-level design and improve security and transmission efficiency, but also promote industrial application and enhance user stickiness. It would help to reveal the development trend of technology and the industrial layout and help relevant subjects to improve their level of technology R&D (research and development) and formulate competitive offensive and defensive strategies.																	0941-0643	1433-3058				JUL	2020	32	13					9593	9602		10.1007/s00521-019-04472-7													
J								Detection of HTTP flooding attacks in cloud using fuzzy bat clustering	NEURAL COMPUTING & APPLICATIONS										Cloud computing; Distributed Denial of Service (DDoS) attack; Cloud Forensics; Fuzzy logic; Bat algorithm	DDOS ATTACKS; INSPIRED ALGORITHM; OPTIMIZATION; SECURITY	Cloud computing plays a major role in reducing the expenditure of infrastructural costs on the basis of pay per use model. Security is the major concern wherein detection of security attacks and crimes is very difficult. Due to the distributed nature of attacks and crimes in the cloud, there is a need for an efficient security mechanism. Traditional security mechanisms cannot be applied directly to identify the source of attack due to the dynamic changes in the cloud. Hypertext Transfer Protocol (HTTP) flooding attacks are identified by keeping track of all the activities of the virtual machine instances running in the cloud. It is hard to identify the source of an attack since an attacker deletes all the possible traces. So, in order to mitigate this issue, the proposed method reads the logs, extracts the relevant features and investigates HTTP flooding attacks by a grouping of similar input patterns using fuzzy bat clustering and determines the anomalous behavior using deviated anomalous score. The suspicious source is determined by finding the event correlation between the virtual machine instance issued by cloud service provider with the suspicious source list. The experimental results are compared with the existing approaches, viz.,k-means clustering, fuzzyc-means clustering, bat clustering and Bartd method in which the proposed method determines the anomalies accurately with very few false alarm than existing approaches.																	0941-0643	1433-3058				JUL	2020	32	13					9603	9619		10.1007/s00521-019-04473-6													
J								A novel error-output recurrent neural network model for time series forecasting	NEURAL COMPUTING & APPLICATIONS										Recurrent neural network; Error-output feedbacks; Moving-average; NARMA; Ridge polynomial neural network; Forecasting; Nonlinear time series	EXCHANGE-RATE; LEARNING ALGORITHM; PREDICTION; NONSTATIONARY; OPTIMIZATION; INTELLIGENCE; REGRESSION; MULTISTEP; SYSTEMS	It is a well-known fact that improving forecasting accuracy is an important yet often challenging issue. Extensive research has been conducted using neural networks (NNs) to improve their forecasting accuracy. In general, the inputs to NNs are the auto-regressive (i.e. lagged variables) of one or more time series. In addition, either network outputs or network errors have been used as extra inputs to NNs. In this paper, however, we propose a novel recurrent neural network forecasting model which is called the ridge polynomial neural network with error-output feedbacks (RPNN-EOF). RPNN-EOF has two main types of inputs: auto-regressive and moving-average inputs. The former is represented by the lagged variables of a time series, while the latter is represented by feeding back network error to the input layer. In addition, network output is fed back to the input layer. The proposed recurrent model has the ability to produce more accurate forecasts due to the advantages of learning temporal dependence and the direct modelling of the moving-average component. A comparative analysis of RPNN-EOF with five neural network models was completed using ten time series. Simulation results have shown that RPNN-EOF is the most accurate model among all the compared models with the time series used. This shows that employing auto-regressive and moving-average inputs together helps to produce more accurate forecasts.																	0941-0643	1433-3058				JUL	2020	32	13					9621	9647		10.1007/s00521-019-04474-5													
J								Genetic algorithm-based community detection in large-scale social networks	NEURAL COMPUTING & APPLICATIONS										Genetic algorithm; Community detection; Similarity index; Fitness function	MULTIOBJECTIVE EVOLUTIONARY ALGORITHM; INDEX; MODULARITY	Communities in social networks are the essential feature which may be considered as a potential parameter in modeling the behavior of the social entities. Detection of communities has attracted a lot of attention in research in social network analysis. It is one of the major challenging problems as it involves high complexity in processing complex web structure. In fact, this problem can be considered as a NP-complete problem in large-scale networks, as this problem is somewhat reducible to the clique problem in graph theory. A number of meta-heuristic algorithms have been proposed to explore the hidden communities. Most of these algorithms have considered the modularity of the network as their objective function. But, the aspect of optimizing the value of modularity is associated with a problem known as resolution limit, where the size of the detected communities depends on the number of edges existing in the network. In this paper, a genetic algorithm-based community detection has been proposed where an efficient single objective function based on similarity matrix has been devised. The similarity index between each pair of nodes has been calculated in a distributed manner over multiple computing nodes. Similarity index proposed in this paper is based on the topological structure of the network. The effectiveness of the proposed approach is examined by comparing the performance with other state-of-the-art community detection algorithms applied over some real-world network datasets.																	0941-0643	1433-3058				JUL	2020	32	13					9649	9665		10.1007/s00521-019-04487-0													
J								Optimal quasi-synchronization of fractional-order memristive neural networks with PSOA	NEURAL COMPUTING & APPLICATIONS										Synchronization; Memristor; Aperiodically optimal control	2ND-ORDER MULTIAGENT SYSTEMS; FINITE-TIME SYNCHRONIZATION; DELAYED NONLINEAR DYNAMICS; STABILITY ANALYSIS; CONTROLLER-DESIGN; OPTIMIZATION; CONSENSUS	In this paper, optimal quasi-synchronization problem for fractional-order memristive delayed neural networks (FMDNNs) is investigated. The model of FMDNNs is transformed into systems with interval parameters. To guarantee quasi-synchronization, a general fractional-order inequalities and aperiodically intermittent controllers are proposed and analyzed. With the help of tools from interval matrix inequalities and fractional stability theory, sufficient conditions are obtained to guarantee quasi-synchronization of the FMDNNs. Synchronization errors about fractional order alpha are clearly stated. The optimal control parameters satisfy the integral square error, and minimal control energy can be computed by using particle swarm optimization algorithm. Finally, simulation examples are given for illustration.																	0941-0643	1433-3058				JUL	2020	32	13					9667	9682		10.1007/s00521-019-04488-z													
J								Risk prediction of type 2 diabetes in steel workers based on convolutional neural network	NEURAL COMPUTING & APPLICATIONS										Convolutional neural network; Steel worker; Type 2 diabetes mellitus (T2DM); Prediction of morbidity risk	MODEL; GLUCOSE	With the change in environment and lifestyle, the number of diabetic patients is increasing rapidly. Diabetes has become one of the most important chronic diseases affecting the health of the Chinese people, and complications, disability, death and treatment costs caused by diabetes have placed a heavy burden on families and society. If the high-risk population of diabetes can be identified and the adverse lifestyle can be changed as soon as possible, the incidence of diabetes can be reduced or the onset of diabetes can be slowed down. Risk prediction model can accurately predict the risk of disease and has been widely used in the field of health management and medical care. This study was based on the special occupational group of steel workers, the risk prediction model of type 2 diabetes was established by using convolutional neural network, and the feasibility of the model was discussed. The results showed that the prediction accuracy of the established model in the training set, verification set, and test set is relatively high, which is 94.5%, 91.0%, and 89.0%, respectively. The area under the ROC curve was 0.950 (95 CI 0.938-0.962), 0.916 (95 CI 0.888-0.945), and 0.899 (95 CI 0.899-0.939), respectively, indicating that the model can accurately predict the risk of type 2 diabetes among steel workers, provide a basis for self-health management of steel workers, facilitate the rational allocation of medical and health resources and the development of health services, and provide a basis for government departments to make decisions.																	0941-0643	1433-3058				JUL	2020	32	13					9683	9698		10.1007/s00521-019-04489-y													
J								Robust extended dissipativity analysis for Markovian jump discrete-time delayed stochastic singular neural networks	NEURAL COMPUTING & APPLICATIONS										Extended dissipativity analysis; Lyapunov-Krasovskii functional; Linear matrix inequality; Markovian jump parameters; Singular neural networks	SYSTEMS; STABILITY	This paper is concerned with the problem of extended dissipativity analysis for delayed uncertain discrete-time singular neural networks (DTSNNs) having Markovian jump parameters and stochastic behavior. This paper demands to derive delay-dependent sufficient conditions such that the DTSNNs to be regular and causal, and is to find the stability nature and the robustness of the performance measures in the mean square sense. Based on Lyapunov-Krasovskii functional method and Cauchy-Schwartz-based summation inequality technique, a sufficient condition to guarantee an extended dissipativity performance and stability criterion for uncertain stochastic DTSNNs is presented in terms of linear matrix inequalities. Finally, numerical examples are provided to illustrate the advantages and improvements of the proposed method.																	0941-0643	1433-3058				JUL	2020	32	13					9699	9712		10.1007/s00521-019-04497-y													
J								Stock closing price prediction based on sentiment analysis and LSTM	NEURAL COMPUTING & APPLICATIONS										Stock market prediction; Long short-term memory; Attention mechanism; Empirical mode decomposition	EMPIRICAL MODE DECOMPOSITION; INVESTOR SENTIMENT; NEURAL-NETWORK; SPECTRUM	Stock market prediction has been identified as a very important practical problem in the economic field. However, the timely prediction of the market is generally regarded as one of the most challenging problems due to the stock market's characteristics of noise and volatility. To address these challenges, we propose a deep learning-based stock market prediction model that considers investors' emotional tendency. First, we propose to involve investors' sentiment for stock prediction, which can effectively improve the model prediction accuracy. Second, the stock pricing sequence is a complex time sequence with different scales of fluctuations, making the accurate prediction very challenging. We propose to gradually decompose the complex sequence of stock price by adopting empirical modal decomposition (EMD), which yields better prediction accuracy. Third, we adopt LSTM due to its advantages of analyzing relationships among time-series data through its memory function. We further revised it by adopting attention mechanism to focus more on the more critical information. Experiment results show that the revised LSTM model can not only improve prediction accuracy, but also reduce time delay. It is confirmed that investors' emotional tendency is effective to improve the predicted results; the introduction of EMD can improve the predictability of inventory sequences; and the attention mechanism can help LSTM to efficiently extract specific information and current mission objectives from the information ocean.																	0941-0643	1433-3058				JUL	2020	32	13					9713	9729		10.1007/s00521-019-04504-2													
J								Machine learning-based auto-scaling for containerized applications	NEURAL COMPUTING & APPLICATIONS										Containerization; Auto-scaling; Proactive controller; Prediction; Neural network; Long short-term memory	WEB APPLICATIONS; CLOUD; MICROSERVICES	Containers are shaping the new era of cloud applications due to their key benefits such as lightweight, very quick to launch, consuming minimum resources to run an application which reduces cost, and can be easily and rapidly scaled up/down as per workload requirements. However, container-based cloud applications require sophisticated auto-scaling methods that automatically and in a timely manner provision and de-provision cloud resources without human intervention in response to dynamic fluctuations in workload. To address this challenge, in this paper, we propose a proactive machine learning-based approach to perform auto-scaling of Docker containers in response to dynamic workload changes at runtime. The proposed auto-scaler architecture follows the commonly abstracted four steps: monitor, analyze, plan, and execute the control loop. The monitor component continuously collects different types of data (HTTP request statistics, CPU, and memory utilization) that are needed during the analysis and planning phase to determine proper scaling actions. We employ in analysis phase a concise yet fast, adaptive, and accurate prediction model based on long short-term memory (LSTM) neural network to predict future HTTP workload to determine the number of containers needed to handle requests ahead of time to eliminate delays caused by starting or stopping running containers. Moreover, in the planning phase, the proposed gradually decreasing strategy avoids oscillations which happens when scaling operations are too frequent. Experimental results using realistic workload show that the prediction accuracy of LSTM model is as accurate as auto-regression integrated moving average model but offers 600 times prediction speedup. Moreover, as compared with artificial neural network model, LSTM model performs better in terms of auto-scaler metrics related to provisioning and elastic speedup. In addition, it was observed that when LSTM model is used, the predicted workload helped in using the minimum number of replicas to handle future workload. In the experiments, the use of GDS showed promising results in keeping the desired performance at reduced cost to handle cases with sudden workload increase/decrease.																	0941-0643	1433-3058				JUL	2020	32	13					9745	9760		10.1007/s00521-019-04507-z													
J								High-parameter-efficiency convolutional neural networks	NEURAL COMPUTING & APPLICATIONS										Mobile CNNs; Multiple group reused convolutions; Decomposed point-wise convolutions; High-parameter-efficiency convolutions		Currently, in order to deploy the convolutional neural networks (CNNs) on the mobile devices and address the over-fitting problem caused by the less abundant datasets, reducing the redundancy of parameters is the main target to construct the mobile CNNs. Based on this target, this paper proposes two novel convolutional kernels, multiple group reused convolutions (MGRCs) and decomposed point-wise convolutions (DPCs), to improve the efficiency of parameters by removing the parameter's redundancy. The summation of MGRC and DPC is called high-parameter-efficiency convolutions (HPEC) in this paper, and the relevant CNNs can be called HPE-CNNs. Experimental results showed that, compared with the traditional convolutional kernels, HPEC can greatly decrease the model size without affecting the performance. Additionally, since the HPE-CNNs reduce the redundancy of parameters more thoroughly than the other mobile CNNs, they can address the over-fitting problem more effectively on the challenging datasets with less abundant training information.																	0941-0643	1433-3058				JUL	2020	32	14					10633	10644		10.1007/s00521-019-04596-w													
J								Swarm intelligence based approach for efficient training of regressive neural networks	NEURAL COMPUTING & APPLICATIONS										Neural networks; Optimization; CFSO; Dynamic systems	OPTIMIZATION ALGORITHMS	This work proposes an efficient approach to solve the problem of training a regressive neural network efficiently. Regressive networks are characterized by delay lines possibly in both the input and the output feedback. Each delay line is connected to the network with synaptic weights and thus increases the number of parameters that must be optimized by the training algorithm. Training algorithms such as the Levenberg-Marquardt, normally used to train neural networks, are prone to local minima entrapment, and for this reason, a strategy to initialize the training procedure correctly is needed. To solve this problem, the continuous flock of starling optimization algorithm, a highly explorative optimizer based on swarm intelligence, is used. The proposed approach is tested and validated on an experimental benchmark featuring a second-order nonlinear dynamic system.																	0941-0643	1433-3058				JUL	2020	32	14					10693	10704		10.1007/s00521-019-04606-x													
J								Scheduling of combined heat and generation outputs in power systems using a new hybrid multi-objective optimization algorithm	NEURAL COMPUTING & APPLICATIONS										Emission and economic dispatch; Combined heat and power unit; Multi-objective optimization; Weighted vertices optimizer; Hybrid optimization algorithm	PARTICLE SWARM OPTIMIZATION; ECONOMIC EMISSION DISPATCH; GRAVITATIONAL SEARCH ALGORITHM; LEARNING BASED OPTIMIZATION; IMPROVED GENETIC ALGORITHM; HURRICANE; UNITS	In this paper, a hybrid optimization algorithm, consisted of weighted vertices-based optimizer (WVO) and particle swarm optimization (PSO) algorithm, is proposed to solve three economic frameworks for scheduling of power sources in order to meet the required power demand in power systems. These frameworks are economic power dispatch, economic emission power dispatch and combined heat and economic power dispatch problems. The basic idea of weighted vertices optimizer (WVO) is given from the bisection root-finding method in mathematics. It uses swarm intelligence and evolutionary strategy to efficiently find the optimum solution. However, the original WVO algorithm has some flaws in complex problems with a high number of variables and constraints. Therefore, this paper presents hybrid WVO-PSO algorithm which solved the mentioned flaws and also improved its speed and accuracy. In this algorithm, varying speed is defined for each vertex by using PSO which helps better exploration through the search space. To evaluate the performance of WVO-PSO, it is applied to some of well-known and complex emission/economic dispatch (EED), combined heat and power economic dispatch (CHPED) and combined heat and power emission/economic dispatch (CHPEED) problems and then the driven results are compared with other recent methods which demonstrates better performance of the proposed method in solving non-convex and constrained EED, CHPED and CHPEED problem in terms of minimizing costs and emissions.																	0941-0643	1433-3058				JUL	2020	32	14					10741	10757		10.1007/s00521-019-04610-1													
J								A modified Henry gas solubility optimization for solving motif discovery problem	NEURAL COMPUTING & APPLICATIONS										Henry gas solubility optimization (HGSO); Motif discovery (MD); Bioinformatics; DNA; Metaheuristics algorithms	FACTOR-BINDING SITES; ALGORITHMS; GENES	The DNA motif discovery (MD) problem is the main challenge of genome biology, and its importance is directly proportional to increasing sequencing technologies. MD plays a vital role in the identification of transcription factor binding sites that help in learning the mechanisms for regulation of gene expression. Metaheuristic algorithms are promising techniques for eliciting motif from DNA genomic sequences, but often fail to demonstrate robust performance by overcoming the inherent challenges in complex gene sequences, making search environment extremely non-convex for optimization methods. This paper proposes a novel modified Henry gas solubility optimization (MHGSO) algorithm for motif discovery which elicits a functional motif in DNA genomic sequences. In our approach, a new stage that captures the main characteristics of the motifs in DNA sequences is proposed, and MHGSO imitates the motifs characteristics for accurate detection of target motif. The performance of the MHGSO algorithm is validated using both synthetic and real datasets. Results confirm the stability and superiority of the proposed algorithm compared to state-of-the-art algorithms including MEME, DREME, XXmotif, PMbPSO, and MACS. Based on several evaluation matrices, MHGSO outperforms the competitor techniques in terms of nucleotide-level correlation coefficient, recall, precision,F-score, Cohen's Kappa, and statistical validation measures.																	0941-0643	1433-3058				JUL	2020	32	14					10759	10771		10.1007/s00521-019-04611-0													
J								Intelligent bearing fault diagnosis using PCA-DBN framework	NEURAL COMPUTING & APPLICATIONS										PCA-DBN; Rolling element bearing; Intelligent fault diagnosis	TRANSFORM	This paper studies the fault diagnosis problem for rolling element bearings. By casting the bearing fault diagnosis as a class of pattern classification problem, we propose a novel intelligent fault diagnosis approach based on principal component analysis (PCA) and deep belief network (DBN). The dimension of raw bearing vibration signals is reduced by adopting PCA method, which consequently extracts the fault signatures in terms of primary eigenvalues and eigenvectors. The modified samples are subsequently trained and tested by the DBN for fault classification and diagnosis. The distinctive feature of our approach is that it requires no complex signal processing on raw vibration data, rendering it easily achievable and widely applicable. The experimental results indicate the effectiveness of the proposed PCA-DBN fault diagnosis scheme compared with other methods.																	0941-0643	1433-3058				JUL	2020	32	14					10773	10781		10.1007/s00521-019-04612-z													
J								Gestalt descriptions for deep image understanding	PATTERN ANALYSIS AND APPLICATIONS										Image analysis; Deep learning-based methods; Gestalt descriptors; Image classification; Face recognition; Person identification	OPTIMIZATION	In this work, we present a novel visual perception-inspired local description approach as a preprocessing step for deep learning. With the ongoing growth of visual data, efficient image descriptor methods are becoming more and more important. Several local point-based description methods were defined in the past decades before the highly accurate and popular deep learning methods such as convolutional neural networks (CNNs) emerged. The method presented in this work combines a novel local description approach inspired by the Gestalt laws with deep learning, and thereby, it benefits from both worlds. To test our method, we conducted several experiments on different datasets of various forensic application domains, e.g., makeup-robust face recognition. Our results show that the proposed approach is robust against overfitting and only little image information is necessary to classify the image content with high accuracy. Furthermore, we compared our experimental results to state-of-the-art description methods and found that our method is highly competitive. For example it outperforms a conventional CNN in terms of accuracy in the domain of makeup-robust face recognition.																	1433-7541	1433-755X															10.1007/s10044-020-00904-6		JUL 2020											
J								Spatio-temporal adversarial learning for detecting unseen falls	PATTERN ANALYSIS AND APPLICATIONS										Fall; Spatio-temporal; Adversarial learning; Autoencoder; Thermal camera; Depth camera	ANOMALY DETECTION; LOCALIZATION	Fall detection is an important problem from both the health and machine learning perspective. A fall can lead to severe injuries, long-term impairments or even death in some cases. In terms of machine learning, it presents a severely class imbalance problem with very few or no training data for falls owing to the fact that falls occur rarely. In this paper, we take an alternate philosophy to detect falls in the absence of their training data, by training the classifier on only the normal activities (that are available in abundance) and identifying a fall as an anomaly. To realize such a classifier, we use an adversarial learning framework, which comprises of a spatio-temporal autoencoder for reconstructing input video frames and a spatio-temporal convolution network to discriminate them against original video frames. 3D convolutions are used to learn spatial and temporal features from the input video frames. The adversarial learning of the spatio-temporal autoencoder will enable reconstructing the normal activities of daily living efficiently, thus rendering detecting unseen falls plausible within this framework. We tested the performance of the proposed framework on camera-sensing modalities that may preserve an individual's privacy (fully or partially), such as thermal and depth camera. Our results on three publicly available datasets show that the proposed spatio-temporal adversarial framework performed better than other baseline frame-based (or spatial) adversarial learning methods.																	1433-7541	1433-755X															10.1007/s10044-020-00901-9		JUL 2020											
J								Behavioral Activity Recognition Based on Gaze Ethograms	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Neuroethology; activity recognition; gaze tracking; gaze ethograrn; screen-based eye tracker; noninvasive eye tracker	EYE; DIRECTION; SCIENCE	Noninvasive behavior observation techniques allow more natural human behavior assessment experiments with higher ecological validity. We propose the use of gaze ethograms in the context of user interaction with a computer display to characterize the user's behavioral activity. A gaze ethogram is a time sequence of the screen regions the user is looking at. It can be used for the behavioral modeling of the user. Given a rough partition of the display space, we are able to extract gaze ethograms that allow discrimination of three common user behavioral activities: reading a text, viewing a video clip, and writing a text. A gaze tracking system is used to build the gaze ethogram. User behavioral activity is modeled by a classifier of gaze ethograms able to recognize the user activity after training. Conventional commercial gaze tracking for research in the neurosciences and psychology science are expensive and intrusive, sometimes impose wearing uncomfortable appliances. For the purposes of our behavioral research, we have developed an open source gaze tracking system that runs on conventional laptop computers using their low quality cameras. Some of the gaze tracking pipeline elements have been borrowed from the open source community. However, we have developed innovative solutions to some of the key issues that arise in the gaze tracker. Specifically, we have proposed texture-based eye features that are quite robust to low quality images. These features are the input for a classifier predicting the screen target area, the user is looking at. We report comparative results of several classifier architectures carried out in order to select the classifier to be used to extract the gaze ethograms for our behavioral research. We perform another classifier selection at the level of ethogram classification. Finally, we report encouraging results of user behavioral activity recognition experiments carried out over an inhouse dataset.																	0129-0657	1793-6462				JUL	2020	30	7							2050025	10.1142/S0129065720500252													
J								A Prototype of EEG System for IoT	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Electroencephalography; Internet of Things; prototype; signal processing	BRAIN-COMPUTER INTERFACES; COMMUNICATION; ROBOT	In this work, we develop open source hardware and software for eye state classification and integrate it with a protocol for the Internet of Things (IoT). We design and build the hardware using a reduced number of components and with a very low-cost. Moreover, we propose a method for the detection of open eyes (oE) and closed eyes (cE) states based on computing a power ratio between different frequency bands of the acquired signal. We compare several real- and complex-valued transformations combined with two decision strategies: a threshold-based method and a linear discriminant analysis. Simulation results show both classifier accuracies and their corresponding system delays.																	0129-0657	1793-6462				JUL	2020	30	7							2050018	10.1142/S0129065720500185													
J								Ensemble Deep Learning on Large, Mixed-Site fMRI Datasets in Autism and Other Tasks	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Autism; big data; functional connectivity; deep learning	FUNCTIONAL CONNECTIVITY; SPECTRUM DISORDER; DEFAULT MODE; REPETITIVE BEHAVIORS; BRAIN ANATOMY; POWER FAILURE; DIAGNOSIS; NETWORK; INDIVIDUALS; SYNCHRONIZATION	Deep learning models for MRI classification face two recurring problems: they are typically limited by low sample size, and are abstracted by their own complexity (the "black box problem"). In this paper, we train a convolutional neural network (CNN) with the largest multi-source, functional MRI (fMRI) connectomic dataset ever compiled, consisting of 43,858 datapoints. We apply this model to a cross-sectional comparison of autism spectrum disorder (ASD) versus typically developing (TD) controls that has proved difficult to characterize with inferential statistics. To contextualize these findings, we additionally perform classifications of gender and task versus rest. Employing class-balancing to build a training set, we trained 3 x 300 modified CNNs in an ensemble model to classify fMRI connectivity matrices with overall AUROCs of 0.6774, 0.7680, and 0.9222 for ASD versus TD, gender, and task versus rest, respectively. Additionally, we aim to address the black box problem in this context using two visualization methods. First, class activation maps show which functional connections of the brain our models focus on when performing classification. Second, by analyzing maximal activations of the hidden layers, we were also able to explore how the model organizes a large and mixed-center dataset, finding that it dedicates specific areas of its hidden layers to processing different covariates of data (depending on the independent variable analyzed), and other areas to mix data from different sources. Our study finds that deep learning models that distinguish ASD from TD controls focus broadly on temporal and cerebellar connections, with a particularly high focus on the right caudate nucleus and paracentral sulcus.																	0129-0657	1793-6462				JUL	2020	30	7							2050012	10.1142/S0129065720500124													
J								Multivariate Pattern Analysis Techniques for Electroencephalography Data to Study Flanker Interference Effects	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Multivariate pattern analysis; electroencephalography; classification; support vector machine; demand-selection task	COMPUTER-AIDED DIAGNOSIS; FALSE DISCOVERY RATE; DECISION-MAKING; CLASSIFICATION; DYNAMICS; FMRI; INFORMATION; REPRESENTATIONS; REINSTATEMENT; ACTIVATION	A central challenge in cognitive neuroscience is to understand the neural mechanisms that underlie the capacity to control our behavior according to internal goals. Flanker tasks, which require responding to stimuli surrounded by distracters that trigger incompatible action tendencies, are frequently used to measure this conflict. Even though the interference generated in these situations has been broadly studied, multivariate analysis techniques can shed new light into the underlying neural mechanisms. The current study is an initial approximation to adapt an interference Flanker paradigm embedded in a Demand-Selection Task (DST) to a format that allows measuring concurrent high-density electroencephalography (EEG). We used multivariate pattern analysis (MVPA) to decode conflict-related electrophysiological markers associated with congruent or incongruent target events in a time-frequency resolved way. Our results replicate findings obtained with other analysis approaches and offer new information regarding the dynamics of the underlying mechanisms, which show signs of reinstantiation. Our findings, some of which could not have been obtained with classic analytical strategies, open novel avenues of research.																	0129-0657	1793-6462				JUL	2020	30	7							2050024	10.1142/S0129065720500240													
J								EEG Connectivity Analysis Using Denoising Autoencoders for the Detection of Dyslexia	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Periodogram; EEG; connectivity; autoencoder; dyslexia	FUNCTIONAL CONNECTIVITY; BRAIN CONNECTIVITY; SYNCHRONIZATION; GRAPH; COMPLEXITY; DYNAMICS; CHILDREN; NETWORK	The Temporal Sampling Framework (TSF) theorizes that the characteristic phonological difficulties of dyslexia are caused by an atypical oscillatory sampling at one or more temporal rates. The LEEDUCA study conducted a series of Electroencephalography (EEG) experiments on children listening to amplitude modulated (AM) noise with slow-rythmic prosodic (0.5-1 Hz), syllabic (4-8 Hz) or the phoneme (12-40 Hz) rates, aimed at detecting differences in perception of oscillatory sampling that could be associated with dyslexia. The purpose of this work is to check whether these differences exist and how they are related to children's performance in different language and cognitive tasks commonly used to detect dyslexia. To this purpose, temporal and spectral inter-channel EEG connectivity was estimated, and a denoising autoencoder (DAE) was trained to learn a low-dimensional representation of the connectivity matrices. This representation was studied via correlation and classification analysis, which revealed ability in detecting dyslexic subjects with an accuracy higher than 0.8, and balanced accuracy around 0.7. Some features of the DAE representation were significantly correlated (p < 0.005) with children's performance in language and cognitive tasks of the phonological hypothesis category such as phonological awareness and rapid symbolic naming, as well as reading efficiency and reading comprehension. Finally, a deeper analysis of the adjacency matrix revealed a reduced bilateral connection between electrodes of the temporal lobe (roughly the primary auditory cortex) in DD subjects, as well as an increased connectivity of the F7 electrode, placed roughly on Broca's area. These results pave the way for a complementary assessment of dyslexia using more objective methodologies such as EEG.																	0129-0657	1793-6462				JUL	2020	30	7							2050037	10.1142/S0129065720500379													
J								Dyslexia Diagnosis by EEG Temporal and Spectral Descriptors: An Anomaly Detection Approach	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										EEG; dyslexia; deep learning; autoencoder; anomaly detection; automatic diagnosis	FUNCTIONAL CONNECTIVITY; DEVELOPMENTAL DYSLEXIA; SPEECH ENVELOPE; CHILDREN; BRAIN; GRAPH; SYNCHRONIZATION; COMPLEXITY; CLASSIFICATION; MODULATIONS	Diagnosis of learning difficulties is a challenging goal. There are huge number of factors involved in the evaluation procedure that present high variance among the population with the same difficulty. Diagnosis is usually performed by scoring subjects according to results obtained in different neuropsychological (performance-based) tests specifically designed to this end. One of the most frequent disorders is developmental dyslexia (DD), a specific difficulty in the acquisition of reading skills not related to mental age or inadequate schooling. Its prevalence is estimated between 5% and 12% of the population. Traditional tests for DD diagnosis aim to measure different behavioral variables involved in the reading process. In this paper, we propose a diagnostic method not based on behavioral variables but on involuntary neurophysiological responses to different auditory stimuli. The experiments performed use electroencephalography (EEG) signals to analyze the temporal behavior and the spectral content of the signal acquired from each electrode to extract relevant (temporal and spectral) features. Moreover, the relationship of the features extracted among electrodes allows to infer a connectivity-like model showing brain areas that process auditory stimuli in a synchronized way. Then an anomaly detection system based on the reconstruction residuals of an autoencoder using these features has been proposed. Hence, classification is performed by the proposed system based on the differences in the resulting connectivity models that have demonstrated to be a useful tool for differential diagnosis of DD as well as a method to step towards gaining a better knowledge of the brain processes involved in DD. The results corroborate that nonspeech stimulus modulated at specific frequencies related to the sampling processes developed in the brain to capture rhymes, syllables and phonemes produces effects in specific frequency bands that differentiate between controls and DD subjects. The proposed method showed relatively high sensitivity above 0.6, and up to 0.9 in some of the experiments.																	0129-0657	1793-6462				JUL	2020	30	7							2050029	10.1142/S012906572050029X													
J								Deep Support Vector Machines for the Identification of Stress Condition from Electrodermal Activity	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Electrodermal activity; support vector machines; deep support vector machines; calm; stress	EMOTION RECOGNITION; CLASSIFICATION	Early detection of stress condition is beneficial to prevent long-term mental illness like depression and anxiety. This paper introduces an accurate identification of stress/calm condition from electrodermal activity (EDA) signals. The acquisition of EDA signals from a commercial wearable as well as their storage and processing are presented. Several time-domain, frequency-domain and morphological features are extracted over the skin conductance response of the EDA signals. Afterwards, a classification is undergone by using several classical support vector machines (SVMs) and deep support vector machines (D-SVMs). In addition, several binary classifiers are also compared with SVMs in the stress/calm identification task. Moreover, a series of video clips evoking calm and stress conditions have been viewed by 147 volunteers in order to validate the classification results. The highest F1-score obtained for SVMs and D-SVMs are 83% and 92%, respectively. These results demonstrate that not only classical SVMs are appropriate for classification of biomarker signals, but D-SVMs are very competitive in comparison to other classification techniques. In addition, the results have enabled drawing useful considerations for the future use of SVMs and D-SVMs in the specific case of stress/calm identification.																	0129-0657	1793-6462				JUL	2020	30	7							2050031	10.1142/S0129065720500318													
J								Affinity Regularized Non-Negative Matrix Factorization for Lifelong Topic Modeling	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Data models; Semantics; Task analysis; Graphics processing units; Big Data; Convergence; Maintenance engineering; Lifelong topic model (LTM); non-negative matrix factorization (NMF); semantic affinity; knowledge graph		Lifelong topic model (LTM), an emerging paradigm for never-ending topic learning, aims to yield higher-quality topics as time passes through knowledge accumulated from the past yet learned for the future. In this paper, we propose a novel lifelong topic model based on non-negative matrix factorization (NMF), called Affinity Regularized NMF for LTM (NMF-LTM), which to our best knowledge is distinctive from the popular LDA-based LTMs. NMF-LTM achieves lifelong learning by introducing word-word graph Laplacian as semantic affinity regularization. Other priors such as sparsity, diversity, and between-class affinity are incorporated as well for better performance, and a theoretical guarantee is provided for the algorithmic convergence to a local minimum. Extensive experiments on various public corpora demonstrate the effectiveness of NMF-LTM, particularly its human-like behaviors in two carefully designed learning tasks and the ability in topic modeling of big data. A further exploration of semantic relatedness in knowledge graphs and a case study on a large-scale real-world corpus exhibit the strength of NMF-LTM in discovering high-quality topics in an efficient and robust way.																	1041-4347	1558-2191				JUL 1	2020	32	7					1249	1262		10.1109/TKDE.2019.2904687													
J								Blocking Self-Avoiding Walks Stops Cyber-Epidemics: A Scalable GPU-Based Approach	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Spread interdiction; self-avoiding walks; GPUs	ALGORITHMS; SCALE	Cyber-epidemics, the widespread of fake news or propaganda through social media, can cause devastating economic and political consequences. A common countermeasure against cyber-epidemics is to disable a small subset of suspected social connections or accounts to effectively contain the epidemics. An example is the recent shutdown of 125,000 ISIS-related Twitter accounts. Despite many proposed methods to identify such a subset, none are scalable enough to provide high-quality solutions in nowadays' billion-size networks. To this end, we investigate the Spread Interdiction problems that seek the most effective links (or nodes) for removal under the well-known Linear Threshold model. We propose novel CPU-GPU methods that scale to networks with billions of edges, yet possess rigorous theoretical guarantee on the solution quality. At the core of our methods is an O(1)-space out-of-core algorithm to generate a new type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a low memory requirement enables handling of big networks and, more importantly, hiding latency via scheduling of millions of threads on GPUs. Comprehensive experiments on real-world networks show that our algorithms provide much higher quality solutions and are several orders of magnitude faster than the state-of-the art. Comparing to the (single-core) CPU counterpart, our GPU implementations achieve significant speedup factors up to 177x on a single GPU and 338x on a GPU pair.																	1041-4347	1558-2191				JUL 1	2020	32	7					1263	1275		10.1109/TKDE.2019.2904969													
J								Complication Risk Profiling in Diabetes Care: A Bayesian Multi-Task and Feature Relationship Learning Approach	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Diabetes; Task analysis; Diseases; Medical diagnostic imaging; Predictive models; Analytical models; Healthcare analytics; diabetes; risk prediction; multi-task learning; correlated shrinkage	CLAIMS DATA; ACID-BASE; PREDICTION; ELECTROLYTE; MELLITUS; TIME	Diabetes mellitus, commonly known as diabetes, is a chronic disease that often results in multiple complications. Risk prediction of diabetes complications is critical for healthcare professionals to design personalized treatment plans for patients in diabetes care for improved outcomes. In this paper, focusing on Type 2 diabetes mellitus (T2DM), we study the risk of developing complications after the initial T2DM diagnosis from longitudinal patient records. We propose a novel multi-task learning approach to simultaneously model multiple complications where each task corresponds to the risk modeling of one complication. Specifically, the proposed method strategically captures the relationships (1) between the risks of multiple T2DM complications, (2) between different risk factors, and (3) between the risk factor selection patterns, which assumes similar complications have similar contributing risk factors. The method uses coefficient shrinkage to identify an informative subset of risk factors from high-dimensional data, and uses a hierarchical Bayesian framework to allow domain knowledge to be incorporated as priors. The proposed method is favorable for healthcare applications because in addition to improved prediction performance, relationships among the different risks and among risk factors are also identified. Extensive experimental results on a large electronic medical claims database show that the proposed method outperforms state-of-the-art models by a significant margin. Furthermore, we show that the risk associations learned and the risk factors identified lead to meaningful clinical insights.																	1041-4347	1558-2191				JUL 1	2020	32	7					1276	1289		10.1109/TKDE.2019.2904060													
J								CVTM: A Content-Venue-Aware Topic Model for Group Event Recommendation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Correlation; Games; Context modeling; Social networking (online); Probabilistic logic; Recommender systems; Task analysis; Group recommendation; probabilistic generative model; event recommendation; event-based social networks	SYSTEMS	Event recommendation is essential to help people find attractive events to attend, but it intrinsically faces cold-start problem. The previous studies exploit multiple contextual factors to overcome the cold-start problem in event recommendation. However, they do not consider the correlation among different contextual factors. Moreover, suggesting events for a group of users also has not been well studied. In this paper, we first discover the correlation between organizer and textual content, i.e., the events held by the same organizer tend to have more similar content. Based on this observation, we present a content-venue-aware topic model (CVTM) to capture group interests on an event from two perspectives: content and venue. The correlation between organizer and content is modeled in CVTM to alleviate the sparsity of textual content, and then we can further extract group interests on content of an event more accurately. Finally, a group event recommendation method using CVTM is proposed. We conduct comprehensive experiments to evaluate the recommendation performance of our model on two real-world datasets. The results demonstrate that the proposed model outperforms the state-of-the-art methods that suggest upcoming events for groups. Besides, CVTM can learn semantically coherent latent topics which are useful to explain recommendations.																	1041-4347	1558-2191				JUL 1	2020	32	7					1290	1303		10.1109/TKDE.2019.2904066													
J								Discovery and Recognition of Emerging Human Activities Using a Hierarchical Mixture of Directional Statistical Models	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Data models; Activity recognition; Training; Training data; Kernel; Mixture models; Smart homes; Activity recognition; online learning; incremental learning; active learning; semi-supervised learning; mixture model; von Mises-Fisher distribution; hierarchical mixture; hierarchical clustering; pervasive computing; smart home		Human activity recognition plays a significant role in enabling pervasive applications as it abstracts low-level noisy sensor data into high-level human activities, which applications can respond to. With more and more activity-aware applications deployed in real-world environments, a research challenge emerges-discovering and learning new activities that have not been pre-defined or observed in the training phase. This paper tackles this challenge by proposing a hierarchical mixture of directional statistical models. The model supports incrementally, continuously updating the activity model over time with the reduced annotation effort and without the need for storing historical sensor data. We have validated this solution on four publicly available, third-party smart home datasets, and have demonstrated up to 91.5 percent accuracies of detecting and recognising new activities.																	1041-4347	1558-2191				JUL 1	2020	32	7					1304	1316		10.1109/TKDE.2019.2905207													
J								Efficient Contour Computation of Group-Based Skyline	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Group-based skyline; multiple skyline layers; representative skyline; concurrent search; subspace skyline; combination queue; group-based clustering	REPRESENTATIVE SKYLINE; QUERIES	Skyline, aiming at finding a Pareto optimal subset of points in a multi-dimensional dataset, has gained great interest due to its extensive use for multi-criteria analysis and decision making. The skyline consists of all points that are not dominated by any other points. It is a candidate set of the optimal solution, which depends on a specific evaluation criterion for optimum. However, conventional skyline queries, which return individual points, are inadequate in group querying case since optimal combinations are required. To address this gap, we study the skyline computation in the group level and propose efficient methods to find the Group-based skyline (G-skyline). For computing the front $l$l skyline layers, we lay out an efficient approach that does the search concurrently on each dimension and investigates each point in the subspace. After that, we present a novel structure to construct the G-skyline with a queue of combinations of the first-layer points. We further demonstrate that the G-skyline is a complete candidate set of top-l solutions, which is the main superiority over previous group-based skyline definitions. However, as G-skyline is complete, it contains a large number of groups which can make it impractical. To represent the "contour" of the G-skyline, we define the Representative G-skyline (RG-skyline). Then, we propose a Group-based clustering (G-clustering) algorithm to find out RG-skyline groups. Experimental results show that our algorithms are several orders of magnitude faster than the previous work.																	1041-4347	1558-2191				JUL 1	2020	32	7					1317	1332		10.1109/TKDE.2019.2905239													
J								Evaluation of the Sample Clustering Process on Graphs	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Measurement; Clustering algorithms; Task analysis; Memory management; Social networking (online); Knowledge engineering; Indexes; Graph clustering; graph sampling; multiple ground-truths; evaluation framework; quality metrics	ORGANIZATION; COMMUNITIES; ALGORITHMS	An increasing number of networks are becoming large-scale and continuously growing in nature, such that clustering on them in their entirety could be intractable. A feasible way to overcome this problem is to sample a representative subgraph and exploit its clustering structure (namely, sample clustering process). However, there are two issues that we should address in current studies. One underlying question is how to evaluate the clustering quality of the entire sample clustering process. Another non-trivial issue is that multiple ground-truths exist in networks, thus evaluating the clustering results in such scenario is also a challenging task. In this paper, first we utilize the set-matching methodology to quantitatively evaluate how differently the clusters of the sampled counterpart correspond to the ground-truth(s) in the original graph, and propose several new quality metrics to capture the differences of clustering structure in various aspects. Second, we put forward an evaluation framework for the general problems of evaluating the clustering quality on graph samples. Extensive experiments on various synthetic and real-world graphs demonstrate that our new quality metrics are more accurate and insightful for the sample clustering evaluation than conventional metrics (e.g., NMI). Thus the evaluation framework is effective and practical to assess the clustering quality of the sample clustering process on massive graphs.																	1041-4347	1558-2191				JUL 1	2020	32	7					1333	1347		10.1109/TKDE.2019.2904682													
J								Graph K-means Based on Leader Identification, Dynamic Game, and Opinion Dynamics	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Social networking (online); Indexes; Games; Optimization; Computational modeling; Economics; Cultural differences; Social media networks; multi-objective optimization; leader identification; dynamic game; opinion dynamics	COMMUNITY DETECTION; SOCIAL-INFLUENCE; NETWORKS; SYSTEM; MODEL	With the explosion of social media networks, many modern applications are concerning about people's connections, which leads to the so-called social computing. An elusive question is to study how opinion communities form and evolve in real-world networks with great individual diversity and complex human connections. In this scenario, the classic K-means technique and its extended versions could not be directly applied, as they largely ignore the relationship among interactive objects. On the other side, traditional community detection approaches in statistical physics would be neither adequate nor fair: they only consider the network topological structure but ignore the heterogeneous-objects' attributive information. To this end, we attempt to model a realistic social media network as a discrete-time dynamical system, where the opinion matrix and the community structure could mutually affect each other. In this paper, community detection in social media networks is naturally formulated as a multi-objective optimization problem (MOOP), i.e., finding a set of densely connected components with similar opinion vectors. We propose a novel and powerful graph K-means framework, which is composed of three coupled phases in each discrete-time period. Specifically, the first phase uses a fast heuristic approach to identify those opinion leaders who have relatively high local reputation; the second phase adopts a novel dynamic game model to find the locally Pareto-optimal community structure; and the final phase employs a robust opinion dynamics model to simulate the evolution of the opinion matrix. We conduct a series of comprehensive experiments on real-world benchmark networks to validate the performance of GK-means through comparisons with the state-of-the-art graph clustering technologies.																	1041-4347	1558-2191				JUL 1	2020	32	7					1348	1361		10.1109/TKDE.2019.2903712													
J								Haery: A Hadoop Based Query System on Accumulative and High-Dimensional Data Model for Big Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Data models; Big Data; Partitioning algorithms; NoSQL databases; Indexing; Key-value data; column-oriented store; multi-dimensional data model; linearization; accumulation		Column-oriented stores, known for their scalability and flexibility, are a common NoSQL database implementation and are increasingly used in big data management. In column-oriented stores, a "full-scan" query strategy is inefficient and the search space can be reduced if data is well partitioned or indexed; however, there is no pre-defined schema for building and maintaining partitions and indexes at lower cost. We leverage an accumulative and high-dimensional data model, a sophisticated linearization algorithm, and an efficient query algorithm, to solve the challenge of how a pre-defined and well-partitioned data model can be applied to flexible and time-varied key-value data. We adapt a high-dimensional array as the data model to partition the key-value data without additional storage and massive calculation; improve the Z-order linearization algorithm, which map multidimensional data to one dimension while preserving locality of the data points, for flexibility; efficiently build an expansion mechanism for the data model to support time-varied data. The result is Haery, a column-oriented store, based on a distributed file system and computing framework. In experiments, Haery is compared with Hive, HBase, Cassandra, MongoDB, PostgresXL, and HyperDex in terms of query performance. With results indicating Haery on average performs 4.57x, 4.23x, 3.55x, 1.79x, 1.82x, and 120.6x faster, respectively.																	1041-4347	1558-2191				JUL 1	2020	32	7					1362	1377		10.1109/TKDE.2019.2904056													
J								Inferring Full Diffusion History from Partial Timestamps	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										History; Diffusion processes; Monitoring; Heuristic algorithms; Computational modeling; Privacy; Reconstruction algorithms; Graph mining; diffusion	NETWORK; MODEL	Understanding diffusion processes in networks has emerged as an important research topic because of its wide range of applications. Analysis of diffusion traces can help us answer important questions such as the source(s) of diffusion and the role of each node during the diffusion process. However, in large-scale networks, due to the cost and privacy concerns, it is almost impossible to monitor the entire network and collect the complete diffusion trace. In this paper, we tackle the problem of reconstructing the diffusion history from a partial observation. We formulate the diffusion history reconstruction problem as a maximum a posteriori (MAP) problem and prove the problem is NP-hard. Then, we propose a step-by-step reconstruction algorithm, which can always produce a diffusion history that is consistent with the partial observation. Our experimental results based on synthetic and real networks show that the algorithm significantly outperforms some existing methods.																	1041-4347	1558-2191				JUL 1	2020	32	7					1378	1392		10.1109/TKDE.2019.2905210													
J								Learning Distilled Graph for Large-Scale Social Network Data Clustering	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Social networking (online); Feature extraction; Spectral analysis; Clustering algorithms; Noise measurement; Sparse matrices; Laplace equations; Feature evaluation and selection; clustering; spectral analysis; social network	FEATURE-SELECTION; PREDICTION; FRAMEWORK; ALGORITHM	Spectral analysis is critical in social network analysis. As a vital step of the spectral analysis, the graph construction in many existing works utilizes content data only. Unfortunately, the content data often consists of noisy, sparse, and redundant features, which makes the resulting graph unstable and unreliable. In practice, besides the content data, social network data also contain link information, which provides additional information for graph construction. Some of previous works utilize the link data. However, the link data is often incomplete, which makes the resulting graph incomplete. To address these issues, we propose a novel Distilled Graph Clustering (DGC) method. It pursuits a distilled graph based on both the content data and the link data. The proposed algorithm alternates between two steps: in the feature selection step, it finds the most representative feature subset w.r.t. an intermediate graph initialized with link data; in graph distillation step, the proposed method updates and refines the graph based on only the selected features. The final resulting graph, which is referred to as the distilled graph, is then utilized for spectral clustering on the large-scale social network data. Extensive experiments demonstrate the superiority of the proposed method.																	1041-4347	1558-2191				JUL 1	2020	32	7					1393	1404		10.1109/TKDE.2019.2904068													
J								Modeling and Computing Probabilistic Skyline on Incomplete Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Probabilistic logic; Computational modeling; Data models; Partitioning algorithms; Indexes; Motion pictures; Sorting; Probabilistic skyline; incomplete data; query processing	QUERIES; IMPUTATION	The skyline query is important in the database community. In recent years, the researches on incomplete data have been increasingly considered, especially for the skyline query. However, the existing skyline definition on incomplete data cannot provide users with valuable references. In this paper, we propose a novel skyline definition utilizing probabilistic model on incomplete data where each point has a probability to be in the skyline. In particular, it returns K points with the highest skyline probabilities. In addition, we propose incomplete models and estimate probability density functions of missing values on independent, correlated, and anti-correlated distributions, respectively. Meanwhile, it is a big challenge to compute probabilistic skyline on incomplete data. We propose three efficient algorithms SPISkyline, SPCSkyline, and SPASkyline for probabilistic skyline computation on incomplete data complying with independent, correlated, and anti-correlated distributions, respectively. They employ pruning strategy, optimization of the process of probability computation, and sorting technique to improve the efficiency of probabilistic skyline computation on incomplete data. Our experimental results demonstrate that our proposed concept of probabilistic skyline is an effective method to tackle skyline query on incomplete data and our algorithms are tens of times faster than the naive algorithm on both synthetic and real datasets.																	1041-4347	1558-2191				JUL 1	2020	32	7					1405	1418		10.1109/TKDE.2019.2904967													
J								Multi-View Scaling Support Vector Machines for Classification and Feature Selection	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Support vector machines; Feature extraction; Collaboration; Optimization; Training; Data mining; Machine learning; Multiple views; classification; feature selection; multi-class support vector machines	OBJECT DETECTION	With the explosive growth of data, the multi-view data is widely used in many fields, such as data mining, machine learning, computer vision, and so on. Because such data always has a complex structure, i.e., many categories, many perspectives of description and high dimension, how to formulate an accurate and reliable framework for the multi-view classification is a very challenging task. In this paper, we propose a novel multi-view classification method by using multiple multi-class Support Vector Machines (SVMs) with a novel collaborative strategy. Here, each multi-class SVM embeds the scaling factor to renewedly adjust the weight allocation of all features, which is beneficial to highlight more important and discriminative features. Furthermore, we adopt the decision function values to integrate multiple multi-class learners and introduce the confidence score across multiple classes to determine the final classification result. In addition, through a series of the mathematical deduction, we bridge the proposed model with the solvable problem and solve it through an alternating iteration optimization method. We evaluate the proposed method on several image and face datasets, and the experimental results demonstrate that our proposed method performs better than other state-of-the-art learning algorithms.																	1041-4347	1558-2191				JUL 1	2020	32	7					1419	1430		10.1109/TKDE.2019.2904256													
J								Top-k Dominating Queries on Skyline Groups	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Top-k dominating queries; skyline queries; skyline groups; query processing	COMPUTATION	The top-k dominating (TKD) query on skyline groups returns k skyline groups that dominate the maximum number of points in a given data set. The TKD query combines the advantages of skyline groups and top-k dominating queries, thus has been frequently used in decision making, recommendation systems, and quantitative economics. Traditional skylines are inadequate to answer queries from both individual and groups of points. The group size could be too large to be processed in a reasonable time as a single operator (i.e., the skyline group operator). In this paper, we address the performance problem of grouping for TKD queries in skyline database. We formulate the problem of grouping, define the group operator in skyline, and propose several efficient algorithms to find top-k skyline groups. Thus, we provide a systematic study of TKD queries on skyline groups and validate our algorithms with extensive empirical results on synthetic and realworld data.																	1041-4347	1558-2191				JUL 1	2020	32	7					1431	1444		10.1109/TKDE.2019.2904065													
J								Distance Surface for Event-Based Optical Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Optical imaging; Optical sensors; Cameras; Voltage control; Neuromorphics; Image edge detection; Surface treatment; Motion estimation; optical flow; dynamic vision sensor; neuromorphic camera	MOTION ESTIMATION	We propose DistSurf-OF, a novel optical flow method for neuromorphic cameras. Neuromorphic cameras (or event detection cameras) are an emerging sensor modality that makes use of dynamic vision sensors (DVS) to report asynchronously the log-intensity changes (called "events") exceeding a predefined threshold at each pixel. In absence of the intensity value at each pixel location, we introduce a notion of "distance surface"-the distance transform computed from the detected events-as a proxy for object texture. The distance surface is then used as an input to the intensity-based optical flow methods to recover the two dimensional pixel motion. Real sensor experiments verify that the proposed DistSurf-OF accurately estimates the angle and speed of each events.																	0162-8828	1939-3539				JUL 1	2020	42	7					1547	1556		10.1109/TPAMI.2020.2986748													
J								Deep Slow Motion Video Reconstruction With Hybrid Imaging System	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Computational photography; video frame interpolation; slow motion; deep learning; hybrid imaging	OPTICAL-FLOW ESTIMATION; CAMERA	Slow motion videos are becoming increasingly popular, but capturing high-resolution videos at extremely high frame rates requires professional high-speed cameras. To mitigate this problem, current techniques increase the frame rate of standard videos through frame interpolation by assuming linear object motion which is not valid in challenging cases. In this paper, we address this problem using two video streams as input; an auxiliary video with high frame rate and low spatial resolution, providing temporal information, in addition to the standard main video with low frame rate and high spatial resolution. We propose a two-stage deep learning system consisting of alignment and appearance estimation that reconstructs high resolution slow motion video from the hybrid video input. For alignment, we propose to compute flows between the missing frame and two existing frames of the main video by utilizing the content of the auxiliary video frames. For appearance estimation, we propose to combine the warped and auxiliary frames using a context and occlusion aware network. We train our model on synthetically generated hybrid videos and show high-quality results on a variety of test scenes. To demonstrate practicality, we show the performance of our system on two real dual camera setups with small baseline.																	0162-8828	1939-3539				JUL 1	2020	42	7					1557	1569		10.1109/TPAMI.2020.2987316													
J								Neural Opacity Point Cloud	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Rendering (computer graphics); Geometry; Hair; Visualization; Image color analysis; Cameras; Computational photography	IMAGE; VIDEO	Fuzzy objects composed of hair, fur, or feather are impossible to scan even with the latest active or passive 3D scanners. We present a novel and practical neural rendering (NR) technique called neural opacity point cloud (NOPC) to allow high quality rendering of such fuzzy objects at any viewpoint. NOPC employs a learning-based scheme to extract geometric and appearance features on 3D point clouds including their opacity. It then maps the 3D features onto virtual viewpoints where a new U-Net based NR manages to handle noisy and incomplete geometry while maintaining translation equivariance. Comprehensive experiments on existing and new datasets show our NOPC can produce photorealistic rendering on inputs from multi-view setups such as a turntable system for hair and furry toy captures.																	0162-8828	1939-3539				JUL 1	2020	42	7					1570	1581		10.1109/TPAMI.2020.2986777													
J								Differential 3D Facial Recognition: Adding 3D to Your State-of-the-Art 2D Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Two dimensional displays; Feature extraction; Face recognition; Facial features; Image resolution; Data mining; Differential 3D; active stereo; face recognition; spoofing detection; 3D facial analysis	FACE RECOGNITION	Active illumination is a prominent complement to enhance 2D face recognition and make it more robust, e.g., to spoofing attacks and low-light conditions. In the present work we show that it is possible to adopt active illumination to enhance state-of-the-art 2D face recognition approaches with 3D features, while bypassing the complicated task of 3D reconstruction. The key idea is to project over the test face a high spatial frequency pattern, which allows us to simultaneously recover real 3D information plus a standard 2D facial image. Therefore, state-of-the-art 2D face recognition solution can be transparently applied, while from the high frequency component of the input image, complementary 3D facial features are extracted. Experimental results on ND-2006 dataset show that the proposed ideas can significantly boost face recognition performance and dramatically improve the robustness to spoofing attacks.																	0162-8828	1939-3539				JUL 1	2020	42	7					1582	1593		10.1109/TPAMI.2020.2986951													
J								Shape and Reflectance Reconstruction Using Concentric Multi-Spectral Light Field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Shape; Surface reconstruction; Lighting; Light sources; Image reconstruction; Computational modeling; Shape reconstruction; surface reflectance; multi-spectral; light field	PHOTOMETRIC STEREO; MULTIVIEW STEREO; COLOR	Recovering the shape and reflectance of non-Lambertian surfaces remains a challenging problem in computer vision since the view-dependent appearance invalidates traditional photo-consistency constraint. In this paper, we introduce a novel concentric multi-spectral light field (CMSLF) design that is able to recover the shape and reflectance of surfaces of various materials in one shot. Our CMSLF system consists of an array of cameras arranged on concentric circles where each ring captures a specific spectrum. Coupled with a multi-spectral ring light, we are able to sample viewpoint and lighting variations in a single shot via spectral multiplexing. We further show that our concentric camera and light source setting results in a unique single-peak pattern in specularity variations across viewpoints. This property enables robust depth estimation for specular points. To estimate depth and multi-spectral reflectance map, we formulate a physics-based reflectance model for the CMSLF under the surface camera (S-Cam) representation. Extensive synthetic and real experiments show that our method outperforms the state-of-the-art shape reconstruction methods, especially for non-Lambertian surfaces.																	0162-8828	1939-3539				JUL 1	2020	42	7					1594	1605		10.1109/TPAMI.2020.2986764													
J								SweepCam - Depth-Aware Lensless Imaging Using Programmable Masks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Image reconstruction; Cameras; Image resolution; Semiconductor device measurement; Inverse problems; Convolution; Lensless imaging; computational photography		Lensless cameras, while extremely useful for imaging in constrained scenarios, struggle with resolving scenes with large depth variations. To resolve this, we propose imaging with a set of mask patterns displayed on a programmable mask, and introduce a computational focusing operator that helps to resolve the depth of scene points. As a result, the proposed imager can resolve dense scenes with large depth variations, allowing for more practical applications of lensless cameras. We also present a fast reconstruction algorithm for scene at multiple depths that reduces reconstruction time by two orders of magnitude. Finally, we build a prototype to show the proposed method improves both image quality and depth resolution of lensless cameras.																	0162-8828	1939-3539				JUL 1	2020	42	7					1606	1617		10.1109/TPAMI.2020.2986784													
J								PhlatCam: Designed Phase-Mask Based Thin Lensless Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Image reconstruction; Two dimensional displays; Lenses; Three-dimensional displays; lensless imaging; diffractive masks; phase retrieval refocusing; 3D imagin	IMAGE; CELLS	We demonstrate a versatile thin lensless camera with a designed phase-mask placed at sub-2 mm from an imaging CMOS sensor. Using wave optics and phase retrieval methods, we present a general-purpose framework to create phase-masks that achieve desired sharp point-spread-functions (PSFs) for desired camera thicknesses. From a single 2D encoded measurement, we show the reconstruction of high-resolution 2D images, computational refocusing, and 3D imaging. This ability is made possible by our proposed high-performance contour-based PSF. The heuristic contour-based PSF is designed using concepts in signal processing to achieve maximal information transfer to a bit-depth limited sensor. Due to the efficient coding, we can use fast linear methods for high-quality image reconstructions and switch to iterative nonlinear methods for higher fidelity reconstructions and 3D imaging.																	0162-8828	1939-3539				JUL 1	2020	42	7					1618	1629		10.1109/TPAMI.2020.2987489													
J								One-Bit Time-Resolved Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Imaging; Time measurement; Image resolution; Sensors; Quantization (signal); Current measurement; Photonics; Computational imaging; inverse problems; one-bit sampling; sparse recovery and time-resolved imaging	SIGNALS	Spatial resolution is one of the fundamental bottlenecks in the area of time-resolved imaging. Since each pixel measures a scene-dependent time profile, there is a technological limit on the size of pixel arrays that can be simultaneously used to perform measurements. To overcome this barrier, in this paper, we propose a low-complexity, one-bit sensing scheme. On the data capture front, the time-resolved measurements are mapped to a sequence of +1 and -1. This leads to an extremely simple implementation and at the same time poses a new form of information loss. On the image recovery front, our one-bit time-resolved imaging scheme is complemented with a non-iterative recovery algorithm that can handle the case of single and multiple light paths. Extensive computer simulations and physical experiments benchmarked against conventional Time-of-Flight imaging data corroborate our theoretical framework. Thus, our low-complexity alternative to time-resolved imaging can indeed potentially lead to a new imaging methodology.																	0162-8828	1939-3539				JUL 1	2020	42	7					1630	1641		10.1109/TPAMI.2020.2986950													
J								Neural Sensors: Learning Pixel Exposures for HDR Imaging and Video Compressive Sensing With Programmable Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Optical sensors; Image sensors; Image coding; High-speed optical techniques; Optical imaging; High-dynamic range imaging; video compressive sensing; high-speed imaging; programmable sensors; vision chip; deep neural networks; end-to-end optimization	NETWORKS; CHIP	Camera sensors rely on global or rolling shutter functions to expose an image. This fixed function approach severely limits the sensors' ability to capture high-dynamic-range (HDR) scenes and resolve high-speed dynamics. Spatially varying pixel exposures have been introduced as a powerful computational photography approach to optically encode irradiance on a sensor and computationally recover additional information of a scene, but existing approaches rely on heuristic coding schemes and bulky spatial light modulators to optically implement these exposure functions. Here, we introduce neural sensors as a methodology to optimize per-pixel shutter functions jointly with a differentiable image processing method, such as a neural network, in an end-to-end fashion. Moreover, we demonstrate how to leverage emerging programmable and re-configurable sensor-processors to implement the optimized exposure functions directly on the sensor. Our system takes specific limitations of the sensor into account to optimize physically feasible optical codes and we evaluate its performance for snapshot HDR and high-speed compressive imaging both in simulation and experimentally with real scenes.																	0162-8828	1939-3539				JUL 1	2020	42	7					1642	1653		10.1109/TPAMI.2020.2986944													
J								Adversarial Learning of Structure-Aware Fully Convolutional Networks for Landmark Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Pose estimation; Two dimensional displays; Three-dimensional displays; Heating systems; Task analysis; Training; Pose estimation; landmark localization; structure-aware network; adversarial training; multi-task learning; deep convolutional networks	FLEXIBLE MIXTURES; POSE ESTIMATION; FACE ALIGNMENT	Landmark/pose estimation in single monocular images has received much effort in computer vision due to its important applications. It remains a challenging task when input images come with severe occlusions caused by, e.g., adverse camera views. Under such circumstances, biologically implausible pose predictions may be produced. In contrast, human vision is able to predict poses by exploiting geometric constraints of landmark point inter-connectivity. To address the problem, by incorporating priors about the structure of pose components, we propose a novel structure-aware fully convolutional network to implicitly take such priors into account during training of the deep network. Explicit learning of such constraints is typically challenging. Instead, inspired by how human identifies implausible poses, we design discriminators to distinguish the real poses from the fake ones (such as biologically implausible ones). If the pose generator G generates results that the discriminator fails to distinguish from real ones, the network successfully learns the priors. Training of the network follows the strategy of conditional Generative Adversarial Networks (GANs). The effectiveness of the proposed network is evaluated on three pose-related tasks: 2D human pose estimation, 2D facial landmark estimation and 3D human pose estimation. The proposed approach significantly outperforms several state-of-the-art methods and almost always generates plausible pose predictions, demonstrating the usefulness of implicit learning of structures using GANs.																	0162-8828	1939-3539				JUL 1	2020	42	7					1654	1669		10.1109/TPAMI.2019.2901875													
J								Ambiguity-Free Radiometric Calibration for Internet Photo Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Radiometric calibration; photo collections; internet images; exponential ambiguity; edge color blending	CAMERA RESPONSE	Radiometrically calibrating nonlinear images from Internet photo collections makes photometric analysis applicable not only to lab data but also to big image data in the wild. However, conventional calibration methods cannot be directly applied to such photo collections. This paper presents a method to jointly perform radiometric calibration for a set of nonlinear images in Internet photo collections. By incorporating the consistency of scene reflectance of corresponding pixels across nonlinear images, the proposed method first estimates radiometric response functions of all the nonlinear images up to a unique exponential ambiguity using a rank minimization framework. The ambiguity is then resolved using the linear edge color blending constraint. Quantitative evaluation using both synthetic and real-world data shows the effectiveness of the proposed method.																	0162-8828	1939-3539				JUL 1	2020	42	7					1670	1684		10.1109/TPAMI.2019.2901458													
J								Hiding Images within Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Containers; Neural networks; Image coding; Image reconstruction; Image color analysis; Training; Receivers; Information hiding; image verification; image trust	PRINCIPAL COMPONENT ANALYSIS; NEURAL-NETWORKS	We present a system to hide a full color image inside another of the same size with minimal quality loss to either image. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we examine how the result is achieved and apply numerous transformations to analyze if image quality in the host and hidden image can be maintained. These transformation range from simple image manipulations to sophisticated machine learning-based adversaries. Two extensions to the basic system are presented that mitigate the possibility of discovering the content of the hidden image. With these extensions, not only can the hidden information be kept secure, but the system can be used to hide even more than a single image. Applications for this technology include image authentication, digital watermarks, finding exact regions of image manipulation, and storing meta-information about image rendering and content.																	0162-8828	1939-3539				JUL 1	2020	42	7					1685	1697		10.1109/TPAMI.2019.2901877													
J								Learning Multiple Local Metrics: Global Consideration Helps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Redundancy; Euclidean distance; Task analysis; Training; Complexity theory; Semantics; Distance metric learning; similarity measures; multi-metric learning; global and local; generalization analysis		Learning distance metric between objects provides a better measurement for their relative comparisons. Due to the complex properties inside or between heterogeneous objects, multiple local metrics become an essential representation tool to depict various local characteristics of examples. Different from existing methods building more than one local metric directly, however in this paper, we emphasize the effect of the global metric when generating those local ones. Since local metrics can be considered as types of amendments which describe the biases towards localities based on some commonly shared characteristic, it is expected that the performance of every single local metric for a specified locality can be "lifted" when learning with the global jointly. Following this consideration, we propose the Local metrIcs Facilitated Transformation (Lift) framework, where an adaptive number of local transformations are constructed with the help of their global counterpart. Generalization analyses not only reveal the relationship between the global and local metrics but also indicate when and why the framework works theoretically. In the implementation of Lift, locality anchored centers assist the decomposition of multiple local views, and a diversity regularizer is proposed to reduce the redundancy among biases. Empirical classification comparisons reveal the superiority of the Lift idea. Numerical and visualization investigations on different domains validate its adaptability and comprehensibility as well.																	0162-8828	1939-3539				JUL 1	2020	42	7					1698	1712		10.1109/TPAMI.2019.2901675													
J								Logistic Regression Confined by Cardinality-Constrained Sample and Feature Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Sparsity; non-convex optimization; feature selection; sample selection; imbalanced classification; logistic regression	IMMUNODEFICIENCY-VIRUS-INFECTION; VARIABLE SELECTION; HIV-INFECTION; SPARSE; VOLUME; REGULARIZATION; IMPAIRMENT; ALCOHOLISM; SHRINKAGE; RELEVANCE	Many vision-based applications rely on logistic regression for embedding classification within a probabilistic context, such as recognition in images and videos or identifying disease-specific image phenotypes from neuroimages. Logistic regression, however, often performs poorly when trained on data that is noisy, has irrelevant features, or when the samples are distributed across the classes in an imbalanced setting; a common occurrence in visual recognition tasks. To deal with those issues, researchers generally rely on adhoc regularization techniques or model a subset of these issues. We instead propose a mathematically sound logistic regression model that selects a subset of (relevant) features and (informative and balanced) set of samples during the training process. The model does so by applying cardinality constraints (via l(0)-'norm' sparsity) on the features and samples. l(0) defines sparsity in mathematical settings but in practice has mostly been approximated (e.g., via l(1) or its variations) for computational simplicity. We prove that a local minimum to the non-convex optimization problems induced by cardinality constraints can be computed by combining block coordinate descent with penalty decomposition. On synthetic, image recognition, and neuroimaging datasets, we show that the accuracy of the method is higher than alternative methods and classifiers commonly used in the literature.																	0162-8828	1939-3539				JUL 1	2020	42	7					1713	1728		10.1109/TPAMI.2019.2901688													
J								Online Nearest Neighbor Search Using Hamming Weight Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Nearest neighbor search; binary codes; sublinear search; tree search; Hamming Weight	BINARY; SPACE	Nearest neighbor search is a basic and recurring proximity problem that has been studied for several decades. The goal is to preprocess a dataset of points so that we can quickly report the closet point(s) to any query point. Many recent applications of NNS involve datasets that are very large and dynamic, that is items of data items become available gradually. In this study, we propose a data structure for solving NNS for dynamic binary data where both query and dataset items are represented as binary strings. The proposed tree data structure, called the Hamming Weight Tree, is simple and as the names suggests, is based on partitioning the feature space of binary strings by exploiting the Hamming weights of the binary codes and their substrings. Given a Hamming Weight Tree of binary codes, we propose two search algorithms that accommodate nearest neighbor search for two different distance functions, the Hamming distance and the angular distance. Our empirical results show significant speedup in comparison with the best known large-scale solutions.																	0162-8828	1939-3539				JUL 1	2020	42	7					1729	1740		10.1109/TPAMI.2019.2902391													
J								Optimal Transport in Reproducing Kernel Hilbert Spaces: Theory and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Kernel; Covariance matrices; Hilbert space; Task analysis; Geometry; Modeling; Optimal transport; reproducing kernel hilbert spaces; kernel methods; optimal transport map; Wasserstein distance; Wasserstein geometry; covariance operator; image classification; domain adaptation	DISTANCE; CLASSIFICATION	In this paper, we present a mathematical and computational framework for comparing and matching distributions in reproducing kernel Hilbert spaces (RKHS). This framework, called optimal transport in RKHS, is a generalization of the optimal transport problem in input spaces to (potentially) infinite-dimensional feature spaces. We provide a computable formulation of Kantorovich's optimal transport in RKHS. In particular, we explore the case in which data distributions in RKHS are Gaussian, obtaining closed-form expressions of both the estimated Wasserstein distance and optimal transport map via kernel matrices. Based on these expressions, we generalize the Bures metric on covariance matrices to infinite-dimensional settings, providing a new metric between covariance operators. Moreover, we extend the correlation alignment problem to Hilbert spaces, giving a new strategy for matching distributions in RKHS. Empirically, we apply the derived formulas under the Gaussianity assumption to image classification and domain adaptation. In both tasks, our algorithms yield state-of-the-art performances, demonstrating the effectiveness and potential of our framework.																	0162-8828	1939-3539				JUL 1	2020	42	7					1741	1754		10.1109/TPAMI.2019.2903050													
J								Synthesizing Supervision for Learning Deep Saliency Network without Human Annotation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Object detection; Detectors; Training; Knowledge engineering; Task analysis; Semantics; Feature extraction; Salient object detection; supervision synthesis; annotation-free; weakly supervised semantic segmentation	OBJECT DETECTION; DRIVEN	Recently, the research field of salient object detection is undergoing a rapid and remarkable development along with the wide usage of deep neural networks. Being trained with a large number of images annotated with strong pixel-level ground-truth masks, the deep salient object detectors have achieved the state-of-the-art performance. However, it is expensive and time-consuming to provide the pixel-level ground-truth masks for each training image. To address this problem, this paper proposes one of the earliest frameworks to learn deep salient object detectors without requiring any human annotation. The supervisory signals used in our learning framework are generated through a novel supervision synthesis scheme, in which the key insights are "knowledge source transition" and "supervision by fusion". Specifically, in the proposed learning framework, both the external knowledge source and the internal knowledge source are explored dynamically to provide informative cues for synthesizing supervision required in our approach, while a two-stream fusion mechanism is also established to implement the supervision synthesis process. Comprehensive experiments on four benchmark datasets demonstrate that the deep salient object detector trained by our newly proposed learning framework often works well without requiring any human annotated masks, which even approaches to its upper-bound obtained under the fully supervised learning fashion (within only 3 percent performance gap). Besides, we also apply the salient object detector learnt with our annotation-free learning framework to assist the weakly supervised semantic segmentation task, which demonstrates that our approach can also alleviate the heavy supplementary supervision required in the existing weakly supervised semantic segmentation framework.																	0162-8828	1939-3539				JUL 1	2020	42	7					1755	1769		10.1109/TPAMI.2019.2900649													
J								Unsupervised Tracklet Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Data models; Deep learning; Labeling; Adaptation models; Unsupervised learning; Training data; Person re-identification; unsupervised tracklet association; trajectory fragmentation; multi-task deep learning	NETWORK; SET	Most existing person re-identification (re-id) methods rely on supervised model learning on per-camera-pair manually labelled pairwise training data. This leads to poor scalability in a practical re-id deployment, due to the lack of exhaustive identity labelling of positive and negative image pairs for every camera-pair. In this work, we present an unsupervised re-id deep learning approach. It is capable of incrementally discovering and exploiting the underlying re-id discriminative information from automatically generated person tracklet data end-to-end. We formulate an Unsupervised Tracklet Association Learning (UTAL) framework. This is by jointly learning within-camera tracklet discrimination and cross-camera tracklet association in order to maximise the discovery of tracklet identity matching both within and across camera views. Extensive experiments demonstrate the superiority of the proposed model over the state-of-the-art unsupervised learning and domain adaptation person re-id methods on eight benchmarking datasets.																	0162-8828	1939-3539				JUL 1	2020	42	7					1770	1782		10.1109/TPAMI.2019.2903058													
J								Asymmetric Mapping Quantization for Nearest Neighbor Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Vector quantization; nearest neighbour search; image retrieval; distributed optimization		Nearest neighbor search is a fundamental problem in computer vision and machine learning. The straightforward solution, linear scan, is both computationally and memory intensive in large scale high-dimensional cases, hence is not preferable in practice. Therefore, there have been a lot of interests in algorithms that perform approximate nearest neighbor (ANN) search. In this paper, we propose a novel addition-based vector quantization algorithm, Asymmetric Mapping Quantization (AMQ), to efficiently conduct ANN search. Unlike existing addition-based quantization methods that suffer from handling the problem caused by the norm of database vector, we map the query vector and database vector using different mapping functions to transform the computation of L-2 distance to inner product similarity, thus do not need to evaluate the norm of database vector. Moreover, we further propose Distributed Asymmetric Mapping Quantization (DAMQ) to enable AMQ to work on very large dataset by distributed learning. Extensive experiments on approximate nearest neighbor search and image retrieval validate the merits of the proposed AMQ and DAMQ.																	0162-8828	1939-3539				JUL 1	2020	42	7					1783	1790		10.1109/TPAMI.2019.2925347													
J								Border-Peeling Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Clustering algorithms; Clustering methods; Optics; Kernel; Data analysis; Manuals; Bandwidth; Clustering; non-parametric techniques		In this paper, we present a novel non-parametric clustering technique. Our technique is based on the notion that each latent cluster is comprised of layers that surround its core, where the external layers, or border points, implicitly separate the clusters. Unlike previous techniques, such as DBSCAN, where the cores of the clusters are defined directly by their densities, here the latent cores are revealed by a progressive peeling of the border points. Analyzing the density of the local neighborhoods allows identifying the border points and associating them with points of inner layers. We show that the peeling process adapts to the local densities and characteristics to successfully separate adjacent clusters (of possibly different densities). We extensively tested our technique on large sets of labeled data, including high-dimensional datasets of deep features that were trained by a convolutional neural network. We show that our technique is competitive to other state-of-the-art non-parametric methods using a fixed set of parameters throughout the experiments.																	0162-8828	1939-3539				JUL 1	2020	42	7					1791	1797		10.1109/TPAMI.2019.2924953													
J								Ranking-Preserving Cross-Source Learning for Image Retargeting Quality Assessment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Measurement; Training; Benchmark testing; Quality assessment; Neural networks; Computational modeling; Predictive models; Image retargeting; image quality assessment; learning to rank; general regression neural network	COLOR	Image retargeting techniques adjust images into different sizes and have attracted much attention recently. Objective quality assessment (OQA) of image retargeting results is often desired to automatically select the best results. Existing OQA methods train a model using some benchmarks (e.g., RetargetMe), in which subjective scores evaluated by users are provided. Observing that it is challenging even for human subjects to give consistent scores for retargeting results of different source images (diff-source-results), in this paper we propose a learning-based OQA method that trains a General Regression Neural Network (GRNN) model based on relative scores-which preserve the ranking-of retargeting results of the same source image (same-source-results). In particular, we develop a novel training scheme with provable convergence that learns a common base scalar for same-source-results. With this source specific offset, our computed scores not only preserve the ranking of subjective scores for same-source-results, but also provide a reference to compare the diff-source-results. We train and evaluate our GRNN model using human preference data collected in RetargetMe. We further introduce a subjective benchmark to evaluate the generalizability of different OQA methods. Experimental results demonstrate that our method outperforms ten representative OQA methods in ranking prediction and has better generalizability to different datasets.																	0162-8828	1939-3539				JUL 1	2020	42	7					1798	1805		10.1109/TPAMI.2019.2923998													
J								5GAuNetS: an autonomous 5G network selection framework for Industry 4.0	SOFT COMPUTING										5G; Industry 4; 0; FAHP; ECM-based TOPSIS; Handover; Ranking abnormality	EXTENT ANALYSIS METHOD; DECISION-MAKING; FUZZY-AHP; MOBILE	The megatrends within the industrial automation and global value chains expedited the adoption of "Industry 4.0 enabled by 5G" to comprehend extremely flexible and smart production systems. The pivotal challenge for the smart manufacturing leveraging on 5G is the seamless vertical handover and connectivity to a suitable network in accordance with the determined application. The existing literature reports numerous strategies to ensure "always best connected" paradigm but they suffer from a couple of limitations. The amateurish approach employed in these strategies propelled the development of an autonomous network selection model exploiting fuzzy analytical hierarchical process consolidated with the novel extended efficacy coefficient method-based Technique for Order Preference by Similarity to Ideal Solution. This article addresses the vertical handover execution under the circumstances of four typical 5G application scenarios, respectively, i.e. Tactile Internet, Bitpipe, Internet of Things and Internet Access for Regional Areas. The analytical results validated through the extensive simulation revealed that the proposed hybrid scheme is effective and efficient compared to other methods in terms of avoiding the unnecessary handover and the ranking abnormality issues.																	1432-7643	1433-7479				JUL	2020	24	13					9507	9523		10.1007/s00500-019-04460-y													
J								ANFIS-based model for predicting actual shear rate associated with wall slip phenomenon	SOFT COMPUTING										ANFIS; Concentration; Particle size; Rheology; Temperature; Wall slip	CONCENTRATED SUSPENSIONS; POLYMER-SOLUTIONS; APPARENT SLIP; FLUID-FLOW; VELOCITY; CAPILLARY; TEMPERATURE; PARTICLES; COUETTE; LAYER	Wall slip can be defined as a phenomenon in the flow of suspensions due to the movement of particles away from the wall boundary, leaving a thin liquid rich layer adjacent to the wall. It should be taken into consideration in material designing, manufacturing and transportation as it may cause inaccurate rheological measurements such as shear rate and viscosity. The apparent (measured) shear rate is higher than the actual shear rate. The traditional method for actual shear rate determination is not efficient from the perspective of time and cost consumption. Therefore, there is a need to develop a mathematical model that is able to detect the complex pattern of the actual shear rate and accurately predict its value based on the available measured input variables. Volumetric concentration, particle size, temperature and shear stress are selected as the input, while the actual shear rate is kept as output while designing the architecture of ANFIS model. Sixteen ANFIS models with different architecture were designed and evaluated using different statistical indices. Model XVI with number of membership function equal to 3, input product of two sigmoid membership function, output linear membership function type integrated with hybrid optimization method appears to be the most suitable model architecture for predicting the actual shear rate.																	1432-7643	1433-7479				JUL	2020	24	13					9639	9649		10.1007/s00500-019-04475-5													
J								LinkZoo: A Collaborative Resource Management Tool Based on Linked Data	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Collaborative Environments; Linked Data; Personal Information Management; Resource Management; Semantic Web		This article presents LinkZoo, a web-based, linked data enabled tool that supports collaborative management of information resources. LinkZoo addresses the modern needs of information-intensive collaboration environments to publish, manage, and share heterogeneous resources within user-driven contexts. Users create and manage diverse types of resources into common spaces such as files, web documents, people, datasets, and calendar events. They can interlink them, annotate them, and share them with other users, thus enabling collaborative editing, as well as enrich them with links to externally linked data resources. Resources are inherently modeled and published as resource description framework (RDF) and can be explicitly interlinked and dereferenced by external applications. LinkZoo supports creation of dynamic communities that enable web-based collaboration through resource sharing and annotating, exposing objects on the linked data Cloud under controlled vocabularies and permissions. The authors demonstrate the applicability of the tool on a popular collaboration use case scenario for sharing and organizing research resources.																	1552-6283	1552-6291				JUL-SEP	2020	16	3					1	19		10.4018/IJSWIS.2020070101													
J								Secure Timestamp-Based Mutual Authentication Protocol for IoT Devices Using RFID Tags	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Anonymity; Authentication; Confidentiality; Internet of Things; RFID tags	PRIVACY; IDENTIFICATION; INTERNET; THINGS	Internet of Things (IoT) is playing more and more important roles in our daily lives in the last decade. It can be a part of traditional machine or equipment to daily household objects as well as wireless sensor networks and devices. IoT has a huge potential which is still to be unleashed. However, as the foundation of IoT is the Internet and all the data collected by these devices is over the Internet, these devices also face threats to security and privacy. At the physical or sensor layer of IoT devices the most commonly used technology is RFID. Thus, securing the RFID tag by cryptographic mechanisms can secure our data at the device as well as during communication. This article first discusses the flaws of our previous ultra-lightweight protocol due to its vulnerability to passive secret disclosure attack. Then, the authors propose a new protocol to overcome the shortcomings of our previous work. The proposed scheme uses timestamps in addition to bitwise operation to provide security against de-synchronization and disclosure. This research also presents a security and performance analysis of our approach and its comparison with other existing schemes.																	1552-6283	1552-6291				JUL-SEP	2020	16	3					20	34		10.4018/IJSWIS.2020070102													
J								The Effect of Gender, Age, and Education on the Adoption of Mobile Government Services	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Age; Education; E-Government; Gender; Mobile Government Services; Mobile Government; UTAUT	COMPUTER SELF-EFFICACY; INFORMATION-TECHNOLOGY; USER ACCEPTANCE; SEMANTIC WEB; MODEL; INTEROPERABILITY; PREDICTORS; INTERNET	This study explored the important role of demographic factors such as gender, age, and education in the adoption of mobile government (m-government) services. The Unified Theory of Acceptance and Use of Technology (UTAUT) model was used as the theoretical foundation whiles the data was captured and analyzed with SPSS and SmartPLS. The results have demonstrated that gender is a significant predictor of both the intention to use and performance expectancy of m-government services. However, gender does not determine mobile self-efficacy. In addition, age and education were both were significant predictors of performance expectancy, mobile self-efficacy and the intention to use m-government services respectively. The implications of these and other findings of the study are thoroughly discussed.																	1552-6283	1552-6291				JUL-SEP	2020	16	3					35	52		10.4018/IJSWIS.2020070103													
J								Advanced Learning Analytics in Academic Education: Academic Performance Forecasting Based on an Artificial Neural Network	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Academic Evaluation; Decision Support Systems; Key Performance Indicator; Neural Networks	DECISION-SUPPORT-SYSTEM; BIG DATA; STUDENT; FRAMEWORK; IMPACT	The integration of innovative data mining and decision-making techniques in the context of higher education is a bold initiative towards enhanced performance. Predictive and descriptive analytics add interesting insights for significant aspects the education. The purpose of this article is to summarize a novel approach for the adoption of artificial intelligence (AI) techniques towards forecasting of academic performance. The added value of applying AI techniques for advanced decision making in education is the realization that the scientific approach to standard problems in academia, like the enhancement of academic performance is feasible. For the purpose of this research the authors promote a research in Saudi Arabia. The vision of the Knowledge Society in the Kingdom of Saudi Arabia is a critical milestone towards digital transformation. The human capital and the integration of industry and academia has to be based on holistic approaches to skills and competencies management. One of the main objectives of an academic decision maker is to ensure that academic resources are adequately planned and that students are properly advised. To achieve such an objective, an extensive analysis of large volumes of data may be required. This research develops a decision support system (DSS) that is based on an artificial neural network (ANN) model that can be deployed for effective academic planning and advising. The system is based on evaluating academic metrics against academic performance for students. The model integrates inputs from relevant academic data sources into an autonomous ANN. A simulation of real data on an ANN is conducted to validate the system's accuracy. Moreover, an ANN is compared with different mathematical approaches. The system enables the quality assurance of planning, advising, and the monitoring of academic decisions. The overall contribution of this work is a novel approach to the deployment of Artificial Intelligent for advanced decision making in higher education. In future work this model is integrated with big data and analytics research for advanced visualizations																	1552-6283	1552-6291				JUL-SEP	2020	16	3					70	87		10.4018/IJSWIS.2020070105													
J								Research Synthesis and Thematic Analysis of Twitter Through Bibliometric Analysis	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Bibliometric Analysis; Thematic Analysis; Twitter; VOSviewer	SOCIAL MEDIA RESEARCH; HIGHER-EDUCATION; EVENT DETECTION; SENTIMENT ANALYSIS; HEALTH; NETWORKS; DISASTER; INFORMATION; COMMUNITIES; ONLINE	In literature, there is a shortage of comprehensive documents that can provide proper details about Twitter in research community. This study conducted a first descriptive bibliometric analysis to examine the most influential journals, institutions, and countries on Twitter. Similarly, bibliometric mapping analysis is carried out to explore different research themes in Twitter publications. VOSviewer was employed to process the 11,006 Twitter publications retrieved from the Web of Science (WoS) from 2009 to 2018. Obtained results suggest that USA and China received the highest number of publications on Twitter research, while the University of Illinois was the most productive institute. Furthermore, the five major themes have emerged in Twitter publications, and its remarkable role has been found in event detection, sentiment analysis, education, health, politics, and crisis as well as risk management. The authors believe that this study will open new doors for researchers to use online Twitter social networking communities in beauty salons, consulting companies, banks, and airlines.																	1552-6283	1552-6291				JUL-SEP	2020	16	3					88	109		10.4018/IJSWIS.2020070106													
J								CustNER: A Rule-Based Named-Entity Recognizer With Improved Recall	INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS										Information Extraction; Named Entity Classification; Named Entity Recognition; Rule-Based NER		This article describes CustNER: a system for named-entity recognition (NER) of person, location, and organization. Realizing the incorrect annotations of existing NER, four categories of false negatives have been identified. The NEs not annotated contain nationalities, have corresponding resource in DBpedia, are acronyms of other NEs. A rule-based system, CustNER, has been proposed that utilizes existing NERs and DBpedia knowledge base. CustNER has been trained on the open knowledge extraction (OKE) challenge 2017 dataset and evaluated on OKE and CoNLL03 (Conference on Natural Language Learning) datasets. The OKE dataset has also been annotated with the three types. Evaluation results show that CustNER outperforms existing NERs with F score 12.4% better than Stanford NER and 3.1% better than Illinois NER. On another standard evaluation dataset for which the system is not trained, the CoNLL03 dataset, CustNER gives results comparable to existing systems with F score 3.9% better than Stanford NER, though Illinois NER F score is 1.3% better than CustNER.																	1552-6283	1552-6291				JUL-SEP	2020	16	3					110	127		10.4018/IJSWIS.2020070107													
J								Improved covariant local feature detector	PATTERN RECOGNITION LETTERS											SCALE																		0167-8655	1872-7344				JUL	2020	135						1	7		10.1016/j.patrec.2020.03.027													
J								One-step spectral clustering based on self -paced learning	PATTERN RECOGNITION LETTERS											MINIMIZATION																		0167-8655	1872-7344				JUL	2020	135						8	14		10.1016/j.patrec.2020.03.035													
J								Comparison of incremental linear dimension reduction methods for streaming data	PATTERN RECOGNITION LETTERS											DISCRIMINANT-ANALYSIS																		0167-8655	1872-7344				JUL	2020	135						15	21		10.1016/j.patrec.2020.03.028													
J								Semantically consistent text to fashion image synthesis with an enhanced attentional generative adversarial network ?	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						22	29		10.1016/j.patrec.2020.02.030													
J								Efficient component-hypertree construction based on hierarchy of partitions	PATTERN RECOGNITION LETTERS											CONNECTIVITY; IMAGE; TREE; SEGMENTATION; REPRESENTATION																		0167-8655	1872-7344				JUL	2020	135						30	37		10.1016/j.patrec.2020.02.032													
J								The equivalence of two definitions of compatible homography matrices	PATTERN RECOGNITION LETTERS											CONSTRAINTS; TRACKING																		0167-8655	1872-7344				JUL	2020	135						38	43		10.1016/j.patrec.2020.03.033													
J								Structural sparse representation with biometric recognition class -specific dictionary for ECG	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						44	49		10.1016/j.patrec.2020.04.022													
J								Peeling off image layers on topographic architectures	PATTERN RECOGNITION LETTERS											TREE; SHAPES																		0167-8655	1872-7344				JUL	2020	135						50	56		10.1016/j.patrec.2020.04.023													
J								CNN-DMRI: A Convolutional Neural Network for Denoising of Magnetic Resonance Images	PATTERN RECOGNITION LETTERS										Convolutional Neural Network; Denoising; Encoder-decoder; Magnetic Resonance Imaging; Residual learning		Magnetic Resonance Images (MRI) are often contaminated by rician noise at the acquisition time. This type of noise typically deteriorates the performance of disease diagnosis by a human observer or an automated system. Thus, it is necessary to remove the rician noise from MRI scans as a preprocessing step. In this letter, we propose a novel Convolutional Neural Network (CNN), viz. CNN-DMRI, for denoising of MRI scans. The network uses a set of convolutions to separate the image features from the noise. The network also employs encoder-decoder structure for preserving the prominent features of the image while ignoring unnecessary ones. The training of the network is carried out in an end-to-end way by utilizing residual learning scheme. The performance of the proposed CNN has been tested qualitatively and quantitatively on one simulated and four real MRI datasets. Extensive experimental findings suggest that the proposed network can denoise MRI images effectively without losing crucial image details. (C) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				JUL	2020	135						57	63		10.1016/j.patrec.2020.03.036													
J								Multi scale mirror connection based encoder decoder network for text localization	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						64	71		10.1016/j.patrec.2020.04.002													
J								Automatic region of interest segmentation for breast thermogram classification	PATTERN RECOGNITION LETTERS											CANCER; FEATURES; IMAGES																		0167-8655	1872-7344				JUL	2020	135						72	81		10.1016/j.patrec.2020.03.025													
J								Graph -based selective rank fusion for unsupervised image retrieval	PATTERN RECOGNITION LETTERS											SCALE; COLOR; SIMILARITY																		0167-8655	1872-7344				JUL	2020	135						82	89		10.1016/j.patrec.2020.03.032													
J								Robust pruning for efficient CNNs A	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						90	98		10.1016/j.patrec.2020.03.034													
J								DIABLO: Dictionary -based attention block for deep metric learning	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						99	105		10.1016/j.patrec.2020.03.020													
J								Automated detection of Alzheimer?s disease using bi-directional empirical model decomposition	PATTERN RECOGNITION LETTERS											PSEUDO ZERNIKE MOMENT; NEURAL-NETWORK; CLASSIFICATION; DIAGNOSIS; MRI; SPECTRUM; FUSION																		0167-8655	1872-7344				JUL	2020	135						106	113		10.1016/j.patrec.2020.03.014													
J								Historical building point cloud segmentation combining hierarchical watershed transform and curvature analysis	PATTERN RECOGNITION LETTERS											MODELS																		0167-8655	1872-7344				JUL	2020	135						114	121		10.1016/j.patrec.2020.04.010													
J								Masking domain -specific information for cross -domain deception detection	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						122	130		10.1016/j.patrec.2020.04.020													
J								Cross -modal guidance based auto -encoder for multi -video summarization	PATTERN RECOGNITION LETTERS											RELEVANCE																		0167-8655	1872-7344				JUL	2020	135						131	137		10.1016/j.patrec.2020.04.011													
J								Unsupervised generation of polygonal approximations based on the convex hull	PATTERN RECOGNITION LETTERS											DOMINANT POINT DETECTION; DIGITAL PLANAR CURVES; SHAPE REPRESENTATION; EFFICIENT ALGORITHM																		0167-8655	1872-7344				JUL	2020	135						138	145		10.1016/j.patrec.2020.04.014													
J								Steganographic universal adversarial perturbations	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						146	152		10.1016/j.patrec.2020.04.025													
J								A new approach for optimal time -series segmentation ?	PATTERN RECOGNITION LETTERS											OPTIMAL POLYGONAL-APPROXIMATION; ALGORITHM																		0167-8655	1872-7344				JUL	2020	135						153	159		10.1016/j.patrec.2020.04.006													
J								Joint image restoration and matching method based on distance -weighted sparse representation prior	PATTERN RECOGNITION LETTERS											REGISTRATION																		0167-8655	1872-7344				JUL	2020	135						160	166		10.1016/j.patrec.2020.04.003													
J								Local low -rank matrix recovery for hyperspectral image denoising with t 0 gradient constraint	PATTERN RECOGNITION LETTERS											RESTORATION																		0167-8655	1872-7344				JUL	2020	135						167	172		10.1016/j.patrec.2020.04.012													
J								Image decomposition by bidimensional ensemble patch transform	PATTERN RECOGNITION LETTERS											EMPIRICAL MODE DECOMPOSITION																		0167-8655	1872-7344				JUL	2020	135						173	179		10.1016/j.patrec.2020.03.029													
J								Rubik Gaussian-based patterns for dynamic texture classification	PATTERN RECOGNITION LETTERS										Dynamic texture; Dynamic texture classification; Gaussian filtering; DoG; LBP; Video representation	LOCAL BINARY COUNT; REPRESENTATION; SCALE	Illumination, noise, and changes of environments, scales negatively impact on encoding chaotic motions for dynamic texture (DT) representation. This paper proposes a new method to overcome those issues by addressing the following novel concepts. First, different Gaussian-based kernels are taken into account as an effective filtered pre-processing with low computational cost to point out robust and invariant features. Second, a discriminative operator, named Local Rubik-based Pattern (LRP), is introduced to adequately capture both shape and motion cues of DTs by proposing a new concept of complemented components together with an effective encoding method. In addition, it also addresses a novel thresholding to take into account rich spatio-temporal relationships extracted from a new model of neighborhood supporting region. Finally, an efficient framework for DT description is presented by exploiting operator LRP for encoding various instances of Gaussian-based volumes in order to form a robust descriptor against noise, changes of illumination, scale, and environment. Experiments for DT classification on benchmark datasets have authenticated the interest of our proposal. (C) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				JUL	2020	135						180	187		10.1016/j.patrec.2020.04.007													
J								An IoT-ready solution for automated recognition of water contaminants	PATTERN RECOGNITION LETTERS											LOW-COST; QUALITY; SYSTEM; PLATFORM																		0167-8655	1872-7344				JUL	2020	135						188	195		10.1016/j.patrec.2020.04.019													
J								Towards automated computer vision: analysis of the AutoCV challenges 2019?	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						196	203		10.1016/j.patrec.2020.04.030													
J								Gaze -based classification of autism spectrum disorder	PATTERN RECOGNITION LETTERS											EARLY INTERVENTION; CHILDREN; NETWORK																		0167-8655	1872-7344				JUL	2020	135						204	212		10.1016/j.patrec.2020.04.028													
J								Spatially regularized active diffusion learning for high -dimensional images ?	PATTERN RECOGNITION LETTERS											PROPAGATION																		0167-8655	1872-7344				JUL	2020	135						213	220		10.1016/j.patrec.2020.04.021													
J								Two -stream collaborative network for multi -label chest X-ray Image classification with lung segmentation	PATTERN RECOGNITION LETTERS											RECOGNITION																		0167-8655	1872-7344				JUL	2020	135						221	227		10.1016/j.patrec.2020.04.016													
J								Defective texture classification using optimized neural network structure	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						228	236		10.1016/j.patrec.2020.04.017													
J								Deviation based clustering for unsupervised person re -identification	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						237	243		10.1016/j.patrec.2020.04.039													
J								Modal features for image texture classification	PATTERN RECOGNITION LETTERS											DECOMPOSITION; ROUGHNESS; FORM																		0167-8655	1872-7344				JUL	2020	135						249	255		10.1016/j.patrec.2020.04.036													
J								Time -sync comments denoising via graph convolutional and contextual encoding *	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						256	263		10.1016/j.patrec.2020.05.004													
J								Securing the internet of vehicles through lightweight block ciphers *	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						264	270		10.1016/j.patrec.2020.04.038													
J								Learning transferable features in meta -learning for few -shot text classification	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						271	278		10.1016/j.patrec.2020.05.007													
J								Online streaming feature selection with incremental feature grouping	WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY										feature selection; features grouping; redundancy analysis; stream of features; streaming data		Today, the dimensionality of data is increasing in a massive way. Thus, traditional feature selection techniques are not directly applicable. Consequently, recent research has led to the development of a more efficient approach to the selection of features from a feature stream, known as streaming feature selection. Another active research area, related to feature selection, is feature grouping. Feature grouping selects relevant features by evaluating the hidden information of selected features. However, although feature grouping is a promising technique, it is not directly applicable to feature streams. In this paper, we propose a novel and efficient algorithm that uses online feature grouping, embedded within a new incremental technique, to select features from a feature stream. This technique groups similar features together; it assigns new incoming features to an existing group or creates a new group. To the best of our knowledge, this is the first approach that proposes the use of incremental feature grouping to perform feature selection from features. We have implemented this algorithm and evaluated it, using benchmark datasets, against state-of-the-art streaming feature selection algorithms that use feature grouping or incremental selection techniques. The results show superior performance by the proposed technique through combining the online selection and grouping, in terms of prediction accuracy and running time. This article is categorized under: Algorithmic Development > Spatial and Temporal Data Mining Technologies > Data Preprocessing Technologies > Classification Technologies > Machine Learning																	1942-4787	1942-4795				JUL	2020	10	4							e1364	10.1002/widm.1364													
J								A survey of recent methods on deriving topics from Twitter: algorithm to evaluation	KNOWLEDGE AND INFORMATION SYSTEMS										Topic derivation; Twitter analysis; Algorithms; Evaluations	NONNEGATIVE MATRIX FACTORIZATION; MODEL; IMAGE; LDA	In recent years, studies related to topic derivation in Twitter have gained a lot of interest from businesses and academics. The interconnection between users and information has made social media, especially Twitter, an ultimate platform for propagation of information about events in real time. Many applications require topic derivation from this social media platform. These include, for example, disaster management, outbreak detection, situation awareness, surveillance, and market analysis. Deriving topics from Twitter is challenging due to the short content of the individual posts. The environment itself is also highly dynamic. This paper presents a review of recent methods proposed to derive topics from social media platform from algorithms to evaluations. With regard to algorithms, we classify them based on the features they exploit, such as content, social interactions, and temporal aspects. In terms of evaluations, we discuss the datasets and metrics generally used to evaluate the methods. Finally, we highlight the gaps in the research this far and the problems that remain to be addressed.																	0219-1377	0219-3116				JUL	2020	62	7					2485	2519		10.1007/s10115-019-01429-z													
J								Case notion discovery and recommendation: automated event log building on databases	KNOWLEDGE AND INFORMATION SYSTEMS										Process mining; Event log; Database; Case notion; Recommendation; Ranking		Process mining techniques use event logs as input. When analyzing complex databases, these event logs can be built in many ways. Events need to be grouped into traces corresponding to a case. Different groupings provide different views on the data. Building event logs is usually a time-consuming, manual task. This paper provides a precise view on the case notion on databases, which enables the automatic computation of event logs. Also, it provides a way to assess event log quality, used to rank event logs with respect to their interestingness. The computational cost of building an event log can be avoided by predicting the interestingness of a case notion, before the corresponding event log is computed. This makes it possible to give recommendations to users, so they can focus on the analysis of the most promising process views. Finally, the accuracy of the predictions and the quality of the rankings generated by our unsupervised technique are evaluated in comparison to the existing regression techniques as well as to state-of-the-art learning to rank algorithms from the information retrieval field. The results show that our prediction technique succeeds at discovering interesting event logs and provides valuable recommendations to users about the perspectives on which to focus the efforts during the analysis.																	0219-1377	0219-3116				JUL	2020	62	7					2539	2575		10.1007/s10115-019-01430-6													
J								Location histogram privacy by Sensitive Location Hiding and Target Histogram Avoidance/Resemblance	KNOWLEDGE AND INFORMATION SYSTEMS										Location privacy; Histogram privacy; Location-based services; Dynamic programming	RECOMMENDATION	A location histogram is comprised of the number of times a user has visited locations as they move in an area of interest, and it is often obtained from the user in the context of applications such as recommendation and advertising. However, a location histogram that leaves a user's computer or device may threaten privacywhen it contains visits to locations that the user does not want to disclose (sensitive locations), or when it can be used to profile the user in a way that leads to price discrimination and unsolicited advertising (e.g., as "wealthy" or "minority member"). Ourwork introduces two privacy notions to protect a location histogram from these threats: Sensitive Location Hiding, which aims at concealing all visits to sensitive locations, and Target Avoidance/Resemblance, which aims at concealing the similarity/dissimilarity of the user's histogram to a target histogram that corresponds to an undesired/desired profile. We formulate an optimization problem around each notion: Sensitive Location Hiding (SLH), which seeks to construct a histogram that is as similar as possible to the user's histogram but associates all visits with nonsensitive locations, and TargetAvoidance/Resemblance (TA/TR), which seeks to construct a histogram that is as dissimilar/similar as possible to a given target histogram but remains useful for getting a good response from the application that analyzes the histogram. We develop an optimal algorithm for each notion, which operates on a notionspecific search space graph and finds a shortest or longest path in the graph that corresponds to a solution histogram. In addition, we develop a greedy heuristic for the TA/TR problem, which operates directly on a user's histogram. Our experiments demonstrate that all algorithms are effective at preserving the distribution of locations in a histogram and the quality of location recommendation. They also demonstrate that the heuristic produces near-optimal solutions while being orders of magnitude faster than the optimal algorithm for TA/TR.																	0219-1377	0219-3116				JUL	2020	62	7					2613	2651		10.1007/s10115-019-01432-4													
J								Verifying the manipulation of data objects according to business process and data models	KNOWLEDGE AND INFORMATION SYSTEMS										Business processes; Integration of data and processes; Data object state; Object-relational mapping; Data state verification	WORKFLOW NETS; VERIFICATION; SOUNDNESS	Business processes read and write data objects, usually stored in databases. Although data models and activity-oriented business process models originate from different paradigms, they need to work together properly. The data object states are transformed during each process instance by the activities of the process model. It is therefore necessary to verify whether the states of the data objects are correct according to the process model, and to discover the states of the stored data objects. This implies determining the relation between the data objects stored in the database, the data objects involved in the process, and the activities that within the business process that create the data objects and modify their states. In order to verify the business process annotated with data states and to reduce the existing gap between data model and business process model, we propose a methodology that includes enlarging the capability to describe data states in business processes; verifying the completeness and consistency of the data states described in accordance with their relation to the business process model; and discovering the states of the data objects stored in the database according to the business process model where they are managed. The methodology is supported by a framework that enables a natural-like language to be employed to describe the states, to apply the necessary algorithms to verify the consistency and completeness of the model, and to determine the states of the stored data objects according to the model described. To validate our proposal, an extension of ActivitiTM has been implemented and applied to a real example as an illustration of its applicability.																	0219-1377	0219-3116				JUL	2020	62	7					2653	2683		10.1007/s10115-019-01431-5													
J								Fraud detection via behavioral sequence embedding	KNOWLEDGE AND INFORMATION SYSTEMS										Fraud detection; Behavioral sequence; LSTM; Network embedding; Attention		Fraud detection is usually compared to finding a needle in a haystack and remains a challenging task because fraudulent acts are buried in massive amounts of normal behavior and true intentions may be disguised in a single snapshot. Indeed, fraudulent incidents usually take place in consecutive time steps to gain illegal benefits, which provides unique clues for probing fraudulent behavior by considering a complete behavioral sequence rather than detecting fraud from a snapshot of behavior. Additionally, fraudulent behavior may involve different parties, such that the interaction patterns between sources and targets can help distinguish fraudulent acts from normal behavior. Therefore, in this paper, we model the attributed behavioral sequences generated from consecutive behaviors in order to capture the sequential patterns, while those that deviate from the pattern can be detected as fraudulence. Considering the characteristics of the behavioral sequence, we propose a novel model,NHA-LSTM, by augmenting the traditional LSTM with a modified forget gate, where the interval time between consecutive time steps is considered. Furthermore, we design a self-historical attention mechanism to allow for long time dependencies, which can help identify repeated or cyclical appearances. In addition, we propose an enhanced network embedding method, FraudWalk, to construct embeddings for the nodes in the interaction network with regard to higher-order interactions and particular time constraints for revealing potential group fraudulence. The node embeddings, along with the feature vectors, are fed into the model to capture the interactions between sources and targets. To validate the effectiveness of sequential behavior embeddings, we experiment on a real-world telecommunication dataset with prediction and classification tasks based on the learned embeddings. The experimental results show that the learned embeddings can better identify fraudulent behavior. Finally, we visualize the weights of the attention mechanism to provide a rational interpretation of human behavioral patterns.																	0219-1377	0219-3116				JUL	2020	62	7					2685	2708		10.1007/s10115-019-01433-3													
J								Attentive multi -stage convolutional neural network for crowd counting	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						279	285		10.1016/j.patrec.2020.05.009													
J								Topology -learnable graph convolution for skeleton -based action recognition	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						286	292		10.1016/j.patrec.2020.05.005													
J								Automated detection of diabetic retinopathy using convolutional neural networks on a small dataset	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						293	298		10.1016/j.patrec.2020.04.026													
J								Phoneme classification in reconstructed phase space with convolutional neural networks ?	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						299	306															
J								A novel Pooling Block for improving lightweight deep neural networks ?	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						307	312		10.1016/j.patrec.2020.05.012													
J								Perturbation analysis of gradient -based adversarial attacks	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						313	320		10.1016/j.patrec.2020.04.034													
J								Decomposition and construction of higher -dimensional neighbourhood operations	PATTERN RECOGNITION LETTERS											SWEEP-PLANE ALGORITHM																		0167-8655	1872-7344				JUL	2020	135						321	328		10.1016/j.patrec.2020.04.015													
J								Real time human action recognition using triggered frame extraction and a typical CNN heuristic	PATTERN RECOGNITION LETTERS											VIDEOS																		0167-8655	1872-7344				JUL	2020	135						329	336		10.1016/j.patrec.2020.04.031													
J								Markerless detection of ancient rock carvings in the wild: rock art in Vathy, Astypalaia	PATTERN RECOGNITION LETTERS											CULTURAL-HERITAGE; 3D RECONSTRUCTION																		0167-8655	1872-7344				JUL	2020	135						337	345		10.1016/j.patrec.2020.03.026													
J								Trends in IoT based solutions for health care: Moving AI to the edge	PATTERN RECOGNITION LETTERS											SMART HEALTH; CLOUD; SYSTEM; PLATFORM																		0167-8655	1872-7344				JUL	2020	135						346	353		10.1016/j.patrec.2020.05.016													
J								Weighted sigmoid gate unit for an activation function of deep neural network	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						354	359		10.1016/j.patrec.2020.05.017													
J								On the importance of similarity characteristics of curve clustering and its applications	PATTERN RECOGNITION LETTERS											FUNCTIONAL DATA; REGISTRATION																		0167-8655	1872-7344				JUL	2020	135						360	367		10.1016/j.patrec.2020.04.024													
J								Zero shot learning based on class visual prototypes and semantic consistency	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						368	374		10.1016/j.patrec.2020.04.029													
J								A novel PCA-based approach for building on -board sensor classifiers for water contaminant detection	PATTERN RECOGNITION LETTERS											LOW-COST; QUALITY; CLASSIFICATION; ALGORITHM; PLATFORM; SYSTEM; SVM																		0167-8655	1872-7344				JUL	2020	135						375	381		10.1016/j.patrec.2020.05.015													
J								Mean oriented Riesz features for micro expression classification ?	PATTERN RECOGNITION LETTERS											RECOGNITION																		0167-8655	1872-7344				JUL	2020	135						382	389		10.1016/j.patrec.2020.05.008													
J								Image fusion for stabilized medical video sequence using multimodal parametric registration	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						390	401		10.1016/j.patrec.2020.04.001													
J								Efficient binocular stereo correspondence matching with 1-D Max -Trees	PATTERN RECOGNITION LETTERS											CONNECTED OPERATORS; IMAGE																		0167-8655	1872-7344				JUL	2020	135						402	408		10.1016/j.patrec.2020.02.019													
J								Deep learning frameworks for diabetic retinopathy detection with smartphone-based retinal imaging systems	PATTERN RECOGNITION LETTERS											VALIDATION																		0167-8655	1872-7344				JUL	2020	135						409	417		10.1016/j.patrec.2020.04.009													
J								Fast correspondence -based point cloud registration by pair -wise inlier checking and transformation decomposition	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						418	424		10.1016/j.patrec.2020.05.013													
J								Parametric PCA for unsupervised metric learning	PATTERN RECOGNITION LETTERS											DIMENSIONALITY REDUCTION; ALGORITHMS																		0167-8655	1872-7344				JUL	2020	135						425	430		10.1016/j.patrec.2020.05.011													
J								Image stitching with positional relationship constraints of feature points and lines	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						431	440		10.1016/j.patrec.2020.05.003													
J								Pattern recognition techniques for provenance classification of archaeological ceramics using ultrasounds	PATTERN RECOGNITION LETTERS																													0167-8655	1872-7344				JUL	2020	135						441	450		10.1016/j.patrec.2020.04.013													
J								Pseudo distribution on unseen classes for generalized zero shot learning	PATTERN RECOGNITION LETTERS											NETWORK																		0167-8655	1872-7344				JUL	2020	135						451	458		10.1016/j.patrec.2020.05.021													
J								Binary spotted hyena optimizer and its application to feature selection	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Spotted hyena optimizer; Feature selection; Binary optimization problem; Metaheuristics	ALGORITHM; SEARCH	Spotted hyena optimizer (SHO) is a recently developed metaheuristic technique that mimics the hunting behavior of the spotted hyenas. However, it does not provide optimal solution for discrete problems. Therefore, a novel binary version of Spotted Hyena Optimizer is proposed in this paper. The binary version of SHO can deal with discrete optimization problems. In the proposed algorithm, tangent hyperbolic function is utilized to squash the continuous position and then these values are used to update the position of spotted hyenas. The prey searching, encircling, and attacking are three main steps of binary spotted hyena optimizer. The proposed algorithm has been compared with six well-known metaheuristic techniques over 29 benchmark test functions. The effects of convergence, scalability, and control parameters have been investigated. The statistical significance of the proposed approach has also been examined through ANOVA test. The proposed approach is also applied on feature selection domain. The performance of proposed approach has been compared with four well-known metaheuristic techniques over eleven UCI repository datasets. The experimental results reveal that the proposed approach is able to search the optimal feature set than the others.																	1868-5137	1868-5145				JUL	2020	11	7					2625	2645		10.1007/s12652-019-01324-z													
J								Fall detection system with portable camera	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Fall detection; Portable camera; Histogram of oriented gradient; Optical flow	ACCELEROMETRY; FEAR	The fall is one of the major problems that threaten the health of the elderly. According to world statistics, between 28 and 35% of seniors aged over 65 suffer from at least one fall per year. Continuous monitoring and rapid detection of critical events such as falls allows for rapid response and minimizes impacts. For this, several fall detection devices have been designed by the researchers. This paper proposes a fall detection device for elderly people at home using a portable camera worn on the hips to preserve privacy. The method of fall detection that we propose uses two image processing tools: The oriented gradient histogram (HOG) and the optical flow. The results of tests being carried on 14 subjects show that falls can be detected from standing, sitting or lying with a general sensitivity of 95%, from a set of data resulting from 20 tests, performed by each of the volunteers, for each of these three scenarios as well as for activities of daily living; the HOG-based method allowed the detection of falls but introduced many false detections which led to a specificity of 46.66%. The introduction of the optical flow has improved the specificity by reducing it to 68.33%. The system has been shown to be effective for rotations with a specificity increased by 50% over the use of HOG only. Also, the specificity has slightly increased for the events: sit down and lie down. However, this increase is accompanied by a decrease in sensitivity, since some falls are not detected by the optical flow, as the case of falls from an 'elongated' position.																	1868-5137	1868-5145				JUL	2020	11	7					2647	2659		10.1007/s12652-019-01326-x													
J								NextRoute: a lossless model for accurate mobility prediction	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobility prediction; Mobile computing; Lossless model; Compact prediction tree; Noise tolerance; Intelligent transportation systems	ROUTE PREDICTION; SEQUENTIAL PATTERNS; COMPRESSION; TRACKING	Mobility prediction of vehicles has become a key feature in mobility management in smart cities, mobile computing environments, intelligent transportation systems, vehicular networks, and location-based services. It has several important applications in traffic congestion forecasting, location-based routing protocol designs and targeting advertisements generation, etc. Mobility prediction (aka route prediction) consists of forecasting future routes to be traversed by a vehicle. Several models have been proposed for route prediction. These models are generally probabilistic models (e.g., Markov models) or data mining-based models (e.g., sequential rule-based models), and are trained with historical location data. Although these models were shown to perform well, one important drawback is that they are lossy. In other words, a large amount of information found in the location data is discarded by their training processes. Consequently, these models do not perform well for predicting routes where detailed information is required to perform accurate predictions. Besides, several prediction models assume the Markovian hypothesis that the next location of a user only depends on his/her current location and any previous movement of the user is ignored in prediction. This hypothesis has been employed, such as in Lian et al. (ACM Trans Intell Syst Technol 6:1-27,2015. 10.1145/2629557), as a simplifying assumption because it allows building models having a small size. However, this assumption is often unrealistic and thus greatly decreases the accuracy of route prediction. Moreover, these models are noise sensitive as they do not tolerate the smallest deviation in location data principally prone to several disturbances and uncertainty issues. To address these limitations, this paper introduces a novel route prediction model namedNextRoute. The proposed model is lossless as it compresses location data in a prediction tree without information loss, and it is designed to use all the relevant information contained in the training data to perform prediction. In contrast to some other proposals,NextRouteprovides efficient noise tolerance strategy that loosened the similarity measure when matching the current trajectory of vehicle with historical data. An extensive experimental evaluation was conducted with real-world and synthetic datasets providing quite encouraging results.																	1868-5137	1868-5145				JUL	2020	11	7					2661	2681		10.1007/s12652-019-01327-w													
J								Non-negative matrix factorization for implicit aspect identification	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Opinion mining; Aspect based sentiment analysis; Implicit aspect; Non-negative matrix factorization	CHINESE REVIEWS	Sentiment analysis, also named opinion mining, is an important task in e-commerce. Recent years, many researchers have been focused on fine-grained sentiment analysis. Aspect level opinion mining detects the detailed sentiments about features of products. However, current aspect identification methods mainly focus on extracting explicit appeared aspects. The task of implicit aspect identification is still a big challenge in sentiment analysis. In this paper, we propose a novel implicit aspect identification approach based on non-negative matrix factorization. The approach first clusters product aspects by combining the co-occurrence information with intra-relations of aspect and opinion words, which can enhance the performance of aspect clustering substantially. In the next step, the approach collects context information of aspects, and represents review sentences by word vectors. Finally, a classifier is constructed to identify and predict the target implicit aspects. We also prove the convergence of our approach. Experimental results demonstrate that our approach outperforms baseline methods in most cases.																	1868-5137	1868-5145				JUL	2020	11	7					2683	2699		10.1007/s12652-019-01328-9													
J								Classification approach for understanding implications of emotions using eye-gaze	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Autism; Virtual reality; Eye-tracking; Fixation duration; Pupil diameter; Blink rate; Classification; SVM	AUTISM; CHILDREN; RECOGNITION; PATTERNS; TRACKING; ADOLESCENTS; VALIDATION; THERAPY	Atypical behavioral viewing pattern is one of the core deficits of individuals with Autism Spectrum Disorder (ASD). This diminishes their ability to understand the communicator's facial emotional expression and often misinterpret one's intended emotion. Here, we investigated the feasibility of using one's gaze-related indices to estimate distinctive changes corresponding to various emotions. We designed a usability study with nine individuals with ASD and Typically Developing (TD) individuals who were exposed to Virtual Reality (VR) based social scenarios. The VR scenes presented virtual characters who narrated their social experience in the form of short stories with context-relevant emotional expressions. Simultaneously, we collected one's gaze-related physiological indices (PIs) and behavioral looking pattern indices (BIs) using a technologically-enhanced eye-tracker. Subsequently, these PIs and BIs were used to classify the implications of the emotional expressions both within and across the ASD and TD groups. Results of the usability study indicate that one's gaze-related indices can be discriminated with 97% accuracy for various emotions for intra-group analysis and 100% accuracy for inter-group analysis.																	1868-5137	1868-5145				JUL	2020	11	7					2701	2713		10.1007/s12652-019-01329-8													
J								A lightweight ANN based robust localization technique for rapid deployment of autonomous systems	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Localization; NLOS; LOS; Artificial neural network; Ultrasound; UWB		The capability to localize or identify position in the field of deployment is a primary requirement of future autonomous system in domains such as warehouse transportation, ambient-assisted living/ health care systems, search and rescue, motion monitoring, etc. Although reliable indoor localization in the order of few centimeters can be achieved with the existing localization systems in Line-of-Sight (LOS) conditions, the localization under Non-line-of-Sight (NLOS) conditions is an open area of research. In range-based localization systems, distance estimation is a pre-requisite for location estimation. Time of Arrival (ToA) is considered to be the most accurate technique for distance estimation when compared to Time Difference of Arrival (TDoA) or Received Signal Strength Indication (RSSI). Most of the work available as literature on indoor localization under NLOS conditions is based on the profiling of the indoor deployment area under various NLOS conditions and mitigating NLOS affected timestamps from the ToA measurements. However, it is not practically possible to obtain a comprehensive data set containing all possible conditions of NLOS in indoor environments. In this paper, an Artificial Neural Network based Location Estimation Unit (ANN-LEU) based scheme is proposed to estimate the two-dimensional (2-D) location of an object under LOS and NLOS conditions. One of the unique features of the novel location estimation scheme is that the training of the system is required to be performed only under LOS conditions, thus facilitating the quick deployment in new environments. The proposed ANN-LEU is robust as it identifies the presence of NLOS if any, in the ToA measurements and thus removing false position estimations if any. The Mean Average Error (MAE) error in position estimated during the performance analysis of the proposed system was restricted to lesser than 20 cm, if the object is in range of three beacons in LOS, and also for the scenarios in which one of the three beacon nodes are in NLOS. The proposed scheme eliminates false position identification. The proposed scheme requires lesser number of beacons for localization when compared to the available indoor localization systems, thus also improving the cost and energy efficiency.																	1868-5137	1868-5145				JUL	2020	11	7					2715	2730		10.1007/s12652-019-01331-0													
J								Spherical fuzzy Dombi aggregation operators and their application in group decision making problems	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING											MEAN OPERATORS; SETS	Spherical fuzzy sets (SFSs), recently proposed by Ashraf, is one of the most important concept to describe the fuzzy information in the process of decision making. In SFSs the sum of the squares of memberships grades lies in close unit interval and hence accommodate more uncertainties. Thus, this set outperforms over the existing structures of fuzzy sets. In real decision making problems, there is often a treat regarding a neutral character towards the membership and non-membership degrees expressed by the decision-makers. To get a fair decision during the process, in this paper, we define some new operational laws by Dombi t-norm and t-conorm. In the present study, we propose Spherical fuzzy Dombi weighted averaging (SFDWA), Spherical fuzzy Dombi ordered weighted averaging (SFDOWA), Spherical fuzzy Dombi hybrid weighted averaging (SFDHWA), Spherical fuzzy Dombi weighted geometric (SFDWG), Spherical fuzzy Dombi ordered weighted geometric (SFDOWG) and Spherical fuzzy Dombi hybrid weighted geometric (SFDHWG) aggregation operators and discuss several properties of these aggregation operators. These aforesaid operators are enormously used to help a successful solution of the decision problems. Then an algorithm by using spherical fuzzy set information in decision-making matrix is developed and applied the algorithm to decision-making problem to illustrate its applicability and effectiveness. Through this algorithm, we proved that our proposed approach is practical and provides decision makers a more mathematical insight before making decisions on their options. Besides this, a systematic comparison analysis with other existent methods is conducted to reveal the advantages of our method. Results indicate that the proposed method is suitable and effective for decision process to evaluate their best alternative.																	1868-5137	1868-5145				JUL	2020	11	7					2731	2749		10.1007/s12652-019-01333-y													
J								Enhancing coverage and connectivity using energy prediction method in underwater acoustic WSN	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										MUAWSN; Cluster head; WSN; Modified HH-DABRP; MCMC	WIRELESS SENSOR NETWORKS; PLACEMENT; ALGORITHM	In a mobile underwater acoustic wireless sensor networks (MUAWSN), one of the most important challenging issues is coverage and connectivity during data transmission. It is very difficult to access and cover the monitoring region due to less coverage in underwater environments. Various algorithms, strategies and mechanisms have been proposed by researchers around the world to solve these problems. A new approach is implemented in mobile underwater acoustic wireless sensor networks to enhance maximum coverage and connectivity of the cluster networks. In our proposed work, random cluster deployment of sensors in MUAWSN is used. The coverage hole problem is realistic in the MUAWSN due to node damage or active node count goes below the threshold limit. An energy prediction algorithm is proposed using Markov Chain Monte Carlo (MCMC) process which enhances the maximum coverage and connectivity during data transmission by analyzing the sample value of known parameter in water surface. The topology gets altered due to water mobility caused by several factors such as waves, winds, currents and network coverage and connectivity performance. In addition, to improve hop-by-hop dynamic address based (HH-DAB) Routing Protocol predicting energy consumption is re-framed as modified hop-by-hop dynamic address based (modified HH-DAB) Routing Protocol in which the random mobility of the node get stretched in 2-D space which leads to maximum coverage and connectivity in 3-D. Theoretical analysis and experimental simulation results are evaluated based on performance metrics such as residual energy consumption (REC), packet delivery ratio (PDR), network coverage ratio (NCR) and Network Lifetime. The results shows that the proposed Modified HH-DAB system has maximum residual energy consumption of 14.28%, maximum increase in packet delivery ratio of 50%, maximum increase in network coverage ratio of 50% and maximum increase in network lifetime of 50%. The results are encouraging and our proposed method is found to be more efficient than the HH-DAB protocol. The proposed protocols of modified HH-DAB mechanism improves coverage, connectivity and network lifetime.																	1868-5137	1868-5145				JUL	2020	11	7					2751	2760		10.1007/s12652-019-01334-x													
J								A sanitization approach for privacy preserving data mining on social distributed environment	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Service provider; Sanitization; Helper user; Optimal key; User data; Kernel k-means; Artificial bee colony	CLUSTERING-ALGORITHM; NETWORK; ANONYMIZATION; SELECTION; PROTOCOL	Data owners worry about their private data in the information that is being uncovered without authorization in the cloud computing environment. While applying privacy preserving methods to the data, the data owners attempt to retain the knowledge inside the data. One approach to solve this problem is the concept of distributed databases where different parties have horizontal or vertical partitions of the data. Cluster analysis is a frequently used data mining task which aims at decomposing or partitioning a usually multivariate data set into groups such that the data objects in one group are more similar to each other. While using encryption based kernel k-means algorithm, large data's can't be encrypted in the distributed environment. To extend the privacy concept, a novel method based Privacy Preserving Distributed Data Mining is planned. According to this, a sanitization approach will be developed to improve the privacy of the user data. In sanitization process, a privacy based objective function will be developed and an optimal key will be generated based on the proposed objective function. Here artificial bee colony algorithm will be utilized for optimal key generation and large amount of data can be encrypted. Once the sanitization process is done, the sanitized information will be updated to service provider by the helper user for each cluster. Finally, the experimentation will be carried out with existing database to prove the efficiency of the proposed algorithm. The implementation will be done in JAVA using cloud simulator. Extensive execution assessments and security analysis exhibit the legitimacy and efficiency of the proposed technique.																	1868-5137	1868-5145				JUL	2020	11	7					2761	2777		10.1007/s12652-019-01335-w													
J								Single rate based extended logarithmic multicast congestion control	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Congestion control; Single rate; Logarithmic multicast; Multicast communication		Due to increased demand for video data by heterogeneous Internet users, the demand of multicasting is increasing day by day. Multicasting is an efficient group communication technique, which is widely used in various applications such as bloggers, Internet group, forums, conferences, YouTube and online TV. Because of the heterogeneous nature of receivers, the network become congested that results in high packet loss, less throughput and reduced QoS. The multicast congestion control seems to be an effective solution to tackle the congestion issue in which the reception rate is adjusted according to the feedback of receivers. This paper provides a new congestion control scheme for multicast communication called Extended Logarithmic Increase and Multiplicative Decrease (ELIMD) to reduce packet loss, increase throughput, QoS and fairness during group communication. The entire research work is classified and elaborated in the key components namely architecture, newly designed equations, and flow charts. Experimental validation in NS-2.35 has affirmed the efficiency of the proposed scheme ELIMD against the existing schemes.																	1868-5137	1868-5145				JUL	2020	11	7					2779	2791		10.1007/s12652-019-01340-z													
J								A fog-based hybrid intelligent system for energy saving in smart buildings	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Ambient intelligence; Fuzzy systems; Fog computing; Energy efficiency	AMBIENT INTELLIGENCE; TABU SEARCH; FUZZY; INTERNET; PARADIGM; THINGS	In recent years, the widespread diffusion of pervasive sensing devices and the increasing need for reducing energy consumption have encouraged research in the energy-aware management of smart environments. Following this direction, this paper proposes a hybrid intelligent system which exploits a fog-based architecture to achieve energy efficiency in smart buildings. Our proposal combines reactive intelligence, for quick adaptation to the ever-changing environment, and deliberative intelligence, for performing complex learning and optimization. Such hybrid nature allows our system to be adaptive, by reacting in real time to relevant events occurring in the environment and, at the same time, to constantly improve its performance by learning users' needs. The effectiveness of our approach is validated in the application scenario of a smart home by extensive experiments on real sensor traces. Experimental results show that our system achieves substantial energy savings in the management of a smart environment, whilst satisfying users' needs and preferences.																	1868-5137	1868-5145				JUL	2020	11	7					2793	2807		10.1007/s12652-019-01375-2													
J								Unsupervised intelligent system based on one class support vector machine and Grey Wolf optimization for IoT botnet detection	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet of Things; Anomaly detection; Botnets; Feature selection; Intrusion detection system; Grey wolf optimization algorithm; Novelty detection; One class support vector machine	GAUSSIAN KERNEL; NETWORK; SELECTION; INTERNET	Recently, the number of Internet of Things (IoT) botnet attacks has increased tremendously due to the expansion of online IoT devices which can be easily compromised. Botnets are a common threat that takes advantage of the lack of basic security tools in IoT devices and can perform a series of Distributed Denial of Service (DDoS) attacks. Developing new methods to detect compromised IoT devices is urgent in order to mitigate the negative consequences of these IoT botnets since the existing IoT botnet detection methods still present some issues, such as, relying on labelled data, not being validated with newer botnets, and using very complex machine learning algorithms. Anomaly detection methods are promising for detecting IoT botnet attacks since the amount of available normal data is very large. One of the powerful algorithms that can be used for anomaly detection is One Class Support vector machine (OCSVM). The efficiency of the OCSVM algorithm depends on several factors that greatly affect the classification results such as the subset of features that are used for training OCSVM model, the kernel type, and its hyperparameters. In this paper, a new unsupervised evolutionary IoT botnet detection method is proposed. The main contribution of the proposed method is to detect IoT botnet attacks launched form compromised IoT devices by exploiting the efficiency of a recent swarm intelligence algorithm called Grey Wolf Optimization algorithm (GWO) to optimize the hyperparameters of the OCSVM and at the same time to find the features that best describe the IoT botnet problem. To prove the efficiency of the proposed method, its performance is evaluated using typical anomaly detection evaluation measures over a new version of a real benchmark dataset. The experimental results show that the proposed method outperforms all other algorithms in terms of true positive rate, false positive rate, and G-mean for all IoT device types. Also, it achieves the lowest detection time, while significantly reducing the number of selected features.																	1868-5137	1868-5145				JUL	2020	11	7					2809	2825		10.1007/s12652-019-01387-y													
J								eUASBP: enhanced user authentication scheme based on bilinear pairing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										BAN logic; Authentication; Bilinear pairing; Session key agreement	EFFICIENT AUTHENTICATION; SMART; SECURITY; LOGIC	One of the cryptographic services i.e., authentication is very essential for the servers to identify authorized users and to neglect unauthorized users. In this work, we have considered Awasthi's scheme and shown that the same scheme is vulnerable to several serious attacks. This paper not only describes the security pitfalls of Awasthi's scheme but also designs a new scheme using bilinear pairing to protect the system from existing security drawbacks with other attractive features like strong mutual authentication, smart card stolen threat protection. Strong security ofeUASBPis ensured through security analysis ofeUASBPbased on BAN logic.eUASBPreaches the BAN logic goals by the application of BAN rules. Our informal security analysis shows that proposedeUASBPprovides security against attacks possible with smart card based applications. In addition to thateUASBPprovides mutual authentication, session key agreement, and early wrong password detection. Bayat et al. authentication scheme also provides security against possible attacks of smart card based applications but doesn't support session key agreement and early wrong password detection. Computation cost ofeUASBPis less when compared with other authentication schemes. SinceeUASBPuses less number of bilinear operations when compared with other related authentication schemes. The performance analysis shows that our protocol is more secure in comparison with state of the art and also better in terms of storage, computation and communication overheads.																	1868-5137	1868-5145				JUL	2020	11	7					2827	2840		10.1007/s12652-019-01388-x													
J								C-tree: efficient cell-based indexing of indoor mobile objects	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Spatial; temporal databases; Indexing methods; Moving objects; Indoor spaces	MOVING-OBJECTS; QUERIES	With the increasing popularity of indoor positioning system technologies, many applications have become available that allow moving objects to be monitored and queried on the basis of their indoor locations. At the center of these applications is a data structure that is used for indexing the moving objects. For most of the current applications, the indexing is based on certain modifications of methods from the established research area of indexing objects moving in outdoor spaces. But the approach to indexing objects moving in indoor spaces should be more radically different. The nature of indoor spaces, which essentially consist of cells and connections between cells, and the concept of cell-based adjacency, as opposed to metric-based adjacency, require a significantly different focus and approach. In this paper, we present a cell-based index structure, which is called theC-tree('C' for 'cell'), for efficiently grouping and managing updates of moving objects in indoor spaces. The C-tree can efficiently serve indoor spatial queries, topological queries, adjacency queries and density-based queries. In addition, as shown in the paper, the density of indoor cells can play an important role in the performance of the index data structure. Taking cell density into account, we extend the application of the C-tree to construct what is called adensity-based index tree, which substantially improves the performance of the index structure when the indoor space contains high density cells.																	1868-5137	1868-5145				JUL	2020	11	7					2841	2857		10.1007/s12652-019-01397-w													
J								Scheme fuzzy approach to classify skin tonalities through geographic distribution	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Skin; Color model; Fuzzy logic; Geographic distribution	SEGMENTATION; RECOGNITION	One of the most significant current discussions in Computer Science is the skin recognition. Many papers have studied the skin detection using different techniques, artificial vision, machine learning, deep learning among others. Despite its long success, the skin recognition has several problems in use. However, there has been little discussion about generate a skin tonalities classification. The aim of this paper is to propose a system to skin tonalities through geographic distribution based on clustering algorithms, pattern recognition and fuzzy logic. This distribution gives us the opportunity to classify the skin tonalities. We can study each skin tonality for any applications as medical diagnosis, security. In the first stage, we use the RGB color model to training the system. Then, we tested the system with different color models. We use color model with the best result to propose geographic distribution based skin tonalities. The results show that is possible to generate a skin tonalities classification. The proposed system is using to skin recognition, showing interesting results under controlled and no controlled conditions.																	1868-5137	1868-5145				JUL	2020	11	7					2859	2870		10.1007/s12652-019-01400-4													
J								H-V scan and diagonal trajectory: accurate and low power localization algorithms in WSNs	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Wireless sensor networks; Mobile anchor node; Localization; Path planning	WIRELESS SENSOR NETWORKS; HYBRID; TOA	Obtaining the accurate location of the sensor nodes, which is known as the localization algorithm, is considered a significant issue in various applications of wireless sensor networks (WSNs). The present study introduced two anchor-based localization algorithms, namely, H-V scan and diagonal localization. These two algorithms are based on the received signal strength indicator (RSSI) and connectivity information, respectively. In addition, the diagonal algorithm relies on a diagonal trajectory in which the accuracy is improved while the consumed energy and localization time are decreased. Further, the H-V scan method benefits from collinearity and thus the location of the nodes is determined by the collinear position packets. Therefore, RWP, circle, LMAT, Z-curve, and H-curve methods, along with the proposed methods by Inet package of Omnetpp simulator were implemented for a fair comparison. The results indicated that in diagonal method accuracy improves about 1.2 times and consumed energy and localization time decrease about 65% compare to the best results of all the related studies. Furthermore, the results confirmed that the H-V scan which uses from collinearity concept, increases the accuracy about eight times.																	1868-5137	1868-5145				JUL	2020	11	7					2871	2882		10.1007/s12652-019-01406-y													
J								Collection and analysis of physiological data in smart environments: a systematic mapping	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Smart environments; Ubiquitous computing; E-health; Physiological data; Data analysis	GAMIFICATION; FRAMEWORK; DEVICES; CARE	In a world with an increasing population, an alternative for aiding healthcare systems is the use of sensors and wearable devices for monitoring patient physiological data. The analysis of collected data can help guide health services or the self-care of patients. This paper explores literature related to the collection and analysis of physiological data in smart environments by means of a systematic mapping study, organized in three steps: (1) identification of research questions; (2) elaboration of the search process; (3) definition of the criteria for filtering results. Papers were added using the snowball sampling method. This work encompassed 5870 papers published in the past 11 years, up to April 2019. The final selection resulted in 32 papers. Among these, 25 works collected cardiac data, 23 used Wi-Fi, Bluetooth, GSM, or ZigBee technologies, and 14 used techniques for the analysis of physiological data. Mapping verified the more prevalent trends and technologies in the collected and analyzed physiological data from smart environments. The filtering process allowed for a focus on communication technologies and vital sign data types. Three general questions (GQ), two specific questions (SQ), and two statistical questions (STQ) were answered. Similar reviews have already been conducted focusing on sensors, rather than collecting techniques and physiological data analysis. This denotes an opportunity for further studies in the vital sign analysis area.																	1868-5137	1868-5145				JUL	2020	11	7					2883	2897		10.1007/s12652-019-01409-9													
J								A generalization model for multi-record privacy preservation	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Privacy preservation; Data publication; Multi-record microdata; Generalization	ANONYMIZATION	Privacy preservation becomes a more and more serious problem in data publication, which has drawn dramatic attention in research and development. Recently, several privacy preservation models and algorithms have been proposed for publishing data. However, most of the previous methods suffer from more than one drawback as follows: (i) Could not be used on multi-record datasets. (ii) Only guarantee one-way generalization. (iii) User privacy preferences are ignored. In order to satisfy higher privacy requirements and make it suitable for multi-record publishing datasets, a bidirectional personalized generalization (BP-generalization) model is proposed as a new solution in this paper. The rational is to focus anonymous objects on both relational and set-valued information. First, we merge tuples with the same attribute values in multi-record datasets to ensure the validity of quasi-identifier anonymity. Second, by enforcingl-diversity on equivalence groups andk-anonymity on fingerprint buckets respectively, privacy preservation model may resist bi-directional chain attack. Finally, a new hierarchical generalization strategy is also proposed for personal privacy preservation of sensitive attributes, then different generalization rules can be adopted for different levels of sensitive values. Extensive experimental results on two datasets show that the performance of our method is better than state-of-art techniques in terms of efficiency and information loss.																	1868-5137	1868-5145				JUL	2020	11	7					2899	2912		10.1007/s12652-019-01430-y													
J								Research on image classification method of features of combinatorial convolution	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Image classification; Convolutional neural network; Combinatorial convolution; Weighted concatenation		In image classification, shallow convolutional features and deep convolutional features are not fully utilized by many network frameworks. To solve this problem, we propose a combinatorial convolutional network (CCNet) that integrates convolutional features of all levels. According to its own structure, the convolutional features of shallow, medium, and deep levels are extracted. These features are combined by weighted concatenation and convolutional fusion, and the coefficients of each channel of final combination feature are again weighted to improve the identification degree of features. CCNet can improve the single case where most network only add or concatenate shallow and deep features, so that the network can achieve lower classification error rate while generating low-dimensional features. Extensive experiments are performed on CIFAR-10 and CIFAR-100 respectively. The experimental results show that the low-dimensional image feature vectors generated by CCNet effectively reduce the classification error rate when the number of convolutional layers does not exceed 100 layers.																	1868-5137	1868-5145				JUL	2020	11	7					2913	2923		10.1007/s12652-019-01433-9													
J								Mining patient opinion to evaluate the service quality in healthcare: a deep-learning approach	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Online doctor reviews; Service quality; Sentiment analysis; Multimodal fusion; Deep learning	CONVOLUTIONAL NEURAL-NETWORKS; ONLINE DOCTOR REVIEWS; SENTIMENT ANALYSIS; PHYSICIAN; SATISFACTION; MODEL; CLASSIFICATION; IMPACT; CHINA	The emergence of social media has created several opportunities for patients to evaluate the quality of healthcare services by posting online reviews. The rich text and photographic information in the online reviews results insights into how patients' experience with the doctor and their satisfaction with healthcare service delivery. Various studies have performed patients' opinion analysis using textual contents. This study presents a novel multimodal approach to analyze the patients' sentiment regarding the quality of healthcare service delivery (high vs. low). In comparison with existing studies, we consider not only the unique textual contents but photographic contents as well from theYelp.complatform, which is more challenging due to feature extraction. We evaluate the performance of the baseline, and deep learning algorithms across textual cues, visual cues, and the fusion of both text and visual cues. Experimental results indicated that the addition of novel features increases the models' accuracy to 15.0% across text and visual cues. Furthermore, fusing text and visual contents improve the classification accuracy by at least 12.64% instead of considering the contents alone. Preliminary comparative experiments result show that the deep learning model outperformed all other algorithms. In comparison with several other state-of-the-art methods in the biomedical domain, the proposed model could significantly enhance the performance of the classifier indicating the effectiveness and suitability of the methodology.																	1868-5137	1868-5145				JUL	2020	11	7					2925	2942		10.1007/s12652-019-01434-8													
J								Correlation coefficients of dual hesitant fuzzy sets and their application in engineering management	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Engineering management; Decision making; Dual hesitant fuzzy set; Correlation coefficient; Shapley function	GROUP DECISION-MAKING	Engineering management plays an important role in the socio-economic field, where complex and uncertain factors usually exist. Dual hesitant fuzzy sets (DHFSs) are powerful tools to denote the decision makers' uncertain and hesitant preferences. Correlation measures and correlation coefficients are two important types of indices in decision making. This paper focuses on correlation measures and correlation coefficients for DHFSs and their application in engineering management. To do this, two dual hesitant fuzzy correlation coefficients are defined, and their properties are studied. Considering the situation where interactive characteristics among elements exist, two Shapley correlation coefficients are defined. When the weighting information is incompletely known, models for the optimal two-additive measures are built. Then, an algorithm to clustering analysis and decision making with incomplete weighting information and interactive characteristics are presented, respectively. Two corresponding examples about real estate investment and engineering cost management are offered to demonstrate the application of the approaches.																	1868-5137	1868-5145				JUL	2020	11	7					2943	2961		10.1007/s12652-019-01435-7													
J								A RESTful middleware for AI controlled sensors, actuators and smart devices	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet of things; Sensor networks; Smart devices; Artificial intelligence; Middleware; RESTful API	DISCOVERY; NETWORKS; WEB	The numerous applications of internet of things (IoT) and sensor networks combined with specialized devices used in each has led to a proliferation of domain specific middleware, which in turn creates interoperability issues between the corresponding architectures and the technologies used. But what if we wanted to use a machine learning algorithm to an IoT application so that it adapts intelligently to changes of the environment, or enable a software agent to enrich with artificial intelligence (AI) a smart home consisting of multiple and possibly incompatible technologies? In this work we answer these questions by studying a framework that explores how to simplify the incorporation of AI capabilities to existing sensor-actuator networks or IoT infrastructures making the services offered in such settings smarter. Towards this goal we present eVATAR+, a middleware that implements the interactions within the context of such integrations systematically and transparently from the developers' perspective. It also provides a simple and easy to use interface for developers to use. eVATAR+ uses JAVA server technologies enhanced by mediator functionality providing interoperability, maintainability and heterogeneity support. We exemplify eVATAR+ with a concrete case study and we evaluate the relative merits of our approach by comparing our work with the current state of the art.																	1868-5137	1868-5145				JUL	2020	11	7					2963	2986		10.1007/s12652-019-01439-3													
J								Prediction of electrical power disturbances using machine learning techniques	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Electrical power disturbances; Machine learning techniques; Features selection; Classification	ANT COLONY OPTIMIZATION; CASCADING FAILURE; LOGISTIC-REGRESSION; ALGORITHMS	Electrical power disturbances have negative social, economic, and political impacts. They can lead to catastrophic results that may end with blackouts. Increased understanding, analysis, and prediction of electrical disturbances can help to avoid the occurrence of major disturbances or at least to limit their consequences. This paper develops a system that predicts the type of electrical disturbances using machine learning techniques (MLTs). The proposed system is used for features selection and classification of an open source electrical disturbances dataset available online. Ant colony optimization is used for the features selection and 5 MLTs are adopted for classification; k-nearest neighbor, artificial neural networks, decision tree, logistic regression, and naive bayes. The findings and results showed that the proposed system has the ability to efficiently classify electrical disturbances with a classification accuracy ranging from 74.57 to 86.11% depending on the classifier used.																	1868-5137	1868-5145				JUL	2020	11	7					2987	3003		10.1007/s12652-019-01440-w													
J								Local P2P group (LPG) communication in structured mobile P2P networks	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Local P2P group; Mobile P2P networks; Mobility pattern; LPG table	PROTOCOL; CHORD	With the onset of the digital era and the availability of the internet, the need for digital data in a huge manner can be fulfilled by peer-to-peer (P2P) network instead of a traditional client server-based solution. Generally, mobile communication is based on cellular networks or multi-hop wireless networks. Cellular networks have adequate fixed infrastructure whereas multi-hop wireless networks have limited infrastructure and hence there are many limitations. The P2P systems are mainly designed for wired networks and the routing is based on IP infrastructure. Chord based protocols are widely deployed in the structured P2P networks but it can not perform well when implemented for mobile P2P networks due to the mobility of the users. Mobility pattern of mobile users plays an important role in locating users and delivering data packets seamlessly. Today, many of the mobile users follow a fixed mobility pattern in urban cities and mobility pattern of the mobile users can be utilized to reduce table update cost and increase Lookup Success Rate (LSR). We have proposed Local P2P Group (LPG) based communication scheme for structured mobile P2P networks. We are focussed on the mobility pattern of the mobile users in urban cities. We have analytically evaluated the proposed scheme using fluid-flow and RWP (Random Waypoint) mobility models and found that the proposed scheme performs better than the existing schemes like MR-Chord and MobiStore. Our proposed scheme has up to 40% higher Lookup Success Rate and 81% less table update cost than existing schemes, MR-Chord and MobiStore.																	1868-5137	1868-5145				JUL	2020	11	7					3005	3019		10.1007/s12652-019-01442-8													
J								Neutrality operations-based Pythagorean fuzzy aggregation operators and its applications to multiple attribute group decision-making process	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Pythagorean fuzzy sets; Neutrality operations; Aggregation operators; Multi attribute group decision making	MEMBERSHIP GRADES; SOFT SETS; LAWS; EXTENSION; NUMBERS; TOPSIS	Pythagorean fuzzy sets accommodate more uncertainties than the intuitionistic fuzzy sets and hence it is one of the most important concepts to describe the fuzzy information in the process of decision making. Under this environment, the main objective of the work is to develop some new operational laws and their corresponding weighted aggregation operators. For it, we define some new neutral addition and scalar multiplication operational laws by incorporating the features of a neutral character towards the membership degrees of the set and the probability sum. Some properties of the proposed laws are investigated. Then, associated with these operational laws, we define some novel Pythagorean fuzzy weighted, ordered weighted and hybrid neutral averaging aggregation operators for Pythagorean fuzzy information, which can neutrally treat the membership and non-membership degrees. The various relations and the characteristics of the proposed operators are discussed. Further, in order to ease with the possible application, we present an algorithm to solve the multiple attribute group decision-making problems under the Pythagorean fuzzy environment. Finally, a practical example is provided to illustrate the approach and show its superiority, advantages by comparing their performance with some several existing approaches.																	1868-5137	1868-5145				JUL	2020	11	7					3021	3041		10.1007/s12652-019-01448-2													
J								Multi-depth dilated network for fashion landmark detection with batch-level online hard keypoint mining	IMAGE AND VISION COMPUTING										Fashion landmark detection; Convolutional neural network; Deep learning		Deep learning has been applied to fashion landmark detection in recent years, and great progress has been made. However, the detection of hard keypoints, such as those which are occluded or invisible, remains challenging and must be addressed. To tackle this problem, in the feature exaction level a novel Multi-Depth Dilated (MDD) block which is composed of different numbers of dilated convolutions in parallel and a Multi-Depth Dilated Network (MDDNet) constructed by MDD blocks are proposed in this paper, and in the training level a network training method of Batch-level Online Hard Keypoint Mining (B-OHKM) is proposed. During the training of network, each clothing keypoint is one-to-one corresponding to the related loss value calculated at that keypoint. The greater the loss of the keypoint, the more difficult it is for the network to detect that keypoint. In that way, hard keypoints can be effectively mined, so that the network can be trained in a targeted manner to improve the performance of hard keypoints. The results of experiments on two large-scale fashion benchmark datasets demonstrate that the proposed MDDNet that uses the MDD block and B-OHKM method achieves state-of-the-art results. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103930	10.1016/j.imavis.2020.103930													
J								Zero-sum game theory model for segmenting skin regions	IMAGE AND VISION COMPUTING										Skin detection; Color; Texture; Zero-sum game; Nash Equilibrium	CLASSIFICATION; IMAGES	This paper presents a new method for skin region segmentation based on a zero-sum game theory model which exploits the opposite classifications of an image region by different skin detectors. In fact, these regions are considered conflict areas between two players (skin and non-skin) and skin detectors are considered strategies. An appropriate utility function is then defined. The computation of the saddle point (The Nash equilibrium) in the mixed extension of the proposed zero-sum game allows classifying effectively the conflict areas and so reducing the false positive skin detection. Experiments were conducted on three publicaily available databases using four selected skin detectors based on skin color information, skin-texture cues and employ rule-based or neural networks. The results show that the proposed method outperforms the existing skin segmentation approaches in reducing the false positive rates and obtains promising results in the skin segmentation performance. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103925	10.1016/j.imavis.2020.103925													
J								Class-aware domain adaptation for improving adversarial robustness	IMAGE AND VISION COMPUTING										Domain adaptation; Adversarial robustness		Recent works have demonstrated convolutional neural networks are vulnerable to adversarial examples, i.e., inputs to machine learning models that an attacker has intentionally designed to cause the models to make a mistake. To improve the adversarial robustness of neural networks, adversarial training has been proposed to train networks by injecting adversarial examples into the training data. However, adversarial training could overfit to a specific type of adversarial attack and also lead to standard accuracy drop on clean images. To this end, we propose a novel Class-Aware Domain Adaptation (CADA) method for adversarial defense without directly applying adversarial training. Specifically, we propose to learn domain-invariant features for adversarial examples and dean images via a domain discriminator. Furthermore, we introduce a class-aware component into the discriminator to increase the discriminative power of the network for adversarial examples. We evaluate our newly proposed approach using multiple benchmark datasets. The results demonstrate that our method can significantly improve the state-of-the-art of adversarial robustness for various attacks and maintain high performances on clean images. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103926	10.1016/j.imavis.2020.103926													
J								Learning rebalanced human parsing model from imbalanced datasets	IMAGE AND VISION COMPUTING										Human parsing; Semantic segmentation; Imbalanced datasets	SEGMENTATION	Research on human parsing methods has attracted increasing attention in a wide range of applications. However, dataset imbalance is still a challenging problem in this task, which directly affects the performance of human parsing. There are different types of dataset imbalance problems. For example, the numbers of samples for various labels in a dataset may differ, the scales of objects identified by different labels may vary considerably, the differences between some heterogeneous label types may be much smaller than other cases, and in some extreme situations, images may be labeled incorrectly. In this paper, we propose a rebalanced model for imbalanced human parsing. Two innovative blocks are included in the model, i.e., a pre-bilateral awareness block and a combined-order statistics awareness block. The function of the former is to leverage the multiscale feature extractors to capture the changing scale information in an efficient way from the spatial space. Meanwhile, the function of the latter is to exploit the information of the feature distributions from the channel space. Furthermore. we propose an imbalance data-drop algorithm to simultaneously solve the mislabeling and small sample label weighting problems. Extensive experiments are conducted on three datasets, and the experimental results demonstrate that our method is able to solve the problem of data imbalance efficiently and obtain better human parsing performance. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103928	10.1016/j.imavis.2020.103928													
J								Cross-resolution learning for Face Recognition	IMAGE AND VISION COMPUTING										Deep learning; Low resolution Face Recognition; Cross resolution Face Recognition		Convolutional Neural Network models have reached extremely high performance on the Face Recognition task. Mostly used datasets, such as VGGFace2, focus on gender, pose, and age variations, in the attempt of balancing them to empower models to better generalize to unseen data. Nevertheless, image resolution variability is not usually discussed, which may lead to a resizing of 256 pixels. While specific datasets for very low-resolution faces have been proposed, less attention has been paid on the task of cross-resolution matching. Hence, the discrimination power of a neural network might seriously degrade in such a scenario. Surveillance systems and forensic applications are particularly susceptible to this problem since, in these cases, it is common that a low-resolution query has to be matched against higher-resolution galleries. Although it is always possible to either increase the resolution of the query image or to reduce the size of the gallery (less frequently), to the best of our knowledge, extensive experimentation of cross-resolution matching was missing in the recent deep learning-based literature. In the context of low- and cross-resolution Face Recognition, the contribution of our work is fourfold: i) we proposed a training procedure to fine-tune a state-of-the-art model to empower it to extract resolution-robust deep features; ii) we conducted an extensive test campaign by using high-resolution datasets (IJB-B and IJB-C) and surveillance-camera-quality datasets (QMUL-SurvFace, TinyFace, and SCface) showing the effectiveness of our algorithm to train a resolution-robust model; iii) even though our main focus was the cross-resolution Face Recognition, by using our training algorithm we also improved upon state-of-the-art model performances considering low-resolution matches; iv) we showed that our approach could be more effective concerning preprocessing faces with super-resolution techniques. The python code of the proposed method will be available at https://github.com/fvmassoli/cross-resolution-face-recognition. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103927	10.1016/j.imavis.2020.103927													
J								Dense convolutional feature histograms for robust visual object tracking	IMAGE AND VISION COMPUTING										Object Tracking; Deep Learning; Bag-of-Features; Convolutional Feature Histograms	NETWORKS	Despite recent breakthroughs in the field, Visual Object Tracking remains an open and challenging task in Computer Vision. Modern applications require trackers to not only be accurate but also very last, even on embedded systems. In this work, we use features from Convolutional Neural Networks to build histograms, which are more adept at handling appearance variations, in an end-to-end trainable architecture. To deal with the internal covariate shift that occurs when extracting histograms from convolutional features as well as to incorporate informations from the multiple levels of the neural hierarchy, we propose and use a novel densely connected architecture where histograms from multiple layers are concatenated to produce the final representation. Experimental results validate our hypotheses on the benefits of using histograms as opposed to standard convolutional features, as the proposed histogram-based tracker surpasses recently proposed sophisticated trackers on multiple benchmarks. Long-term tracking results also reaffirm the usefulness of the proposed tracker in more challenging scenarios, where appearance variations are more severe and traditional trackers fail. (C) 2020 Elsevier B.V. All rights reserved.																	0262-8856	1872-8138				JUL	2020	99								103933	10.1016/j.imavis.2020.103933													
J								Discriminative common feature subspace learning for age-invariant face recognition	IET BIOMETRICS										face recognition; learning (artificial intelligence); image representation; distance measure; age variations; age-invariant face recognition; human ageing; discriminative common feature subspace learning; cross-age face recognition methods; CACD database; FG-Net database; Fisher criterion; feature representation	REGRESSION; POSE	Considering human ageing has a big impact on cross-age face recognition, and the effect of ageing on face recognition in non-ideal images has not been well addressed yet. In this study, the authors propose a discriminative common feature subspace learning method to deal with the problem. Specifically, they consider the samples of the same individual with big age gaps have different distributions in the original space, and employ the maximum mean discrepancy as the distance measure to compute the distances between the sample means of the different distributions. Then the distance measure is integrated into Fisher criterion to learn a discriminative common feature subspace. The aim is to map the images with different ages to the common subspace, and to construct new feature representation which is robust to age variations and discriminative to different subjects. To evaluate the performance of the proposed method on cross-age face recognition, the authors construct extensive experiments on CACD and FG-Net databases. Experimental results show that the proposed method outperforms other subspace based methods and state-of-art cross-age face recognition methods.																	2047-4938	2047-4946				JUL	2020	9	4					136	142		10.1049/iet-bmt.2019.0104													
J								Palmprint recognition using state-of-the-art local texture descriptors: a comparative study	IET BIOMETRICS										image classification; palmprint recognition; image texture; biometric fields; local binary pattern methods; feature extraction techniques; nonLBP texture methods; palmprint recognition problem; unconstrained challenging palmprint databases; local texture descriptor testing; Wilcoxon signed-rank testing	FACIAL IMAGE RECOGNITION; BINARY PATTERNS; FACE RECOGNITION; QUADRUPLE PATTERN; NUMBER PATTERN; CLASSIFICATION; SYSTEM; LBP; EXTRACTION; RETRIEVAL	Several human being traits can be used as a robust and distinctive identifier for a given person. The palm region of the hand is one of these features that researchers in biometric fields have given a huge consideration in recent years. Many works have been proposed in the literature to design palmprint (an image acquired of the palm region) recognition framework. Extraction of prominent image local features is a critical module in most of these approaches. Local Binary Patterns (LBP) like methods, have emerged as one of the most effective feature extraction techniques. Despite a period of remarkable evolution, neither extensive and comprehensive evaluation nor comparison has been performed to date on a large number of LBP variants and non-LBP texture methods in palmprint recognition problem. Motivated by this, this paper aims to fill that gap and provide a comprehensive comparative study of the performance of a large number of recent texture descriptors in palmprint recognition. Extensive experimental results on the well-known constrained and unconstrained challenging palmprint databases, indicate that a number of tested local texture descriptors, which are evaluated for the first time on palmprint recognition, achieve promising results. Classification results are statistically compared through Wilcoxon signed rank test.																	2047-4938	2047-4946				JUL	2020	9	4					143	153		10.1049/iet-bmt.2019.0103													
J								PRNU-based detection of facial retouching	IET BIOMETRICS										face recognition; biometrics (access control); image coding; object detection; PRNU-based detection; facial retouching; facial images; facial appearance; retouching algorithms; face recognition technologies; robust face recognition; retouching detection system; antiphotoshop legislations; beautification applications; beautified face images; biometric performance; photo response nonuniformity; JPEG compression	FACE RECOGNITION	Nowadays, many facial images are acquired using smart phones. To ensure the best outcome, users frequently retouch these images before sharing them, e.g. via social media. Modifications resulting from used retouching algorithms might be a challenge for face recognition technologies. Towards deploying robust face recognition as well as enforcing anti-photoshop legislations, a reliable detection of retouched face images is needed. In this work, the effects of facial retouching on face recognition are investigated. A qualitative assessment of 32 beautification apps is conducted. Based on this assessment five apps are chosen which are used to create a database of 800 beautified face images. Biometric performance is measured before and after retouching using a commercial face recognition system. Subsequently, a retouching detection system based on the analysis of photo response non-uniformity (PRNU) is presented. Specifically, scores obtained from analysing spatial and spectral features extracted from PRNU patterns across image cells are fused. In a scenario, in which unaltered bona fide images are compressed to the average sizes of the retouched images using JPEG, the proposed PRNU-based detection scheme is shown to robustly distinguish between bona fide and retouched images achieving an average detection equal error rate of 13.7% across all retouching algorithms.																	2047-4938	2047-4946				JUL	2020	9	4					154	164		10.1049/iet-bmt.2019.0196													
J								BMIAE: blockchain-based multi-instance Iris authentication using additive ElGamal homomorphic encryption	IET BIOMETRICS										biometrics (access control); authorisation; cryptography; iris recognition; feature extraction; data privacy; image matching; system vulnerability; novel multiinstance iris authentication system; BMIAE; untrusted server; iris templates; expensive storage; SDUMLA-HMT iris databases; centralised server; additive ElGamal homomorphic encryption; multibiometric systems; unimodal systems; biometric templates; privacy concerns; biometric authentication systems; blockchain-based multiinstance iris authentication; transmission channel; smart contract; CASIA-V3-Interval; IITD iris databases	GENERATION; SYSTEMS; SECURE	Multi-biometric systems have been widely accepted in various applications due to its capability to solve the limitations of unimodal systems. Directly storing the biometric templates into a centralised server leads to privacy concerns. In the past few years, many biometric authentication systems based on homomorphic encryption have been introduced to provide security for the templates. Most of the existing solutions rely on an implication of the assumption that the server is 'honest-but-curious'. Therefore, the compromise of server results into the entire system vulnerability and fails to provide the integrity. To address this, we propose a novel multi-instance iris authentication system, BMIAE to deal with malicious attacks over the transmission channel and at the untrusted server. BMIAE encrypt the iris templates using ElGamal encryption to guarantee confidentiality and Smart contract running on a Blockchain helps to achieve the integrity of templates and matching result. BMIAE also addresses the limitations of using Blockchain for biometrics like privacy and expensive storage. To check the effectiveness and robustness, BMIAE has experimented on CASIA-V3-Interval, IITD and SDUMLA-HMT iris databases. Experimental results show that BMIAE provides improved accuracy, and eliminates the need to trust the centralised server when compared to the state-of-the-art approaches.																	2047-4938	2047-4946				JUL	2020	9	4					165	177		10.1049/iet-bmt.2019.0169													
J								Heterogeneous Synaptic Weighting Improves Neural Coding in the Presence of Common Noise	NEURAL COMPUTATION											FISHER INFORMATION; MUTUAL INFORMATION; POPULATION; VARIABILITY; CONNECTIVITY; CONTRIBUTE; DISCHARGE; INFERENCE; ACCURACY; MODELS	Simultaneous recordings from the cortex have revealed that neural activity is highly variable and that some variability is shared across neurons in a population. Further experimental work has demonstrated that the shared component of a neuronal population's variability is typically comparable to or larger than its private component. Meanwhile, an abundance of theoretical work has assessed the impact that shared variability has on a population code. For example, shared input noise is understood to have a detrimental impact on a neural population's coding fidelity. However, other contributions to variability, such as common noise, can also play a role in shaping correlated variability. We present a network of linear-nonlinear neurons in which we introduce a common noise input to model-for instance, variability resulting from upstream action potentials that are irrelevant to the task at hand. We show that by applying a heterogeneous set of synaptic weights to the neural inputs carrying the common noise, the network can improve its coding ability as measured by both Fisher information and Shannon mutual information, even in cases where this results in amplification of the common noise. With a broad and heterogeneous distribution of synaptic weights, a population of neurons can remove the harmful effects imposed by afferents that are uninformative about a stimulus. We demonstrate that some nonlinear networks benefit from weight diversification up to a certain population size, above which the drawbacks from amplified noise dominate over the benefits of diversification. We further characterize these benefits in terms of the relative strength of shared and private variability sources. Finally, we studied the asymptotic behavior of the mutual information and Fisher information analytically in our various networks as a function of population size. We find some surprising qualitative changes in the asymptotic behavior as we make seemingly minor changes in the synaptic weight distributions.																	0899-7667	1530-888X				JUL	2020	32	7					1239	1276		10.1162/neco_a_01287													
J								A Model for the Study of the Increase in Stimulus and Change Point Detection with Small and Variable Spiking Delays	NEURAL COMPUTATION											INFORMATION; NEURONS; INTEGRATION; TIME; CODE	Precise timing of spikes between different neurons has been found to convey reliable information beyond the spike count. In contrast, the role of small and variable spiking delays, as reported, for example, in the visual cortex, remains largely unclear. This issue becomes particularly important considering the high speed of neuronal information processing, which is assumed to be based on only a few milliseconds within each processing step. We investigate the role of small and variable spiking delays with a parsimonious stochastic spiking model that is strongly motivated by experimental observations. The model contains only two parameters for the response of a neuron to one stimulus, describing directly the rate and the delay, or phase. Within the theoretical model, we specifically investigate two quantities, the probability of correct stimulus detection and the probability of correct change point detection, as a function of these parameters and within short periods of time. Optimal combinations of the two parameters across stimuli are derived that maximize these probabilities and enable comparison of pure rate, pure phase, and combined codes. In particular, the gain in correct detection probability when adding small and variable spiking delays to pure rate coding increases with the number of stimuli. More interesting, small and variable spiking delays can considerably improve the process of detecting changes in the stimulus, while also decreasing the probability of false alarms and thus increasing robustness and speed of change point detection. The results are compared to empirical spike train recordings of neurons in the visual cortex reported earlier in response to a number of visual stimuli. The results suggest that near-optimal combinations of rate and phase parameters may be implemented in the brain and that adding phase information could particularly increase the quality of change point detection in cases of highly similar stimuli.																	0899-7667	1530-888X				JUL	2020	32	7					1277	1321		10.1162/neco_a_01285													
J								A Mathematical Analysis of Memory Lifetime in a Simple Network Model of Memory	NEURAL COMPUTATION											NEURAL-NETWORKS; CAPACITY	We study the learning of an external signal by a neural network and the time to forget it when this network is submitted to noise. The presentation of an external stimulus to the recurrent network of binary neurons may change the state of the synapses. Multiple presentations of a unique signal lead to its learning. Then, during the forgetting time, the presentation of other signals (noise) may also modify the synaptic weights. We construct an estimator of the initial signal using the synaptic currents and in this way define a probability of error. In our model, these synaptic currents evolve as Markov chains. We study the dynamics of these Markov chains and obtain a lower bound on the number of external stimuli that the network can receive before the initial signal is considered forgotten (probability of error above a given threshold). Our results are based on a finite-time analysis rather than large-time asymptotic. We finally present numerical illustrations of our results.																	0899-7667	1530-888X				JUL	2020	32	7					1322	1354		10.1162/neco_a_01286													
J								Shapley Homology: Topological Analysis of Sample Influence for Neural Networks	NEURAL COMPUTATION											PERSISTENT HOMOLOGY	Data samples collected for training machine learning models are typically assumed to be independent and identically distributed (i.i.d.). Recent research has demonstrated that this assumption can be problematic as it simplifies the manifold of structured data. This has motivated different research areas such as data poisoning, model improvement, and explanation of machine learning models. In this work, we study the influence of a sample on determining the intrinsic topological features of its underlying manifold. We propose the Shapley homology framework, which provides a quantitative metric for the influence of a sample of the homology of a simplicial complex. Our proposed framework consists of two main parts: homology analysis, where we compute the Betti number of the target topological space, and Shapley value calculation, where we decompose the topological features of a complex built from data points to individual points. By interpreting the influence as a probability measure, we further define an entropy that reflects the complexity of the data manifold. Furthermore, we provide a preliminary discussion of the connection of the Shapley homology to the Vapnik-Chervonenkis dimension. Empirical studies show that when the zero-dimensional Shapley homology is used on neighboring graphs, samples with higher influence scores have a greater impact on the accuracy of neural networks that determine graph connectivity and on several regular grammars whose higher entropy values imply greater difficulty in being learned.																	0899-7667	1530-888X				JUL	2020	32	7					1355	1378		10.1162/neco_a_01289													
J								Generation of Scale-Invariant Sequential Activity in Linear Recurrent Networks	NEURAL COMPUTATION											TIME CELLS; MEMORY TRACES; CORTEX; REPRESENTATION; INFORMATION; CONSTANTS; SEQUENCES; MODEL	Sequential neural activity has been observed in many parts of the brain and has been proposed as a neural mechanism for memory. The natural world expresses temporal relationships at a wide range of scales. Because we cannot know the relevant scales a priori, it is desirable that memory, and thus the generated sequences, is scale invariant. Although recurrent neural network models have been proposed as a mechanism for generating sequences, the requirements for scale-invariant sequences are not known. This letter reports the constraints that enable a linear recurrent neural network model to generate scale-invariant sequential activity. A straightforward eigendecomposition analysis results in two independent conditions that are required for scale invariance for connectivity matrices with real, distinct eigenvalues. First, the eigenvalues of the network must be geometrically spaced. Second, the eigenvectors must be related to one another via translation. These constraints are easily generalizable for matrices that have complex and distinct eigenvalues. Analogous albeit less compact constraints hold for matrices with degenerate eigenvalues. These constraints, along with considerations on initial conditions, provide a general recipe to build linear recurrent neural networks that support scale-invariant sequential activity.																	0899-7667	1530-888X				JUL	2020	32	7					1379	1407		10.1162/neco_a_01288													
J								Minimal Spiking Neuron for Solving Multilabel Classification Tasks	NEURAL COMPUTATION											NETWORKS; MODEL	The multispike tempotron (MST) is a powersul, single spiking neuron model that can solve complex supervised classification tasks. It is also internally complex, computationally expensive to evaluate, and unsuitable for neuromorphic hardware. Here we aim to understand whether it is possible to simplify the MST model while retaining its ability to learn and process information. To this end, we introduce a family of generalized neuron models (GNMs) that are a special case of the spike response model and much simpler and cheaper to simulate than the MST. We find that over a wide range of parameters, the GNM can learn at least as well as the MST does. We identify the temporal autocorrelation of the membrane potential as the most important ingredient of the GNM that enables it to classify multiple spatiotemporal patterns. We also interpret the GNM as a chemical system, thus conceptually bridging computation by neural networks with molecular information processing. We conclude the letter by proposing alternative training approaches for the GNM, including error trace learning and error backpropagation.																	0899-7667	1530-888X				JUL	2020	32	7					1408	1429		10.1162/neco_a_01290													
J								Explaining versus describing human decisions: Hilbert space structures in decision theory	SOFT COMPUTING										Quantum structures; Cognitive science; Decision theory; Ellsberg paradox; Operational realism	QUANTUM; AMBIGUITY; RISK	Despite the impressive success of quantum structures to model long-standing human judgement and decision puzzles, thequantum cognition research programmestill faces challenges about its explanatory power. Indeed, quantum models introduce new parameters, which may fit empirical data without necessarily explaining them. Also, one wonders whether more general non-classical structures are better equipped to model cognitive phenomena. In this paper, we provide arealistic-operational foundation of decision processesusing a known decision-making puzzle, theEllsberg paradox, as a case study. Then, we elaborate a novel representation of the Ellsberg decision situation applying standard quantum correspondence rules which map realistic-operational entities into quantum mathematical terms. This result opens the way towards an independent, foundational, rather than phenomenological, motivation for a general use of quantum Hilbert space structures in human cognition.																	1432-7643	1433-7479				JUL	2020	24	14					10219	10229		10.1007/s00500-019-04140-x													
J								Violation of CHSH inequality and marginal laws in mixed sequential measurements with order effects	SOFT COMPUTING										Bell's inequalities; Tsirelson's bound; Marginal laws; No-signaling conditions; Order effects		We model a typical Bell-test experimental situation by considering that Alice and Bob perform incompatible measurements in a sequential way, with mixed orders of execution. After emphasizing that order effects will generally produce a violation of the marginal laws, we derive an upper limit for the observed correlations. More precisely, when Alice's and Bob'smeasurements are compatible, the marginal laws are obeyed and Tsirelson's bound limits the quantum correlations in the Bell-CHSH inequality to 2v 2. On the other hand, when Alice and Bob perform incompatible mixed sequential measurements, the marginal laws are typically violated and the upper limit for the correlations is pushed up to 2v 3. Considering that significant violations of the marginal laws (also called no-signaling conditions) have been observed in the data of numerous Bell-test experiments, the present analysis provides a possible mechanism for their appearance, when the protocols are such that Alice's and Bob's measurements can be assumed to be performed in a mixed sequential way. We, however, emphasize that this does not imply that a communication with superluminal effective speed would be possible.																	1432-7643	1433-7479				JUL	2020	24	14					10231	10238		10.1007/s00500-019-04186-x													
J								An equational theory for sigma\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sigma $$\end{document}-complete orthomodular lattices	SOFT COMPUTING										sigma-Complete orthomodular lattices; Infinitary operations; Hilbert style calculus		The condition of s-completeness related to orthomodular lattices places an important role in the study of quantum probability theory. In the framework of algebras with infinitary operations, an equational theory for the category of s-complete orthomodular lattices is given. In this structure, we study the congruences theory and directly irreducible algebras establishing an equational completeness theorem. Finally, a Hilbert style calculus related to s-complete orthomodular lattices is introduced and a completeness theorem is obtained.																	1432-7643	1433-7479				JUL	2020	24	14					10257	10264		10.1007/s00500-019-04510-5													
J								How images combine meaning: quantum entanglement in visual perception	SOFT COMPUTING										CHSH inequality; Quantum structures; Visual perception; Meaning connection		Various empirical tests performed on human participants and also by means of search engines on the Web reveal that, whenever the conceptual combinationThe Animal Actsis considered as a combination of the individual conceptsAnimalandActs, the 'Clauser-Horne-Shimony-Holt' version of Bell's inequalities ('CHSH inequality') is violated. We work out in this paper a quantum representation in Hilbert space for a dataset collected on the same combination of concepts using 'Google Images' as search engine, which 'significantly violated' the CHSH inequality. This result proves the existence of non-classical structures in visual perception and strongly indicates the presence of 'quantum entanglement' as an explanation for the meaning connection between the component concepts, also when this meaning connection is expressed through images.																	1432-7643	1433-7479				JUL	2020	24	14					10277	10286		10.1007/s00500-020-04692-3													
J								A new method to predict the interference effect in quantum-like Bayesian networks	SOFT COMPUTING										Bayesian networks; Quantum decision making; Prisoner's dilemma game; Sure thing principle; Quantum probability	UNCERTAINTY; CHOICE	Recent researches on human decision-making behaviors reveal some interesting phenomenon which are difficult to be explained under the structure of classic probability theory. The quantum-like Bayesian networks, like many other quantum models, have been developed to solve this problem. Powerful as these models are to explain the experimental results, these models usually contain unknown quantum parameters. In quantum-like Bayesian networks, such parameters represent the interference between different decisions. In this paper, a heuristic method is proposed to measure the interference effect. The proposed model also has its connection with the original quantum-like Bayesian networks. The experimental data from several Prisoners dilemma games are used to test the proposed method. The testing results illustrate the efficiency of the proposed method.																	1432-7643	1433-7479				JUL	2020	24	14					10287	10294		10.1007/s00500-020-04693-2													
J								Novel neutrality aggregation operator-based multiattribute group decision-making method for single-valued neutrosophic numbers	SOFT COMPUTING										Group decision-making problems; Multiattribute decision-making; Single-valued neutrosophic sets; Neutrality laws; Aggregation operators	INTUITIONISTIC FUZZY-SETS; SIMILARITY MEASURE	The paper aims to give some new kinds of operational laws named as neutrality addition and scalar multiplication for the pairs of single-valued neutrosophic numbers. The main idea behind these operations is to include the neutral characters of the decision-maker towards the preferences of the objects when it shows the equal degrees to membership functions. Some salient features of them are investigated also. Further based on these laws, some new aggregation operators are developed to aggregate the different preferences of the decision-makers. Desirable relations and properties are investigated in detail. Finally, a multiattribute group decision-making approach based on the proposed operators is presented and investigated with numerous numerical examples. The superiors, as well as the advantages of the operators, are also discussed in it.																	1432-7643	1433-7479				JUL	2020	24	14					10327	10349		10.1007/s00500-019-04535-w													
J								Multi-item fuzzy economic production quantity model with multiple deliveries	SOFT COMPUTING										Fuzzy demand; EPQ; alpha-cut approach; Metaheuristic algorithms; Multiple deliveries	PRODUCTION-INVENTORY MODEL; DETERIORATING PRODUCTION PROCESSES; GENETIC ALGORITHM APPROACH; RAMP TYPE DEMAND; EPQ MODEL; IMPERFECT QUALITY; SPACE CONSTRAINT; PREPARATION TIME; POWER DISPATCH; OPTIMIZATION	Inventory control is one of the most critical issues in corporate management. Many mathematical models have been developed to optimize control strategies for the companies' inventory. Economic production quantity (EPQ) is one of the classic models for inventory control, which is widely used. To deal with the uncertainty in the real world, we need to develop new and useful models for modeling systems of inventory management. In such cases, fuzzy models play a unique role in the field of inventory management. The main contribution of this study is to apply some well-known metaheuristic to solve an extended EPQ model based on fuzzy numbers considering multiple deliveries. This study aims to develop an EPQ model by considering demand as triangular fuzzy numbers and multiple deliveries (delivering in multiple packages) and by considering limitations in warehouse space as well as the total number of orders. Given these conditions, EPQ costs are calculated, and new modeling is presented. The obtained fuzzy model has been simplified by using the a-cut and changing the variables, and finally, the most well-known metaheuristic algorithms, GA, PSO, GWO, and ICA, are applied in different problem sizes, and obtained results are analyzed in terms of minimizing cost function and CPU time. The result of this paper shows that GWO has superior performance in terms of various parameters.																	1432-7643	1433-7479				JUL	2020	24	14					10363	10387		10.1007/s00500-019-04539-6													
J								The solution of direct and inverse fractional advection-dispersion problems by using orthogonal collocation and differential evolution	SOFT COMPUTING										Fractional advection-dispersion problem; Orthogonal collocation; Differential evolution	BOUNDARY-VALUE-PROBLEMS; NUMERICAL-METHOD; EQUATIONS	The advection-dispersion phenomenon can be observed in various fields of science. Mathematically, this process can be studied by considering empirical models, high-order differential equations, and fractional differential equations. In this paper, a fractional model considered to represent the transport of passive tracers carried out by fluid flow in a porous media is studied both in the direct and inverse contexts. The studied mathematical model considers a one-dimensional fractional advection-dispersion equation with fractional derivative boundary conditions. The solutions of both direct and inverse problems are obtained by using the orthogonal collocation method and the differential evolution optimization algorithm approaches, respectively. In this case, the source term along the spatial and time coordinates is taken as a design variable. The obtained results with the solution of the direct problem are compared with those determined by using an implicit finite difference scheme. The results indicate that the proposed approach characterizes a promising methodology to solve the direct and inverse fractional advection-dispersion problems.																	1432-7643	1433-7479				JUL	2020	24	14					10389	10399		10.1007/s00500-019-04541-y													
J								Solving energy management of renewable integrated microgrid systems using crow search algorithm	SOFT COMPUTING										Combined economic-emission dispatch; Penalty factor; Microgrid; Grey wolf optimization; Teaching-learning-based optimization; Sine cosine algorithm; Crow search algorithm	OPERATION COST MINIMIZATION; OPTIMIZATION; STORAGE; DISPATCH	This paper aims to percolate energy management of microgrid systems by minimizing the generation cost of the same. Energy management of microgrid refers to the optimal sizing and scheduling of the distributed energy resources to reduce the generation cost and pollutant emission. A recently developed crow search algorithm (CSA) is implemented to execute the optimization. The proposed CSA imitates the crows' memory and tactics of hiding and chasing their food. Six renewable integrated microgrid test systems and a total of eighteen different cases are considered for this study. Various practical complexities such as valve point loading effect, combined economic-emission dispatch using price penalty factor method, modeling of the renewable energy sources and energy storage systems are taken into consideration for energy management of the microgrid systems. Results obtained are then compared to a number of different soft computing techniques such as genetic algorithm and particle swarm optimization and the likes to justify the effectiveness of the proposed algorithm. A statistical analysis, viz. Wilcoxon signed-rank test, is performed to prove the superiority of the proposed approach over the various other optimization techniques used in the paper.																	1432-7643	1433-7479				JUL	2020	24	14					10433	10454		10.1007/s00500-019-04553-8													
J								Framework to forecast environment changes by optimized predictive modelling based on rough set and Elman neural network	SOFT COMPUTING										Artificial intelligence; Error optimizer algorithm; Environment monitoring; Feature reduction; Intelligent systems; Machine learning; Mathematical predictive modelling algorithm; Neural network; Optimized predictive modelling; Rough set theory; Soft computing	ALGORITHMS	The techniques pertaining to soft computing are the base for commencement, model and organization of intelligent systems in order to offer more perfect, economical and realistic solution which has minimal complexity levels. The concept of intelligent systems has for long supported objectives on sustainability, improvisation of efficiency and symbolized various kinds of activities like creation of jobs, earning profits, providing services and improvement in capacities in ICT. The applications based on this system are widespread in the technological market because of massive development in grid, cloud, mobile and big data applications and its corresponding connectivity advantages. ICT triggers data scientists to satisfy technical-based demands of intelligent systems around data analytics and big data applications. The major features of big data like that of reservation of designs on information and knowledge have offered the public undertaking an opportunity to enhance production levels, improved efficiency and its effectiveness. The main objective of this paper is to enhance the accuracy of predictive modelling using an optimized predictive modelling based on rough set (RS) and Elman neural network (ElNN). These advanced predictive models are designed on the basis of RS approach in initial stages and in later processes enhanced with the support of Elman-NN. RS has an excellent feature selection capability, and Elman-NN is the best at nonlinear system modelling. By integrating them, the proposed method can limit the input dimension and optimize the structure for ElNN modelling. This can reduce the mathematical computation complexity with the progress of predictive models. The experimental results indicate that through RS feature selection and the structure of Elman-NN, the predictive model can be simplified significantly with enhanced model performance. The predictive accuracy of data sets, namely air quality in Northern Taiwan, hazardous air pollutants, historical hourly weather data and US pollutants through optimization, is above 99%, and this model proves that the results of optimized predictive error are far better than those obtained by other neural networks like PCA-RBF, PCA-NN, FFNN-BP with PCA, MLR, FFNN-BP, ELM, SOM, RBF and ART2.																	1432-7643	1433-7479				JUL	2020	24	14					10467	10480		10.1007/s00500-019-04556-5													
J								A new artificial bee colony algorithm-based color space for fire/flame detection	SOFT COMPUTING										Fire; flame detection; Linear color space; Artificial bee colony; K-means; Jaccard index; Dice index	FOREST-FIRE DETECTION; FLAME DETECTION; COMPUTER VISION; VIDEO; MODEL	Image processing-based fire/flame detection has become popular in recent years. In this paper, a novel fire/flame detection system based on a new conversion matrix and artificial bee colony algorithm was presented. Flame and non-flame image pixel values were combined to have a new feature matrix. A conversion matrix was generated randomly. The conversion matrix was multiplied by the feature matrix. The error of this multiplication result was calculated using theK-means clustering algorithm. The conversion matrix was updated until getting desired performance using artificial bee colony algorithm. At the end of the updating process, updated conversion matrix was multiplied with all images in the dataset to move all images to new color space. The final images were converted into binary images. Otsu method was used to get binary images. These binary images were compared with the corresponding ground truth images in the dataset. The aim of this comparison is to calculate the similarity ratio of the two images. This ratio shows the extent to which the original image features are preserved. A forest fire dataset was used which has 500 forest fire images. It is publicly available and called as Corsican Fire Database. Jaccard and Dice similarity measure parameters were used to evaluate the proposed system performance and compared with other similar study such as particle swarm optimization. Evaluated mean Jaccard index value was 0.76, and mean Dice index value was 0.85. This evaluation was made for 500 images. These results provide that this system can be used in fire/flame detection systems.																	1432-7643	1433-7479				JUL	2020	24	14					10481	10492		10.1007/s00500-019-04557-4													
J								A two-stage three-machine assembly scheduling problem with a truncation position-based learning effect	SOFT COMPUTING										Two-stage assembly; Greedy iterative algorithm; Branch-and-bound; Flowshop	ITERATED GREEDY ALGORITHM; DEPENDENT SETUP TIMES; TOTAL COMPLETION-TIME; 2-MACHINE FLOWSHOP; SINGLE-MACHINE; HEURISTICS; MAKESPAN; MINIMIZE	The two-stage assembly scheduling problem has a lot of applications in industrial and service sectors. Furthermore, truncation-based learning effects have received growing attention in connection with scheduling problems. However, it is relatively unexplored in the two-stage assembly scheduling problem. Therefore, we addressed the two-stage assembly with truncation learning effects with two machines in the first stage and an assembly machine in the second stage. The objective function was to complete all jobs as soon as possible (or to minimize the makespan). Due to the NP-hardness of the considered problem, we proposed several dominance relations and a lower bound for the branch-and-bound method for finding the optimal solution. Moreover, we proposed six versions of hybrids greedy iterative algorithm, where three versions of the local searches algorithm with and without a probability scheme are embedded. They include extraction and backward-shifted reinsertion, pairwise interchange and extraction and forward-shifted reinsertion for searching good-quality solutions. The experimental results of all proposed algorithms are presented on small-size and big-size jobs.																	1432-7643	1433-7479				JUL	2020	24	14					10515	10533		10.1007/s00500-019-04561-8													
J								Online adaptive PID tracking control of an aero-pendulum using PSO-scaled fuzzy gain adjustment mechanism	SOFT COMPUTING										Aero-pendulum; Proportional-integral-derivative control; Self-tuning control; Fuzzy inference system; Particle swarm optimization	SLIDING-MODE CONTROL; POSITION CONTROL; LOGIC	This article is centered on the development of a robust position control and disturbance compensation strategy for a mechatronic aero-pendulum using the soft computing paradigm. The pendulum arm is rotated about its pivot via the thrust generated by two coaxial contra-rotating motorized propellers installed at its free end. The tracking error in arm's angular position is fed to a multi-loop feedback controller. The proportional-integral-derivative (PID) controller, in the outer loop, stabilizes the arm at the reference position. The reference current control signals generated by the PID position controller are fed to two PI controllers, in the inner loop, that are responsible for regulating the current consumption of each motorized propeller. Initially, the fixed PID controller gains are evaluated by selecting the optimal value of the system's closed-loop pole using the particle swarm optimization (PSO) algorithm. However, to mitigate the inefficacies of fixed gain controller and further enhance the system's robustness against bounded exogenous disturbances and damping against oscillations, the closed-loop pole is dynamically adjusted via fuzzy inference system, after every sampling interval. The fuzzy membership functions are calibrated offline via PSO algorithm. The superior time optimal control behavior rendered by the proposed controller is validated by comparing its performance with fixed gain controller via credible real-time experiments.																	1432-7643	1433-7479				JUL	2020	24	14					10629	10643		10.1007/s00500-019-04568-1													
J								Enhancement of security using optimized DoS (denial-of-service) detection algorithm for wireless sensor network	SOFT COMPUTING										Sensors; Denial of service; Attack; Wireless sensor network		Wireless sensor networks involved every part of application in today's life. This can detect the various type of information from environment and communicated to users in real time. Information is stored by using cloud technology and that can be accessed by the users. The information is prone to attacks as they are part of cooperative communication. Building algorithms at node level is not secured as they transfer data in open traffic. This has provided scope for this study to concentrate on algorithms that are available for denial-of-service attacks as they put down the network performance to a less minimum. The paper henceforth proposes optimized energy-based constraint DoS (denial-of-service) detection algorithm, i.e., OBES algorithm for handling denial-of-service attacks that learns the network traffic and manages the intruders. This has been compared with denial-of-service attack detection with energy constraint in WSN. The implementation has been done in NS2. The performance has been presented in terms of nodes, interval and lifetime. From results, it can be observed that the proposed OBES algorithm is efficient as it achieves more available energy, less delay, less packet loss and more lifetime for the network. From results, it can be observed that OBES algorithm performs well compared to denial-of-service attack detection with energy constraint algorithm.																	1432-7643	1433-7479				JUL	2020	24	14					10681	10691		10.1007/s00500-019-04573-4													
J								Optimizing ligand conformations in flexible protein targets: a multi-objective strategy	SOFT COMPUTING										Molecular docking; Multi-objective optimization; Metaheuristics	HIV-1 PROTEASE; MOLECULAR DOCKING; WILD-TYPE; INHIBITION; ALGORITHM; ACCURACY	Finding the orientation of a ligand (small molecule) with the lowest binding energy to the macromolecule (receptor) is a complex optimization problem, commonly called ligand-protein docking. This problem has been usually approached by minimizing a single objective that corresponds to the final free energy of binding. In this work, we propose a new multi-objective strategy focused on minimizing: (1) the root mean square deviation (RMSD) between the co-crystallized and predicted ligand atomic coordinates, and (2) the ligand-receptor intermolecular energy. This multi-objective strategy provides the molecular biologists with a range of solutions computing different RMSD scores and intermolecular energies. A set of representative multi-objective algorithms, namely NSGA-II, SMPSO, GDE3 and MOEA/D, have been evaluated in the scope of an extensive set of docking problems, which are featured by including HIV-proteases with flexible ARG8 side chains and their inhibitors. As use cases for biological validation, we have included a set of instances based on new retroviral inhibitors to HIV-proteases. The proposed multi-objective approach shows that the predictions of ligand's pose can be promising in cases in which studiesin silicoare necessary to test new candidate drugs (or analogue drugs) to a given therapeutic target.																	1432-7643	1433-7479				JUL	2020	24	14					10705	10719		10.1007/s00500-019-04575-2													
J								A novel methodology for performance evaluation of IT projects in a fuzzy environment: a case study	SOFT COMPUTING										Information technology; Performance evaluation; Balanced scorecard; Hesitant fuzzy weights; HMG operator; Case study	INFORMATION-TECHNOLOGY; CONSTRUCTION PROJECTS; BALANCED SCORECARD; COST ESTIMATION; ENABLING ROLE; MANAGEMENT; INDICATORS; DECISION; SUCCESS; MODEL	Most of the information technology (IT) projects are canceled or failed due to different reasons, while some of them are performed poorly in terms of cost, time, scope, customer satisfaction, etc. Therefore, it is important to identify the most important criteria affecting the performance of IT projects, measure their performance, identify the issues, and continually improve the performance of both the projects and the organizations. Although IT organizations place value on the importance of the project performance to release on time, with low cost, and in accordance with the customer expectations, they lack ways of determining the most suitable performance criteria for continually measuring, improving, and controlling them. This study proposes a new methodology to evaluate the performance of IT projects in a fuzzy environment. For this aim, firstly, the most suitable criteria are identified based on the balanced scorecard method. In the second step, the relative priorities of the criteria are determined with the help of expert judgments and hesitant fuzzy weights with hesitant multiplicative geometric operator. Then, the priorities of the criteria are used to evaluate the performance of IT projects in a Turkish company by using real data.																	1432-7643	1433-7479				JUL	2020	24	14					10755	10770		10.1007/s00500-019-04579-y													
J								Analysis on energy consumption in smart grid WSN using path operator calculus centrality based HSA-PSO algorithm	SOFT COMPUTING										Path Operator Calculus Centrality; Harmonic Search Algorithm; Particle Swarm Optimization	WIRELESS SENSOR NETWORKS; ROUTING PROTOCOL; EFFICIENT; CONTEXT	In this paper, the consumption of energy is efficiently balanced using the high searching capability of harmony search algorithm (HSA). However, centrality in finding the route is considered as an utmost challenge in finding the important node in WSN. Hence, the path operator calculus centrality (SPOCC) is used to optimize the centrality problems in routing. The SPOCC finds the main routing path using HSA, and high centrality node is estimated by particle swarm optimization (PSO) algorithm, thereby ensuring optimal routing with reduced energy consumption. The utilization of PSO improves the lifetime of nodes using its dynamic capability. The performance of the proposed hybrid algorithm is evaluated using the various result metrics in smart grid outdoor transmission environment. The results show that the proposed hybrid algorithm obtains better improvement in terms of reduced delay and high residual energy than the existing algorithms.																	1432-7643	1433-7479				JUL	2020	24	14					10771	10783		10.1007/s00500-019-04580-5													
