PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								SVD-based redundancy removal in 1-D CNNs for acoustic scene classification	PATTERN RECOGNITION LETTERS										Pruning; SoundNet; Embedding; Response matrix; Acoustic scene classification		In this letter, we propose a concise feature representation framework for acoustic scene classification by pruning embeddings obtained from SoundNet, a deep convolutional neural network. We demonstrate that the feature maps generated at various layers of SoundNet have redundancy. The proposed singular value decomposition based method reduces the redundancy while relying on the assumption that useful feature maps produced by different classes lie along different directions. This leads to ignoring the feature maps that produce similar embeddings for different classes. In the context of using an ensemble of classifiers on the various layers of SoundNet, pruning the redundant feature maps leads to reduction in dimensionality and computational complexity. Our experiments on acoustic scene classification demonstrate that ignoring 73% of feature maps reduces the performance by less than 1% with 12.67% reduction in computational complexity. In addition to this, we also show that the proposed pruning framework can be utilized to remove filters in the SoundNet network architecture, with 13x lesser model storage requirement. Also, the number of parameters reduce from 28 million to 2 million with marginal degradation in performance. This small model obtained after applying the proposed pruning procedure is evaluated on different acoustic scene classification datasets, and shows excellent generalization ability. (c) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						383	389		10.1016/j.patrec.2020.02.004													
J								Flexible character accuracy measure for reading-order-independent evaluation	PATTERN RECOGNITION LETTERS										Performance evaluation; OCR; Reading order; Accuracy		The extraction of textual information from scanned document pages is a fundamental stage in any digitisation effort and directly determines the success of the overall document analysis and understanding application scenarios. To evaluate and improve the performance of optical character recognition (OCR), it is necessary to measure the accuracy of that step alone, without the influence of the processing steps that precede it (e.g. text block segmentation and ordering). Current OCR performance evaluation measures (based on edit distance) are strongly subjective as they need to first serialise the entire text in the documents - a process influenced heavily by the specific reading order determined (often wrongly, especially in cases of multicolumn and complex layouts) by processing steps prior to OCR. This paper presents a new objective and practical edit-distance-based character recognition accuracy measure which overcomes those limitations. It achieves its independence from the reading order by comparing sub-strings of text in a flexible way (i.e. allowing for ordering variations). The precision of the flexible character accuracy measure enables the effective tuning of complete digitisation workflows (as OCR errors are isolated and other steps can be evaluated and optimised separately). For the same reason, it also enables a better estimation of post-OCR (manual) correction effort required. The proposed character accuracy measure has been systematically analysed and validated under lab conditions as well as successfully used in practice in a number of high-profile international competitions since 2017. (c) 2020 Published by Elsevier B.V.																	0167-8655	1872-7344				MAR	2020	131						390	397		10.1016/j.patrec.2020.02.003													
J								Improving pattern spotting in historical documents using feature pyramid networks	PATTERN RECOGNITION LETTERS										Pattern spotting; Image retrieval; Historical documents; Convolutional neural network		Pattern spotting consists of locating different instances of a given object (i.e. an image query) in a collection of historical document images. These patterns may vary in shape, size, color, context and even style because they are hand-drawn, which makes pattern spotting a difficult task. To tackle this problem, we propose a Convolutional Neural Network (CNN) approach based on Feature Pyramid Networks (FPN) as the feature extractor of our system. Using FPN allows to extract descriptors of local regions of the documents to be indexed and queries, at multiple scales with just a single forward pass. Experiments conducted on DocExplore dataset show that the proposed system improves mAP by 73% (from 0.157 to 0.272) in pattern localization compared with state-of-the-art results, even when the feature extractor is not trained with domain-specific data. Memory requirement and computation time are also decreased since the descriptor dimension used for distance computation is reduced by a factor of 16. (c) 2020 Published by Elsevier B.V.																	0167-8655	1872-7344				MAR	2020	131						398	404		10.1016/j.patrec.2020.02.002													
J								Recognising decorations in archaeological finds through the analysis of characteristic curves on 3D models	PATTERN RECOGNITION LETTERS										Recognition of characteristic curves; Hough transform; Curve patterns; Archaeological 3D models; Similarity of curve decorations	HOUGH TRANSFORM; ALGEBRAIC APPROACH; ROBUST; LINES	In the analysis of archaeological finds, it is important for archaeologists to identify their style, origin, period, etc. to allow their correct classification. In the digital era, the development of automatic techniques to measure the peculiar characteristics of archaeological finds would be of great help in this activity. Considering that ancient artefacts are very often incomplete, consumed, degraded, if not consisting of simple fragments, geometric details, such as decorations, visual motifs, patterns, are more useful for their analysis than global characteristics. These patterns are usually composed by characteristic curves arranged in a regular way, as in a Greek fret or a floral band. Here we propose the recognition of characteristic curves on 3D models of archaeological artefacts, identified by a set of characteristic points. We approximate these curves with known curves to provide localisation and quantitative measurement of the characteristic features used as decorations or patterns of the digital models of ancient objects. To solve this problem, we adopt a generalised version of the Hough Transform (HT). In addition, we introduce new rules of composition and automatic aggregation of the characteristic curves, not limiting the recognition to a single curve at a time and supporting an automatic annotation of the fragment digital model. (c) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						405	412		10.1016/j.patrec.2020.01.025													
J								Feature-extraction methods for historical manuscript dating based on writing style development	PATTERN RECOGNITION LETTERS											DEAD-SEA-SCROLLS; WRITER IDENTIFICATION	Paleographers and philologists perform significant research in finding the dates of ancient manuscripts to understand the historical contexts. To estimate these dates, the traditional process of using classical paleography is subjective, tedious, and often time-consuming. An automatic system based on pattern recognition techniques that infers these dates would be a valuable tool for scholars. In this study, the development of handwriting styles over time in the Dead Sea Scrolls, a collection of ancient manuscripts, is used to create a model that predicts the date of a query manuscript. In order to extract the handwriting styles, several dedicated feature-extraction techniques have been explored. Additionally, a self-organizing time map is used as a codebook. Support vector regression is used to estimate a date based on the feature vector of a manuscript. The date estimation from grapheme-based technique outperforms other feature-extraction techniques in identifying the chronological style development of handwriting in this study of the Dead Sea Scrolls. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license. (http://creativecommons.org/licenses/by-nc-nd/4.0/)																	0167-8655	1872-7344				MAR	2020	131						413	420		10.1016/j.patrec.2020.01.027													
J								End-to-end visual speech recognition for small-scale datasets	PATTERN RECOGNITION LETTERS											BOTTLENECK FEATURES	Visual speech recognition models traditionally consist of two stages, feature extraction and classification. Several deep learning approaches have been recently presented aiming to replace the feature extraction stage by automatically extracting features from mouth images. However, research on simultaneously learning features and performing classification remains limited. In addition, most of the existing methods require large amounts of data in order to achieve state-of-the-art performance, otherwise they under-perform. In this work, an end-to-end lip-reading system for isolated word recognition is presented based on fully-connected layers and Long-Short Memory (LSTM) networks which is suitable for smallscale datasets. The model consists of two streams: one which extracts features directly from the mouth images and one which extracts features from the difference images. A Bidirectional LSTM (BL STM) is used for modelling the temporal dynamics in each stream which are then fused via another BLSTM. An absolute improvement in classification rate of 0.6%, 3.4%, 3.9%, 11.4% over the state-of-the-art is reported on the OuluVS2, CUAVE, AVLetters and AVLetters2 databases, respectively. (c) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						421	427		10.1016/j.patrec.2020.01.022													
J								Robust geodesic based outlier detection for class imbalance problem	PATTERN RECOGNITION LETTERS										Outlier detection; Structural stability; Local structure		Outlier detection is very useful in many applications, such as fraud detection and network intrusion detection. However, some existing methods often generate incorrect identification results due to the imbalanced distribution of data points. In this paper, we present a robust geodesic-based outlier detection algorithm which simultaneously considers both global disconnectivity score and local real degree as measures of outlierness. We first construct the global disconnectivity score to incorporate suitable global characteristics of data, then we provide the local real degree to effectively consider the local characteristics of points. Thus, we can identify local outliers with higher overall connectivity but in a smaller cluster with fewer points. Experimental results obtained for a number of synthetic and real-world data sets demonstrate the effectiveness and robustness of our method. In particular, we estimate an increase in average area under curve (AUC) on ten datasets of approximately 15%, with smaller RMSD than any of the competing methods. (c) 2020 Published by Elsevier B.V.																	0167-8655	1872-7344				MAR	2020	131						428	434		10.1016/j.patrec.2020.01.028													
J								Multi-scale Gated Fully Convolutional DenseNets for semantic labeling of historical newspaper images	PATTERN RECOGNITION LETTERS										Historical newspapers; Fully Convolutional Networks; Multi-scale Gating Bock; Densely connected network; Gating mechanism; pixel labeling		Historical newspaper image analysis is a challenging task due to the complex layout of newspapers and its variability among collections. While traditional approaches are rule-based methods with many successive steps, recent works show that deep learning approaches can be successfully used to provide a pixel labeling of the various fields occurring in a page. This allows the automatic extraction of the document structure and accessing the different semantic entities. Recent improvements proposed to strengthen convolutional neural network capacities such as gated mechanism may also apply well to to task at end. In this respect, we propose a fully convolutional neural network architecture (FCN) that outputs a pixel-labeling of the various semantic entities that occur in historical newspaper images. Our model is based on a novel Multi-Scale Gated Block architecture (MSGB), made of dense connections and gating mechanisms that handle a multi-scale analysis of the input image with self-attention. Evaluations conducted on 4 historical newspaper datasets including up to 11 semantic classes show that our proposition outperforms standard FCN architectures. (c) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						435	441		10.1016/j.patrec.2020.01.026													
J								Hierarchical Attention Network for Action Segmentation	PATTERN RECOGNITION LETTERS												Temporal segmentation of events is an essential task and a precursor for the automatic recognition of human actions in the video. Several attempts have been made to capture frame-level salient aspects through attention but they lack the capacity to effectively map the temporal relationships in between the frames as they only capture a limited span of temporal dependencies. To this end we propose a complete end-to-end supervised learning approach that can better learn relationships between actions over time, thus improving the overall segmentation performance. The proposed hierarchical recurrent attention framework analyses the input video at multiple temporal scales, to form embeddings at frame level and segment level, and perform fine-grained action segmentation. This generates a simple, lightweight, yet extremely effective architecture for segmenting continuous video streams and has multiple application domains. We evaluate our system on multiple challenging public benchmark datasets, including MERL Shopping, 50 salads, and Georgia Tech Egocentric datasets and achieves state-of-the-art performance. The evaluated datasets encompass numerous video capture settings which are inclusive of static overhead camera views and dynamic, ego-centric head-mounted camera views, demonstrating the direct applicability of the proposed framework in a variety of settings. (c) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						442	448		10.1016/j.patrec.2020.01.023													
J								BshapeNet: Object detection and instance segmentation with bounding shape masks	PATTERN RECOGNITION LETTERS												We propose a modularizable component that can predict the boundary shapes and boxes of an image, along with a new masking scheme for improving object detection and instance segmentation. Specifically, we introduce two types of novel masks: a bounding box (bbox) mask and a bounding shape (bshape) mask. For each of these types, we consider two variants-the "Thick" model and the "Scored" model-both of which have the same morphology but differ in ways that make their boundaries thicker. To evaluate our masks, we design extended frameworks by adding a bshape mask (or a bbox mask) branch to a Faster R-CNN, and call this BshapeNet (or BboxNet). Furthermore, we propose BshapeNet+, a network that combines a bshape mask branch with a Mask R-CNN. Among our various models, BshapeNet+ demonstrates the best performance in both tasks. In addition, BshapeNet+ markedly outperforms the baseline models on MS COCO and Cityscapes and achieves highly competitive results with state-of-the-art models. In particular, the experimental results show that our branch works well on small objects and is easily applicable to various models, such as PANet as well as Faster R-CNN and Mask R-CNN. (C) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						449	455		10.1016/j.patrec.2020.01.024													
J								CMIR-NET : A deep learning based model for cross-modal retrieval in remote sensing	PATTERN RECOGNITION LETTERS										Remote sensing; Cross-modal retrieval; Deep learning; Panchromatic; Multispectral; Audio samples	GRAPH CONVOLUTIONAL NETWORK	We address the problem of cross-modal information retrieval in the domain of remote sensing. In particular, we are interested in two application scenarios: i) cross-modal retrieval between panchromatic (PAN) and multispectral imagery, and ii) multi-label image retrieval between very high resolution (VHR) images and speech-based label annotations. These multi-modal retrieval scenarios are more challenging than the traditional uni-modal retrieval approaches given the inherent differences in distributions between the modalities. However, with the increasing availability of multi-source remote sensing data and the scarcity of enough semantic annotations, the task of multi-modal retrieval has recently become extremely important. In this regard, we propose a novel deep neural network-based architecture that is considered to learn a discriminative shared feature space for all the input modalities, suitable for semantically coherent information retrieval. Extensive experiments are carried out on the benchmark large-scale PAN - multispectral DSRSID dataset and the multi-label UC-Merced dataset. Together with the Merced dataset, we generate a corpus of speech signals corresponding to the labels. Superior performance with respect to the current state-of-the-art is observed in all the cases. (C) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						456	462		10.1016/j.patrec.2020.02.006													
J								An adaptive feature extraction model for classification of thyroid lesions in ultrasound images	PATTERN RECOGNITION LETTERS										Feature extraction; Image filtering; Benign and malignant thyroid lesion; Image texture feature; Computer-aided diagnosis system; Ultrasound	FILTER; TEXTURE; ENHANCEMENT; COMBINATION; BENIGN; NOISE	The thyroid is the chief hormonal gland that controls the growth, metabolism, and maturation of the body. However, the function of the thyroid gland could be disrupted if it produces too much or too little hormones. Furthermore, there could be abnormal growth in thyroid cell tissue, leading to the formation of a benign or malignant thyroid lesion. Ultrasound is a typical non-invasive diagnosis approach to check for cancerous thyroid lesions. However, the visual interpretation of the ultrasound thyroid images is challenging and time-consuming. Hence, a feature engineering model is proposed to overcome these challenges. We propose to transform image pixel intensity values into high dimensional structured data set before fitting a Regression analysis framework to estimate kernel parameters for an image filter model. We then adopt a Bayesian network inference to estimate a subset for the textural features with a significant conditional dependency in the classification of thyroid lesions. The analysis of the proposed feature engineering model showed that the classification performance had an overall significant improvement over other image filter models. We achieve 96.00% classification accuracy with a sensitivity and specificity of 99.64% and 90.23% respectively for a filter size of 13 x 13. The analysis of results indicate that the diagnosis of ultrasound images thyroid nodules is significantly boosts by adaptively learning filter parameters for feature engineering model. (C) 2020 Elsevier B.V. All rights reserved.																	0167-8655	1872-7344				MAR	2020	131						463	473		10.1016/j.patrec.2020.02.009													
J								Swapping trajectories with a sufficient sanitizer	PATTERN RECOGNITION LETTERS										Privacy preserving mobility data mining; Real-time mobility data anonymization; Trajectory anonymization; Sufficient sanitizer; Intelligent transportation systems; Origin-Destination matrices	PRIVACY	Real-time mobility data is useful for several applications such as planning transports in metropolitan areas or localizing services in towns. However, if such data is collected without any privacy protection it may reveal sensible locations and pose safety risks to an individual associated to it. Thus, mobility data must be anonymized preferably at the time of collection. In this paper, we consider the SwapMob algorithm that mitigates privacy risks by swapping partial trajectories. We formalize the concept of sufficient sanitizer and show that the SwapMob algorithm is a sufficient sanitizer for various statistical decision problems. That is, it preserves the aggregate information of the spatial database in the form of sufficient statistics and also provides privacy to the individuals. This may be used for personalized assistants taking advantage of users' locations, so they can ensure user privacy while providing accurate response to the user requirements. We measure the privacy provided by SwapMob as the Adversary Information Gain, which measures the capability of an adversary to leverage his knowledge of exact data points to infer a larger segment of the sanitized trajectory. We test the utility of the data obtained after applying SwapMob sanitization in terms of Origin-Destination matrices, a fundamental tool in transportation modelling. (C) 2020 The Authors. Published by Elsevier B.V.																	0167-8655	1872-7344				MAR	2020	131						474	480		10.1016/j.patrec.2020.02.011													
J								A Generalized p-Norm Knowledge-Based Score Function for an Interval-Valued Intuitionistic Fuzzy Set in Decision Making	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Decision making; Fuzzy sets; Entropy; Knowledge based systems; Tools; Atmospheric measurements; Particle measurements; Interval-valued intuitionistic fuzzy sets (IvIFSs); knowledge measure; multiattribute group decision making (MAGDM); score function	ENTROPY MEASURES; SIMILARITY	This paper addresses the commonly used methods for solving multiple attribute group decision-making problems under an interval-valued intuitionistic fuzzy environment. It is shown that either the most popular score function and its latterly improved versions or other related methods may lead to the undesirable results. Apart from these seemly heuristic methods, we propose a generalized p-norm knowledge-based score function for the interval-valued intuitionistic fuzzy set, which is a generalization of the score function for intuitionistic fuzzy sets as well. The proposed score function is defined as the average amount of knowledge of information depicted in terms of the interval-valued intuitionistic fuzzy sets, that regards their quantitative level of information referred to a reference level, fuzziness and qualitative significance of information. It is proved that the proposed score function has good algebraic properties, such as monotonicity under multiplication or aggregation operator, which are not preserved in the case of existing score functions. We show that the proposed score function is a simple, easily interpreted approach, which provides intuitive results in ranking the IvIFSs as well as IFSs, particularly. Several illustrative examples are performed to demonstrate the superiority of the proposed method in measuring and discriminating the IvIFSs. A comparative analysis with the preceding methods in solving decision-making problems is conducted to show the effectiveness of the proposed method in real-life applications.																	1063-6706	1941-0034				MAR	2020	28	3					409	423		10.1109/TFUZZ.2019.2907068													
J								Sampled-Data Output-Feedback Tracking Control for Interval Type-2 Polynomial Fuzzy Systems	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Interval type-2 (IT2) fuzzy logic; polynomial fuzzy-model-based (PFMB) control systems; sampled-data output; stability analysis; sum-of-square (SOS); tracking control	H-INFINITY CONTROL; STABILITY ANALYSIS; NONLINEAR-SYSTEMS; CONTROL DESIGN; DISCRETIZATION; STABILIZATION; UNCERTAINTIES; PERFORMANCE; SETS	In this paper, we investigate the stability and performance of the interval type-2 (IT2) polynomial fuzzy-model-based tracking control system, formed by an IT2 polynomial fuzzy model and an IT2 polynomial fuzzy controller, based on the output feedback and sampled-data structure. IT2 fuzzy sets are employed to capture the uncertainties of the nonlinear plant. Furthermore, considering the digital implementation of control strategy and only the system outputs are available, the IT2 polynomial fuzzy controller is of discrete time and output-feedback type. Both membership-function-independent and membership-function-dependent stability analysis, with the consideration of $H_\infty$ performance index, are conducted to develop stability conditions in terms of sum-of-square based on Lyapunov stability theory. The information of membership functions, system states, and sampling process are included in the stability analysis for the relaxation of stability conditions. Simulation examples are presented to verify the effectiveness of the proposed tracking control approach.																	1063-6706	1941-0034				MAR	2020	28	3					424	433		10.1109/TFUZZ.2019.2907503													
J								Reinforcement Neural Fuzzy Surrogate-Assisted Multiobjective Evolutionary Fuzzy Systems With Robot Learning Control Application	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Optimization; Process control; Fuzzy control; Robots; Training; Mathematical model; Evolutionary fuzzy systems (EFS); multiobjective optimization algorithms; neural fuzzy systems; surrogate-assisted learning; temporal difference (TD) learning	ANT COLONY OPTIMIZATION; GENETIC ALGORITHM; DESIGN; NAVIGATION; NETWORKS	This paper proposes a new reinforcement neural fuzzy surrogate (RNFS)-assisted multiobjective evolutionary optimization (RNFS-MEO) algorithm to boost the learning efficiency of data-driven fuzzy controllers (FCs). The RNFS-MEO is applied to evolve a population of FCs in a multiobjective robot wall-following control problem in order to reduce the number of time-consuming control trials and the implementation time of learning. In the RNFS-MEO, the RNFS is incorporated into a typical multiobjective continuous ant colony optimization algorithm to improve its learning efficiency. The RNFS estimates the accumulated multiobjective function values of the FCs in a colony without applying them to control a process, which helps reduce the number of control trials. The RNFS is trained online through structure and parameter learning based on the reinforcement signals from controlling a process. Considering the influence of the current control signals on the future states of a controlled process, the temporal difference technique is used in the RNFS training so that it estimates not only the current but also the future objective function values. The colony of FCs in the RNFS-MEO is repeatedly evolved based on the RNFS estimated values or the objective function values from real evaluations until a colony of successful FCs is found. The RNFS-MEO-based FC learning approach is applied to a robot wall-following control problem. Simulations and experiments on the robot control application are performed to verify the effectiveness and efficiency of the RNFS-MEO.																	1063-6706	1941-0034				MAR	2020	28	3					434	446		10.1109/TFUZZ.2019.2907513													
J								Three-Way Group Conflict Analysis Based on Pythagorean Fuzzy Set Theory	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Fuzzy sets; Decision theory; Rough sets; Information systems; Bayes methods; Decision making; Uncertainty; Bayesian minimum risk theory; conflict analysis; Pythagorean fuzzy information system; Pythagorean fuzzy loss function; Pythagorean fuzzy sets (PFSs)	CRITERIA DECISION-MAKING; ROUGH SET; MEMBERSHIP GRADES; MODEL; REDUCTION; EXTENSION; TOPSIS	In some real-world situations, Pythagorean fuzzy sets are more powerful and effective than intuitionistic fuzzy sets to describe vague and uncertain information, and there are many Pythagorean fuzzy information systems for conflicts in which attitudes of agents on issues are depicted by Pythagorean fuzzy numbers. In this paper, we first provide the concepts of positive, neutral, and negative alliances with two thresholds and employ examples to illustrate how to compute positive, neutral, and negative alliances in Pythagorean fuzzy information systems for conflicts. Then, we focus on three-way conflict analysis based on the Bayesian minimum risk theory and explore examples to show how to compute the positive, neutral, and negative alliances with a Pythagorean fuzzy loss function given by an expert. Finally, we study how to calculate positive, neutral, and negative alliances with group decision theory and take examples to demonstrate how to construct the positive, neutral, and negative alliances with a group of Pythagorean fuzzy loss functions given by more experts.																	1063-6706	1941-0034				MAR	2020	28	3					447	461		10.1109/TFUZZ.2019.2908123													
J								Z-Differential Equations	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Acceptable information area; horizontal membership functions (HMFs); random process; (s, mu)-cut; Z-derivative; Z-Laplace transform; Z-numbers; Z-process	HORIZONTAL MEMBERSHIP FUNCTION; Z-NUMBERS; NUMERICAL-SOLUTION; CONTROLLED SYSTEM; FUZZY; EXISTENCE	This paper is devoted to make a framework for studying a class of uncertain differential equations called Z-differential equations. In order to achieve the purpose, we first introduce four basic operations on Z+-numbers based on semigranular function. Then, the limit and continuity concepts of a Z-number-valued function are given, under a definition of a metric on the space of Z+-numbers. Moreover, the concepts of Z-differentiability, Z-integral, and Z-Laplace transform of a Z-number-valued function are introduced. In addition, by giving some theories proved in this paper, a basis for calculus-Z-calculus-is established. We further give theories based on which existence and uniqueness of Z-differential equations are investigated. A conceptual unity between Z-differential equations and Z+-numbers is also shown. The conceptual unity demonstrates that a Z-differential equation may be expressed as a bimodal differential equation combining a fuzzy differential equation (FDE) and a random differential equation. Moreover, the concept of a bimodal cut called $ (s, mu)-cut is introduced and its relation to other new concepts such as acceptable time and acceptable information area is explained. Using an example, the application of Z-differential equations in medicine is clarified. It is demonstrated that Z-differential equations outperform FDEs in making a decision under uncertainty.																	1063-6706	1941-0034				MAR	2020	28	3					462	473		10.1109/TFUZZ.2019.2908131													
J								Fuzzy Stabilization Design for Semilinear Parabolic PDE Systems With Mobile Actuators and Sensors	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Actuators; Sensor systems; Mathematical model; Fuzzy control; Control design; Linear matrix inequalities; Exponential stability; fuzzy control; mobile actuator; sensor guidance; semilinear parabolic partial differential equation (PDE) system	DISTRIBUTED-PARAMETER SYSTEMS; EXPONENTIAL STABILIZATION; VOLTERRA NONLINEARITIES	This paper deals with a fuzzy stabilization design problem for a class of semilinear parabolic partial differential equation (PDE) systems using mobile actuators and sensors. Initially, a Takagi-Sugeno (T-S) fuzzy PDE model is employed to accurately represent the semilinear parabolic PDE system. Subsequently, based on the T-S fuzzy model, a stabilization scheme containing the fuzzy controllers and the guidance of mobile actuator/sensor pairs is proposed, where the spatial domain is decomposed into multiple subdomains according to the number of actuator/sensor pairs and each actuator/sensor pair is capable of moving within the respective subdomain. Then, by a Lyapunov direct technique, an integrated design of fuzzy controllers plus mobile actuator/sensor guidance laws is developed in the form of bilinear matrix inequalities (BMIs), such that the resulting closed-loop system is exponentially stable and the mobile actuator/sensor guidance can enhance the transient performance of the closed-loop system. Furthermore, an iterative algorithm based on linear matrix inequalities is proposed to solve the BMIs. Finally, two examples are given to illustrate the effectiveness of the proposed method.																	1063-6706	1941-0034				MAR	2020	28	3					474	486		10.1109/TFUZZ.2019.2908139													
J								Decentralized H-infinity Sampled-Data Fuzzy Filter for Nonlinear Interconnected Oscillating Systems With Uncertain Interconnections	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Decentralized sampled-data fuzzy filter; linear matrix inequality (LMI); nonlinear interconnected systems; oscillating systems; uncertain interconnections	NEURAL-NETWORKS; TIME-DELAY; DESIGN	This paper proposes a decentralized $H_\infty$ sampled-data fuzzy filter design for nonlinear interconnected systems composed of multiple subsystems with uncertain interconnections and variable sampling intervals. The interconnected system and the decentralized filter are modeled using Takagi-Sugeno fuzzy systems. To derive the filter-design conditions, the estimation error dynamics are modeled, and the $H_\infty$ filter performance inequality is defined. The filter performance inequality is aimed at minimizing the ratio of the estimation error to the sum of the norm of the disturbance and oscillating system. The sufficient conditions for the filter design are derived using the Wirtinger-based integral inequality and expressed in the form of linear matrix inequalities. Finally, the performance of the proposed filter-design techniques is demonstrated through two simulation examples.																	1063-6706	1941-0034				MAR	2020	28	3					487	498		10.1109/TFUZZ.2019.2908151													
J								Extracting LPV and qLPV Structures From State-Space Functions: A TP Model Transformation Based Framework	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Numerical models; Control design; State-space methods; Mathematical model; Indexes; Hypercubes; LMI control design; polytop model; TP model; TP model transformation; TS model	STABILITY CONDITIONS; CONTROL DESIGN; SYSTEMS; MANIPULATION; ALGORITHM	This paper proposes a tensor product (TP) model transformation-based framework requiring minimal human intuition to numerically reconstruct linear time invariant, Takagi-Sugeno (T-S) fuzzy model-based linear parameter varying and quasi-linear parameter varying representations of state-space models. The proposed framework facilitates the manipulation of the structure of the system matrix, the parameter vector-including state elements-and the vertex systems. The motivation behind this capability is that all of these structural components strongly influence the control design and the resulting control performance. An important feature of the framework is that it is agnostic towards the formulation of the state-space model, i.e., whether it is given using soft-computing-based techniques or closed formulae. The proposed approach is an extension of the TP model-based control design framework and inherits all of its advantageous properties, e.g., it can be easily used to find minimal representations, including the higher order singular value-based canonical form, and it supports the clear formulation of complexity/accuracy tradeoffs and allows for conversions to various types of convex representations, making for a flexible way to manipulate the weighting and antecedent functions. This paper gives examples to show how the framework can be used in a routine-like fashion and to highlight how it can be applied to the problem of finding useful T-S fuzzy model variations of a given model.																	1063-6706	1941-0034				MAR	2020	28	3					499	509		10.1109/TFUZZ.2019.2908770													
J								Global Fuzzy Adaptive Consensus Control of Unknown Nonlinear Multiagent Systems	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Protocols; Symmetric matrices; Artificial neural networks; Adaptive control; Fuzzy control; Uncertainty; Adaptive fuzzy control; consensus algorithm; formation control; fuzzy logic systems (FLSs); multiagent systems (MAS)	TIME-DELAY SYSTEMS; OUTPUT REGULATION; FEEDBACK SYSTEMS; NEURAL-NETWORK; SYNCHRONIZATION; LEADER; TRACKING; AGENTS	This paper investigates the global consensus problems for the first-order and second-order unknown nonlinear multiagent systems (MASs) with uncertain input disturbance. Fuzzy logic systems are applied to solve the global consensus problem for unknown nonlinear MASs. A fully distributed adaptive fuzzy control is designed to enable followers asymptotically to track the leader without using any dynamics of the leader. The global consensus conditions are also derived for the first-order and second-order unknown MASs, which overcomes the drawback of the semiglobal consensus in existing literature. It is worth mentioning that the proposed approach can greatly alleviate the computation burden because it only needs to update a few parameters. An efficient framework is also given to achieve the global formation control of the second-order unknown nonlinear MAS with an undirected connected graph. Finally, four simulated examples are given to illustrate the effectiveness of the proposed control protocols.																	1063-6706	1941-0034				MAR	2020	28	3					510	522		10.1109/TFUZZ.2019.2908771													
J								PID-Like Adaptive Fuzzy Controller Design Based on Absolute Stability Criterion	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Stability criteria; Fuzzy control; Adaptation models; Closed loop systems; Adaptive systems; Absolute stability; adaptive control; fuzzy control	SYSTEMS	This paper describes a method of PID-like adaptive fuzzy controller design for a linear time-invariant single-input and single-output dynamic plant. The plant transfer function is assumed to be partially known. The controller operates in the direct adaptation mode with the output feedback and a nonlinear reference model which provides better closed-loop response parameters than the system with a PID linear controller. The closed-loop stability is guaranteed during the adaptation process. The fuzzy controller is assumed to be a nonlinearity in a bounded sector and is defined by highly interpretable fuzzy rules. The absolute stability criterion for the system, containing PID-like fuzzy controller, is delivered. A design procedure that generalizes and significantly extends results reported so far in the literature and considerably automates the searching process of a nonlinear adaptive fuzzy controller is provided.																	1063-6706	1941-0034				MAR	2020	28	3					523	533		10.1109/TFUZZ.2019.2908772													
J								Triangular Norms for Gravitational Wave Data Fusion	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Gravitational waves; t-norms; time-frequency representations		The first direct observation of gravitational waves of cosmic origin was a milestone in fundamental research, paving the way to gravitational wave and multimessenger astronomy. In this paper, we discuss the application of t-norms as a possible natural tool for implementing consistency tests between the data gathered by different noncolocated gravitational wave detectors, useful for both discriminating transient gravitational wave signals from transient instrumental or environmental noises, and estimating the signal arrival-time delays between different detectors, and hence the direction of arrival.																	1063-6706	1941-0034				MAR	2020	28	3					534	543		10.1109/TFUZZ.2019.2910453													
J								Fuzzy Clustering-Based Adaptive Regression for Drifting Data Streams	IEEE TRANSACTIONS ON FUZZY SYSTEMS										c-Means; concept drift; data stream; fuzzy clustering; regression	PENALIZED REGRESSION; CLASSIFICATION; TOLERANT; ONLINE	Current models and algorithms have been increasingly required to learn in a nonstationary environment because the phenomenon of concept drift (or pattern shift) may occur, that is, the assumption that data are identically distributed may be invalid in data streams. Once the data pattern changes, a well-trained model built on the previous, now obsolete data cannot provide an accurate prediction for future data. To obtain reliable prediction, it is important to understand the existing patterns in the data stream and to know which pattern the current examples belong to during the modeling process. However, it is ambiguous to classify an example to a certain pattern in many real-world cases. In this paper, we propose a novel adaptive regression approach, called FUZZ-CARE, to dynamically recognize, train, and store patterns, and assign the membership degree of the upcoming examples belonging to these patterns. Membership degrees are presented by the membership matrix obtained from a kernel fuzzy c-means clustering, which is synchronously trained and adapted with regression parameters. Rather than designing a complicated procedure to continuously chase the newest pattern, which is a common approach in the literature, FUZZ-CARE abstracts useful past information to help predict newly arrived examples. It thus effectively avoids the risk of insufficient training due to the lack of new data and improves prediction accuracy. Experiments on six synthetic datasets and 21 real-world datasets validate the high accuracy and robustness of our approach.																	1063-6706	1941-0034				MAR	2020	28	3					544	557		10.1109/TFUZZ.2019.2910714													
J								Person Footprint of Uncertainty-Based CWW Model for Power Optimization in Handheld Devices	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Computing with words (CWWs); interval approach (IA); interval type-2 fuzzy sets; per-C power management approach (PMA); person footprint of uncertainty (FOU); power management; Hao-Mendel approach (HMA)	DECISION-MAKING; WORDS; FREQUENCY	Present-day handheld battery-enabled devices such as smartphones and tablets attract rich user experience but are often criticized for their short battery lives. Battery life is a subjective term and depends on a user's perceptions. A novel work to achieve power optimization for these devices, according to users' perceptions, was the design of user-satisfaction-aware power management approach, perceptual computer power management approach (Per-C PMA). But we have found that the design of Per-C PMA requires collection of data intervals from a group of subjects. This limits the practical viability of Per-C PMA for highly personal handheld battery-enabled devices such as smartphones and tablets. So, here we propose a user-satisfaction-aware PMA called Per-C for Personalized Power Management Approach or "Per-C PPMA," one that achieves significant reductions in power consumption compared to existing PMAs and noticeable improvements in the overall user satisfaction. Per-C PPMA uses the mathematical technique of person footprint of uncertainty (FOU) to process users' linguistic opinions. Person FOU can either use an interval approach (IA) or Hao-Mendel approach (HMA) for data processing. The recommendations generated using IA and HMA are the same. However, IA takes a much higher computational time than HMA, even though both have the same asymptotic complexity of $\boldsymbol{O}({\boldsymbol{w}*\boldsymbol{n}})$. We strongly believe that Per-C PPMA is a novel technique and our work is the first such application of Person FOU on any hardware platform. An important outcome of this study is a ready-to-use mobile app "Per-C PPMA" (currently freely available on the website http://www.sau.int/similar to cilab/).																	1063-6706	1941-0034				MAR	2020	28	3					558	568		10.1109/TFUZZ.2019.2911049													
J								Reinforced Fuzzy Clustering-Based Ensemble Neural Networks	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Ensemble neural networks; fuzzy clustering; L-2-norm regularization; multinomial logistic regression (MLR); nonlinear least square estimation (LSE)	NONLINEAR LEAST-SQUARES; INFORMATION GRANULATION; REGRESSION; SYSTEMS; DESIGN; AID	In this paper, we propose reinforced fuzzy clustering-based ensemble neural networks (FCENNs) classifier. The objective of this paper is focused on the development of the design methodologies of ensemble neural networks classifier for constructing the network structure and enhancing the learning methods of fuzzy clustering-based neural networks through the combination of the probabilistic model and its learning mechanism. The proposed FCENNs classifier takes into consideration a cross-entropy error function to improve learning while $L_2$-norm regularization is used to reduce overfitting as well as enhance generalization abilities. The essential points of the proposed reinforced FCENNs classifier can be enumerated as follows: First, in the proposed classifier, the cross-entropy error function is used as a cost function; to do this, a softmax function is applied to represent a categorical distribution located at the nodes of the output layer. Second, the learning mechanism is composed of two parts. First, fuzzy C-means clustering forms the connections (weights) of the hidden layer while the connections of the output layer are adjusted with the aid of the nonlinear least squares method using Newton's method-based learning. Third, $L_2$ norm-regularization is considered to avoid the degradation of generalization ability caused by overfitting. The learning mechanism similar to ridge regression is realized by adding $L_2$ penalty term to the cross-entropy error function. From the viewpoint of performance improvement achieved through the proposed novel learning method, the design methodology for the ensemble neural networks classifier is discussed and analyzed with the aid of a diversity of two-dimensional synthetic data and machine learning datasets.																	1063-6706	1941-0034				MAR	2020	28	3					569	582		10.1109/TFUZZ.2019.2911492													
J								Optimal Rule-Based Granular Systems From Data Streams	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Adaptive systems; evolving systems; granular computing; information specificity; online data stream	EVOLVING FUZZY; NEURAL-NETWORKS; IDENTIFICATION; MODELS; PRINCIPLE; DESIGN	We introduce an incremental learning method for the optimal construction of rule-based granular systems from numerical data streams. The method is developed within a multiobjective optimization framework considering the specificity of information, model compactness, and variability and granular coverage of the data. We use $\alpha$-level sets over Gaussian membership functions to set model granularity and operate with hyperrectangular forms of granules in nonstationary environments. The resulting rule-based systems are formed in a formal and systematic fashion. They can be useful in time series modeling, dynamic system identification, predictive analytics, and adaptive control. Precise estimates and enclosures are given by linear piecewise and inclusion functions related to optimal granular mappings.																	1063-6706	1941-0034				MAR	2020	28	3					583	596		10.1109/TFUZZ.2019.2911493													
J								Interval Sugeno Integral With Preference	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Aggregation function; fuzzy integral inference; fuzzy measure; interval values; sugeno integral	AGGREGATION OPERATORS; CHOQUET	Sugeno Integral is based on Fuzzy Integral Inference and widely used in applications such as decision making and computational intelligence. When concerned inputs are intervals, directly using Sugeno Integral to respectively aggregate the lower bounds and upper bounds of those intervals has limitations and does not embody fuzzy integral inference. This study analyzes the fuzzy integral inference in interval environment, defines some more suitable orderings on the set of all intervals in [0, 1], i.e., the congruent $\lambda $-ordering, and then proposes the Interval Sugeno Integral with preference. The novel aggregation technique proposed in this study proves to better embody fuzzy integral inference when performing Sugeno Integral.																	1063-6706	1941-0034				MAR	2020	28	3					597	601		10.1109/TFUZZ.2019.2908127													
J								An Inherent Difficulty in the Aggregation of Multidimensional Data	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Aggregates; Data aggregation; Data analysis; Geometry; Data integration; Task analysis; Centroid; monotonicity; multidimensional data aggregation; orthogonal equivariance		In the field of information fusion, the problem of data aggregation has been formalized as an order-preserving process that builds upon the property of monotonicity. However, fields such as computational statistics, data analysis, and geometry usually emphasize the role of equivariances to various geometrical transformations in aggregation processes. Admittedly, if we consider a unidimensional data fusion task, both requirements are often compatible with each other. Nevertheless, in this paper, we show that, in the multidimensional setting, the only idempotent functions that are monotone and orthogonal equivariant are the over-simplistic weighted centroids. Even more, this result still holds after replacing monotonicity and orthogonal equivariance by the weaker property of orthomonotonicity. This implies that the aforementioned approaches to the aggregation of multidimensional data are irreconcilable, and that, if a weighted centroid is to be avoided, we must choose between monotonicity and a desirable behavior with regard to orthogonal transformations.																	1063-6706	1941-0034				MAR	2020	28	3					602	606		10.1109/TFUZZ.2019.2908135													
J								Deep Learning for Video Game Playing	IEEE TRANSACTIONS ON GAMES										Games; Deep learning; Neural networks; Reinforcement learning; Mathematical model; Unsupervised learning; Algorithms; learning; machine learning algorithms; multilayer neural network; artificial intelligence	CONTENT GENERATION; NEURAL-NETWORKS; NEUROEVOLUTION; ENVIRONMENT	In this paper, we review recent deep learning advances in the context of how they have been applied to play different types of video games such as first-person shooters, arcade games, and real-time strategy games. We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges in the context of applying these machine learning methods to video games, such as general game playing, dealing with extremely large decision spaces and sparse rewards.																	2475-1502	2475-1510				MAR	2020	12	1					1	20		10.1109/TG.2019.2896986													
J								Procedural Puzzle Generation: A Survey	IEEE TRANSACTIONS ON GAMES										Games; Generators; Space exploration; Taxonomy; Programming; Feature extraction; Procedural content; puzzle games		Procedural content generation (PCG) for games has existed since the 1980s and is becoming increasingly important for creating game worlds, backstory, and characters across many genres, in particular, open-world games, such as Minecraft (2011) and No Man's Sky (2016). A particular challenge faced by such games is that the content and/or gameplay may become repetitive. Puzzles constitute an effective technique for improving gameplay by offering players interesting problems to solve, but the use of PCG for generating puzzles has been limited compared with its use for other game elements, and efforts have focused mainly on games that are strictly puzzle games, rather than creating puzzles to be incorporated into other genres. Nevertheless, a significant body of work exists, which allows puzzles of different types to be generated algorithmically, and there is scope for much more research into this area. This paper presents a detailed survey of existing work in PCG for puzzles, reviewing 32 methods within 11 categories of puzzles. For the purpose of analysis, this paper identifies a total of seven salient characteristics related to the methods, which are used to show commonalities and differences between techniques and to chart promising areas for future research.																	2475-1502	2475-1510				MAR	2020	12	1					21	40		10.1109/TG.2019.2917792													
J								Profit Optimizing Churn Prediction for Long-Term Loyal Customers in Online Games	IEEE TRANSACTIONS ON GAMES										Games; Predictive models; Analytical models; Data models; Hidden Markov models; Data mining; Churn prediction; cost-benefit analysis; customer lifetime value; data mining; game analytics		To successfully operate online games, gaming companies are introducing the systematic customer relationship management model. Particularly, churn analysis is one of the most important issues, because preventing a customer from churning is often more cost-efficient than acquiring a new customer. Churn prediction models should, thus, consider maximizing not only accuracy but also the expected profit derived from the churn prevention. We, thus, propose a churn prediction method for optimizing profit consisting of two main steps: first, selecting prediction target, second, tuning threshold of the model. In online games, the distribution of a user's customer lifetime value is very biased that a few users contribute to most of the sales, and most of the churners are no-paying users. Consequently, it is cost-effective to focus on churn prediction to loyal customers who have sufficient benefits. Furthermore, it is more profitable to adjust the threshold of the prediction model so that the expected profit is maximized rather than maximizing the accuracy. We applied the proposed method to real-world online game service, Aion, one of the most popular online games in South Korea, and then show that our method has more cost-effectiveness than the prediction model for total users when the campaign cost and the conversion rate are considered.																	2475-1502	2475-1510				MAR	2020	12	1					41	53		10.1109/TG.2018.2871215													
J								Construction of Strongly Mutually Distinct Sudoku Tables and Solid Sudoku Cubes by Cyclotomic Cosets	IEEE TRANSACTIONS ON GAMES										Sudoku table (ST); solid Sudoku table (SST); solid Sudoku cubes (SSCs); Sudoku puzzle; strongly mutually distinct Sudoku puzzles (SMDSPs)		A new method of constructing Sudoku tables (STs) (Sudoku Latin squares) is introduced by making use of individual vectors of cyclotomic cosets of $Z_n$ and their Kronecker product. We show that, it is possible to construct $m$ different STs of order $m$ such that for every $0\leq u, v \leq m-1$ the $(u, v)$-entry of these $m$ STs is different. These STs could be considered as a perfect set of strongly mutually distinct (SMD) STs, which in turn are used to construct a solid Sudoku cube $(\text{SSC})$. As a result, a new version of SMD Sudoku puzzles under a new rule and condition is introduced that are interesting for Sudoku puzzles game designers.																	2475-1502	2475-1510				MAR	2020	12	1					54	62		10.1109/TG.2018.2880953													
J								Reinforcement Learning to Create Value and Policy Functions Using Minimax Tree Search in Hex	IEEE TRANSACTIONS ON GAMES										Hex; policy function; reinforcement learning; value function	GAME; GO	Recently, the use of reinforcement-learning algorithms has been proposed to create value and policy functions, and their effectiveness has been demonstrated using Go, Chess, and Shogi. In previous studies, the policy function was trained to predict the search probabilities of each move output by Monte Carlo tree search; thus, a number of simulations were required to obtain the search probabilities. We propose a reinforcement-learning algorithm with game of self-play to create value and policy functions such that the policy function is trained directly from the game results without the search probabilities. In this study, we use Hex, a board game developed by Piet Hein, to evaluate the proposed method. We demonstrate the effectiveness of the proposed learning algorithm in terms of the policy function accuracy, and play a tournament with the proposed computer Hex algorithm DeepEZO and 2017 world-champion programs. The tournament results demonstrate that DeepEZO outperforms all programs. DeepEZO achieved a winning percentage of 79.3% against the world-champion program MoHex2.0 under the same search conditions on $13 \times 13$ board. We also show that the highly accurate policy functions can be created by training the policy functions to increase the number of moves to be searched in the loser position.																	2475-1502	2475-1510				MAR	2020	12	1					63	73		10.1109/TG.2019.2893343													
J								Manipulating Narrative Salience in Interactive Stories Using Indexter's Pairwise Event Salience Hypothesis	IEEE TRANSACTIONS ON GAMES										Planning; Games; Computational modeling; Predictive models; Indexes; Cognition; Psychology	RECOGNITION; GENERATION; MODEL; PLOT	The salience of a narrative event is defined as the ease with which an audience member can recall that past event. This paper describes a series of experiments investigating the use of salience as a predictor of player behavior in interactive narrative scenarios. We utilize Indexter, a plan-based model of narrative for reasoning about salience. Indexter defines a mapping of five event indices identified by cognitive science research onto narrative planning event structures. The indices-protagonist, time, space, causality, and intentionality-correspond to the "who, when, where, how, and why" of a narrative event, and represent dimensions by which events can be linked in short-term memory. We first evaluate Indexter's claim that it can effectively model the salience of past events in a player's mind. Next, we demonstrate that salience can be used to predict players' choices for endings in an interactive story, and finally, we demonstrate that the same technique can be applied to influence players to choose certain endings.																	2475-1502	2475-1510				MAR	2020	12	1					74	85		10.1109/TG.2019.2905230													
J								Avatars of a Feather Flock Together: Gender Homophily in Online Video Games Revealed via Exponential Random Graph Modeling	IEEE TRANSACTIONS ON GAMES										Exponential random graph (ERG) modeling; game analytics; gender homophily; online video games; social networks	SOCIAL NETWORKS; FRIENDSHIP NETWORKS; SAME-GENDER; SEGREGATION; BEHAVIOR; SEX; SCHOOL; SELF; REPRESENTATION; MOTIVATIONS	Increasingly more scholars have regarded the virtual worlds of massively multiplayer online games (MMOGs) as a social laboratory, and have paid research attention to the online interactions between its large number of players. In the present study, we examine a widely observed real-life phenomenon gender homophily (i.e., people of the same gender flocking together) in this virtual context. Specifically, we investigate how collaboration networks in an MMOG (Destiny) are shaped by the adopted gender of the avatar characters. This focus is interesting, as avatar gender in video games is generally a choice that is less constrained than it is in real life. To investigate the effect of gender in online video games, while controlling for the effects of several confounding factors, we employed a technique called exponential random graph modeling. Mirroring how interpersonal relationships are often gendered in real life, and despite common phenomenon such as gender swapping, we found evidence supporting gender homophily in the MMOG environment.																	2475-1502	2475-1510				MAR	2020	12	1					86	100		10.1109/TG.2019.2961836													
J								Measuring Player Retention and Monetization Using the Mean Cumulative Function	IEEE TRANSACTIONS ON GAMES										Game analytics; metrics; monetization; retention	COUNTING-PROCESSES; REGRESSION; MODELS; TESTS	Game analytics supports game development by providing direct quantitative feedback about player experience. Player retention and monetization have become central business statistics in free-to-play game development. Total playtime and lifetime value in particular are central benchmarks, but many metrics have been used for this purpose. However, game developers often want to perform analytics in a timely manner before all users have churned from the game. This causes data censoring, which makes many metrics biased. In this article, we introduce how the mean cumulative function (MCF) can be used to measure metrics from censored data. Statistical tools based on the MCF allow game developers to determine whether a given change improves a game or whether a game is good enough for public release. The MCF is a general tool that estimates the expected value of a metric for any data set and does not rely on a model for the data. We demonstrate the advantages of this approach on a real in-development free-to-play mobile game Hipster Sheep.																	2475-1502	2475-1510				MAR	2020	12	1					101	114		10.1109/TG.2020.2964120													
J								Gamorithm	IEEE TRANSACTIONS ON GAMES										Games; Artificial intelligence; Computational modeling; Game theory; Google; Image color analysis; Algorithms; game	GAME	Examining games from a fresh perspective, we present the idea of game-inspired and game-based algorithms, dubbed gamorithms.																	2475-1502	2475-1510				MAR	2020	12	1					115	118		10.1109/TG.2018.2867743													
J								Heterogeneous Multilayer Generalized Operational Perceptron	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neurons; Biological neural networks; Network topology; Learning systems; Topology; Computational modeling; Nonhomogeneous media; Architecture learning; feedforward network; generalized operational perceptron (GOP); progressive learning	EXTREME LEARNING-MACHINE; NEURAL-NETWORKS	The traditional multilayer perceptron (MLP) using a McCulloch-Pitts neuron model is inherently limited to a set of neuronal activities, i.e., linear weighted sum followed by nonlinear thresholding step. Previously, generalized operational perceptron (GOP) was proposed to extend the conventional perceptron model by defining a diverse set of neuronal activities to imitate a generalized model of biological neurons. Together with GOP, a progressive operational perceptron (POP) algorithm was proposed to optimize a predefined template of multiple homogeneous layers in a layerwise manner. In this paper, we propose an efficient algorithm to learn a compact, fully heterogeneous multilayer network that allows each individual neuron, regardless of the layer, to have distinct characteristics. Based on the complexity of the problem, the proposed algorithm operates in a progressive manner on a neuronal level, searching for a compact topology, not only in terms of depth but also width, i.e., the number of neurons in each layer. The proposed algorithm is shown to outperform other related learning methods in extensive experiments on several classification problems.																	2162-237X	2162-2388				MAR	2020	31	3					710	724		10.1109/TNNLS.2019.2914082													
J								LABIN: Balanced Min Cut for Large-Scale Data	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Computational modeling; Clustering algorithms; Computational complexity; Data models; Clustering methods; Laplace equations; Learning systems; Clustering; graph cut; large-scale data; spectral clustering		Although many spectral clustering algorithms have been proposed during the past decades, they are not scalable to large-scale data due to their high computational complexities. In this paper, we propose a novel spectral clustering method for large-scale data, namely, large-scale balanced min cut (LABIN). A new model is proposed to extend the self-balanced min-cut (SBMC) model with the anchor-based strategy and a fast spectral rotation with linear time complexity is proposed to solve the new model. Extensive experimental results show the superior performance of our proposed method in comparison with the state-of-the-art methods including SBMC.																	2162-237X	2162-2388				MAR	2020	31	3					725	736		10.1109/TNNLS.2019.2909425													
J								Adaptive Deep Modeling of Users and Items Using Side Information for Recommendation	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptation models; Recommender systems; Feature extraction; Computational modeling; Predictive models; Task analysis; Adaptive systems; Adaptive user preference model; attention factor; convolutional neural network (CNN); recommendation system	MATRIX FACTORIZATION	In the existing recommender systems, matrix factorization (MF) is widely applied to model user preferences and item features by mapping the user-item ratings into a low-dimension latent vector space. However, MF has ignored the individual diversity where the user's preference for different unrated items is usually different. A fixed representation of user preference factor extracted by MF cannot model the individual diversity well, which leads to a repeated and inaccurate recommendation. To this end, we propose a novel latent factor model called adaptive deep latent factor model (ADLFM), which learns the preference factor of users adaptively in accordance with the specific items under consideration. We propose a novel user representation method that is derived from their rated item descriptions instead of original user-item ratings. Based on this, we further propose a deep neural networks framework with an attention factor to learn the adaptive representations of users. Extensive experiments on Amazon data sets demonstrate that ADLFM outperforms the state-of-the-art baselines greatly. Also, further experiments show that the attention factor indeed makes a great contribution to our method.																	2162-237X	2162-2388				MAR	2020	31	3					737	748		10.1109/TNNLS.2019.2909432													
J								Exactly Robust Kernel Principal Component Analysis	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Sparse matrices; Principal component analysis; Minimization; Kernel; Matrix decomposition; Feature extraction; Optimization; High rank; kernel; low rank; noise removal; robust principal component analysis (RPCA); sparse; subspace clustering	SUBSPACE; PCA	Robust principal component analysis (RPCA) can recover low-rank matrices when they are corrupted by sparse noises. In practice, many matrices are, however, of high rank and, hence, cannot be recovered by RPCA. We propose a novel method called robust kernel principal component analysis (RKPCA) to decompose a partially corrupted matrix as a sparse matrix plus a high- or full-rank matrix with low latent dimensionality. RKPCA can be applied to many problems such as noise removal and subspace clustering and is still the only unsupervised nonlinear method robust to sparse noises. Our theoretical analysis shows that, with high probability, RKPCA can provide high recovery accuracy. The optimization of RKPCA involves nonconvex and indifferentiable problems. We propose two nonconvex optimization algorithms for RKPCA. They are alternating direction method of multipliers with backtracking line search and proximal linearized minimization with adaptive step size (AdSS). Comparative studies in noise removal and robust subspace clustering corroborate the effectiveness and the superiority of RKPCA.																	2162-237X	2162-2388				MAR	2020	31	3					749	761		10.1109/TNNLS.2019.2909686													
J								Distributed Dissipative State Estimation for Markov Jump Genetic Regulatory Networks Subject to Round-Robin Scheduling	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Discrete-time genetic regulatory networks (GRN); distributed dissipative state estimation; Markov jump parameters; round-robin scheduling (RRS)	STABILITY ANALYSIS; NEURAL-NETWORKS; TIME; SYSTEMS; SYNCHRONIZATION; LEAKAGE; DELAYS	The distributed dissipative state estimation issue of Markov jump genetic regulatory networks subject to round-robin scheduling is investigated in this paper. The system parameters randomly change in the light of a Markov chain. Each node in sensor networks communicates with its neighboring nodes in view of the prescribed network topology graph. The round-robin scheduling is employed to arrange the transmission order to lessen the likelihood of the occurrence of data collisions. The main goal of the work is to design a compatible distributed estimator to assure that the distributed error system is strictly gamma-stochastically dissipative. By applying the Lyapunov stability theory and a modified matrix decoupling way, sufficient conditions are derived by solving some convex optimization problems. An illustrative example is given to verify the validity of the provided method.																	2162-237X	2162-2388				MAR	2020	31	3					762	771		10.1109/TNNLS.2019.2909747													
J								Compact and Computationally Efficient Representation of Deep Neural Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Computationally efficient deep learning; data structures; lossless coding; neural network compression; sparse matrices		At the core of any inference procedure, deep neural networks are dot product operations, which are the component that requires the highest computational resources. For instance, deep neural networks, such as VGG-16, require up to 15-G operations in order to perform the dot products present in a single forward pass, which results in significant energy consumption and thus limits their use in resource-limited environments, e.g., on embedded devices or smartphones. One common approach to reduce the complexity of the inference is to prune and quantize the weight matrices of the neural network. Usually, this results in matrices whose entropy values are low, as measured relative to the empirical probability mass distribution of its elements. In order to efficiently exploit such matrices, one usually relies on, inter alia, sparse matrix representations. However, most of these common matrix storage formats make strong statistical assumptions about the distribution of the elements; therefore, cannot efficiently represent the entire set of matrices that exhibit low-entropy statistics (thus, the entire set of compressed neural network weight matrices). In this paper, we address this issue and present new efficient representations for matrices with low-entropy statistics. Alike sparse matrix data structures, these formats exploit the statistical properties of the data in order to reduce the size and execution complexity. Moreover, we show that the proposed data structures can not only be regarded as a generalization of sparse formats but are also more energy and time efficient under practically relevant assumptions. Finally, we test the storage requirements and execution performance of the proposed formats on compressed neural networks and compare them to dense and sparse representations. We experimentally show that we are able to attain up to x42 compression ratios, x5 speed ups, and x 90 energy savings when we lossless convert the state-of-the-art networks, such as AlexNet, VGG-16, ResNet152, and DenseNet, into the new data structures and benchmark their respective dot product.																	2162-237X	2162-2388				MAR	2020	31	3					772	785		10.1109/TNNLS.2019.2910073													
J								Stability-Based Generalization Analysis of Distributed Learning Algorithms for Big Data	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Big data; distributed learning algorithms; distributed simulations; generalization	DATA ANALYTICS; CONQUER; REGRESSION	As one of the efficient approaches to deal with big data, divide-and-conquer distributed algorithms, such as the distributed kernel regression, bootstrap, structured perception training algorithms, and so on, are proposed and broadly used in learning systems. Some learning theories have been built to analyze the feasibility, approximation, and convergence bounds of these distributed learning algorithms. However, less work has been studied on the stability of these distributed learning algorithms. In this paper, we discuss the generalization bounds of distributed learning algorithms from the view of algorithmic stability. First, we introduce a definition of uniform distributed stability for distributed algorithms and study the distributed algorithms' generalization risk bounds. Then, we analyze the stability properties and generalization risk bounds of a kind of regularization-based distributed algorithms. Two generalization distributed risks obtained show that the generalization distributed risk bounds for the difference between their generalization distributed and empirical distributed/leave-one-computer-out risks are closely related to the size of samples n and the amount of working computers m mathcal O(m/n(1/2)). Furthermore, the results in this paper indicate that, for a good generalization regularized distributed kernel algorithm, the regularization parameter lambda should be adjusted with the change of the term m/n(1/2). These theoretic discoveries provide the useful guidance when deploying the distributed algorithms on practical big data platforms. We explore our theoretic analyses through two simulation experiments. Finally, we discuss some problems about the sufficient amount of working computers, nonequivalence, and generalization for distributed learning. We show that the rules for the computation on one single computer may not always hold for distributed learning.																	2162-237X	2162-2388				MAR	2020	31	3					801	812		10.1109/TNNLS.2019.2910188													
J								Recurrent Neural Networks With External Addressable Long-Term and Working Memory for Learning Long-Term Dependences	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Recurrent neural networks; Logic gates; Random access memory; Memory architecture; Microprocessors; External addressable memory (EAM); long-term memory; recurrent neural network (RNN); working memory		Learning long-term dependences (LTDs) with recurrent neural networks (RNNs) is challenging due to their limited internal memories. In this paper, we propose a new external memory architecture for RNNs called an external addressable long-term and working memory (EALWM)-augmented RNN. This architecture has two distinct advantages over existing neural external memory architectures, namely the division of the external memory into two parts-long-term memory and working memory-with both addressable and the capability to learn LTDs without suffering from vanishing gradients with necessary assumptions. The experimental results on algorithm learning, language modeling, and question answering demonstrate that the proposed neural memory architecture is promising for practical applications.																	2162-237X	2162-2388				MAR	2020	31	3					813	826		10.1109/TNNLS.2019.2910302													
J								Log-Sum-Exp Neural Networks and Posynomial Models for Convex and Log-Log-Convex Data	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convex optimization; data-driven optimization; feedforward neural networks (FFNNs); function approximation; geometric programming (GP); surrogate models; tropical polynomials	MULTILAYER FEEDFORWARD NETWORKS; APPROXIMATION; SIMULATION	In this paper, we show that a one-layer feedforward neural network with exponential activation functions in the inner layer and logarithmic activation in the output neuron is a universal approximator of convex functions. Such a network represents a family of scaled log-sum exponential functions, here named log-sum-exp (LSET). Under a suitable exponential transformation, the class of LSET functions maps to a family of generalized posynomials GPOS(T), which we similarly show to be universal approximators for log-log-convex functions. A key feature of an LSET network is that, once it is trained on data, the resulting model is convex in the variables, which makes it readily amenable to efficient design based on convex optimization. Similarly, once a GPOS(T) model is trained on data, it yields a posynomial model that can be efficiently optimized with respect to its variables by using geometric programming (GP). The proposed methodology is illustrated by two numerical examples, in which, first, models are constructed from simulation data of the two physical processes (namely, the level of vibration in a vehicle suspension system, and the peak power generated by the combustion of propane), and then optimization-based design is performed on these models.																	2162-237X	2162-2388				MAR	2020	31	3					827	838		10.1109/TNNLS.2019.2910417													
J								A Robust Visual System for Small Target Motion Detection Against Cluttered Moving Backgrounds	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Visual systems; Visualization; Neurons; Insects; Motion detection; Sensitivity; Background motion; cluttered natural environment; neural modeling; small target motion detector (STMD); visual system model	COLLISION DETECTION; MODEL; VISION; MECHANISM; PATHWAYS; NEURONS	Monitoring small objects against cluttered moving backgrounds is a huge challenge to future robotic vision systems. As a source of inspiration, insects are quite apt at searching for mates and tracking prey, which always appear as small dim speckles in the visual field. The exquisite sensitivity of insects for small target motion, as revealed recently, is coming from a class of specific neurons called small target motion detectors (STMDs). Although a few STMD-based models have been proposed, these existing models only use motion information for small target detection and cannot discriminate small targets from small-target-like background features (named fake features). To address this problem, this paper proposes a novel visual system model (STMD+) for small target motion detection, which is composed of four subsystems-ommatidia, motion pathway, contrast pathway, and mushroom body. Compared with the existing STMD-based models, the additional contrast pathway extracts directional contrast from luminance signals to eliminate false positive background motion. The directional contrast and the extracted motion information by the motion pathway are integrated into the mushroom body for small target discrimination. Extensive experiments showed the significant and consistent improvements of the proposed visual system model over the existing STMD-based models against fake features.																	2162-237X	2162-2388				MAR	2020	31	3					839	853		10.1109/TNNLS.2019.2910418													
J								Trajectory Tracking on Uncertain Complex Networks via NN-Based Inverse Optimal Pinning Control	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Complex networks; Artificial neural networks; Trajectory tracking; Optimal control; Neurons; Couplings; Synchronization; Chaotic system; complex network; inverse optimal control; neural network (NN); pinning control; trajectory tracking	DYNAMICAL NETWORKS; NONLINEAR CONTROL; NEURAL-NETWORKS; SYNCHRONIZATION; SYSTEMS	A new approach for trajectory tracking on uncertain complex networks is proposed. To achieve this goal, a neural controller is applied to a small fraction of nodes (pinned ones). Such controller is composed of an on-line identifier based on a recurrent high-order neural network, and an inverse optimal controller to track the desired trajectory; a complete stability analysis is also included. In order to verify the applicability and good performance of the proposed control scheme, a representative example is simulated, which consists of a complex network with each node described by a chaotic Lorenz oscillator.																	2162-237X	2162-2388				MAR	2020	31	3					854	864		10.1109/TNNLS.2019.2910504													
J								Nonsynaptic Error Backpropagation in Long-Term Cognitive Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Associative memories; cognitive mapping; error backpropagation; long-term memory; nonsynaptic learning; recurrent neural networks	CONVERGENCE	We introduce a neural cognitive mapping technique named long-term cognitive network (LTCN) that is able to memorize long-term dependencies between a sequence of input and output vectors, especially in those scenarios that require predicting the values of multiple dependent variables at the same time. The proposed technique is an extension of a recently proposed method named short-term cognitive network that aims at preserving the expert knowledge encoded in the weight matrix while optimizing the nonlinear mappings provided by the transfer function of each neuron. A nonsynaptic, backpropagation-based learning algorithm powered by stochastic gradient descent is put forward to iteratively optimize four parameters of the generalized sigmoid transfer function associated with each neuron. Numerical simulations over 35 multivariate regression and pattern completion data sets confirm that the proposed LTCN algorithm attains statistically significant performance differences with respect to other well-known state-of-the-art methods.																	2162-237X	2162-2388				MAR	2020	31	3					865	875		10.1109/TNNLS.2019.2910555													
J								Bipartite Differential Neural Network for Unsupervised Image Change Detection	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Buildings; Image segmentation; Neural networks; Image resolution; Geology; Imaging; Change detection; convolutional neural networks (CNNs); deep learning; image coregistration; unsupervised learning	SAR IMAGES; DEEP; REGISTRATION	Image change detection detects the regions of change in multiple images of the same scene taken at different times, which plays a crucial role in many applications. The two most popular image change detection techniques are as follows: pixel-based methods heavily rely on accurate image coregistration while object-based approaches can tolerate coregistration errors to some extent but are sensitive to image segmentation or classification errors. To address these issues, we propose an unsupervised image change detection approach based on a novel bipartite differential neural network (BDNN). The BDNN is a deep neural network with two input ends, which can extract the holistic features from the unchanged regions in the two input images, where two learnable change disguise maps (CDMs) are used to disguise the changed regions in the two input images, respectively, and thus demarcate the unchanged regions therein. The network parameters and CDMs will be learned by optimizing an objective function, which combines a loss function defined as the likelihood of the given input image pair over all possible input image pairs and two constraints imposed on CDMs. Compared with the pixel-based and object-based techniques, the BDNN is less sensitive to inaccurate image coregistration and does not involve image segmentation or classification. In fact, it can even skip over coregistration if the degree of transformation (due to the different view angles and/or positions of the camera) between the two input images is not that large. We compare the proposed approach with several state-of-the-art image change detection methods on various homogeneous and heterogeneous image pairs with and without coregistration. The results demonstrate the superiority of the proposed approach.																	2162-237X	2162-2388				MAR	2020	31	3					876	890		10.1109/TNNLS.2019.2910571													
J								A Switched Operation Approach to Sampled-Data Control Stabilization of Fuzzy Memristive Neural Networks With Time-Varying Delay	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Delays; Switches; Artificial neural networks; Memristors; Delay effects; Fuzzy memristive neural networks (FMNNs); sampled-data control; stabilization; time-varying delay	COMPLEX DYNAMICAL NETWORKS; EXPONENTIAL STABILIZATION; IMPULSIVE CONTROL; SYNCHRONIZATION; STABILITY; SYSTEMS; DESIGN; DISCRETE; MODEL	This paper investigates the issue of sampled-data stabilization for Takagi-Sugeno fuzzy memristive neural networks (FMNNs) with time-varying delay. First, the concerned FMNNs are transformed into the tractable fuzzy NNs based on the excitatory and inhibitory of memristive synaptic weights using a new convex combination technique. Meanwhile, a switched fuzzy sampled-data controller is employed for the first time to tackle stability problems related to FMNNs. Then, the novel stabilization criteria of the FMNNs are established using the fuzzy membership functions (FMFs)-dependent Lyapunov-Krasovskii functional. This sufficiently utilizes information from not only the delayed state and the actual sampling pattern but also the FMFs. Two simulation examples are presented to demonstrate the feasibility and validity of the proposed method.																	2162-237X	2162-2388				MAR	2020	31	3					891	900		10.1109/TNNLS.2019.2910574													
J								Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Cranes; Payloads; Task analysis; Robustness; Marine vehicles; Stability analysis; Hardware; Antiswing control; motion control; neural networks; ship-mounted cranes; underactuated systems	OVERHEAD CRANE; CONTAINER CRANE; SHAPING CONTROL; COMPENSATION; DYNAMICS; SYSTEMS; STABILIZATION; PARAMETERS; PAYLOAD; DESIGN	As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.																	2162-237X	2162-2388				MAR	2020	31	3					901	914		10.1109/TNNLS.2019.2910580													
J								Robust and Sparse Linear Discriminant Analysis via an Alternating Direction Method of Multipliers	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Alternating direction method of multipliers (ADMMs); dimensionality reduction (DR); linear discriminant analysis (LDA); robust linear discriminant analysis (RLDA); sparse feature extraction	PRINCIPAL COMPONENT ANALYSIS; CONVERGENCE RATE; LEAST-SQUARES; ALGORITHMS	In this paper, we propose a robust linear discriminant analysis (RLDA) through Bhattacharyya error bound optimization. RLDA considers a nonconvex problem with the L-1-norm operation that makes it less sensitive to outliers and noise than the L-2-norm linear discriminant analysis (LDA). In addition, we extend our RLDA to a sparse model (RSLDA). Both RLDA and RSLDA can extract unbounded numbers of features and avoid the small sample size (SSS) problem, and an alternating direction method of multipliers (ADMM) is used to cope with the nonconvexity in the proposed formulations. Compared with the traditional LDA, our RLDA and RSLDA are more robust to outliers and noise, and RSLDA can obtain sparse discriminant directions. These findings are supported by experiments on artificial data sets as well as human face databases.																	2162-237X	2162-2388				MAR	2020	31	3					915	926		10.1109/TNNLS.2019.2910991													
J								From Whole to Part: Reference-Based Representation for Clustering Categorical Data	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Categorical data; clustering; dimensionality reduction; dissimilarity measure; space structure	ALGORITHM	Dissimilarity measures play a crucial role in clustering and, are directly related to the performance of clustering algorithms. However, effectively measuring the dissimilarity is not easy, especially for categorical data. The main difficulty of the dissimilarity measurement for categorical data is that its representation lacks a clear space structure. Therefore, the space structure-based representation has been proposed to provide the categorical data with a clear linear representation space. This representation improves the clustering performance obviously but only applies to small data sets because its dimensionality increases rapidly with the size of the data set. In this paper, we investigate the possibility of reducing the dimensionality of the space structure-based representation while maintaining the same representation ability. A lightweight representation scheme is proposed by taking a set of representative objects as the reference system (called the reference set) to position other objects in the Euclidean space. Moreover, a preclustering-based strategy is designed to select an appropriate reference set quickly. Finally, the representation scheme together with the k-means algorithm provides an efficient method to cluster the categorical data. The theoretical and the experimental analysis shows that the proposed method outperforms state-of-the-art methods in terms of both accuracy and efficiency.																	2162-237X	2162-2388				MAR	2020	31	3					927	937		10.1109/TNNLS.2019.2911118													
J								Cognitive Action Laws: The Case of Visual Features	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Boundary conditions; Mathematical model; Visualization; Computer vision; Kinetic energy; Indexes; Cognitive action; cognitive action laws; information overloading control; stochastic gradient descent; visual features	SLOW FEATURE ANALYSIS	This paper proposes a theory for understanding perceptual learning processes within the general framework of laws of nature. Artificial neural networks are regarded as systems whose connections are Lagrangian variables, namely, functions depending on time. They are used to minimize the cognitive action, an appropriate functional index that measures the agent interactions with the environment. The cognitive action contains a potential and a kinetic term that nicely resemble the classic formulation of regularization in machine learning. A special choice of the functional index, which leads to the fourth-order differential equations-Cognitive Action Laws (CAL)-exhibits a structure that mirrors classic formulation of machine learning. In particular, unlike the action of mechanics, the stationarity condition corresponds with the global minimum. Moreover, it is proven that typical asymptotic learning conditions on the weights can coexist with the initialization provided that the system dynamics is driven under a policy referred to as information overloading control. Finally, the theory is experimented for the problem of feature extraction in computer vision.																	2162-237X	2162-2388				MAR	2020	31	3					938	949		10.1109/TNNLS.2019.2911174													
J								Convolutional Neural Networks as Asymmetric Volterra Models Based on Generalized Orthonormal Basis Functions	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Kernel; Mathematical model; Convolution; Convolutional neural networks; Nonlinear systems; Computational modeling; Convolutional neural networks (CNNs); generalized orthonormal basis functions (GOBFs); system identification; Volterra models		This paper introduces a convolutional neural network (CNN) approach to derive Volterra models of dynamical systems based on generalized orthonormal basis function (GOBF)-Volterra. The approach derives the parameters of the model through a CNN and the neural network's learned weights represent the poles of a system. Simulation results show that the parameters of the system can be exactly recovered when no noise is applied. Furthermore, when noise is present, the errors in the parameters are very small for both the linear and nonlinear cases. Finally, the approach is used to identify the model of a quadcopter using data from actual flight tests. Comparisons with previous works demonstrate that CNNs can be satisfactorily used for the identification of dynamical systems.																	2162-237X	2162-2388				MAR	2020	31	3					950	959		10.1109/TNNLS.2019.2911603													
J								Synchronization of the Networked System With Continuous and Impulsive Hybrid Communications	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Synchronization; Topology; Network topology; Switches; Sun; Learning systems; Lyapunov methods; Directed spanning tree (DST); hybrid communications; neural networks; synchronization	TIME-VARYING DELAYS; VALUED NEURAL-NETWORKS; DYNAMICAL NETWORKS; STABILITY ANALYSIS; COMPLEX NETWORKS; FLOCKING; STABILIZATION	Many networked systems display some kind of dynamics behaving in a style with both continuous and impulsive communications. The cooperation behaviors of these networked systems with continuous connected or impulsive connected or both connected topologies of communications are important to understand. This paper is devoted to the synchronization of the networked system with continuous and impulsive hybrid communications, where each topology of communication mode is not connected in every moment. Two kind of structures, i.e., fixed structure and switching structures, are taken into consideration. A general concept of directed spanning tree (DST) is proposed to describe the connectivity of the networked system with hybrid communication modes. The suitable Lyapunov functions are constructed to analyze the synchronization stability. It is showed that for fixed topology having a jointly DST, the networked system with continuous and impulsive hybrid communication modes will achieve asymptotic synchronization if the feedback gain matrix and the average impulsive interval are properly selected. The results are then extended to the switching case where the graph has a frequently jointly DST. Some simple examples are then given to illustrate the derived synchronization criteria.																	2162-237X	2162-2388				MAR	2020	31	3					960	971		10.1109/TNNLS.2019.2911926													
J								Adaptive Neural Output-Feedback Decentralized Control for Large-Scale Nonlinear Systems With Stochastic Disturbances	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptive neural control; large-scale systems; stochastic disturbances	TRACKING CONTROL; CONTROL DESIGN; DELAY SYSTEMS; TIME-DELAY; NETWORK; STABILIZATION	This paper addresses the problem of adaptive neural output-feedback decentralized control for a class of strongly interconnected nonlinear systems suffering stochastic disturbances. An state observer is designed to approximate the unmeasurable state signals. Using the approximation capability of radial basis function neural networks (NNs) and employing classic adaptive control strategy, an observer-based adaptive backstepping decentralized controller is developed. In the control design process, NNs are applied to model the uncertain nonlinear functions, and adaptive control and backstepping are combined to construct the controller. The developed control scheme can guarantee that all signals in the closed-loop systems are semiglobally uniformly ultimately bounded in fourth-moment. The simulation results demonstrate the effectiveness of the presented control scheme.																	2162-237X	2162-2388				MAR	2020	31	3					972	983		10.1109/TNNLS.2019.2912082													
J								Heterogeneous Domain Adaptation via Nonlinear Matrix Factorization	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Kernel; Task analysis; Training; Object recognition; Correlation; Hilbert space; Deep learning; Heterogeneous domain adaptation (HDA); matrix factorization; reproducing kernel Hilbert space (RKHS)	KERNEL	Heterogeneous domain adaptation (HDA) aims to solve the learning problems where the source- and the target-domain data are represented by heterogeneous types of features. The existing HDA approaches based on matrix completion or matrix factorization have proven to be effective to capture shareable information between heterogeneous domains. However, there are two limitations in the existing methods. First, a large number of corresponding data instances between the source domain and the target domain are required to bridge the gap between different domains for performing matrix completion. These corresponding data instances may be difficult to collect in real-world applications due to the limited size of data in the target domain. Second, most existing methods can only capture linear correlations between features and data instances while performing matrix completion for HDA. In this paper, we address these two issues by proposing a new matrix-factorization-based HDA method in a semisupervised manner, where only a few labeled data are required in the target domain without requiring any corresponding data instances between domains. Such labeled data are more practical to obtain compared with cross-domain corresponding data instances. Our proposed algorithm is based on matrix factorization in an approximated reproducing kernel Hilbert space (RKHS), where nonlinear correlations between features and data instances can be exploited to learn heterogeneous features for both the source and the target domains. Extensive experiments are conducted on cross-domain text classification and object recognition, and experimental results demonstrate the superiority of our proposed method compared with the state-of-the-art HDA approaches.																	2162-237X	2162-2388				MAR	2020	31	3					984	996		10.1109/TNNLS.2019.2913723													
J								Global Stabilization of Fractional-Order Memristor-Based Neural Networks With Time Delay	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Memristors; State feedback; Stability analysis; Biological neural networks; Synchronization; Capacitors; Linear matrix inequalities; Delay; fractional-order nonlinear systems; linear matrix inequalities (LMIs); memristor-based neural networks (MNNs); Mittag-Leffler stability; stabilization	SYNCHRONIZATION; STABILITY; DYNAMICS; CHAOS	This paper addresses the global stabilization of fractional-order memristor-based neural networks (FMNNs) with time delay. The voltage threshold type memristor model is considered, and the FMNNs are represented by fractional-order differential equations with discontinuous right-hand sides. Then, the problem is addressed based on fractional-order differential inclusions and set-valued maps, together with the aid of Lyapunov functions and the comparison principle. Two types of control laws (delayed state feedback control and coupling state feedback control) are designed. Accordingly, two types of stabilization criteria [algebraic form and linear matrix inequality (LMI) form] are established. There are two groups of adjustable parameters included in the delayed state feedback control, which can be selected flexibly to achieve the desired global asymptotic stabilization or global Mittag-Leffler stabilization. Since the existing LMI-based stability analysis techniques for fractional-order systems are not applicable to delayed fractional-order nonlinear systems, a fractional-order differential inequality is established to overcome this difficulty. Based on the coupling state feedback control, some LMI stabilization criteria are developed for the first time with the help of the newly established fractional-order differential inequality. The obtained LMI results provide new insights into the research of delayed fractional-order nonlinear systems. Finally, three numerical examples are presented to illustrate the effectiveness of the proposed theoretical results.																	2162-237X	2162-2388				MAR	2020	31	3					997	1009		10.1109/TNNLS.2019.2915353													
J								Neural Networks-Based Distributed Adaptive Control of Nonlinear Multiagent Systems	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptive control; Synchronization; Decentralized control; Nonlinear dynamical systems; Laplace equations; Learning systems; Multi-agent systems; Cooperative control; leader-following consensus; prescribed performance; unmodeled dynamics	TRACKING CONTROL; FEEDBACK; CONSENSUS; DESIGN; SYNCHRONIZATION; UNCERTAINTIES; DYNAMICS; AFFINE	The cooperative control problem of nonlinear multiagent systems is studied in this paper. The followers in the communication network are subject to unmodeled dynamics. A fully distributed neural-networks-based adaptive control strategy is designed to guarantee that all the followers are asymptotically synchronized to the leader, and the synchronization errors are within a prescribed level, where some global information, such as minimum and maximum singular value of graph adjacency matrix, is not necessarily to be known. Based on the Lyapunov stability theory and algebraic graph theory, the stability analysis of the resulting closed-loop system is provided. Finally, an numerical example illustrates the effectiveness and potential of the proposed new design techniques.																	2162-237X	2162-2388				MAR	2020	31	3					1010	1021		10.1109/TNNLS.2019.2915376													
J								Constrained Quaternion-Variable Convex Optimization: A Quaternion-Valued Recurrent Neural Network Approach	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Quaternions; Optimization; Convex functions; Recurrent neural networks; Calculus; Biological neural networks; Collective intelligence; Constrained convex optimization; generalized gradient inclusion; generalized Hamilton-real (GHR) calculus; Lyapunov function	SINGULAR SPECTRUM ANALYSIS; FINITE-TIME CONSENSUS; MULTIAGENT SYSTEMS; GRADIENT OPERATOR; COMPLEX MATRIX	This paper proposes a quaternion-valued one-layer recurrent neural network approach to resolve constrained convex function optimization problems with quaternion variables. Leveraging the novel generalized Hamilton-real (GHR) calculus, the quaternion gradient-based optimization techniques are proposed to derive the optimization algorithms in the quaternion field directly rather than the methods of decomposing the optimization problems into the complex domain or the real domain. Via chain rules and Lyapunov theorem, the rigorous analysis shows that the deliberately designed quaternion-valued one-layer recurrent neural network stabilizes the system dynamics while the states reach the feasible region in finite time and converges to the optimal solution of the considered constrained convex optimization problems finally. Numerical simulations verify the theoretical results.																	2162-237X	2162-2388				MAR	2020	31	3					1022	1035		10.1109/TNNLS.2019.2916597													
J								Consensus Tracking Control of Switched Stochastic Nonlinear Multiagent Systems via Event-Triggered Strategy	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Multi-agent systems; Switches; Protocols; Consensus algorithm; Nonlinear dynamical systems; Learning systems; Consensus tracking; event-triggered control; multiagent systems; stochastic systems; switched systems	LEADER-FOLLOWING CONSENSUS; MEAN-SQUARE CONSENSUS; TIME; SYNCHRONIZATION; NETWORKS	In this paper, the consensus tracking problem is investigated for a class of continuous switched stochastic nonlinear multiagent systems with an event-triggered control strategy. For continuous stochastic multiagent systems via event-triggered protocols, it is rather difficult to avoid the Zeno behavior by the existing methods. Thus, we propose a new protocol design framework for the underlying systems. It is proven that follower agents can almost surely track the given leader signal with bounded errors and no agent exhibits the Zeno behavior by the given control scheme. Finally, two numerical examples are given to illustrate the effectiveness and advantages of the new design techniques.																	2162-237X	2162-2388				MAR	2020	31	3					1036	1045		10.1109/TNNLS.2019.2917137													
J								The Robustness of Outputs With Respect to Disturbances for Boolean Control Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Robustness; Learning systems; Matrix converters; Genetics; Matrix decomposition; Collective intelligence; Boolean control network (BCN); robustness; semi-tensor product (STP); output	STABILITY; DESIGN	In this brief, we investigate the robustness of outputs with respect to disturbances for Boolean control networks (BCNs) by semi-tensor product (STP) of matrices. First, BCNs are converted into the corresponding algebraic forms by STP, then two sufficient conditions for the robustness are derived. Moreover, the corresponding permutation system and permutation graph are constructed. It is proven that if there exist controllers such that the outputs of permutation systems are robust with respect to disturbances, then there must also exist controllers such that the outputs of the corresponding original systems achieve robustness with respect to disturbances. One effective method is proposed to construct controllers to achieve robustness. Examples are also provided to illustrate the correctness of the obtained results.																	2162-237X	2162-2388				MAR	2020	31	3					1046	1051		10.1109/TNNLS.2019.2910193													
J								Composite Learning Enhanced Robot Impedance Control	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Impedance; Convergence; Robots; Stability criteria; Uncertainty; Parameter estimation; Adaptive control; composite adaptation; impedance control; learning control; parameter convergence; robot		The desired impedance dynamics can be achieved for a robot if and only if an impedance error converges to zero or a small neighborhood of zero. Although the convergence of impedance errors is important, it is seldom obtained in the existing impedance controllers due to robots modeling uncertainties and external disturbances. This brief proposes two composite learning impedance controllers (CLICs) for robots with parameter uncertainties based on whether a factorization assumption is satisfied or not. In the proposed control designs, the convergence of impedance errors, reflected by the convergence of parameter estimation errors and some auxiliary errors, is achieved by using composite learning laws under a relaxed excitation condition. The theoretical results are proven based on the Lyapunov theory. The effectiveness and advantages of the proposed CLICs are validated by simulations on a parallel robot in three cases.																	2162-237X	2162-2388				MAR	2020	31	3					1052	1059		10.1109/TNNLS.2019.2912212													
J								Robust Event-Triggered Control Invariance of Probabilistic Boolean Control Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Probabilistic logic; Robust control; State feedback; Biological system modeling; Learning systems; Event-triggered control (ETC); probabilistic Boolean control network (PBCN); robust control invariance; semi-tensor product (STP)	STABILIZATION; CONTROLLABILITY; STABILITY	In this brief, the robust control invariance problem of probabilistic Boolean control networks (PBCNs) is investigated by a class of event-triggered control (ETC), which is an intermittent control scheme in essential. By resorting to the semi-tensor product (STP) technique, a PBCN with ETC can be equivalently described in a form of an algebraic linear system. Based on which, a matrix testing condition is derived to judge whether the given set can be a robust ETC invariant set (RETCIS). Subsequently, a necessary and sufficient condition is developed for the existence of event-triggered controllers. Meanwhile, all feasible event-triggered controllers are designed for guaranteeing the given set to be an RETCIS. Finally, a biological example is employed to demonstrate the availability of theoretical results.																	2162-237X	2162-2388				MAR	2020	31	3					1060	1065		10.1109/TNNLS.2019.2917753													
J								Comments on "Fractional Extreme Value Adaptive Training Method: Fractional Steepest Descent Approach"	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convergence; Signal processing algorithms; Adaptive learning; Estimation; Learning systems; Training; Steady-state; Fractional calculus; fractional differential; fractional energy norm; fractional extreme point; fractional gradient		In this comment, we raise serious concerns over the derivation of the rate of convergence of fractional steepest descent algorithm in fractional adaptive learning approach presented in "Fractional Extreme Value Adaptive Training Method: Fractional Steepest Descent Approach." We substantiate that the estimate of the rate of convergence is grandiloquent. We also draw attention toward a critical flaw in the design of the algorithm stymieing its applicability for broad adaptive learning problems. Our claims are based on analytical reasoning supported by experimental results.																	2162-237X	2162-2388				MAR	2020	31	3					1066	1068		10.1109/TNNLS.2019.2899219													
J								Automatic computation of mandibular indices in dental panoramic radiographs for early osteoporosis detection	ARTIFICIAL INTELLIGENCE IN MEDICINE										Intelligent image segmentation; Computer vision; Artificial intelligence; Mandibular indices; Mandibular bony structures; Dental panoramic radiographs; Osteoporosis	BONE-MINERAL DENSITY; CORTICAL WIDTH; TRABECULAR BONE; POSTMENOPAUSAL WOMEN; TEXTURE ANALYSIS; DIAGNOSIS; RISK; MASS; FEATURES; EROSION	Aim: A new automatic method for detecting specific points and lines (straight and curves) in dental panoramic radiographies (orthopantomographies) is proposed, where the human knowledge is mapped to the automatic system. The goal is to compute relevant mandibular indices (Mandibular Cortical Width, Panoramic Mandibular Index, Mandibular Ratio, Mandibular Cortical Index) in order to detect the thinning and deterioration of the mandibular bone. Data can be stored for posterior massive analysis. Methods: Panoramic radiographies are intrinsically complex, including: artificial structures, unclear limits in bony structures, jawbones with irregular curvatures and intensity levels, irregular shapes and borders of the mental foramen, irregular teeth alignments or missing dental pieces. An intelligent sequence of linked imaging segmentation processes is proposed to cope with the above situations towards the design of the automatic segmentation, making the following contributions: (i) Fuzzy K-means classification for identifying artificial structures; (ii) adjust a tangent line to the lower border of the lower jawbone (lower cortex), based on texture analysis, grey scale dilation, binarization and labelling; (iii) identification of the mental foramen region and its centre, based on multi-thresholding, binarization, morphological operations and labelling; (iv) tracing a perpendicular line to the tangent passing through the centre of the mental foramen region and two parallel lines to the tangent, passing through borders on the mental foramen intersected by the perpendicular; (v) following the perpendicular line, a sweep is made moving up the tangent for detecting accumulation of binary points after applying adaptive filtering; (vi) detection of the lower mandible alveolar crest line based on the identification of inter-teeth gaps by saliency and interest points feature description. Results: The performance of the proposed approach was quantitatively compared against the criteria of expert dentists, verifying also its validity with statistical studies based on the analysis of deterioration of bone structures with different levels of osteoporosis. All indices are computed inside two regions of interest, which tolerate flexibility in sizes and locations, making this process robust enough. Conclusions: The proposed approach provides an automatic procedure able to process with efficiency and reliability panoramic X-Ray images for early osteoporosis detection.																	0933-3657	1873-2860				MAR	2020	103								101816	10.1016/j.artmed.2020.101816													
J								Classification of glomerular hypercellularity using convolutional features and support vector machine	ARTIFICIAL INTELLIGENCE IN MEDICINE										Hypercellularity; Human kidney biopsy; Convolutional neural network	DEEP; NETWORK; IMAGES	Glomeruli are histological structures of the kidney cortex formed by interwoven blood capillaries, and are responsible for blood filtration. Glomerular lesions impair kidney filtration capability, leading to protein loss and metabolic waste retention. An example of lesion is the glomerular hypercellularity, which is characterized by an increase in the number of cell nuclei in different areas of the glomeruli. Glomerular hypercellularity is a frequent lesion present in different kidney diseases. Automatic detection of glomerular hypercellularity would accelerate the screening of scanned histological slides for the lesion, enhancing clinical diagnosis. Having this in mind, we propose a new approach for classification of hypercellularity in human kidney images. Our proposed method introduces a novel architecture of a convolutional neural network (CNN) along with a support vector machine, achieving near perfect average results on FIOCRUZ data set in a binary classification (lesion or normal). Additionally, classification of hypercellularity sub-lesions was also evaluated, considering mesangial, endocapilar and both lesions, reaching an average accuracy of 82%. Either in binary task or in the multi-classification one, our proposed method outperformed Xception, ResNet50 and InceptionV3 networks, as well as a traditional handcrafted-based method. To the best of our knowledge, this is the first study on deep learning over a data set of glomerular hypercellularity images of human kidney.																	0933-3657	1873-2860				MAR	2020	103								101808	10.1016/j.artmed.2020.101808													
J								A fusion framework to extract typical treatment patterns from electronic medical records	ARTIFICIAL INTELLIGENCE IN MEDICINE										Electronic medical records; Similarity network fusion; Clustering analysis; Treatment pattern extraction	SYSTEM	Objective: Electronic Medical Records (EMRs) contain temporal and heterogeneous doctor order information that can be used for treatment pattern discovery. Our objective is to identify "right patient", "right drug", "right dose", "right route", and "right time" from doctor order information. Methods: We propose a fusion framework to extract typical treatment patterns based on multi-view similarity Network Fusion (SNF) method. The multi-view SNF method involves three similarity measures: content-view similarity, sequence-view similarity and duration-view similarity. An EMR dataset and two metrics were utilized to evaluate the performance and to extract typical treatment patterns. Results: Experimental results on a real-world EMR dataset show that the multi-view similarity network fusion method outperforms all the single-view similarity measures and also outperforms the existing similarity measure methods. Furthermore, we extract and visualize typical treatment patterns by clustering analysis. Conclusion: The extracted typical treatment patterns by combining doctor order content, sequence, and duration views can provide data-driven guidelines for artificial intelligence in medicine and help clinicians make better decisions in clinical practice.																	0933-3657	1873-2860				MAR	2020	103								101782	10.1016/j.artmed.2019.101782													
J								ADHD classification by dual subspace learning using resting-state functional connectivity	ARTIFICIAL INTELLIGENCE IN MEDICINE										ADHD; Feature selection; Graph embedding; Graph Laplacian; Subspace learning; SVM-RFE	DEFICIT HYPERACTIVITY DISORDER; INDIVIDUALS	As one of the most common neurobehavioral diseases in school-age children, Attention Deficit Hyperactivity Disorder (ADHD) has been increasingly studied in recent years. But it is still a challenge problem to accurately identify ADHD patients from healthy persons. To address this issue, we propose a dual subspace classification algorithm by using individual resting-state Functional Connectivity (FC). In detail, two subspaces respectively containing ADHD and healthy control features, called as dual subspaces, are learned with several subspace measures, wherein a modified graph embedding measure is employed to enhance the intra-class relationship of these features. Therefore, given a subject (used as test data) with its FCs, the basic classification principle is to compare its projected component energy of FCs on each subspace and then predict the ADHD or control label according to the subspace with larger energy. However, this principle in practice works with low efficiency, since the dual subspaces are unstably obtained from ADHD databases of small size. Thereby, we present an ADHD classification framework by a binary hypothesis testing of test data. Here, the FCs of test data with its ADHD or control label hypothesis are employed in the discriminative FC selection of training data to promote the stability of dual subspaces. For each hypothesis, the dual subspaces are learned from the selected FCs of training data. The total projected energy of these FCs is also calculated on the subspaces. Sequentially, the energy comparison is carried out under the binary hypotheses. The ADHD or control label is finally predicted for test data with the hypothesis of larger total energy. In the experiments on ADHD-200 dataset, our method achieves a significant classification performance compared with several state-of-the-art machine learning and deep learning methods, where our accuracy is about 90 % for most of ADHD databases in the leave-one-out cross-validation test.																	0933-3657	1873-2860				MAR	2020	103								101786	10.1016/j.artmed.2019.101786													
J								Mixed-integer optimization approach to learning association rules for unplanned ICU transfer	ARTIFICIAL INTELLIGENCE IN MEDICINE										Emergency department; Critical care; Unplanned ICU transfer; Association rule; Mixed-integer optimization	INTENSIVE-CARE-UNIT; EARLY WARNING SCORE; EMERGENCY-DEPARTMENT; RISK-FACTORS; ADMISSION; MORBIDITY; SELECTION; PREDICT; SEPSIS	After admission to emergency department (ED), patients with critical illnesses are transferred to intensive care unit (ICU) due to unexpected clinical deterioration occurrence. Identifying such unplanned ICU transfers is urgently needed for medical physicians to achieve two-fold goals: improving critical care quality and preventing mortality. A priority task is to understand the crucial rationale behind diagnosis results of individual patients during stay in ED, which helps prepare for an early transfer to ICU. Most existing prediction studies were based on univariate analysis or multiple logistic regression to provide one-size-fit-all results. However, patient condition varying from case to case may not be accurately examined by such a simplistic judgment. In this study, we present a new decision tool using a mathematical optimization approach aiming to automatically discover rules associating diagnostic features with high-risk outcome (i.e., unplanned transfers) in different deterioration scenarios. We consider four mutually exclusive patient subgroups based on the principal reasons of ED visits: infections, cardiovascular/respiratory diseases, gastrointestinal diseases, and neurological/other diseases at a suburban teaching hospital. The analysis results demonstrate significant rules associated with unplanned transfer outcome for each subgroups and also show comparable prediction accuracy (>70%) compared to state-of-the-art machine learning methods while providing easy-to-interpret symptom-outcome information.																	0933-3657	1873-2860				MAR	2020	103								101806	10.1016/j.artmed.2020.101806													
J								Batch Mode Active Learning on the Riemannian Manifold for Automated Scoring of Nuclear Pleomorphism in Breast Cancer	ARTIFICIAL INTELLIGENCE IN MEDICINE										Batch Mode Active Learning; Nuclear Atypia Scoring; Riemannian Manifold; Histopathological Image Analysis; Submodular Optimization	HISTOPATHOLOGICAL IMAGE-ANALYSIS; REGION COVARIANCE; PROGNOSTIC VALUE; CLASSIFICATION; GRADE; SEGMENTATION; DESCRIPTOR; DIAGNOSIS; FRAMEWORK; FEATURES	Breast cancer is the most prevalent invasive type of cancer among women. The mortality rate of the disease can be reduced considerably through timely prognosis and felicitous treatment planning, by utilizing the computer aided detection and diagnosis techniques. With the advent of whole slide image (WSI) scanners for digitizing the histopathological tissue samples, there is a drastic increase in the availability of digital histopathological images. However, these samples are often unlabeled and hence they need labeling to be done through manual annotations by domain experts and experienced pathologists. But this annotation process required for acquiring high quality large labeled training set for nuclear atypia scoring is a tedious, expensive and time consuming job. Active learning techniques have achieved widespread acceptance in reducing this human effort in annotating the data samples. In this paper, we explore the possibilities of active learning on nuclear pleomorphism scoring over a non-Euclidean framework, the Riemannian manifold. Active learning technique adopted for the cancer grading is in the batch-mode framework, that adaptively identifies the apt batch size along with the batch of instances to be queried, following a submodular optimization framework. Samples for annotation are selected considering the diversity and redundancy between the pair of samples, based on the kernelized Riemannian distance measures such as log-Euclidean metrics and the two Bregman divergences - Stein and Jeffrey divergences. Results of the adaptive Batch Mode Active Learning on the Riemannian metric show a superior performance when compared with the state-of-the-art techniques for breast cancer nuclear pleomorphism scoring, as it makes use of the information from the unlabeled samples.																	0933-3657	1873-2860				MAR	2020	103								101805	10.1016/j.artmed.2020.101805													
J								Measuring the effects of confounders in medical supervised classification problems: the Confounding Index (CI)	ARTIFICIAL INTELLIGENCE IN MEDICINE										Machine learning; Confounding variables; Biomedical data; Classification	GENE-EXPRESSION; SEGMENTATION; AREA; ROC	Over the years, there has been growing interest in using machine learning techniques for biomedical data processing. When tackling these tasks, one needs to bear in mind that biomedical data depends on a variety of characteristics, such as demographic aspects (age, gender, etc.) or the acquisition technology, which might be unrelated with the target of the analysis. In supervised tasks, failing to match the ground truth targets with respect to such characteristics, called confounders, may lead to very misleading estimates of the predictive performance. Many strategies have been proposed to handle confounders, ranging from data selection, to normalization techniques, up to the use of training algorithm for learning with imbalanced data. However, all these solutions require the confounders to be known a priori. To this aim, we introduce a novel index that is able to measure the confounding effect of a data attribute in a bias-agnostic way. This index can be used to quantitatively compare the confounding effects of different variables and to inform correction methods such as normalization procedures or ad-hoc-prepared learning algorithms. The effectiveness of this index is validated on both simulated data and real-world neuroimaging data.																	0933-3657	1873-2860				MAR	2020	103								101804	10.1016/j.artmed.2020.101804													
J								An effective approach for CT lung segmentation using mask region-based convolutional neural networks	ARTIFICIAL INTELLIGENCE IN MEDICINE										Image segmentation lung; Mask R-CNN; Machine learning	ACTIVE CONTOUR METHOD; IMAGE SEGMENTATION; AIR-POLLUTION; MEDICAL DATA; R-CNN; CLASSIFICATION; OPTIMIZATION; PREDICTION; DISEASES; QUALITY	Computer vision systems have numerous tools to assist in various medical fields, notably in image diagnosis. Computed tomography (CT) is the principal imaging method used to assist in the diagnosis of diseases such as bone fractures, lung cancer, heart disease, and emphysema, among others. Lung cancer is one of the four main causes of death in the world. The lung regions in the CT images are marked manually by a specialist as this initial step is a significant challenge for computer vision techniques. Once defined, the lung regions are segmented for clinical diagnoses. This work proposes an automatic segmentation of the lungs in CT images, using the Convolutional Neural Network (CNN) Mask R-CNN, to specialize the model for lung region mapping, combined with supervised and unsupervised machine learning methods (Bayes, Support Vectors Machine (SVM), K-means and Gaussian Mixture Models (GMMs)). Our approach using Mask R-CNN with the K-means kernel produced the best results for lung segmentation reaching an accuracy of 97.68 +/- 3.42% and an average runtime of 11.2 s. We compared our results against other works for validation purposes, and our approach had the highest accuracy and was faster than some state-of-the-art methods.																	0933-3657	1873-2860				MAR	2020	103								101792	10.1016/j.artmed.2020.101792													
J								Scalogram based prediction model for respiratory disorders using optimized convolutional neural networks	ARTIFICIAL INTELLIGENCE IN MEDICINE										Lung sounds; Scalogram; Empirical mode decomposition; Convolutional neural networks; Deep spectrum features; Optimizers	LUNG SOUNDS; TIME-FREQUENCY; CLASSIFICATION	Auscultation of the lung is a conventional technique used for diagnosing chronic obstructive pulmonary diseases (COPDs) and lower respiratory infections and disorders in patients. In most of the earlier works, wavelet transforms or spectrograms have been used to analyze the lung sounds. However, an accurate prediction model for respiratory disorders has not been developed so far. In this paper, a pre-trained optimized Alexnet Convolutional Neural Network (CNN) architecture is proposed for predicting respiratory disorders. The proposed approach models the segmented respiratory sound signal into Bump and Morse scalograms from several intrinsic mode functions (IMFs) using empirical mode decomposition (EMD) method. From the extracted intrinsic mode functions, the percentage energy calculated for each wavelet coefficient in the form of scalograms are computed. Subsequently, these scalograms are given as input to the pre-trained optimized CNN model for training and testing. Stochastic gradient descent with momentum (SGDM) and adaptive data momentum (ADAM) optimization algorithms were examined to check the prediction accuracy on the dataset comprising of four classes of lung sounds, normal, crackles (coarse and fine), wheezes (monophonic & polyphonic) and low-pitched wheezes (Rhonchi). On comparison to the baseline method of standard Bump and Morse wavelet transform approach which produced 79.04 % and 81.27 % validation accuracy, an improved accuracy of 83.78 % is achieved by the virtue of scalogram representation of various IMFs of EMD. Hence, the proposed approach achieves significant performance improvement in accuracy compared to the existing state-of- the-art techniques in literature.																	0933-3657	1873-2860				MAR	2020	103								101809	10.1016/j.artmed.2020.101809													
J								Medical knowledge embedding based on recursive neural network for multi-disease diagnosis	ARTIFICIAL INTELLIGENCE IN MEDICINE										Electronic medical records; First-order logic; Knowledge embedding; Recursive neural network		The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding (Le., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge, but also establish the quantifiable relationship among embeddings. In this paper, we propose a recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with a recursive neural network for multi-disease diagnosis. After the RNKN is efficiently trained using manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. The experimental results confirm that the diagnostic accuracy of the RNKN is superior to those of four machine learning models, four classical neural networks and Markov logic network. The results also demonstrate that the more explicit the evidence extracted from CEMRs, the better the performance. The RNKN gradually reveals the interpretation of knowledge embeddings as the number of training epochs increases.																	0933-3657	1873-2860				MAR	2020	103								101772	10.1016/j.artmed.2019.101772													
J								Gait characteristics and clinical relevance of hereditary spinocerebellar ataxia on deep learning	ARTIFICIAL INTELLIGENCE IN MEDICINE										Hereditary; Spinocerebellar ataxia; Gait characteristics; Cerebellar volume; Wearable gait detector	CEREBELLAR VOLUME	Background: Deep learning has always been at the forefront of scientific research. It has also been applied to medical research. Hereditary spinocerebellar ataxia (SCA) is characterized by gait abnormalities and is usually evaluated semi-quantitatively by scales. However, more detailed gait characteristics of SCA and related objective methods have not yet been established. Therefore, the purpose of this study was to evaluate the gait characteristics of SCA patients, as well as to analyze the correlation between gait parameters, clinical scales, and imaging on deep learning. Methods: Twenty SCA patients diagnosed by genetic detection were included in the study. Ten patients who were tested via functional magnetic resonance imaging (fMRI) were included in the SCA imaging subgroup. All SCA patients were evaluated with the International Cooperative Ataxia Rating Scale (ICARS) and Scale for the Assessment and Rating of Ataxia (SARA) clinical scales. The gait control group included 16 healthy subjects, and the imaging control group included seven healthy subjects. Gait data consisting of 10 m of free walking of each individual in the SCA group and the gait control group were detected by wearable gait-detection equipment. Stride length, stride time, velocity, supporting-phase percentage, and swinging-phase percentage were extracted as gait parameters. Cerebellar volume and the midsagittal cerebellar proportion in the posterior fossa (MRVD) were calculated according to MR. Results: There were significant differences in stride length, velocity, supporting-phase percentage, and swinging-phase percentage between the SCA group and the gait control group. The stride length and stride velocity of SCA groups were lower while supporting phase was longer than those of the gait control group. SCA group's velocity was negatively correlated with both the ICARS and SARA scores. The cerebellar volume and MRVD of the SCA imaging subgroup were significantly smaller than those of the imaging control group. MRVD was significantly correlated with ICARS and SARA scores, as well as stride velocity variability. Conclusion: SCA gait parameters were characterized by a reduced stride length, slower walking velocity, and longer supporting phase. Additionally, a smaller cerebellar volume correlated with an increased irregularity in gait. Gait characteristics exhibited considerable clinical relevance to hereditary SCA. We conclude that a combination of gait parameters, ataxia scales, and MRVD may represent more objective markers for clinical evaluations of SCA.																	0933-3657	1873-2860				MAR	2020	103								101794	10.1016/j.artmed.2020.101794													
J								An incremental explanation of inference in Bayesian networks for increasing model trustworthiness and supporting clinical decision making	ARTIFICIAL INTELLIGENCE IN MEDICINE										Bayesian networks; Explanation of reasoning; Trust; Decision making	ABDUCTION; PREDICTION	Various AI models are increasingly being considered as part of clinical decision-support tools. However, the trustworthiness of such models is rarely considered. Clinicians are more likely to use a model if they can understand and trust its predictions. Key to this is if its underlying reasoning can be explained. A Bayesian network (BN) model has the advantage that it is not a black-box and its reasoning can be explained. In this paper, we propose an incremental explanation of inference that can be applied to 'hybrid' BNs, i.e. those that contain both discrete and continuous nodes. The key questions that we answer are: (1) which important evidence supports or contradicts the prediction, and (2) through which intermediate variables does the information flow. The explanation is illustrated using a real clinical case study. A small evaluation study is also conducted.																	0933-3657	1873-2860				MAR	2020	103								101812	10.1016/j.artmed.2020.101812													
J								A multicenter random forest model for effective prognosis prediction in collaborative clinical research network	ARTIFICIAL INTELLIGENCE IN MEDICINE										Clinical decision support; Distributed privacy-preserving modeling; Ensemble learning; Generative adversarial networks; Variable importance ranking	PRIVACY; CALIBRATION; VALIDATION	Background: The accuracy of a prognostic prediction model has become an essential aspect of the quality and reliability of the health-related decisions made by clinicians in modern medicine. Unfortunately, individual institutions often lack sufficient samples, which might not provide sufficient statistical power for models. One mitigation is to expand data collection from a single institution to multiple centers to collectively increase the sample size. However, sharing sensitive biomedical data for research involves complicated issues. Machine learning models such as random forests (RF), though they are commonly used and achieve good performances for prognostic prediction, usually suffer worse performance under multicenter privacy-preserving data mining scenarios compared to a centrally trained version. Methods and materials: In this study, a multicenter random forest prognosis prediction model is proposed that enables federated clinical data mining from horizontally partitioned datasets. By using a novel data enhancement approach based on a differentially private generative adversarial network customized to clinical prognosis data, the proposed model is able to provide a multicenter RF model with performances on par with-or even better than-centrally trained RF but without the need to aggregate the raw data. Moreover, our model also incorporates an importance ranking step designed for feature selection without sharing patient-level information. Result: The proposed model was evaluated on colorectal cancer datasets from the US and China. Two groups of datasets with different levels of heterogeneity within the collaborative research network were selected. First, we compare the performance of the distributed random forest model under different privacy parameters with different percentages of enhancement datasets and validate the effectiveness and plausibility of our approach. Then, we compare the discrimination and calibration ability of the proposed multicenter random forest with a centrally trained random forest model and other tree-based classifiers as well as some commonly used machine learning methods. The results show that the proposed model can provide better prediction performance in terms of discrimination and calibration ability than the centrally trained RF model or the other candidate models while following the privacy-preserving rules in both groups. Additionally, good discrimination and calibration ability are shown on the simplified model based on the feature importance ranking in the proposed approach. Conclusion: The proposed random forest model exhibits ideal prediction capability using multicenter clinical data and overcomes the performance limitation arising from privacy guarantees. It can also provide feature importance ranking across institutions without pooling the data at a central site. This study offers a practical solution for building a prognosis prediction model in the collaborative clinical research network and solves practical issues in real-world applications of medical artificial intelligence.																	0933-3657	1873-2860				MAR	2020	103								101814	10.1016/j.artmed.2020.101814													
J								Real-world data medical knowledge graph: construction and applications	ARTIFICIAL INTELLIGENCE IN MEDICINE										real-world data; medical knowledge graph; CDSS; quadruplet; PSR		Objective: Medical knowledge graph (KG) is attracting attention from both academic and healthcare industry due to its power in intelligent healthcare applications. In this paper, we introduce a systematic approach to build medical KG from electronic medical records (EMRs) with evaluation by both technical experiments and end to end application examples. Materials and Methods: The original data set contains 16,217,270 de-identified clinical visit data of 3,767,198 patients. The KG construction procedure includes 8 steps, which are data preparation, entity recognition, entity normalization, relation extraction, property calculation, graph cleaning, related-entity ranking, and graph embedding respectively. We propose a novel quadruplet structure to represent medical knowledge instead of the classical triplet in KG. A novel related-entity ranking function considering probability, specificity and reliability (PSR) is proposed. Besides, probabilistic translation on hyperplanes (PrTransH) algorithm is used to learn graph embedding for the generated KG. Results: A medical KG with 9 entity types including disease, symptom, etc. was established, which contains 22,508 entities and 579,094 quadruplets. Compared with term frequency - inverse document frequency (TF/IDF) method, the normalized discounted cumulative gain (NDCG@10) increased from 0.799 to 0.906 with the proposed ranking function. The embedding representation for all entities and relations were learned, which are proven to be effective using disease clustering. Conclusion: The established systematic procedure can efficiently construct a high-quality medical KG from large-scale EMRs. The proposed ranking function PSR achieves the best performance under all relations, and the disease clustering result validates the efficacy of the learned embedding vector as entity's semantic representation. Moreover, the obtained KG finds many successful applications due to its statistics-based quadruplet. where N-infinity(min) is a minimum co-occurrence number and R is the basic reliability value. The reliability value can measure how reliable is the relationship between S-i and O-ij. The reason for the definition is the higher value of N-co(S-i,O-ij) the relationship is more reliable. However, the reliability values of the two relationships should not have a big difference if both of their co-occurrence numbers are very big. In our study, we finally set N-infinity(min) = 10 and R = 1 after some experiments. For instance, if co-occurrence numbers of three relationships are 1, 100 and 10000, their reliability values are 1, 2.96 and 5 respectively.																	0933-3657	1873-2860				MAR	2020	103								101817	10.1016/j.artmed.2020.101817													
J								Multi-resolution convolutional networks for chest X-ray radiograph based lung nodule detection	ARTIFICIAL INTELLIGENCE IN MEDICINE										Computer-aided detection; x-ray radiograph; Lung nodule detection; Multi-resolution patch-based convolutional neural network	COMPUTER-AIDED DIAGNOSIS; OPERATING CHARACTERISTIC ANALYSIS; FALSE-POSITIVE REDUCTION; PULMONARY NODULES; BONE SUPPRESSION; DETECTION SYSTEM; CANCER; SEGMENTATION; RADIOLOGISTS; PERFORMANCE	Lung cancer is the leading cause of cancer death worldwide. Early detection of lung cancer is helpful to provide the best possible clinical treatment for patients. Due to the limited number of radiologist and the huge number of chest x-ray radiographs (CXR) available for observation, a computer-aided detection scheme should be developed to assist radiologists in decision-making. While deep learning showed state-of-the-art performance in several computer vision applications, it has not been used for lung nodule detection on CXR. In this paper, a deep learning-based lung nodule detection method was proposed. We employed patch-based multi-resolution convolutional networks to extract the features and employed four different fusion methods for classification. The proposed method shows much better performance and is much more robust than those previously reported researches. For publicly available Japanese Society of Radiological Technology (JSRT) database, more than 99% of lung nodules can be detected when the false positives per image (FPs/image) was 0.2. The FAUC and R-CPM of the proposed method were 0.982 and 0.987, respectively. The proposed approach has the potential of applications in clinical practice.																	0933-3657	1873-2860				MAR	2020	103								101744	10.1016/j.artmed.2019.101744													
J								Comprehensive electrocardiographic diagnosis based on deep learning	ARTIFICIAL INTELLIGENCE IN MEDICINE										Cardiovascular diseases; Coronary artery disease; Myocardial infarction; Congestive heart failure; beep learning; 10-fold validation; Convolutional neural network; Long short-term memory	CORONARY-ARTERY-DISEASE; RECURRENT NEURAL-NETWORK; MYOCARDIAL-INFARCTION; ECG SIGNALS; HEART-DISEASE; AUTOMATED DETECTION; CLASSIFICATION; IDENTIFICATION	Cardiovascular disease (CVD) is the leading cause of death worldwide, and coronary artery disease (CAD) is a major contributor. Early-stage CAD can progress if undiagnosed and left untreated, leading to myocardial infarction (MI) that may induce irreversible heart muscle damage, resulting in heart chamber remodeling and eventual congestive heart failure (CHF). Electrocardiography (ECG) signals can be useful to detect established MI, and may also be helpful for early diagnosis of CAD. For the latter especially, the ECG perturbations can be subtle and potentially misclassified during manual interpretation and/or when analyzed by traditional algorithms found in ECG instrumentation. For automated diagnostic systems (ADS), deep learning techniques are favored over conventional machine learning techniques, due to the automatic feature extraction and selection processes involved. This paper highlights various deep learning algorithms exploited for the classification of ECG signals into CAD, MI, and CHF conditions. The Convolutional Neural Network (CNN), followed by combined CNN and Long Short-Term Memory (LSTM) models, appear to be the most useful architectures for classification. A 16-layer LSTM model was developed in our study and validated using 10-fold cross-validation. A classification accuracy of 98.5% was achieved. Our proposed model has the potential to be a useful diagnostic tool in hospitals for the classification of abnormal ECG signals.																	0933-3657	1873-2860				MAR	2020	103								101789	10.1016/j.artmed.2019.101789													
J								Multi-planar 3D breast segmentation in MRI via deep convolutional neural networks	ARTIFICIAL INTELLIGENCE IN MEDICINE										MRI; Breast; Segmentation; Convolutional neural networks; U-Net	COMPUTER-AIDED DIAGNOSIS; NEOADJUVANT CHEMOTHERAPY; SYSTEM; PERFORMANCE; SURVIVAL; IMAGES	Nowadays, Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) has demonstrated to be a valid complementary diagnostic tool for early detection and diagnosis of breast cancer. However, without a CAD (Computer Aided Detection) system, manual DCE-MRI examination can be difficult and error-prone. The early stage of breast tissue segmentation, in a typical CAD, is crucial to increase reliability and reduce the computational effort by reducing the number of voxels to analyze and removing foreign tissues and air. In recent years, the deep convolutional neural networks (CNNs) enabled a sensible improvement in many visual tasks automation, such as image classification and object recognition. These advances also involved radiomics, enabling high-throughput extraction of quantitative features, resulting in a strong improvement in automatic diagnosis through medical imaging. However, machine leaming and, in particular, deep learning approaches are gaining popularity in the radiomics field for tissue segmentation. This work aims to accurately segment breast parenchyma from the air and other tissues (such as chest-wall) by applying an ensemble of deep CNNs on 3D MR data. The novelty, besides applying cutting-edge techniques in the radiomics field, is a multi-planar combination of U-Net CNNs by a suitable projection-fusing approach, enabling multi-protocol applications. The proposed approach has been validated over two different datasets for a total of 109 DCE-MRI studies with histopathologically proven lesions and two different acquisition protocols. The median dice similarity index for both the datasets is 96.60 % ( +/- 0.30 %) and 95.78 % ( +/- 0.51 %) respectively with p < 0.05, and 100% of neoplastic lesion coverage.																	0933-3657	1873-2860				MAR	2020	103								101781	10.1016/j.artmed.2019.101781													
J								An intelligent learning approach for improving ECG signal classification and arrhythmia analysis	ARTIFICIAL INTELLIGENCE IN MEDICINE										ECG; Noise suppression; Baseline wander (BW); Power line interference (PLI); Electromyography (EMG); Signal to noise ratio (SNR); Devoted wavelet; Feature extraction; HMM (Hidden Markov Model); Cardiac arrhythmia	POWER-LINE INTERFERENCE; FEATURE-EXTRACTION; REMOVAL; FILTER	The recognition of cardiac arrhythmia in minimal time is important to prevent sudden and untimely deaths. The proposed work includes a complete framework for analyzing the Electrocardiogram (ECG) signal. The three phases of analysis include 1) the ECG signal quality enhancement through noise suppression by a dedicated filter combination; 2) the feature extraction by a devoted wavelet design and 3) a proposed hidden Markov model (HMM) for cardiac arrhythmia classification into Normal (N), Right Bundle Branch Block (RBBB), Left Bundle Branch Block (LBBB), Premature Ventricular Contraction (PVC) and Atrial Premature Contraction (APC). The main features extracted in the proposed work are minimum, maximum, mean, standard deviation, and median. The experiments were conducted on forty-five ECG records in MIT BIH arrhythmia database and in MIT BIN noise stress test database. The proposed model has an overall accuracy of 99.7 % with a sensitivity of 99.7 % and a positive predictive value of 100 %. The detection error rate for the proposed model is 0.0004. This paper also includes a study of the cardiac arrhythmia recognition using an IoMT (Internet of Medical Things) approach.																	0933-3657	1873-2860				MAR	2020	103								101788	10.1016/j.artmed.2019.101788													
J								A multi-context CNN ensemble for small lesion detection	ARTIFICIAL INTELLIGENCE IN MEDICINE										Ensemble classifier; Deep learning; Convolutional neural networks; Computer-aided detection (CADe); Mammograms; Ocular fundus images	DEEP NEURAL-NETWORKS; MICROCALCIFICATION DETECTION; MICROANEURYSM DETECTION; BAYESIAN NETWORKS; REDUCTION; DIAGNOSIS	In this paper, we propose a novel method for the detection of small lesions in digital medical images. Our approach is based on a multi-context ensemble of convolutional neural networks (CNNs), aiming at learning different levels of image spatial context and improving detection performance. The main innovation behind the proposed method is the use of multiple-depth CNNs, individually trained on image patches of different dimensions and then combined together. In this way, the final ensemble is able to find and locate abnormalities on the images by exploiting both the local features and the surrounding context of a lesion. Experiments were focused on two well-known medical detection problems that have been recently faced with CNNs: microcalcification detection on full-field digital mammograms and microaneurysm detection on ocular fundus images. To this end, we used two publicly available datasets, INbreast and E-ophtha. Statistically significantly better detection performance were obtained by the proposed ensemble with respect to other approaches in the literature, demonstrating its effectiveness in the detection of small abnormalities.																	0933-3657	1873-2860				MAR	2020	103								101749	10.1016/j.artmed.2019.101749													
J								Prognostic factors of Rapid symptoms progression in patients with newly diagnosed parkinson's disease	ARTIFICIAL INTELLIGENCE IN MEDICINE										Parkinson's disease; Rapid progression; Prognostic factors; Machine learning	SLEEP BEHAVIOR DISORDER; QUALITY-OF-LIFE; MOTOR PROGRESSION; AUTONOMIC DYSFUNCTION; RATING-SCALE; RISK-FACTORS; DEPRESSION; ANXIETY; IMPAIRMENT; DISABILITY	Tracking symptoms progression in the early stages of Parkinson's disease (PD) is a laborious endeavor as the disease can be expressed with vastly different phenotypes, forcing clinicians to follow a multi-parametric approach in patient evaluation, looking for not only motor symptomatology but also non-motor complications, including cognitive decline, sleep problems and mood disturbances. Being neurodegenerative in nature, PD is expected to inflict a continuous degradation in patients' condition over time. The rate of symptoms progression, however, is found to be even more chaotic than the vastly different phenotypes that can be expressed in the initial stages of PD. In this work, an analysis of baseline PD characteristics is performed using machine learning techniques, to identify prognostic factors for early rapid progression of PD symptoms. Using open data from the Parkinson's Progression Markers Initiative (PPMI) study, an extensive set of baseline patient evaluation outcomes is examined to isolate determinants of rapid progression within the first two and four years of PD. The rate of symptoms progression is estimated by tracking the change of the Movement Disorder Society-Unified Parkinson's Disease Rating Scale (MDS-UPDRS) total score over the corresponding follow-up period. Patients are ranked according to their progression rates and those who expressed the highest rates of MDS-UPDRS total score increase per year of follow-up period are assigned into the rapid progression class, using 5- and 10-quantiles partition. Classification performance against the rapid progression class was evaluated in a per quantile partition analysis scheme and in quantile-independent approach, respectively. The results shown a more accurate patient discrimination with quantile partitioning, however, a much more compact subset of baseline factors is extracted in the latter, making a more suitable for actual interventions in practice. Classification accuracy improved in all cases when using the longer 4-year follow-up period to estimate PD progression, suggesting that a prolonged patient evaluation can provide better outcomes in identifying rapid progression phenotype. Non-motor symptoms are found to be the main determinants of rapid symptoms progression in both follow-up periods, with autonomic dysfunction, mood impairment, anxiety, REM sleep behavior disorders, cognitive decline and memory impairment being alarming signs at baseline evaluation, along with rigidity symptoms, certain laboratory blood test results and genetic mutations.																	0933-3657	1873-2860				MAR	2020	103								101807	10.1016/j.artmed.2020.101807													
J								A novel method of motor imagery classification using eeg signal	ARTIFICIAL INTELLIGENCE IN MEDICINE										Electroencephalogram; BCI; Principal component analysis; ELM; Fisher's linear discriminant	EXTREME LEARNING-MACHINE	A subject of extensive research interest in the Brain Computer Interfaces (BCIs) niche is motor imagery (MI), where users imagine limb movements to control the system. This interest is owed to the immense potential for its applicability in gaming, neuro-prosthetics and neuro-rehabilitation, where the user's thoughts of imagined movements need to be decoded. Electroencephalography (EEG) equipment is commonly used for keeping track of cerebrum movement in BCI systems. The EEG signals are recognized by feature extraction and classification. The current research proposes a Hybrid-KELM (Kernel Extreme Learning Machine) method based on PCA (Principal Component Analysis) and FLD (Fisher's Linear Discriminant) for MI BCI classification of EEG data. The performance and results of the method are demonstrated using BCI competition dataset III, and compared with those of contemporary methods. The proposed method generated an accuracy of 96.54%.																	0933-3657	1873-2860				MAR	2020	103								101787	10.1016/j.artmed.2019.101787													
J								Semantic segmentation with DenseNets for carotid artery ultrasound plaque segmentation and CIMT estimation	ARTIFICIAL INTELLIGENCE IN MEDICINE										Semantic segmentation of carotid artery; Intima media thickness; Ultrasound images; Atherosclerotic plaque detection; Fully convolutional neural networks	INTIMA-MEDIA THICKNESS; IMT MEASUREMENT; SYSTEM	Background and objective: The measurement of carotid intima media thickness (CIMT) in ultrasound images can be used to detect the presence of atherosclerotic plaques. Usually, the CIMT estimation strategy is semi-automatic, since it requires: (1) a manual examination of the ultrasound image for the localization of a region of interest (ROI), a fast and useful operation when only a small number of images need to be measured; and (2) an automatic delineation of the CIM region within the ROI. The existing efforts for automating the process have replicated the same two-step structure, resulting in two consecutive independent approaches. In this work, we propose a fully automatic single-step approach based on semantic segmentation that allows us to segment the plaque and to estimate the CIMT in a fast and useful manner for large data sets of images. Methods: Our single-step approach is based on densely connected convolutional neural networks (DenseNets) for semantic segmentation of the whole image. It has two remarkable characteristics: (1) it avoids ROI definition, and (2) it captures multi-scale contextual information in the complete image interpretation, due to the concatenation of feature maps carried out in DenseNets. Once the input image is segmented, a straightforward method for CIMT estimation and plaque detection is applied. Results: The proposed method has been validated with a large data set (REGICOR) of more than 8000 images, corresponding to two territories of the carotid artery: common carotid artery (CCA) and bulb. Among them, a subset of 331 images has been used to evaluate the performance of semantic segmentation (approximate to 90% for train, approximate to 10% for test). The experimental results demonstrated that our method outperforms other deep models and shallow approaches found in the literature. In particular, our CIMT estimation reaches a correlation coefficient of 0.81, and a CIMT mean error of 0.02 and 0.06 mm in CCA and Bulb images, respectively. Furthermore, the accuracy for plaque detection is 96.45% and 78.09% in CCA and Bulb, respectively. To test the generalization power, the method has also been tested with another data set (NEFRONA) that includes images acquired with different equipment. Conclusions: The validation carried out demonstrates that the proposed method is accurate and objective for both plaque detection and CIMT measurement. Moreover, the robustness and generalization capacity of the method have been proven with two different data sets.																	0933-3657	1873-2860				MAR	2020	103								101784	10.1016/j.artmed.2019.101784													
J								Topic-informed neural approach for biomedical event extraction	ARTIFICIAL INTELLIGENCE IN MEDICINE										Neural topic model; Variational inference; Biomedical event extraction; Neural network		As a crucial step of biological event extraction, event trigger identification has attracted much attention in recent years. Deep representation methods, which have the superiorities of less feature engineering and end-to-end training, show better performance than statistical methods. While most deep learning methods have been done on sentence-level event extraction, there are few works taking document context into account, losing potentially informative knowledge that is beneficial for trigger detection. In this paper, we propose a variational neural approach for biomedical event extraction, which can take advantage of latent topics underlying documents. By adopting a joint modeling manner of topics and events, our model is able to produce more meaningful and event-indicative words compare to prior topic models. In addition, we introduce a language model embeddings to capture context-dependent features. Experimental results show that our approach outperforms various baselines in a commonly used multi-level event extraction corpus.																	0933-3657	1873-2860				MAR	2020	103								101783	10.1016/j.artmed.2019.101783													
J								Random Forest enhancement using improved Artificial Fish Swarm for the medial knee contact force prediction	ARTIFICIAL INTELLIGENCE IN MEDICINE										Artificial Fish Swarm; Random Forest; Knee replacement; Contact force prediction	NEURAL-NETWORK; IN-VIVO; GAIT; JOINT; CLASSIFICATION; WALKING; DESIGN; TORQUE; MODEL; HIP	Knee contact force (KCF) is an important factor to evaluate the knee joint function for the patients with knee joint impairment. However, the KCF measurement based on the instrumented prosthetic implants or inverse dynamics analysis is limited due to the invasive, expensive price and time consumption. In this work, we propose a KCF prediction method by integrating the Artificial Fish Swarm and the Random Forest algorithm. First, we train a Random Forest to learn the nonlinear relation between gait parameters (input) and contact pressures (output) based on a dataset of three patients instrumented with knee replacement. Then, we use the improved artificial fish group algorithm to optimize the main parameters of the Random Forest based KCF prediction model. The extensive experiments verify that our method can predict the medial knee contact force both before and after the intervention of gait patterns, and the performance outperforms the classical multi-body dynamics analysis and artificial neural network model.																	0933-3657	1873-2860				MAR	2020	103								101811	10.1016/j.artmed.2020.101811													
J								A Furcated Visual Collision Avoidance System for an Autonomous Microrobot	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Autonomous robots; biologically inspired; collision avoidance; direction and proximity estimation; furcated luminance-difference processing (FLDP)	NEURAL-NETWORK; REAL-TIME; VISION; RECOGNITION; DETECTORS	This paper proposes a secondary reactive collision avoidance system for microclass of robots based on a novel approach known as the furcated luminance-difference processing (FLDP) inspired by the lobula giant movement detector, a wide-field visual neuron located in the lobula layer of a locust nervous system. This paper addresses some of the major collision avoidance challenges: obstacle proximity and direction estimation, and operation in GPS-denied environment with irregular lighting. Additionally, it has proven effective in detecting edges independent of background color, size, and contour. The FLDP executes a series of image enhancement and edge detection algorithms to estimate collision threat-level which further determines whether the robot's field of view must be dissected where each section's response is compared against the others to generate a simple collision-free maneuver. Ultimately, the computation load and the performance of the model are assessed against an eclectic set of offline as well as real-time real-world collision scenarios validating the proposed model's asserted capability to avoid obstacles at more than 670 mm prior to collision, moving at 1.2 ms(-1) with a successful avoidance rate of 90% processing at 120 Hz on a simple single-core microcontroller, sufficient to conclude the system's feasibility for real-time real-world applications that possess fail-safe collision avoidance system.																	2379-8920	2379-8939				MAR	2020	12	1					1	11		10.1109/TCDS.2018.2858742													
J								Can the Evidence for Explanatory Reasoning Be Explained Away?	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Bayes' rule; belief updating; biases; explanation; probability; reasoning	INFERENCE	Recent evidence appears to show a close connection between explanation and belief revision, specifically, the revision of graded beliefs. Insofar as this is also evidence of violations of Bayesian norms of reasoning, the question arises whether we are facing a new bias here, on a par with previously discovered biases in probabilistic reasoning. We consider an apparently successful attempt by Costello and Watts to explain away a number of known such biases in terms of sampling error, which makes those biases look entirely innocuous and compatible with the descriptive adequacy of Bayesian psychology in any but the most uninteresting way. Specifically, we query whether this attempt can be extended to neutralize the aforementioned evidence allegedly showing that explanatory considerations influence our reasoning in ways inconsistent with Bayesian prescriptions.																	2379-8920	2379-8939				MAR	2020	12	1					12	17		10.1109/TCDS.2018.2861832													
J								Cooperative Manipulation for a Mobile Dual-Arm Robot Using Sequences of Dynamic Movement Primitives	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Mobile robots; Mobile dual-arm manipulation; redundancy resolution; sequences of dynamic movement primitives (SDMPs)	OPTIMIZATION	In order to extend promising robot applications in human daily lives, robots need to perform dextrous manipulation tasks, particularly for a mobile dual-arm robot. This paper propose a novel control strategy, which consists of a first trial process and a learning phase, to enable a mobile dual-arm robot to complete a grasp-and-place task which can be decomposed into movement sequences, such as reaching, grasping, and cooperative manipulation of a grasped object. Under the guidance of vision system, the robot with physical constraints successfully fulfills the task by tracking trajectories generated by redundancy resolution online using a neural-dynamic optimization. Then a reinforcement learning algorithm called the policy improvement with path integrals for sequences of dynamic movement primitives is applied to learn and adjust the recorded trajectories. Experimental results of the developed mobile dual-arm robot verified that the proposed strategy is able to successfully and optimally complete a grasp-and-place task.																	2379-8920	2379-8939				MAR	2020	12	1					18	29		10.1109/TCDS.2018.2868921													
J								Abnormal Event Detection From Videos Using a Two-Stream Recurrent Variational Autoencoder	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Abnormal event detection; convolutional long-short term memory (LSTM); reconstruction error probability; two-stream fusion; variational autoencoder (VAE)	ANOMALY DETECTION; CROWDED SCENES; HISTOGRAMS; LOCALIZATION; FLOW	With the massive deployment of distributed video surveillance systems, the automatic detection of abnormal events in video streams has become an urgent need. An abnormal event can be considered as a deviation from the regular scene; however, the distribution of normal and abnormal events is severely imbalanced, since the abnormal events do not frequently occur. To make use of a large number of video surveillance videos of regular scenes, we propose a semi-supervised learning scheme, which only uses the data that contains the ordinary scenes. The proposed model has a two-stream structure that is composed of the appearance and motion streams. For each stream, a recurrent variational autoencoder can model the probabilistic distribution of the normal data in a semi-supervised learning scheme. The appearance and motion features from the two streams can provide complementary information to describe this probabilistic distribution. Comprehensive experiments validate the effectiveness of our proposed scheme on several public benchmark data sets which include the Avenue, the Ped1, the Ped2, the Subway-entry, and the Subway-exit.																	2379-8920	2379-8939				MAR	2020	12	1					30	42		10.1109/TCDS.2018.2883368													
J								Robotic-Assisted Rehabilitation Trainer Improves Balance Function in Stroke Survivors	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Balance function; force field control; motion intention; rehabilitation robot; stroke	GAIT; RECOVERY; ADAPTATION; STABILITY; SUPPORT	Nerve injury after stroke leads to disorders of locomotion and a declining balance function, which increases the risk of falling. Restriction of pelvic motions can hinder successful rehabilitation, hence a robotic-assisted rehabilitation trainer (RART) is proposed to assist patients in controlling the pelvic motions via force field. The mechanical design, kinetic framework, and the intention-based controller of the RART are introduced in this paper. Based on an intention-based control strategy, the robot generates force field that affects the pelvic motions (vertical and lateral motion, rotation, and obliquity) via a compliant pelvic brace while the patient is walking on ground. A control experiment with 16 hemiplegic patients is carried out to examine the effects on recovery of the balance function. Clinical evaluations and gait analysis are performed before and after the treatment. The experimental results show that the proposed control method is effective in motion recognition, and significant improvements of the balance function, gait speed, stride, stride frequency, Fugl-Meyer assessment, peak knee, and hip flexion angle during swing phase for their affected side are observed in the comparisons within the RART group. These preliminary results demonstrate that the proposed robot with force field and visual feedback may be effective in improving the balance function.																	2379-8920	2379-8939				MAR	2020	12	1					43	53		10.1109/TCDS.2018.2883653													
J								DeepFeat: A Bottom-Up and Top-Down Saliency Model Based on Deep Features of Convolutional Neural Networks	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Bottom-up (BU); convolutional neural networks; deep features; ground-truth; saliency model; top-down (TD); visual attention	VISUAL-ATTENTION; ROBOT	A deep feature-based saliency model (DeepFeat) is developed to leverage understanding of the prediction of human fixations. Conventional saliency models often predict the human visual attention relying on few image cues. Although such models predict fixations on a variety of image complexities, their approaches are limited to the incorporated features. In this paper, we aim to utilize the deep features of convolutional neural networks by combining bottom-up (BU) and top-down (TD) saliency maps. The proposed framework is applied on deep features of three popular deep convolutional neural networks (DCNNs). We exploit four evaluation metrics to evaluate the correspondence between the proposed saliency model and the ground-truth fixations over two datasets. The results demonstrate that the deep features of pretrained DCNNs over the ImageNet dataset are strong predictors of the human fixations. The incorporation of BU and TD saliency maps outperforms the individual BU or TD implementations. Moreover, in comparison to nine saliency models, including four state-of-the-art and five conventional saliency models, our proposed DeepFeat model outperforms the conventional saliency models over all four evaluation metrics.																	2379-8920	2379-8939				MAR	2020	12	1					54	63		10.1109/TCDS.2019.2894561													
J								Selective Perception as a Mechanism to Adapt Agents to the Environment: An Evolutionary Approach	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Artificial neural networks (ANNs); attention; cognition; genetic algorithms; intelligent agents; machine learning; perception; short-term memory	WORKING-MEMORY; ATTENTION	Rapid advancement of machine learning makes it possible to consider large amounts of data to learn from. Learning agents may get data ranging on real intervals directly from the environment they interact with, in a process usually time expensive. To improve learning and manage these data, approximated models and memory mechanisms are adopted. In most of the implementations of reinforcement learning facing this type of data, approximation is obtained by neural networks and the process of drawing information from data is mediated by a short-term memory that stores the previous experiences for additional relearning, to speed-up the learning process, mimicking what is done by people. In this paper, we are proposing a novel computational approach able to selectively filter the information, or cognitive load, for the agent's short-term memory, thus emulating the attention mechanism characteristic of human perception. In this work, we use genetic algorithms in order to evolve the most efficient attention filter mechanism that would be able to provide the agent with an optimal perception for a specific environment by discriminating which experiences are valuable for the learning process. This approach can evolve a filter which can able to provide an optimal cognitive load of the experiences entering in the agent's short-term memory of a limited capacity. The evolved sampling dynamics can also lead to the emergence of intrinsically motivated curiosity.																	2379-8920	2379-8939				MAR	2020	12	1					64	72		10.1109/TCDS.2019.2896306													
J								Zero-Shot Classification Based on Multitask Mixed Attribute Relations and Attribute-Specific Features	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Attribute relation learning; attribute-specific features; multitask; zero-shot classification	OBJECTS	Zero-shot classification is a hot topic in computer vision and pattern recognition. Most zero-shot classification methods are based on the intermediate level representation of attributes to achieve knowledge transfer from the training classes to the unseen test classes. Recently, multitask learning (MTL) has been shown as one of state-of-the-art approaches for attribute learning and zero-shot classification. Aiming at the attribute relation learning, features shared by attributes learning and attribute heterogeneity, we propose a zero-shot classification based on multitask mixed attribute relations and attribute-specific features. First, considering the relationship between attribute-attribute and attribute-features, a second-order attribute relation and attribute-specific features learning model is constructed from training samples based on MTL. Second, second-order attribute relation is extended to high-order attribute relation and multiple attribute classifiers are learned. Finally, zero-shot classification is completed based on the maximum posterior probability. Experimental results on AWA and PubFig data sets show that the proposed method can yield more accurate attribute prediction and zero-shot classification compared with several multitask attribute learning methods.																	2379-8920	2379-8939				MAR	2020	12	1					73	83		10.1109/TCDS.2019.2902250													
J								Semantic Relational Object Tracking	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Object tracking; perceptual anchoring; probabilistic logic programming; probabilistic reasoning; relational particle filtering; semantic world modeling		This paper addresses the topic of semantic world modeling by conjoining probabilistic reasoning and object anchoring. The proposed approach uses a so-called bottom-up object anchoring method that relies on rich continuous attribute values measured from perceptual sensor data. A novel anchoring matching function learns to maintain object entities in space and time and is validated using a large set of trained humanly annotated ground truth data of real-world objects. For more complex scenarios, a high-level probabilistic object tracker has been integrated with the anchoring framework and handles the tracking of occluded objects via reasoning about the state of unobserved objects. We demonstrate the performance of our integrated approach through scenarios such as the shell game scenario, where we illustrate how anchored objects are retained by preserving relations through probabilistic reasoning.																	2379-8920	2379-8939				MAR	2020	12	1					84	97		10.1109/TCDS.2019.2915763													
J								Memory Mechanisms for Discriminative Visual Tracking Algorithms With Deep Neural Networks	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Deep neural networks (DNNs); memory mechanisms; online learning; visual tracking	ROBUST OBJECT TRACKING	Deep-neural-networks-based online visual tracking methods have achieved state-of-the-art results. One of the core components of these methods is the memory pool, in which a number of samples consisting of image patches and the corresponding labels are stored to update the online tracking network. Hence, the mechanism of updating the stored samples determines the performance of the tracking method. In this paper, a novel memory mechanism is proposed to control the writing and reading accesses of the memory pool using credit assignment network H, which learns features of the target object. This memory mechanism comprises the writing and reading mechanisms. In the writing mechanism, network H produces credits for the current tracked object and the samples in the memory pool. This ensures that the reliable samples are written into the memory pool and the unreliable samples are replaced if the memory pool is full. In the reading mechanism, network H assigns an importance score to each sample selected to update the online tracking network. The state-of-the-art tracking methods with and without the proposed memory mechanism are evaluated on the CVPR2013 and OTB100 benchmarks. The experimental results demonstrated that the proposed memory mechanism improves tracking performance significantly.																	2379-8920	2379-8939				MAR	2020	12	1					98	108		10.1109/TCDS.2019.2900506													
J								Usage-Based Learning in Human Interaction With an Adaptive Virtual Assistant	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Human-system interfaces; intelligent assistant; language; usage-based learning	COMPUTATIONAL MODEL; LANGUAGE; CONSTRUCTION; BUILD; BABY	Today users can interact with popular virtual assistants such as Siri to accomplish their tasks on a digital environment. In these systems, links between natural language requests and their concrete realizations are specified at the conception phase. A more adaptive approach would be to allow the user to provide natural language instructions or demonstrations when a task is unknown by the assistant. An adaptive solution should allow the virtual assistant to operate a much larger digital environment composed of multiple application domains and providers and better match user needs. We have previously developed robotic systems, inspired by human language developmental studies, that provide such a usage-based adaptive capacity. Here, we extend this approach to human interaction with a virtual assistant that can first learn the mapping between verbal commands and basic action semantics of a specific domain. Then, it can learn higher level mapping by combining previously learned procedural knowledge in interaction with the user. The flexibility of the system is demonstrated as the virtual assistant can learn actions in new domains (e-mail, Wikipedia, etc.), and then can learn how e-mail and Wikipedia basic procedures can be combined to form hybrid procedural knowledge.																	2379-8920	2379-8939				MAR	2020	12	1					109	123		10.1109/TCDS.2019.2927399													
J								A Brain-Inspired Visual Fear Responses Model for UAV Emergent Obstacle Dodging	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Unmanned ariel vehicle (UAV) dodging emergent obstacles; visual fear responses pathway	SUPERIOR COLLICULUS; PERIAQUEDUCTAL GRAY; LOOMING OBJECTS; DIRECTION SELECTIVITY; NEURAL-NETWORK; AMYGDALA; NEURONS; PATHWAY; COLLISION; CORTEX	Dodging emergent dangers is an innate cognitive ability for animals, which helps them to survive in the natural environment. The retina-superior colliculus (SC)-pulvinar-amygdala-periaqueductal gray pathway is responsible for the visual fear responses, and it is able to quickly detect the looming obstacles for innate dodging. Inspired by the mechanism of the visual fear responses pathway, we propose a brain-inspired emergent obstacle dodging method to model the functions of the related brain regions. This method first detects the moving direction and speed of the salient point of moving objects (retina). Then, we detect the looming obstacles (SC). Third, we modulate attention to the most dangerous area (pulvinar). Fourth, if the degree of danger exceeds the threshold (amygdala), the unmanned ariel vehicle (UAV) moves back to dodge it (periaqueductal gray). Two types of experiments are conducted to validate the effectiveness of the proposed model. In a simulated scene, we simulate the process of mice's fear responses by putting looming dark lights shining on them. In a natural scene, we apply the proposed model to the UAV emergent obstacles dodging. Compared to the stereo vision model, the proposed model is not only more biologically realistic from the mechanisms perspective, but also more accurate and faster for computation.																	2379-8920	2379-8939				MAR	2020	12	1					124	132		10.1109/TCDS.2019.2939024													
J								Self-Structured Cortical Learning Algorithm by Dynamically Adjusting Columns and Cells	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										time-series data prediction; cortical learning algorithm; self-structuring algorithm		The cortical learning algorithm (CLA) is a type of time-series data prediction algorithm based on the human neocortex. CLA uses multiple columns to represent an input data value at a timestep, and each column has multiple cells to represent the time-series context of the input data. In the conventional CLA, the numbers of columns and cells are user-defined parameters. These parameters depend on the input data, which can be unknown before learning. To avoid the necessity for setting these parameters beforehand, in this work, we propose a self-structured CLA that dynamically adjusts the numbers of columns and cells according to the input data. The experimental results using the time-series test inputs of a sine wave, combined sine wave, and logistic map data demonstrate that the proposed self-structured algorithm can dynamically adjust the numbers of columns and cells depending on the input data. Moreover, the prediction accuracy is higher than those of the conventional long short-term memory and CLAs with various fixed numbers of columns and cells. Furthermore, the experimental results on a multistep prediction of real-world power consumption show that the proposed self-structured CLA achieves a higher prediction accuracy than the conventional long short-term memory.																	1343-0130	1883-8014				MAR	2020	24	2					185	198															
J								Computer Humor and Human Humor: Construction of Japanese "Nazokake" Riddle Generation Systems	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										humor; dependency analysis; language generation; cognitive science	APPRECIATION	Humor is important in smooth human communications, however, computer-generated humor is still distinguishable from humor that arises naturally in human communication. The purpose of this study is to construct a computer system that can generate humor in a human-like manner. The method involves using "nazokake" riddles, which comprise a type of Japanese word game. The game creates humorous links between two incongruous premises by linking them semantically to homophones: "Why is A like B? Because X/X'," where A and B are independent premises and X and X' are homophones linked to A and B, respectively. In a previous study, a system was constructed to generate such riddles based on a simple word similarity between two nouns that are homophones. This study builds on the previous study by generating more complex riddles based on the dependency relationships between homophonic verb-noun combinations. Subsequently, the two systems are compared with each other by evaluating them against riddles created by humans. The results show that the system based on dependency relationships generated more humorous, unexpected, and natural riddles than that based on word similarities. However, these riddles were not equal to those created by humans.																	1343-0130	1883-8014				MAR	2020	24	2					199	205		10.20965/jaciii.2020.p0199													
J								A New Sensing Direction Rotation Approach to Area Coverage Optimization in Directional Sensor Network	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										directional sensor network; area coverage problem; sensing direction rotation; coverage verification algorithm; particle swarm optimization	DEPLOYMENT; ALGORITHM; VORONOI	Coverage is a crucial issue in directional sensor networks (DSNs), and a high coverage ratio ensures a good quality of service (QoS). However, a DSN encounters various problems because they use directional sensor nodes, which are characterized by directionality and a definite sensing angle. To address the area coverage problem of DSNs, this paper proposes a new sensing direction rotation approach to optimize coverage. First, we conduct grid partitioning in the target area and propose a coverage verification algorithm to justify the coverage situation of the grid points. Then, we utilize particle swarm optimization (PSO) to find an optimal sensing direction group of the directional sensor nodes to maximize the coverage ratio. Extensive simulation experiments were conducted to prove the effectiveness and reliability of our proposed approach. The results show that the approach improves the area coverage ratio of DSNs in various scenarios.																	1343-0130	1883-8014				MAR	2020	24	2					206	213															
J								Lifestyle Analysis from Household Electricity Consumption Data	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										electricity consumption data; smart meter; lifestyle analysis		This paper aims to analyze the lifestyle of residents from household electricity consumption data. Improving QOL (Quality of Life) of elderlies has attracted attention in a super-aging society. It is known that the lifestyle of a person directly affects his / her health and QOL. Therefore, understanding a lifestyle is expected to be useful for providing various support for improving QOL, such as recommending adequate actions and daily habit. As a means for understanding residents' lifestyle, this paper focuses on household electricity consumption data, which gets to be available with the spread of smart meters. The analysis is conducted by estimating the time of taking essential actions such as wake up and eating. As the target data has no ground truth, this paper also shows the result of an experiment on the detection of the essential actions. The analysis results reveal several findings which could be useful for improving QOL, such as positive correlation between regularity of dinner time and bedtime.																	1343-0130	1883-8014				MAR	2020	24	2					214	220		10.20965/jaciii.2020.p0214													
J								Assessment of Coke Oven Operating State Using Trend Analysis and Information Entropy	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										coke oven; operating state assessment; qualitative trend analysis; information entropy	GROUP DECISION-MAKING; MULTIPLE CRITERIA; FUZZY; IDENTIFICATION; DIAGNOSIS; SUPPORT	In the combustion process of a coke oven, it is crucial to evaluate the operating state to ensure control performance for the stabilization of the coke oven temperature. This paper presents an assessment method for a coke oven operating state based on the analysis of the mechanism. A coke oven, which is an integrator, is categorized into serial subsystems, which include two coking chambers and one combustion chamber. First, the raw gas temperature of every coking chamber is extracted online and is combined with the qualitative trend analysis that yields the feature point of the raw gas temperature. Subsequently, fuzzy method is presented to describe the uncertainty and evaluate the heat level of each subsystem. Finally, a comprehensive assessment of the operating state of the coke oven is performed by combining the weighted contribution of all subsystems, which is expressed by information entropy. Simulations and experiments demonstrate the validity of the method.																	1343-0130	1883-8014				MAR	2020	24	2					221	231															
J								Characteristics for Performance Optimization of Safety-Critical System Development (SCSD)	JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS										safety-critical systems (SCSs); safety-critical system development (SCSD); area; system development; performance	SOFTWARE-DEVELOPMENT	Safety-critical systems (SCS) are the most significant systems that affect our daily life in many areas such as flight control systems, railway systems, medical devices, nuclear systems, and military weapons. SCS failures could result in losing life or serious injuries. Improving the practices during development phases of SCS can reduce failures up to 40%, thus resulting developers to follows specific development practices and techniques. Developers should improve safety-critical system development (SCSD) by taking into account all factors and understanding the causes of failure. Previous studies have highlighted the causes of failure during the development of SCS, but for specific areas such as designs, requirements, or the human factor, while developers need to know the causes of failure in all areas and the relationship between them clearly and comprehensively. This research aims to analyze SCSD characteristics and discuss performance improvement as well as causes of failure. This paper proposed a guideline that helps developers reduce the causes of failure during SCS development. This guide has four characteristics, each with a role in improving SCSD and reducing causes of failure.																	1343-0130	1883-8014				MAR	2020	24	2					232	242		10.20965/jaciii.2020.p0232													
J								Optimum design of fuzzy controller using hybrid ant lion optimizer and Jaya algorithm	ARTIFICIAL INTELLIGENCE REVIEW										Fuzzy logic controller; Optimization; Benchmark building; Ant lion optimizer; Jaya algorithm; Hybrid method	VIBRATION SUPPRESSION	Fuzzy logic controller is the most common and versatile control algorithm in the structural motion control. In most cases, the formulation of the fuzzy controller is based on the human knowledge and expert so the membership functions and the rule base are formulated by trials and errors. In recent years, there is an increasing interest to optimize the fuzzy logic controller with different metaheuristics and nature inspired approaches. This paper focuses on the optimization of a fuzzy controller applied to the seismically excited nonlinear buildings. In the majority of cases, this problem is formulated based on the linear behavior of the structure, however in this paper, objective functions and the performance criteria are considered with respect to the nonlinear responses of the structures. The optimization algorithm is based on the implementation of ant lion optimizer and Jaya algorithm as a hybrid method. The new method is utilized to design a fuzzy controller for two benchmark buildings with nonlinear behavior. The performance of the hybrid method is compared with various classical and advanced optimization algorithms.																	0269-2821	1573-7462				MAR	2020	53	3					1553	1584		10.1007/s10462-019-09713-8													
J								Generation of maximal fuzzy cliques of fuzzy permutation graph and applications	ARTIFICIAL INTELLIGENCE REVIEW										Fuzzy graph; Fuzzy permutation graph; Maximal fuzzy cliques; Fuzzy independent sets; Fuzzy complement; Design of algorithm	INDEPENDENT SETS; ALGORITHMS	Fuzzy permutation graph (FPG) plays a significant role in solving real-life problems where the scope and application of crisp permutation graph get limited due to the fuzziness involved in real situations. In this article an algorithm is designed to find out all maximal fuzzy cliques of a FPG. A similar algorithm is developed at the same time to find out all maximal fuzzy independent sets of the said graph. The inter-relationship between FPG and its two types of complements is presented based on the facts and theories established on fuzzy cliques and fuzzy independent sets. The importance of fuzzy cliques of FPG is discussed through an application on a daily-life problem. The unique property of a FPG having two types of complement graphs help us to solve many useful problems. Here, we have shown how this property of FPG helps us to overcome a hazardous situation occurred due to disrupted scheduling of trains on a foggy day.																	0269-2821	1573-7462				MAR	2020	53	3					1585	1614		10.1007/s10462-019-09714-7													
J								Enhanced bag of visual words representations for content based image retrieval: a comparative study	ARTIFICIAL INTELLIGENCE REVIEW										Image retrieval; Visual dictionary; Bag of visual words; Semantic gap	FEATURES	The exponential growth of digital image data poses numerous open problems to computer vision researchers. In this regard, designing an efficient and more accurate mechanism that finds and retrieve desired images from large repositories is of greater importance. To this end, various types of content based image retrieval (CBIR) systems have been developed. A typical CBIR system enables the search and retrieval of desired images from large databases that are similar to a given query image by means of automatically extracted visual features from image pixels. In CBIR domain, the bag of visual words (BoVW) model is one of the most widely used feature representation scheme and there exist a number of image retrieval frameworks based on BoVW model. It has been observed that most of them demonstrated promising results for the task of medium and large scale image retrieval. However, image retrieval literature lacks a comparative evaluation of these extended BoVW formulations. To this end, this paper aims to categorize and evaluate the existing BoVW model based formulations for the task of content based image retrieval. The commonly used datasets and the evaluation metrics to assess the retrieval effectiveness of these existing models are discussed. Moreover, quantitative evaluation of state of the art image retrieval systems based on BoVW model is also provided. Finally, certain promising directions for future research are proposed on the basis of the existing models and the demand from real-world.																	0269-2821	1573-7462				MAR	2020	53	3					1615	1653		10.1007/s10462-019-09715-6													
J								Deep learning-based breast cancer classification through medical imaging modalities: state of the art and research challenges	ARTIFICIAL INTELLIGENCE REVIEW										Breast cancer classification; Deep learning; Medical imaging modalities; Convolutional neural network	COMPUTER-AIDED DIAGNOSIS; NETWORK; LESIONS; PERFORMANCE; MAMMOGRAMS; PREDICTION; FRAMEWORK; ENSEMBLE; SYSTEMS; TUMORS	Breast cancer is a common and fatal disease among women worldwide. Therefore, the early and precise diagnosis of breast cancer plays a pivotal role to improve the prognosis of patients with this disease. Several studies have developed automated techniques using different medical imaging modalities to predict breast cancer development. However, few review studies are available to recapitulate the existing literature on breast cancer classification. These studies provide an overview of the classification, segmentation, or grading of many cancer types, including breast cancer, by using traditional machine learning approaches through hand-engineered features. This review focuses on breast cancer classification by using medical imaging multimodalities through state-of-the-art artificial deep neural network approaches. It is anticipated to maximize the procedural decision analysis in five aspects, such as types of imaging modalities, datasets and their categories, pre-processing techniques, types of deep neural network, and performance metrics used for breast cancer classification. Forty-nine journal and conference publications from eight academic repositories were methodically selected and carefully reviewed from the perspective of the five aforementioned aspects. In addition, this study provided quantitative, qualitative, and critical analyses of the five aspects. This review showed that mammograms and histopathologic images were mostly used to classify breast cancer. Moreover, about 55% of the selected studies used public datasets, and the remaining used exclusive datasets. Several studies employed augmentation, scaling, and image normalization pre-processing techniques to minimize inconsistencies in breast cancer images. Several types of shallow and deep neural network architecture were employed to classify breast cancer using images. The convolutional neural network was utilized frequently to construct an effective breast cancer classification model. Some of the selected studies employed a pre-trained network or developed new deep neural networks to classify breast cancer. Most of the selected studies used accuracy and area-under-the-curve metrics followed by sensitivity, precision, and F-measure metrics to evaluate the performance of the developed breast cancer classification models. Finally, this review presented 10 open research challenges for future scholars who are interested to develop breast cancer classification models through various imaging modalities. This review could serve as a valuable resource for beginners on medical image classification and for advanced scientists focusing on deep learning-based breast cancer classification through different medical imaging modalities.																	0269-2821	1573-7462				MAR	2020	53	3					1655	1720		10.1007/s10462-019-09716-5													
J								A survey of swarm and evolutionary computing approaches for deep learning	ARTIFICIAL INTELLIGENCE REVIEW										Deep learning; Metaheuristic algorithms; Artificial neural networks; Deep neural networks; Evolutionary computing; Swarm intelligence	CONVOLUTIONAL NEURAL-NETWORKS; GRAVITATIONAL SEARCH ALGORITHM; BELIEF NETWORKS; RECEPTIVE-FIELDS; OPTIMIZATION; COMPUTATION; MODEL; CLASSIFICATION; INTELLIGENCE; PREDICTION	Deep learning (DL) has become an important machine learning approach that has been widely successful in many applications. Currently, DL is one of the best methods of extracting knowledge from large sets of raw data in a (nearly) self-organized manner. The technical design of DL depends on the feed-forward information flow principle of artificial neural networks with multiple layers of hidden neurons, which form deep neural networks (DNNs). DNNs have various architectures and parameters and are often developed for specific applications. However, the training process of DNNs can be prolonged based on the application and training set size (Gong et al. 2015). Moreover, finding the most accurate and efficient architecture of a deep learning system in a reasonable time is a potential difficulty associated with this approach. Swarm intelligence (SI) and evolutionary computing (EC) techniques represent simulation-driven non-convex optimization frameworks with few assumptions based on objective functions. These methods are flexible and have been proven effective in many applications; therefore, they can be used to improve DL by optimizing the applied learning models. This paper presents a comprehensive survey of the most recent approaches involving the hybridization of SI and EC algorithms for DL, the architecture of DNNs, and DNN training to improve the classification accuracy. The paper reviews the significant roles of SI and EC in optimizing the hyper-parameters and architectures of a DL system in context to large scale data analytics. Finally, we identify some open problems for further research, as well as potential issues related to DL that require improvements, and an extensive bibliography of the pertinent research is presented.																	0269-2821	1573-7462				MAR	2020	53	3					1767	1812		10.1007/s10462-019-09719-2													
J								A survey of mono- and multi-lingual character recognition using deep and shallow architectures: indic and non-indic scripts	ARTIFICIAL INTELLIGENCE REVIEW										Multilingual; Monolingual; Character recognition (CR); Benchmark corpora; Indic and non-indic scripts; Japanese; Chinese; Arabic and Latin; Pre-processing; Post-processing; Feature extraction; Deep and shallow architectures; Online CR; Offline CR	ARABIC HANDWRITING RECOGNITION; POST-PROCESSING SYSTEM; HIDDEN MARKOV-MODELS; FEATURE-EXTRACTION; WORD RECOGNITION; CHINESE CHARACTERS; LINE DETECTION; ONLINE; SEGMENTATION; HMM	The cultural and regional diversity across the world and specifically in India has given birth to a large number of writing systems and scripts having a variety of character sets. For scripts having a larger character set, just a simple keyboard with limited character set is not the optimal way for providing inputs to the computer. Variations in individual handwriting due to mood swings, changes in medium of writing, changes in writing styles, etc. pose a challenge before the character recognition (CR) research community. Similar kinds of symbols in various scripts and languages act as a big barrier in multilingual CR. Lack of benchmark results and corpora for multilingual CR hinder the research in multilingual CR. There have been only a limited number of articles for optimal combination of features and classifiers to process multilingual data. Multilingual CR has least explored the Indic scripts. This paper presents a detailed review and analysis of the work done in multilingual online as well as offline CR for Indic and non-Indic scripts. The paper mainly contributes in two ways: Firstly, it provides a clear perspective about various phases of monolingual and multilingual CR; and secondly, identifies the major deficiencies in monolingual and multilingual CR for printed and handwritten text. It contributes by giving an in-depth view of work done at each phase including data acquisition, pre-processing, segmentation, feature extraction, recognition and post-processing of CR. Issues to be resolved at each phase have also been elaborated. The recent work done using Deep and Shallow architectures has been analysed. Tools used for these architectures have been compared to highlight their pros and cons. The present work also suggests how further research can be conducted in the field of monolingual and multilingual CR. The problems such as CR in hybrid documents, identifying more reliable features, resolving issues of similar characters, identifying optimal combination strategies for deep and shallow architectures, etc. need to be tackled in future research.																	0269-2821	1573-7462				MAR	2020	53	3					1813	1872		10.1007/s10462-019-09720-9													
J								Computer aided detection in automated 3-D breast ultrasound images: a survey	ARTIFICIAL INTELLIGENCE REVIEW										Ultrasound; Breast; Detection; Mass	CANCER-DETECTION; TUMOR-DETECTION; DETECTION ALGORITHM; MASS DETECTION; CLASSIFICATION; SEGMENTATION; MAMMOGRAPHY; FEATURES; SPARSE; WOMEN	Nowadays, breast cancer is the leading cause of cancer death for women all over the world. Since the reason of breast cancer is unknown, early detection of the disease plays an important role in cancer control, saving lives and reducing costs. Among different modalities, automated 3-D breast ultrasound (3-D ABUS) is a new and effective imaging modality which has attracted a lot of interest as an adjunct to mammography for women with dense breasts. However, reading ABUS images is time consuming for radiologists and subtle abnormalities may be overlooked. Hence, computer aided detection (CADe) systems can be utilized as a second interpreter to assist radiologists to increase their screening speed and sensitivity. In this paper, a general architecture representing different CADe systems for ABUS images is introduced and the approaches for implementation of each block are categorized and reviewed. In addition, the limitations of these systems are discussed and their performance in terms of sensitivity and number of false positives per volume are compared.																	0269-2821	1573-7462				MAR	2020	53	3					1919	1941		10.1007/s10462-019-09722-7													
J								Integration of case-based reasoning and fuzzy approaches for real-time applications in dynamic environments: current status and future directions	ARTIFICIAL INTELLIGENCE REVIEW										Case-based reasoning; Fuzzy approaches; Real-time applications; Knowledge representation; Fuzzy-based case-based reasoning	ROUGH SET-THEORY; COGNITIVE MAPS; RETRIEVAL; INTELLIGENT; ADAPTATION; ALGORITHMS; SELECTION; STRATEGY; SYSTEMS; MODEL	This survey reviews recent researches conducted on the application of fuzzy approaches to Case-Based Reasoning (CBR) dealing with real-time applications. Fuzzy approaches have been effectively applied for knowledge representation, feature selection, and learning in CBR. Dealing with imprecise and uncertain knowledge, generalization, mining, and learning also in combination with low computational complexity are the main advantages of fuzzy approaches used in the CBR context. This paper presents and summarizes new findings on the integration of fuzzy approaches with CBR. The survey results highlight the advantages of fuzzy approaches in CBR for real-time applications. They show the current state of fuzzy-based CBR approaches. In addition, fuzzy approaches which are more operative for each operation in CBR are addressed. Those operations most contributing to the advantages of the fuzzy approach will be pointed out and detailed. Low accuracy, storage and computational challenges with a large amount of experiences and uncertainties are important issues in case of real-time applications. This paper proposes a general fuzzy-based CBR approach for real-time applications to benefit the advantages of previous approaches. Finally, some considerations of latest developments in fuzzy approaches which may be introduced as potential research directions for real-time applications are stated.																	0269-2821	1573-7462				MAR	2020	53	3					1943	1974		10.1007/s10462-019-09723-6													
J								Leveraging synonymy and polysemy to improve semantic similarity assessments based on intrinsic information content	ARTIFICIAL INTELLIGENCE REVIEW										Information content; Ontology-based semantic similarity; Synonymy; Polysemy; WordNet	NEW-MODEL; RELATEDNESS; FRAMEWORK; QUERIES; FAMILY	Semantic similarity measures based on the estimation of the information content (IC) of concepts are currently regarded as the state of the art. Calculating the IC in an intrinsic (i.e., ontology-based) way is particularly convenient due to its accuracy and lack of dependency on annotated corpora. Intrinsic IC calculation models estimate concept probabilities from the taxonomic knowledge (i.e., number of hyponyms and/or hypernyms of the concepts) modelled in an ontology. In this paper, we aim to improve the intrinsic calculation of the IC by leveraging not only the hyponyms and hypernyms of concepts, but also the explicit evidences of synonymy and polysemy that ontologies such as WordNet also model. Specifically, we propose a more accurate intrinsic estimation of the concepts' probabilities in which the IC calculation relies. We evaluate the accuracy of our proposal through a set of comprehensive experiments in which our IC calculation model is tested on a variety of IC-based similarity measures and benchmarks. Experimental results show that our proposal obtains consistently good accuracies, which vary less across measures and benchmarks than the most prominent intrinsic IC calculation models available in the literature.																	0269-2821	1573-7462				MAR	2020	53	3					2023	2041		10.1007/s10462-019-09725-4													
J								Enhanced leader particle swarm optimisation (ELPSO): a new algorithm for optimal scheduling of home appliances in demand response programs	ARTIFICIAL INTELLIGENCE REVIEW										Demand response; Electrical energy; Energy; Optimisation; Metaheuristics; Particle swarm optimisation	ENERGY MANAGEMENT-SYSTEM; HOUSEHOLD APPLIANCES; EFFICIENT ALGORITHM; PSO ELPSO; CONSUMPTION	Smart grids enable the residential consumers to have an active role in the management of their electricity consumption through home energy management (HEM) systems. HEM systems adjust the ON-OFF status and/or operation modes of home appliances under demand response programs, typically in a way that the electricity bill of the home is minimised and/or the peak load is minimised. This represents a constrained multi-objective optimisation problem with integer decision variables. The existing methodologies for optimal scheduling of home appliances have two drawbacks; most of them have not taken the consumers' comfort into account and also powerful optimisation algorithms have not been used for solving this problem. In this paper, the problem of optimal scheduling of home appliances in HEM systems is formulated as a constrained, multi-objective optimisation problem with integer decision variables and a powerful variant of particle swarm optimisation, named as enhanced leader particle swarm optimisation (ELPSO) is proposed for solving this problem. Optimal scheduling of appliances is done for ten different scenarios that consider different demand response programs. The problem is solved for two different smart homes respectively with 10 and 11 appliances, both including electric vehicle as a big residential load. The results indicate the superiority of ELPSO over basic PSO, artificial bee colony, backtracking search algorithm, gravitational search algorithm and dragonfly algorithm. In the proposed multi-objective formulation, the effect of weight factor on optimal electricity bill of the home and optimal comfort of the consumers is meticulously investigated.																	0269-2821	1573-7462				MAR	2020	53	3					2043	2073		10.1007/s10462-019-09726-3													
J								Performance evaluation of classifiers for the recognition of offline handwritten Gurmukhi characters and numerals: a study	ARTIFICIAL INTELLIGENCE REVIEW										Artificial intelligence; Classification algorithms; Supervised learning; Performance measurement; Comparative studies		Classification is a process to pull out patterns from a number of classes by using various statistical properties and artificial intelligence techniques. The problem of classification is considered as one of the important problems for the development of applications and for efficient data analysis. Based on the learning adaptability and capability to solve complex computations, classifiers are always the best suited for the pattern recognition problems. This paper presents a comparative study of various classifiers and the results achieved for offline handwritten Gurmukhi characters and numerals recognition. Various classifiers used and evaluated in this study include k-nearest neighbors, linear-support vector machine (SVM), RBF-SVM, Naive Bayes, decision tree, convolution neural network and random forest classifier. For the experimental work, authors used a balanced data set of 13,000 samples that includes 7000 characters and 6000 numerals. To assess the performance of classifiers, authors have used the Waikato Environment for Knowledge Analysis which is an open source tool for machine learning. The performance is assessed by considering various parameters such as accuracy rate, size of the dataset, time taken to train the model, false acceptance rate, false rejection rate and area under receiver operating characteristic Curve. The paper also highlights the comparison of correctness of tests obtained by applying the selected classifiers. Based on the experimental results, it is clear that classifiers considered in this study have complementary rewards and they should be implemented in a hybrid manner to achieve higher accuracy rates. After executing the experimental work, their comparison and analysis, it is concluded that the Random Forest classifier is performing better than other recently used classifiers for character and numeral recognition of offline handwritten Gurmukhi characters and numerals with the recognition accuracy of 87.9% for 13,000 samples.																	0269-2821	1573-7462				MAR	2020	53	3					2075	2097		10.1007/s10462-019-09727-2													
J								An extended TOPSIS method based on ordered fuzzy numbers for group decision making	ARTIFICIAL INTELLIGENCE REVIEW										MCDM; Ordered fuzzy numbers; TOPSIS; Group decision making	SUPPLIER SELECTION; EXTENSION	Multiple criteria decision making methods have become very popular in recent years and are frequently applied in many real-life situations. One of the most commonly used is the Technique for Order Preference by Similarity to Ideal Solution. Its original version is based on the information provided by the decision maker as exact numerical values. However, in some real-life situations, the decision maker may not be able to precisely express the value of the ratings of alternatives with respect to criteria or else he/she uses linguistic expressions. In such situations he/she may use other data formats, such as: interval numbers, fuzzy numbers, ordered fuzzy numbers, hesitant fuzzy sets, intuitionistic fuzzy sets and other. On the other hand, the increasing complexity of the decision problems analysed makes it less feasible to consider all the relevant aspects of the problems by a single decision maker. As a result, many real-life problems are discussed by a group of decision makers. The aim of this paper and its main contribution is to present a new approach for ranking of alternatives for group decision making using the Technique for Order Preference by Similarity to Ideal Solution method based on ordered fuzzy numbers. This is an alternative to methods that use different forms of averages for the aggregation of the individual matrices into a collective matrix. In the proposed approach aggregation is not needed and all individual decision information of decision makers is taken into account in determining the ranking of alternatives and the selecting the best one. The key stage of this method is the transformation of the decision matrices provided by the decision makers into matrices of alternatives. A matrix corresponding to an alternative is composed of its assessments with respect to all criteria, performed by all the decision makers. A numerical example illustrates the proposed approach.																	0269-2821	1573-7462				MAR	2020	53	3					2099	2129		10.1007/s10462-019-09728-1													
J								Linguistic neutrosophic partitioned Maclaurin symmetric mean operators based on clustering algorithm and their application to multi-criteria group decision-making	ARTIFICIAL INTELLIGENCE REVIEW										LNNs; LNWPMSM operator; Similarity measures; Clustering algorithm; MCGDM	SIMILARITY MEASURES; AGGREGATION OPERATORS; PREFERENCE RELATIONS; FUZZY-SETS; INFORMATION; ENTROPY	Linguistic neutrosophic number (LNN) can describe evaluation information by three linguistic variables indicating truth-membership, indeterminacy-membership and falsity-membership respectively, which is an effective tool to represent uncertainty, the partitioned Maclaurin symmetric mean (PMSM) operator can reflect the interrelationships among criteria where there are interrelationships among criteria in the same partition, but the criteria in different partitions are irrelevant, so, in this paper, we extend the PMSM operator to LNNs, define linguistic neutrosophic partitioned Maclaurin symmetric mean operator and linguistic neutrosophic weighted partitioned Maclaurin symmetric mean (LNWPMSM) operator, and discuss the properties and theorems of the proposed operators. Then we propose a clustering algorithm for linguistic neutrosophic sets based on the similarity measure to give some objective and reasonable partitions among criteria, and based on the LNWPMSM operator and the objective partition structure of the criteria, a novel multi-criteria group decision-making method is developed for linguistic neutrosophic environment. Finally, one practical example is presented to illustrate the applicability of the proposed method, and a comparison analysis is to show the advantages of the proposed method compared with the existing methods.																	0269-2821	1573-7462				MAR	2020	53	3					2131	2170		10.1007/s10462-019-09729-0													
J								Interval neutrosophic hesitant fuzzy Einstein Choquet integral operator for multicriteria decision making	ARTIFICIAL INTELLIGENCE REVIEW										Einstein operations; Interval neutrosophic hesitant fuzzy set; Fuzzy measure; Interval neutrosophic hesitant fuzzy Einstein Choquet integral	AGGREGATION OPERATORS; INFERENCE; NETWORKS; RANKING	Recently interval neutrosophic hesitant fuzzy sets are found to be more general and useful to express incomplete, indeterminate and inconsistent information. In this paper, we define some new Einstein operational rules on interval neutrosophic hesitant fuzzy elements, then we propose the interval neutrosophic hesitant fuzzy Einstein Choquet integral (INHFECI) operator and discuss its properties. Further, an approach for multicriteria decision making is developed to study the interaction between the input arguments under the interval neutrosophic hesitant fuzzy environment. The main advantage of the proposed operator is that, it can deal with the situations of the positive interaction, negative interaction or non-interaction among the criteria, during the decision making process. Also, the proposed operator can replace the weighted average to aggregate dependent criteria of interval neutrosophic hesistant fuzzy information for obtaining more accurate results. Moreover, some interval neutrosophic hesitant fuzzy weighted average operators are proposed as special cases of INHFECI operator. Finally, an illustrative example follows.																	0269-2821	1573-7462				MAR	2020	53	3					2171	2206		10.1007/s10462-019-09730-7													
J								Applicability of LAMDA as classification model in the oil production	ARTIFICIAL INTELLIGENCE REVIEW										Classification models; LAMDA; LAMDA-HAD; Oil business; Data mining	ALGORITHM	This work analyzes the utilization of classification models in the context of the oil industry and presents examples of application. Particularly, we analyze three case studies, two to explain the behavior of oil wells that produce via artificial methods (the classification as a descriptive model), and another to predict the oil prices (the classification as a predictive model). The classification technique used in this work is LAMDA-HAD, which is an improvement to the well-known technique called learning algorithm multivariable and data analysis (LAMDA), that has been used in diagnostic tasks. Finally, the results with the descriptive and predictive models are discussed, in order to analyze the importance of the classification in the context of the oil business.																	0269-2821	1573-7462				MAR	2020	53	3					2207	2236		10.1007/s10462-019-09731-6													
J								Novel meta-heuristic bald eagle search optimisation algorithm	ARTIFICIAL INTELLIGENCE REVIEW										Bald eagle behaviour; Meta-heuristic algorithm; Optimisation; Unconstrained benchmark problem	PARTICLE SWARM OPTIMIZATION; GLOBAL OPTIMIZATION; DIFFERENTIAL EVOLUTION	This study proposes a bald eagle search (BES) algorithm, which is a novel, nature-inspired meta-heuristic optimisation algorithm that mimics the hunting strategy or intelligent social behaviour of bald eagles as they search for fish. Hunting by BES is divided into three stages. In the first stage (selecting space), an eagle selects the space with the most number of prey. In the second stage (searching in space), the eagle moves inside the selected space to search for prey. In the third stage (swooping), the eagle swings from the best position identified in the second stage and determines the best point to hunt. Swooping starts from the best point and all other movements are directed towards this point. BES is tested by adopting a three-part evaluation methodology that (1) describes the benchmarking of the optimisation problem to evaluate the algorithm performance, (2) compares the algorithm performance with that of other intelligent computation techniques and parameter settings and (3) evaluates the algorithm based on mean, standard deviation, best point and Wilcoxon signed-rank test statistic of the function values. Optimisation results and discussion confirm that the BES algorithm competes well with advanced meta-heuristic algorithms and conventional methods.																	0269-2821	1573-7462				MAR	2020	53	3					2237	2264		10.1007/s10462-019-09732-5													
J								A comprehensive survey on symbiotic organisms search algorithms	ARTIFICIAL INTELLIGENCE REVIEW										SOS algorithms; Optimization; Meta-heuristic algorithms; Nonlinear optimization	PARTICLE SWARM OPTIMIZATION; 2 SOLUTION REPRESENTATIONS; LOAD FREQUENCY CONTROL; DIFFERENTIAL EVOLUTION; ECONOMIC-DISPATCH; OPTIMAL-DESIGN; SOS ALGORITHM; POWER-SYSTEM; TRANSMISSION; PERFORMANCE	Recently, meta-heuristic algorithms have made remarkable progress in solving types of complex and NP-hard problems. So that, most of this algorithms are inspired by swarm intelligence and biological systems as well as other physical and chemical systems in nature. Of course, different divisions for meta-heuristic algorithms have been presented so far, and the number of these algorithms is increasing day by day. Among the meta-heuristic algorithms, some algorithms have a very high efficiency, which are a suitable method for solving real-world problems, but some algorithms have not been sufficiently studied. One of the nature-inspired meta-heuristic algorithms is symbiotic organisms search (SOS), which has been able to solve the majority of engineering issues so far. In this paper, firstly, the primary principles, the basic concepts, and mathematical relations of the SOS algorithm are presented and then the engineering applications of the SOS algorithm and published researches in different applications are examined as well as types of modified and multi-objective versions and hybridized discrete models of this algorithm are studied. This study encourages the researchers and developers of meta-heuristic algorithms to use this algorithm for solving various problems, because it is a simple and powerful algorithm to solve complex and NP-hard problems. In addition, a detailed and perfect statistical analysis was performed on the studies that had used this algorithm. According to the accomplished studies and investigations, features and factors of this algorithm are better than other meta-heuristic algorithm, which has increased its usability in various fields.																	0269-2821	1573-7462				MAR	2020	53	3					2265	2312		10.1007/s10462-019-09733-4													
J								Integral Backstepping Control of LPMSM Drive System Using Revised Recurrent Fuzzy NN and Mended Particle Swarm Optimization	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Particle swarm optimization; Backstepping control; Lyapunov stability; Recurrent fuzzy neural network; Linear permanent magnet synchronous motor	NEURAL-NETWORK CONTROL; SYNCHRONIZATION; ALGORITHM; DESIGN; MOTOR	A linear permanent magnet synchronous motor (LPMSM) drive system is keeping in many nonlinear effects such as the external load force, the flux saturation, the cogging force, the column friction and Stribeck force, and the parameters variations. Due to the uncertainty effects the existing linear controllers can not achieve better control performances for the LPMSM drive system. To raise robustness under occurrence of uncertainty, the integral backstepping control system with hitting function is proposed for controlling the LPMSM drive system in accordance with the Lyapunov function. To improve larger chattering phenomenon under uncertainties effects, the integral backstepping control system with revised recurrent fuzzy neural network (RRFNN) and mended particle swarm optimization (MPSO) is proposed to operate the LPMSM drive system to raise robustness of system. The RRFNN is used to estimate the value of the external lumped force uncertainty. Moreover, the error compensation control with the error compensation mechanism is proposed to compensate the minimum reconstructed error of the error estimation law. Besides, four variable learning rates in the weights of the RRFNN are regulated by virtue of MPSO with segment regulation to speed-up parameter's convergence. Finally, comparative performances through some tentative upshots are verified that the integral backstepping control system by virtue of RRFNN with MPSO has better control performances than those of the proposed methods for the LPMSM drive system.																	1562-2479	2199-3211				MAR	2020	22	2			SI		400	413		10.1007/s40815-019-00775-y													
J								High-Speed Interval Type-2 Fuzzy System for Dynamic Crossover Parameter Adaptation in Differential Evolution and Its Application to Controller Optimization	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy system; Differential Evolution algorithm; Crossover parameter; Dynamic parameter; Interval Type-2 fuzzy logic	GENETIC ALGORITHM; INFERENCE SYSTEM; LOGIC SYSTEMS; DIAGNOSIS	The main contribution in this paper is the use of a new type-reduction method to improve the processing speed of Type-2 fuzzy systems for dynamic parameter adaptation in the Differential Evolution algorithm. The proposed type-reduction is an approximation to the Continuous Karnik-Mendel (CEK) method, which is the equivalent to using a traditional Interval Type-2 fuzzy system, but with lower computational cost. The motivation of this work is to verify that the proposed methodology is equivalent in performance to an Interval Type-2 fuzzy system. The first type-reduction method was proposed by Karnik and Mendel (KM), and then was followed by its enhanced version called EKM, and the continuous versions were called CKM and CEKM. In addition, there were variations of these and also other types of variations that eliminate the type-reduction process reducing the computational cost to a Type-1 defuzzification. The concept of approximation to the Continuous Karnik-Mendel (CEK) method is new in the area of metaheuristic algorithms and this is why it is in our interest to work with this methodology. We propose to use this methodology to achieve a dynamic crossover (CR) parameter adaptation in the Differential Evolution algorithm, and the objective is to use the type-reduction process and also provide a continuous solution to the defuzzification. This proposed methodology is applied to a set of mathematical functions and a control problem, for verifying the efficiency of the proposed methodology compared to the original algorithm and other existing methods in the literature.																	1562-2479	2199-3211				MAR	2020	22	2			SI		414	427		10.1007/s40815-019-00723-w													
J								Fuzzy Logic Control of SLMMC-Based SAPF Under Nonlinear Loads	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Cascade H-bridge (CHB); Fuzzy logic controller; Half-bridge submodule (HBSM); In-phase disposition (IPD); Modular multilevel converter (MMC); PI controller; Shunt active power filter (SAPF)	SHUNT ACTIVE-FILTER; POWER; MODULATION; TOPOLOGIES; 3-PHASE	This work proposes fuzzy logic controller (FLC) for seven-level modular multilevel converter (SLMMC)-based shunt active power filter (SAPF) to reduce harmonics in source current. Half-bridge submodule is proposed for SLMMC due to its simple configuration and low conduction losses. An instantaneous real and reactive power (IPQ) method is proposed to extract reference currents. The multicarrier-based in-phase disposition (IPD) pulse width modulation method is proposed to control the switches in efficient approach. The performance of FLC in SLMMC and seven-level cascade H-bridge SAPF is verified in terms of harmonic reduction under nonlinear loads. The capacitor voltage balancing is achieved using the proposed FLC. The proposed work is simulated using MATLAB/Simulink software package.																	1562-2479	2199-3211				MAR	2020	22	2			SI		428	437		10.1007/s40815-019-00622-0													
J								Multi-level Fuzzy Based Renyi Entropy for Linguistic Classification of Texts in Natural Scene Images	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Text detection; Linguistic classification; CIE-Lab color space; Stroke width transform; Hu moments; Support vector machine	VIDEO; SEGMENTATION; RECOGNITION; FRAMEWORK	This paper focuses on linguistic classification of scene texts in natural scene images. In this paper, an attempt is made to localize texts based on multi-level thresholding by fuzzy-based Renyi entropy. Complex natural scene images with diversified challenges are considered. A set of heuristic rules comprising geometric filters and stroke width transform govern the process of locating potential text regions. The scene images may contain more than one language, where text recognition by optical character recognition system becomes challenging. Manual intervention is needed to specify the language of each text. To overcome this hurdle, linguistic classification of text regions is suggested in this paper. The proposed method is validated using publicly available dataset-MSRA-TD500. Results show that fuzzy-based Renyi entropy thresholding is able to segment the foreground text from complex natural scene images. Geometric filters could capture the inherent uniformity of the text. Stroke width transform eliminates the non-text regions. The performance measures such as precision, recall and F-measures are 78%, 77% and 76%, respectively. This shows the ability of the algorithm to extract the text from the scenes. The geometric feature such as area and corner shows better variation in discriminating the linguistic texts. Further, the first three Hu moment features also contribute remarkable role in analyzing the shape of extracted text regions. The classifier based on support vector machine (SVM) yields classification accuracy of 85.45% in discriminating English and Chinese alphabets. Area under the ROC curve (AUC) is 0.851 for SVM classifier. The proposed methodology has proved its robustness against common degradations, such as uneven illumination, varying font characteristics and blurring effects. Experimental results show that our method achieves better performance in linguistic classification.																	1562-2479	2199-3211				MAR	2020	22	2			SI		438	449		10.1007/s40815-019-00654-6													
J								Fuzzy Clustering with Self-growing Net	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy clustering; Self-growing net; Clustering with deep architecture	SPARSE REPRESENTATION; ALGORITHM	A novel deep feature mapping method self-growing net (SG-Net) is proposed, and its combination with classical fuzzy c-means (FCM) called SG-Net-FCM is further developed. SG-Net is a feedforward learning structure for nonlinear explicit feature mapping and includes four types of layers, i.e., input, fuzzy mapping, hybrid, and output layers. The fuzzy mapping layer maps the data from input layer to a high-dimensional feature space using TSK fuzzy mapping, i.e. the fuzzy mapping of Takagi-Sugeno-Kang fuzzy system (TSK-FS). Afterward, each layer in SG-Net accepts additional inputs from all preceding layers and provides its own distinguished features by using principal component analysis to all subsequent layers. The final output of SG-Net is fed to FCM. Since SG-Net-FCM is developed based on the TSK fuzzy mapping, it is more interpretable than classical kernelized fuzzy clustering methods. The effectiveness of the proposed clustering algorithm is experimentally verified on UCI datasets.																	1562-2479	2199-3211				MAR	2020	22	2			SI		450	460		10.1007/s40815-019-00782-z													
J								A Modified Fuzzy Logic Relation-Based Approach for Electricity Consumption Forecasting in India	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Short-term demand forecasting; UP electricity demand; Fuzzy time series; Weighted average; Fuzzy logic relation; Partition; K-Means	TIME-SERIES; ENROLLMENTS; DEMAND; MODELS	Prediction of electricity demand is made using Load forecasting technique to meet the ever-growing demand. In this paper, future electricity demand forecasted for the whole state of Uttar Pradesh (India), using the dataset collected from the Central Electricity Authority. This dataset consists of electricity demand for the whole state of UP for every 15-min block. Different models were used to forecast future demand. XGradientBoost (XGBoost), a machine learning algorithm was used to forecast demand first. Further forecasting was performed using deep learning models such as Long Short-Term Memory (LSTM) using neural networks as they are considered to be more efficient and accurate than XGBoost. Fuzzy time series (FTS) models were considered to incorporate trend and seasonality present in our dataset. From various FTS models, the best mean absolute percentage error achieved (MAPE) was 2.34%. A new method KmFuzz is proposed in this paper that uses modified K-Means clustering for finding an optimal number of partitions on which fuzzy logic is applied. Fuzzy sets are obtained by applying fuzzification on the dataset and the total number of sets generated are equal to the number of optimal partitions. Then the weighted average method is used for defuzzification and forecasting the next hour demand using the demand data of previous hours with MAPE of 1.94%, thus improving the accuracy further.																	1562-2479	2199-3211				MAR	2020	22	2			SI		461	475		10.1007/s40815-019-00704-z													
J								Simulation of a Bubble-Column Reactor by Three-Dimensional CFD: Multidimension- and Function-Adaptive Network-Based Fuzzy Inference System	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Multidimensional machine learning; ANFIS method; Artificial intelligence method; Bubble-column reactor; CFD	CONVECTION HEAT-TRANSFER; GAS-LIQUID FLOW; NEURAL-NETWORK; NANOCOMPOSITE MEMBRANES; TURBULENCE MODELS; ANFIS; PREDICTION; DYNAMICS; COMBINATION; BEHAVIOR	Recently, novel approaches have been developed for simulating bubbly flow as well as distributed and constant phase evolution by means of a two-phase reactor. Among these approaches, the Eulerian-Eulerian method and soft computing approaches can be mentioned. Since complex numerical methods (for example, multidimensional Eulerian-Eulerian method) require several runs for fluid conditions optimization, a method which can decrease these runs can be very useful and practical. This method is provided by joining computational fluid dynamic (CFD) to the adaptive neuro-fuzzy inference system (ANFIS). In this technique, valuable information is provided for a careful analysis of fluid conditions. Also, it can facilitate a vast amount of data categorization in synthetic neural network nodes, which eliminates the need for a complex nonstructured CFD mesh. Moreover, a neural geometry can be provided, in which no limitation of mesh numbers in the fluid domain would exist. The key CFD parameters in the scale-up of the reactorstaken into consideration in the current research are gas and liquid circulations. These factors are applied as output factors for prediction tool in various dimensions in the ANFIS method. The results obtained in this study show appropriate conformity concerning ANFIS and CFD results depending on multiple dimensions. In this study, the grouping of CFD and multifunction the ANFIS method delivers the nondiscrete domain in different dimensions and presents an intelligent instrument for the local prediction of multiphase flow. The result shows that three inputs, which represent the dimension of the reactor, and learning stage of the ANFIS method provide a better understanding of flow characteristics in the two-phase reactor, while the two-dimensional ANFIS method even with multistructured functions cannot predict well the multiphase flow in the reactor.																	1562-2479	2199-3211				MAR	2020	22	2			SI		477	490		10.1007/s40815-019-00741-8													
J								Research on UBI Auto Insurance Pricing Model Based on Adaptive SAPSO to Optimize the Fuzzy Controller	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy control; Particle swarm optimization; Autonomous underwriting coefficient	GA ALGORITHM; SYSTEM	In order to accurately determine the auto insurance rate of UBI, this paper proposes to use fuzzy controller to calculate the rate and optimize it by using the simulated annealing particle swarm algorithm with Metropolis criterion. Firstly, a fuzzy controller is constructed by selecting monthly mileage and violation times to calculate the self-underwriting coefficient. In order to eliminate the subjectivity defect of fuzzy controller, the correlation function of independent underwriting coefficient and historical risk data is proposed as the fitness function of evaluating fuzzy rules, using adaptive simulated annealing particle swarm optimization algorithm is intelligent search, according to the fitness value of continual iteration and optimize the optimal fuzzy rules. Finally, the fuzzy controller is reconstructed with the optimal fuzzy rules to estimate the auto insurance rate accurately. The results show that the adaptive simulated annealing particle swarm optimization algorithm can effectively extract the driving behavior information and can calculate the more reasonable and accurate autonomous underwriting coefficient. The results are highly correlated with the number of historical accidents and have the ability and stability of risk quantification.																	1562-2479	2199-3211				MAR	2020	22	2			SI		491	503		10.1007/s40815-019-00789-6													
J								On General Framework of Type-1 Membership Function Construction: Case Study in QoS Planning	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Membership function; Membership function construction; Membership function generation; Fuzzification problem; Fuzzy set; Type-1 fuzzy set; Quality of service; Enterprise business service; Response time	GROUP DECISION-MAKING; HESITANT FUZZY-SET; SERVICE SELECTION; PREFERENCE; DISCOVERY	Fuzzy approaches that are proposed to describe uncertain, impressive or vague concepts, are based on the construction of membership function (MF), which reflects what is known about the linguistic variables in the application domain. However, a non-trivial problem exists in how to construct the most appropriate MF that has the best-fit representation of the analysed problem. Therefore, many authors propose their own ways to construct MF using a certain technique in a particular application domain. Consequently, the need for a general approach for constructing MF led us to systematise and to generalise the analysed approaches into a general methodological framework (GMF) of constructing MF. The novelty of this paper is that the proposed GMF is general, domain independent and free of a chosen understanding of fuzziness (i.e., similarity (imprecision), preference (vagueness), and uncertainty). To verify the proposed GMF, it was applied for the enterprise business service quality (QoS(EBS)) planning problem. The obtained results showed that a semi-automatic MF construction for QoS(EBS) planning was more sensitive, less subjective and more precise than a manual construction. Moreover, illustrative examples showed that our proposed GMF is applicable and implementable. The reliability of the results was assessed using experts and users' experience, which is based on general guidelines of the "acceptable" response time limits for various activities.																	1562-2479	2199-3211				MAR	2020	22	2			SI		504	521		10.1007/s40815-019-00753-4													
J								Evaluation Model of Industrial Operation Quality Under Multi-source Heterogeneous Data Information	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Industrial operation; Quality evaluation; Multi-source heterogeneous data; Multi-source heterogeneous multi-attribute decision-making; Grey relational degree of linguistic 2-tuple matrix	GROUP DECISION-MAKING; SUPPLY CHAIN; ECONOMIC GLOBALIZATION; SUSTAINABILITY; COMPETITIVENESS; MECHANISM; SELECTION; LOCATION	Constructing scientific evaluation system and evaluation methods to make timely quantitative evaluation for regional industrial operation quality is of great practical significance for expediting the new industrialization process and promoting the improvement of national economic operation quality. Aiming at the problem of evaluating the industrial operation quality, this paper constructs a new evaluation system from the perspective of industrial operation performance and industrial development potential, and then proposes a multi-source heterogeneous multi-attribute decision-making method based on the linguistic 2-tuple model to evaluate the industrial operation quality. In this method, the original multi-source heterogeneous data whereby real numbers, interval numbers, and linguistic fuzzy numbers coexist are all transformed into linguistic 2-tuples, then a new ranking method based on grey relational degree of linguistic 2-tuple matrix is presented to rank the level of industrial operation quality for the given cities. Further, a decision-making example of evaluating the industrial operation quality for 14 cities in Hunan Province of China is provided to highlight the implementation, availability, and feasibility of the proposed evaluation model.																	1562-2479	2199-3211				MAR	2020	22	2			SI		522	547		10.1007/s40815-019-00776-x													
J								Multiple Attribute Group Decision-Making Approach Based on Multi-granular Unbalanced Hesitant Fuzzy Linguistic Information	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Multiple attribute group decision making; Multi-granular hesitant fuzzy linguistic term set; Unbalanced linguistic term set; Choquet integral	REPRESENTATION MODEL; TERM SETS; OPERATORS; DEAL	Based on multi-granular hesitant linguistic theory and unbalanced linguistic information, this paper proposes multi-granular unbalanced hesitant fuzzy linguistic term set, which can better describe the fuzzy and uncertain information from multiple attribute group decision making (MAGDM). In order to solve decision-making problem with interrelated attributes (or decision makers), the multi-granular unbalanced hesitant fuzzy linguistic Choquet integral average operator is proposed, and some properties about this operator are investigated, then a novel group decision-making method by the proposed operator is developed, and an example is adopted to demonstrate the proceeding of this method. Finally, compared with two existing methods, the effectiveness of the proposed method in MAGDM is shown.																	1562-2479	2199-3211				MAR	2020	22	2			SI		604	618		10.1007/s40815-019-00672-4													
J								A Multi-attribute Fuzzy Fluctuation Time Series Model Based on Neutrosophic Soft Sets and Information Entropy	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy time series; Neutrosophic soft set; Information entropy; Forecasting model	LOGICAL RELATIONSHIP GROUPS; FORECASTING ENROLLMENTS; SIMILARITY MEASURES; ALGORITHMS	Most existing forecasting models abstract logical rules that are based on historical discrete states in time series, and inconsistencies between these discrete states are rarely described quantitatively. In this paper, a multi-attribute fuzzy fluctuation time series-forecasting model based on neutrosophic soft sets (NSSs) and information entropy is proposed, which describes the complex changes of the logical rule training stage from the two characteristics of the state and volatility. The innovation and advantages of the model are mainly as follows: (1) The NSSs which have multi-attribute mapping and multi-dimensional expression functions can depict the complex state of multiple attributes in a specific period of time and thus characterise the state of the stock market clearly. (2) Using information entropy to quantify the degree of inconsistency of stock market fluctuations at a certain time which reflect the characteristics of volatility in the stock market effectively. (3) The similarity measure is used to find the optimal rule from the dimensions of state and volatility. To verify the validity of this model, this paper takes the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) as an example. Experiments show that the model has a stable prediction performance for different data sets. Meanwhile, the prediction error is compared with other methods, which proves that the model has better prediction accuracy and versatility.																	1562-2479	2199-3211				MAR	2020	22	2			SI		636	652		10.1007/s40815-019-00771-2													
J								Three-Way Decisions with Intuitionistic Uncertain Linguistic Decision-Theoretic Rough Sets Based on Generalized Maclaurin Symmetric Mean Operators	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										IULVs; GMSM operator; 3WDs; DTRS	OPTIMIZATION	As a typical model of three-way decisions (3WDs), decision-theoretic rough set (DTRS) has received extensive attention from researchers in the decision-making fields. Intuitionistic uncertain linguistic variables (IULVs) combine the advantages of intuitionistic fuzzy sets (IFSs) and uncertain linguistic variables (ULVs), IULV is more flexible in dealing with uncertain information in decision-making process, and provides a novel means for obtaining loss function (LF) of DTRSs. To get more comprehensive results, a new 3WD model is proposed to solve the multi-attribute group decision-making (MAGDM) problem. First, we gave the LF of DTRSs with IULVs, combined the IULVs and the generalized Maclaurin symmetric mean (GMSM), and proposed the IULGMSM and WIULGMSM operators to aggregate decision information; further, we proposed an intuitionistic uncertain linguistic DTRS model. Then, a method for deducing a new DTRS model is constructed, which can give the corresponding semantic interpretation of the decision results of each alternative. Finally, an example is applied to elaborate the proposed method in detail, and the effects of different conditional probabilities on decision results are discussed.																	1562-2479	2199-3211				MAR	2020	22	2			SI		653	667		10.1007/s40815-019-00718-7													
J								Hesitant Fuzzy Multiple Integrals for Information Aggregation	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Hesitant fuzzy element; Additive multiple integral; Multiplicative multiple integral	DECISION-MAKING; ENTROPY; SETS	Hesitant fuzzy element (HFE), membership degree of which consists of a set of crisp values, is used as an expression form when the decision makers encounter hesitance in providing their judgements. To aggregate large-scale group decision-making information under hesitant fuzzy environment, in this paper, we construct the multiple integrals for the HFEs. First, we propose the linear operations and limitation approaches of the HFEs. Next, we construct the hesitant fuzzy additive integral and hesitant fuzzy multiplicative integral and discuss their properties. Based on the two hesitant fuzzy integrals, we derive the hesitant fuzzy additive integral operator and hesitant fuzzy multiplicative integral operator to aggregate the continuous HFEs. Moreover, the useful properties of these operators are also investigated. Finally, we apply the hesitant fuzzy additive integral and hesitant fuzzy multiplicative integral operators to fuse the massive discrete HFEs which will be turned into the continuous form in advance to validate the effectiveness of the proposed multiple integrals operators. Compared with the existing methods which can only process a finite number of discrete HFEs, our methods can deal with infinitely large number of HFEs and decrease the loss of information.																	1562-2479	2199-3211				MAR	2020	22	2			SI		668	685		10.1007/s40815-019-00748-1													
J								An Integrated Fuzzy Carbon Management-Based Model for Suppliers' Performance Evaluation and Selection in Green Supply Chain Management	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Supplier selection; Green supply chain management; Carbon management; FPP; FVIKOR	DERIVING PRIORITIES; TOPSIS; VIKOR; AHP	Assessing suppliers based on green focused attributes is a critical issue recently implemented by industries due to increasing community knowledge about global warming and climate change. Carbon management is a new branch of green supplier selection which focuses on other aspects of environmental issues. This study integrates a new fuzzy modification of Analytical Hierarchy Process (AHP) known as Fuzzy Preference Programming (FPP) with Fuzzy VlseKriterijumska Optimizacija I Kompromisno Resenje (FVIKOR) to assess suppliers' performance with respect to carbon management criteria. Four dimensions and twelve criteria have been selected based on previous studies and experts' opinions. Linguistic variables are employed to gather the experts' opinions about the importance degree of the dimensions and corresponding attributes. Subsequently, the importance weights of each dimension and its corresponding criteria are computed by using FPP. The performance ratings of the suppliers based on the determined criteria are collected under a fuzzy environment using linguistic variables. Then, FVIKOR is applied to obtain the overall environmental performance with respect to carbon management attributes. Through a case study in a textile company, the performance scores of its suppliers were elicited in accordance with this procedure. Finally, validation and managerial implications show that the developed model is robust and applicable.																	1562-2479	2199-3211				MAR	2020	22	2			SI		712	723		10.1007/s40815-019-00759-y													
J								Extended Pythagorean Fuzzy TOPSIS Method Based on Similarity Measure for Sustainable Recycling Partner Selection	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Pythagorean fuzzy sets; Multi-criteria decision making; Similarity measure; TOPSIS; Sustainable recycling partner selection	SUPPLY-CHAIN MANAGEMENT; DECISION-MAKING; INFORMATION MEASURES; MEMBERSHIP GRADES; DISTANCE MEASURE; SETS; GREEN; PERFORMANCE; DIVERGENCE; FRAMEWORK	Recently, the organizations have concentrated on sustainability development and introduced several strategies for sustainability due to government policies, society concern, environmental impacts and needs of economy. Uncertainty commonly occurred in the sustainability development. Pythagorean fuzzy sets (PFSs), an extension of IFSs, have been demonstrated as an extremely valuable tool to tackle the uncertainty and ambiguity arisen in many practical situations. Thus, the proposed study focuses under Pythagorean fuzzy environment. In the present study, an approach is developed on the basis of Pythagorean fuzzy sets and Technique for Order Preference by means of Similarity to Ideal Solution method for the purpose of solving sustainable recycling partner selection problems with completely unknown decision experts and criteria weights. To calculate criteria weights, new similarity measure based on trigonometric function for PFSs is developed. Aiming at showing the way our approach can be effectively used to evaluate the realistic multi-criteria decision making problems, we carry out a case study of sustainable recycling partner selection problem. In addition, the results obtained from the proposed method are compared to those of some presently existing methods to validate the proposed method. The analytical results confirm the proficiency and reasonableness of the proposed method.																	1562-2479	2199-3211				MAR	2020	22	2			SI		735	747		10.1007/s40815-019-00689-9													
J								Multi-robot online sensing strategies for the construction of communication maps	AUTONOMOUS ROBOTS										Multi-robot systems; Sensing strategies; Communication maps	CONNECTIVITY; ENVIRONMENTS; NETWORKS	This paper tackles the problem of constructing a communication map of a known environment using multiple robots. A communication map encodes information on whether two robots can communicate when they are at two arbitrary locations and plays a fundamental role for a multi-robot system deployment to reliably and effectively achieve a variety of tasks, such as environmental monitoring and exploration. Previous work on communication map building typically considered only scenarios with a fixed base station and designed offline methods, which did not exploit data collected online by the robots. This paper proposes Gaussian Process-based online methods to efficiently build a communication map with multiple robots. Such robots form a mesh network, where there is no fixed base station. Specifically, we provide two leader-follower online sensing strategies to coordinate and guide the robots while collecting data. Furthermore, we improve the performance and computational efficiency by exploiting prior communication models that can be built from the physical map of the environment. Extensive experimental results in simulation and with a team of TurtleBot 2 platforms validate the approach.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		299	319		10.1007/s10514-019-09862-3													
J								Efficient recursive distributed state estimation of hidden Markov models over unreliable networks	AUTONOMOUS ROBOTS										Distributed state estimation; Multi-robot systems; Unreliable networks; Hidden Markov models	TIME NONLINEAR-SYSTEMS; KALMAN FILTER; CONSENSUS; FUSION	We consider a scenario in which a process of interest, evolving within an environment occupied by several agents, is well-described probablistically via a Markov model. The agents each have local views and observe only some limited partial aspects of the world, but their overall task is to fuse their data to construct an integrated, global portrayal. The problem, however, is that their communications are unreliable: network links may fail, packets can be dropped, and generally the network might be partitioned for protracted periods. The fundamental problem then becomes one of consistency as agents in different parts of the network gain new information from their observations but can only share this with those with whom they are able to communicate. As the communication network changes, different views may be at odds; the challenge is to reconcile these differences. The issue is that correlations must be accounted for, lest some sensor data be double counted, inducing overconfidence or bias. As a means to address these problems, a new recursive consensus filter for distributed state estimation on hidden Markov models is presented. It is shown to be well-suited to multi-agent settings and associated applications since the algorithm is scalable, robust to network failure, capable of handling non-Gaussian transition and observation models, and is, therefore, quite general. Crucially, no global knowledge of the communication network is ever assumed. We have dubbed the algorithm a Hybrid method because two existing pieces are used in concert: the first, iterative conservative fusion is used to reach consensus over potentially correlated priors, while consensus over likelihoods, the second, is handled using weights based on a Metropolis Hastings Markov chain. To attain a detailed understanding of the theoretical upper limit for estimator performance modulo imperfect communication, we introduce an idealized distributed estimator. It is shown that under certain general conditions, the proposed Hybrid method converges exponentially to the ideal distributed estimator, despite the latter being purely conceptual and unrealizable in practice. An extensive evaluation of the Hybrid method, through a series of simulated experiments, shows that its performance surpasses competing algorithms.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		321	338		10.1007/s10514-019-09854-3													
J								Cooperative visual-inertial sensor fusion: fundamental equations and state determination in closed-form	AUTONOMOUS ROBOTS										Visual-inertial sensor fusion; Observability; Cooperative sensor fusion; Closed-form solution	NAVIGATION; LOCALIZATION; VISION; MOTION	This paper investigates the visual and inertial sensor fusion problem in the cooperative case and provides new theoretical and basic results. Specifically, the case of two agents is investigated. Each agent is equipped with inertial sensors (accelerometer and gyroscope) and with a monocular camera. By using the monocular camera, each agent can observe the other agent. No additional camera observations (e.g., of external point features in the environment) are considered. First, the entire observable state is analytically derived. This state contains the relative position between the two agents (which includes the absolute scale), the relative velocity, the three Euler angles that express the rotation between the two local frames and all the accelerometer and gyroscope biases. Then, the basic equations that describe this system are analytically obtained. The last part of the paper describes the use of these equations to obtain a closed-form solution that provides the observable state in terms of the visual and inertial measurements provided in a short time interval. This last contribution is the extension of the results presented in Kaiser et al. (IEEE Robot Autom Lett 2(1):18-25, 2017), Martinelli (IEEE Trans Robot 28(1):44-60, 2012; Int J Comput Vis 106(2):138-152, 2014) to the cooperative case. The impact of the presence of the bias on the performance of this closed-form solution is also investigated and a simple and effective method to obtain the gyroscope bias is proposed. Extensive simulations clearly show that the proposed method is successful. It is worth noting that it is possible to automatically retrieve the absolute scale and simultaneously calibrate the gyroscopes not only without any prior knowledge (as in Kaiser et al. IEEE Robot Autom Lett 2(1):18-25, 2017), but also without external point features in the environment.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		339	357		10.1007/s10514-019-09841-8													
J								Gaussian process decentralized data fusion meets transfer learning in large-scale distributed cooperative perception	AUTONOMOUS ROBOTS										Gaussian process; Decentralized data fusion; Scalability		This paper presents novel Gaussian process decentralized data fusion algorithms exploiting the notion of agent-centric support sets for distributed cooperative perception of large-scale environmental phenomena. To overcome the limitations of scale in existing works, our proposed algorithms allow every mobile sensing agent to utilize a different support set and dynamically switch to another during execution for encapsulating its own data into a local summary that, perhaps surprisingly, can still be assimilated with the other agents' local summaries (i.e., based on their current support sets) into a globally consistent summary to be used for predicting the phenomenon. To achieve this, we propose a novel transfer learning mechanism for a team of agents capable of sharing and transferring information encapsulated in a summary based on a support set to that utilizing a different support set with some loss that can be theoretically bounded and analyzed. To alleviate the issue of information loss accumulating over multiple instances of transfer learning, we propose a new information sharing mechanism to be incorporated into our algorithms in order to achieve memory-efficient lazy transfer learning. Empirical evaluation on three real-world datasets for up to 128 agents show that our algorithms outperform the state-of-the-art methods.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		359	376		10.1007/s10514-018-09826-z													
J								SOUL: data sharing for robot swarms	AUTONOMOUS ROBOTS										Swarm robotics; Information sharing; Stigmergy; Multi-robot systems	MULTIROBOT; COMMUNICATION	Interconnected devices and mobile multi-robot systems are increasingly present in many real-life scenarios. To be effective, these systems need to collect large amounts of data from their environment, and often these data need to be aggregated, shared, and distributed. Many multi-robot systems are designed to share state information and commands, but their communication infrastructure is often too limited for significant data transfers. This paper introduces Swarm-Oriented Upload of Labeled data, a mechanism that allows members of a fully distributed system to share data with their peers. We leverage a BitTorrent-like strategy to share data in smaller chunks, or datagrams, with policies that minimize reconstruction time. We performed extensive simulations to study the properties of the system and to demonstrate its scalability. We report experiments conducted with real robots following two realistic deployment scenarios: searching for objects in a scene, and replacing the full identity of a defective robot.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		377	394		10.1007/s10514-019-09855-2													
J								A robust localization system for multi-robot formations based on an extension of a Gaussian mixture probability hypothesis density filter	AUTONOMOUS ROBOTS										Multi-robot tracking; Formation control; Cooperative positioning system; Probability hypothesis density filter; Cooperative localization	CONSENSUS; ASSIGNMENT	This paper presents a strategy for providing reliable state estimates that allow a group of robots to realize a formation even when communication fails and the tracking data alone is insufficient for maintaining a stable formation. Furthermore, the tracking information does not provide the identity of the robot, therefore a simple fusion of tracking and communication data is not possible. We extend a Gaussian mixture probability hypothesis density filter to incorporate, firstly, absolute poses exchanged by the robots, and secondly, the geometry of the desired formation. Our method of combining communicated data, information about the formation and sensory detections is capable of maintaining the state estimates even when long-duration occlusions occur, and improves awareness of the situation when the communication is sporadic or suffers from short-term outage. The proposed method is validated using a high-fidelity simulator in scenarios with a formation of up to five robots. The results show that the proposed tracking strategy allows for sustaining formations in cluttered environments, with high measurement uncertainty and low quality communication.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		395	414		10.1007/s10514-019-09860-5													
J								On-board range-based relative localization for micro air vehicles in indoor leader-follower flight	AUTONOMOUS ROBOTS										Relative localization; Leader-follower; Micro air vehicles; Autonomous flight; Indoor	SWARM; ORIENTATION; COVERAGE	We present a range-based solution for indoor relative localization by micro air vehicles (MAVs), achieving sufficient accuracy for leader-follower flight. Moving forward from previous work, we removed the dependency on a common heading measurement by the MAVs, making the relative localization accuracy independent of magnetometer readings. We found that this restricts the relative maneuvers that guarantee observability, and also that higher accuracy range measurements are required to rectify the missing heading information, yet both disadvantages can be tackled. Our implementation uses ultra wideband, for both range measurements between MAVs and sharing their velocities, accelerations, yaw rates, and height with each other. We showcased our implementation on a total of three Parrot Bebop 2.0 MAVs and performed leader-follower flight in a real-world indoor environment. The follower MAVs were autonomous and used only on-board sensors to track the same trajectory as the leader. They could follow the leader MAV in close proximity for the entire durations of the flights.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		415	441		10.1007/s10514-019-09843-6													
J								dRRT*: Scalable and informed asymptotically-optimal multi-robot motion planning	AUTONOMOUS ROBOTS										Multi-robot motion planning; Multi-robot problems; Motion planning; Asymptotic optimality; Sampling-based motion planning; Multi-arm motion planning	MULTIPLE ROBOTS; CONSTRAINTS; ALGORITHMS; COMPLEXITY; ROADMAPS; HARDNESS; PATHS	Many exciting robotic applications require multiple robots with many degrees of freedom, such as manipulators, to coordinate their motion in a shared workspace. Discovering high-quality paths in such scenarios can be achieved, in principle, by exploring the composite space of all robots. Sampling-based planners do so by building a roadmap or a tree data structure in the corresponding configuration space and can achieve asymptotic optimality. The hardness of motion planning, however, renders the explicit construction of such structures in the composite space of multiple robots impractical. This work proposes a scalable solution for such coupled multi-robot problems, which provides desirable path-quality guarantees and is also computationally efficient. In particular, the proposed dRRT*is an informed, asymptotically-optimal extension of a prior sampling-based multi-robot motion planner, dRRT The prior approach introduced the idea of building roadmaps for each robot and implicitly searching the tensor product of these structures in the composite space. This work identifies the conditions for convergence to optimal paths in multi-robot problems, which the prior method was not achieving. Building on this analysis, dRRTis first properly adapted so as to achieve the theoretical guarantees and then further extended so as to make use of effective heuristics when searching the composite space of all robots. The case where the various robots share some degrees of freedom is also studied. Evaluation in simulation indicates that the new algorithm, dRRT* converges to high-quality paths quickly and scales to a higher number of robots where various alternatives fail. This work also demonstrates the planner's capability to solve problems involving multiple real-world robotic arms.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		443	467		10.1007/s10514-019-09832-9													
J								Average case constant factor time and distance optimal multi-robot path planning in well-connected environments	AUTONOMOUS ROBOTS										Path and motion planning; Multi-robot systems; Optimal path planning	PEBBLE MOTION; INTRACTABILITY; FEASIBILITY; HARDNESS; GRAPHS	Fast algorithms for optimal multi-robot path planning are sought after in real-world applications. Known methods, however, generally do not simultaneously guarantee good solution optimality and good (e.g., polynomial) running time. In this work, we develop a first low-polynomial running time algorithm, called SplitAndGroup (SaG), that solves the multi-robot path planning problem on grids and grid-like environments, and produces constant factor makespan optimal solutions on average over all problem instances. That is, SaG is an average case O(1)-approximation algorithm and computes solutions with sub-linear makespan. SaG is capable of handling cases when the density of robots is extremely high - in a graph-theoretic setting, the algorithm supports cases where all vertices of the underlying graph are occupied. SaG attains its desirable properties through a careful combination of a novel divide-and-conquer technique, which we denote as global decoupling, and network flow based methods for routing the robots. Solutions from SaG, in a weaker sense, are also a constant factor approximation on total distance optimality.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		469	483		10.1007/s10514-019-09858-z													
J								Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning	AUTONOMOUS ROBOTS										Reinforcement learning; Multi-agent planning; Distributed robotics; Semi-Markov decision processes; Markov decision processes; Upper confidence bound tree search; Hierarchical planning; Hierarchical Markov decision processes; Model-based reinforcement learning; Swarm robotics; Dynamic domain reduction; Submodularity	POMDPS	We consider scenarios where a swarm of unmanned vehicles (UxVs) seek to satisfy a number of diverse, spatially distributed objectives. The UxVs strive to determine an efficient plan to service the objectives while operating in a coordinated fashion. We focus on developing autonomous high-level planning, where low-level controls are leveraged from previous work in distributed motion, target tracking, localization, and communication. We rely on the use of state and action abstractions in a Markov decision processes framework to introduce a hierarchical algorithm, Dynamic Domain Reduction for Multi-Agent Planning, that enables multi-agent planning for large multi-objective environments. Our analysis establishes the correctness of our search procedure within specific subsets of the environments, termed 'sub-environment' and characterizes the algorithm performance with respect to the optimal trajectories in single-agent and sequential multi-agent deployment scenarios using tools from submodularity. Simulated results show significant improvement over using a standard Monte Carlo tree search in an environment with large state and action spaces.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		485	503		10.1007/s10514-019-09871-2													
J								Hybrid planning and distributed iterative repair for multi-robot missions with communication losses	AUTONOMOUS ROBOTS										Multi-robot missions; Hybrid planning; Plan repair		This paper presents a planning and execution architecture suited for the initial planning, the execution and the on-board repair of a plan for a multi-robot mission. The team as a whole must accomplish its mission while dealing with online events such as robots breaking down, new objectives for the team, late actions and intermittent communications. We have chosen a "plan then repair" approach where an initial plan is computed offline and updated online whenever disruptive events happen. We have defined an hybrid planner that mixes Partial Order Planning (POP) with a Hierarchical Task Network (HTN)-based modelling of actions. This planner, called HiPOP for Hierarchical Partial-Order Planner, computes plans with temporal flexibility (thus easing its execution) and abstract actions (thus easing the repair process). It uses a symbolic representation of the world and has been extended with geometrical reasoning to adapt to multi-robots missions. Plans are executed in a distributed way: each robot is responsible of executing its own actions, and to propagate delays in its local plan, taking benefit from the temporal flexibility of the plan. When an inconsistency or a failure arises, a distributed repair algorithm based on HiPOP is used to repair the plan, by iteratively removing actions in the plan in order to amend the global plan. This repair is done onboard one of the robot of the team, and takes care of partial communication. The whole architecture has been evaluated through several benchmarks, statistical simulations, and field experiments involving 8 robots.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		505	531		10.1007/s10514-019-09869-w													
J								Competition and cooperation in a community of autonomous agents	AUTONOMOUS ROBOTS										Multi-agent systems; Social robotics; Game theory; Adversarial risk analysis; Bargaining	SUBJECTIVE-PROBABILITY	Agents that perform intelligent tasks interacting with humans in a seamless manner are becoming a reality. In contexts in which interactions among agents repeat over time, they might evolve from a cooperative to a competitive attitude, and vice versa, depending on environmental factors and other contextual circumstances. We provide a framework to model transitions between competition and cooperation in a community of agents. Competition is dealt with through the paradigm of adversarial risk analysis, which provides a disagreement solution; implicitly, we minimize the distance to such solution. Cooperation is handled through a concept of maximal separation from the disagreement solution. Mixtures of both problems are used to refer to in-between behaviour. We illustrate the ideas with several simulations in relation with a group of robots. Our motivation is the constitution of communities of robotic agents that interact among them and with one or more users.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		533	546		10.1007/s10514-019-09867-y													
J								Auctions for multi-robot task allocation in communication limited environments	AUTONOMOUS ROBOTS										Multi-robot; Multi-agent; Auction; Any-Com; Task allocation; Prim allocation; G-Prim; Sequential Auction; Parallel Auction; Combinatorial Auction	COORDINATION	We consider the problem of multi-robot task allocation using auctions, and study how lossy communication between the auctioneer and bidders affects solution quality. We demonstrate both analytically and experimentally that even though many auction algorithms have similar performance when communication is perfect, different auctions degrade in different ways as communication quality decreases from perfect to nonexistent. Thus, if a multi-robot system is expected to encounter lossy communication, then the auction algorithm that it uses for task allocation must be chosen carefully. We compare six auction algorithms including: standard implementations of the Sequential Auction, Parallel Auction, Combinatorial Auction; a generalization of the Prim Allocation Auction called G-Prim; and two multi-round variants of a Repeated Parallel Auction. Variants of these auctions are also considered in which award information from previous rounds is rebroadcast by the auctioneer during later rounds. We consider a variety of valuation functions used by the bidders, including: the total and maximum distance traveled (for distance based cost functions), the expected profit or cost to a robot (assuming robots' task values are drawn from a random distribution). Different auctioneer objectives are also evaluated, and include: maximizing profit (max sum), minimizing cost (min sum), and minimizing the maximum distance traveled by any particular robot (min max). In addition to the cost value functions that are used, we are also interested in fleet performance statistics such as the expected robot utilization rate, and the expected number of items won by each robot. Experiments are performed both in simulation and on real AscTec Pelican quad-rotor aircraft. In simulation, each algorithm is considered across communication qualities ranging from perfect to nonexistent. For the case of the distance-based cost functions, the performance of the auctions is compared using two different communication models: (1) a Bernoulli model and (2) the Gilbert-Elliot model. The particular auction that performs the best changes based on the the reliability of the communication between the bidders and the auctioneer. We find that G-Prim and its repeated variant perform relatively well when communication is poor, and that re-sending winner data in later rounds is an easy way improve the performance of multi-round auctions, in general.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		547	584		10.1007/s10514-019-09828-5													
J								Automated synthesis of decentralized controllers for robot swarms from high-level temporal logic specifications	AUTONOMOUS ROBOTS										Formal methods; Automated synthesis; Robotic swarm; Temporal logic	ABSTRACTION	The majority of work in the field of swarm robotics focuses on the bottom-up design of local rules for individual robots that create emergent swarm behaviors. In this paper, we take a top-down approach and consider the following problem: how can we specify a desired collective behavior and automatically synthesize decentralized controllers that can be distributed over robots to achieve the collective objective in a provably correct way? We propose a formal specification language for the high-level description of swarm behaviors on both the swarm and individual levels. We present algorithms for automated synthesis of decentralized controllers and synchronization skeletons that describe how groups of robots must coordinate to satisfy the specification. We demonstrate our proposed approach through an example in simulation.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		585	600		10.1007/s10514-019-09861-4													
J								Cooperative Queuing Policies for Effective Scheduling of Operator Intervention	AUTONOMOUS ROBOTS										Multi-robot systems cooperation; Human-robot interaction; Cooperative learning in MRS; Autonomous surface vessels		We consider multi-robot applications, where a team of robots can ask for the intervention of a human operator to handle difficult situations. As the number of requests grows, team members will have to wait for the operator attention, hence the operator becomes a bottleneck for the system. Our aim in this context is to make the robots learn cooperative strategies to decrease the idle time of the system by modeling the operator as a shared resource. In particular, we consider a balking queuing model where robots decide whether or not to join the queue and use multi-robot learning to estimate the best cooperative policy. In more detail, we formalize the problem as Decentralized Markov Decision Process and provide a suitable state representation, so to apply an independent learners approach. We evaluate the proposed method in a robotic water monitoring simulation and empirically show that our approach can significantly improve the team performance, while being computationally tractable.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		617	626		10.1007/s10514-019-09877-w													
J								Distributed coverage in mobile sensor networks without location information	AUTONOMOUS ROBOTS										Mobile sensor networks; Area coverage; Game theory; Self-regulated deployment; Distributed learning; Simplicial complexes	NODE DEPLOYMENT	With the recent advances in robotic technologies, field coverage using mobile sensors is now possible, so that a small set of sensors can be mounted on mobile robots and move to desired areas. Compared to static settings, area coverage is more complicated in a mobile sensor network due to the dynamics arising from the continuous movement of the sensors. This complication is even higher in the more realistic case where little or no prior metric information is available about the sensor field. In this paper, we consider the problem of self-deployment of a set of mobile sensors which have no knowledge of the area, the number of nodes, their location, and even the distances to each other. In this restricted setting, we formulate the problem as a multi-player game in which each sensor tries to maximize its coverage while considering the overlapping sensing areas by its neighbors. We propose a distributed learning algorithm for coordinating the movement of the sensors in the field, and prove its convergence to the equilibria of the formulated game. Simulation results demonstrate that for moderate density deployments, the proposed algorithm competes with the existing location-dependent mobility strategies, while outperforming location-free algorithms.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		627	645		10.1007/s10514-019-09859-y													
J								CARE: Cooperative Autonomy for Resilience and Efficiency of robot teams for complete coverage of unknown environments under robot failures	AUTONOMOUS ROBOTS										Multi-robot system; Self-organization; Resilience; Autonomy; Coverage path planning	MULTIROBOT COVERAGE; MOBILE-ROBOT; EXPLORATION; NAVIGATION	This paper addresses the problem of Multi-robot Coverage Path Planning for unknown environments in the presence of robot failures. Unexpected robot failures can seriously degrade the performance of a robot team and in extreme cases jeopardize the overall operation. Therefore, this paper presents a distributed algorithm, called Cooperative Autonomy for Resilience and Efficiency, which not only provides resilience to the robot team against failures of individual robots, but also improves the overall efficiency of operation via event-driven replanning. The algorithm uses distributed Discrete Event Supervisors, which trigger games between a set of feasible players in the event of a robot failure or idling, to make collaborative decisions for task reallocations. The game-theoretic structure is built using Potential Games, where the utility of each player is aligned with a shared objective function for all players. The algorithm has been validated in various complex scenarios on a high-fidelity robotic simulator, and the results demonstrate that the team achieves complete coverage under failures, reduced coverage time, and faster target discovery as compared to three alternative methods.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		647	671		10.1007/s10514-019-09870-3													
J								Distributed multi-target search and tracking using the PHD filter	AUTONOMOUS ROBOTS										Multi-target tracking; Distributed estimation and control; Voronoi partition; PHD filter	COVERAGE; TARGETS; PURSUIT	This paper proposes a distributed estimation and control algorithm that enables a team of mobile robots to search for and track an unknown number of targets. These targets may be stationary or moving, and the number of targets may vary over time as targets enter and leave the area of interest. The robots are equipped with sensors that have a finite field of view and may experience false negative and false positive detections. The robots use a novel, distributed formulation of the Probability Hypothesis Density (PHD) filter, which accounts for the limitations of the sensors, to estimate the number of targets and the positions of the targets. The robots then use Lloyd's algorithm, a distributed control algorithm that has been shown to be effective for coverage and search tasks, to drive their motion within the environment. We utilize the output of the PHD filter as the importance weighting function within Lloyd's algorithm. This causes the robots to be drawn towards areas that are likely to contain targets. We demonstrate the efficacy of our proposed algorithm, including comparisons to a coverage-based controller with a uniform importance weighting function, through an extensive series of simulated experiments. These experiments show teams of 10-100 robots successfully tracking 10-50 targets in both 2D and 3D environments.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		673	689		10.1007/s10514-019-09840-9													
J								Adaptive target tracking with a mixed team of static and mobile guards: deployment and activation strategies	AUTONOMOUS ROBOTS										Target tracking; Mobile coverage; Sensor networks	PURSUIT-EVASION; SENSOR NETWORK	This work explores a variation of the art gallery problem in which a team of static and mobile guards track a mobile intruder with unknown maximum speed. We consider the special case when the mobile guards are restricted to move along the diagonals of a polygonal environment. First, we present an algorithm to identify candidate vertices in a polygon at which either static guards can be placed or they can serve as an endpoint of the segment on which mobile guards move. Next, we present a technique to partition the environment based on the triangulation of the environment, and allocate guards to each partition to track the intruder. The allocation strategy leads to a classification of the mobile guards based on their task and coordination requirements. Finally, we present a strategy to activate/deactivate static guards based on the speed of the intruder. Simulation results are presented to validate the efficacy of the proposed techniques.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		691	703		10.1007/s10514-019-09833-8													
J								Air-ground cooperative topometric mapping of traversable ground	AUTONOMOUS ROBOTS										Air-ground cooperation; Cooperative mapping; Hybrid map	NAVIGATION	In this paper, we propose an approach for cooperative mapping of traversable ground from aerial and ground views in structured outdoor and indoor environments. The presented approach achieves a hybrid map building based on traversable ground skeletonization and graph matching. The obtained map is an augmented ground traversability map, represented as a hybrid topological/metric graph from heterogeneous sources. This approach provides a very suitable representation for ground navigation and planning. To validate this approach, the proposed algorithm is applied between aerial views, provided by a UAV flying over an experimental site, and ground maps from ground robots at different exploration stages, in realistic simulation and real-world environments.																	0929-5593	1573-7527				MAR	2020	44	3-4			SI		705	720		10.1007/s10514-019-09872-1													
J								Normative decision analysis in forensic science	ARTIFICIAL INTELLIGENCE AND LAW										Normative decision analysis; Decision theory; Value of consequences; Forensic decision; Forensic expert reporting		This paper focuses on the normative analysis-in the sense of the classic decision-theoretic formulation-of decision problems that arise in connection with forensic expert reporting. We distinguish this analytical account from other common types of decision analyses, such as descriptive approaches. While decision theory is, since several decades, an extensively discussed topic in legal literature, its use in forensic science is more recent, and with an emphasis on goals such as the analysis of the logical structure of forensic expert conclusions regarding, for example, propositions of common source of evidential and known materials. Typical examples are so-called identification (or, individualization) decisions, especially categorical conclusions according to which fingermarks (or stains of biological nature, handwriting, etc.) come from a particular a person of interest. We will present and compare ways of stating forensic identification decisions in decision-theoretic terms and explain their underlying rationale. In particular, we will emphasize the importance of viewing this analysis as normative in the sense of providing a reflective rather than a prescriptive reference point against which people in charge of forensic identification decisions may compare their otherwise (possibly) intuitive and informal reasoning, before acting. Normative decision analysis in forensic science thus provides a vector through which current practice can be articulated, scrutinized and rethought.																	0924-8463	1572-8382				MAR	2020	28	1			SI		7	25		10.1007/s10506-018-9232-2													
J								A new use case for argumentation support tools: supporting discussions of Bayesian analyses of complex criminal cases	ARTIFICIAL INTELLIGENCE AND LAW										Argument schemes; Reasoning about evidence; Probability; Argumentation support	FRAMEWORK	In this paper a new use case for legal argumentation support tools is considered: supporting discussions about analyses of complex criminal cases with the help of Bayesian probability theory. By way of a case study, two actual discussions between experts in court cases are analysed on their argumentation structure. In this study the usefulness of several recognised argument schemes is confirmed, a new argument scheme for arguments from statistics are proposed, and an analysis is given of debates between experts about the validity of their arguments. From a practical point of view the case study yields insights into the design of support software for discussions about Bayesian analyses of complex criminal cases.																	0924-8463	1572-8382				MAR	2020	28	1			SI		27	49		10.1007/s10506-018-9235-z													
J								Group-to-individual (G2i) inferences: challenges in modeling how the U.S. court system uses brain data	ARTIFICIAL INTELLIGENCE AND LAW										Neuroscience; Criminal trials; Bias; Ambiguous data	ARTIFICIAL-INTELLIGENCE; SITUATIONAL CHARACTER; NEUROSCIENCE; VIOLENCE; FAILURE; DEATH; WOMEN; LAW	Regardless of formalization used, one on-going challenge for AI systems that model legal proceedings is accounting for contextual issues, particularly where judicial decisions are made in criminal cases. The law assumes a rational approach to rule application in deciding a defendant's guilt; however, judges and juries can behave irrationally. What should a model prize: efficiency, accuracy, or fairness? Exactly whether and how to incorporate the psychology of courtroom interactions into formal models or expert systems has only just begun to be examined in a serious fashion. Here, I outline data from the United States which suggest that trying to incorporate psychological biases into formal models of legal decision-making will be challenging. I focus on the use of neuroscience data in criminal trials, homing in on so-called group-to-individual (G2i) inferences. I argue that data which should be the most effective at swaying judicial decisions are in fact those most likely not to make a difference in the disposition of the case. I conclude that judges often assign culpability by ignoring what our best science regarding how human decision-making occurs.																	0924-8463	1572-8382				MAR	2020	28	1			SI		51	68		10.1007/s10506-018-9234-0													
J								Arguing about causes in law: a semi-formal framework for causal arguments	ARTIFICIAL INTELLIGENCE AND LAW										Argumentation; Causation; Evidence; Law; Legal reasoning		Disputes over causes play a central role in legal argumentation and liability attribution. Legal approaches to causation often struggle to capture cause-in-fact in complex situations, e.g. overdetermination, preemption, omission. In this paper, we first assess three current theories of causation (but-for, NESS, 'actual causation') to illustrate their strengths and weaknesses in capturing cause-in-fact. Secondly, we introduce a semi-formal framework for modelling causal arguments through strict and defeasible rules. Thirdly, the framework is applied to the Althen vaccine injury case. And lastly, we discuss the need for new criteria based on a common causal argumentation framework and propose ideas on how to integrate the current theories of causation to assess the strength of causal arguments, while also acknowledging the tension between evidence-based and policy-based causal analysis in law.																	0924-8463	1572-8382				MAR	2020	28	1			SI		69	89		10.1007/s10506-019-09246-z													
J								Assessment criteria or standards of proof? An effort in clarification	ARTIFICIAL INTELLIGENCE AND LAW										Assessment of evidence; Beyond reasonable doubt; Fact-finding; Intime conviction; Judicial discretion; Standards of proof	DECISION-THEORY; BURDEN; PROBABILITIES; ARGUMENTS; SCENARIOS	The paper provides a conceptual distinction between evidence assessment criteria and standards of proof. Evidence must be assessed in order to check whether it satisfies a relevant standard of proof, and the assessment is operated with some criterion; so both criteria and standards are necessary for fact-finding. In addition to this conceptual point, the article addresses three main questions: (1) Why do some scholars and decision-makers take assessment criteria as standards of proof and vice versa? (2) Why do systems differ as to criteria and standards? (3) How can a system work if it neglects one of these things? The answers to the first and second question come from the historical and procedural differences between the systems. The answer to the third focuses on the functional connection between criteria and standards.																	0924-8463	1572-8382				MAR	2020	28	1			SI		91	109		10.1007/s10506-018-9233-1													
J								Proof beyond a context-relevant doubt. A structural analysis of the standard of proof in criminal adjudication	ARTIFICIAL INTELLIGENCE AND LAW										Set of epistemic defeaters; Context-relevant doubts; Reasons for decisions; Inferential contextualism; Criminal evidence; Scepticism; Applied epistemology		The present article proceeds from the mainstream view that the conceptual framework underpinning adversarial systems of criminal adjudication, i.e. a mixture of common-sense philosophy and probabilistic analysis, is unsustainable. In order to provide fact-finders with an operable structure of justification, we need to turn to epistemology once again. The article proceeds in three parts. First, I examine the structural features of justification and how various theories have attempted to overcome Agrippa's trilemma. Second, I put Inferential Contextualism to the test and show that a defeasible structure of justification allocating epistemic rights and duties to all participants of an inquiry manages to dissolve the problem of scepticism. Third, I show that our epistemic practice already embodies a contextualist mechanism. Our problem was not that our Standard of Proof is inoperable but that it was not adequately conceptualized. Contextualism provides the framework to articulate the abovementioned practice and to treat 'reasonable doubts' as a mechanism which we can now describe in detail. The seemingly insurmountable problem with our efforts to define the concept "reasonable doubts" was the fact that we have been conflating the surface features of this mechanism and its internal structure, i.e. the rules for its use.																	0924-8463	1572-8382				MAR	2020	28	1			SI		111	133		10.1007/s10506-019-09248-x													
J								A system of communication rules for justifying and explaining beliefs about facts in civil trials	ARTIFICIAL INTELLIGENCE AND LAW										Argumentation theory; Evidence; Inductive reasoning; Explanation; Justification; Bayes' theorem; Coherence	JURIDICAL PROOF; LEGAL; COHERENCE	This paper addresses the problems of justifying and explaining beliefs about facts in the context of civil trials. The first section contains some remarks about the nature of adjudicative fact-finding and highlights the communicative features of deciding about facts in judicial context. In Sect. 2, some difficulties and the incompleteness presented by Bayesian and coherentist frameworks, which are taken as methods suitable to solve the above-mentioned problems, are pointed out. In the third section, the purely epistemic approach to the justification and the explanation of beliefs about facts is abandoned and focus is given to the dialectical nature of civil procedure, where the parties and, particularly, the judge have to make their reasoning clear enough to allow a fruitful and efficient debate about facts. For this purpose, a communication/argumentation system is put forward, consisting of fourteen intertwined rules of discourse. The system embodies the fundamental epistemic principle according to which belief is updated given new evidence, is tailored for abductive inferences and is structured on fundamental concepts of civil procedural law. The fourth section presents an empirical application of the system to a real case.																	0924-8463	1572-8382				MAR	2020	28	1			SI		135	150		10.1007/s10506-019-09247-y													
J								Interactive virtue and vice in systems of arguments: a logocratic analysis	ARTIFICIAL INTELLIGENCE AND LAW										Argument; Evidence; Logocratic; Virtue; Pragmatics; Inference		The Logocratic Method, and the Logocratic theory that underwrites it, provide a philosophical explanation of three purposes or goals that arguers have for their arguments: to make arguments that are internally strong (the premises follow from the conclusions, to a greater or lesser degree-greatest degree in valid deductive arguments), or that are dialectically strong (win in some forum of argument competition, as for example in litigation contests of plaintiffs or prosecutors on the one hand, and defendants, on the other), or that are rhetorically strong (effective at persuading a targeted audience). This article presents the basic terms and methods of Logocratic analysis and then uses a case study to illustrate the Logocratic explanation of arguments. Highlights of this explanation are: the use of a (non-moral) virtue (and vice) framework to explicate the three strengths and weaknesses of arguments that are of greatest interest to arguers in many contexts (including but not limited to the context of legal argument), the Logocratic explication of the structure of abduction generally and of legal abduction specifically, the concept of a system of arguments, and the concept of the dynamic interactive virtue (and vice) of arguments-a property of systems of arguments in which the system of arguments as a whole (for example, the set of several arguments typically offered by a plaintiff or by a defendant) is as virtuous (or vicious) as are the component arguments that comprise the system. This is especially important since, according to Logocratic theory (and as illustrated in detail in this paper), some arguments, such as abduction and analogical argument, are themselves comprised of different logical forms (for example, abduction always plays a role within analogical argument, and either deduction or defeasible modus ponens, always plays a role within legal abduction).																	0924-8463	1572-8382				MAR	2020	28	1			SI		151	179		10.1007/s10506-019-09257-w													
J								Framework for extreme imbalance classification: SWIM-sampling with the majority class	KNOWLEDGE AND INFORMATION SYSTEMS										Machine learning; Imbalanced classification; Extreme imbalance; Synthetic oversampling; SMOTE	PREDICTION; SMOTE	The class imbalance problem is a pervasive issue in many real-world domains. Oversampling methods that inflate the rare class by generating synthetic data are amongst the most popular techniques for resolving class imbalance. However, they concentrate on the characteristics of the minority class and use them to guide the oversampling process. By completely overlooking the majority class, they lose a global view on the classification problem and, while alleviating the class imbalance, may negatively impact learnability by generating borderline or overlapping instances. This becomes even more critical when facing extreme class imbalance, where the minority class is strongly underrepresented and on its own does not contain enough information to conduct the oversampling process. We propose a framework for synthetic oversampling that, unlike existing resampling methods, is robust on cases of extreme imbalance. The key feature of the framework is that it uses the density of the well-sampled majority class to guide the generation process. We demonstrate implementations of the framework using the Mahalanobis distance and a radial basis function. We evaluate over 25 benchmark datasets and show that the framework offers a distinct performance improvement over the existing state-of-the-art in oversampling techniques.																	0219-1377	0219-3116				MAR	2020	62	3					841	866		10.1007/s10115-019-01380-z													
J								Nearest base-neighbor search on spatial datasets	KNOWLEDGE AND INFORMATION SYSTEMS										Information technology; k-nearest neighbor query; Group version of nearest neighbor query; Nearest base-neighbor query; Spatial databases	QUERIES	This paper presents a nearest base-neighbor (NBN) search that can be applied to a clustered nearest neighbor problem on spatial datasets with static properties. Given two sets of data points R and S, a query point q, distance threshold delta and cardinality threshold k, the NBN query retrieves a nearest point r (called the base-point) in R where more than k points in S are located within the distance delta. In this paper, we formally define a base-point and NBN problem. As the brute-force approach to this problem in massive datasets has large computational and I/O costs, we propose in-memory and external memory processing techniques for NBN queries. In particular, our proposed in-memory algorithms are used to minimize I/Os in the external memory algorithms. Furthermore, we devise a solution-based index, which we call the neighborhood-augmented grid, to dramatically reduce the search space. A performance study is conducted both on synthetic and real datasets. Our experimental results show the efficiency of our proposed approach.																	0219-1377	0219-3116				MAR	2020	62	3					867	897		10.1007/s10115-019-01360-3													
J								Kernel conditional clustering and kernel conditional semi-supervised learning	KNOWLEDGE AND INFORMATION SYSTEMS										Conditional clustering; Conditional semi-supervised learning; Conditional dependence measure; Alternative clustering; Label propagation		The results of clustering are often affected by covariates that are independent of the clusters one would like to discover. Traditionally, alternative clustering algorithms can be used to solve such clustering problems. However, these suffer from at least one of the following problems: (1) Continuous covariates or nonlinearly separable clusters cannot be handled; (2) assumptions are made about the distribution of the data; (3) one or more hyper-parameters need to be set. The presence of covariates also has an effect in a different type of problem such as semi-supervised learning. To the best of our knowledge, there is no existing method addressing the semi-supervised learning setting in the presence of covariates. Here we propose two novel algorithms, named kernel conditional clustering (KCC) and kernel conditional semi-supervised learning (KCSSL), whose objectives are derived from a kernel-based conditional dependence measure. KCC is parameter-light and makes no assumptions about the cluster structure, the covariates, or the distribution of the data, while KCSSL is fully parameter-free. On both simulated and real-world datasets, the proposed KCC and KCSSL algorithms perform better than state-of-the-art methods. The former detects the ground truth cluster structures more accurately, and the latter makes more accurate predictions.																	0219-1377	0219-3116				MAR	2020	62	3					899	925		10.1007/s10115-019-01334-5													
J								Exploiting patterns to explain individual predictions	KNOWLEDGE AND INFORMATION SYSTEMS										Explanation; Local explanation; Pattern; Contrast pattern	RULE EXTRACTION; CLASSIFIERS	Users need to understand the predictions of a classifier, especially when decisions based on the predictions can have severe consequences. The explanation of a prediction reveals the reason why a classifier makes a certain prediction, and it helps users to accept or reject the prediction with greater confidence. This paper proposes an explanation method called Pattern Aided Local Explanation (PALEX) to provide instance-level explanations for any classifier. PALEX takes a classifier, a test instance and a frequent pattern set summarizing the training data of the classifier as inputs, and then outputs the supporting evidence that the classifier considers important for the prediction of the instance. To study the local behavior of a classifier in the vicinity of the test instance, PALEX uses the frequent pattern set from the training data as an extra input to guide generation of new synthetic samples in the vicinity of the test instance. Contrast patterns are also used in PALEX to identify locally discriminative features in the vicinity of a test instance. PALEX is particularly effective for scenarios where there exist multiple explanations. In our experiments, we compare PALEX to several state-of-the-art explanation methods over a range of benchmark datasets and find that it can identify explanations with both high precision and high recall.																	0219-1377	0219-3116				MAR	2020	62	3					927	950		10.1007/s10115-019-01368-9													
J								Integrating learned and explicit document features for reputation monitoring in social media	KNOWLEDGE AND INFORMATION SYSTEMS										Document representation; Information theory; Machine learning; Microblogging	ENTROPY; SIMILARITY	Currently, monitoring reputation in social media is probably one of the most lucrative applications of information retrieval methods. However, this task poses new challenges due to the dynamicity of contents and the need for early detection of topics that affect the reputations of companies. Addressing this problem with learning mechanisms that are based on training data sets is challenging, given that unseen features play a crucial role. However, learning processes are necessary to capture domain features and dependency phenomena. In this work, based on observational information theory, we define a document representation framework that enables the combination of explicit text features and supervised and unsupervised signals into a single representation model. Our theoretical analysis demonstrates that the observation information quantity (OIQ) generalizes the most popular representation methods, in addition to capturing quantitative values, which is required for integrating signals from learning processes. In other words, the OIQ allows us to give the same treatment to features that are currently managed separately. Empirically, our experiments on the reputation-monitoring scenario demonstrated that adding features progressively from supervised (in particular, Bayesian inference over annotated data) and unsupervised learning methods (in particular, proximity to clusters) increases the similarity estimation performance. This result is verified under various similarity criteria (pointwise mutual information, Jaccard and Lin's distances and the information contrast model). According to our formal analysis, the OIQ is the first representation model that captures the informativeness (specificity) of quantitative features in the document representation.																	0219-1377	0219-3116				MAR	2020	62	3					951	985		10.1007/s10115-019-01383-w													
J								Identifying at-risk students based on the phased prediction model	KNOWLEDGE AND INFORMATION SYSTEMS										Online education; Student performance; Feature extraction; Prediction model; Educational big data mining	ONLINE; PERFORMANCE; ACHIEVEMENT; PARTICIPATION; SYSTEMS	Identifying at-risk students is one of the most important issues in online education. During different stages of a semester, students display various online learning behaviors. Therefore, we propose a phased prediction model to predict at-risk students at different stages of a semester. We analyze students' individual characteristics and online learning behaviors, extract features that are closely related to their learning performance, and propose combined feature sets based on a time window constraint strategy and a learning time threshold constraint strategy. The results of our experiments show that the precision of the proposed model in different phases is from 90.4 to 93.6%.																	0219-1377	0219-3116				MAR	2020	62	3					987	1003		10.1007/s10115-019-01374-x													
J								A systematic framework of predicting customer revisit with in-store sensors	KNOWLEDGE AND INFORMATION SYSTEMS										Revisit prediction; Retail analytics; Predictive analytics; Feature engineering; Marketing; Mobility data	SHOPPING PATH; PREDICTABILITY	Recently, there is a growing number of off-line stores that are willing to conduct customer behavior analysis. In particular, predicting revisit intention is of prime importance, because converting first-time visitors to loyal customers is very profitable. Thanks to noninvasive monitoring, shopping behaviors and revisit statistics become available from a large proportion of customers who turn on their mobile devices. In this paper, we propose a systematic framework to predict the revisit intention of customers using Wi-Fi signals captured by in-store sensors. Using data collected from seven flagship stores in downtown Seoul, we achieved 67-80% prediction accuracy for all customers and 64-72% prediction accuracy for first-time visitors. The performance improvement by considering customer mobility was 4.7-24.3%. Furthermore, we provide an in-depth analysis regarding the effect of data collection period as well as visit frequency on the prediction performance and present the robustness of our model on missing customers. We released some tutorials and benchmark datasets for revisit prediction at https://github.com/kaist-dmlab/revisit.																	0219-1377	0219-3116				MAR	2020	62	3					1005	1035		10.1007/s10115-019-01373-y													
J								Evidential positive opinion influence measures for viral marketing	KNOWLEDGE AND INFORMATION SYSTEMS										Influence maximization; Influence measure; User opinion; Theory of belief functions; Viral marketing	NODES; MAXIMIZATION; MODELS	The viral marketing is a relatively new form of marketing that exploits social networks to promote a brand, a product, etc. The idea behind it is to find a set of influencers on the network that can trigger a large cascade of propagation and adoptions. In this paper, we will introduce an evidential opinion-based influence maximization model for viral marketing. Besides, our approach tackles three opinion-based scenarios for viral marketing in the real world. The first scenario concerns influencers who have a positive opinion about the product. The second scenario deals with influencers who have a positive opinion about the product and produces effects on users who also have a positive opinion. The third scenario involves influence users who have a positive opinion about the product and produce effects on the negative opinion of other users concerning the product in question. Next, we proposed six influence measures, two for each scenario. We also use an influence maximization model that the set of detected influencers for each scenario. Finally, we show the performance of the proposed model with each influence measure through some experiments conducted on a generated dataset and a real-world dataset collected from Twitter.																	0219-1377	0219-3116				MAR	2020	62	3					1037	1062		10.1007/s10115-019-01375-w													
J								Dynamically updating approximations based on multi-threshold tolerance relation in incomplete interval-valued decision information systems	KNOWLEDGE AND INFORMATION SYSTEMS										Dynamic data; Multi-threshold tolerance relation; Approximation set; Incomplete interval-valued decision information system	ROUGH SETS APPROACH; ATTRIBUTE REDUCTION; FUSION	With the development of society, data noise and other factors will cause the incompleteness of information systems. Objects may increase or decrease over time in information systems. The classical information system can be extended to the incomplete interval-valued decision information system (IIDIS) that is the researching object of this paper. Incremental learning technique is a significant method for solving approximate sets under dynamic data. This article defines a multi-threshold tolerance relation based on the set pair analysis theory and establishes a rough set model in IIDIS. Then, several methods and algorithms for statically/dynamically solving approximate sets are shown. Finally, comparative experiments from six UCI data sets show both dynamic algorithms take less time than the static algorithm to calculate the approximate sets no matter how object set changes.																	0219-1377	0219-3116				MAR	2020	62	3					1063	1087		10.1007/s10115-019-01377-8													
J								Local low-rank Hawkes processes for modeling temporal user-item interactions	KNOWLEDGE AND INFORMATION SYSTEMS										Hawkes process; Kernel smoothing; Sequential data		Hawkes processes have become very popular in modeling multiple recurrent user-item interaction events that exhibit mutual-excitation properties in various domains. Generally, modeling the interaction sequence of each user-item pair as an independent Hawkes process is ineffective since the prediction accuracy of future event occurrences for users and items with few observed interactions is low. On the other hand, multivariate Hawkes processes (MHPs) can be used to handle multi-dimensional random processes where different dimensions are correlated with each other. However, an MHP either fails to describe the correct mutual influence between dimensions or become computational inhibitive in most real-world events involving a large collection of users and items. To tackle this challenge, we propose local low-rank Hawkes processes to model large-scale user-item interactions, which efficiently captures the correlations of Hawkes processes in different dimensions. In addition, we design an efficient convex optimization algorithm to estimate model parameters and present a parallel algorithm to further increase the computation efficiency. Extensive experiments on real-world datasets demonstrate the performance improvements of our model in comparison with the state of the art.																	0219-1377	0219-3116				MAR	2020	62	3					1089	1112		10.1007/s10115-019-01379-6													
J								Accelerating pattern-based time series classification: a linear time and space string mining approach	KNOWLEDGE AND INFORMATION SYSTEMS										Time series; Classification; String mining; Linear time and space		Subsequences-based time series classification algorithms provide interpretable and generally more accurate classification models compared to the nearest neighbor approach, albeit at a considerably higher computational cost. A number of discretized time series-based algorithms have been proposed to reduce the computational complexity of these algorithms; however, the asymptotic time complexity of the proposed algorithms is also cubic or higher-order polynomial. We present a remarkably fast and resource-efficient time series classification approach which employs a linear time and space string mining algorithm for extracting frequent patterns from discretized time series data. Compared to other subsequence or pattern-based classification algorithms, the proposed approach only requires a few parameters, which can be chosen arbitrarily and do not require any fine-tuning for different datasets. The time series data are discretized using symbolic aggregate approximation, and frequent patterns are extracted using a string mining algorithm. An independence test is used to select the most discriminative frequent patterns, which are subsequently used to create a transformed version of the time series data. Finally, a classification model can be trained using any off-the-shelf algorithm. Extensive empirical evaluations demonstrate the competitive classification accuracy of our approach compared to other state-of-the-art approaches. The experiments also show that our approach is at least one to two orders of magnitude faster than the existing pattern-based methods due to the extremely fast frequent pattern extraction, which is the most computationally intensive process in pattern-based time series classification approaches.																	0219-1377	0219-3116				MAR	2020	62	3					1113	1141		10.1007/s10115-019-01378-7													
J								Information-preserving abstractions of event data in process mining	KNOWLEDGE AND INFORMATION SYSTEMS										Process mining; Information preservation; Language abstraction; Model abstraction; Rediscoverability; Directly follows; Minimum self-distance; Inclusive choice	PROCESS MODELS; SIMILARITY; BEHAVIOR; TASKS	Process mining aims at obtaining information about processes by analysing their past executions in event logs, event streams, or databases. Discovering a process model from a finite amount of event data thereby has to correctly infer infinitely many unseen behaviours. Thereby, many process discovery techniques leverage abstractions on the finite event data to infer and preserve behavioural information of the underlying process. However, the fundamental information-preserving properties of these abstractions are not well understood yet. In this paper, we study the information-preserving properties of the "directly follows" abstraction and its limitations. We overcome these by proposing and studying two new abstractions which preserve even more information in the form of finite graphs. We then show how and characterize when process behaviour can be unambiguously recovered through characteristic footprints in these abstractions. Our characterization defines large classes of practically relevant processes covering various complex process patterns. We prove that the information and the footprints preserved in the abstractions suffice to unambiguously rediscover the exact process model from a finite event log. Furthermore, we show that all three abstractions are relevant in practice to infer process models from event logs and outline the implications on process mining techniques.																	0219-1377	0219-3116				MAR	2020	62	3					1143	1197		10.1007/s10115-019-01376-9													
J								High average-utility sequential pattern mining based on uncertain databases	KNOWLEDGE AND INFORMATION SYSTEMS										High average-utility sequential pattern mining; Sequential patterns; Uncertain database; Data mining	FREQUENT ITEMSETS; ALGORITHM	The emergence and proliferation of the internet of things (IoT) devices have resulted in the generation of big and uncertain data due to the varied accuracy and decay of sensors and their different sensitivity ranges. Since data uncertainty plays an important role in IoT data, mining the useful information from uncertain dataset has become an important issue in recent decades. Past works focus on mining the high sequential patterns from the uncertain database. However, the utility of a derived sequence increases along with the size of the sequence, which is an unfair measure to evaluate the utility of a sequence since any combination of a high-utility sequence will also be the high-utility sequence, even though the utility of a sequence is merely low. In this paper, we address the limitation of the previous potential high-utility sequential pattern mining and present a potentially high average-utility sequential pattern mining framework for discovering the set of potentially high average-utility sequential patterns (PHAUSPs) from the uncertain dataset by considering the size of a sequence, which can provide a fair measure of the patterns than the previous works. First, a baseline potentially high average-utility sequential pattern algorithm and three pruning strategies are introduced to completely mine the set of the desired PHAUSPs. To reduce the computational cost and accelerate the mining process, a projection algorithm called PHAUP is then designed, which leads to a reduction in the size of candidates of the desired patterns. Several experiments in terms of runtime, number of candidates, memory overhead, number of discovered pattern, and scalability are then evaluated on both real-life and artificial datasets, and the results showed that the proposed algorithm achieves promising performance, especially the PHAUP approach.																	0219-1377	0219-3116				MAR	2020	62	3					1199	1228		10.1007/s10115-019-01385-8													
J								Two approaches for clustering algorithms with relational-based data	KNOWLEDGE AND INFORMATION SYSTEMS										Relational database; Relational data clustering approach; Cluster validity measures	INDEXES	It is well known that relational databases still play an important role for many companies around the world. For this reason, the use of data mining methods to discover knowledge in large relational databases has become an interesting research issue. In the context of unsupervised data mining, for instance, the conventional clustering algorithms cannot handle the particularities of the relational databases in an efficient way. There are some clustering algorithms for relational datasets proposed in the literature. However, most of these methods apply complex and/or specific procedures to handle the relational nature of data, or the relational-based methods do not capture the relational nature in an efficient way. Aiming to contribute to this important topic, in this paper, we will present two simple and generic approaches to handle relational-based data for clustering algorithms. One of them treats the relational data through the use of a hierarchical structure, while the second approach applies a weight structure based on relationship and attribute information. In presenting these two approaches, we aim to tackle relational-based dataset in a simple and efficient way, improving the efficiency of corporations that handle relational-based in the unsupervised data mining context. In order to evaluate the effectiveness of the presented approaches, a comparative analysis will be conducted, comparing the proposed approaches with some existing approaches and with a baseline approach. In all analyzed approaches, we will use two well-known types of clustering algorithms (agglomerative hierarchical and K-means). In order to perform this analysis, we will use two internal and one external clusters as validity measures.																	0219-1377	0219-3116				MAR	2020	62	3					1229	1253		10.1007/s10115-019-01384-9													
J								Improved normalized graph cut with generalized data for enhanced segmentation in cervical cancer detection	EVOLUTIONARY INTELLIGENCE										Improved normalized graph cut; Pap smear test; Anisotropic diffusion equation; Hybrid dual-stage active contour method; Maximum flow algorithm	NUCLEI; CLASSIFICATION; INTELLIGENT; CYTOPLASM; ALGORITHM	Cervical cancer must be detected at an earlier stage since the late diagnosis reduces the probability of survival among the women population of the world. In this paper, improved normalized graph cut with generalized data for enhanced segmentation (INGC-GDES) mechanism was proposed for effective detection of the cytoplasm and nucleus boundary of the pap smear cell in order to detect the cervical cancer in an optimized manner. This proposed INGC-GDES approach is implemented over the pap smear cervix cells in order to analyze its hazy and overlapping boundaries for superior detection of cervical cancer cells. In this INGC-GDES approach, the preprocessed cervical image is converted into an improved normalized graph cut set for combining the merits of spatial and intensity information related to the processed image used for analysis. The method of maximum flow algorithm is applied over the derived normalized graph cut set for determining the optimal pixel points that aid in superior detection of cervical cancer. The results of the proposed INGC-GDES mechanism is determined to be predominant in enhancing the classification accuracy rate by 28% superior to the investigated graph cut-based segmentation approaches.																	1864-5909	1864-5917				MAR	2020	13	1			SI		3	8		10.1007/s12065-019-00226-5													
J								An artificial fish swarm algorithm for a multi-objective grain transportation problem	EVOLUTIONARY INTELLIGENCE										MOP; GTOP; Artificial fish swarm algorithm; Improved artificial fish swarm algorithm		The problem of grain transportation optimization is a typical NP-complete problem. To solve the problem, it is necessary to construct a mathematical model for the optimization of grain transportation. As the single-objective grain transportation route optimization model is difficult to better simulate the complex and varied conditions in real life, the multi-objective grain transportation route optimization model is closer to reality and has more guiding significance for practical problems. Therefore, this paper constructs a multi-objective grain transportation optimization problem model. And improved the artificial fish swarm algorithm to make it can be better solution. First, a similar fragment distance is introduced to replace the traditional distance calculation method. Second, we play the guiding role of bulletin board to insert the optimal solution fragment in the bulletin board into the current solution. Finally, according to the characteristics of food transportation problems, three behaviors of artificial fish were improved and mixed neighborhood search was conducted. In simulation experiments, the precision of the traditional artificial fish algorithm and improved algorithm is more and more low with the increase of amount of data. The difference between that and the optimal solution in the database is becoming more and more big, but the error in not only path length but also the number of vehicles of the improved algorithm is still within the scope of the permit. The error of the traditional artificial fish algorithm is far beyond permissible range. Experimental results show that the improved artificial fish swarm algorithm achieves high solution accuracy in path length and the number of vehicles. However, because there is no time window constraint, the conflict between the number of vehicle and the path length is very small. Finally, the set of Pareto solutions converges to 1 or 2 points.																	1864-5909	1864-5917				MAR	2020	13	1			SI		9	19		10.1007/s12065-019-00228-3													
J								Prediction of forest unit volume based on hybrid feature selection and ensemble learning	EVOLUTIONARY INTELLIGENCE										Prediction of unit volume; Hybrid feature selection; Ensemble learning; Model fusion; Forest resources	BOOSTED REGRESSION TREE; SITKA SPRUCE; GROWTH; PINE	Aiming at the characteristics of forestry data with high dimensionality and complex samples, this paper explores an ensemble learning method suitable for predicting forest unit volume, which provides a scientific basis for forest resource management and decision-making. According to the real data provided by the National Forestry Science Data Sharing Service Platform, a FL-Stacking model based on hybrid feature selection and ensemble learning is proposed. Firstly, the model extracts features based on Filter-Lasso hybrid method, then constructs the prediction model of forest unit volume based on ensemble learning, and uses eight prediction models such as Linear SVM regression as the fusion basis model in the training set by Stacking scheme. The data are verified by 10 folds cross-validation. Finally, the fusion and optimization of the basic model are carried out. The experimental results show that the optimal accuracy of the single model is 83.81%, the multi-model predicted by FL-Stacking model is 84.55%, and the R-2 value is increased by 0.74 percentage points. The comparative analysis results of different models on real data sets show that the FL-Stacking integrated prediction model proposed in this paper has a high accuracy in estimating forest unit volume, and has a great practical research value.																	1864-5909	1864-5917				MAR	2020	13	1			SI		21	32		10.1007/s12065-019-00219-4													
J								Analysis of evolutionary process of fog computing system based on BA and ER network hybrid model	EVOLUTIONARY INTELLIGENCE										Fog computing system; BA scale-free network; ER random network; Evolutionary process	ENERGY	Fog computing is oriented to the Internet of Things, which integrates network, computing, storage and application capabilities. It is a semi-virtualized distributed service computing paradigm. It extends data, data processing and applications to the edge of the network and provides intelligent services for users nearby. The purpose of this paper is to design a safe, stable and efficient fog computing model. On the basis of the structure of fog computing system, the evolution process of fog computing nodes is modeled based on BA scale-free network and ER stochastic network model. Then the evolution process of network hybrid model is analyzed. Finally, the evolution model of fog computing system is solved, and a network model with two network characteristics is obtained. Experiments show that the hybrid network model has the advantages of two basic networks.																	1864-5909	1864-5917				MAR	2020	13	1			SI		33	38		10.1007/s12065-019-00225-6													
J								Application of improved time series Apriori algorithm by frequent itemsets in association rule data mining based on temporal constraint	EVOLUTIONARY INTELLIGENCE										Time series; Apriori algorithm; Frequent item; Data mining; Association rule; Temporal constraint		The basic idea of Apriori algorithm is first introduced in this paper, which is to find all frequent sets in a transaction. The frequent requirements of these frequent sets are greater than or equal to the minimum support of the set. On this basis, the working principle of the traditional Apriori algorithm is analyzed, and the existing problems are pointed out. To solve these problems, an improved Apriori algorithm is proposed for time series of frequent itemsets. Finally, on the basis of analyzing the methods and processes of mining association rules for time series, this improved time series Apriori algorithm for frequent itemsets is applied to mining association rules based on time constraints. The experimental results show that the improved Apriori algorithm is better than the traditional one in storage space.																	1864-5909	1864-5917				MAR	2020	13	1			SI		39	49		10.1007/s12065-019-00234-5													
J								Structure optimization method based on automatic vectorization	EVOLUTIONARY INTELLIGENCE										Structure peeling; Address mapping; SIMD vectorization; Access affinity		Structure is used more extensively used in program such as scientific computing. But the non-continuity and the non-aligment of vectorization structure array have a dramatic influence on the efficiency of program's vectorizaton. To reduce the access to these addresses during the SIMD vectorization, a structure peeling model is proposed based on the structure which combines domain access affinity and domain data type. At the same time, to meet t the requirement of memory access continuity and alignment in the vectorization of structured array, an address conversion method is proposed which structure arrays are mapped one by one map to two-dimensional arrays, further reducing the failure rate of cache. By using the test suites of gcc_vec, spec2000 and spec2006, the experimental results on the compiler of automatic vector show that the performance of optimized method can be improved by more than 8%.																	1864-5909	1864-5917				MAR	2020	13	1			SI		51	58		10.1007/s12065-019-00229-2													
J								A node-priority based large-scale overlapping community detection using evolutionary multi-objective optimization	EVOLUTIONARY INTELLIGENCE										Community detection; Multi-objective optimization; Large-scale network; Pareto fronts; Node priority	GENETIC ALGORITHM; COMPLEX NETWORKS; MODULARITY	Community structure is one of the most important features in complex networks. However, with increasing of network scale, some existing methods cannot effectively detect the community structure of complex network, and the available methods mostly aimed at non-overlapping networks. In this paper, we focus on overlapping community detection in large-scale networks, because most of the communities in real-world networks are overlapped. In order to improve the accuracy of large-scale overlapping community detection, we suggest a community detection method based on node priority. The proposed algorithm has two advantages: (1) We define a priority function fNN to assess the closeness between adjacent nodes. It explores the potential community structure in advance and reduces the scale of networks. (2) We employ NSGA-II and select all Pareto fronts to mine large-scale overlapping communities. The proposed algorithm is tested by the artificial and real datasets. The results show that the proposed algorithm can effectively improve the accuracy of community detection and has better optimization effect.																	1864-5909	1864-5917				MAR	2020	13	1			SI		59	68		10.1007/s12065-019-00250-5													
J								Energy consumption laxity-based quorum selection for distributed object-based systems	EVOLUTIONARY INTELLIGENCE										Quorum-based locking protocol; Data management; Energy-aware information systems; Object-based systems; Replication	POWER-CONSUMPTION; MODEL; SERVER; ALGORITHM	In object based systems, an object is an unit of computation resource. Distributed applications are composed of multiple objects. Objects in an application are replicated to multiple servers in order to increase reliability, availability, and performance. On the other hand, the large amount of electric energy is consumed in a system compared with non-replication systems since multiple replicas of each object are manipulated on multiple servers. In this paper, the energy consumption laxity-based quorum selection (ECLBQS) algorithm is proposed to construct a quorum for each method issued by a transaction so that the total electric energy consumption of servers to perform methods can be reduced in the quorum based locking protocol. The total electric energy consumption of servers, the average execution time of each transaction, and the number of aborted transactions are shown to be more reduced in the ECLBQS algorithm than the random algorithm in evaluation.																	1864-5909	1864-5917				MAR	2020	13	1			SI		71	82		10.1007/s12065-018-0157-1													
J								Performance evaluation of support vector machine and convolutional neural network algorithms in real-time vehicle type and color classification	EVOLUTIONARY INTELLIGENCE										Vehicle detection and classification; Video processing; Tiny-YOLO; Intelligent traffic management systems		In order for traffic management and information systems to provide proper traffic flow, it is necessary to obtain information about traffic with the help of various sensors. In this context, in recent years the use of video cameras in traffic observation and control has become very widespread and actively used. Numerous studies such as license plate recognition, vehicle number finding, traffic intensity determination, vehicle speed calculation, band violation and vehicle classification can be done with the help of video processing based video monitoring systems. Traffic surveillance videos are very actively used for this purpose. In this paper, we have developed a system that classifies vehicles according to their type. Firstly we create a vehicle dataset from an uncalibrated camera. Then, we test Tiny-YOLO real-time object detection and classification system and support vector machine (SVM) classifier model on our dataset and well-known public BIT-Vehicle dataset in terms of recall, precision, and intersection over union performance metrics. Experimental results show that two methods can be used to classify real-time streaming traffic video data.																	1864-5909	1864-5917				MAR	2020	13	1			SI		83	91		10.1007/s12065-018-0167-z													
J								Message broadcasting by opportunistic communication on unit disk graphs	EVOLUTIONARY INTELLIGENCE										Opportunistic communication; Movement pattern; Levy walk; Homesick Levy walk; Unit disk graphs	FLIGHT SEARCH PATTERNS; LEVY-WALK	Opportunistic communication is one of the key technologies in the area of advertisement, information sharing, disaster evacuation guidance in delay-tolerant networks (DTNs), vehicular ad hoc networks (VANETs) and so on. The efficiency of opportunistic communication is correlated with the movement pattern. Random walks are often used as the movement patterns of a pedestrian. Even amongst those, Levy walk that is a family of random walks is attracted attention as a human movement pattern. There are lots of works of Levy walk in the context of target detection in swarm robotics, analyzing human walk patterns, and modeling the behavior of animal foraging in recent years. According to these results, it is known as an efficient method to search and come across one another in a two-dimensional plane. However, all these works assume a continuous plane and hardly any results on graphs are available. In this paper, we assume agents move on a unit disk graph and show the impact of the movement patterns based on Levy walk and Homesick Levy walk to the efficiency of message broadcasting by them. Our simulation results show that the configuration of Levy walk and Homesick Levy walk movement patterns with the smaller scaling parameter diffuses a message efficiently compared to it with the larger one.																	1864-5909	1864-5917				MAR	2020	13	1			SI		93	102		10.1007/s12065-018-0189-6													
J								Implementation of adaptive scheme in evolutionary technique for anomaly-based intrusion detection	EVOLUTIONARY INTELLIGENCE										ISCX 2012; Network security; Adaptive grasshopper optimization algorithm; Intrusion detection	GRASSHOPPER OPTIMIZATION ALGORITHM; FEATURE-SELECTION; NETWORKS; ENSEMBLE; CLASSIFIER; SYSTEMS	Intrusion detection has become important to network security because of the increasing connectivity between computers and internet. Various Intrusion Detection Systems have been investigated to protect web or networks using several evolutionary methods and classification techniques. In this study, we propose a new technique by combining Ensemble of Feature Selection (EFS) and Adaptive Grasshopper Optimization Algorithm (AGOA) methods, called EFSAGOA which can help to identify the types of attack. In the proposed approach, initially, EFS method is applied to rank the attribute for selecting the high ranked subset of attributes. Then, AGOA is employed to determine important attributes from the reduced datasets that can contribute to predict the networks traffic behavior. Furthermore, adaptive behavior of GOA uses to decide whether a record represents an anomaly or not, differing from some approaches acquainted in the literature. AGOA uses the Support Vector Machine (SVM) as a fitness function to choose the extremely efficient features and to maximize the classification performance. In addition, it is also applied to optimize the penalty factor (C), kernel parameter (sigma) and tube size (epsilon)of SVM classifier. The performance of EFSAGOA has been evaluated on modern intrusion data as ISCX 2012. The experimental results demonstrate that the proposed method performs better and obtain high detection rate, accuracy, and low false alarm rate compared to other state-of-art techniques in ISCX 2012 data.																	1864-5909	1864-5917				MAR	2020	13	1			SI		103	117		10.1007/s12065-019-00293-8													
J								A construction of smart city evaluation system based on cloud computing platform	EVOLUTIONARY INTELLIGENCE										Cloud computing; Smart city; Evaluation system; Index value; Index weight	IMPLEMENTATION; CITIES	Smart city is a complex systematic engineering. It not only needs planing, constructing, managing and running, but also requires evaluating, optimizing and adjusting, in order to keep the smart city construction prospective, reasonable and effective. The application of cloud computing platform can effectively improve the intellectualization of urban. According to the problems such as the blind construction and the unsatisfied results during the process of the smart city construction, we carry on the theoretical exploration about smart city evaluation system based on cloud platform and studying the indexes included in smart city and relation among them, and further propose the method of the smart city evaluation system. The core of the method is the smart city evaluation indexes system, evaluation method and optimization strategy and the feasibility of the method is verified by an example. Finally, we propose an application-oriented cloud computing platform architecture, it can improve the evaluation results and maximize the capacity of smart cities.																	1864-5909	1864-5917				MAR	2020	13	1			SI		119	129		10.1007/s12065-019-00259-w													
J								Robust Fitting in Computer Vision: Easy or Hard?	INTERNATIONAL JOURNAL OF COMPUTER VISION										Robust fitting; Consensus maximisation; Inlier set maximisation; Computational hardness	ALGORITHMS; COMPLEXITY	Robust model fitting plays a vital role in computer vision, and research into algorithms for robust fitting continues to be active. Arguably the most popular paradigm for robust fitting in computer vision is consensus maximisation, which strives to find the model parameters that maximise the number of inliers. Despite the significant developments in algorithms for consensus maximisation, there has been a lack of fundamental analysis of the problem in the computer vision literature. In particular, whether consensus maximisation is "tractable" remains a question that has not been rigorously dealt with, thus making it difficult to assess and compare the performance of proposed algorithms, relative to what is theoretically achievable. To shed light on these issues, we present several computational hardness results for consensus maximisation. Our results underline the fundamental intractability of the problem, and resolve several ambiguities existing in the literature.																	0920-5691	1573-1405				MAR	2020	128	3			SI		575	587		10.1007/s11263-019-01207-y													
J								Learning SO(3) Equivariant Representations with Spherical CNNs	INTERNATIONAL JOURNAL OF COMPUTER VISION										Equivariance; Sphere; Spherical CNN; 3D vision		We address the problem of 3D rotation equivariance in convolutional neural networks. 3D rotations have been a challenging nuisance in 3D classification tasks requiring higher capacity and extended data augmentation in order to tackle it. We model 3D data with multi-valued spherical functions and we propose a novel spherical convolutional network that implements exact convolutions on the sphere by realizing them in the spherical harmonic domain. Resulting filters have local symmetry and are localized by enforcing smooth spectra. We apply a novel pooling on the spectral domain and our operations are independent of the underlying spherical resolution throughout the network. We show that networks with much lower capacity and without requiring data augmentation can exhibit performance comparable to the state of the art in standard 3D shape retrieval and classification benchmarks.																	0920-5691	1573-1405				MAR	2020	128	3			SI		588	600		10.1007/s11263-019-01220-1													
J								EKLT: Asynchronous Photometric Feature Tracking Using Events and Frames	INTERNATIONAL JOURNAL OF COMPUTER VISION										Asynchronous; Low latency; High dynamic range; Dynamic vision sensor; Event camera; Feature tracking; Maximum likelihood; Generative model; Low-level vision	VISUAL ODOMETRY; VISION; SLAM	We present EKLT, a feature tracking method that leverages the complementarity of event cameras and standard cameras to track visual features with high temporal resolution. Event cameras are novel sensors that output pixel-level brightness changes, called "events". They offer significant advantages over standard cameras, namely a very high dynamic range, no motion blur, and a latency in the order of microseconds. However, because the same scene pattern can produce different events depending on the motion direction, establishing event correspondences across time is challenging. By contrast, standard cameras provide intensity measurements (frames) that do not depend on motion direction. Our method extracts features on frames and subsequently tracks them asynchronously using events, thereby exploiting the best of both types of data: the frames provide a photometric representation that does not depend on motion direction and the events provide updates with high temporal resolution. In contrast to previous works, which are based on heuristics, this is the first principled method that uses intensity measurements directly, based on a generative event model within a maximum-likelihood framework. As a result, our method produces feature tracks that are more accurate than the state of the art, across a wide variety of scenes.																	0920-5691	1573-1405				MAR	2020	128	3			SI		601	618		10.1007/s11263-019-01209-w													
J								Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input	INTERNATIONAL JOURNAL OF COMPUTER VISION										Vision and language; Sound; Speech; Multimodal learning; Language acquisition; Visual object discovery; Unsupervised learning; Self-supervised learning		In this paper, we explore neural network models that learn to associate segments of spoken audio captions with the semantically relevant portions of natural images that they refer to. We demonstrate that these audio-visual associative localizations emerge from network-internal representations learned as a by-product of training to perform an image-audio retrieval task. Our models operate directly on the image pixels and speech waveform, and do not rely on any conventional supervision in the form of labels, segmentations, or alignments between the modalities during training. We perform analysis using the Places 205 and ADE20k datasets demonstrating that our models implicitly learn semantically coupled object and word detectors.																	0920-5691	1573-1405				MAR	2020	128	3			SI		620	641		10.1007/s11263-019-01205-0													
J								CornerNet: Detecting Objects as Paired Keypoints	INTERNATIONAL JOURNAL OF COMPUTER VISION										Object detection; Associative embedding; Hourglass network		We propose CornerNet, a new approach to object detection where we detect an object bounding box as a pair of keypoints, the top-left corner and the bottom-right corner, using a single convolution neural network. By detecting objects as paired keypoints, we eliminate the need for designing a set of anchor boxes commonly used in prior single-stage detectors. In addition to our novel formulation, we introduce corner pooling, a new type of pooling layer that helps the network better localize corners. Experiments show that CornerNet achieves a 42.2% AP on MS COCO, outperforming all existing one-stage detectors.																	0920-5691	1573-1405				MAR	2020	128	3			SI		642	656		10.1007/s11263-019-01204-1													
J								Differential Scene Flow from Light Field Gradients	INTERNATIONAL JOURNAL OF COMPUTER VISION										Scene flow; 3D motion estimation; Differential analysis; Differential motion; Light fields; 3D shape and motion estimation; Computational cameras	OPTICAL-FLOW; STEREO	This paper presents novel techniques for recovering 3D dense scene flow, based on differential analysis of 4D light fields. The key enabling result is a per-ray linear equation, called the ray flow equation, that relates 3D scene flow to 4D light field gradients. The ray flow equation is invariant to 3D scene structure and applicable to a general class of scenes, but is under-constrained (3 unknowns per equation). Thus, additional constraints must be imposed to recover motion. We develop two families of scene flow algorithms by leveraging the structural similarity between ray flow and optical flow equations: local 'Lucas-Kanade' ray flow and global 'Horn-Schunck' ray flow, inspired by corresponding optical flow methods. We also develop a combined local-global method by utilizing the correspondence structure in the light fields. We demonstrate high precision 3D scene flow recovery for a wide range of scenarios, including rotation and non-rigid motion. We analyze the theoretical and practical performance limits of the proposed techniques via the light field structure tensor, a 3x3 matrix that encodes the local structure of light fields. We envision that the proposed analysis and algorithms will lead to design of future light-field cameras that are optimized for motion sensing, in addition to depth sensing.																	0920-5691	1573-1405				MAR	2020	128	3			SI		679	697		10.1007/s11263-019-01230-z													
J								GANimation: One-Shot Anatomically Consistent Facial Animation	INTERNATIONAL JOURNAL OF COMPUTER VISION										GAN; Face animation; Action-unit condition		Recent advances in generative adversarial networks (GANs) have shown impressive results for the task of facial expression synthesis. The most successful architecture is StarGAN (Choi et al. in CVPR, 2018), that conditions GANs' generation process with images of a specific domain, namely a set of images of people sharing the same expression. While effective, this approach can only generate a discrete number of expressions, determined by the content and granularity of the dataset. To address this limitation, in this paper, we introduce a novel GAN conditioning scheme based on action units (AU) annotations, which describes in a continuous manifold the anatomical facial movements defining a human expression. Our approach allows controlling the magnitude of activation of each AU and combining several of them. Additionally, we propose a weakly supervised strategy to train the model, that only requires images annotated with their activated AUs, and exploit a novel self-learned attention mechanism that makes our network robust to changing backgrounds, lighting conditions and occlusions. Extensive evaluation shows that our approach goes beyond competing conditional generators both in the capability to synthesize a much wider range of expressions ruled by anatomically feasible muscle movements, as in the capacity of dealing with images in the wild. The code of this work is publicly available at .																	0920-5691	1573-1405				MAR	2020	128	3			SI		698	713		10.1007/s11263-019-01210-3													
J								Convolutional Networks with Adaptive Inference Graphs	INTERNATIONAL JOURNAL OF COMPUTER VISION										Convolutional neural networks; Gumbel-Softmax; Residual networks		Do convolutional networks really need a fixed feed-forward structure? What if, after identifying the high-level concept of an image, a network could move directly to a layer that can distinguish fine-grained differences? Currently, a network would first need to execute sometimes hundreds of intermediate layers that specialize in unrelated aspects. Ideally, the more a network already knows about an image, the better it should be at deciding which layer to compute next. In this work, we propose convolutional networks with adaptive inference graphs (ConvNet-AIG) that adaptively define their network topology conditioned on the input image. Following a high-level structure similar to residual networks (ResNets), ConvNet-AIG decides for each input image on the fly which layers are needed. In experiments on ImageNet we show that ConvNet-AIG learns distinct inference graphs for different categories. Both ConvNet-AIG with 50 and 101 layers outperform their ResNet counterpart, while using 20%and 38% less computations respectively. By grouping parameters into layers for related classes and only executing relevant layers, ConvNet-AIG improves both efficiency and overall classification quality. Lastly, we also study the effect of adaptive inference graphs on the susceptibility towards adversarial examples. We observe that ConvNet-AIG shows a higher robustness than ResNets, complementing other known defense mechanisms.																	0920-5691	1573-1405				MAR	2020	128	3			SI		730	741		10.1007/s11263-019-01190-4													
J								Group Normalization	INTERNATIONAL JOURNAL OF COMPUTER VISION										Normalization; Image recognition; Object detection; Batch size	STATISTICS	Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems-BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO (), and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.																	0920-5691	1573-1405				MAR	2020	128	3			SI		742	755		10.1007/s11263-019-01198-w													
J								DeepTAM: Deep Tracking and Mapping with Convolutional Neural Networks	INTERNATIONAL JOURNAL OF COMPUTER VISION										Camera tracking; Multi view stereo; ConvNets		We present a system for dense keyframe-based camera tracking and depth map estimation that is entirely learned. For tracking, we estimate small pose increments between the current camera image and a synthetic viewpoint. This formulation significantly simplifies the learning problem and alleviates the dataset bias for camera motions. Further, we show that generating a large number of pose hypotheses leads to more accurate predictions. For mapping, we accumulate information in a cost volume centered at the current depth estimate. The mapping network then combines the cost volume and the keyframe image to update the depth prediction, thereby effectively making use of depth measurements and image-based priors. Our approach yields state-of-the-art results with few images and is robust with respect to noisy camera poses. We demonstrate that the performance of our 6 DOF tracking competes with RGB-D tracking algorithms.We compare favorably against strong classic and deep learning powered dense depth algorithms.																	0920-5691	1573-1405				MAR	2020	128	3			SI		756	769		10.1007/s11263-019-01221-0													
J								Support vector regression to correct motor current of machine tool drives	JOURNAL OF INTELLIGENT MANUFACTURING										Friction model; Machine tool drive; Support vector regression; Cutting technology	CUTTING FORCE MEASUREMENT; FRICTION MODEL; FEED DRIVES; COMPENSATION; SELECTION	Nonlinear friction is the limiting factor in using motor current signals to estimate the load of machine tools. The inertia of the axis and the positional dependency of the friction add another degree of complexity. The work focuses on industrial machining centers with ball-screw driven stages as they are used in metal cutting. The approach uses Internal low-frequency signals from the NC controller to keep the barriers for an industrial application at a minimum. The contribution of this study is twofold: First, it extends conventional analytic friction models so that they incorporate positional dependency of friction, as well as the contribution of the inertia of the axis. Second, it proposes how to model the both effects jointly through support vector regression. This data-driven model outperforms the extended Stribeck and the generalized Maxwell-slip friction models, which serve as a representative benchmark for static and dynamic friction models respectively. However, this comes with the need for a careful selection of the data, on which the support vector machine is trained, in order to obtain an accurate and general model.																	0956-5515	1572-8145				MAR	2020	31	3					553	560		10.1007/s10845-019-01464-1													
J								On-line part deformation prediction based on deep learning	JOURNAL OF INTELLIGENT MANUFACTURING										Deformation prediction; Monitoring data; Deep learning; Tensor model	DISTORTION; COMPONENTS; MODEL	Deformation prediction is the basis of deformation control in manufacturing process planning. This paper presents an on-line part deformation prediction method using a deep learning model during numerical control machining process, which is different from traditional methods based on finite element simulation of stress release prior to the actual machining process. A fourth-order tensor model is proposed to represent the continuous part geometric information, process information, and monitoring information, which is used as the input to the deep learning model. A deep learning framework with a conventional neural network and a recurrent neural network has been constructed and trained by monitored deformation data and process information associated with interim part geometric information. The proposed method can be generalised for different parts with certain similarities and has the potential to provide a reference for an adaptive machining control strategy for reducing part deformation. The proposed method was validated by actual machining experiments, and the results show that the prediction accuracy has been improved compared with existing methods. Furthermore, this paper shifts the difficult problem of residual stress measurement and off-line deformation prediction to the solution of on-line deformation prediction based on deformation monitoring data.																	0956-5515	1572-8145				MAR	2020	31	3					561	574		10.1007/s10845-019-01465-0													
J								A study on the prediction of inherent deformation in fillet-welded joint using support vector machine and genetic optimization algorithm	JOURNAL OF INTELLIGENT MANUFACTURING										T-joint fillet welding; Inherent deformations; Numerical simulation; Support vector machine; Genetic algorithm; Finite element method	ARTIFICIAL NEURAL-NETWORK; WELDING DISTORTION PREDICTION; RESIDUAL-STRESSES; BEAD GEOMETRY; PARAMETER OPTIMIZATION; NUMERICAL-SIMULATION; ANGULAR DISTORTIONS; TENSILE-STRENGTH; DEFECT DETECTION; SM490A STEEL	The inherent deformation method has a significant advantage in evaluating the total welding deformations for large and complex welded structures. The prerequisite for applying this approach is that the inherent deformations of corresponding weld joints should be known beforehand. In this study, an intelligent model based on support vector machine (SVM) and genetic algorithm (GA) was established to predict the inherent deformations of a fillet-welded joint. The training samples were obtained from numerical experiments conducted by the thermal-elastic-plastic finite element analysis. In the developed SVM model, the welding speed, current, voltage and plate thickness were considered as input parameters, and the longitudinal and transverse inherent deformations were corresponding outputs. The correlation coefficients and percentage errors for all the samples were calculated to evaluate the prediction performance of the SVM model. The research results demonstrate that the SVM model optimized by GA can be used to assess the longitudinal and transverse inherent deformations for the T-joint fillet weld with acceptable accuracy.																	0956-5515	1572-8145				MAR	2020	31	3					575	596		10.1007/s10845-019-01469-w													
J								Integrating customer requirements into customized product configuration design based on Kano's model	JOURNAL OF INTELLIGENT MANUFACTURING										Customer requirements; Product configuration; Product design; Kano's model	QUALITY FUNCTION DEPLOYMENT; MASS CUSTOMIZATION; SATISFACTION; MANAGEMENT; OPTIMIZATION; QFD	Owing to the increasing concerns about customer needs in the current competitive market, the identification and incorporation of customer requirements (CRs) into product configuration designs have raised the interest of both researchers and practitioners. Most of the design methodologies focus on explicit technical domains to define CRs into specific design parameters directly. However, the CRs are so complicated that they are usually expressed in vague, ambiguous language containing uncertain information and are not in the form of well-defined specifications of product attributes and components. Kano's model provides a qualitative way to classify CRs accurately. However, research contributions are seldom found in terms of quantitatively integrating Kano's model with product designs. This paper identifies a novel approach based on the quantification of Kano's model for integrating CRs into product engineering characteristics. Kano's model is quantified by identifying the relationships between the CRs and customer satisfaction to link the requirements mapping phase and product configuration design phase. The quantitative results derived from Kano's model are formulated as the multi-objective functions in a mixed non-linear programming model to identify the product configuration solution. For illustrative purposes, an example associated with the configuration design of a material-forming configuration production line is presented to demonstrate the capability of the proposed model.																	0956-5515	1572-8145				MAR	2020	31	3					597	613		10.1007/s10845-019-01467-y													
J								A methodology for solving facility layout problem considering barriers: genetic algorithm coupled with A* search	JOURNAL OF INTELLIGENT MANUFACTURING										Manufacturing systems design; Facility layout problem; Genetic algorithm; A* search algorithm; Monte Carlo simulation	SIMULATED ANNEALING ALGORITHM; ANT COLONY OPTIMIZATION; ASSEMBLY-LINE; DESIGN; SINGLE; STRATEGIES	This work proposes a new methodology and mathematical formulation to address the facility layout problem. The goal is to minimise the total material handling cost subjected to production-derived constraints. This cost is a function of the distance that the products should cover within the facility. The first idea is to use the A* algorithm to identify the distances between workstations in a more realistic way. A* determines the shortest path within the facility that contains obstacles and transportation routes. The second idea is to combine a genetic algorithm and the A* algorithm with a homogenous methodology to improve the quality of the facility layouts. In an iterative way, the layout solution space is explored using the genetic algorithm. We study the impacts of the appropriate crossover and mutation operators and the values of the parameters used in this algorithm on the cost of the proposed arrangements. These operators and parameter values are fine-tuned using Monte Carlo simulations. The facility arrangements are all compared and discussed based on their material handling cost associated with the Euclidean distance, rectilinear distance, and A* algorithm. Finally, we present a set of conclusions regarding the suggested methodology and discuss our future research goals.																	0956-5515	1572-8145				MAR	2020	31	3					615	640		10.1007/s10845-019-01468-x													
J								Genetic algorithms applied to integration and optimization of billing and picking processes	JOURNAL OF INTELLIGENT MANUFACTURING										Warehouse management; Maximize billing; Minimize costs; Picking systems; Genetic algorithms	VARIABLE NEIGHBORHOOD SEARCH; ORDER PICKING; SUPPLY CHAIN; HYBRID ALGORITHM; TRAVEL DISTANCE; WAREHOUSE; OPERATIONS; PICKERS; SYSTEMS; STORAGE	This article intends to provide a computational tool that integrates and provides optimized solutions to two interdependent problems called Optimized Billing Sequencing (OBS) and Optimized Picking Sequence (OPS). These problems are addressed separately by the existing literature and refer respectively to the optimization of billing and picking processes in a typical warehouse with low-level picker-to-parts system. Integration literature is, therefore, limited and there is a demand for more robust OBS/OPS optimization methods. This approach will deal with practical dilemmas that have not been addressed by researchers yet to propose an extension to the OBS model by Pinto et al. (J Intell Manuf 29(2):405-422, 2018) along with a specific variation of the Order Batching and Sequencing Problem. The premise is to prove to managers the possibility of making more consistent decisions about the trade-off between the level of customer service and the warehouse efficiency. The proposed tool is formulated by the integration of two Genetic Algorithms called GA-OBS and GA-OPS where GA-OBS maximizes the order portfolio billing and generates the picking order to the OPS, whereas GA-OPS comprises the iteration of batch and routing algorithms to minimize picking total time and cost to the OPS. Experiments with problems with different complexity levels showed that the proposed tool produces solutions of satisfactory quality to OBS/OPS. The approach proposed fills a gap in the literature and makes innovative contributions to the development of more suitable optimization methods to the reality of warehouses.																	0956-5515	1572-8145				MAR	2020	31	3					641	659		10.1007/s10845-019-01470-3													
J								A modular factory testbed for the rapid reconfiguration of manufacturing systems	JOURNAL OF INTELLIGENT MANUFACTURING										Reconfigurable; Testbed; Smart factory; Distributed control	ARCHITECTURE; PRODUCT; DESIGN; MODEL; ROBOT; INTEGRATION; RESOURCE; PLATFORM; SUPPORT; SMART	The recent manufacturing trend toward mass customization and further personalization of products requires factories to be smarter than ever before in order to: (1) quickly respond to customer requirements, (2) resiliently retool machinery and adjust operational parameters for unforeseen system failures and product quality problems, and (3) retrofit old systems with upcoming new technologies. Furthermore, product lifecycles are becoming shorter due to unbounded and unpredictable customer requirements, thereby requiring reconfigurable and versatile manufacturing systems that underpin the basic building blocks of smart factories. This study introduces a modular factory testbed, emphasizing transformability and modularity under a distributed shop-floor control architecture. The main technologies and methods, being developed and verified through the testbed, are presented from the four aspects of rapid factory transformation: self-layout recognition, rapid workstation and robot reprogramming, inter-layer information sharing, and configurable software for shop-floor monitoring.																	0956-5515	1572-8145				MAR	2020	31	3					661	680		10.1007/s10845-019-01471-2													
J								SDF-GA: a service domain feature-oriented approach for manufacturing cloud service composition	JOURNAL OF INTELLIGENT MANUFACTURING										Service domain features (SDFs); Service composition and optimal selection (SCOS); Cloud manufacturing (CMfg); Manufacturing cloud service composition; Genetic algorithm (GA)	SELECTION; RESOURCE	Cloud manufacturing (CMfg) is a new service-oriented manufacturing paradigm in which shared resources are integrated and encapsulated as manufacturing services. When a single service is not able to meet some manufacturing requirement, a composition of multiple services is then required via CMfg. Service composition and optimal selection (SCOS) is a key technique for creating an on-demand quality of service (QoS)-optimal efficient manufacturing service composition to satisfy various user requirements. Given the number of services with the same functionality and a similar level of QoS, SCOS has been seen as a key challenge in CMfg research. One effective approach to solving SCOS problems is to use service domain features (SDF) through investigating the probability of services being used for a specific requirement from multiple perspectives. The approach can result in a division of the service space and then help streamline the service space with large-scale candidate services. The approach can also search for optimal subspaces that most likely contribute to an overall optimal solution. Accordingly, this paper develops an SDF-oriented genetic algorithm to effectively create a manufacturing service composition with large-scale candidate services. Fine-grained SDF definitions are developed to divide the service space. SDF-based optimization strategies are adopted. The novelty of the proposed algorithm is presented based on Bayes' theorem. The effectiveness of the proposed algorithm is validated by solving three real-world SCOS problems in a private CMfg.																	0956-5515	1572-8145				MAR	2020	31	3					681	702		10.1007/s10845-019-01472-1													
J								Control chart pattern recognition using the convolutional neural network	JOURNAL OF INTELLIGENT MANUFACTURING										Control chart; Pattern recognition; Convolutional neural network; Feature learning; Deep learning	FEATURE-EXTRACTION; PERFORMANCE	Unnatural control chart patterns (CCPs) usually correspond to the specific factors in a manufacturing process, so the control charts have become important means of the statistical process control. Therefore, an accurate and automatic control chart pattern recognition (CCPR) is of great significance for manufacturing enterprises. In order to improve the CCPR accuracy, experts have designed various complex features, which undoubtedly increases the workload and difficulty of the quality control. To solve these problems, a CCPR method based on a one-dimensional convolutional neural network (1D-CNN) is proposed. The proposed method does not require to extract complex features manually; instead, it uses a 1D-CNN to obtain the optimal feature set from the raw data of the CCPs through the feature learning and completes the CCPR. The dataset for training and validation, containing six typical CCPs, is generated by the Monte-Carlo simulation. Then, the influence of the network structural parameters and activation functions on the recognition performance is analyzed and discussed, and some suggestions for parameter selection are given. Finally, the performance of the proposed method is compared with that of the traditional multi-layer perceptron method using the same dataset. The comparison results show that the proposed 1D-CNN method has obvious advantages in the CCPR tasks. Compared with the related literature, the features extracted by the 1D-CNN are of higher quality. Furthermore, the 1D-CNN trained with simulation dataset still perform well in recognizing the real dataset from the production environment.																	0956-5515	1572-8145				MAR	2020	31	3					703	716		10.1007/s10845-019-01473-0													
J								Research on adaptive CNC machining arithmetic and process for near-net-shaped jet engine blade	JOURNAL OF INTELLIGENT MANUFACTURING										Adaptive CNC machining process; Measuring bad points culling algorithm; Camber line calculation algorithm; ICP algorithm; Near-net-shaped blade; Rigid-flexible coupling fixture	PROBING STRATEGY; OPTIMIZATION; REGISTRATION; LOCALIZATION; COMPONENTS; ALGORITHM	Near-net-shaped jet engine blade machining process have better performance on both reducing material waste during production and improving work reliability in service, while precision machining of this blade is very challengeable and difficult due to its positioning difficulty and low stiffness. This paper propose that reasonable fixture and adaptive CNC machining technology can provide a systematic solution for the machining of near-net-shaped blade Tenon root, tip and Leading edges and Trailing edges (LTE). Firstly, process characteristics, difficulties and requirements of near-net-shaped blade are analyzed. Secondly, adaptive CNC machining process and its key technical principles are introduced and optimized, and proposes measuring bad points culling algorithm of simultaneously using distance relationship, angle relationship and radius relationship, and proposes camber line calculation algorithm of equidistant offset, and optimizes the iterative closest point (ICP) algorithm based on point-to-line ICP algorithm with six control points, and realizes the reconstruction of processing model. Finally, the feasibility of the proposed adaptive CNC machining process and the designed Polyetheretherketone (PEEK-GF30) material and multi-points support rigid-flexible coupling fixture are verified by a typical near-net-shaped blade LTE and Tenon root adaptive CNC machining process experiments. The results shows that the proposed process scheme of reasonable fixture and adaptive CNC machining process can solve two problems of near-net-shaped blade manufacturing of position difficulty and low stiffness. The designed fixture of PEEK-GF30 material and multi-point support rigid-flexible coupling, and the optimized adaptive CNC machining process algorithms can realize high-precision manufacturing of near-net-shaped jet engine blade.																	0956-5515	1572-8145				MAR	2020	31	3					717	744		10.1007/s10845-019-01474-z													
J								Optimization of preventive maintenance for series manufacturing system by differential evolution algorithm	JOURNAL OF INTELLIGENT MANUFACTURING										Preventive maintenance strategy; Series manufacturing system; Differential evolution; Reliability; Imperfect maintenance	OPTIMAL REPLACEMENT; IMPERFECT; POLICY; COST; MODEL; STRATEGIES; MINIMIZE	The costs of preventive maintenance have been extensively studied by scholars across all preventive optimization model disciplines. However, one phenomenon fails to be fully studied: breakdown and breakdown maintenance costs. We set out to fill this gap in this study. This study considered the cost of equipment preventive maintenance, and the breakdown maintenance cost caused by an accidental breakdown. In order to more accurately establish the reliability model of equipment breakdown, the three-parameter Weibull distribution was applied to set up the reliability model of equipment and the differential evolution algorithm was adopted to optimize the parameters. On this basis, preventive maintenance was regarded as imperfect maintenance in the study of preventive maintenance strategies for single equipment. In consideration of the combined influence of preventive maintenance and breakdown maintenance, a maintenance strategy in which preventive maintenance times N served as the decision variable was obtained to build a mathematical model on benefit expectation of single equipment in unit time. Based on the research of single equipment, a further study was performed on the multi-equipment series system. Moreover, two strategies were given, both of which use preventive maintenance times N as the decision variable. The first strategy is to take the average cost rate of the system under long-term operation as the optimization objective, while the second strategy is to apply single component maintenance strategy in series system. In the numerical example study, a series manufacturing system composed of two devices was chosen as the research object. Interestingly, we discussed the effect of initial conditions of two-parameter DE on output results. After acquiring the optimal initialization parameters, the failure rate function was achieved by the DE to estimate the parameters of three-parameter Weibull distribution. Meanwhile, the maintenance times N was optimized according to the two strategies respectively. The best result were selected from the results of both strategies based on availability. Thus, the validity and practicability of the proposed research methods are verified.																	0956-5515	1572-8145				MAR	2020	31	3					745	757		10.1007/s10845-019-01475-y													
J								Segmentation-based deep-learning approach for surface-defect detection	JOURNAL OF INTELLIGENT MANUFACTURING										Surface-defect detection; Visual inspection; Quality control; Deep learning; Computer vision; Segmentation networks; Industry 4; 0		Automated surface-anomaly detection using machine learning has become an interesting and promising area of research, with a very high and direct impact on the application domain of visual inspection. Deep-learning methods have become the most suitable approaches for this task. They allow the inspection system to learn to detect the surface anomaly by simply showing it a number of exemplar images. This paper presents a segmentation-based deep-learning architecture that is designed for the detection and segmentation of surface anomalies and is demonstrated on a specific domain of surface-crack detection. The design of the architecture enables the model to be trained using a small number of samples, which is an important requirement for practical applications. The proposed model is compared with the related deep-learning methods, including the state-of-the-art commercial software, showing that the proposed approach outperforms the related methods on the specific domain of surface-crack detection. The large number of experiments also shed light on the required precision of the annotation, the number of required training samples and on the required computational cost. Experiments are performed on a newly created dataset based on a real-world quality control case and demonstrates that the proposed approach is able to learn on a small number of defected surfaces, using only approximately 25-30 defective training samples, instead of hundreds or thousands, which is usually the case in deep-learning applications. This makes the deep-learning method practical for use in industry where the number of available defective samples is limited. The dataset is also made publicly available to encourage the development and evaluation of new methods for surface-defect detection.																	0956-5515	1572-8145				MAR	2020	31	3					759	776		10.1007/s10845-019-01476-x													
J								A convolutional approach to quality monitoring for laser manufacturing	JOURNAL OF INTELLIGENT MANUFACTURING										Neural-networks; Convolutional-neural-networks; Quality-control; Laser-cladding; Laser-welding	SYSTEMS	The extraction of meaningful features from the monitoring of laser processes is the foundation of new non-destructive quality inspection methods for the manufactured pieces, which has been and remains a growing interest in industry. We present ConvLBM, a novel approach to monitor Laser Based Manufacturing processes in real-time. ConvLBM uses a Convolutional Neural Network model to extract features and quality indicators from raw Medium Wavelength Infrared coaxial images. We demonstrate the ability of ConvLBM to represent process dynamics, and predict quality indicators in two scenarios: dilution estimation in Laser Metal Deposition, and location of defects in laser welding processes. Obtained results represent a breakthrough in the 3D printing of large metal parts, and in the quality control of welding processes. We are also releasing the first large dataset of annotated images of laser manufacturing.																	0956-5515	1572-8145				MAR	2020	31	3					789	795		10.1007/s10845-019-01495-8													
J								Group Conformity in Social Networks	JOURNAL OF LOGIC LANGUAGE AND INFORMATION										Social networks; Diffusion; Influence; Peer pressure; Conformity; Threshold model; Axiomatization; Completeness; Armstrong's axioms; Multiagent systems	DIFFUSION; MODELS	Diffusion in social networks is a result of agents' natural desires to conform to the behavioral patterns of their peers. In this article we show that the recently proposed "propositional opinion diffusion model" could be used to model an agent's conformity to different social groups that the same agent might belong to, rather than conformity to the society as whole. The main technical contribution of this article is a sound and complete logical system describing the properties of the influence relation in this model. The logical system is an extension of Armstrong's axioms from database theory by one new axiom that captures the topological structure of the network.																	0925-8531	1572-9583				MAR	2020	29	1			SI		3	19		10.1007/s10849-019-09303-5													
J								On the Logic of Balance in Social Networks	JOURNAL OF LOGIC LANGUAGE AND INFORMATION										Modal logic; Completeness; Social networks; Balance	STRUCTURAL BALANCE	Modal logics for reasoning about social networks is currently an active field of research. There is still a gap, however, between the state of the art in logical formalisations of concepts related to social networks and the much more mature field of social network analysis. In this paper we take a step to bridge that gap. One of the key foundations of social network analysis is balance theory, which is used to analyse signed social networks where agents can have positive ("friends") or negative ("enemies") relationships. Certain combinations of positive and negative relationships are considered to be unbalanced, or unstable-in particular the occurrence of cycles with an odd number of negative relationships. Especially relatively short cycles with an odd number of negative relationships are thought to put pressure on the agents to change one or more of the involved relationships from negative to positive or the other way around. Most existing logics for reasoning about social networks are defined for unsigned networks. In this paper we develop a modal logic for reasoning about structural properties of signed social networks, and give a sound and complete Hilbert-style axiomatic system. Furthermore, we completely axiomatise classes of signed social networks that are balanced to a certain degree n, in the sense that there are no cycles of length up to n with an odd number of negative relationships. Finally, we completely axiomatise the class of all fully balanced complete signed social networks, i.e., networks where everyone is connected with everyone else. Axiomatic completeness is non-trivial because neither the balance properties, nor the dichotomy between positive and negative relations, are modally definable. The paper thus provides a logical basis for reasoning about signed social networks in general and balanced networks in particular.																	0925-8531	1572-9583				MAR	2020	29	1			SI		53	75		10.1007/s10849-019-09297-0													
J								Multi-agent Logics for Reasoning About Higher-Order Upper and Lower Probabilities	JOURNAL OF LOGIC LANGUAGE AND INFORMATION										Probabilistic logic; Upper and lower probabilities; Decidability; Completeness theorem	KNOWLEDGE	We present a propositional and a first-order logic for reasoning about higher-order upper and lower probabilities. We provide sound and complete axiomatizations for the logics and we prove decidability in the propositional case. Furthermore, we show that the introduced logics generalize some existing probability logics.																	0925-8531	1572-9583				MAR	2020	29	1			SI		77	107		10.1007/s10849-019-09301-7													
J								Deep memetic models for combinatorial optimization problems: application to the tool switching problem	MEMETIC COMPUTING										Deep architecture; Hybrid algorithms; Memetic algorihms; Tool switching problem (ToSP)	ALGORITHMS; SEARCH; NUMBER	Memetic algorithms are techniques that orchestrate the interplay between population-based and trajectory-based algorithmic components. In particular, some memetic models can be regarded under this broad interpretation as a group of autonomous basic optimization algorithms that interact among them in a cooperative way in order to deal with a specific optimization problem, aiming to obtain better results than the algorithms that constitute it separately. Going one step beyond this traditional view of cooperative optimization algorithms, this work tackles deep meta-cooperation, namely the use of cooperative optimization algorithms in which some components can in turn be cooperative methods themselves, thus exhibiting a deep algorithmic architecture. The objective of this paper is to demonstrate that such models can be considered as an efficient alternative to other traditional forms of cooperative algorithms. To validate this claim, different structural parameters, such as the communication topology between the agents, or the parameter that influences the depth of the cooperative effort (the depth of meta-cooperation), have been analyzed. To do this, a comparison with the state-of-the-art cooperative methods to solve a specific combinatorial problem, the Tool Switching Problem, has been performed. Results show that deep models are effective to solve this problem, outperforming metaheuristics proposed in the literature.																	1865-9284	1865-9292				MAR	2020	12	1					3	22		10.1007/s12293-019-00294-1													
J								A memetic algorithm with optimal recombination for the asymmetric travelling salesman problem	MEMETIC COMPUTING										Optimal recombination; Local search; Restart rule; Computational experiment	LOCAL SEARCH; OPTIMIZATION	We propose a new memetic algorithm with optimal recombination for the asymmetric travelling salesman problem (ATSP). The optimal recombination problem (ORP) is solved in a crossover operator based on a new exact algorithm that solves the ATSP on cubic digraphs. A new mutation operator makes random jumps in 3-opt or 4-opt neighborhoods. The initial population is constructed by means of greedy constructive heuristics. The 3-opt local search is used to improve the initial and the final populations. A computational experiment on the TSPLIB instances shows that the proposed algorithm yields results competitive to those of other well-known algorithms for ATSP and confirms that the ORP may be used successfully in memetic algorithms.																	1865-9284	1865-9292				MAR	2020	12	1					23	36		10.1007/s12293-019-00291-4													
J								Noising methods with hybrid greedy repair operator for 0-1 knapsack problem	MEMETIC COMPUTING										Noising method; 0-1 knapsack problem; Threshold accepting; Hybrid greedy repair operator	MONARCH BUTTERFLY OPTIMIZATION; CHEMICAL-REACTION OPTIMIZATION; GLOBAL HARMONY SEARCH; ALGORITHM	Noising methods (NMs) include a set of local search methods and can be considered as simulated annealing algorithm or threshold accepting (TA) method when its components are properly chosen. This paper studies how to utilize NMs for solving the 0-1 knapsack problem (0-1 KP). Two noising strategies, noising variation of objective function and noising data, are used to help NMs escape from local optima. When noising variation of objective function is used, probabilistic acceptance or deterministic acceptance is used to decide whether to accept neighbor solutions. Two decreasing strategies, arithmetical decreasing and geometrical decreasing, are used to control the change of parameter noise-rate. In total, six variants of NMs including two TAs are designed to solve the 0-1 KP. In those variants, a hybrid greedy repair operator, which combines density-based and value-based greedy drop and add operators, is designed to get better balance between intensification and diversification. Extensive experiments were performed to compare the performances of the six variants of NMs. The performances of the six variants of NMs were also compared with some state-of-the-art metaheuristics on a wide range of small size, medium size, and large size 0-1 KP instances. Simulation results show that NMs are better than or competitive with other state-of-the-art metaheuristics.																	1865-9284	1865-9292				MAR	2020	12	1					37	50		10.1007/s12293-019-00288-z													
J								An Adaptive Island Evolutionary Algorithm for the berth scheduling problem	MEMETIC COMPUTING										Maritime transportation; Berth scheduling problem; Optimization; Parallel evolutionary algorithms; Island model; Adaptive mechanism; Migration	MARINE CONTAINER TERMINALS; NEIGHBORHOOD SEARCH; ALLOCATION PROBLEM; TABU SEARCH; SHIPS; MODEL	Increasing volumes of the seaborne containerized trade put additional pressure on marine container terminal operators. Long congestion periods have been reported at certain marine container terminals due to inability of the infrastructure to serve the growing demand, increasing number of megaships, port disruptions, and other factors. In order to alleviate congestion and avoid potential cargo delivery delays to the end customers, marine container terminal operators have to enhance the efficiency of their operations. This study focuses on improving the seaside operations at marine container terminals. A new Adaptive Island Evolutionary Algorithm is proposed for the berth scheduling problem, aiming to minimize the total weighted service cost of vessels. The developed algorithm simultaneously executes separate Evolutionary Algorithms in parallel on its islands and exchanges individuals between the islands based on an adaptive mechanism, which allows more efficient exploration of the problem search space. A set of extensive computational experiments indicate that the optimality gaps of the Adaptive Island Evolutionary Algorithm do not exceed 1.93% for the considered small-size problem instances. Furthermore, the proposed solution algorithm was compared against the other state-of-the-art metaheuristic algorithms and exhibited statistically significant improvements in terms of the objective function values.																	1865-9284	1865-9292				MAR	2020	12	1					51	72		10.1007/s12293-019-00292-3													
J								DSM-DE: a differential evolution with dynamic speciation-based mutation for single-objective optimization	MEMETIC COMPUTING										Differential evolution; Mutation strategy; Dynamic speciation; Single-objective optimization	INFORMATION	A new differential evolution algorithm with two dynamic speciation-based mutation strategies (DSM-DE) is proposed to solve single-objective optimization problems. An explorative mutation "DE/seeds-to-seeds" and an exploitative mutation "DE/seeds-to-rand" are employed simultaneously in DSM-DE in the evolutionary process. A Dynamic Speciation Technique is designed to assist the two mutations in order to utilize the potential of selective portioning of critical individuals in the population. It dynamically divides the population into numbers of species whilst taking species seeds as centers. The best individuals for each species are used as base vectors in each species in the proposed mutation strategies. "DE/seeds-to-seeds" selects individuals from species seeds and current species to constitute difference vectors whereas "DE/seeds-to-rand" selects from the whole population. Thus the two mutation strategies can accelerate the convergence process without decreasing diversity of the population. Comparison results with four classic DE variants, one state-of-art DE variant and two improved non-DE variants on CEC2014, CEC2015 benchmark, and Lennard-Jones potential problem reveal that the overall performance of DSM-DE is better than that of the other seven DE algorithms. In addition, experiments also substantiate the effectiveness and superiority of two seeds-guided mutation strategies in DSM-DE.																	1865-9284	1865-9292				MAR	2020	12	1					73	86		10.1007/s12293-019-00279-0													
J								Multi-level diversification approach of semantic-based image retrieval results	PROGRESS IN ARTIFICIAL INTELLIGENCE										Socio-tagged images; Semantic annotation; Semantic retrieval; Semantic rules; k-means clustering; Search result diversification	QUERY EXPANSION; ANNOTATION; COLOR; RELEVANCE; FEATURES; SEARCH	With the increasing popularity of social photograph-sharing Web sites, a huge mass of digital images, associated with a set of tags voluntarily introduced by amateur photographers, is daily hosted and consequently, the Tag-based social Image Retrieval technique has been widely adopted. However, tag-based queries are often too ambiguous and abstract to be considered as an efficient solution for the retrieval of the most relevant images that meet the users' needs. As an alternative, the Semantic-based social Image Retrieval technique has emerged for the purpose of retrieving the relevant images covering as much possible the topics that a given ambiguous query (q) may have. Actually, the diversification strategies are a great challenge for researchers. In this context, we jointly investigate two processes at the ambiguous query preprocessing and postprocessing levels. On the one hand, we propose a Tag-based Query Semantic Reformulation process, which aims at reformulating the tag-based users' queries, according to multiple semantic facets of the different images' views, by using a set of predefined ontological semantic rules. On the other hand, we propose a Multi-level Image Diversification process that can first perform a two-level-based image clustering offline, and second, filter and re-rank the image cluster retrieval results according to their pertinence versus the reformulated query online. The experimental results and statistical analysis performed on a collection of 25.000 socio-tagged images shared on Flickr demonstrate the effectiveness of the proposed technique, which is compared with the research technique based on one-level-based image clustering, tag-based image research technique and recent CBIR techniques.																	2192-6352	2192-6360				MAR	2020	9	1					1	30		10.1007/s13748-019-00195-x													
J								Improving financial bankruptcy prediction in a highly imbalanced class distribution using oversampling and ensemble learning: a case from the Spanish market	PROGRESS IN ARTIFICIAL INTELLIGENCE										Financial distress; Prediction; Ensemble learning; Financial crisis	FEATURE-SELECTION; CORPORATE BANKRUPTCY; ROTATION FOREST; RATIOS; MACHINE; ALGORITHM; MODELS; SMOTE; SETS	Bankruptcy is one of the most critical financial problems that reflects the company's failure. From a machine learning perspective, the problem of bankruptcy prediction is considered a challenging one mainly because of the highly imbalanced distribution of the classes in the datasets. Therefore, developing an efficient prediction model that is able to detect the risky situation of a company is a challenging and complex task. To tackle this problem, in this paper, we propose a hybrid approach that combines the synthetic minority oversampling technique with ensemble methods. Moreover, we apply five different feature selection methods to find out what are the most dominant attributes on bankruptcy prediction. The proposed approach is evaluated based on a real dataset collected from Spanish companies. The conducted experiments show promising results, which prove that the proposed approach can be used as an efficient alternative in case of highly imbalanced datasets.																	2192-6352	2192-6360				MAR	2020	9	1					31	53		10.1007/s13748-019-00197-9													
J								A multi-objective interactive dynamic particle swarm optimizer	PROGRESS IN ARTIFICIAL INTELLIGENCE										Multi-objective optimization; Particle swarm optimization; Interactive decision making; Dynamic optimization problem; Comparative study		Multi-objective optimization deals with problems having two or more conflicting objectives that have to be optimized simultaneously. When the objectives change somehow with time, the problems become dynamic, and if the decision maker indicates preferences at runtime, then the algorithms to solve them become interactive. In this paper, we propose the integration of SMPSO/RP, an interactive multi-objective particle swarm optimizer based on SMPSO, with InDM2, an algorithmic template for dynamic interactive optimization with metaheuristics. The result is SMPSO/RPD, an algorithm that provides the search capabilities of SMPSO, incorporates an interactive preference articulation mechanism based on defining one or more reference points, and is able to deal with dynamic problems. We conduct a qualitative study showing the working of SMPSO/RPD on three benchmark problems, remaining a qualitative analysis as an open line of future research.																	2192-6352	2192-6360				MAR	2020	9	1					55	65		10.1007/s13748-019-00198-8													
J								Improving recommender systems by encoding items and user profiles considering the order in their consumption history	PROGRESS IN ARTIFICIAL INTELLIGENCE										Recommender systems; Profiles; Matrix factorization; Collaborative filtering		The aim of Recommender Systems is to suggest items (products) to satisfy each user's particular taste. Representation strategies play a very important role in these systems, as an adequate codification of users and items is expected to ease the induction of a model which synthesizes their tastes and make better recommendations. However, in addition to gathering information about users' tastes, there is an additional aspect that can be relevant for a proper codification strategy, namely the order in which the user interacted with the items. In this paper, several encoding strategies based on neural networks are analyzed and applied to solve two different recommendation tasks in the context of music playlists. The results show that the order in which the musical pieces were listened to is relevant for the codification of items (songs). We also find that the encoding of user profiles should use a different amount of historical data depending on the learning task to be solved. In other words, we do not always have to use all the available data; sometimes, it is better to discard old information, as tastes change over time.																	2192-6352	2192-6360				MAR	2020	9	1					67	75		10.1007/s13748-019-00199-7													
J								A survey and benchmarking study of multitreatment uplift modeling	DATA MINING AND KNOWLEDGE DISCOVERY										Uplift modeling; Business analytics; Prescriptive analytics; Causality; Matching; Literature survey	MULTIPLE TREATMENTS; PROPENSITY SCORE; CAUSAL	Uplift modeling is an instrument used to estimate the change in outcome due to a treatment at the individual entity level. Uplift models assist decision-makers in optimally allocating scarce resources. This allows the selection of the subset of entities for which the effect of a treatment will be largest and, as such, the maximization of the overall returns. The literature on uplift modeling mostly focuses on queries concerning the effect of a single treatment and rarely considers situations where more than one treatment alternative is utilized. This article surveys the current literature on multitreatment uplift modeling and proposes two novel techniques: the naive uplift approach and the multitreatment modified outcome approach. Moreover, a benchmarking experiment is performed to contrast the performances of different multitreatment uplift modeling techniques across eight data sets from various domains. We verify and, if needed, correct the imbalance among the pretreatment characteristics of the treatment groups by means of optimal propensity score matching, which ensures a correct interpretation of the estimated uplift. Conventional and recently proposed evaluation metrics are adapted to the multitreatment scenario to assess performance. None of the evaluated techniques consistently outperforms other techniques. Hence, it is concluded that performance largely depends on the context and problem characteristics. The newly proposed techniques are found to offer similar performances compared to state-of-the-art approaches.																	1384-5810	1573-756X				MAR	2020	34	2					273	308		10.1007/s10618-019-00670-y													
J								Identifying exceptional (dis)agreement between groups	DATA MINING AND KNOWLEDGE DISCOVERY										Supervised pattern mining; Subgroup discovery; Exceptional model mining; Behavioral data analysis	SUBGROUP DISCOVERY; PATTERN; ALGORITHM; FREQUENT; SET	Under the term behavioral data, we consider any type of data featuring individuals performing observable actions on entities. For instance, voting data depict parliamentarians who express their votes w.r.t. legislative procedures. In this work, we address the problem of discovering exceptional (dis)agreement patterns in such data, i.e., groups of individuals that exhibit an unexpected (dis)agreement under specific contexts compared to what is observed in overall terms. To tackle this problem, we design a generic approach, rooted in the Subgroup Discovery/Exceptional Model Mining framework, which enables the discovery of such patterns in two different ways. A branch-and-bound algorithm ensures an efficient exhaustive search of the underlying search space by leveraging closure operators and optimistic estimates on the interestingness measures. A second algorithm abandons the completeness by using a sampling paradigm which provides an alternative when an exhaustive search approach becomes unfeasible. To illustrate the usefulness of discovering exceptional (dis)agreement patterns, we report a comprehensive experimental study on four real-world datasets relevant to three different application domains: political analysis, rating data analysis and healthcare surveillance.																	1384-5810	1573-756X				MAR	2020	34	2					394	442		10.1007/s10618-019-00665-9													
J								NegPSpan: efficient extraction of negative sequential patterns with embedding constraints	DATA MINING AND KNOWLEDGE DISCOVERY										Sequential patterns mining; Pattern semantics; Absence modeling; Negative containment	ALGORITHM; GROWTH	Sequential pattern mining is concerned with the extraction of frequent or recurrent behaviors, modeled as subsequences, from a sequence dataset. Such patterns inform about which events are frequently observed in sequences, i.e. events that really happen. Sometimes, knowing that some specific event does not happen is more informative than extracting observed events. Negative sequential patterns (NSPs) capture recurrent behaviors by patterns having the form of sequences mentioning both observed events and absence of events. Few approaches have been proposed to mine such NSPs. In addition, the syntax and semantics of NSPs differ in the different methods which makes it difficult to compare them. This article provides a unified framework for the formulation of the syntax and the semantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts NSPs using a prefix-based depth-first scheme, enabling maxgap constraints that other approaches do not take into account. The formal framework highlights the differences between the proposed approach and methods from the literature, especially against the state of the art approach eNSP. Intensive experiments on synthetic and real datasets show that NegPSpan can extract meaningful NSPs and that it can process bigger datasets than eNSP thanks to significantly lower memory requirements and better computation times.																	1384-5810	1573-756X				MAR	2020	34	2					563	609		10.1007/s10618-019-00672-w													
J								Heart disease detection using hybrid of bacterial foraging and particle swarm optimization	EVOLVING SYSTEMS										Electrocardiography (ECG); Bacterial foraging optimization (BFO); Particle swarm optimization (PSO); Support vector machine (SVM)	CORONARY-ARTERY DISEASE; ANT COLONY OPTIMIZATION; NEURAL-NETWORK; GA-ACO; ALGORITHM; PSO	Bacterial-foraging-optimization (BFO) has newly raised and one of the most useful nature inspired optimization algorithm for real parametric optimization. During the process of random walk, the BFO algorithm makes search in the random direction, which increases delay. To overcome the delay in reaching the global optimum and also to boost up the performance of BFO, we proposed an algorithm by mixing the features of BFO and particle swarm optimization (PSO) for detecting the abnormal cardiac beat. Computer simulations illustrate the usefulness of the developed approach compared to the basic versions of BFO and PSO. The main aim of the research is to develop new modifications of BFO and its combination with transform technique such as Wavelet Transform and machine learning method, support vector machines (SVMs) to test their performances in the detection of cardiac arrhythmia. Modification of BFO focuses for improving its convergence in terms of speed and accuracy. Provided results in this paper show that, for the detection of MI and BBB classes, the BFPSO algorithm with SVM gives 98.9% and 99.3% accuracy on MIT-BIH database by including NSR database also. Moreover, the results demonstrate the effectiveness of the proposed method to improve the detection of cardiac arrhythmia.																	1868-6478	1868-6486				MAR	2020	11	1					15	28		10.1007/s12530-019-09312-6													
J								An aggregation approach to multi-criteria recommender system using genetic programming	EVOLVING SYSTEMS										Collaborative filtering; Genetic programming; Multi-criteria ratings; Recommender system		Recommender system is one of the emerging personalization tools in e-commerce domains for suggesting suitable items to users. Traditional collaborative filtering (CF) based recommender systems (RSs) suggest items to users based on the overall ratings to find out similar users. Multi-criteria ratings are used to capture user preferences efficiently in multi-criteria recommender systems (MCRSs), and incorporation of criteria ratings can lead to higher performance in MCRS. However, aggregation of these criteria ratings is a major concern in MCRS. In this paper, we propose a multi-criteria collaborative filtering-based RS by leveraging information derived from multi-criteria ratings through Genetic programming (GP). The proposed system consists of two parts: (1) weights of each user for every criterion are computed through our proposed modified sub-tree crossover in GP process (2) criteria weights are then incorporated in CF process to generate effective recommendations in our proposed system. The obtained results present significant improvements in prediction and recommendation qualities in comparison to heuristic approaches.																	1868-6478	1868-6486				MAR	2020	11	1					29	44		10.1007/s12530-019-09296-3													
J								MFOFLANN: moth flame optimized functional link artificial neural network for prediction of earthquake magnitude	EVOLVING SYSTEMS										Neural network; Moth-flame Optimization; FLANN; Gradient descent; Least squares; Regression	ALGORITHM	It is true that the world today suffers greatly from the modernization by humans however the natural disasters in no way do less harm. In the wake of this threat, there is a need of prediction of earthquake magnitude beforehand so as to determine the severity of the disaster and create an early warning system to avoid any casualty as far as possible. To curb the menace of earthquakes, there have been significant improvements in earthquake engineering regarding the study of different seismological parameters that influence earthquakes and generate useful features from them that can be used for earthquake forecasting. In this regard, there are various organizations such as the united states geological survey, the international seismological centre that collect records about details of all the earthquakes, small shockwaves occurring across major continental regions of the world, aid various research works related to earthquake modeling. This article is aimed towards a methodology of combining a neural network model known as functional link artificial neural network with both standard machine learning algorithms and certain nature-inspired optimization algorithms so as to achieve the task of predicting earthquake magnitudes.																	1868-6478	1868-6486				MAR	2020	11	1					45	63		10.1007/s12530-019-09293-6													
J								A hybridization of grey wolf optimizer and differential evolution for solving nonlinear systems	EVOLVING SYSTEMS										Hybridization algorithm; Metaheuristics; Nonlinear system of equations; Differential evolution; Grey wolf optimizer	PARTICLE SWARM OPTIMIZATION; POWER DISPATCH; ALGORITHM; EQUATIONS; SCHEME	This paper proposes a new algorithm for solving systems of complex nonlinear equations as an optimization problem. A hybridization algorithm from two inspired algorithms, grey wolf optimizer (GWO) and differential evolution (DE) is named GWO-DE. A new improving encircling prey and new crossover technique is used for updating the new agents of GWO-DE based on the generated agents of DE and GWO. Since GWO-DE has the advantages over GWO and DE, it subdues the inability of GWO and DE for solving unconstrained optimization problems and systems of nonlinear equations. Numerical experiments of 13 unconstrained optimization problems in 100 dimension and seven benchmark systems of nonlinear equations are employed to test the performance of GWO-DE. The non-parametric Wilcoxon statistical test and Friedman test are conducted for this study. Empirical results show that GWO-DE is able to circumvent other algorithms in the literature by getting the optimum solutions for most of systems of nonlinear equations and optimization problems and demonstrates its efficiency in comparison with other existing algorithms.																	1868-6478	1868-6486				MAR	2020	11	1					65	87		10.1007/s12530-019-09291-8													
J								Clustering subspace generalization to obtain faster reinforcement learning	EVOLVING SYSTEMS										Model-based reinforcement learning; Experience generalization; Clustering space		In reinforcement learning, very low and even lack of spatial generalization capability result in slow learning. Exploiting possible experience generalization in subspaces, a sub-dimension of the original state representation, is one approach to speed up learning in terms of required interactions. The target of this paper is to alleviate the detriment of the perceptual aliasing in the subspaces further to enhance the benefit of their generalization. We augment an extra dimension to the subspaces coming from a clustering process on the state-space. Through this framework, called Clustered-Model Based Learning with Subspaces (C-MoBLeS), states with similar policies are categorized to the same cluster and the agent can exploit the generalization of the subspace learning more by this localization. Therefore, the agent uses generalization of the subspaces which are in the cluster of the agent's state. Several experiments show that C-MoBLeS increases the learning speed effectively.																	1868-6478	1868-6486				MAR	2020	11	1					89	103		10.1007/s12530-019-09290-9													
J								Artificial bee colony optimization (ABC) for grape leaves disease detection	EVOLVING SYSTEMS										Feature selection; Artificial bee colony; Grape leaf; Disease detection	FEATURE-SELECTION; CLASSIFICATION; PSO	Plants are one of the important sources of food to the mankind. Plant diseases affect the economy of the country and also reduce the quality of agricultural product. Throughout the world, grapes are treated as a major fruit source, which contains nutrients like vitamin C. Diseases in the grape plants seriously affect the quality and production of grapes. Computer vision-based techniques have been used successfully in the last decades, to detect and classify the plants diseases. This paper deals with the identification and classification of diseases in grape leaves by using artificial bee colony (ABC) based feature selection. Initially the input images are applied with pre-processing steps which eliminate noises and background of the images. The features of color, texture and shape are extracted. ABC based attribute selection is used to find the optimal feature set. The selected features are given to the support vector machine classifier for foliar disease detection of grapes. The proposed method is experimented and compared with the other feature selection algorithms. The comparison results depict, the efficacy of the proposed method through the performance metrics such as recall, precision and classification accuracy.																	1868-6478	1868-6486				MAR	2020	11	1					105	117		10.1007/s12530-019-09289-2													
J								A novel under sampling strategy for efficient software defect analysis of skewed distributed data	EVOLVING SYSTEMS										Software defects analysis; Classification; Decision tree; Class imbalance learning; Under sampling		The software quality development process is a continuous process which starts by identifying a reliable fault detection technique. The implementation of the effective fault detection technique depends on the properties of the dataset in terms of domain information, characteristics of input data, complexity, etc. The early detection of defective modules provide more time for the developers to allocate resources effectively to deliver the quality software in time. The class imbalance nature of the software defect datasets indicates that the existing techniques are unsuccessful for identifying all the defective modules. Misclassification of the defective modules in the software engineering datasets invites unexpected loses to the software developers. To classify the class imbalance software datasets in an efficient way, we have proposed a novel approach called as under sampling strategy. This proposed approach uses under sampling strategy to reduce the less prominent instances from majority subset. The experimental results confirm that the proposed approach can deliver more accuracy in predicting the modules which are error prone with less and simple rules.																	1868-6478	1868-6486				MAR	2020	11	1					119	131		10.1007/s12530-018-9261-9													
J								Integrating multiple methods to enhance medical data classification	EVOLVING SYSTEMS										Classifier; Fuzzy-neural network; Bag of words; Medical data classification		In medical data classification, data reduction and improving classification performance are the important issues in the current scenario. In existing medical data classification methods, initially, the medical data pre-processing is performed. After pre-processing feature selection is performed, otherwise, the process is more time consuming and has poor accuracy. Here we have proposed two algorithms for enhancing the classification performance on medical data. In first proposed method Bag of Words technique is used for better feature subset selection. Subsequently, the hybrid Fuzzy-Neural Network approach used that can handle imprecision in data while classification. This combination of feature selection technique and Fuzzy-Neural Network classifier approach gives enhanced classification accuracy. In the second proposed algorithm, we have integrated data cleaning technique to improve data quality as pre-processing technique along with bag of words and Fuzzy-Neural Network, this method performs classification on clean filtered data with appropriately reduced feature set that results in more accurate classification than the existing methods. Thus in proposed approaches we have tried to handle three issues, removing noise in data, optimal feature subset selection and handling imprecision in data. The comparative study of various medical datasets in terms of accuracy shows that the two proposed algorithms perform better as compared to existing techniques and the enhancement obtained is around 3% and 17% respectively. In addition the performance of Bag of Words feature selection method used in the proposed system is compared with two feature selection methods LSFS and SFFS.																	1868-6478	1868-6486				MAR	2020	11	1					133	142		10.1007/s12530-019-09272-x													
J								Characteristic of Mayer Waves in Electrophysiological, Hemodynamic and Vascular Signals	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Mayer waves; neurovascular coupling; oxygenated and reduced hemoglobin; adaptive approximations; matching pursuit	BLOOD-PRESSURE FLUCTUATIONS; HEART-RATE-VARIABILITY; LOW-FREQUENCY; 0.1 HZ; SPECTRAL-ANALYSIS; RESTING SUBJECTS; OSCILLATIONS; BAROREFLEX; RATS	We evaluated the properties of oscillations in the Mayer waves (MW) frequency range (similar to 0.1Hz) detected in blood pressure, heart rate variability, cerebral blood oxygenation changes and evolution of electroencephalographic (EEG) rhythms to elucidate the mechanisms of MW generation. We examined the persistence of MW in different signals and stability of their oscillations on the level of individual MW waveforms, which was achieved by applying matching pursuit (MP). MP yields adaptive time-frequency approximation of signal's structures in terms of frequency, amplitude, time occurrence, and time-span. The number of waveforms contributing to 95% of the energy of the signals was vastly different for the time series, but the average number of waveforms conforming to the MW criteria was almost the same (3.5 +/- 0.4 per 120 s epoch). In all the investigated signals, MW had the same distributions of frequency and the number of cycles. We show that the MW energy ratios in different signals varied strongly, p < 0.001. The highest percentage of MW energy was observed in blood pressure signals, heart rate variability, and reduced hemoglobin, in contrast to brain signals and oxygenated hemoglobin. The percentage of MW energy was related to the strength of causal influence exerted by them on the other signals. Our results indicate existence of a common mechanism of MW generation and support the hypothesis of MW generation in the baroreflex loop; however, they do not exclude the action of a central pacemaker.																	0129-0657	1793-6462				MAR	2020	30	3							2050003	10.1142/S0129065720500033													
J								Reorganization of Large-Scale Functional Networks During Low-Frequency Electrical Stimulation of the Cortical Surface	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Cortico-cortical evoked potentials; seizure onset zone; epilepsy; dynamic functional connectivity; graph parameters	CORTICOCORTICAL EVOKED-POTENTIALS; GRAPH-THEORETICAL ANALYSIS; MINIMUM SPANNING TREE; EPILEPTIFORM DISCHARGES; NEOCORTICAL EPILEPSY; BRAIN NETWORKS; CONNECTIVITY; SINGLE; EEG; ONSET	We investigated the functional network reorganization caused by low-frequency electrical stimulation (LFES) of human brain cortical surface. Intracranial EEG data from subdural grid positions were analyzed in 16 pre-surgery epileptic patients. LFES was performed by injecting current pulses (10 mA, 0.2 ms pulse width, 0.5Hz, 25 trials) into all adjacent electrode contacts. Dynamic functional connectivity analysis was carried out on two frequency bands (low: 1-4Hz; high: 10-40 Hz) to investigate the early, high frequency and late, low frequency responses elicited by the stimulation. The centralization increased in early compared to late responses, suggesting a more prominent role of direct neural links between primarily activated areas and distant brain regions. Injecting the current into the seizure onset zone (SOZ) evoked a more integrated functional topology during the early (N1) period of the response, whereas during the late (N2) period - regardless of the stimulation site - the connectedness of the SOZ was elevated compared to the non-SOZ tissue. The abnormal behavior of the epileptic sub-network during both part of the responses supports the idea of the pathogenic role of impaired inhibition and excitation mechanisms in epilepsy.																	0129-0657	1793-6462				MAR	2020	30	3							1950022	10.1142/S0129065719500229													
J								Olfactory EEG Signal Classification Using a Trapezoid Difference-Based Electrode Sequence Hashing Approach	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Olfactory EEG; classification; right-angled trapezoid differences; trapezoid difference-based electrode sequence hashing approach; feature optimization	BRAIN-COMPUTER INTERFACE; WAVELET METHODOLOGY; PARKINSONS-DISEASE; CONNECTIVITY; DIAGNOSIS; NETWORKS; IMAGERY; SYSTEM; SYNCHRONIZATION; RECOGNITION	Olfactory-induced electroencephalogram (EEG) signal classification is of great significance in a variety of fields, such as disorder treatment, neuroscience research, multimedia applications and brain-computer interface. In this paper, a trapezoid difference-based electrode sequence hashing method is proposed for olfactory EEG signal classification. First, an N-layer trapezoid feature set whose size ratio of the top, bottom and height is 1:2:1 is constructed for each frequency band of each EEG sample. This construction is based on N optimized power-spectral-density features extracted from N real electrodes and N nonreal electrode's features. Subsequently, the N real electrodes' sequence (ES) codes of each layer of the constructed trapezoid feature set are obtained by arranging the feature values in ascending order. Finally, the nearest neighbor classification is used to find a class whose ES codes are the most similar to those of the testing sample. Thirteen-class olfactory EEG signals collected from 11 subjects are used to compare the classification performance of the proposed method with six traditional classification methods. The comparison shows that the proposed method gives average accuracy of 94.3%, Cohen's kappa value of 0.94, precision of 95.0%, and F1-measure of 94.6%, which are higher than those of the existing methods.																	0129-0657	1793-6462				MAR	2020	30	3							2050011	10.1142/S0129065720500112													
J								A TrAdaBoost Method for Detecting Multiple Subjects' N200 and P300 Potentials Based on Cross-Validation and an Adaptive Threshold	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										N200; P300; TrAdaBoost; adaptive threshold; cross-validation; brain-computer interface	BRAIN-COMPUTER INTERFACE; COMMON SPATIAL-PATTERNS; SUPPORT VECTOR MACHINE; LEARNING ALGORITHM; NEURAL-NETWORK; CLASSIFICATION; ERP; EXTRACTION; DIAGNOSIS	Traditional training methods need to collect a large amount of data for every subject to train a subject-specific classifier, which causes subjects fatigue and training burden. This study proposes a novel training method, TrAdaBoost based on cross-validation and an adaptive threshold (CV-T-TAB), to reduce the amount of data required for training by selecting and combining multiple subjects' classifiers that perform well on a new subject to train a classifier. This method adopts cross-validation to extend the amount of the new subject's training data and sets an adaptive threshold to select the optimal combination of the classifiers. Twenty-five subjects participated in the N200- and P300-based brain-computer interface. The study compares CV-T-TAB to five traditional training methods by testing them on the training of a support vector machine. The accuracy, information transfer rate, area under the curve, recall and precision are used to evaluate the performances under nine conditions with different amounts of data. CV-T-TAB outperforms the other methods and retains a high accuracy even when the amount of data is reduced to one-third of the original amount. The results imply that CV-T-TAB is effective in improving the performance of a subject-specific classifier with a small amount of data by adopting multiple subjects' classifiers, which reduces the training cost.																	0129-0657	1793-6462				MAR	2020	30	3							2050009	10.1142/S0129065720500094													
J								A Three-Dimensional Microelectrode Array to Generate Virtual Electrodes for Epiretinal Prosthesis Based on a Modeling Study	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Virtual electrode; microelectrode array; electrical stimulation; epiretinal prosthesis	ELECTRICAL-STIMULATION; COCHLEAR IMPLANT; GANGLION-CELLS; MORPHOMETRIC-ANALYSIS; RETINAL STIMULATION; NEURAL STIMULATION; ARTIFICIAL VISION; EXCITATION; PERCEPTS; PERFORMANCE	Despite many advances in the development of retinal prostheses, clinical reports show that current retinal prosthesis subjects can only perceive prosthetic vision with poor visual acuity. A possible approach for improving visual acuity is to produce virtual electrodes (VEs) through electric field modulation. Generating controllable and localized VEs is a crucial factor in effectively improving the perceptive resolution of the retinal prostheses. In this paper, we aimed to design a microelectrode array (MEA) that can produce converged and controllable VEs by current steering stimulation strategies. Through computational modeling, we designed a three-dimensional concentric ring-disc MEA and evaluated its performance with different stimulation strategies. Our simulation results showed that electrode-retina distance (ERD) and inter-electrode distance (IED) can dramatically affect the distribution of electric field. Also the converged VEs could be produced when the parameters of the three-dimensional MEA were appropriately set. VE sites can be controlled by manipulating the proportion of current on each adjacent electrode in a current steering group (CSG). In addition, spatial localization of electrical stimulation can be greatly improved under quasi-monopolar (QMP) stimulation. This study may provide support for future application of VEs in epiretinal prosthesis for potentially increasing the visual acuity of prosthetic vision.																	0129-0657	1793-6462				MAR	2020	30	3							2050006	10.1142/S0129065720500069													
J								Distinct Patterns of Functional Connectivity During the Comprehension of Natural, Narrative Speech	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Reorganization; functional connectivity; naturalistic speech; speech comprehension; natural paradigms	BRAIN CONNECTIVITY; COMPONENT ANALYSIS; NETWORKS; SEIZURE; GRAPH; MEG; ORGANIZATION; COMPLEXITY; DYNAMICS; CORTEX	Recent continuous task studies, such as narrative speech comprehension, show that fluctuations in brain functional connectivity (FC) are altered and enhanced compared to the resting state. Here, we characterized the fluctuations in FC during comprehension of speech and time-reversed speech conditions. The correlations of Hilbert envelope of source-level EEG data were used to quantify FC between spatially separate brain regions. A symmetric multivariate leakage correction was applied to address the signal leakage issue before calculating FC. The dynamic FC was estimated based on a sliding time window. Then, principal component analysis (PCA) was performed on individually concatenated and temporally concatenated FC matrices to identify FC patterns. We observed that the mode of FC induced by speech comprehension can be characterized with a single principal component. The condition-specific FC demonstrated decreased correlations between frontal and parietal brain regions and increased correlations between frontal and temporal brain regions. The fluctuations of the condition-specific FC characterized by a shorter time demonstrated that dynamic FC also exhibited condition specificity over time. The FC is dynamically reorganized and FC dynamic pattern varies along a single mode of variation during speech comprehension. The proposed analysis framework seems valuable for studying the reorganization of brain networks during continuous task experiments.																	0129-0657	1793-6462				MAR	2020	30	3							2050007	10.1142/S0129065720500070													
J								Joint consensus and diversity for multi-view semi-supervised classification	MACHINE LEARNING										Consensus; Diversity; Multi-view; Semi-supervised classification	IMAGE FEATURES; PROPAGATION	As data can be acquired in an ever-increasing number of ways, multi-view data is becoming more and more available. Considering the high price of labeling data in many machine learning applications, we focus on multi-view semi-supervised classification problem. To address this problem, in this paper, we propose a method called joint consensus and diversity for multi-view semi-supervised classification, which learns a common label matrix for all training samples and view-specific classifiers simultaneously. A novel classification loss named probabilistic square hinge loss is proposed, which avoids the incorrect penalization problem and characterizes the contribution of training samples according to its uncertainty. Power mean is introduced to incorporate the losses of different views, which contains the auto-weighted strategy as a special case and distinguishes the importance of various views. To solve the non-convex minimization problem, we prove that its solution can be obtained from another problem with introduced variables. And an efficient algorithm with proved convergence is developed for optimization. Extensive experimental results on nine datasets demonstrate the effectiveness of the proposed algorithm.																	0885-6125	1573-0565				MAR	2020	109	3			SI		445	465		10.1007/s10994-019-05844-9													
J								Skill-based curiosity for intrinsically motivated reinforcement learning	MACHINE LEARNING										Reinforcement learning; Exploration; Autonomous exploration; Curiosity in reinforcement learning		Reinforcement learning methods rely on rewards provided by the environment that are extrinsic to the agent. However, many real-world scenarios involve sparse or delayed rewards. In such cases, the agent can develop its own intrinsic reward function called curiosity to enable the agent to explore its environment in the quest of new skills. We propose a novel end-to-end curiosity mechanism for deep reinforcement learning methods, that allows an agent to gradually acquire new skills. Our method scales to high-dimensional problems, avoids the need of directly predicting the future, and, can perform in sequential decision scenarios. We formulate the curiosity as the ability of the agent to predict its own knowledge about the task. We base the prediction on the idea of skill learning to incentivize the discovery of new skills, and guide exploration towards promising solutions. To further improve data efficiency and generalization of the agent, we propose to learn a latent representation of the skills. We present a variety of sparse reward tasks in MiniGrid, MuJoCo, and Atari games. We compare the performance of an augmented agent that uses our curiosity reward to state-of-the-art learners. Experimental evaluation exhibits higher performance compared to reinforcement learning models that only learn by maximizing extrinsic rewards.																	0885-6125	1573-0565				MAR	2020	109	3			SI		493	512		10.1007/s10994-019-05845-8													
J								Handling concept drift via model reuse	MACHINE LEARNING										Concept drift; Model reuse; Non-stationary environments		In many real-world applications, data are often collected in the form of a stream, and thus the distribution usually changes in nature, which is referred to as concept drift in the literature. We propose a novel and effective approach to handle concept drift via model reuse, that is, reusing models trained on previous data to tackle the changes. Each model is associated with a weight representing its reusability towards current data, and the weight is adaptively adjusted according to the performance of the model. We provide both generalization and regret analysis to justify the superiority of our approach. Experimental results also validate its efficacy on both synthetic and real-world datasets.																	0885-6125	1573-0565				MAR	2020	109	3			SI		533	568		10.1007/s10994-019-05835-w													
J								Communication-efficient distributed multi-task learning with matrix sparsity regularization	MACHINE LEARNING										Distributed learning; Multi-task learning; Acceleration	SELECTION	This work focuses on distributed optimization for multi-task learning with matrix sparsity regularization. We propose a fast communication-efficient distributed optimization method for solving the problem. With the proposed method, training data of different tasks can be geo-distributed over different local machines, and the tasks can be learned jointly through the matrix sparsity regularization without a need to centralize the data. We theoretically prove that our proposed method enjoys a fast convergence rate for different types of loss functions in the distributed environment. To further reduce the communication cost during the distributed optimization procedure, we propose a data screening approach to safely filter inactive features or variables. Finally, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the effectiveness of our proposed method.																	0885-6125	1573-0565				MAR	2020	109	3			SI		569	601		10.1007/s10994-019-05847-6													
J								Multi-label optimal margin distribution machine	MACHINE LEARNING										Optimal margin distribution machine; Multi-label learning; Support vector machine; Margin theory	SUPPORT VECTOR MACHINE	Multi-label support vector machine (Rank-SVM) is a classic and effective algorithm for multi-label classification. The pivotal idea is to maximize the minimum margin of label pairs, which is extended from SVM. However, recent studies disclosed that maximizing the minimum margin does not necessarily lead to better generalization performance, and instead, it is more crucial to optimize the margin distribution. Inspired by this idea, in this paper, we first introduce margin distribution to multi-label learning and propose multi-label Optimal margin Distribution Machine (mlODM), which optimizes the margin mean and variance of all label pairs efficiently. Extensive experiments in multiple multi-label evaluation metrics illustrate that mlODM outperforms SVM-style multi-label methods. Moreover, empirical study presents the best margin distribution and verifies the fast convergence of our method.																	0885-6125	1573-0565				MAR	2020	109	3			SI		623	642		10.1007/s10994-019-05837-8													
J								Few-shot learning with adaptively initialized task optimizer: a practical meta-learning approach	MACHINE LEARNING										Few-shot learning; Meta-learning; Supervised-learning; Multi-task learning; Task-specific		Considering the data collection and labeling cost in real-world applications, training a model with limited examples is an essential problem in machine learning, visual recognition, etc. Directly training a model on such few-shot learning (FSL) tasks falls into the over-fitting dilemma, which would turn to an effective task-level inductive bias as a key supervision. By treating the few-shot task as an entirety, extracting task-level pattern, and learning a task-agnostic model initialization, the model-agnostic meta-learning (MAML) framework enables the applications of various models on the FSL tasks. Given a training set with a few examples, MAML optimizes a model via fixed gradient descent steps from an initial point chosen beforehand. Although this general framework possesses empirically satisfactory results, its initialization neglects the task-specific characteristics and aggravates the computational burden as well. In this manuscript, we propose our AdaptiVely InitiAlized Task OptimizeR (Aviator) approach for few-shot learning, which incorporates task context into the determination of the model initialization. This task-specific initialization facilitates the model optimization process so that it obtains high-quality model solutions efficiently. To this end, we decouple the model and apply a set transformation over the training set to determine the initial top-layer classifier. Re-parameterization of the first-order gradient descent approximation promotes the gradient back-propagation. Experiments on synthetic and benchmark data sets validate that our Aviator approach achieves the state-of-the-art performance, and visualization results demonstrate the task-adaptive features of our proposed Aviator method.																	0885-6125	1573-0565				MAR	2020	109	3			SI		643	664		10.1007/s10994-019-05838-7													
J								Parameter estimation in uncertain differential equations	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertain differential equation; Method of moments; Uncertainty theory; Parameter estimation	MODEL	Parameter estimation is a critical problem in the wide applications of uncertain differential equations. The method of moments is employed for the first time as an approach for estimating the parameters in uncertain differential equations. Based on the difference form of an uncertain differential equation, a function of the parameters is proved to follow a standard normal uncertainty distribution. Setting the empirical moments of the functions of the parameters and the observed data equal to the moments of the standard normal uncertainty distribution, a system of equations about the parameters is obtained whose solutions are the estimates of the parameters. Analytic examples and numerical examples are given to illustrate the proposed method of moments.																	1568-4539	1573-2908				MAR	2020	19	1					1	12		10.1007/s10700-019-09310-y													
J								Using local learning with fuzzy transform: application to short term forecasting problems	FUZZY OPTIMIZATION AND DECISION MAKING										Fuzzy sets; Forecasting; Lazy learning; Local regression	NEURAL-NETWORK; LOAD; PREDICTION; REGRESSION	In this paper, we formally discuss a computational scheme, which combines a local weighted regression model with fuzzy transform (or F-transform for short). The latter acts as a reduction technique on the cardinality of the learning problem, resulting in a more efficient algorithm. We tested the proposed approach first through two typical benchmark problems, that is the Henon and the Mackey-Glass chaotic time series, then we applied it to short-term forecasting problems. Short-term forecasting is important in the energy field for the management of power systems and for energy trading. Hence, we considered two typical application examples in this field, that is wind power forecasting and load forecasting. Numerical results show the effectiveness of the proposed approach through a comparison against alternative techniques.																	1568-4539	1573-2908				MAR	2020	19	1					13	32		10.1007/s10700-019-09311-x													
J								Least absolute deviations estimation for uncertain regression with imprecise observations	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertain regression; Least absolute deviations; Uncertainty theory; Imprecise observation	ALGORITHM	Traditionally regression analysis answers questions about the relationships among variables based on the assumption that the observation values of variables are precise numbers. It has long been dominated by least squares, mostly due to the elegant theoretical foundation and ease of implementation. However, in many cases, we can only get imprecise observation values and the assumptions upon which the least squares is based may not be valid. So this paper characterizes the imprecise data in terms of uncertain variables and proposes a novel robust approach under the principle of least absolute deviations to estimate the unknown parameters in uncertain regression models. Furthermore, some general estimate approaches are also explored. Finally, numerical examples illustrate that our estimate is more robust than the least squares implying it is more suitable to handle observations with outliers.																	1568-4539	1573-2908				MAR	2020	19	1					33	52		10.1007/s10700-019-09312-w													
J								On product of positive L-R fuzzy numbers and its application to multi-period portfolio selection problems	FUZZY OPTIMIZATION AND DECISION MAKING										Fuzzy sets; Fuzzy arithmetic; Positive L-R fuzzy number; Multi-period portfolio selection	INTERVAL APPROXIMATION; OPTIMIZATION	With the wide applications of fuzzy theory in optimization, fuzzy arithmetic attracts great attention due to its inevitability in solution process. However, the complexity of the Zadeh extension principle significantly reduces the practicability of fuzzy optimization technology. In this paper, we prove some important properties on positive L-R fuzzy numbers, and propose a new calculation method for the product of multiple positive L-R fuzzy numbers. Furthermore, a numerical integral-based simulation algorithm (NISA) is proposed to approximate the expected value, variance and skewness of the product of positive L-R fuzzy numbers. As applications, a fuzzy multi-period utility maximization model for portfolio selection problem is considered. For handling the large number of multiplications on L-R fuzzy numbers during the optimization process, a genetic algorithm integrating NISA is designed. Finally, some numerical experiments are presented to demonstrate the advantages of NISA. The results greatly enrich the fuzzy arithmetic methods and promote the practicability of fuzzy optimization technology.																	1568-4539	1573-2908				MAR	2020	19	1					53	79		10.1007/s10700-019-09308-6													
J								Category of soft Lie algebra	SOFT COMPUTING										Lie algebra; Soft Lie algebra; Injective object	SETS	In this article, we consider category LA(F) of all Lie algebras over a field F and Lie algebra homomorphisms and obtain some basic results of this category, such as the existence of product, equalizer, coequalizer, and pullback. Then, we introduce a subcategory of the category of soft sets, whose objects are soft Lie algebras and morphisms are soft Lie algebra homomorphisms and study some properties. In particular, we show that this category does not have a product. Also, we characterize injective objects in category soft set and category of soft Lie algebras over F.																	1432-7643	1433-7479				MAR	2020	24	5					3067	3076		10.1007/s00500-019-04583-2													
J								L-algebras in logic, algebra, geometry, and topology	SOFT COMPUTING										Algebraic logic; L-algebra; l-group; p-adic numbers; Projective space; Measure; Integration; Heyting algebra		An intuitive introduction to L-algebras and their relationship to groups with a one- or two-sided lattice ordering is given, with applications in algebra, analysis, and geometry.																	1432-7643	1433-7479				MAR	2020	24	5					3077	3085		10.1007/s00500-019-04616-w													
J								General L-fuzzy aggregation functions based on complete residuated lattices	SOFT COMPUTING										General L-fuzzy aggregation functions; L-fuzzy relations; Complete residuated lattices; Upper and lower general L-fuzzy aggregation approximation functions	APPROXIMATION; LOGIC	As a vital tool in data analysis, aggregation functions have been widely studied in many papers. In particular, one of the recent research topics for aggregation functions is the study of the various extension forms of those useful functions. This paper continues to research this topic from the theoretical point of view. First, we introduce the notions of L-fuzzy aggregation functions and general L-fuzzy aggregation functions based on complete residuated lattices. Then we present the upper and lower general L-fuzzy aggregation approximation functions of the general L-fuzzy aggregation functions, which are the pointwise extension of an L-fuzzy aggregation function. Moreover, we consider some vital properties of those aggregation approximation functions and investigate the relationship between those aggregation approximation functions and the corresponding L-fuzzy relations. Finally, we show that the approach of axiomatizations of the upper and lower general L-fuzzy aggregation approximation functions ensures the existence of corresponding L-fuzzy relations which generate the functions.																	1432-7643	1433-7479				MAR	2020	24	5					3087	3112		10.1007/s00500-019-04642-8													
J								On interval-valued fuzzy soft set theory applied to semigroups	SOFT COMPUTING										Interval-valued fuzzy soft set; Interval-valued fuzzy soft semigroup; Interval-valued fuzzy soft quasi-ideal; Interval-valued fuzzy soft interior ideal; Interval-valued fuzzy soft bi-ideal	ORDERED SEMIGROUPS; TERMS; ALGORITHMS; IDEALS	In this paper, we focus on combining the theories of interval-valued fuzzy soft sets over semigroups, and establishing a new framework for interval-valued fuzzy soft semigroups. The aim of this manuscript is to apply interval-valued fuzzy soft set for dealing with several kinds of theories in semigroups. First, we present the concepts of interval-valued fuzzy soft sets, interval-valued fuzzy soft semigroups, interval-valued fuzzy soft ideals, interval-valued fuzzy soft quasi-ideals, interval-valued fuzzy soft interior ideals and interval-valued fuzzy soft bi-ideals. Meanwhile, some illustrative examples are given to show the rationality of the definitions introduced in this paper. Also, we prove that a non-empty subset of a semigroup S is a subsemigroup (left ideal, right ideal, ideal) of S if and only if the interval-valued fuzzy soft set over S is the interval-valued fuzzy soft subsemigroup (interval-valued fuzzy soft left ideal, interval-valued fuzzy soft right ideal, interval-valued fuzzy soft ideal) over S. Second, several new kinds of generalized fuzzy soft sets over semigroups are proposed, and related properties and mutual relationships are also investigated. Moreover, we study relation between quasi-ideals and interval-valued fuzzy soft quasi-ideals over semigroups. Finally, we obtain necessary and sufficient conditions of an interval-valued fuzzy soft ideal in order to be an interval-valued fuzzy soft interior ideal.																	1432-7643	1433-7479				MAR	2020	24	5					3113	3123		10.1007/s00500-019-04655-3													
J								An interactive nonparametric evidential regression algorithm with instance selection	SOFT COMPUTING										Nonparametric evidential regression; Belief functions; Instance selection	AGGREGATION OPERATORS; FUZZY; IMPRECISE; UNCERTAIN	The nonparametric evidential regression (EVREG) method provides flexible forms of prediction regarding the value of output, allowing the output of training instances to be partially unknown. However, the superfluous training instances still have negative effects on the parameter learning in EVREG. To relax this limitation, this paper introduces an interactive nonparametric evidential regression (IEVREG) algorithm with instance selection. More specifically, the significance of an instance is firstly measured by defining the evaluation functions, taking into account both the prediction accuracy of regression model and the spatial information between that instance with other ones. According to a search strategy, the instances with high degree of significance are then selected to maximize an objective function. Different from existing instance selection methods, the selection of training instances is synchronously accomplished with the parameter learning in IEVREG, rather than just a separated data preprocessing operation as traditional methods do. Furthermore, the noise and redundant instances can be simultaneously removed and the performance of IEVREG is robust to the order of presentation of instances in raw data set. Experimental results show that the proposed IEVREG algorithm has appropriate prediction accuracy, while performing well selection of the representative training instances from the raw data set. Simulations on synthetic and UCI real-world data sets validate our conclusions.																	1432-7643	1433-7479				MAR	2020	24	5					3125	3140		10.1007/s00500-020-04667-4													
J								Ant colony systems optimization applied to BNF grammars rule derivation (ACORD algorithm)	SOFT COMPUTING										Grammatical swarm; Ant colony optimization; Particle swarm optimization; Grammatical evolution	GENETIC ALGORITHM; PARTICLE SWARM; HEURISTICS; TSP	Ant colony systems have been widely employed in optimization issues primarily focused on path finding optimization, such as travelling salesman problem. The main advantage lies in the choice of the edge to be explored, defined using pheromone trails. This paper proposes the use of ant colony systems to explore a Backus-Naur form grammar whose elements are solutions to a given problem. Similar models, without using ant colonies, have been used to solve optimization problems or to automatically generate programs such as grammatical swarm (based on particle swarm optimization) and grammatical evolution (based on genetic algorithms). This work presents the application of proposed ant colony rule derivation algorithm and benchmarks this novel approach in a well-known deceptive problem, the Santa Fe Trail. Proposed algorithm opens the way to a new branch of research in swarm intelligence, which until now has been almost nonexistent, using ant colony algorithms to generate solutions of a given problem described by a BNF grammar with the advantage of genotype/phenotype mapping, described in grammatical evolution. In this case, such mapping is performed based on the pheromone concentration for each production rule. The experimental results demonstrate proposed algorithm outperforms grammatical evolution algorithm in the Santa Fe Trail problem with higher success rates and better solutions in terms of the required steps.																	1432-7643	1433-7479				MAR	2020	24	5					3141	3154		10.1007/s00500-020-04670-9													
J								Generalized trapezoidal cubic linguistic fuzzy ordered weighted average operator and group decision-making	SOFT COMPUTING										Trapezoidal cubic linguistic fuzzy numbers; Aggregation trapezoidal cubic linguistic fuzzy information; Cubic linguistic fuzzy decision-making problems	AGGREGATION OPERATORS; NUMBERS	In this paper, we define aggregation operators for trapezoidal cubic linguistic fuzzy sets which includes generalized cubic linguistic fuzzy averaging (geometric) operator, generalized trapezoidal cubic linguistic fuzzy weighted averaging (GTrCLFWA) operator, generalized trapezoidal cubic linguistic fuzzy weighted geometric (GTrCFWG) operator, generalized trapezoidal cubic linguistic fuzzy ordered weighted average (GTrCLFOWA) operator, generalized trapezoidal cubic linguistic fuzzy ordered weighted geometric (GTrCLFOWG) operator, generalized trapezoidal cubic linguistic fuzzy hybrid averaging (GTrCLFHA) operator and generalized trapezoidal cubic linguistic fuzzy hybrid geometric (GTrCLFHG) operator. Furthermore, we relate these aggregation operators to develop an approach to multiple attribute group decision-making with trapezoidal cubic linguistic fuzzy information. Finally, a numerical example is providing to demonstrate the submission of the established approach.																	1432-7643	1433-7479				MAR	2020	24	5					3155	3171		10.1007/s00500-020-04672-7													
J								Filter topologies on MV-algebras II	SOFT COMPUTING										MV-algebra; Filter topology; Order topology		We show in this paper that the filter topology on an MV-chain is precisely the order topology when the filter is non-principal and has an infimum in the MV-chain. Then, we show that for an arbitrary MV-algebra A which is complete, the canonical monomorphism h of A into its subdirect product must be a continuous mapping. As a result, we give a sufficient condition for a complete MV-algebra equipped with the filter topology to be Hausdorff.																	1432-7643	1433-7479				MAR	2020	24	5					3173	3177		10.1007/s00500-020-04682-5													
J								Topological residuated lattices	SOFT COMPUTING										Residuated lattice; Topological residuated lattice; Filter; Separation axioms; Completion; Linear topology		The notion of a (semi)topological residuated lattice is introduced, and its properties are investigated. Some separation axioms on topological residuated lattices are studied. The notion of completion of a residuated lattice is introduced and characterized by means of the inverse limit of an inverse system. A residuated lattice with a given system of filters is illustrated with the linear topology, and it is shown that a compact and Hausdorff residuated lattice with the linear topology is complete.																	1432-7643	1433-7479				MAR	2020	24	5					3179	3192		10.1007/s00500-020-04709-x													
J								Dual-information-based evolution and dual-selection strategy in evolutionary multiobjective optimization	SOFT COMPUTING										Dual information (DI); Dual-selection strategy (DS); Diversity; Adaptive limited stable matching; Adaptive neighboring information; Many-objective optimization	MATCHING-BASED SELECTION; ALGORITHM; PERFORMANCE; DIVERSITY; MOEA/D	Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously in a collaborative manner in one run. The recently proposed stable matching (STM)-based selection is a variant of MOEA/D that achieves one-to-one STM between subproblems and solutions on the basis of mutual preferences. However, the STM has a high probability of matching a good convergence solution with a subproblem, which results in an imbalance between convergence and diversity of selection result. In this study, we propose a new variant of MOEA/D with dual-information and dual-selection (DS) strategy (MOEA/D-DIDS). Different from other evolutionary operations, we use an adaptive historical and neighboring information in generating new individuals to avoid local optima and accelerate convergence rate. In the selection operation, we use the adaptive limited STM (beta LSTM) strategy, where parameter beta is adaptive in accordance with the evolutionary process, as a guideline to select a population from the mixed population that survives as the next parent population. In addition to beta LSTM, we use an STM to select competitive individuals as the members of the next mixed population. This DS strategy not only balances convergence and diversity but also holds the elite solutions. The effectiveness and competitiveness of MOEA/D-DIDS are validated and compared with several state-of-the-art evolutionary multiobjective optimization algorithms on benchmark problems.																	1432-7643	1433-7479				MAR	2020	24	5					3193	3221		10.1007/s00500-019-04081-5													
J								A robust fuzzy control approach for path-following control of autonomous vehicles	SOFT COMPUTING										Fuzzy system; Non-stationary fuzzy sets; Compensator; Robustness; Autonomous vehicles	STEERING CONTROL; ALGORITHM; TRACKING; OPTIMIZATION	This paper presents a robust fuzzy control approach for the lateral path-following of autonomous road vehicles (ARVs). The dynamics of the ARV is estimated online thorough a new non-singleton fuzzy system based on the non-stationary fuzzy sets. The asymptotic stability of the proposed method is ensured, and the adaptation laws for the proposed fuzzy system are derived based on the Lyapunov stability theorem. The robustness of the proposed control method is verified for a vehicle system performing a double-lane-change maneuver at different forward speeds subjected to structured and unmodeled uncertainties and different disturbances. The effectiveness of the proposed approach is further investigated under different measurement noise levels. Based on the obtained results, it is concluded that the proposed control strategy can be effectively applied to the path-following task of ARVs under a wide range of operating conditions and external disturbances.																	1432-7643	1433-7479				MAR	2020	24	5					3223	3235		10.1007/s00500-019-04082-4													
J								Hospital service quality evaluation: an integrated model based on Pythagorean fuzzy AHP and fuzzy TOPSIS	SOFT COMPUTING										Service quality; Public and private hospitals; Pythagorean fuzzy sets; PFAHP; PFTOPSIS	DECISION-MAKING; OCCUPATIONAL-HEALTH; RISK-ASSESSMENT; EXTENSIONS; SCALE; VIKOR	Providing better hospital service quality is one of the major concerns of healthcare industry in the world. Since health services in Turkey are provided in a very competitive environment, for making a better choice, the services delivered by the public and private hospitals should be evaluated according to the viewpoint of stakeholders in terms of satisfaction. In this study, a model proposal is presented based on the concept of Pythagorean fuzzy analytic hierarchy process and Pythagorean fuzzy technique for order preference by similarity to ideal solution method to provide an accurate decision-making process for evaluating the hospital service quality. We study under fuzzy environment to reduce uncertainty and vagueness, and use linguistic variables parameterized by Pythagorean fuzzy numbers. The proposed approach is separated from others with the integration of the methods in a way providing a systematic fuzzy decision-making process. A case study including 32 service quality criteria and two public and one private hospitals in Turkey assessed by 32 evaluators by medical staff, hospital executives, auxiliaries, and patients is performed to demonstrate the applicability and validity of the proposed approach. On conclusion, integrated model produces reliable and suggestive outcomes better representing the vagueness of decision-making process.																	1432-7643	1433-7479				MAR	2020	24	5					3237	3255		10.1007/s00500-019-04084-2													
J								Generating trading rules on US Stock Market using strongly typed genetic programming	SOFT COMPUTING										Strongly typed genetic programming; Rule generation; Stock market; Evolutionary computation; Portfolio composition	MODEL; ALGORITHMS; PREDICTION; SELECTION; DESIGN; RETURN	Extracting rules from stock market data is an important and exciting problem, where investment decisions should be as clear and intuitive as possible in order for investors to choose the composition of their portfolios. Thus, it is important to guarantee that this process is done with a good framework and reliable techniques. In this context, portfolio composition is a puzzle with respect to selecting the appropriate assets and the optimal timing to invest. There are several models and algorithms to make these decisions, and in recent years, machine learning applications have been used to solve this puzzle with exceptional results. This technique allows a large amount of data to be processed, resulting in more informed recommendations on which asset to choose. Our study uses strongly typed genetic programming to generate rules to buy, hold and sell stocks in the US stock market, considering a rolling windows approach. We propose a different training approach, focusing the fitness function on a ternary decision based on the return prediction of each stock analyzed. The ternary rule matches perfectly with the three decisions: buy, hold and sell. Therefore, the rules are simple, intuitive, and easy for investors to understand. The results show that the proposed algorithm generates higher profits than the classical optimization approach. Moreover, the profits obtained are higher than the buy-and-hold strategy and the return of the indexes representative of the US stock market.																	1432-7643	1433-7479				MAR	2020	24	5					3257	3274		10.1007/s00500-019-04085-1													
J								Finite-time stability for uncertain differential equations: a first investigation on a new class of multi-agent systems	SOFT COMPUTING										Uncertain differential equation; Liu's process; Stability; Consensus; Fuzzy transform	CONSENSUS; MODEL	In this paper, we discuss a new kind of stability, that is, finite-time stability, for uncertain differential equations, by formalizing some properties. As a possible application, we define a new class of uncertain multi-agent systems, according to the Liu's uncertainty theory, as a counterpart of stochastic multi-agent systems. We formalize the governing equations, driven by canonical process, which is a type of uncertain process with stationary and independent increments. The concept of finite-time consensus in the context of uncertainty theory is consequently derived. A numerical procedure to estimate the settling time is proposed. The case with proportional delay was also considered.																	1432-7643	1433-7479				MAR	2020	24	5					3275	3284		10.1007/s00500-019-04086-0													
J								Sequence- and structure-based prediction of amyloidogenic regions in proteins	SOFT COMPUTING										Protein misfolding; Amyloid aggregation; Secondary structure; Solvent accessibility; Support vector machine; String kernels	FIBRIL-FORMING SEGMENTS; SECONDARY STRUCTURE; AGGREGATION-PRONE; SERVER; BETA; DETERMINANTS; DISEASE	Machine learning methods are increasingly used in proteomics research, especially in analyzing and predicting protein structures, functions, subcellular localizations and interactions. However, much research in recent years has focused on protein misfolding problem and the impact of unfolded and defective proteins on cell dysfunction, due to its considerable importance for molecular medicine. These abnormal proteins degradation and deposition often result in the formation of certain plaque cores among them the so-called amyloid fibrils which are responsible for an increasing number of highly debilitating disorders in humans. Yet, a significant challenge remains, especially in understanding the underlying causes and major risk factors of these harmful deposits in vital organs and tissues. This paper explores the potential of string kernel-based support vector machines in the prediction of amyloidogenic regions in proteins by incorporating the most informative features of the protein sequence such as predicted secondary structure and solvent accessibility, with a special focus on alpha-helical conformations which seem to be primarily concerned with amyloidogenesis. The performances compared with the most popular methods on Pep424 and Reg33 benchmark datasets indicate the robustness of the predictive model. Furthermore, the results showed accurate prediction of regions promoting fibrillogenesis for experimentally determined amyloid proteins and revealed that the five amino acids Leucine, Glycine, Alanine, Valine and Serine are predominantly present in amyloid-prone regions and confirm that the core regions of an amyloid aggregate are not necessarily fully buried.																	1432-7643	1433-7479				MAR	2020	24	5					3285	3308		10.1007/s00500-019-04087-z													
J								Parameter estimation of regression model with AR(p) error terms based on skew distributions with EM algorithm	SOFT COMPUTING										Autoregressive stationary process; EM algorithm; Linear regression; Skew distributions	AUTOREGRESSIVE MODELS; LIKELIHOOD	In the linear regression model, the errors are usually assumed to be uncorrelated. However, in real-life data, this assumption is not often plausible. In this study, first, we will assume that the errors of the regression model have autoregressive structure. This type of regression models has been considered before. However, in those papers under this assumption usually, the symmetric distributions are used as error distribution. The main contribution of this work is to use skew distributions instead of symmetric distributions as error distribution in regression models with autoregressive errors. We provide expectation maximization algorithm to compute the maximum likelihood estimates for the parameters. The performances of the proposed estimators are demonstrated with a simulation study and a real data example. We also provide the confidence intervals using the observed Fisher information matrix for the corresponding estimators.																	1432-7643	1433-7479				MAR	2020	24	5					3309	3330		10.1007/s00500-019-04089-x													
J								New work of trapezoidal cubic linguistic uncertain fuzzy Einstein hybrid weighted averaging operator and decision making	SOFT COMPUTING										Trapezoidal cubic linguistic uncertain fuzzy number (TrCLUFN); Einstein t-norm; Arithmetic averaging operator; Multiple-attribute decision making (MADM); Numerical application	AGGREGATION OPERATORS; INTERVAL; SETS	In this paper, we define some Einstein operations on trapezoidal cubic linguistic uncertain fuzzy numbers and develop two arithmetic averaging operators, that is, trapezoidal cubic linguistic uncertain fuzzy Einstein weighted averaging operator and trapezoidal cubic linguistic uncertain fuzzy Einstein hybrid weighted averaging (TrCLUFEHWA) operator, for aggregating trapezoidal cubic linguistic uncertain fuzzy information. Furthermore, we establish various properties of these operators and derive the relationship between the proposed operators and the exiting aggregation operators. We apply the TrCLUFEHWA operator to multiple-attribute decision making with trapezoidal cubic linguistic uncertain fuzzy information. Finally, a numerical example is provided to demonstrate the submission of the established approach.																	1432-7643	1433-7479				MAR	2020	24	5					3331	3354		10.1007/s00500-019-04096-y													
J								Two-dimensional perceptrons	SOFT COMPUTING										Neural networks; Multilayer perceptron; Two-dimensional perceptron; Left weight matrix; Right weight matrix		Convolutional neural networks (CNNs) have made remarkable success in image classification. However, it is still an open problem how to develop new models instead of CNNs. Here, we propose a novel model, namely two-dimensional perceptron (TDP), to get direct input of 2D data for further processing. A TDP computes hidden neurons from the input via left/right matrix multiplication, producing left-weighted TDP and right-weighted TDP, respectively. Experimental results on MNIST and COIL-20 datasets show that, in cases with the same number of hidden neurons, the model obtains 5%-45% relative performance improvement and 2 x-36x speedup in comparison with the corresponding multilayer perceptron and convolutional neural network. Hence, it is a promising and potential model that may open some new directions for deep neural networks, particularly alternatives to CNNs.																	1432-7643	1433-7479				MAR	2020	24	5					3355	3364		10.1007/s00500-019-04098-w													
J								Optimizing the trade-off between performance measures and operational risk in a food supply chain environment	SOFT COMPUTING										Supply chain management; Manufacturing; Quality management; Risk management	MONITORING-SYSTEM; LEAD TIME; MANAGEMENT; PERSPECTIVES; FRAMEWORK; NETWORKS; MODELS	In the context of a growing world population and the need to use limited resources responsibly, this study is motivated by the increasing pressures on the food industry, which include issues of food security, safety, and waste. In the context of a global food supply chain, we combine processing time and cost (PT&C) with operational risk (ORk) in a novel integrated approach to designing and optimizing monitoring systems. This study of a flagship product widely consumed around the world provides quantitative analysis and results based on real-world data from an international food company. The findings indicate that our multi-objective methodology provides quantitative insights into-and is capable of quantifying-an unexpected nonlinear relationship between PT&C and ORk. We show numerically how to decrease PT&C significantly by means of a minor increase in ORk, an outcome which is highly appealing for the industry. In addition, we provide accurate measurements of the impact of each individual monitoring activity, which allows the identification of the monitoring activities that are most critical. Generalizable insights for practitioners are derived from a step-by-step optimization of the entire monitoring system.																	1432-7643	1433-7479				MAR	2020	24	5					3365	3378		10.1007/s00500-019-04099-9													
J								Analysis of microchannel resistance factor based on automated simulation framework and BP neural network	SOFT COMPUTING										Microchannel; Resistance factor; Automatic simulation; Improved BP network	DEVELOPED LAMINAR-FLOW; PRESSURE-DROP; HEAT-TRANSFER; NUMERICAL-SIMULATION; LIQUID FLOW; FLUID-FLOW; CONDENSATION; PREDICTION	In this paper, self-design automated simulation and artificial neural network (ANN) model were developed to analyze and estimate the resistance factor in rectangle cross-section microchannels. The main purpose is to obtain a universal solution method through numerical simulation which can solve the resistance factor problem for invariant cross-section microchannels. Through Python language, the automatic coalescent of preprocessing Gambit, computing software CFD and post-processing Tecplot make the simulation framework realize the automatic acquisition of microchannel resistance factor samples. Then, 100 simulation samples with different aspect ratios for Reynolds numbers ranging from 50 to 500 were obtained. After validation, the width and height of microchannels were applied as input data set of the ANN model, and the resistance factor was determined as the target data. In order to improve BP algorithm for training ANN, a new swarm evolution algorithm was realized by combining the strong point of gradient descent method, genetic algorithm and particle swarm optimization, which is called particle swarm evolution algorithm. Finally, the result of resistance factor model was established and verified by several existing measurement value of pressure drop from remarkable experimental.																	1432-7643	1433-7479				MAR	2020	24	5					3379	3391		10.1007/s00500-019-04101-4													
J								Shear strength prediction of reinforced concrete beams by baseline, ensemble, and hybrid machine learning models	SOFT COMPUTING										Structural design; Artificial intelligence; Machine learning; Reinforced concrete beam; Shear strength; Civil engineering	ADAPTIVE REGRESSION SPLINES; SUPPORT VECTOR REGRESSION; ARTIFICIAL-INTELLIGENCE; COMPRESSIVE STRENGTH; FIREFLY ALGORITHM; OPTIMIZATION; EQUATIONS	The shear strength of reinforced concrete (RC) beams is critical in the design of structural members. Developing an effective mathematical method for accurately estimating shear strength of RC beams is beneficial for civil engineers. This work presents a hybrid artificial intelligent (AI) model for effectively predicting the shear strength of various types of RC beam. The hybrid AI model was developed by integrating an optimization algorithm [smart firefly algorithm (SFA)] and machine learning [least squares support vector regression (LSSVR)], in which the SFA was used to optimize the hyperparameters of LSSVR, improving its predictive accuracy. Three large datasets were used to train and test the hybrid AI model in predicting shear strength of RC beams. The predictive accuracy of the hybrid AI model was compared comprehensively with those of single AI models, ensemble AI models, and empirical methods. The comparison results show that the hybrid AI model outperformed the others in predicting the shear strength of a wide range of RC beam types. In particular, with the test data of RC beams without stirrups, the hybrid AI model yielded a mean absolute percentage error (MAPE) of 21.703%. In predicting shear strength of RC beams with stirrups, the hybrid AI model yielded an MAPE of 12.941%. For RC beams with FRP reinforcement, the hybrid AI model yielded an MAPE 18.951%. Therefore, this hybrid AI model can be a better alternative method to help civil engineers in designing RC beams.																	1432-7643	1433-7479				MAR	2020	24	5					3393	3411		10.1007/s00500-019-04103-2													
J								Use of Choquet integrals inmultivalued contexts	SOFT COMPUTING										L-fuzzy concept analysis; L-fuzzy context sequences; WOWA operators; Choquet integrals	AGGREGATION OPERATORS; FUZZY	In this work, multivalued contexts are studied, in which the different observations are related to each other. Continuing the studies already carried out in previous works, the use of Choquet integrals can be an adequate tool for this situations. If in addition the set of objects or attributes of these contexts represent a temporal sequence, we can also represent these contexts as sequences of contexts that evolve in time and we can use tools in this field to extract information. Finally, as illustrative application, the developed theory is used to measure student progress in learning.																	1432-7643	1433-7479				MAR	2020	24	5					3413	3423		10.1007/s00500-019-04104-1													
J								Multi-criteria group decisionmaking based on ELECTRE I method in Pythagorean fuzzy information	SOFT COMPUTING										Pythagorean fuzzy set; Pythagorean fuzzy number; ELECTRE method; Outranking relation; Concordance set; Discordance set	CRITERIA; EXTENSION; SELECTION; CHOICE; TOPSIS	ELECTRE is a family of multi-criteria decision analysis techniques which has the ability to provide as much as possible precise and suitable set of actions or alternatives to the underlying problem by eliminating the alternatives which are outranked by others. Group decision making is an effective process to provide the most appropriate solution to real-world decision-making scenarios by considering and merging the expert opinions of multiple individuals on problem. The purpose of this research study is to extend the ELECTRE I method to Pythagorean fuzzy ELECTRE I (PF-ELECTRE I) method in group decision-making environment, as Pythagorean fuzzy set model is more superior tool to capture vagueness and incompleteness in human evaluations. The developed method has ability to solve multi-criteria group decision-making problems in which the assessment information on available alternatives, provided by the experts, is presented as Pythagorean fuzzy decision matrices having each entry characterized by Pythagorean fuzzy number (PFN). The approach is formulated by introducing the concepts of strong, midrange and weak Pythagorean fuzzy concordance and discordance sets to elaborate the outranking relation among alternatives with respect to conflicting criteria. Framework of group decision supporting system based on PF-ELECTRE I is demonstrated by a flowchart. Finally, two illustrative examples in the field of health safety and environment management are given to verify and demonstrate the applicability of our proposed approach.																	1432-7643	1433-7479				MAR	2020	24	5					3425	3453		10.1007/s00500-019-04105-0													
J								Applying hybrid genetic-PSO technique for tuning an adaptive PID controller used in a chemical process	SOFT COMPUTING										Divided wall distillation column; Genetic algorithm; PID controller; Particle swarm optimization; Fuzzy gain scheduling PID; Neural PID tuner; ANFIS PID tuner; Hybrid GA-PSO	DIVIDING WALL COLUMN; PARTICLE SWARM OPTIMIZATION; MODEL-PREDICTIVE CONTROL; NEURAL-NETWORK; ALGORITHM; DESIGN; SEPARATION	The conventional PID controller has static parameters that cannot be changed at different operating conditions. As a result, the term 'adaptive PID controller' has appeared to solve this problem. This controller can be tuned using intelligent techniques such as Fuzzy Logic Control, Neural Network Control, or Adaptive Neuro-Fuzzy Inference Systems. However, the choice of the suitable parameters for these intelligent controllers has a direct effect on their performance. Metaheuristics algorithms-with their powerful performance, speed, and optimal parameter selection-can be applied for choosing controller parameters efficiently. In this paper, a hybrid of genetic algorithm and particle swarm optimization is proposed to tune the parameters of different adaptive PID controllers. To evaluate the performance of the proposed hybrid optimization method on the different adaptive PID controllers, these controllers are applied to control the operation of one of the most difficult chemical processes, the divided wall distillation column. The proposed column used in this work separates a ternary mixture of ethanol, propanol, and n-butanol. Our proposed hybrid optimization technique is compared with the genetic algorithm, and simulation results show that our proposed hybrid genetic-particle swarm technique outperforms genetic algorithm for different disturbances.																	1432-7643	1433-7479				MAR	2020	24	5					3455	3474		10.1007/s00500-019-04106-z													
J								Opinion spam detection framework using hybrid classification scheme	SOFT COMPUTING										Opinion spam; Spammer; Spam detection; Fake reviews		With the advent of social networking sites, opinion-mining applications have attracted the interest of the online community on review sites to know about products for their purchase decisions. However, due to increasing trend of posting spam (fake) reviews to promote the target products or defame the specific brands of competitors, Opinion Spam detection and classification has emerged as a hot issue in the community of opinion mining and sentiment analysis. We investigate the issue of Opinion Spam detection by using different combinations of entities, features, and their sentiment scores. We enrich the feature set of a baseline Spam detection method with Spam detection features (Opinion Spam, Opinion Spammer, Item Spam). Using a dataset of reviews from the Amazon site and sentences labeled for Spam detection, we evaluate the role of spamicity-related features in detecting and classifying spam (fake) clues and distinguishing them from genuine reviews. For this purpose, we introduce a rule-based feature weighting scheme and propose a method for tagging the review sentence as spam and non-spam. Experiments results depict that spam-related features improve Spam detection in review sentences posted on product review sites. Adding a revised feature weighting scheme achieved an accuracy increase from 93 to 96%. Furthermore, a hybrid set of features are shown to improve the performance of Opinion Spam detection in terms of better precision, recall, and F-measure values. This work shows that combining spam-related features with rule-based weighting scheme can improve the performance of even baseline Spam detection method. This improvement can be of use to Opinion Spam detection systems, due to the growing interest of individuals and companies in isolating fake (spam) and genuine (non-spam) reviews about products. The outcome of this work will provide an insight into spam-related features and feature weighting and will assist in developing more advanced applications for Opinion Spam detection. In the field of Opinion Spam detection, previous state-of-the-art studies used less number of spamicity-related features and less efficient feature weighting scheme. However, we provided a revised feature selection and a revised feature weighting scheme with normalized spamicity score computation technique. Therefore, our contribution is novel to the field because it provides a significant improvement over the comparing methods.																	1432-7643	1433-7479				MAR	2020	24	5					3475	3498		10.1007/s00500-019-04107-y													
J								Semi-supervised data clustering using particle swarm optimisation	SOFT COMPUTING										Semi-supervised clustering; Particle swarm optimisation; Bare bones		In this study, we propose the semi-supervised particle swarm optimisation (ssPSO) algorithm for data clustering. The algorithm takes advantage of the strengths of semi-supervised fuzzy c-means (ssFCM) and particle swarm optimisation (PSO) to allow for a more informed search using labelled data across small number of iterations while maintaining diversity in the search process. ssFCM algorithms can find meaningful clusters using available labelled data to guide the learning process. PSOs are often chosen to solve clustering problems due to their versatility in problem representation and exploration capabilities. To verify the goodness of ssPSOs and provide practical insights to researchers, the clustering performances and clustering behaviours of ssPSOs are investigated and compared with PSO variants and ssFCMs. Two approaches of ssPSO were studied, one applied at initialisation only and the other throughout the learning process. Evaluated based on accuracy and quantisation error (QE), the ssPSO, PSOs and ssFCM algorithms were tested on 13 UCI datasets with different sizes, dimensions, number of classes and distribution, exploring several swarm size and maximum iteration settings over 100 runs. Visual examination of biplots and convergence graphs was conducted. ssPSOs were found to perform competitively well with ssFCM in most datasets in terms of accuracy and outperform ssFCM in terms of QE using swarm size 20 and maximum iteration 20. The results demonstrate that ssPSOs perform particularly well in sparsely distributed datasets with overlapping clusters and produce clusters with better structures in terms of QE. Furthermore, ssPSOs were demonstrated to perform competitively well as ssFCM in datasets with more than three clusters, while QPSO performed poorly in such datasets.																	1432-7643	1433-7479				MAR	2020	24	5					3499	3510		10.1007/s00500-019-04114-z													
J								Hyperparameter tuning in convolutional neural networks for domain adaptation in sentiment classification (HTCNN-DASC)	SOFT COMPUTING										Domain adaptation; Sentiment analysis; Convolution neural networks; Deep learning; Doc2Vec		In-domain adaptation (DA), the knowledge trained in one domain, is used to test an unknown domain. Existing approaches use limited efforts on DA in sentiment classification (SC) using neural networks. The challenging task here is the dissimilarity in the semantic behavior across domains. In this paper, convolutional neural networks (CNNs) learn the knowledge of a particular domain using Doc2Vec feature representation which provides good performance for DA in SC for the target domain. Our empirical analysis with one-layer CNN exhibits significant change in the accuracy by tuning the hyperparameters involved with the CNN. This paper derives into a suitable CNN architecture accompanying hyperparameters which favor DA between different domains. Our empirical analysis with multi-domain dataset demonstrates that with suitable hyperparameters, CNN works well for DASC problems. The comparative study shows that CNN with Doc2Vec model provides a strong capability of learning large data representation semantically with other state-of-the-art methods for the DASC.																	1432-7643	1433-7479				MAR	2020	24	5					3511	3527		10.1007/s00500-019-04117-w													
J								An uncertain two-echelon fixed charge transportation problem	SOFT COMPUTING										Fixed charge; Supply chain; Uncertainty; Genetic algorithm; Particle swarm optimization	GENETIC ALGORITHM; MODEL	In the present study, a two-echelon fixed charge transportation problem is investigated under uncertainty. Due to the existence of considerable amount of uncertainties, the demands, supplies, availabilities, fixed charges and transported quantities in this problem are assumed as uncertain variables. The aim is to maximize the total profit under uncertain environments. The expected value model, chance-constrained model and measure chance model are developed, and the deterministic equivalent forms of these models are obtained by inverse uncertainty distribution. Genetic algorithm and particle swarm optimization are proposed to solve the equivalent forms of the models based on the structure of the problem. To verify the effectiveness of these proposed approaches, numerical experiments are performed.																	1432-7643	1433-7479				MAR	2020	24	5					3529	3541		10.1007/s00500-019-04119-8													
J								A fuzzy application of the group Z(n) to complete hypergroups	SOFT COMPUTING										Complete hypergroup; Intuitionistic fuzzy set; Intuitionistic fuzzy subhypergroup; Wieferich prime	ORDER LESS-THAN; IPS HYPERGROUPS; DIRECT-PRODUCT; GRADE; SEQUENCE; SETS	The purpose of this paper is the study of intuitionistic fuzzy subhypergroups of some special finite complete hypergroups. More exactly, in this paper we determine all m-tuples, characterizing the considered complete hypergroups, such that the grade intuitionistic fuzzy set ((mu) over bar, (lambda) over bar) is an intuitionistic fuzzy subhypergroup of such hypergroups. Here, we deal with complete hypergroups obtained from groups isomorphic with the additive groups of integers modulo p(2) or modulo pq, with p and q distinct odd primes. This article is a continuation of a previous work, concerning the complete hypergroups obtained from groups isomorphic with the additive groups of integers modulo p or modulo 2p, with p a prime number. It represents the starting point, the mathematical base, for writing a general algorithm for characterizing all complete hypergroups obtained from a group G and having the grade intuitionistic fuzzy set as an intuitionistic fuzzy subhypergroup.																	1432-7643	1433-7479				MAR	2020	24	5					3543	3550		10.1007/s00500-019-04121-0													
J								A novel parallel local search algorithm for the maximum vertex weight clique problem in large graphs	SOFT COMPUTING										Maximum clique problem; Parallel search; Vertex weight; MPI	WINNER DETERMINATION; OPTIMIZATION	This study proposes a new parallel local search algorithm (Par-LS) for solving the maximum vertex weight clique problem (MVWCP) in large graphs. Solving the MVWCP in a large graph with millions of edges and vertices is an intractable problem. Parallel local search methods are powerful tools to deal with such problems with their high-performance computation capability. The Par-LS algorithm is developed on a distributed memory environment by using message passing interface libraries and employs a different exploration strategy at each processor. The Par-LS introduces new operators parallel(omega,1)-swap and parallel(1,2)-swap, for searching the neighboring solutions while improving the current solution through iterations. During our experiments, 172 of 173 benchmark problem instances from the DIMACS, BHOSLIB and Network Data Repository graph libraries are solved optimally with respect to the best/optimal reported results. A new best solution for the largest problem instance of the BHOSLIB benchmark (frb100-40) is discovered. The Par-LS algorithm is reported as one of the best performing algorithms in the literature for the solution of the MVWCP in large graphs.																	1432-7643	1433-7479				MAR	2020	24	5					3551	3567		10.1007/s00500-019-04122-z													
J								The grid-to-neighbourhood relationship in cellular GAs: from design to solving complex problems	SOFT COMPUTING										Cellular genetic algorithms; Adaptation; Cellular networks; Mobility management	GENETIC ALGORITHM	Cellular genetic algorithms (cGAs) are a class of evolutionary algorithms in which the population is structured as a grid and interactions between individuals are restricted to the neighbourhood. Like any other optimisation algorithm, the cGA's efficiency lies in its ability to find an adequate balance between its exploratory and exploitive capabilities. The search selection pressure represents a good indicator of the state of that balance. From that point of view, it has been shown that the cGA's grid-to-neighbourhood relationship can be used to reflect this property. Until today, not much has been done in that area of research and many questions still surround this grid-to-neighbourhood effect. This paper describes a systematic study on the effects of that ratio on the efficiency of the cGA. This is done by proposing a dynamic cGA that adapts its ratio through evolving its grid structure using some strategy. The study is conducted using a wide range of dynamic and static ratio-control policies and, for the first time, by considering both synchronous and asynchronous cGAs. As a validation problem, we have opted for a real-world complex problem in advanced cellular networks: the users' mobility management. A wide set of differently sized and realistic instances of this problem have been used, and several comparisons have been conducted against other top-ranked solvers. The experiments showed that the ratio strategy rules the cGA's convergence, efficiency and scalability. Its effectiveness is correlated with the ratio-adaptation policy and the replacement synchronism being used. Indeed, our proposals that are based on deterministic and dynamic strategies with an asynchronous replacement were able to outperform most of the state-of-the-art algorithms.																	1432-7643	1433-7479				MAR	2020	24	5					3569	3589		10.1007/s00500-019-04125-w													
J								Public information, heterogeneous attention and market instability	SOFT COMPUTING										Selective attention; Decision-making; Adjustment speed; Dynamic model	STOCK-PRICE REACTION; OPTIMIZATION ALGORITHM; CROSS-SECTION; VOLATILITY; ARRIVAL; DYNAMICS; MEDIA; MODEL; COST; NEWS	In this paper, we investigate how market instability is formed with investment decision models of heterogeneous agents who are characterized by different selectivities of attention to public information. In the nonlinear dynamic decision model, agents make decisions on trading volume based on their own volume and marginal payoff of the previous period, as well as their selective attention to public information. One goal of this paper is to use the model to explore the condition under which public information could trigger the market instability. A second, related, goal is to study whether there is other investor behavior factor that leads to market instability. We find that some traders' significant attention to bad news or most traders' significant attention to good news can lead to market instability. We also find that whole market also may develop into chaos through bifurcation, with increasing relative trading adjustment speed responding to marginal payoff for some traders, although all traders pay no attention to public information. The relative trading adjustment speed responding to marginal payoff is more likely to cause market instability than public information. Our findings reveal an extremely simple stylized fact that market instability always occurs when there is no public information.																	1432-7643	1433-7479				MAR	2020	24	5					3591	3599		10.1007/s00500-019-04126-9													
J								Determining optimal designs for geosynthetic-reinforced soil bridge abutments	SOFT COMPUTING										Geosynthetics; Bridge abutment; Geosynthetic-reinforced soil; Computational modeling; Numerical analysis; Structural optimization	OPTIMIZATION; PERFORMANCE; WALLS	The article presents a parametric study of optimal designs for geosynthetic-reinforced soil (GRS) bridge abutments. A mixed integer design optimization model GRS-BA was developed, which is comprised of an accurate objective function of the construction costs. The cost objective function was constrained by a set of geotechnical and design conditions that were in accordance with current practice rules and recommendations. The optimal design recommendation for GRS bridge abutments was developed. A typical example of such an abutment is presented in order to compare design solutions derived from conventional design methods with solutions obtained from the proposed optimal design procedure.																	1432-7643	1433-7479				MAR	2020	24	5					3601	3614		10.1007/s00500-019-04127-8													
J								Hierarchical fuzzy design by a multi-objective evolutionary hybrid approach	SOFT COMPUTING										Hierarchical design; Type-2 fuzzy systems; Beta basis function; Structure learning; Multi-objective optimization; Parameter tuning	LOGIC SYSTEMS; ALGORITHM; PREDICTION; CLASSIFICATION; IDENTIFICATION; INFERENCE; SELECTION; INTERVAL; RULES	This paper presents a new tree hierarchical representation of type-2 fuzzy systems. The proposed system is called the type-2 hierarchical flexible beta fuzzy system (T2HFBFS) and is trained based on two-phase optimization mechanism. The first optimization step is a multi-objective structural learning phase. This phase is based on the multi-objective extended immune programming algorithm and aims to obtain an improved T2HFBFS structure with good interpretability-accuracy trade-off. The second optimization step is a parameter tuning phase. Using a hybrid evolutionary algorithm, this phase allows the adjustment of antecedent and consequent membership function parameters of the obtained T2HFBFS. By interleaving the two learning steps, an optimal and accurate hierarchical type-2 fuzzy system is derived with the least number of possible rules. The performance of the system is evaluated by conducting case studies for time series prediction problems and high-dimensional classification problems. Results prove that the T2HFBFS could attain superior performance than other existing approaches in terms of achieving high accuracy with a significant rule reduction.																	1432-7643	1433-7479				MAR	2020	24	5					3615	3630		10.1007/s00500-019-04129-6													
J								Bipolar fuzzy Dombi prioritized aggregation operators in multiple attribute decision making	SOFT COMPUTING										Bipolar fuzzy elements; Dombi operations; Bipolar fuzzy Dombi prioritized weighted averaging (BFDPWA) operator; Bipolar fuzzy Dombi prioritized weighted geometric (BFDPWG) operator; Multiple attribute decision making	INTUITIONISTIC FUZZY; SETS	In this article, used Dombi t-norm (TN) and t-conorm (TCN) which can generate more complex and more flexible operation rules by adjusting a parameter to combine with prioritized aggregation operators (AOs) in bipolar fuzzy (BF) environment. In this study, introduced bipolar fuzzy Dombi prioritized AOs, namely bipolar fuzzy Dombi prioritized averaging operator, bipolar fuzzy Dombi geometric operator, bipolar fuzzy Dombi prioritized weighted averaging operator and bipolar fuzzy Dombi prioritized weighted geometric operator as these operators along with proofs to aggregate various preferences of the decision makers. Then, we investigated several properties of its. In this purpose, we designed a multiple attribute decision-making technique for the proposed study. Finally, an illustrative example is given to demonstrate proposed approach under BF environment and a sensitivity analysis is considered for the working parameter on the ordering of the alternatives. A comparative study is provided for the choice best decision of the proposed approach with the existing problems. Finally, it is concluded that the proposed approach gives a more practical nature to aggregate the information process during the data analysis, and hence they take an alternative way for solving decision-making problems.																	1432-7643	1433-7479				MAR	2020	24	5					3631	3646		10.1007/s00500-019-04130-z													
J								Group-based whale optimization algorithm	SOFT COMPUTING										Biological; Meta-heuristic algorithm; Whale optimization algorithm		Meta-heuristic algorithms are divided into two categories: biological and non-biological. Biological algorithms are divided into evolutionary and swarm-based intelligence, where the latter is divided into imitation based and sign based. The whale algorithm is a meta-heuristic biological swarm-based intelligence algorithm (based on imitation). This algorithm suffers from the early convergence problem which means the population convergences early to an unfavorable optimum point. Usually, the early convergence occurs because of the weakness in exploration capability (global search). In this study, an optimized version of the whale algorithm is proposed that introduces a new idea in grouping of whales (called GWOA) to overcome the early convergence problem. The proposed whale optimization algorithm is compared with the standard whale algorithm (WOA), CWOA improved whale algorithm, particle swarm optimization, and BAT algorithms applying CEC2017 functions. The results of the experiments show that the proposed method applying Friedman's test on 30 standard benchmark functions has a better performance than the other baseline algorithms.																	1432-7643	1433-7479				MAR	2020	24	5					3647	3673		10.1007/s00500-019-04131-y													
J								Extended dissipativity and event-triggered synchronization for T-S fuzzy Markovian jumping delayed stochastic neural networks with leakage delays via fault-tolerant control	SOFT COMPUTING										Event-triggered scheme; Markovian jump parameters; Lyapunov-Krasovskii functional; Linear matrix inequality; Fault-tolerant control; Extended dissipative	SAMPLED-DATA CONTROL; H-INFINITY; NEUTRAL-TYPE; STATE ESTIMATION; CONTROL-SYSTEMS; EXPONENTIAL SYNCHRONIZATION; STABILITY; DISCRETE; COMMUNICATION; DESIGN	This paper concentrates on the extended dissipativity and event-triggered synchronization for T-S fuzzy Markovian jumping delayed stochastic neural networks with leakage delays and fault-tolerant control. We present an event-triggered communication scheme, which utilizes the effect of transmission delay with different failure rates. After giving a foundation to the stochastic model, the paper establishes some fundamental results on quadratically stable and extended dissipativity utilizing the Lyapunov functional, free-weight matrices, as well as the relationship between time-varying delay and leakage delays. The explicit expression of the desired controller gains and event-triggered parameters can be obtained by solving the established LMIs. The novel extended dissipative inequality contains several weighting matrices, by converting the weighting matrices in a new performance index, and the extended dissipativity will be degraded to the H-infinity performance, L-2 - L-infinity performance, passivity and dissipativity, respectively. Finally, interesting numerical examples are given to show the effectiveness of the theoretical results.																	1432-7643	1433-7479				MAR	2020	24	5					3675	3694		10.1007/s00500-019-04136-7													
J								Uncertain multi-objective optimization for the water-rail-road intermodal transport system with consideration of hub operation process using a memetic algorithm	SOFT COMPUTING										Water-rail-road intermodal transport; Hub-and-spoke network; Uncertain theory; Uncertain programming; Memetic algorithm	SPOKE NETWORK; MODELS	This paper addresses the multi-objective optimization of water-rail-road (WRR) intermodal transport system under uncertainty by explicitly capturing intermodal hub operation activities. Through the use of hub-and-spoke-type network, we formulate an uncertain multi-objective programming model for the WRR intermodal transportation network design problem, in which the cost, time and reliability objectives are simultaneously considered. Subsequently, we turn the original model into a deterministic equivalent multi-objective programming model under mild assumptions. Eventually, we utilize the epsilon-constraint method to reformulate the crisp multi-objective programming model to a modified mono objective one, which has proven to be NP-hard. Hence, we develop a memetic algorithm (MA) by combining a genetic algorithm and local intensification to solve the proposed problem. When designing the MA, we propose a combination encoding scheme to represent the location of intermodal hubs, the allocation of the demand nodes and the assignment of transportation modes. Moreover, we provide two local intensification operators to enhance exploitation ability. Finally, we implement a series of numerical experiments based on the Turkish network data set to verify the practicability of the proposed model and effectiveness of the solution approach developed in the paper.																	1432-7643	1433-7479				MAR	2020	24	5					3695	3709		10.1007/s00500-019-04137-6													
J								Stability analysis of chemotaxis dynamics in bacterial foraging optimization over multi-dimensional objective functions	SOFT COMPUTING										Bacterial foraging optimization; Chemotaxis dynamics; Multi-dimensional objective function; General mathematical model; Lyapunov stability theorem	PARTICLE SWARM; DIFFERENTIAL EVOLUTION; ALGORITHM; CONVERGENCE	Bacterial foraging optimization (BFO) has been proved to be an efficient optimization method and successfully applied to a variety of fields in the real world. In BFO, the chemotaxis process is a complex and close combination of swimming and tumbling and plays a crucial role in searching better solutions. A previous study has modeled the dynamics of the chemotaxis mechanism mathematically and investigated the stability and convergence behavior of the chemotaxis dynamics over the one-dimensional objective function by Lyapunov stability theorem. However, this study appears to be very limited from a practical point of view, and how to extend their study to the multi-dimensional objective function is a challenge. To solve it, we present a stability analysis of chemotaxis dynamics in BFO over the multi-dimensional objective function in this paper. First, the general mathematical model of the chemotaxis mechanism over the multi-dimensional objective function is created. Secondly, this paper uses the general descent search to analyze the general mathematical model and points out two necessary conditions for avoiding the bacterium to trap into a non-optimal solution. And then, the stability and convergence of the chemotaxis dynamics, represented by the general mathematical model, are proved by using Lyapunov stability theorem. Finally, empirical research is conducted to validate the above theoretical analysis.																	1432-7643	1433-7479				MAR	2020	24	5					3711	3725		10.1007/s00500-019-04139-4													
J								An ensemble learning framework for convolutional neural network based on multiple classifiers	SOFT COMPUTING										Ensemble learning; Convolutional neural network; Bagging; Boosting; Random forest		y Traditional machine learning methods have certain limitations in constructing high-precision estimation models and improving generalization ability, but ensemble learning that combines multiple different single models into one model is significantly better than that obtained by a single machine learning model. When the types of data sets are diversified and the scale is increasing, the ensemble learning algorithm has the problem of incomplete representation of features. At this time, convolutional neural network (CNN) with excellent feature learning ability makes up for the shortcomings of ensemble learning. In this paper, an ensemble learning framework for convolutional neural network based on multiple classifiers is proposed. First, this method mainly classifies UCI data sets using the ensemble learning algorithms based on multiple classifiers. Then, feature extraction is performed on the image data set MNIST using a convolutional neural network, and the extracted features are applied as input to be classified using an ensemble learning framework. The experimental results show that the accuracy of ensemble learning is higher than the accuracy of a single classifier and the accuracy of CNN + ensemble learning framework is higher than the accuracy of ensemble learning framework.																	1432-7643	1433-7479				MAR	2020	24	5					3727	3735		10.1007/s00500-019-04141-w													
J								Adaptive fuzzy observer-based cooperative control of unknown fractional-order multi-agent systems with uncertain dynamics	SOFT COMPUTING										Multi-agent systems; Fractional order; Robust control; Uncertain dynamics	LEADER-FOLLOWING CONSENSUS; TRACKING CONTROL; NEURAL-NETWORK; SYNCHRONIZATION; OPERATORS	In our paper, a new cooperative control for unknown fractional-order multi-agent systems is proposed. In addition to unknown dynamics, for the first time, the values of the fractional orders are also assumed to be unknown, and a new robust observer-based cooperative method for consensus issue of multi-agent systems (MASs) is presented. The unknown functions in the dynamics of the systems in all agents are estimated with the proposed interval type 2 fuzzy self-structuring radial basis function neural network (IT2F-SRBFNN). The free parameters of all IT2F-SRBFNN in all agents are adjusted using the adaptation laws which can be derived from the Lyapunov stability analysis. The strength of the proposed strategy is verified by a number of simulation examples.																	1432-7643	1433-7479				MAR	2020	24	5					3737	3752		10.1007/s00500-019-04142-9													
J								Multi-level cognitive concept learning method oriented to data sets with fuzziness: a perspective from features	SOFT COMPUTING										Cognitive concept learning; Fuzzy concept; Fuzzy set; Granular computing; Multi-level cognitive	FUZZY GRAPH REPRESENTATION; CONCEPT LATTICES; KNOWLEDGE REDUCTION; 3-WAY; INFORMATION	As a new interdisciplinary field induced by formal concept analysis, rough set, granular computing and cognitive computing, cognitive concept learning has received a great attention in recent years. Cognitive concept learning refers to the acquisition of specific concepts through specific cognitive concept learning approaches. The processes of concept learning mainly focus on simulating human brain recognizing concepts through the modeling of brain intelligence. In this paper, we investigate the mechanism of multi-level cognitive concept learning method oriented to data sets with fuzziness by discussing the process of human cognition. Through a newly defined fuzzy focal feature set, we put forward a corresponding structure of feature-oriented multi-level cognitive concept learning method in data sets with fuzziness from a perspective of philosophical and psychological views of human cognition. To make the presented cognitive concept learning approach much easier to understand and to apply it to practice widely, we establish an algorithm to recognize fuzzy concepts and incomplete fuzzy concepts. In addition, we present a case study about how to recognize and distinguish any two different micro-expressions from an information system with quantitative description to use our proposed method and theory to solve conceptual cognition problems, and also we perform an experimental evaluation on five data sets downloaded from the University of California-Irvine databases. Compared with the existing granular computing approach to two-way learning, we obtain more concepts than the two-way learning approach, which shows the feasibility and effectiveness of our feature-oriented multi-level cognitive learning method in data sets with fuzziness.																	1432-7643	1433-7479				MAR	2020	24	5					3753	3770		10.1007/s00500-019-04144-7													
J								A new approach for the rainbow spanning forest problem	SOFT COMPUTING										Graph theory; Edge-colored graph; Rainbow tree; Metaheuristic; Integer programming	TREE; ALGORITHMS	Given an edge-colored graph G, a tree with all its edges with different colors is called a rainbow tree. The rainbow spanning forest (RSF) problem consists of finding a spanning forest of G, with the minimum number of rainbow trees. In this paper, we present an integer linear programming model for the RSF problem that improves a previous formulation for this problem. A GRASP metaheuristic is also implemented for providing fast primal bounds for the exact method. Computational experiments carried out over a set of random instances show the effectiveness of the strategies adopted in this work, solving problems in graphs with up to 100 vertices.																	1432-7643	1433-7479				MAR	2020	24	5					3771	3780		10.1007/s00500-019-04145-6													
J								Green supplier selection of electric vehicle charging based on Choquet integral and type-2 fuzzy uncertainty	SOFT COMPUTING										Supply chain management; Green supplier selection; Electric vehicle charging facility; Interval type-2 fuzzy sets; lambda-fuzzy measure; Choquet integral	ANALYTIC NETWORK PROCESS; MULTICRITERIA DECISION-MAKING; MULTI CRITERIA APPROACH; ORDER ALLOCATION; PROGRAMMING APPROACH; MODEL; CHAIN; MCDM; ENVIRONMENT; VIKOR	In this paper, a framework under interval type-2 fuzzy (IT2F) environment is proposed to select the optimal green supplier of electric vehicle charging facility (EVCF). In the primary stage, a decision committee consisting of senior executives and experts is established, and qualified suppliers are also selected. The second stage aims to solve the problem of inherent uncertainties and criteria interactions. So, firstly, IT2F numbers are adopted for the performance evaluation since the criteria value cannot be adequately represented by type-1 fuzzy numbers. Then, lambda-fuzzy measure is adopted to measure the fuzzy densities of criteria by considering the interactions. After that, these fuzzy densities and aggregated IT2F matrix are as inputs to a proposed IT2F Choquet integral (IT2FCI) operator to evaluate the suppliers. Finally, to illustrate the validity of the proposed framework, a case study with a sensitivity analysis is presented. The weighting results indicate that the criterion of "production cost'' owns the largest fuzzy density of 0.65, and the sorting results show that none of these alternatives are optimal in all criteria and the results are relatively stable for a change in fuzzy density.																	1432-7643	1433-7479				MAR	2020	24	5					3781	3795		10.1007/s00500-019-04147-4													
J								Some inequalities and limit theorems for fuzzy random variables adopted with alpha-values of fuzzy numbers	SOFT COMPUTING										Fuzzy random variables; Convergence theorem; Inequality; alpha-Values	STRONG LAW; RANDOM SETS; MEAN-VALUE; WEAK LAWS; CONVERGENCE	In this paper, some essential stochastic inequalities and several convergence theorems were investigated for fuzzy random variables. The classical counterpart relationship between the proposed convergence theorems was also discussed in the fuzzy environment. The main advantage of the proposed method is its minimal requirements for such limit theorems and inequalities compared to the conventional methods used in the fuzzy environments. The previous methods mostly rely on the lower and upper bounds of the alpha-cuts of fuzzy random variables, while the proposed method utilizes a unified quantity called alpha-value.																	1432-7643	1433-7479				MAR	2020	24	5					3797	3807		10.1007/s00500-019-04149-2													
J								A recognition-verification system for noisy faces based on an empirical mode decomposition with Green's functions	SOFT COMPUTING										Empirical mode decomposition; Green's function; Discrete cosine transform; Face recognition; Face verification; k-NN; SVM; Filters	ALGORITHM; SIGNAL	Face recognition or verification remains a real challenge in the area of pattern recognition and image processing. The image acquisition process is a crucial step in which noise will inevitably be introduced, and in most cases this noise drastically decreases the accuracy of the classification rate of recognition systems, making them ineffective. This paper presents a novel approach to face recognition or verification, which increases the recognition rate in noisy environmental conditions. The latter is achieved by using the intrinsic face mode functions that result from applying a bi-dimensional empirical mode decomposition with Green's functions in tension to noisy images. Each image is individually decomposed, and noisy modes are discarded or filtered during reconstruction. Then, the extracted modes are used for classification purposes with canonical classifiers such as vector support machines or k-nearest neighbor classifiers. Experimental results show that this method achieves very stable results, almost independently of the amount of noise added to the image, due to the ability of decomposition to capture the noise in the first mode. Classification results using noisy images are at the same level as other algorithms proposed for the same databases but working on clean images and therefore are better than those obtained using classic image filters in noisy images. Moreover, unlike most of the available algorithms, the algorithm proposed in this paper is based on the input data (without the need to adjust parameters), making it transparent to the user. Finally, the proposed new approach achieves good results independently of the type of noise, the level of noise and the type of the database, which is not possible with other classical methods requiring parameter adjustment.																	1432-7643	1433-7479				MAR	2020	24	5					3809	3827		10.1007/s00500-019-04150-9													
J								A new image encryption algorithm using random numbers generation of two matrices and bit-shift operators	SOFT COMPUTING										Image encryption; Security; Random numbers generation; Bit-shifting operators	FRACTIONAL FOURIER-TRANSFORM; CHAOS; CIPHER	In this work, we proposed a new approach to encrypt color images using two matrices with size of 16 9 16 whose integer values are between 0 and 255 generated randomly, and the bit-shift operators. These matrices are used to perform the first encryption phase. The first value of the first matrix is calculated from the pixels of each channel (red, green and blue) of the original image; the rest of the values are randomly generated; each value must be unique; the values of the second matrix are unique and generated randomly. The first encryption phase of the original image is done by digraph (two-digit sequence). We take the first digit in the first matrix, the second digit in the second matrix; then, we look in these matrices for the numbers that complete the rectangle. In the second encryption phase, we used a right circular shift of bits; the number of bits to shift is calculated according to a function which considers the values of the two matrices as well as their positions (row and column). Therefore, any change in the two keys (two matrices) will completely change the encrypted image. Our encryption system is resistant against brute force attacks, statistical attacks as well as differential attacks. The results are justified by applying several safety criteria, such as correlation coefficient, entropy and peak signal-to-noise ratio (PSNR). In addition, our method is very sensitive to the change made, either in the original image or in the two keys used for the encryption, which was justified by calculating the number of changing pixel rate (NPCR > 99.69) and the unified averaged changed intensity (UACI > 33.54).																	1432-7643	1433-7479				MAR	2020	24	5					3829	3848		10.1007/s00500-019-04151-8													
J								Robotic manipulator control based on an optimal fractional-order fuzzy PID approach: SiL real-time simulation	SOFT COMPUTING										Robotic manipulator; Fractional calculus; Fractional-order fuzzy PID controller; Fuzzy logic controller; Multi-objective particle swarm optimization	SLIDING MODE CONTROL; PERFORMANCE ANALYSIS	Robotic manipulator control is a challenging task due to its nonlinear, interacting multi-input-multi-output dynamics. In this paper, we proposed an optimal robust fractional-order fuzzy PID controller based on multi-objective particle swarm optimization (MOPSO) algorithm for a two-link robotic manipulator. In order to minimize position and trajectory-tracking error, MOPSO finds the optimal parameters of fuzzy membership functions and order of the fractional operators. To show the effectiveness of the proposed controller, the software-in-the-loop real-time simulation is executed, and the results are compared to conventional fuzzy PID, fractional-order PID, and linear PID controllers.																	1432-7643	1433-7479				MAR	2020	24	5					3849	3860		10.1007/s00500-019-04152-7													
J								Adaptive multi-population inflationary differential evolution	SOFT COMPUTING										Global optimisation; Differential evolution; Multi-population algorithm; Adaptive algorithm	REAL-PARAMETER OPTIMIZATION; BENCHMARK; ALGORITHM	This paper proposes a multi-population adaptive version of inflationary differential evolution algorithm. Inflationary differential evolution algorithm (IDEA) combines basic differential evolution (DE) with some of the restart and local search mechanisms of Monotonic Basin Hopping (MBH). In the adaptive version presented in this paper, the DE parameters CR and F are automatically adapted together with the size of the local restart bubble and the number of local restarts of MBH. The proposed algorithm implements a simple but effective mechanism to avoid multiple detections of the same local minima. The novel mechanism allows the algorithm to decide whether to start or not a local search. The algorithm has been extensively tested over more than fifty test functions from the competitions of the Congress on Evolutionary Computation (CEC), CEC 2005, CEC 2011 and CEC 2014, and compared against all the algorithms participating in those competitions. For each test function, the paper reports best, worst, median, mean and standard deviation values of the best minimum found by the algorithm. Comparisons with other algorithms participating in the CEC competitions are presented in terms of relative ranking, Wilcoxon tests and success rates. For completeness, the paper presents also the single population adaptive IDEA, that can adapt only CR and F, and shows that this simpler version can outperform the multi-population one if the radius of the restart bubble and the number of restarts are properly chosen.																	1432-7643	1433-7479				MAR	2020	24	5					3861	3891		10.1007/s00500-019-04154-5													
J								Power-law fitness scaling on multi-objective evolutionary algorithms: interpretations of experimental results	SOFT COMPUTING										Fitness scaling; Evolutionary algorithms; SPEA2; DOPGA; Gamma correction	KRILL HERD; GENETIC ALGORITHMS; OPTIMIZATION; PERFORMANCE; SYSTEMS	The effect of power-law fitness scaling method on the convergence and distribution of MOEAs is investigated in a systematic fashion. The proposed method is named as gamma (gamma) correction-based fitness scaling (GCFS). What scaling does is that the selection pressure of a population can be efficiently regulated. Hence, fit and unfit individuals may be separated well in fitness-wise before going to the selection mechanism. It is then applied to Strength Pareto Evolutionary Algorithm 2 (SPEA2) and Domination Power of an individual Genetic Algorithm (DOPGA). Firstly, the effectiveness of GCFS is tested by 11 static gamma values (including 0.5, 1, 2, ..., 9, 10) on nine well-known benchmarks. Simulated study safely states that SPEA2 and DOPGA may perform generally better with the square (gamma = 2) and the cubic (gamma = 3) of original fitness value, respectively. Secondly, an adaptive version of GCFS is proposed based on statistical merits (standard deviation and mean of fitness values) and implemented to the selected MOEAs. Generally speaking, fitness scaling significantly improves the convergence properties of MOEAs without extra computational burdens. It is observed that the convergence ability of existing MOEAs with fitness scaling (static or adaptive) can be improved. Simulated results also show that GCFS is only effective when fitness proportional selection methods (such as stochastic universal sampling-SUS) are used. GCFS is not effective when tournament selection is used.																	1432-7643	1433-7479				MAR	2020	24	5					3893	3907		10.1007/s00500-019-04242-6													
J								An effective dimension reduction algorithm for clustering Arabic text	EGYPTIAN INFORMATICS JOURNAL										Clustering; Dimensionality reduction; PCA; SVD; NMF; Arabic NLP	NONNEGATIVE MATRIX FACTORIZATION	Text clustering is a challenging task in natural language processing due to the very high dimensional space produced by this process (i.e. curse of dimensionality problem). Since these texts contain considerable amounts of ambiguities and redundancies, they produce different noise effects. For an efficient and accurate clustering algorithm, we need to extract the main concepts of the text by eliminating the noise and reducing the high dimensionality of the data. This paper compares among three of the famous dimension reduction algorithms for text clustering to show the pros and cons of each one, namely Principal Component Analysis (PCA), Nonnegative Matrix Factorization (NMF) and Singular Value Decomposition (SVD). It presents an effective dimension reduction algorithm for Arabic text clustering using PCA. For that purpose, a series of the experiments has been conducted using two linguistic corpora for both English and Arabic and analyzed the results from a clustering quality point of view. The experiments have shown that PCA improves the quality of the clustering process and that it gives more interpretable results with less time needed for the clustering process for both Arabic and English documents. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					1	5		10.1016/j.eij.2019.05.002													
J								A comprehensive study for Arabic Sentiment Analysis (Challenges and Applications)	EGYPTIAN INFORMATICS JOURNAL										Semantics; Arabic Sentiment Analysis; Social sciences; Machine learning; ALSA six-level framework		yy Arabic language processing works on multiple levels; less often, these complementary levels synergize well with each other. Arabic Language Sentiment Analysis (ALSA) levels consist of phonetics, morphology, syntax, lexicology, semantics, and figurative nature. The analysis of opinions and feelings is of interest in English and Indo-European languages, with little emphasis in the Arabic language, which is a language full of rhetorical characteristics and implicit meanings that have positive and negative connotations and meanings across the six linguistic levels. This paper presents a comprehensive and full proposal of a strategy for ALSA. The ALSA framework analyzes the opinions and feelings at all levels of language, in addition to the importance of building an annotated corpus, which helps to understand an Arabic sentence from the level of phonetics to the rhetorical and metonymy levels. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					7	12		10.1016/j.eij.2019.06.001													
J								An efficient methodology for discovering both of gene-environment interactions and gene-gene interactions causing genetic diseases	EGYPTIAN INFORMATICS JOURNAL										Genetic diseases; Feature selection methods; Relief algorithm; Genetic algorithm; Classification decision tree	EXPRESSION; ALGORITHM	Genetic diseases are one of the most critical diseases facing human societies, their risk lies in the transmission of genetic characteristics from one generation to another, where the imbalance of these characteristics leads to an unhealthy offspring, which negatively affects the effort of this offspring and its services to society. Genetic disease is caused by a mutation in the Deoxyribonucleic Acid (DNA), these genetic mutations are generated by nonlinear interactions between two or more genes and / or environmental exposures. The aim of this paper is to discover both of gene-environment interactions and gene-gene interactions causing a genetic disease, the proposed methodology is based on both of the filter and wrapper feature selection methods, it uses the filter method using a Relief algorithm to detect the gene-environment interactions, wrapper method using genetic algorithm to discover gene-gene interactions, and classification decision tree algorithm to generate the conditional rules of gene-gene interactions. It has been evaluated using many different classifier models on four benchmark databases, and compared its performance with an Apriori algorithm for generating rules of gene-gene interactions, the proposed methodology achieved the highest performance and better classification accuracy on all databases containing patients affected by gene-environment interactions or gene-gene interactions or both of gene-environment and gene-gene interactions. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					13	22		10.1016/j.eij.2019.10.001													
J								Employing PCA and t-statistical approach for feature extraction and classification of emotion from multichannel EEG signal	EGYPTIAN INFORMATICS JOURNAL										Brain-computer interface (BCI); Emotion recognition; Electroencephalogram (EEG); SEED (SJTU Emotion EEG dataset); Support vector machine (SVM); Artificial neural network (ANN); Linear discriminant analysis (LDA); k-Nearest neighbor (kNN); Classification accuracy	NEAR-INFRARED SPECTROSCOPY; RECOGNITION; ENTROPY; POTENTIALS; TASKS	To achieve a highly efficient brain-computer interface (BCI) system regarding emotion recognition from electroencephalogram (EEG) signal, the most crucial issues are feature extractions and classifier selection. This work proposes an innovative method that hybridizes the principal component analysis (PCA) and t-statistics for feature extraction. This work contributes to successfully implement spatial PCA to reduce signal dimensionality and to select the suitable features based on the t-statistical inferences among the classes. The proposed method has been applied on the SEED dataset (SJTU Emotion EEG Dataset) that yielded significant channels and features for getting higher classification accuracy. With extracted features, four classifiers- support vector machine (SVM), artificial neural network (ANN), linear discriminant analysis (LDA), and k-nearest neighbor (kNN) method were applied to classify the emotional states. The classifiers showed slightly different classification accuracies compared to each other. ANN and SVM showed the highest classification accuracy (86.57 +/- 4.08 and 85.85 +/- 5.72) in case of subject dependent approach. On the other hand, the proposed method provides 84.3% and 77.1% classification accuracy with ANN and SVM, respectively in case of subject independent approach. Eventually, the proposed method and its outcomes demonstrate that this proposal is better than the several existing methods in emotion recognition. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					23	35		10.1016/j.eij.2019.10.002													
J								Noise robust Laws' filters based on fuzzy filters for texture classification	EGYPTIAN INFORMATICS JOURNAL										Fuzzy filter; Laws' mask; Texture classification; Texture features	LOCAL BINARY PATTERN; DESCRIPTORS; REDUCTION; IMAGES	y Laws' mask method has achieved wide acceptance in texture analysis, however it is not robust to noise. Fuzzy filters are well known for denoising applications. This work proposes a noise-robust Laws' mask descriptor by integrating the exiting fuzzy filters with the traditional Laws' mask for the improvement of texture classification of noisy texture images. Images are corrupted by adding Gaussian noise of different values. These noisy images are transformed into fuzzy images through fuzzy filters of different windows. Then the texture features are extracted using Laws' mask descriptor. To investigate the proposed techniques two texture databases i.e. Brodatz and STex are used. The proposals are assessed by comparing the performance of the traditional Laws' mask descriptor alone and after combined with the fuzzy filters on noisy images. The k-Nearest Neighbor (k-NN) classifier is utilized in the classification task. Results indicate that the proposed approach delivers higher classification accuracy than the traditional Laws' mask method. Hence, validate that the suggested methods significantly improve the noised texture classification. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					37	49		10.1016/j.eij.2019.10.003													
J								A robust clustering algorithm using spatial fuzzy C-means for brain MR images	EGYPTIAN INFORMATICS JOURNAL										Clustering algorithm; MRI; Fuzzy C-means	SEGMENTATION; INFORMATION; FILTER	Magnetic Resonance Imaging (MRI) is a medical imaging modality that is commonly employed for the analysis of different diseases. However, these images come with several problems such as noise and other imaging artifacts added during acquisition process. The researchers have actual challenges for segmentation under the consideration of these effects. In medical images, a well-known clustering approach like Fuzzy C-Means widely used for segmentation. The performance of FCM algorithm is fast in noise-free images; however, this method did not consider the spatial context of the image due to which its performance suffers when images corrupted with noise and other imaging relics. In this paper, a weighted spatial Fuzzy C-Means (wsFCM) segmentation method is proposed that considered the spatial information of image. Moreover, a spatial function is also developed that integrate a membership function. In order assess this function, a neighborhood window is established around a pixel and more weights have been assigned to those pixels which have greater correlation with central pixel in local neighborhood. By integration of this spatial function in membership function, the modified membership function strengthens the original membership function in handling the noise and intensity inhomogeneity, which has the ability to preserves and maintains structural information like edges. A comprehensive set of experimentation is performed on publicly accessible simulated and real standard brain MRI datasets. The performance of the proposed method has been compared with existing state-of-the-art methods. The results show that the performance of the proposed method is better and robust in handling noise and intensity inhomogeneity than of the existing works. (C) 2019 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University.																	1110-8665	2090-4754				MAR	2020	21	1					51	66		10.1016/j.eij.2019.10.005													
J								A Meta-Objective Approach for Many-Objective Evolutionary Optimization	EVOLUTIONARY COMPUTATION										Many-objective optimization; evolutionary multi-objective optimization; meta-objective; convergence; diversity	MULTIOBJECTIVE OPTIMIZATION; ALGORITHM; DIVERSITY; CONVERGENCE; SELECTION; MOEA/D	Pareto-based multi-objective evolutionary algorithms experience grand challenges in solving many-objective optimization problems due to their inability to maintain both convergence and diversity in a high-dimensional objective space. Exiting approaches usually modify the selection criteria to overcome this issue. Different from them, we propose a novel meta-objective (MeO) approach that transforms the many-objective optimization problems in which the new optimization problems become easier to solve by the Pareto-based algorithms. MeO converts a given many-objective optimization problem into a new one, which has the same Pareto optimal solutions and the number of objectives with the original one. Each meta-objective in the new problem consists of two components which measure the convergence and diversity performances of a solution, respectively. Since MeO only converts the problem formulation, it can be readily incorporated within any multi-objective evolutionary algorithms, including those non-Pareto-based ones. Particularly, it can boost the Pareto-based algorithms' ability to solve many-objective optimization problems. Due to separately evaluating the convergence and diversity performances of a solution, the traditional density-based selection criteria, for example, crowding distance, will no longer mistake a solution with poor convergence performance for a solution with low density value. By penalizing a solution in term of its convergence performance in the meta-objective space, the Pareto dominance becomes much more effective for a many-objective optimization problem. Comparative study validates the competitive performance of the proposed meta-objective approach in solving many-objective optimization problems.																	1063-6560	1530-9304				MAR	2020	28	1					1	25		10.1162/evco_a_00243													
J								Global Convergence of the (1+1) Evolution Strategy to a Critical Point	EVOLUTIONARY COMPUTATION										Evolution strategies; sufficient decrease; global convergence	SELF-ADAPTATION	We establish global convergence of the (1 + 1) evolution strategy, that is, convergence to a critical point independent of the initial state. More precisely, we show the existence of a critical limit point, using a suitable extension of the notion of a critical point to measurable functions. At its core, the analysis is based on a novel progress guarantee for elitist, rank-based evolutionary algorithms. By applying it to the (1 + 1) evolution strategy we are able to provide an accurate characterization of whether global convergence is guaranteed with full probability, or whether premature convergence is possible. We illustrate our results on a number of example applications ranging from smooth (non-convex) cases over different types of saddle points and ridge functions to discontinuous and extremely rugged problems.																	1063-6560	1530-9304				MAR	2020	28	1					27	53		10.1162/evco_a_00248													
J								A Revisit of Infinite Population Models for Evolutionary Algorithms on Continuous Optimization Problems	EVOLUTIONARY COMPUTATION										Evolutionary algorithms; infinite population models; population dynamics; convergence in distribution; theoretical analysis		Infinite population models are important tools for studying population dynamics of evolutionary algorithms. They describe how the distributions of populations change between consecutive generations. In general, infinite population models are derived from Markov chains by exploiting symmetries between individuals in the population and analyzing the limit as the population size goes to infinity. In this article, we study the theoretical foundations of infinite population models of evolutionary algorithms on continuous optimization problems. First, we show that the convergence proofs in a widely cited study were in fact problematic and incomplete. We further show that the modeling assumption of exchangeability of individuals cannot yield the transition equation. Then, in order to analyze infinite population models, we build an analytical framework based on convergence in distribution of random elements which take values in the metric space of infinite sequences. The framework is concise and mathematically rigorous. It also provides an infrastructure for studying the convergence of the stacking of operators and of iterating the algorithm which previous studies failed to address. Finally, we use the framework to prove the convergence of infinite population models for the mutation operator and the k-ary recombination operator. We show that these operators can provide accurate predictions for real population dynamics as the population size goes to infinity, provided that the initial population is identically and independently distributed.																	1063-6560	1530-9304				MAR	2020	28	1					55	85		10.1162/evco_a_00249													
J								A Tandem Evolutionary Algorithm for Identifying Causal Rules from Complex Data	EVOLUTIONARY COMPUTATION										Evolutionary algorithm; epistasis; heterogeneity; multiplexer; learning classifier systems; machine learning	LEARNING CLASSIFIER SYSTEM; CHRONIC CHAGAS-DISEASE; GENETIC-HETEROGENEITY; SUSCEPTIBILITY; EPISTASIS; PRODUCT; CONSTRUCTION; TRANSPORT; PROFILE; RISK	We propose a new evolutionary approach for discovering causal rules in complex classification problems from batch data. Key aspects include (a) the use of a hypergeometric probability mass function as a principled statistic for assessing fitness that quantifies the probability that the observed association between a given clause and target class is due to chance, taking into account the size of the dataset, the amount of missing data, and the distribution of outcome categories, (b) tandem age-layered evolutionary algorithms for evolving parsimonious archives of conjunctive clauses, and disjunctions of these conjunctions, each of which have probabilistically significant associations with outcome classes, and (c) separate archive bins for clauses of different orders, with dynamically adjusted order-specific thresholds. The method is validated on majority-on and multiplexer benchmark problems exhibiting various combinations of heterogeneity, epistasis, overlap, noise in class associations, missing data, extraneous features, and imbalanced classes. We also validate on a more realistic synthetic genome dataset with heterogeneity, epistasis, extraneous features, and noise. In all synthetic epistatic benchmarks, we consistently recover the true causal rule sets used to generate the data. Finally, we discuss an application to a complex real-world survey dataset designed to inform possible ecohealth interventions for Chagas disease.																	1063-6560	1530-9304				MAR	2020	28	1					87	114		10.1162/evco_a_00252													
J								Guiding Neuroevolution with Structural Objectives	EVOLUTIONARY COMPUTATION										Neuroevolution; neural network structure; modularity; diversity	NEURAL-NETWORKS; MODULARITY; EVOLUTION	The structure and performance of neural networks are intimately connected, and by use of evolutionary algorithms, neural network structures optimally adapted to a given task can be explored. Guiding such neuroevolution with additional objectives related to network structure has been shown to improve performance in some cases, especially when modular neural networks are beneficial. However, apart from objectives aiming to make networks more modular, such structural objectives have not been widely explored. We propose two new structural objectives and test their ability to guide evolving neural networks on two problems which can benefit from decomposition into subtasks. The first structural objective guides evolution to align neural networks with a user-recommended decomposition pattern. Intuitively, this should be a powerful guiding target for problems where human users can easily identify a structure. The second structural objective guides evolution towards a population with a high diversity in decomposition patterns. This results in exploration of many different ways to decompose a problem, allowing evolution to find good decompositions faster. Tests on our target problems reveal that both methods perform well on a problem with a very clear and decomposable structure. However, on a problem where the optimal decomposition is less obvious, the structural diversity objective is found to outcompete other structural objectives-and this technique can even increase performance on problems without any decomposable structure at all.																	1063-6560	1530-9304				MAR	2020	28	1					115	140		10.1162/evco_a_00250													
J								Evolution of Deep Convolutional Neural Networks Using Cartesian Genetic Programming	EVOLUTIONARY COMPUTATION										Genetic programming; convolutional neural network; deep learning		The convolutional neural network (CNN), one of the deep learning models, has demonstrated outstanding performance in a variety of computer vision tasks. However, as the network architectures become deeper and more complex, designing CNN architectures requires more expert knowledge and trial and error. In this article, we attempt to automatically construct high-performing CNN architectures for a given task. Our method uses Cartesian genetic programming (CGP) to encode the CNN architectures, adopting highly functional modules such as a convolutional block and tensor concatenation, as the node functions in CGP. The CNN structure and connectivity, represented by the CGP, are optimized to maximize accuracy using the evolutionary algorithm. We also introduce simple techniques to accelerate the architecture search: rich initialization and early network training termination. We evaluated our method on the CIFAR-10 and CIFAR-100 datasets, achieving competitive performance with state-of-the-art models. Remarkably, our method can find competitive architectures with a reasonable computational cost compared to other automatic design methods that require considerably more computational time and machine resources.																	1063-6560	1530-9304				MAR	2020	28	1					141	163		10.1162/evco_a_00253													
J								Second-order multivariate calibration with the extended bilinear model: Effect of initialization, constraints, and composition of the calibration set on the extent of rotational ambiguity	JOURNAL OF CHEMOMETRICS										grid search; initialization and constraints; multivariate curve resolution; rotational ambiguity; second-order multivariate calibration	CURVE RESOLUTION	Extended bilinear modeling is popular in second-order multivariate calibration, particularly when the matrix data for each sample are of chromatographic origin. Since elution time profiles vary across samples, in both shape and peak position, it is not possible to process these data in a three-way trilinear format. In these cases, the most successful model for quantitating analytes in the presence of interferents is multivariate curve resolution-alternating least squares (MCR-ALS) in its extended version, ie, processing an augmented data matrix built with the matrices for a test sample and the calibration samples, appended in the direction of the elution time mode. MCR-ALS starts with certain initial profiles and applies a set of natural constraints during the ALS phase, whose purpose is to reduce the range of feasible solutions or to lead to unique bilinear solutions if possible. In this report, a simulated second-order three-component system (two calibrated analytes and one uncalibrated interferent in test samples) is studied regarding the presence of rotational ambiguity in the bilinear solutions, using (a) a grid search methodology to compute the feasible solutions and (b) MCR-ALS on a large set of test samples to estimate the average prediction errors. Various initialization schemes and constraints are probed, and the results are compared in terms of the extent of rotational ambiguity and global uncertainty in predicted concentrations.																	0886-9383	1099-128X				MAR	2020	34	3			SI				e3130	10.1002/cem.3130													
J								A Verified Implementation of Algebraic Numbers in Isabelle/HOL	JOURNAL OF AUTOMATED REASONING										Theorem proving; Algebraic numbers; Real algebraic geometry; Resultants	ALGORITHM	We formalize algebraic numbers in Isabelle/HOL. Our development serves as a verified implementation of algebraic operations on real and complex numbers. We moreover provide algorithms that can identify all the real or complex roots of rational polynomials, and two implementations to display algebraic numbers, an approximative version and an injective precise one. We obtain verified Haskell code for these operations via Isabelle's code generator. The development combines various existing formalizations such as matrices, Sturm's theorem, and polynomial factorization, and it includes new formalizations about bivariate polynomials, unique factorization domains, resultants and subresultants.																	0168-7433	1573-0670				MAR	2020	64	3			SI		363	389		10.1007/s10817-018-09504-w													
J								Limited Second-Order Functionality in a First-Order Setting	JOURNAL OF AUTOMATED REASONING										ACL2; Theorem proving; Apply; Higher-order logic; Functionals		We describe how we have defined in ACL2 a weak version of the Common Lisp functional apply, which takes a function and list of actuals and applies the function to the actuals. Our version, called apply$, does not operate on functions but on ordinary objects-symbols and lists representing lambda expressions-some of which are interpreted as functions. We define a syntactic notion of "tameness" to identify the interpretable objects. This makes our apply$ weaker than a true second-order functional but we believe apply$ is powerful enough for many uses in ACL2. To maintain soundness and the conservativity of our Definitional Principle we require that certain hypotheses, called "warrants", be present in any theorem relying on the behavior of apply$ on non-primitives. Within these constraints we can define "functionals" such as sum and foldr which map tame "functions" over lists and accumulate the results. This allows the ACL2 user to avoid defining specialized recursive functions for each such application. We can prove and use general-purpose lemmas about these "functionals." We describe the formalization, explain how we keep the Definitional Principle conservative, show examples of useful functions using apply$ and theorems about them, sketch the proof that there is a model of any extension of the system using the new primitives, discuss issues arising in making these functions executable, and show some preliminary performance results.																	0168-7433	1573-0670				MAR	2020	64	3			SI		391	422		10.1007/s10817-018-09505-9													
J								OPTIMATHSAT: A Tool for Optimization Modulo Theories	JOURNAL OF AUTOMATED REASONING										OPTIMATHSAT; Optimization Modulo Theories; OMT; MAXSMT; Sorting networks; Multi-objective optimization	CONSTRAINT SATISFACTION PROBLEMS; SATISFIABILITY MODULO; SAT; LOGIC	Optimization Modulo Theories (OMT) is an extension of SMT which allows for finding models that optimize given objectives. OptiMathSAT is an OMT solver which allows for solving a list of optimization problems on SMT formulas with linear objective functions-on the Boolean, the rational and the integer domains, and on their combination thereof-including (partial weighted) MaxSMT . Multiple and heterogeneous objective functions can be combined together and handled either independently, or lexicographically, or in linear or min-max /max-min combinations. OptiMathSAT provides an incremental interface, it supports both an extended version of the SMT-LIBv2 language and a subset of the FlatZinc language, and can be interfaced via an API. In this paper we describe OptiMathSAT and its usage in full detail.																	0168-7433	1573-0670				MAR	2020	64	3			SI		423	460		10.1007/s10817-018-09508-6													
J								KSP A Resolution-Based Theorem Prover for K-n: Architecture, Refinements, Strategies and Experiments	JOURNAL OF AUTOMATED REASONING										Modal logics; Theorem proving; Resolution method	PROPOSITIONAL MODAL-LOGICS; COMPLETENESS; KNOWLEDGE	In this paper we describe the implementation of KSP, a resolution-based prover for the basic multimodal logic K-n. The prover implements a resolution-based calculus for both local and global reasoning. The user can choose different normal forms, refinements of the basic resolution calculus, and strategies. We describe these options in detail and discuss their implications. We provide experiments comparing some of these options and comparing the prover with other provers for this logic.																	0168-7433	1573-0670				MAR	2020	64	3			SI		461	484		10.1007/s10817-018-09503-x													
J								Scalable Fine-Grained Proofs for Formula Processing	JOURNAL OF AUTOMATED REASONING										SMT; Formula processing; Rewriting; Proof production; Proof reconstruction; Proof checking	CHECKING	We present a framework for processing formulas in automatic theorem provers, with generation of detailed proofs. The main components are a generic contextual recursion algorithm and an extensible set of inference rules. Clausification, skolemization, theory-specific simplifications, and expansion of 'let' expressions are instances of this framework. With suitable data structures, proof generation adds only a linear-time overhead, and proofs can be checked in linear time. We implemented the approach in the SMT solver veriT. This allowed us to dramatically simplify the code base while increasing the number of problems for which detailed proofs can be produced, which is important for independent checking and reconstruction in proof assistants. To validate the framework, we implemented proof reconstruction in Isabelle/HOL.																	0168-7433	1573-0670				MAR	2020	64	3			SI		485	510		10.1007/s10817-018-09502-y													
J								Efficient Verified (UN)SAT Certificate Checking	JOURNAL OF AUTOMATED REASONING										Unsat certificates; SAT solving; DRAT; Isabelle; HOL; Stepwise refinement; Formal verification; Verified software		SAT solvers decide the satisfiability of Boolean formulas in conjunctive normal form. They are commonly used for software and hardware verification. Modern SAT solvers are highly complex and optimized programs. As a single bug in the solver may invalidate the verification of many systems, SAT solvers output certificates for their answer, which are then checked independently. However, even certificate checking requires highly optimized non-trivial programs. This paper presents the first SAT solver certificate checker that is formally verified down to the integer sequence representing the formula. Our tool supports the full DRAT standard, and is even faster than the unverified state-of-the-art tool drat-trim, on a realistic set of benchmarks drawn from the 2016 and 2017 SAT competitions. An optional multi-threaded mode further reduces the runtime, in particular for big certificates.																	0168-7433	1573-0670				MAR	2020	64	3			SI		513	532		10.1007/s10817-019-09525-z													
J								Strong Extension-Free Proof Systems	JOURNAL OF AUTOMATED REASONING										SAT; Propositional proof systems; Proof complexity; Proof checking; Pigeon hole problem; Extended resolution; Clause redundancy	BOUNDED MODEL CHECKING; SATISFIABILITY	We introduce proof systems for propositional logic that admit short proofs of hard formulas as well as the succinct expression of most techniques used by modern SAT solvers. Our proof systems allow the derivation of clauses that are not necessarily implied, but which are redundant in the sense that their addition preserves satisfiability. To guarantee that these added clauses are redundant, we consider various efficiently decidable redundancy criteria which we obtain by first characterizing clause redundancy in terms of a semantic implication relationship and then restricting this relationship so that it becomes decidable in polynomial time. As the restricted implication relation is based on unit propagation-a core technique of SAT solvers-it allows efficient proof checking too. The resulting proof systems are surprisingly strong, even without the introduction of new variables-a key feature of short proofs presented in the proof-complexity literature. We demonstrate the strength of our proof systems on the famous pigeon hole formulas by providing short clausal proofs without new variables.																	0168-7433	1573-0670				MAR	2020	64	3			SI		533	554		10.1007/s10817-019-09516-0													
J								Automatically Verifying Temporal Properties of Pointer Programs with Cyclic Proof	JOURNAL OF AUTOMATED REASONING										Cyclic proof; Temporal logic; Separation logic	VERIFICATION	In this article, we investigate the automated verification of temporal properties of heap-aware programs. We propose a deductive reasoning approach based on cyclic proof. Judgements in our proof system assert that a program has a certain temporal property over memory state assertions, written in separation logic with user-defined inductive predicates, while the proof rules of the system unfold temporal modalities and predicate definitions as well as symbolically executing programs. Cyclic proofs in our system are, as usual, finite proof graphs subject to a natural, decidable soundness condition, encoding a form of proof by infinite descent. We present a proof system tailored to proving CTL properties of nondeterministic pointer programs, and then adapt this system to handle fair execution conditions. We show both versions of the system to be sound, and provide an implementation of each in the Cyclist theorem prover, yielding an automated tool that is capable of automatically discovering proofs of (fair) temporal properties of pointer programs. Experimental evaluation of our tool indicates that our approach is viable, and offers an interesting alternative to traditional model checking techniques.																	0168-7433	1573-0670				MAR	2020	64	3			SI		555	578		10.1007/s10817-019-09532-0													
J								Conflict-Driven Satisfiability for Theory Combination: Transition System and Completeness	JOURNAL OF AUTOMATED REASONING										Theory combination; Conflict-driven decision procedures; Model building; Satisfiability modulo assignment	SAT MODULO THEORIES	Many applications depend on solving the satisfiability of formul AE involving propositional logic and first-order theories, a problem known as Satisfiability Modulo Theory. This article presents a new method for satisfiability modulo a combination of theories, named CDSAT, for Conflict-Driven SATisfiability. CDSAT also solves Satisfiability Modulo Assignment problems that may include assignments to first-order terms. A conflict-driven procedure assigns values to variables to build a model, and performs inferences on demand in order to solve conflicts between assignments and formul AE. CDSAT extends this paradigm to generic combinations of disjoint theories, each characterized by a collection of inference rules called theory module. CDSAT coordinates the theory modules in such a way that the conflict-driven reasoning happens in the union of the theories, not only in propositional logic. As there is no fixed hierarchy with propositional logic at the center and the other theories as satellites, CDSAT offers a flexible framework for model search. We prove the soundness, completeness, and termination of CDSAT, identifying sufficient requirements on theories and modules that ensure these properties.																	0168-7433	1573-0670				MAR	2020	64	3			SI		579	609		10.1007/s10817-018-09510-y													
J								From Chess and Atari to StarCraft and Beyond: How Game AI is Driving the World of AI	KUNSTLICHE INTELLIGENZ											CARLO TREE-SEARCH; DEEP NEURAL-NETWORKS; LEVEL; GO	This paper reviews the field of Game AI, which not only deals with creating agents that can play a certain game, but also with areas as diverse as creating game content automatically, game analytics, or player modelling. While Game AI was for a long time not very well recognized by the larger scientific community, it has established itself as a research area for developing and testing the most advanced forms of AI algorithms and articles covering advances in mastering video games such as StarCraft 2 and Quake III appear in the most prestigious journals. Because of the growth of the field, a single review cannot cover it completely. Therefore, we put a focus on important recent developments, including that advances in Game AI are starting to be extended to areas outside of games, such as robotics or the synthesis of chemicals. In this article, we review the algorithms and methods that have paved the way for these breakthroughs, report on the other important areas of Game AI research, and also point out exciting directions for the future of Game AI.																	0933-1875	1610-1987				MAR	2020	34	1			SI		7	17		10.1007/s13218-020-00647-w													
J								The Many AI Challenges of Hearthstone	KUNSTLICHE INTELLIGENZ										Artificial intelligence; Games; Hearthstone; Deckbuilding; Gameplaying; Player modeling	LEVEL; INTELLIGENCE; GAMES; GO	Since the inception of artificial intelligence, games have benchmarked algorithmic advances. Recent success in classic board games such as Chess and Go have left space for video games that pose related yet different sets of challenges. With this shifted focus, the set of AI problems associated with video games has expanded from simply playing these games to win, to include playing games in particular styles, generating game content, modeling players, etc. Different games pose different challenges for AI systems, and several such AI challenges can typically be addressed in the same game. In this article we analyze the popular collectible card game Hearthstone published by Blizzard in 2014, and describe a varied set of interesting AI challenges it poses. Despite their popularity and associated interesting challenges, collectible card games are relatively understudied in the AI community. By analyzing a single game in-depth, we get a glimpse of the entire field of AI and games through the lens of a single game, discovering a few new variations on existing research topics.																	0933-1875	1610-1987				MAR	2020	34	1			SI		33	43		10.1007/s13218-019-00615-z													
J								Matrix- and Tensor Factorization for Game Content Recommendation	KUNSTLICHE INTELLIGENZ										Player retention; Recommender systems; Latent factor models		Commercial success of modern freemium games hinges on player satisfaction and retention. This calls for the customization of game content or game mechanics in order to keep players engaged. However, whereas game content is already frequently generated using procedural content generation, methods that can reliably assess what kind of content suits a player's skills or preferences are still few and far between. Addressing this challenge, we propose novel recommender systems based on latent factor models that allow for recommending quests in a single player role-playing game. In particular, we introduce a tensor factorization algorithm to decompose collections of bipartite matrices which represent how players' interests and behaviors change over time. Extensive online bucket type tests during the ongoing operation of a commercial game reveal that our system is able to recommend more engaging quests and to retain more players than previous handcrafted or collaborative filtering approaches.																	0933-1875	1610-1987				MAR	2020	34	1			SI		57	67		10.1007/s13218-019-00620-2													
J								Machine-Learning-Based Statistical Arbitrage Football Betting	KUNSTLICHE INTELLIGENZ										Football; Betting strategy; Machine learning; Statistical arbitrage; Sports forecasting	TRADING STRATEGIES; FORECAST ACCURACY; MODEL; PREDICTION; MARKET; SENTIMENT; SCORES; ODDS	Across countries and continents, football (soccer) has drawn increasingly more attention over the last decades and developed into a huge commercial complex. Consequently, the market of bookmakers providing the possibility to bet on the result of football matches grew rapidly, especially with the appearance of the internet. With a high number of games every week in multiple countries, football league matches hold enormous potential for generating profits over time with the use of advanced betting strategies. In this paper, we use machine learning for predicting the outcome of football league matches by exploiting data about match characteristics. Based on insights from the field of statistical arbitrage stock market trading, we show that one could generate meaningful profits over time by betting accordingly. A simulation study analyzing the matches of the five top European football leagues from season 2013/14 to 2017/18 presented economically and statistically significant returns achieved by exploiting large data sets with modern machine learning algorithms. In contrast to these modern algorithms, the break-even point could not be reached with an ordinary linear regression approach or simple betting strategies, e.g. always betting on the home team.																	0933-1875	1610-1987				MAR	2020	34	1			SI		69	80		10.1007/s13218-019-00610-4													
J								AI for Ancient Games Report on the Digital Ludeme Project	KUNSTLICHE INTELLIGENZ										Ancient games; General game systems; Strategy learning; transfer and explanation; Digital Ludeme Project; Digital arch AE oludology		This report summarises the Digital Ludeme Project, a recently launched 5-year research project being conducted at Maastricht University. This computational study of the world's traditional strategy games seeks to improve our understanding of early games, their development, and their role in the spread of related mathematical ideas throughout recorded human history.																	0933-1875	1610-1987				MAR	2020	34	1			SI		89	93		10.1007/s13218-019-00600-6													
J								Uncertainty Handling in Surrogate Assisted Optimisation of Games Dissertation Abstract	KUNSTLICHE INTELLIGENZ										Surrogate-assisted Evolutionary Algorithms; Procedural Content Generation; Uncertainty handling		Real-world problems are often affected by uncertainties of different types and from multiple sources. Algorithms created for expensive optimisation, such as model-based optimisers, introduce additional errors. We argue that these uncertainties should be accounted for during the optimisation process. We thus introduce a benchmark as well as a new surrogate-assisted evolutionary algorithm to investigate this hypothesis further. The benchmark includes two function suites based on procedural content generation for games, which is a common problem observed in games research and also mirrors several types of uncertainties in the real-world. We find that observing and handling the uncertainty present in the problem can improve the optimiser, and also provides valuable insight into the function characteristics.																	0933-1875	1610-1987				MAR	2020	34	1			SI		95	99		10.1007/s13218-019-00613-1													
J								Search, Abstractions and Learning in Real-Time Strategy Games A Dissertation Summary	KUNSTLICHE INTELLIGENZ										Real-time strategy games; Game tree search; Deep convolutional neural networks; Evolutionary algorithms	GO	Real-Time Strategy Games' large state and action spaces pose a significant hurdle to traditional AI techniques. We propose decomposing the game into sub-problems and integrating the partial solutions into action scripts that can be used as abstract actions by a search or machine learning algorithm. The resulting high level algorithm produces sound strategic choices, and can then be combined with a low-level search algorithm to refine tactical choices. We show strong results in SparCraft, Starcraft: Brood War and mu\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\mu $$\end{document}RTS against state-of-the-art agents. We expect advances in RTS AI can be used in commercial videogames for playtesting and game balancing, while also having possible real-world applications.																	0933-1875	1610-1987				MAR	2020	34	1			SI		101	103		10.1007/s13218-019-00614-0													
J								Formation of a Research Discipline Artificial Intelligence and Intellectics at the Technical University of Munich	KUNSTLICHE INTELLIGENZ												Academic Computer Science emerged in Germany at the end of the 1960s. In 2017, the Munich universities celebrated "50 Years of Computer Science in Munich". To this occasion various events were held; also, there was a special issue in the Informatik Spektrum, the official journal of the Gesellschaft fur Informatik e.V. (GI - the German Society for Computer Science) and of associated organizations, as well as an anthology on Computer Science in Munich [1]. One year later, the present authors published a tribute to the research group for Artificial Intelligence/Intellectics at the TUM in a volume of the Deutsche Museum's Preprints series [2], of which the present article is a very brief summary-for much more detailed information and impressions of former group members please refer to this booklet. The Munich group for Artificial Intelligence/Intellectics came into being thanks to academic freedom at German universities, in this case the Technical University of Munich (TUM): A single young scientist is enthusiastic about an idea, a new idea, which has not yet been worked on or supported by any professor at the TUM: Artificial Intelligence or Intellectics. The scientist initiates relationships with other colleagues, nationally and internationally; he is successful, receives research funding, and establishes a research group that asserted itself over almost four decades and influenced and advanced the field. The present article provides a brief history of the group.																	0933-1875	1610-1987				MAR	2020	34	1			SI		109	116		10.1007/s13218-019-00611-3													
J								About block-parallel Boolean networks: a position paper	NATURAL COMPUTING										Discrete dynamical systems; Automata networks; Threshold Boolean networks; Block-parallel updating schedules	REGULATORY NETWORKS; DYNAMICS; DISCRETE; CIRCUITS; FEEDBACK; OSCILLATIONS; ROBUSTNESS; MODULATION; AUTOMATA; SYSTEMS	In automata networks, it is well known that the way entities update their states over time has a major impact on their dynamics. In particular, depending on the chosen update schedule, the underlying dynamical systems may exhibit more or less asymptotic dynamical behaviours such as fixed points or limit cycles. Since such mathematical models have been used in the framework of biological networks modelling, the question of choosing appropriate update schedules has arised soon. In this note, focusing on Boolean networks, our aim is to emphasise that the adequate way of thinking regulations and genetic expression over time is certainly not to consider a wall segregating synchronicity from asynchronicity because they actually complement rather well. In particular, we highlight that specific update schedules, namely block-parallel update schedules, whose intrinsic features are still not known from a theoretical point of view, admit realistic and pertinent properties in the context of biological modelling and deserve certainly more attention from the community.																	1567-7818	1572-9796				MAR	2020	19	1			SI		5	13		10.1007/s11047-019-09779-x													
J								On the influence of the interaction graph on a finite dynamical system	NATURAL COMPUTING										Finite dynamical systems; Boolean networks; Interaction graph; Fixed points; Periodic points; Rank	FIXED-POINTS; MAXIMUM NUMBER; NETWORKS; INFORMATION; SETS	A finite dynamical system (FDS) is a system of multivariate functions over a finite alphabet, that is typically used to model a network of interacting entities. The main feature of a finite dynamical system is its interaction graph, which indicates which local functions depend on which variables; the interaction graph is a qualitative representation of the interactions amongst entities on the network. As such, a major problem is to determine the effect of the interaction graph on the dynamics of the FDS. In this paper, we are interested in three main properties of an FDS: the number of images (the so-called rank), the number of periodic points (the so-called periodic rank) and the number of fixed points. In particular, we investigate the minimum, average, and maximum number of images (or periodic points, or fixed points) of FDSs with a prescribed interaction graph and a given alphabet size; thus yielding nine quantities to study. The paper is split into two parts. The first part considers the minimum rank, for which we derive the first meaningful results known so far. In particular, we show that the minimum rank decreases with the alphabet size, thus yielding the definition of an absolute minimum rank. We obtain lower and upper bounds on this absolute minimum rank, and we give classification results for graphs with very low (or highest) rank. The second part is a comprehensive survey of the results obtained on the nine quantities described above. We not only give a review of known results, but we also give a list of relevant open questions.																	1567-7818	1572-9796				MAR	2020	19	1			SI		15	28		10.1007/s11047-019-09732-y													
J								Boolean dynamics revisited through feedback interconnections	NATURAL COMPUTING										Boolean models; Feedback interconnections; Attractor computation; Asynchronous versus synchronous updates	NETWORKS; MODEL; IDENTIFICATION; ROBUSTNESS; ATTRACTOR; CLOCK	Boolean models of physical or biological systems describe the global dynamics of the system and their attractors typically represent asymptotic behaviors. In the case of large networks composed of several modules, it may be difficult to identify all the attractors. To explore Boolean dynamics from a novel viewpoint, we will analyse the dynamics emerging from the composition of two known Boolean modules. The state transition graphs and attractors for each of the modules can be combined to construct a new asymptotic graph which will (1) provide a reliable method for attractor computation with partial information; (2) illustrate the differences in dynamical behavior induced by the updating strategy (asynchronous, synchronous, or mixed); and (3) show the inherited organization/structure of the original network's state transition graph.																	1567-7818	1572-9796				MAR	2020	19	1			SI		29	49		10.1007/s11047-018-9716-8													
J								Maximum sensitivity to update schedules of elementary cellular automata over periodic configurations	NATURAL COMPUTING										Synchronism sensitivity; Elementary cellular automata; Update digraph		This work is a thoughtful extension of the ideas sketched in Montalva et al. (AUTOMATA 2017 exploratory papers proceedings, 2017), aiming at classifying elementary cellular automata (ECA) according to their maximal one-step sensitivity to changes in the schedule of cells update. It provides a complete classification of the ECA rule space for all period sizes n[ 9 and, together with the classification for all period sizes n <= 9 presented in Montalva et al. (Chaos Solitons Fractals 113:209-220, 2018), closes this problem and opens further questionings. Most of the 256 ECA rule's sensitivity is proved or disproved to be maximum thanks to an automatic application of basic methods. We formalize meticulous case disjunctions that lead to the results, and patch failing cases for some rules with simple arguments. This gives new insights on the dynamics of ECA rules depending on the proof method employed, as for the last rules 45 and 105 requiring o0011THORN induction patterns.																	1567-7818	1572-9796				MAR	2020	19	1			SI		51	90		10.1007/s11047-019-09743-9													
J								Concurrency in Boolean networks	NATURAL COMPUTING										Discrete dynamical systems; Models of concurrency; Synchronism; Reachability	REGULATORY NETWORKS; UPDATE SCHEDULES; FIXED-POINTS; PETRI NETS; STABILITY; CYCLES; NUMBER	Boolean networks (BNs) are widely used to model the qualitative dynamics of biological systems. Besides the logical rules determining the evolution of each component with respect to the state of its regulators, the scheduling of component updates can have a dramatic impact on the predicted behaviours. In this paper, we explore the use of Read (contextual) Petri Nets (RPNs) to study dynamics of BNs from a concurrency theory perspective. After showing bi-directional translations between RPNs and BNs and analogies between results on synchronism sensitivity, we illustrate that usual updating modes for BNs can miss plausible behaviours, i.e., incorrectly conclude on the absence/impossibility of reaching specific configurations. We propose an encoding of BNs capitalizing on the RPN semantics enabling more behaviour than the generalized asynchronous updating mode. The proposed encoding ensures a correct abstraction of any multivalued refinement, as one may expect to achieve when modelling biological systems with no assumption on its time features.																	1567-7818	1572-9796				MAR	2020	19	1			SI		91	109		10.1007/s11047-019-09748-4													
J								Generation and robustness of Boolean networks to model Clostridium difficile infection	NATURAL COMPUTING										Threshold network; Neutral space; Evolutionary computation; Microbiome; Clostridium difficile infection	REGULATORY NETWORKS; GUT MICROBIOTA; COLONIZATION	One of the more common healthcare associated infection is Chronic diarrhea. This disease is caused by the bacterium Clostridium difficile which alters the normal composition of the human gut flora. The most successful therapy against this infection is the fecal microbial transplant (FMT). They displace C. difficile and contribute to gut microbiome resilience, stability and prevent further episodes of diarrhea. The microorganisms in the FMT their interactions and inner dynamics reshape the gut microbiome to a healthy state. Even though microbial interactions play a key role in the development of the disease, currently, little is known about their dynamics and properties. In this context, a Boolean network model for C. difficile infection (CDI) describing one set of possible interactions was recently presented. To further explore the space of possible microbial interactions, we propose the construction of a neutral space conformed by a set of models that differ in their interactions, but share the final community states of the gut microbiome under antibiotic perturbation and CDI. To begin with the analysis, we use the previously described Boolean network model and we demonstrate that this model is in fact a threshold Boolean network (TBN). Once the TBN model is set, we generate and use an evolutionary algorithm to explore to identify alternative TBNs. We organize the resulting TBNs into clusters that share similar dynamic behaviors. For each cluster, the associated neutral graph is constructed and the most relevant interactions are identified. Finally, we discuss how these interactions can either affect or prevent CDI.																	1567-7818	1572-9796				MAR	2020	19	1			SI		111	134		10.1007/s11047-019-09730-0													
J								Spiking neural networks modelled as timed automata: with parameter learning	NATURAL COMPUTING										Neural networks; Parameter learning; Timed automata; Temporal logic; Model checking		In this paper we address the issue of automatically learning parameters of spiking neural networks. Biological neurons are formalized as timed automata and synaptical connections are represented as shared channels among these automata. Such a formalism allows us to take into account several time-related aspects, such as the influence of past inputs in the computation of the potential value of each neuron, or the presence of the refractory period, a lapse of time immediately following the spike emission in which the neuron cannot emit. The proposed model is then formally validated: more precisely, we ensure that some relevant properties expressed as temporal logical formulae hold in the model. Once the validation step is accomplished, we take advantage of the proposed model to write an algorithm for learning synaptical weight values such that an expected behavior can be displayed. The technique we present takes inspiration from supervised learning ones: we compare the effective output of the network to the expected one and backpropagate proper corrective actions in the network. We develop several case studies including a mutual inhibition network.																	1567-7818	1572-9796				MAR	2020	19	1			SI		135	155		10.1007/s11047-019-09727-9													
J								Bionic vision system and its application in license plate recognition	NATURAL COMPUTING										Bionic vision system; Visual attention; Super-resolution; Sparse coding; Convolutional neural networks	VISUAL-ATTENTION; SUPERRESOLUTION	Conventional computer vision systems detect object after super-resolution (SR) or image reconstruction of the whole image, which is not an economical manner. By imitating the visual system of human beings, we proposed the bionic vision system (BVS), which is mainly composed by three parts: object detection by visual attention model, object-oriented SR reconstruction and object recognition by convolutional neural networks. The visual attention model contains both bottom-up and top-down cues. The bottom-up cues integrate low-level features by the feature integration theory. An Adaboost detector imitates the top-down cues. Sparse coding and compressed sensing reconstruction realize the object-oriented SR reconstruction. The BVS was validated on license plate recognition task. Both detection performance and SR reconstruction performance are tested. Besides of these, we also test the final recognition rate, all the experimental results are quite encouraging.																	1567-7818	1572-9796				MAR	2020	19	1			SI		199	209		10.1007/s11047-019-09746-6													
J								A self-adaptive multi-population differential evolution algorithm	NATURAL COMPUTING										Evolutionary algorithm; Differential evolution; Multi-population; Self-adaptive; Numerical optimization	REAL-PARAMETER OPTIMIZATION; ENSEMBLE	Differential evolution (DE) is an efficient population-based search algorithm for solving numerical optimization problems. However, the performance of DE is very sensitive to the choice of mutation strategies and their associated control parameters. In this paper, we propose a self-adaptive multi-population differential evolution algorithm, called SAMDE. The population is randomly divided into three equally sized sub-populations, each with different mutation strategies. At the end of each generation, all sub-populations are updated independently and recombined. Each sub-population uses an adaptive mechanism for selecting how current generation control parameters are generated. An improved mutation strategy, "rand assemble/1", is proposed, its base vector is composed proportionally of three randomly selected individuals. The performance of SAMDE is evaluated on the suite of CEC 2005 benchmark functions. A comparative study is carried out with other state-of-the-art optimization techniques. The results show that SAMDE has a competitive performance compared to several other efficient DE variants.																	1567-7818	1572-9796				MAR	2020	19	1			SI		211	235		10.1007/s11047-019-09757-3													
J								From electric circuits to chemical networks	NATURAL COMPUTING										Electric circuits; Chemical reaction networks; Differential-algebraic system of equations		Electric circuits manipulate electric charge and magnetic flux via a small set of discrete components to implement useful functionality over continuous time-varying signals represented by currents and voltages. Much of the same functionality is useful to biological organisms, where it is implemented by a completely different set of discrete components (typically proteins) and signal representations (typically via concentrations). We describe how to take a linear electric circuit and systematically convert it to a chemical reaction network of the same functionality, as a dynamical system. Both the structure and the components of the electric circuit are dissolved in the process, but the resulting chemical network is intelligible. This approach provides access to a large library of well-studied devices, from analog electronics, whose chemical network realization can be compared to natural biochemical networks, or used to engineer synthetic biochemical networks.																	1567-7818	1572-9796				MAR	2020	19	1			SI		237	248		10.1007/s11047-019-09761-7													
J								Approximate majority analyses using tri-molecular chemical reaction networks	NATURAL COMPUTING										Approximate Majority; Chemical reaction networks; Population protocols	COMPUTATION; CONSENSUS	Approximate Majority is a well-studied problem in the context of chemical reaction networks (CRNs) and their close relatives, population protocols: Given a mixture of two types of species with an initial gap between their counts, a CRN computation must reach consensus on the majority species. Angluin, Aspnes, and Eisenstat proposed a simple population protocol for Approximate Majority and proved correctness and Oolog nTHORN time efficiency with high probability, given an initial gap of size xo ffiffiffinp log nTHORN when the total molecular count in the mixture is n. Motivated by their intriguing but complex proof, we provide a new analysis of several CRNs for Approximate Majority, starting with a very simple trimolecular protocol with just two reactions and two species. We obtain simple analyses of three bi-molecular protocols, including that of Angluin et al., by showing how they emulate the tri-molecular protocol. Our results improve on those of Angluin et al. in that they hold even with an initial gap of Xo root n log n log np THORN. We prove that our tri-molecular CRN is robust even when there is some uncertainty in the reaction rates, when some molecules are Byzantine (i.e., adversarial), or when activation of molecules is triggered by epidemic. We also analyse a natural variant of our tri-molecular protocol for the more general problem of multi-valued consensus. Our analysis approach, which leverages the simplicity of a tri-molecular CRN to ultimately reason about these many variants, may be useful in analysing other CRNs too.																	1567-7818	1572-9796				MAR	2020	19	1			SI		249	270		10.1007/s11047-019-09756-4													
J								Finding next of kin: Cross-lingual embedding spaces for related languages	NATURAL LANGUAGE ENGINEERING										Multilinguality; Text classification; Cross-lingual embeddings	WEB	Some languages have very few NLP resources, while many of them are closely related to better-resourced languages. This paper explores how the similarity between the languages can be utilised by porting resources from better- to lesser-resourced languages. The paper introduces a way of building a representation shared across related languages by combining cross-lingual embedding methods with a lexical similarity measure which is based on the weighted Levenshtein distance. One of the outcomes of the experiments is a Panslavonic embedding space for nine Balto-Slavonic languages. The paper demonstrates that the resulting embedding space helps in such applications as morphological prediction, named-entity recognition and genre classification.																	1351-3249	1469-8110				MAR	2020	26	2					163	182	PII S1351324919000354	10.1017/S1351324919000354													
J								Designing a virtual patient dialogue system based on terminology-rich resources: Challenges and evaluation	NATURAL LANGUAGE ENGINEERING										Dialogue system; Virtual patient; Terminology; Language resources	STANDARDIZED-PATIENT; SPOKEN DIALOGUE; UMLS; GENERATION; STUDENTS; HISTORY	Virtual patient software allows health professionals to practise their skills by interacting with tools simulating clinical scenarios. A natural language dialogue system can provide natural interaction for medical history-taking. However, the large number of concepts and terms in the medical domain makes the creation of such a system a demanding task. We designed a dialogue system that stands out from current research by its ability to handle a wide variety of medical specialties and clinical cases. To address the task, we designed a patient record model, a knowledge model for the task and a termino-ontological model that hosts structured thesauri with linguistic, terminological and ontological knowledge. We used a frame- and rule-based approach and terminology-rich resources to handle the medical dialogue. This work focuses on the termino-ontological model, the challenges involved and how the system manages resources for the French language. We adopted a comprehensive approach to collect terms and ontological knowledge, and dictionaries of affixes, synonyms and derivational variants. Resources include domain lists containing over 161,000 terms, and dictionaries with over 959,000 word/concept entries. We assessed our approach by having 71 participants (39 medical doctors and 32 non-medical evaluators) interact with the system and use 35 cases from 18 specialities. We conducted a quantitative evaluation of all components by analysing interaction logs (11,834 turns). Natural language understanding achieved an F-measure of 95.8%. Dialogue management provided on average 74.3 (+/- 9.5)% of correct answers. We performed a qualitative evaluation by collecting 171 five-point Likert scale questionnaires. All evaluated aspects obtained mean scores above the Likert mid-scale point. We analysed the vocabulary coverage with regard to unseen cases: the system covered 97.8% of their terms. Evaluations showed that the system achieved high vocabulary coverage on unseen cases and was assessed as relevant for the task.																	1351-3249	1469-8110				MAR	2020	26	2					183	220	PII S1351324919000329	10.1017/S1351324919000329													
J								A new approach for textual feature selection based on N-composite isolated labels	NATURAL LANGUAGE ENGINEERING										Textual features; Formal concept; Composite isolated point; Difunctional relation		Textual Feature Selection (TFS) aims to extract relevant parts or segments from text as being the most relevant ones w.r.t. the information it expresses. The selected features are useful for automatic indexing, summarization, document categorization, knowledge discovery, so on. Regarding the huge amount of electronic textual data daily published, many challenges related to the semantic aspect as well as the processing efficiency are addressed. In this paper, we propose a new approach for TFS based on Formal Concept Analysis background. Mainly, we propose to extract textual features by exploring the regularities in a formal context where isolated points exist. We introduce the notion of N-composite isolated points as a set of N words to be considered as a unique textual feature. We show that a reduced value of N (between 1 and 3) allows extracting significant textual features compared with existing approaches even for non-completely covering an initial formal context.																	1351-3249	1469-8110				MAR	2020	26	2					221	243	PII S1351324919000160	10.1017/S1351324919000160													
J								Emerging trends: Reviewing the reviewers (again)	NATURAL LANGUAGE ENGINEERING										Reviewing; Growth; Randomness; Scale		The ACL-2019 Business meeting ended with a discussion of reviewing. Conferences are experiencing a success catastrophe. They are becoming bigger and bigger, which is not only a sign of success but also a challenge (for reviewing and more). Various proposals for reducing submissions were discussed at the Business meeting. IMHO, the problem is not so much too many submissions, but rather, random reviewing. We cannot afford to do reviewing as badly as we do (because that leads to even more submissions). Negative feedback loops are effective. The reviewing process will improve over time if reviewers teach authors how to write better submissions, and authors teach reviewers how to write more constructive reviews. If you have received a not-ok (unhelpful/offensive) review, please help program committees improve by sharing your not-ok reviews on social media.																	1351-3249	1469-8110				MAR	2020	26	2					245	257	PII S1351324920000030	10.1017/S1351324920000030													
J								Adjustable loads control and stochastic stability analysis for multi-energy generation system based on Markov model	NEURAL COMPUTING & APPLICATIONS										Multi-energy generation system; Renewable energy; Markov model; Stochastic stability	HIGH PENETRATION; POWER-SYSTEMS; SMALL-SIGNAL; FLEXIBILITY; STABILIZATION	This paper mainly addresses the issue of the power generation fluctuations due to the stochastic characteristics of the renewable energies, which threaten the stability of the power grid. First, the multi-energy generation system with integration of wind and photovoltaic power is modeled in the framework of Markov model to describe the dynamic changes. Second, to weaken the active power fluctuation of renewable energies generation and improve the utilization of renewable energies, the flexible loads are added for local consumption and an adjustable load control strategy is proposed to guarantee the output power continuous stability of the renewable energies generation. Then, the stochastic stability is analyzed by using Markov stability theory. Finally, the simulation results and analysis are provided to illustrate the effectiveness of the proposed schemes.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1517	1529		10.1007/s00521-019-04120-0													
J								An improved genetic algorithm using greedy strategy toward task scheduling optimization in cloud environments	NEURAL COMPUTING & APPLICATIONS										Cloud computing; Genetic algorithm; Greedy strategy; Task scheduling optimization	MANAGEMENT	Cloud computing is an emerging distributed system that provides flexible and dynamically scalable computing resources for use at low cost. Task scheduling in cloud computing environment is one of the main problems that need to be addressed in order to improve system performance and increase cloud consumer satisfaction. Although there are many task scheduling algorithms, existing approaches mainly focus on minimizing the total completion time while ignoring workload balancing. Moreover, managing the quality of service (QoS) of the existing approaches still needs to be improved. In this paper, we propose a novel algorithm named MGGS (modified genetic algorithm (GA) combined with greedy strategy). The proposed algorithm leverages the modified GA algorithm combined with greedy strategy to optimize task scheduling process. Different from existing algorithms, MGGS can find an optimal solution using fewer number of iterations. To evaluate the performance of MGGS, we compared the performance of the proposed algorithm with several existing algorithms based on the total completion time, average response time, and QoS parameters. The results obtained from the experiments show that MGGS performs well as compared to other task scheduling algorithms.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1531	1541		10.1007/s00521-019-04119-7													
J								Research on supply chain partner selection method based on BP neural network	NEURAL COMPUTING & APPLICATIONS										Supply chain; Partnership; Index construction; BP neural network	FUZZY; MANAGEMENT	In the process of establishing supply chain partnership, partner selection is the key and main step. If the enterprise selects the appropriate supply chain partner, in the material equipment unit price, the material equipment production and the supply ability, the product quality appraisal, the brand meets the demand, the new product development ability, has the bad record, the historical project performance, management system and management level, service level, human resource level, internal information processing level, historical cooperation situation, cooperation will, corporate culture and strategic fit degree, financing support ability, information transmission ability, Enterprise green idea propaganda, product energy consumption or energy consumption ratio, green building project participation in construction, environmental protection and energy-saving product development investment, toxic and harmful raw materials use, green matter The use of flowing green packaging, the use of recycled materials/product recycling, and the treatment of industrial "three wastes" will all produce a series of advantages that cannot be matched by traditional relationships. Then, the whole supply chain competitiveness will be improved. This paper studies the selection and evaluation of the partners in the supply chain environment from the point of view of the current research situation of the cooperative relationship in the supply chain environment at home and abroad. Based on the relevant research results at home and abroad, according to certain principles and methods, combined with experts' evaluation of the future trend of qualitative indicators, a set of evaluation index system of supply chain partners is constructed. The standardized treatment of evaluation index is given. By comparing and analyzing the advantages and disadvantages of the common evaluation methods, the mature BP neural network is applied to the artificial neural network by using the artificial neural network evaluation method. MATLAB software is used to construct neural network. BP neural network is used for training and the trained neural network is used to evaluate an example. The results show that this method can solve the problem of partner selection and evaluation in supply chain environment, and improve the evaluation efficiency.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1543	1553		10.1007/s00521-019-04136-6													
J								Research on path planning of mobile robot based on improved ant colony algorithm	NEURAL COMPUTING & APPLICATIONS										Path planning; Ant colony algorithm; Mobile robot; Pheromone	OPTIMIZATION	To solve the problems of local optimum, slow convergence speed and low search efficiency in ant colony algorithm, an improved ant colony optimization algorithm is proposed. The unequal allocation initial pheromone is constructed to avoid the blindness search at early planning. A pseudo-random state transition rule is used to select path, the state transition probability is calculated according to the current optimal solution and the number of iterations, and the proportion of determined or random selections is adjusted adaptively. The optimal solution and the worst solution are introduced to improve the global pheromone updating method. Dynamic punishment method is introduced to solve the problem of deadlock. Compared with other ant colony algorithms in different robot mobile simulation environments, the results showed that the global optimal search ability and the convergence speed have been improved greatly and the number of lost ants is less than one-third of others. It is verified the effectiveness and superiority of the improved ant colony algorithm.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1555	1566		10.1007/s00521-019-04172-2													
J								Productive service demands modularization for CNC machine tools based on the improved AP clustering algorithm	NEURAL COMPUTING & APPLICATIONS										Improved AP algorithm; Productive service; Clustering analysis; Demands modularization	DESIGN	The integration of manufacturing and service industry has become the mainstream trend. During the manufacturing process, CNC machine tools, as large-scale and complex equipment, involve a variety of service demands in the life cycle, especially the productive service demands are numerous and scattered. The article established the correlation model between customer demands and productive service demands based on clustering ideas and mathematical statistics theory to complete the modularization of productive service demands for CNC machine tools. A comprehensive correlation coefficient model and an improved AP clustering algorithm were put forward. The comprehensive correlation coefficient model mined the correlation between customer demand and production service demand and the self-correlation of production service demands directly based on the combination weight obtained by the analytic hierarchy process and rough set theory. The improved AP clustering algorithm was the combination of AP and Kruskal minimum tree principle. By this new algorithm, the clustering project of productive service demands for every customer demand could be attained. Finally, the five matrices can be computed in 1083 ms, 1067 ms, 1029 ms, 1149 ms and 1042 ms, respectively, by the improved AP clustering algorithm. However, the original AP method should spend 1122 ms, 1241 ms, 1231 ms, 1383 ms and 1231 ms, respectively. So it was very clear that the improved AP clustering algorithm can improve the data processing efficiency.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1567	1579		10.1007/s00521-019-04173-1													
J								An improved particle swarm algorithm to optimize PID neural network for pressure control strategy of managed pressure drilling	NEURAL COMPUTING & APPLICATIONS										Managed pressure drilling; Wellhead back pressure; Pressure control; Throttle valve		The bottom hole pressure (BHP) of managed pressure drilling (MPD) is a typically unstable object with hysteresis that is difficult to be directly controlled. However, at the present stage, BHP control still focuses on conventional PID control and simple intelligent control, requiring repeated data alignment. There are some related problems, such as lack of control over BHP, longer working hours and high cost of drilling. In order to increase economic effects of MPD, this paper analyzes the MPD system and utilizes wellhead back pressure as the controlled variable. According to throttle valve features, basic parameters and boundary conditions of MPD, a mathematical model of throttle valve is also calculated. Besides, this paper focuses on studying the control model and proposes an improved particle swarm algorithm to optimize PID neural network (IPSOPIDNN) model. This model is improved based on inertia weight and fitness function of conventional particle swarm algorithm. Moreover, the particle swarm algorithm is used to optimize the initial weight value of PID neural network, shorten the search time for optimal value of particle swarm, and reduce the chance of local minimum. The real-time control results of IPSO-PIDNN are compared with results of traditional particle swarm optimization PID neural network (PSO-PIDNN) and particle swarm optimization PID neural network (PSO-PIDNN). IPSO-PIDNN control system has some advantages, including favorable self-learning, optimization quality, high levels of control precision, no overshoot, rapid response and short setting time. In this way, advanced automation control of BHP is conducted during managed pressure drilling process, thus providing technical support for the well control safety of managed pressure drilling.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1581	1592		10.1007/s00521-019-04192-y													
J								Research on sound classification based on SVM	NEURAL COMPUTING & APPLICATIONS										Support vector machine; Audio segmentation; Audio classification; Audio signal preprocessing	SEGMENTATION	Sound is a ubiquitous natural phenomenon that contains a wealth of information that constantly enhances our understanding of the objective world. With the continuous development of computer network technology and communication technology, audio information has become a very important part. Audio is a non-semantic symbolic representation and an unstructured binary stream. Because the audio itself lacks the description of content semantics and structured organization, it brings great difficulty to the audio classification work. The research of digital audio classification will become more and more important with the increasing number of digital audio resources in the network. Digital audio classification technology is the key technology to solve this problem. It is the key to solve the problem of audio structure and extract audio structured information and content semantics. It is a research hot spot in the field of audio analysis. It has important application value in many fields, such as audio retrieval, video summary and auxiliary video analysis. This paper studies the structure of audio, the analysis and extraction of audio features, the digital audio classifier based on support vector machines (SVM) and the audio segmentation technology based on BCI. SVM is an important achievement of machine learning research in recent years. As a new machine learning method, SVM can solve practical problems such as small sample, nonlinearity and high dimension, so it has become a new research hot spot after the study of neural network. Experiments show that the SVM-based audio classification algorithm has good classification effect, and the smoothed audio segmentation results are more accurate. With the further development of the research, the research results will be well applied in practice.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1593	1607		10.1007/s00521-019-04182-0													
J								Stock price prediction based on deep neural networks	NEURAL COMPUTING & APPLICATIONS										Financial data prediction; Neural networks; Deep learning; Phase-space reconstruction	TIME-SERIES	Understanding the pattern of financial activities and predicting their development and changes are research hotspots in academic and financial circles. Because financial data contain complex, incomplete and fuzzy information, predicting their development trends is an extremely difficult challenge. Fluctuations in financial data depend on a myriad of correlated constantly changing factors. Therefore, predicting and analysing financial data are a nonlinear, time-dependent problem. Deep neural networks (DNNs) combine the advantages of deep learning (DL) and neural networks and can be used to solve nonlinear problems more satisfactorily compared to conventional machine learning algorithms. In this paper, financial product price data are treated as a one-dimensional series generated by the projection of a chaotic system composed of multiple factors into the time dimension, and the price series is reconstructed using the time series phase-space reconstruction (PSR) method. A DNN-based prediction model is designed based on the PSR method and a long- and short-term memory networks (LSTMs) for DL and used to predict stock prices. The proposed and some other prediction models are used to predict multiple stock indices for different periods. A comparison of the results shows that the proposed prediction model has higher prediction accuracy.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1609	1628		10.1007/s00521-019-04212-x													
J								First arrivals picking based on graph signal theory	NEURAL COMPUTING & APPLICATIONS										Seismic exploration; First arrival; Graph signal processing; Non-connectivity	RECONSTRUCTION	Picking first arrivals is a fundamental but not easy task in the oil seismic exploration, especially in situations where the signal-to-noise ratios are very low. The paper proposed a new picking algorithm with the emerging new graph signal processing technology in the signal processing field. Fundamentally, first arrival picking is actually as a problem to recognize direct seismic waves among background noises. It is apparently that background noises and the direct waves are from different sources, and therefore, there is no connectivity among them, which formulates the fundamentals of the proposed method. With the help of graph signal processing theory, such non-connectivity is fully explored and cast into an optimization problem for picking the first arrivals in oil exploration. From simulations and real measurements results, the proposed method is validated for first arrival picking with good performances, especially in situations with low signal-to-noise ratios.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1629	1637		10.1007/s00521-019-04209-6													
J								The regulatory warning model of regional product quality based on the back-propagation artificial neural network	NEURAL COMPUTING & APPLICATIONS										Regional product quality; Warning model; BP artificial neural network; Predetermination	CUSTOMER SATISFACTION; SUPPLY CHAINS; COMPETITION; INDEX; POLICIES; IMPACT; GREEN	Accidents of product quality occur in food, medicine and industrial products, posing a major risk to consumers. Prediction and control of accidents spread are difficult, mainly due to the complexity of the interaction between stakeholders involved. The regulatory policies formulated by the government play a key role in the regional product quality. In the perspective of government regulation, this paper focuses on the regulatory warning model of regional product quality. In reference to the regional competitiveness index and customer satisfaction index system, the regulatory warning index system is established, according to the four aspects of regional economic development, residential living standard, situation of industrial enterprise and government regulation. In this work, the warning model based on back-propagation artificial neural network is introduced; the quantitative results shows that the predicted value is highly consistent with the actual value after conducting the empirical research on the warning model, using the data of Shandong Province from 2000 to 2013. The study demonstrates that early warning indicators could be useful for the prediction of accidents of regional product quality through back-propagation artificial neural network model. The results may also be useful to government to improve the performance of regulation.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1639	1648		10.1007/s00521-019-04188-8													
J								A novel recommendation system via L0-regularized convex optimization	NEURAL COMPUTING & APPLICATIONS										Recommendation algorithm; Convex optimization; Educational information system; Machine learning		In recent decades, a variety of educational management information systems have been presented due to the increase in social requirement globally. Meanwhile, the students in the Universities have also experienced the benefits brought by these platforms for retrieving, acquiring, and leveraging the education resources that might improve their academic performance accordingly. However, most of the previously presented techniques neglected the course recommendation algorithms following the students' objectives. To bright this gap between the practical requirements and the applications, one convex optimization-based framework with one L0 regularization and the constraint on the learners' characteristics was presented. To evaluate the proposed method, the comparison experiments were conducted between the state-of-the-art recommendation techniques and ours. Experimental results demonstrated the superior performance of the proposed approach over the previous algorithms especially in accuracy.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1649	1663		10.1007/s00521-019-04213-w													
J								Trusted forensics scheme based on digital watermark algorithm in intelligent VANET	NEURAL COMPUTING & APPLICATIONS										Trusted forensics; Security; Digital watermark; VANET		Trusted forensics is one of the most important problems in VANET, and it often needs continuous video monitoring, once break out emergent vehicle accidents, then specific staff members take steps for forensics to obtain facts and define responsibility. Traditional forensics exists problems of inaccurate information, unfair responsibility definition and risk of leakage of user's privacy. To solve the above problem, in this paper, we proposed a trusted forensics scheme based on digital image watermark in intelligent VANET, in which we proposed technical and fair algorithms for trusted forensics, and the trusted forensics scheme includes basic forensics parameter data obtaining critical forensics data automatic generation and forensics data extraction. Once there vehicle accident occurred, the forensics system first obtains the location, timestamp, forensics device data as basic forensics parameter data, and then, it embeds the forensics parameter as watermark into the real-time vehicle accident photograph by the proposed digital watermark algorithm, and thus, the real-time and undeniable forensics data are automatic generated as evidence; when necessary, the forensics system can extract the evidence data and watermark data from the critical forensics data. The proposed scheme can detect the content integrity of image data and even find out tampering mark when the image data are tampered. Additionally, we used neural network algorithm for vehicle license plate recognition and rapid vehicle information gathering. Finally, experiments evaluations manifest the proposed is forensics scheme is secure, robust, and efficient in vehicle forensics.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1665	1678		10.1007/s00521-019-04246-1													
J								Research on location selection model of distribution network with constrained line constraints based on genetic algorithm	NEURAL COMPUTING & APPLICATIONS										Facility location problem; Restricted line constraint; Vehicle path; Bi-level programming	OPTIMIZATION ALGORITHM	With the rapid rise of the Internet, China's e-commerce has also flourished. The development of e-commerce has led to an increase in the volume of logistics and distribution. The further development of e-commerce has also placed higher demands on the timeliness of logistics and distribution. The competition of e-commerce companies has shifted from the competition between business models to the competition between logistics services. The scientific and rational distribution site selection planning is the prerequisite and guarantee for the efficient operation of logistics distribution network. To balance the contradiction between logistics distribution speed and distribution cost has become the key to competition among e-commerce companies. This paper analyzes the current network structure and distribution mode of e-commerce logistics city distribution, and analyzes and discusses the problems existing in current e-commerce logistics city distribution. Furthermore, the bi-level programming is studied. According to the characteristics of the bi-level programming problem, the genetic algorithm flow suitable for bi-level programming is proposed. The bi-level programming model of urban distribution service network site selection with limited lines is proposed. Through the verification of the genetic algorithm in this paper, the proposed method can plan a reasonable service site location layout and distribution models and path selection. The results show that the average daily fuel cost can be reduced by 37.6%, and the transportation distance and fuel cost can be optimized best.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1679	1689		10.1007/s00521-019-04257-y													
J								Research on manufacturing service combination optimization based on neural network and multi-attribute decision making	NEURAL COMPUTING & APPLICATIONS										Multi-attribute decision making; Neural network; Model optimization; Supply chain management	MEAN OPERATORS; ATTRIBUTE	As an important branch of modern decision-making science, the theory and method of multi-attribute decision making have been widely used in many fields, such as society, economy, management and military affairs. Automobile industry as one of the typical manufacturing industries, in this wave, ushered in a transformation and upgrade to get rid of the current weaknesses and difficulties of rare historical development opportunities. Under the environment of Internet and big data, the construction of a new production and operation organization model of the smart car industry will promote its transformation in product planning, design, production, marketing and operation and maintenance. It is propitious to realize the service innovation facing the whole life cycle of the product. In view of this, this paper applies multi-attribute decision making to automobile manufacturing and service industry, taking 14 attributes of manufacturing and six attributes of automobile service as input, and training by BP neural. Finally, an example is given to verify the effectiveness of the method, and the average accuracy is 93.19%.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1691	1700		10.1007/s00521-019-04241-6													
J								Spatiotemporal analysis of trajectory for a new real-time bus routes updated model	NEURAL COMPUTING & APPLICATIONS										GPS trajectory data; Spatial analysis method; RT-BRU model; Bus routes	ARRIVAL-TIME; PREDICTION MODEL; PATTERNS	With the development of location-based service, the wide range of applications of trajectory data obtained by GPS has made great contributions to the analysis of urban buses information. Affected by the increasing quantity of data, filtering out valid GPS trajectory data to update real-time information of urban buses faces new difficulties. In this study, a prototype model named Real-Time Bus Routes Updated model (RT-BRU) is developed to process and mine the GPS trajectory data collected from each urban bus of each interval. The main purpose of this model is to update real-time information of urban bus routes and provide much more realistic public navigation data with the help of trajectory data and geo-statistical tools. Compared to the regular algorithms and Chinese public navigation map data, the experiment results show that the RT-BRU model proposed here can discover more types of urban bus's updated routes and play better in perspective of GPS points counts, operation time, calculation results, correct results and accuracy.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1701	1713		10.1007/s00521-019-04244-3													
J								Government subsidies-based profits distribution pattern analysis in closed-loop supply chain using game theory	NEURAL COMPUTING & APPLICATIONS										Closed-loop supply chain; Government subsidies; Profits distribution pattern; Game theory	COMPETITION; COLLECTION; DECISIONS; REVERSE; DESIGN; NETWORK; MODELS; FUZZY	In closed-loop supply chain, the profits distribution pattern tends towards a comparatively stable status due to complete market competition. However, after introducing government subsidies, the former profits distribution pattern will be destroyed and tend towards a new one. This paper studies differences between the two statuses in the background of new replacement policy of household appliances in China using game theory. We develop two profits distribution models under no government subsidies and under government subsidies in closed-loop supply chain. By comparing the members' profits distribution in the two models, we find that government could control the profits distribution pattern by adjusting government subsidy rate. In addition, we show that average of subsidies, subsidy rate and subsidy limit influence the effects of government subsidies policy significantly.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1715	1724		10.1007/s00521-019-04245-2													
J								Research on basic theory of space fault network and system fault evolution process	NEURAL COMPUTING & APPLICATIONS										Safety system engineering; System reliability; Space fault network; System fault evolution	DIAGNOSIS; DESIGN	To describe the system fault evolution process, the space fault network theory is proposed. Space fault network theory is the third stage of space fault tree theory. The paper introduces the basic research results of space fault network. The basic ideas, basic definitions and corresponding physical meanings of space fault network are discussed. The properties, structure and space fault tree transformation method of space fault network are further studied. The characteristics of the system fault evolution process and its four elements are discussed. The representation methods of space fault network for system fault evolution process are presented. The transformation methods of the general space fault network and multidirectional ring space fault network into space fault tree are given and studied. In particular, the classification and characteristics of unidirectional ring space fault network are studied in detail. Based on the system fault evolution process of the example, we conducted a qualitative analysis, and a space fault network is established and transformed. At the same time, a quantitative analysis is carried out according to the derivation process of the transformation of multidirectional ring space fault network. The results show that the space fault network can effectively describe and analyze the system fault evolution process. This paper has solved some basic problems of system fault evolution process, but more complicated situations need further research.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1725	1744		10.1007/s00521-019-04247-0													
J								Research on context-aware group recommendation based on deep learning	NEURAL COMPUTING & APPLICATIONS										Deep learning; Artificial intelligence; CBOW; Contextual awareness convolution neural network	OPTIMIZATION; SELECTION; CLASSIFICATION; ALGORITHM; IMAGE	In the field of artificial intelligence, the development of many technologies requires technical support for relational classification. Recently, deep learning has been applied more and more to text-based entity relationship classification tasks, but most of the previous methods need to use syntax or dependency structure feature. However, due to the time and space complexity of syntactic parsing, the structural features are inconvenient to use directly in the pre-processing stage. In addition, structural features may have serious domain dependence problems. This paper studies the current recommendation algorithm, analyzes the current research status of the recommendation system, and deeply analyzes the research of deep learning in the field of recommendation systems, based on BPSO algorithm, the context complex segmentation method is applied, and then the deep convolutional neural network is applied for feature extraction. The extracted feature set is sent to WordEmbedding, and using the technology to generates the word vector, the input layer of the CBOW is used to represent the size of the training window. The experimental results show that the model has obvious advantages over the methods proposed in other literature. It can adapt to multi-category context semantic analysis, more accurate related recommendations, and obtain a better user experience.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1745	1754		10.1007/s00521-019-04286-7													
J								Application of improved genetic algorithm in ultrasonic location of transformer partial discharge	NEURAL COMPUTING & APPLICATIONS										Improved genetic algorithm; Particle swarm optimization algorithm; Simulated annealing algorithm; Transformer partial discharge	CONSTRUCTION; OPTIMIZATION	Detecting and locating the partial discharge point inside the transformer is one of the key measures to ensure the normal operation of transformer. In this paper, an improved genetic algorithm (GAICM) based on improved cross-model was proposed. In this algorithm, crossover operator and mutation operator are improved, and an adaptive model is introduced. GAICM was tested by classical test functions. The test results showed that GAICM has good convergence speed and optimization ability. Meanwhile, GAICM was applied to the ultrasonic localization of transformer partial discharge, and its positioning effect was compared with the location effect of genetic algorithm, simulated annealing algorithm and particle swarm optimization algorithm. The experimental result showed that the application of GAICM to the ultrasonic localization of the transformer partial discharge is more effective.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1755	1764		10.1007/s00521-019-04461-w													
J								Dynamic hardware system for cascade SVM classification of melanoma	NEURAL COMPUTING & APPLICATIONS										SVM; Cascade classifier; Melanoma; FPGA; DPR; Embedded system	SUPPORT VECTOR MACHINES; FPGA	Melanoma is the most dangerous form of skin cancer, which is responsible for the majority of skin cancer-related deaths. Early diagnosis of melanoma can significantly reduce mortality rates and treatment costs. Therefore, skin cancer specialists are using image-based diagnostic tools for detecting melanoma earlier. We aim to develop a handheld device featured with low cost and high performance to enhance early detection of melanoma at the primary healthcare. But, developing this device is very challenging due to the complicated computations required by the embedded diagnosis system. Thus, we aim to exploit the recent hardware technology in reconfigurable computing to achieve a high-performance embedded system at low cost. Support vector machine (SVM) is a common classifier that shows high accuracy for classifying melanoma within the diagnosis system and is considered as the most compute-intensive task in the system. In this paper, we propose a dynamic hardware system for implementing a cascade SVM classifier on FPGA for early melanoma detection. A multi-core architecture is proposed to implement a two-stage cascade classifier using two classifiers with accuracies of 98% and 73%. The hardware implementation results were optimized by using the dynamic partial reconfiguration technology, where very low resource utilization of 1% slices and power consumption of 1.5 W were achieved. Consequently, the implemented dynamic hardware system meets vital embedded system constraints of high performance and low cost, resource utilization, and power consumption, while achieving efficient classification with high accuracy.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1777	1788		10.1007/s00521-018-3656-1													
J								Learning-interaction-diversification framework for swarm intelligence optimizers: a unified perspective	NEURAL COMPUTING & APPLICATIONS										Swarm intelligence; Evolutionary algorithm; Meta-heuristic algorithm; Nature-inspired algorithm	ARTIFICIAL BEE COLONY; CUCKOO SEARCH ALGORITHM; OPTIMIZATION ALGORITHM; GLOBAL OPTIMIZATION; FIREFLY ALGORITHM; PART I; EVOLUTIONARY; METAHEURISTICS; MECHANISM; STRATEGY	Due to the efficiency and efficacy in performance to tackle complex optimization problems, swarm intelligence (SI) optimizers, newly emerged as nature-inspired algorithms, have gained great interest from researchers over different fields. A large number of SI optimizers and their extensions have been developed, which drives the need to comprehensively review the characteristics of each algorithm. Hence, a generalized framework laid upon the fundamental principles from which SI optimizers are developed is crucial. This research takes a multidisciplinary view by exploring research motivations from biology, psychology, computing and engineering. A learning-interaction-diversification (LID) framework is proposed where learning is to understand the individual behavior, interaction is to describe the swarm behavior, and diversification is to control the population performance. With the LID framework, 22 state-of-the-art SI algorithms are characterized, and nine representative ones are selected to review in detail. To investigate the relationships between LID properties and algorithmic performance, LID-driven experiments using benchmark functions and real-world problems are conducted. Comparisons and discussions on learning behaviors, interaction relations and diversity control are given. Insights of the LID framework and challenges are also discussed for future research directions.																	0941-0643	1433-3058				MAR	2020	32	6			SI		1789	1809		10.1007/s00521-018-3657-0													
J								A new hybrid image segmentation approach using clustering and black hole algorithm	COMPUTATIONAL INTELLIGENCE										black hole algorithm; clustering; image segmentation; region merging	FUZZY C-MEANS; OUTLIER REJECTION; SWARM; INITIALIZATION	Clustering technique is used in image segmentation because of its simple and easy approach. However, the existing clustering techniques required prior information as input and the performance are entirely dependent on this prior information, which is the main drawback of the clustering approaches. Therefore, many researchers are trying to introduce a novel method with user free parameter. We proposed a clustering method, that is, independent of user parameters and later we used a region merging technique to improve the performance of the clustering output. In this article, we proposed a hybrid image segmentation method which is based on a clustering algorithm and black hole algorithm. In the clustering technique, we have used recursive density estimation technique of surrounding pixels. After clustering technique, presence of small segments may be present and it would give lower a performance of segmentation output. Therefore, a segment is merged with another segment by finding best matched segment. Black hole algorithm concept has been used to define the fitness of each segment and to find the best matching segment. We have compared the proposed method with the other clustering-based segmentation methods and different evaluation indices are used to calculate the performance, and the result proved the effectiveness of the proposed algorithm.																	0824-7935	1467-8640															10.1111/coin.12297		MAR 2020											
J								Increasing sample efficiency in deep reinforcement learning using generative environment modelling	EXPERT SYSTEMS										artificial experience-replay; deep reinforcement learning; environment Modelling; exploration; generative adversarial networks; generative Modelling; Markov decision processes; model-based RL; neural networks; variational autoencoder		Reinforcement learning is a broad scheme of learning algorithms that, in recent times, has shown astonishing performance in controlling agents in environments presented as Markov decision processes. There are several unsolved problems in current state-of-the-art that causes algorithms to learn suboptimal policies, or even diverge and collapse completely. Parts of the solution to address these issues may be related to short- and long-term planning, memory management and exploration for reinforcement learning algorithms. Games are frequently used to benchmark reinforcement learning algorithms as they provide a flexible, reproducible and easy to control environments. Regardless, few games feature the ability to perceive how the algorithm performs exploration, memorization and planning. This article presents The Dreaming Variational Autoencoder with Stochastic Weight Averaging and Generative Adversarial Networks (DVAE-SWAGAN), a neural network-based generative modelling architecture for exploration in environments with sparse feedback. We present deep maze, a novel and flexible maze game-engine that challenges DVAE-SWAGAN in partial and fully observable state-spaces, long-horizon tasks and deterministic and stochastic problems. We show results between different variants of the algorithm and encourage future study in reinforcement learning driven by generative exploration.																	0266-4720	1468-0394														e12537	10.1111/exsy.12537		MAR 2020											
J								Universal fingerprint minutiae extractor using convolutional neural networks	IET BIOMETRICS										feature extraction; fingerprint identification; neural nets; image matching; universal fingerprint minutiae extractor; convolutional neural networks; feature points; fingerprint image; fingerprint recognition; conventional minutiae extractors; modified U-shaped segmentation network; academic extractors; commercial extractors		Minutiae, widely used feature points of fingerprint images, directly decide the performance of fingerprint recognition. Conventional minutiae extractors rely on a series of preprocessing steps, thus performing poorly for bad quality samples due to error accumulations. Existing extractors using convolutional neural networks are trained and tested with a certain specific sensor, thus requiring various modules for different sensors. To solve these problems, a universal minutiae extractor using a modified U-shaped segmentation network is proposed. Specifically, the proposed extractor classifies each pixel of a fingerprint image into a category of minutia with a certain orientation or non-minutia point, thus obtaining location and orientation information of minutiae simultaneously. The experimental results plus comparisons with other academic and commercial extractors prove that the proposed network can extract accurate and robust minutiae regardless of the quality of fingerprints and the sensor types.																	2047-4938	2047-4946				MAR	2020	9	2					47	57		10.1049/iet-bmt.2019.0017													
J								Face recognition: a novel multi-level taxonomy based survey	IET BIOMETRICS										face recognition; feature extraction; multiple application areas; abstraction levels; multilevel face recognition taxonomy; efficient face recognition solutions; face structure; representative face recognition solutions; multilevel taxonomy based survey	LOCAL BINARY PATTERNS; PRINCIPAL COMPONENT ANALYSIS; FRAMEWORK; DATABASE; MODELS; IMAGE	In a world where security issues have been gaining growing importance, face recognition systems have attracted increasing attention in multiple application areas, ranging from forensics and surveillance to commerce and entertainment. To help to understand the landscape and abstraction levels relevant for face recognition systems, face recognition taxonomies allow a deeper dissection and comparison of the existing solutions. This study proposes a new, more encompassing and richer multi-level face recognition taxonomy, facilitating the organisation and categorisation of available and emerging face recognition solutions; this taxonomy may also guide researchers in the development of more efficient face recognition solutions. The proposed multi-level taxonomy considers levels related to the face structure, feature support, and feature extraction approach. Following the proposed taxonomy, a comprehensive survey of representative face recognition solutions is presented. This study concludes with a discussion on current algorithmic and application related challenges, which may define future research directions for face recognition.																	2047-4938	2047-4946				MAR	2020	9	2					58	67		10.1049/iet-bmt.2019.0001													
J								Deep representations for cross-spectral ocular biometrics	IET BIOMETRICS										image representation; learning (artificial intelligence); image matching; biometrics (access control); feature extraction; iris recognition; eye; neural nets; face recognition; cross-spectral ocular biometrics; cross-spectral ocular verification methods; known deep learning representations; nonnormalised iris-periocular regions; publicly available cross-spectral; ResNet-50 deep representations; PolyU bi-spectral; cross-eye-cross-spectral datasets	IRIS RECOGNITION; CLASSIFICATION; CNN	One of the major challenges in ocular biometrics is the cross-spectral scenario, i.e. how to match images acquired in different wavelengths. This study designs and extensively evaluates cross-spectral ocular verification methods using well known deep learning representations based on the iris and periocular regions. Using as inputs, the bounding boxes of non-normalised iris-periocular regions, the authors fine-tune convolutional neural network models, originally trained for face recognition. On the basis of the experiments carried out in two publicly available cross-spectral ocular databases, they report results for intra-spectral and cross-spectral scenarios, with the best performance being observed when fusing ResNet-50 deep representations from both the periocular and iris regions. When compared to the state of the art, they observed that the proposed solution consistently reduces the equal error rate values by 90%/93%/96% and 61%/77%/83% on the cross-spectral scenario and in the PolyU bi-spectral and cross-eye-cross-spectral datasets. Finally, they evaluate the effect that the 'deepness' factor of feature representations has in recognition effectiveness, and based on a subjective analysis of the most problematic pairwise comparisons - they point out further directions for this field of research.																	2047-4938	2047-4946				MAR	2020	9	2					68	77		10.1049/iet-bmt.2019.0116													
J								Efficient method for segmentation of noisy and non-circular iris images using improved particle swarm optimisation-based MRFCM	IET BIOMETRICS										fuzzy set theory; iris recognition; feature extraction; image segmentation; particle swarm optimisation; pattern clustering; image reconstruction; improved particle swarm optimisation-based MRFCM; automated iris-based recognition system; biometric system; iris boundary; noncircular iris boundaries; recognition framework; iris segmentation method; iris recognition; noncircular iris image; noise artefacts; mathematical modelling; morphological reconstruct fuzzy C-means clustering; improved particle swarm optimisation; geodesic active contours; stopping function; matching score distribution; MRFCM; evaluation databases	RECOGNITION	Segmentation of the iris is a crucial stage in an automated iris-based recognition system. The performance of any biometric system primarily relies on how effectively the iris is extracted from the unwanted parts of an iris image. The process of iris segmentation is mainly affected by the noise artefacts such as eyelid/eyelashes occlusions, specular reflections, intensity inhomogeneities, and non-circularity of the iris boundary. A novel and an efficient method has been proposed in this work to segment noisy and non-circular iris boundaries. The mathematical modelling of morphological reconstruct fuzzy C-means clustering (MRFCM) has been presented. The MRFCM based on improved particle swarm optimisation has been implemented before the segmentation in the recognition framework. The resultant images are then segmented by employing geodesic active contours incorporated by a new stopping function. The effect of the proposed segmentation method on iris recognition is observed through matching score distribution. The popular and publicly available datasets such as UBIRISv1, CASIA-v3-Interval, MMU1, and Mobile Iris Challenge Evaluation databases are considered for the evaluation of the proposed method. Recognition accuracy is validated and compared with the well-existing methods.																	2047-4938	2047-4946				MAR	2020	9	2					78	90		10.1049/iet-bmt.2019.0026													
J								Canonical decomposition of dichotomous basic belief assignment	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										belief functions; canonical decomposition; contra-evidence; PCR5 rule; pro-evidence	COMBINATION	In this paper, we prove that any dichotomous basic belief assignment (BBA) m can be expressed as the combination of two simple belief assignments m p and m c called, respectively, the pros and cons BBAs thanks to the proportional conflict redistribution rule no 5 (PCR5). This decomposition always exists and is unique and we call it the canonical decomposition of the BBA m. We also show that canonical decompositions do not exist in general if we use the conjunctive rule, the disjunctive rule, Dempster's rule, Dubois and Prade's or Yager's rules, or even the averaging rule of combination. We give some numerical examples of canonical decompositions and discuss of the potential interest of this canonical decomposition for applications in information fusion.																	0884-8173	1098-111X				JUL	2020	35	7					1105	1125		10.1002/int.22236		MAR 2020											
J								Hierarchical attentive deep neural networks for semantic music annotation through multiple music representations	INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL										Music annotation; Convolutional network; Dual-state LSTM; Gated linear unit; Self-attention	FEATURES	Automatically assigning a group of appropriate semantic tags to one music piece provides an effective way for people to efficiently utilize the massive and ever increasing online and off-line music data. In this paper, we propose a novel end-to-end deep neural network model for automatic music annotation, which effectively integrates available multiple complementary music representations and jointly accomplishes music representation learning, structure modeling, and tag prediction. The model first hierarchically leverages attentive convolutional networks and recurrent networks to learn informative descriptions from Mel-spectrogram and raw waveform of the music and depict time-varying structures embedded in the description sequence. A dual-state LSTM network is then employed to capture the correlations between two representation channels as supplementary music descriptions. Finally, the model aggregates music description sequence into a holistic embedding with a self-attentive multi-weighting mechanism, which adaptively captures multi-aspect summarized information of the music for tag prediction. Experiments on the public MagnaTagATune benchmark music dataset show that the proposed model outperforms state-of-the-art methods for automatic music annotation.																	2192-6611	2192-662X				MAR	2020	9	1			SI		3	16		10.1007/s13735-019-00186-7													
J								ContextNet: representation and exploration for painting classification and retrieval in context	INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL										Art classification; Multi-modal retrieval; Knowledge graphs; Visualisation; Multitask learning	IMAGE; KNOWLEDGE	In automatic art analysis, models that besides the visual elements of an artwork represent the relationships between the different artistic attributes could be very informative. Those kinds of relationships, however, usually appear in a very subtle way, being extremely difficult to detect with standard convolutional neural networks. In this work, we propose to capture contextual artistic information from fine-art paintings with a specific ContextNet network. As context can be obtained from multiple sources, we explore two modalities of ContextNets: one based on multitask learning and another one based on knowledge graphs. Once the contextual information is obtained, we use it to enhance visual representations computed with a neural network. In this way, we are able to (1) capture information about the content and the style with the visual representations and (2) encode relationships between different artistic attributes with the ContextNet. We evaluate our models on both painting classification and retrieval, and by visualising the resulting embeddings on a knowledge graph, we can confirm that our models represent specific stylistic aspects present in the data.																	2192-6611	2192-662X				MAR	2020	9	1			SI		17	30		10.1007/s13735-019-00189-4													
J								Evaluation of the Disturbance Rejection Performance of an Aerial Manipulator	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Hexacopter; ADRC; Disturbance rejection; Aerial manipulator	QUADROTOR; DESIGN	This study mainly focuses on the control of a hexacopter platform that is equipped with a two degree-of-freedom robot arm. The designed control system rejects the disturbances to the attitude dynamics of the hexacopter which are mainly caused by the motion of the robot arm. For this purpose, Active Disturbance Rejection Control (ADRC) is implemented and its disturbance rejection capabilities are investigated. The equations of motion of the hexacopter with a two degree-of-freedom robot arm are derived by using the Newton-Euler approach. Flight tests are utilized to compare the performance of the third order ADRC with that of the cascaded PID (P-PID) controller which is one of the mostly used controllers in commercial multicopter systems. In addition, second and the third order ADRC performances are compared as well. Regulatory and disturbance rejection characteristics of the hexacopter are compared using several performance criteria. It is shown that third order ADRC has a better performance when disturbance acts in both the roll and pitch axes.																	0921-0296	1573-0409				MAR	2020	97	3-4					451	469		10.1007/s10846-019-01013-1													
J								Drone Delivery Scheduling Optimization Considering Payload-induced Battery Consumption Rates	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Battery consumption rate; Payload amount; Path planning; Drone scheduling; Delivery network	TRAVELING SALESMAN PROBLEM; MODEL	This paper addresses the design of a parcel delivery system using drones, which includes the strategic planning of the system and operational planning for a given region. The amount of payload affects the battery consumption rate (BCR), which can cause a disruption in delivery of goods if the BCR was under-estimated in the planning stage or cause unnecessarily higher expenses if it was over-estimated. Hence, a reliable parcel delivery schedule using drones is proposed to consider the BCR as a function of payload in the operational planning optimization. A minimum set covering approach is used to model the strategic planning and a mixed integer linear programming problem (MILP) is used for operational planning. A variable preprocessing algorithm and primal and dual bound generation methods are developed to improve the computational time for solving the operational planning model. The optimal solution provides the least number of drones and their flight paths to deliver parcels while ensuring the safe return of the drones with respect to the battery charge level. Experimental data show that the BCR is a linear function of the payload amount. The results indicate the impact of including the BCR in drone scheduling, 3 out of 5 (60%) flight paths are not feasible if the BCR is not considered. The numerical results show that the sequence of visiting customers impacts the remaining charge.																	0921-0296	1573-0409				MAR	2020	97	3-4					471	487		10.1007/s10846-019-01034-w													
J								Ground Risk Map for Unmanned Aircraft in Urban Environments	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Unmanned aerial vehicles; Unmanned aircraft; Risk map; Risk assessment; Aviation safety; Probability of fatality	DESIGN; SYSTEM	The large diversity of unmanned aircraft requires a suitable and proper risk assessment. In this paper, we propose the use of risk maps to define the risk associated to accidents with unmanned aircraft. It is a two-dimensional location-based map that quantifies the risk to the population on ground of flight operations over a specified area. The risk map is generated through a probabilistic approach and combines several layers, including population density, sheltering factor, no-fly zones, and obstacles. Each element of the risk map has associated a risk value that quantifies the risk of flying over a specific location. Risk values are defined by a risk assessment process using different uncontrolled descent events, drone parameters, environmental characteristics, as well as uncertainties on parameters. The risk map is able to quantify the risk of large areas, such as urban environments, and allows for easy identification of high and low-risk locations. The map is a tool for informed decision making, and our results report some examples of risk map with different aircraft in a realistic urban environment.																	0921-0296	1573-0409				MAR	2020	97	3-4					489	509		10.1007/s10846-019-01015-z													
J								Risk Areas Determination for Autonomous- and Semi-autonomous Aerial Systems Considering Run-Time Technical Reliability Assessment Requirements, Concept, and Tests	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Run-time reliability assessment; Autonomous or semi-autonomous aerial systems; Risk areas	COLLISION-AVOIDANCE; UAV; SENSE	Autonomous or semi-autonomous aerial systems are used in different application domains to simplify or assist humans tasks. In this context, their behavior has to be verifiably safe. Here safe behavior denotes system's interaction with the environment with freedom from unacceptable risk for the environment and the system itself. Traditionally, run-time technical reliability assessment is not considered for risk areas determination. Run-time definition and online control of risk areas based on current technical reliability may be used as a function to assure safe behavior of autonomous or semi-autonomous aerial systems. This contribution introduces a novel technique for the definition and control of risk areas considering system's behavior as well as it's technical reliability during run-time. The technique is used to separate the space around an autonomous aerial system into risk-related areas. On this basis, the safety unit can realize emergency actions to ensure system's safe behavior if necessary. The introduction of the novel technique is realized in the context of the safety unit description and run-time technical reliability assessment. For the run-time technical reliability assessment, a novel technique is introduced, inspired by the functional safety standard IEC 61508. Simulation results demonstrate the successful use of the introduced approach.																	0921-0296	1573-0409				MAR	2020	97	3-4					511	529		10.1007/s10846-019-01056-4													
J								Monocular Trail Detection and Tracking Aided by Visual SLAM for Small Unmanned Aerial Vehicles	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										UAV; Path detection; Visual SLAM	SALIENCY; SEARCH	This article addresses the navigation problem of small and medium-sized unmanned aerial vehicles (UAVs) built to perform missions in forest environments (e.g., search and rescue) by exploiting the presence of natural or man-made paths, typically present in this type of environments. The proposed system extends a previous monocular-based technique for trail detection and tracking so as to take into account volumetric data acquired from a Visual SLAM algorithm and, as a result, to increase its sturdiness upon challenging trails. The experimental results, obtained via a set of 12 videos recorded with a camera installed in a tele-operated, unmanned small-sized aerial vehicle, show the ability of the proposed system to overcome some of the difficulties of the original detector, attaining a success rate of 97.8%.																	0921-0296	1573-0409				MAR	2020	97	3-4					531	551		10.1007/s10846-019-01033-x													
J								An Efficient Approach for Graph-Based Fault Diagnosis in UAVs	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Unmanned aerial vehicle; Fault diagnosis; Structural analysis; Causality assignment; Integer linear programming; Realizability	STRUCTURAL-ANALYSIS APPROACH; RESIDUAL GENERATORS; SENSOR-LOCATION; SYSTEMS; REDUNDANCY; SELECTION	In this work, we tackle the problem of systematic population of a bank of residual generators for model-based fault diagnosis in Unmanned Aerial Vehicles (UAVs). Intended for detailed, large and non-linear system models, Structural Analysis (SA) is applied to produce a graph-based abstraction of the problem in the form of a bipartite graph. The Branch and Bound Integer Linear Programming (BBILP) algorithm is employed, properly adapted to seek a solution for the constrained graph matching problem. Appropriate causality constraints are formulated, which link the structure of the system graph with the analytical form of the residual generators and certify that all resulting residual generators can be implemented automatically using numerical processes. An extensive performance investigation of the proposed approach is carried out, which is shown to be more efficient than other similar algorithms. Benchmarks of UAV models taken from the literature are presented and a simulated response of the diagnostic system against a fault in the roll-rate sensor is showcased.																	0921-0296	1573-0409				MAR	2020	97	3-4					553	576		10.1007/s10846-019-01061-7													
J								Fast 3D Collision Avoidance Algorithm for Fixed Wing UAS	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Fast obstacle avoidance; Air vehicle obstacle avoidance; Avoidance efficiency; Optimal avoidance starting time	OBSTACLE AVOIDANCE; ENVIRONMENTS; NAVIGATION	This paper presents an efficient 3D collision avoidance algorithm for fixed wing Unmanned Aerial Systems (UAS). The algorithm increases the ability of aircraft operations to complete mission goals by enabling fast collision avoidance of multiple obstacles. The new algorithm, which we have named Fast Geometric Avoidance algorithm (FGA), combines geometric avoidance of obstacles and selection of a critical avoidance start time based on kinematic considerations, collision likelihood, and navigation constraints. In comparison to a current way-point generation method, FGA showed a 90% of reduction in computational time for the same obstacle avoidance scenario. Using this algorithm, the UAS is able to avoid static and dynamic obstacles while still being able to recover its original trajectory after successful collision avoidance. Simulations for different mission scenarios show that this method is much more efficient at avoiding multiple obstacles than previous methods. Algorithm effectiveness validation is provided with Monte Carlo simulations and flight missions in an aircraft simulator. FGA was also tested on a fixed-wing aircraft with successful results. Because this algorithm does not have specific requirements on the sensor data types it can be applied to cooperative and non-cooperative intruders.																	0921-0296	1573-0409				MAR	2020	97	3-4					577	604		10.1007/s10846-019-01037-7													
J								A UAV Guidance System Using Crop Row Detection and Line Follower Algorithms	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Embedded image processing; Autonomous UAV guidance; Crop row detection method; Precision agriculture application	AUTOMATIC DETECTION; IMAGES	In precision agriculture, activities such as selective spraying of agrochemicals are essential to maintaining high productivity and quality of agricultural products. The use of unmanned aerial vehicles (UAVs) to perform this activity reduces soil compaction, compared to the use of heavy machinery, and helps to reduce the waste of these artificial substances through a punctual and self-regulating application. This work proposes an entire guiding system for use on UAVs (hardware and software) based on image processing techniques. The software part consists of two algorithms. The first algorithm is the Crop Row Detection which is responsible for the correct identification of the crop rows. The second algorithm is the Line Filter that is responsible for generating the driving parameters sent to the flight controller. In the field experiments performed on the proposed hardware, the algorithm achieved a detection rate of 100% of the crop rows for images with resolutions above 320 x 240. The system performance was measured in laboratory experiments and reached 31.22 FPS for images with small resolution, 320 x 240, and 1.63 FPS for the highest resolution, 1920 x 1080. The main contribution of this work is the design and development of an entire embedded guidance system composed of a hardware and software architectures. Other contributions are: the proposed filter for the image pretreatment; the filter to remove the false positive lines; and the algorithm for generating the guiding parameters based on detected crop rows.																	0921-0296	1573-0409				MAR	2020	97	3-4					605	621		10.1007/s10846-019-01006-0													
J								Search and Localization of a Weak Source with a Multi-robot Formation	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Multi-robot systems; Source seeking; Robotic sensor networks	COOPERATIVE CONTROL; SENSOR NETWORKS; SUCCESS; ROBOT	This paper proposes an algorithm to guide a formation of mobile robots, subject to communication constraints, from an arbitrary position to the location of the source of a physical signal in a planar environment. The information on the signal is only based on noisy measurements of its strength collected during the mission and the signal is considered to be weak and indistinguishable from the noise in a large portion of the environment. The goal of the team is thus to search for a reliable signal and finally converge to the source location. An accurate estimation of the signal gradient is obtained by fusing the data gathered by the robots while moving in a circular formation. The algorithm proposed to steer the formation, called Gradient-biased Correlated Random Walk (GCRW), exploits the gradient estimation to bias a correlated random walk, which ensures an efficient non-oriented search motion when far from the source. The resulting strategy is so able to obtain a suitable trade-off between exploration and exploitation. Results obtained in simulated experiments, including comparisons with possible alternatives, are presented to analyze and evaluate the performance of the proposed approach.																	0921-0296	1573-0409				MAR	2020	97	3-4					623	634		10.1007/s10846-019-01014-0													
J								Model Predictive Fault Tolerant Control for Omni-directional Mobile Robots	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Fault tolerance; Omni-directional mobile robot; Model predictive control	CONTROL-SYSTEMS; DIAGNOSIS	This paper describes the design of a Fault Tolerant Control scheme for an omni-directional mobile robot with four mecanum wheels. We consider actuation faults in which the wheels are not able to receive commands, but still can rotate freely due to the friction with the ground. A Non-linear Model Predictive Controller is employed, in order to appropriately exploit the inherited actuation redundancy of the omni-directional robot, and provide on the fly a unified accommodation solution for multiple combinations of actuation faults. A basic Fault Detection and Isolation scheme is responsible for identifying and isolate the faulty wheels. Accordingly, the control input vector and consequently the dynamic model of the vehicle are reformulated depending on the identified faults. Hence, the predictive control scheme is dynamically updated and calculates the optimal actuation solution, given the faults occurred. The proposed scheme, is able to guide the vehicle to any goal configuration within the workspace, while simultaneously satisfying state (e.g obstacle avoidance) and input (e.g motor limits) constraints. The efficacy of the proposed scheme is evaluated via a set of realistic simulation scenarios, where an omni-directional mobile robot executes a way point tracking mission with obstacle avoidance, inside a restricted workspace and in the presence of different combinations of actuation faults.																	0921-0296	1573-0409				MAR	2020	97	3-4					635	655		10.1007/s10846-019-01029-7													
J								Adaptive Neural Network Control of Underwater Robotic Manipulators Tuned by a Genetic Algorithm	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Control design; Underwater robots; Adaptive neural network; Drag force; Genetic algorithm; Disturbance observer	SLIDING MODE CONTROL; TRACKING CONTROL; FEEDBACK SYSTEMS; CONTROL DESIGN; VEHICLES; EXOSKELETON	This paper describes a novel approach for the control of underwater robots that can handle uncertainties and disturbance problems, which are commonly met in underwater environments. The considered system is an underwater manipulator with n-degrees of freedom. The approximation capability of an adaptive neural network is exploited to estimate uncertainties in system dynamics. Drag and lift forces are considered as an external disturbance, and a disturbance observer approach which has been proved to be effective with on-land robotic systems, is applied to compensate for it. The objective of the controller designed is to track a desired trajectory. To find the optimal gain parameters of this controller, a classical Genetic Algorithm is employed. Extensive simulation studies carried out on a two degrees of freedom manipulator indicate the efficacy of the proposed approach, proving that the disturbance observer originally developed for on-land systems can also be used effectively for underwater robotic systems. Finally, the performance of the proposed controller, tuned by the Genetic Algorithm is compared with that of a controller, tuned manually. The results show that the reliance on a well-known classic Genetic Algorithm for the tuning of the controller parameters not only saves time, but also provides better values of the parameters.																	0921-0296	1573-0409				MAR	2020	97	3-4					657	672		10.1007/s10846-019-01008-y													
J								Research on Synergy Pursuit Strategy of Multiple Underwater Robots	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Synergy control; Pursuit strategy; Semicircular encirclement; Finite state machine; Multiple underwater robots	SEARCH	This paper presents a synergy pursuit strategy that multiple underwater robots pursue a single moving target based on finite state machine. The processes of the pursuit are defined as seven different states, and to implement each state, the corresponding strategies are designed. As the strategy for each state is implemented by a corresponding formation control, a synergy control law is also designed for multiple underwater robots. In the design of the pursuit strategy, the definition of encirclement is put forward for the underwater robots. Furthermore, the proof that a point is encircled by other points on the plane is given. To solve the problem of the concealment in the tracking and the pursuit, a semicircular pursuit strategy and a circular pursuit strategy are also proposed. Finally, based on this pursuit strategy, the simulation of whole process is carried out with the MOOS(Mission Oriented Operating Suite) platform, and the effectiveness of the semicircular and circular pursuit strategy are verified by lake experiment with practical robots. The results of simulation and lake experiment prove that this pursuit strategy can realize synergy tracking and pursuit for a single moving target under the given conditions.																	0921-0296	1573-0409				MAR	2020	97	3-4					673	694		10.1007/s10846-019-01019-9													
J								New Adaptive Segmented Wheel for Locomotion Improvement of Field Robots on Soft Terrain	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Scissor mechanism; Bekker's theory; Field robots; Traction force; UGV	MOBILE ROBOTS; DYNAMICS; DESIGN; SINKAGE; MODEL; UGV	In this paper, a new adjustable segmented wheel is proposed whose platform is composed of a complex closed-loop scissor mechanism wrapped over adjustable spokes. The new platform composed of four proposed wheels is specified to avoid halting, to increase traction force and to adjust body orientation while interacting soft or composite terrains. The soil contact model (SCM), extended from Bekker's theory is implemented to derive the wheel-soil interaction formulations. Furthermore, the Lagrange approach is used to derive the unmanned ground vehicle (UGV) dynamics including interaction forces. The best configurations of adjustable wheel are tabulated according to the terrain properties and the motion types. Finally, the proposed UGV is compared with a typical ordinary UGV to investigate traction forces and halting avoidance. Based on the simulation results and primary tests of the experimental setup, it can be inferred that this new mechanism can effectively adapt itself to different terrain conditions in order to pass the soft concave regions, climb the soft obstacles and move on the composite terrains.																	0921-0296	1573-0409				MAR	2020	97	3-4					695	717		10.1007/s10846-019-01059-1													
J								Zoning a Service Area of Unmanned Aerial Vehicles for Package Delivery Services	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Unmanned Aerial Vehicle; Aerial space design; Zoning	FLOW PATH DESIGN; TRAVELING SALESMAN PROBLEM; GENETIC ALGORITHMS; OPTIMIZATION; DRONE	Package delivery services by deploying Unmanned Aerial Vehicles (UAVs) have received considerable attention due to their significant potential benefits. One of the scenarios making the concept more attractive is to deploy large numbers of UAVs to properly handle increasing demands for the service by the units. However, it is challenging because it increases the difficulty of UAV control as well as the complexity of the scheduling problems involved in the service. To tackle the issues, we propose a systematic approach that decomposes a service area into several disjoint zones. Within a zone, a single UAV at most can be operated. To verify the advantages and performance of the proposed approach, we first optimize the zoning, i.e. a service area decomposition, applying Genetic Algorithm (GA). We then evaluate the service level of the package deliveries by UAVs under the proposed approach using a simulation model.																	0921-0296	1573-0409				MAR	2020	97	3-4					719	731		10.1007/s10846-019-01045-7													
J								Head-synced Drone Control for Reducing Virtual Reality Sickness	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Virtual reality; Sickness; Teleoperation; Drone	MOTION	Controlling a drone using head-mounted display induces virtual reality (VR) sickness. From previous research, it is known that angular velocity is one of the contributing factors to induce VR sickness, however for drones, linear motion and the interaction between linear and angular motion often occur during operation. In this research, we investigate the effect of each conditions experimentally and proposes a method of controlling a drone to reduce VR sickness. We designed a system that does not make user's head fixed at one point but allows to move the head freely. At the same time, the head orientation and direction are synced with the drone's attitude to reduce sensory conflict. Two controllers were compared: joystick control and head control. We tested with a real system and conducted experiments on subjects to verify its effect. The proposed controller reduced angular velocity in the frequency range 0.1 to 10 Hz where a vestibular system becomes most sensitive, and it is demonstrated that reducing sensory conflict contributes to the reduction of VR sickness.																	0921-0296	1573-0409				MAR	2020	97	3-4					733	744		10.1007/s10846-019-01054-6													
J								Hidden Aspects of the Research ADOS Are Bound to Affect Autism Science	NEURAL COMPUTATION											DIAGNOSTIC OBSERVATION SCHEDULE; RESEARCH DOMAIN CRITERIA; SPECTRUM DISORDERS; SENSORIMOTOR; SIGNAL; DYSFUNCTIONS; PREDICTORS; SIGNATURES; PHENOTYPE; SEVERITY	The research-grade Autism Diagnostic Observational Schedule (ADOS) is a broadly used instrument that informs and steers much of the science of autism. Despite its broad use, little is known about the empirical variability inherently present in the scores of the ADOS scale or their appropriateness to define change and its rate, to repeatedly use this test to characterize neurodevelopmental trajectories. Here we examine the empirical distributions of research-grade ADOS scores from 1324 records in a cross-section of the population comprising participants with autism between five and 65 years of age. We find that these empirical distributions violate the theoretical requirements of normality and homogeneous variance, essential for independence between bias and sensitivity. Further, we assess a subset of 52 typical controls versus those with autism and find a lack of proper elements to characterize neurodevelopmental trajectories in a coping nervous system changing at nonuniform, nonlinear rates. Repeating the assessments over four visits in a subset of the participants with autism for whom verbal criteria retained the same appropriate ADOS modules over the time span of the four visits reveals that switching the clinician changes the cutoff scores and consequently influences the diagnosis, despite maintaining fidelity in the same test's modules, room conditions, and tasks' fluidity per visit. Given the changes in probability distribution shape and dispersion of these ADOS scores, the lack of appropriate metric spaces to define similarity measures to characterize change and the impact that these elements have on sensitivity-bias codependencies and on longitudinal tracking of autism, we invite a discussion on readjusting the use of this test for scientific purposes.																	0899-7667	1530-888X				MAR	2020	32	3					515	561		10.1162/neco_a_01263													
J								Model-Free Robust Optimal Feedback Mechanisms of Biological Motor Control	NEURAL COMPUTATION											ADAPTIVE OPTIMAL-CONTROL; CONTINUOUS-TIME; ARM MOVEMENTS; ADAPTATION; VARIABILITY; SYSTEMS; STABILITY; MEMORY; REWARD; SIGNAL	Sensorimotor tasks that humans perform are often affected by different sources of uncertainty. Nevertheless, the central nervous system (CNS) can gracefully coordinate our movements. Most learning frameworks rely on the internal model principle, which requires a precise internal representation in the CNS to predict the outcomes of our motor commands. However, learning a perfect internal model in a complex environment over a short period of time is a nontrivial problem. Indeed, achieving proficient motor skills may require years of training for some difficult tasks. Internal models alone may not be adequate to explain the motor adaptation behavior during the early phase of learning. Recent studies investigating the active regulation of motor variability, the presence of suboptimal inference, and model-free learning have challenged some of the traditional viewpoints on the sensorimotor learning mechanism. As a result, it may be necessary to develop a computational framework that can account for these new phenomena. Here, we develop a novel theory of motor learning, based on model-free adaptive optimal control, which can bypass some of the difficulties in existing theories. This new theory is based on our recently developed adaptive dynamic programming (ADP) and robust ADP (RADP) methods and is especially useful for accounting for motor learning behavior when an internal model is inaccurate or unavailable. Our preliminary computational results are in line with experimental observations reported in the literature and can account for some phenomena that are inexplicable using existing models.																	0899-7667	1530-888X				MAR	2020	32	3					562	595		10.1162/neco_a_01260													
J								Evaluating the Potential Gain of Auditory and Audiovisual Speech-Predictive Coding Using Deep Learning	NEURAL COMPUTATION											LONG-RANGE CORRELATIONS; FREE-ENERGY PRINCIPLE; RECOGNITION; SPECTRUM; QUANTIZATION; SEPARATION; TRACKING; MODELS	Sensory processing is increasingly conceived in a predictive framework in which neurons would constantly process the error signal resulting from the comparison of expected and observed stimuli. Surprisingly, few data exist on the accuracy of predictions that can be computed in real sensory scenes. Here, we focus on the sensory processing of auditory and audiovisual speech. We propose a set of computational models based on artificial neural networks (mixing deep feedforward and convolutional networks), which are trained to predict future audio observations from present and past audio or audiovisual observations (i.e., including lip movements). Those predictions exploit purely local phonetic regularities with no explicit call to higher linguistic levels. Experiments are conducted on the multispeaker LibriSpeech audio speech database (around 100 hours) and on the NTCD-TIMIT audiovisual speech database (around 7 hours). They appear to be efficient in a short temporal range (25-50 ms), predicting 50% to 75% of the variance of the incoming stimulus, which could result in potentially saving up to three-quarters of the processing power. Then they quickly decrease and almost vanish after 250 ms. Adding information on the lips slightly improves predictions, with a 5% to 10% increase in explained variance. Interestingly the visual gain vanishes more slowly, and the gain is maximum for a delay of 75 ms between image and predicted sound.																	0899-7667	1530-888X				MAR	2020	32	3					596	625		10.1162/neco_a_01264													
J								Switching in Cerebellar Stellate Cell Excitability in Response to a Pair of Inhibitory/Excitatory Presynaptic Inputs: A Dynamical System Perspective	NEURAL COMPUTATION											PURKINJE-CELLS; INHIBITION; MANIFOLD; OUTPUT	Cerebellar stellate cells form inhibitory synapses with Purkinje cells, the sole output of the cerebellum. Upon stimulation by a pair of varying inhibitory and fixed excitatory presynaptic inputs, these cells do not respond to excitation (i.e., do not generate an action potential) when the magnitude of the inhibition is within a given range, but they do respond outside this range. We previously used a revised Hodgkin-Huxley type of model to study the nonmonotonic first-spike latency of these cells and their temporal increase in excitability in whole cell configuration (termed run-up). Here, we recompute these latency profiles using the same model by adapting an efficient computational technique, the two-point boundary value problem, that is combined with the continuation method. We then extend the study to investigate how switching in responsiveness, upon stimulation with presynaptic inputs, manifests itself in the context of run-up. A three-dimensional reduced model is initially derived from the original six-dimensional model and then analyzed to demonstrate that both models exhibit type 1 excitability possessing a saddle-node on an invariant cycle (SNIC) bifurcation when varying the amplitude of Iapp. Using slow-fast analysis, we show that the original model possesses three equilibria lying at the intersection of the critical manifold of the fast subsystem and the nullcline of the slow variable hA (the inactivation of the A-type K+ channel), the middle equilibrium is of saddle type with two-dimensional stable manifold (computed from the reduced model) acting as a boundary between the responsive and non-responsive regimes, and the (ghost of) SNIC is formed when the hA-nullcline is (nearly) tangential to the critical manifold. We also show that the slow dynamics associated with (the ghost of) the SNIC and the lower stable branch of the critical manifold are responsible for generating the nonmonotonic first-spike latency. These results thus provide important insight into the complex dynamics of stellate cells.																	0899-7667	1530-888X				MAR	2020	32	3					626	658		10.1162/neco_a_01261													
J								Classification from Triplet Comparison Data	NEURAL COMPUTATION												Learning from triplet comparison data has been extensively studied in the context of metric learning, where we want to learn a distance metric between two instances, and ordinal embedding, where we want to learn an embedding in a Euclidean space of the given instances that preserve the comparison order as much as possible. Unlike fully labeled data, triplet comparison data can be collected in a more accurate and human-friendly way. Although learning from triplet comparison data has been considered in many applications, an important fundamental question of whether we can learn a classifier only from triplet comparison data without all the labels has remained unanswered. In this letter, we give a positive answer to this important question by proposing an unbiased estimator for the classification risk under the empirical risk minimization framework. Since the proposed method is based on the empirical risk minimization framework, it inherently has the advantage that any surrogate loss function and any model, including neural networks, can be easily applied. Furthermore, we theoretically establish an estimation error bound for the proposed empirical risk minimizer. Finally, we provide experimental results to show that our method empirically works well and outperforms various baseline methods.																	0899-7667	1530-888X				MAR	2020	32	3					659	681		10.1162/neco_a_01262													
J								A permissioned blockchain-based implementation of LMSR prediction markets	DECISION SUPPORT SYSTEMS										Blockchain; Design science; Logarithmic Market Scoring Rule; Prediction markets	INFORMATION; IMPACT	Since the seminal work by Hanson (2003), the Logarithmic Market Scoring Rule (LMSR) has become the de facto market-maker mechanism for prediction markets. We suggest in this paper three potential issues with centralized implementations of LMSR, which we refer to as the availability, security, and privacy problems. We also explain how a permissioned blockchain-based implementation of LMSR effectively solves all the above problems. Following the design science research framework (Peffers et al., 2007), our main contribution is a fully functional permissioned blockchain-based implementation of LMSR that is ready to be deployed. We believe our results are of great value not only to prediction market researchers and practitioners looking for LMSR implementations, but also to blockchain professionals looking for fully developed solutions as well as applications of suitable research frameworks to guide blockchain research and development.																	0167-9236	1873-5797				MAR	2020	130								113228	10.1016/j.dss.2019.113228													
J								Exploring the role of deep neural networks for post-disaster decision support	DECISION SUPPORT SYSTEMS										Convolutional neural networks; Decision support; Deep learning; Disaster management; Image analytics	SOCIAL MEDIA DATA; DATA QUALITY; INFORMATION; ANALYTICS	Disaster management operations are information intensive activities due to high uncertainty and complex information needs. Emergency response planners need to effectively plan response activities with limited resources and assign rescue teams to specific disaster sites with high probability of survivors swiftly. Decision making becomes tougher since the limited information available is heterogenous, untimely and often fragmented. We address the problem of lack of insightful information of the disaster sites by utilizing image data obtained from smart infrastructures. We collect geo-tagged images from earthquake-hit regions and apply deep learning method for classification of these images to identify survivors in debris. We find that deep learning method is able to classify the images with significantly higher accuracy than the conventionally used machine learning methods for image classification and utilizes significantly lesser time and computational resources. The novel application of image analytics and the resultant findings from our models have valuable implications for effective disaster response operations, especially in smart urban settlements.																	0167-9236	1873-5797				MAR	2020	130								113234	10.1016/j.dss.2019.113234													
J								A linguistic signaling model of social support exchange in online health communities	DECISION SUPPORT SYSTEMS										Online health communities; Social support exchange; Signaling theory; Sentiment; Negativity bias; Linguistic style matching	VIRTUAL COMMUNITIES; STRENGTH DETECTION; NEGATIVITY BIAS; STYLE MATCHES; LANGUAGE USE; INFORMATION; COMMUNICATION; EMOTIONS; DISEASE; KNOWLEDGE	Health care consumers and patients are increasingly using online health communities (OHCs) to exchange social support and enhance their well-being. The success of OHCs in promoting health, however, depends not just on posting activity by participants, but, crucially, on whether or not responses are subsequently received. While previous studies have considered various mechanisms by which the likelihood of social support provisioning can be increased (e.g., the establishment of social capital), the impacts of linguistic signals have yet to be considered. Therefore, we consider whether or not linguistic signals in posts including sentiment valence, linguistic style matching, readability, post length, and spelling impact the amount of support received. Adopting an overarching theoretical framework of signaling theory, this study proposes a model that explains the signaling roles of linguistic features within OHC posts in promoting social support provision from OHC participants. The research model is empirically tested on a large dataset collected from an OHC platform covering multiple health conditions. Results show that affective linguistic signals, including negative sentiment and linguistic style matching, are effective in invoking both informational and emotional support from the community. We also find that informative linguistic signals including readability, post length, and spelling are positively associated with informational support receipt, while readability and spelling are also positively associated with emotional support receipt. Overall, this research not only enriches our current understandings of the linguistic signaling in OHCs, but also provides practical insights into improving social support exchange in OHCs.																	0167-9236	1873-5797				MAR	2020	130								113233	10.1016/j.dss.2019.113233													
J								Discrete emotions effects on electronic word-of-mouth helpfulness: The moderating role of reviewer gender and contextual emotional tone	DECISION SUPPORT SYSTEMS										Electronic word-of-mouth; Review helpfulness; Emotion; Gender stereotype	ONLINE CONSUMER REVIEWS; PRODUCT REVIEWS; DETERMINANTS; CREDIBILITY; STEREOTYPES; EXPRESSIONS; PERCEPTIONS; MESSAGE; SALES; ANGER	Using frameworks from the literature on emotion, cognitive processing and gender stereotypes, we extend existing research on online product review helpfulness by demonstrating that reviewer gender moderates the relationship between emotional content and review helpfulness and that readers' perceptions of reviewer credibility explain this effect. In the first study, experimental methods were used to demonstrate that the differential effect of angry vs. non-emotional reviews on review helpfulness was moderated by reviewer gender. Further, findings showed that the negative effect of anger on review helpfulness for female (but not male) reviewers was explained by lower reviewer credibility. In the second study, by analyzing product reviews from the Amazon web site, we found supportive evidence for the results of the first study on the relationship between female-expressed anger and review helpfulness. In addition, we explored the influence of gender stereotypes in terms of the relationship between anxiety and review helpfulness and compared it to anger. Study 2 also allowed us to explore the moderation effect of the contextual emotional tone of other reviews on the target product. Our findings highlight limitations in perceived helpfulness ratings due to gender stereotype biases and offer insights for various decision makers to better understand and manage review helpfulness.																	0167-9236	1873-5797				MAR	2020	130								113226	10.1016/j.dss.2019.113226													
J								Leveraging fine-grained transaction data for customer life event predictions	DECISION SUPPORT SYSTEMS										Life event prediction; Predictive modeling; Pseudo-social networks; Customer relationship management (CRM); Big data; Data science	OF-THE-ART; CHURN PREDICTION; RELATIONSHIP MANAGEMENT; LOGISTIC-REGRESSION; DECISION-SUPPORT; BIG DATA; SERVICE; BASE; SEGMENTATION; ATTRIBUTES	This real-world study with a large European financial services provider combines aggregated customer data including customer demographics, behavior and contact with the firm, with fine-grained transaction data to predict four different customer life events: moving, birth of a child, new relationship, and end of a relationship. The fine-grained transaction data-approximately 60 million debit transactions involving around 132,000 customers to > 1.5 million different counterparties over a one-year period-reveal a pseudo-social network that supports the derivation of behavioral similarity measures. To advance decision support systems literature, this study validates the proposed customer life event prediction model in a real-world setting in the financial services industry; compares models that rely on aggregated data, fine-grained transaction data, and their combination; and extends existing methods to incorporate fine-grained data that preserve recency, frequency, and monetary value information of the transactions. The results show that the proposed model predicts life events significantly better than random guessing, especially with the combination of fine-grained transaction and aggregated data. Incorporating recency, frequency, and monetary value information of fine-grained transaction data also significantly improves performance compared with models based on binary logs. Fine-grained transaction data accounts for the largest part of the total variable importance, for all but one of the life events.																	0167-9236	1873-5797				MAR	2020	130								113232	10.1016/j.dss.2019.113232													
J								If erring is human, is system use divine? Omission errors during post-adoptive system use	DECISION SUPPORT SYSTEMS										Human error; Omission error; Attention; Use history; Task variation; Prospective memory; Post-adoptive system use; Mobile application; Field study	WORKING-MEMORY CAPACITY; INFORMATION-TECHNOLOGY; TASK CHARACTERISTICS; DECISION-MAKING; ATTENTION; PERFORMANCE; MANAGEMENT; IMPACT; USAGE; MINDFULNESS	Our study contributes to the research on human error during IS use by studying the antecedents of the omission errors that occur during routine instances of computerized work. While attention lapses have been identified as the main mechanism leading to omission errors, we still know little about how such lapses come about during post-adoptive system use. To address this limitation, we draw our theoretical insights from theories of attention and prospective memory to illustrate how the different forms of system use carry the potential to explain patterns of human error. Accordingly, we distinguish between two forms of use history that can consist of features that are either related or unrelated to the execution of a focal task and examine their effects on the frequency of omission errors. We also examine the interaction effects of task variation on the aforementioned relationship. Our hypotheses are tested by analyzing log data associated with the use of a newly introduced mobile application in the context of a sailing sports event. Our results indicate that restricting ones system use on related task features reduces omission errors, whereas a use history based on unrelated task features produces the opposite effects. Further, task diversity positively moderates the relationship between a use history of unrelated features and omission errors, but has no significant moderating effect on the relationship between a use history of related features and omission errors. Our findings hold a number of implications for the literature on human error, and these are discussed alongside with the implications of our study for practitioners and system design.																	0167-9236	1873-5797				MAR	2020	130								113225	10.1016/j.dss.2019.113225													
J								An intelligent decision support system prototype for hinterland port logistics	DECISION SUPPORT SYSTEMS										Agent-based model; Port community system; Vehicle routing problem; Reinforcement learning; Freight transportation	AGENT-BASED SIMULATION; FREIGHT TRANSPORT; INFORMATION; MODEL; INTEGRATION	Port logistics is characterised by a high degree of fragmentation, uncertainty and complexity. In a context with these characteristics, decision support can be of significant value. This study presents the prototype of an intelligent decision support system (DSS) that leads to horizontal and vertical cooperation among freight agents involved in port logistics. A multi-agent simulation model is presented where heterogeneous actions are enabled as a result of an adaptive reinforcement learning algorithm that is inspired by human decision-making strategies. The model combines optimisation modelling and decision theory to operate in a dynamic environment characterised by information asymmetry among agents and dynamic changes over time. A simulation demonstrates the dynamics and convergence to equilibrium of the interactions of heterogeneous agents for delivery and pick up of import/export shipments. In particular, we answer two specific research questions. What is the likely impact of an intelligent DSS in hinterland container transport as a value-added service of port community system (PCS)? How can an optimum cooperative strategy be formulated to meet the dynamic demand and supply of freight agents in hinterland container transport and achieve agility in the age of hyper-competition? By addressing these two research questions we make a specific contribution by developing an agent-based simulation model in a real-world and large-scale case study, by using a reinforcement learning model based on probability matching theory that allows simulating realistically the adaptive behaviour of agents. The results of the simulation of two weeks of container movements indicate huge savings in total transport costs and distance travelled as well as higher utilisation of trucks from the sharing of resources. Moreover, we show that it is strictly better for smaller freight agents to cooperate a conclusion generated endogenously inside the model as a tradeoff between exploration and exploitation. As a result of this prototype simulation, major freight agents will not necessarily benefit from the DSS mainly because they are already using the economies of scale.																	0167-9236	1873-5797				MAR	2020	130								113227	10.1016/j.dss.2019.113227													
J								A decision support system for home dialysis visit scheduling and nurse routing	DECISION SUPPORT SYSTEMS										Healthcare; Home dialysis; Visit scheduling; Nurse routing; Mathematical programming; Decision support system	HEALTH-CARE; PERITONEAL-DIALYSIS; HEMODIALYSIS; SERVICES; TIMES; COST	Over the last years home dialysis has become the preferred treatment option for some patients with kidney failure. However, determining efficient and effective daily home-dialysis service plans imposes multiple challenges to hospital administrators, as it is a complex task with a number of interrelated decisions. These decisions are about the number of nurses required for daily visits and their travel itineraries, and involve multiple (often conflicting) objectives. Working together with physicians and administrators from The Ottawa Hospital (TOH) in Canada, we have developed a system intended to support administrators of nephrology departments in creating daily visit schedules and routes for nurses assisting with dialysis treatment in patients' homes. The decision support system, called Home Dialysis Scheduler System (HDSS), employs a mixed-integer linear programming model to create daily nurse itineraries that minimize the cost of providing home dialysis for a pre-specified group of patients. In developing this model, we also considered nurses' workload balance, overtime work, need for mealtime breaks (lunch or dinner, depending on shift times), restrictions and preferences associated with the time of the visits, and different types of services provided to patients. The model was validated using data provided by the Division of Nephrology at TOH. The interface of the HDSS was developed following the principles of user-centred design and validated with a group of end-users. In the validation stage, daily visit schedules and nurse routes generated by the HDSS were compared to nurse itineraries created manually by hospital administrators. The use of the HDSS resulted in improved workload distribution among nurses, simpler routes, and reduced total distance travelled which translates into lower costs for the home dialysis program. In this paper, we provide details about the mixed-integer linear programming model, describe the HDSS, and discuss its implementation results and managerial implications.																	0167-9236	1873-5797				MAR	2020	130								113224	10.1016/j.dss.2019.113224													
J								Recommendation of startups as technology cooperation candidates from the perspectives of similarity and potential: A deep learning approach	DECISION SUPPORT SYSTEMS										Doc2vec; Item-based collaborative filtering; Factor analysis; Startup; M&A	SUCCESS FACTORS; ACQUISITIONS; MERGERS; CORPORATION; EXPLOIT	Companies consistently strive to prepare for new technologies for survival. In a rapidly changing market, absorbing innovation through cooperation strategies can complement internal research and development for new technology development. Startups with state-of-the-art technologies are good candidates for successful cooperation; however, it is difficult to identify their technological positions. Our study suggests a framework to identify appropriate startup candidates using startup profile texts provided by the Crunchbase database. We utilize a doc2vec approach to extract feature vectors representing technological meanings from the startup profile texts and patent abstracts of acquiring companies. Based on these vectors, we apply item-based collaborative filtering to estimate scores for technological similarity between a company and a startup to be acquired. Furthermore, we screen for promising startups using factor analysis, with variables representing the startup's potential. We believe that our framework can save time and effort in the early stage of cooperation planning by supporting effective decision-making.																	0167-9236	1873-5797				MAR	2020	130								113229	10.1016/j.dss.2019.113229													
J								Designing information feedback for bidders in multi-item multi-unit combinatorial auctions	DECISION SUPPORT SYSTEMS										Continuous combinatorial auctions; Real-time bidder support; Multi-unit auctions; Electronic markets	DECISION-SUPPORT; PROCUREMENT AUCTIONS; WINNER DETERMINATION	Combinatorial auctions (CAs) promote allocative efficiency and are important market mechanisms for a wide variety of specialized domains where bidders are allowed to place bids on packages of items. However, the adoption of combinatorial auctions in real-life business scenarios has been fairly limited, perhaps because bidders find it difficult to construct their bids without extensive knowledge of the current state of the auction. In this paper, we develop decision support tools for bidders to provide information feedback at runtime for the general class of combinatorial auctions namely, online (continuous) multi-item multi -unit combinatorial auctions (MUCAs), an area that has witnessed a rapid growth of interest in recent years. In online MUCAs the number of packages may be large, and bidders need real time decision support to construct their bids, such as information on the ask prices of packages. The deadness level of a package serves as the ask price, and indicates the minimum bid on the package that keeps it in contention for inclusion in winning combinations in future. It has proved a challenge to find a satisfactory method for computing the deadness levels of packages in MUCAs. Here we present exact methods for determining package deadness levels in such auctions. Both the OR and the XOR formulations are considered. Experiments on simulated data as well as on live data show that the time and memory requirements are not excessive, so it appears possible to adopt the methods for the procurement and sale of commodities in B2B and B2C markets.																	0167-9236	1873-5797				MAR	2020	130								113230	10.1016/j.dss.2019.113230													
J								Traffic-signal control reinforcement learning approach for continuous-time Markov games	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Traffic signal; Nash games; Continuous-time; Markov models	MULTIAGENT SYSTEM; MODELS	Traffic-Signal Control (TSC) models have been transformed from simple pre-timed isolated indications to a more complex form of actuated and coordinated TSC models for highways, railroads, etc. However, existing TSC models cannot always manage inconveniences like: over-saturation, delays by incidents, congestion by weather conditions, among others, which is why this is still an open area of research. An important challenge is to propose a TSC solution model for multiple intersections, which adapts traffic signal timing according to real-time traffic. This paper introduces a novel Reinforcement Learning (RL) approach for solving the Traffic-Signal Control problem for multiple intersections using Continuous-Time Markov Games (CTMG). The RL model is based on a temporal difference method. For estimating the transition rates of the Markov model, we use non-degenerate randomized Markov laws are being used, such that the connected chain is shown to be ergodic, and to visit all states infinitely often, using all the controls in every state. Our reinforcement learning model supposes to have complete information. The estimation of the transition rates is obtained by the number of transitions on an interval of time divided by the total value of the holding time. The estimation of the rewards is defined as the arithmetic mean of the observed rewards. We consider a non-cooperative game model for solving the multiple intersections problem. For computing the Nash equilibrium, we employ an iterative proximal gradient method. As our final contribution, we present a numerical example for validating our model and concretely measure the benefits of the TSC model.																	0952-1976	1873-6769				MAR	2020	89								103415	10.1016/j.engappai.2019.103415													
J								Detecting indicators of cognitive impairment via Graph Convolutional Networks	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Sensor-based activity recognition; Smart homes; Abnormal behaviour detection; Graph Convolutional Networks; Cognitive decline	ACTIVITY RECOGNITION; ABNORMAL-BEHAVIOR; PATTERNS	While the life expectancy is on the rise all over the world, more people face health related problems such as cognitive decline. Dementia is a name used to describe progressive brain syndromes affecting memory, thinking, behaviour and emotion. People suffering from dementia may lose their abilities to perform daily life activities and they become on their caregivers. Hence, detecting the indicators of cognitive decline and warning the caregivers and medical doctors for further diagnosis would be helpful. In this study, we tackle the problem of activity recognition and abnormal behaviour detection in the context of dementia by observing daily life patterns of elderly people. Since there is no real-world data available, firstly a method is presented to simulate abnormal behaviour that can be observed in daily activity patterns of dementia sufferers. Secondly, Graph Convolutional Networks (GCNs) are exploited to recognise activities based on their granular-level sensor activations. Thirdly, abnormal behaviour related to dementia is detected using activity recognition confidence probabilities. Lastly, GCNs are compared against the state-of-the-art methods. The results obtained indicate that GCNs are able to recognise activities and flag abnormal behaviour related to dementia.																	0952-1976	1873-6769				MAR	2020	89								103401	10.1016/j.engappai.2019.103401													
J								Emotional neural networks with universal approximation property for stable direct adaptive nonlinear control systems	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Brain emotional learning; Direct adaptive control; Nonlinear control; Lyapunov stability theory; Neural networks	TYPE-2 FUZZY CONTROL; INTELLIGENT CONTROLLER; CONTROL STRATEGY; SPEED CONTROL; PD CONTROL; DESIGN; TRACKING; POSITION; MODEL	Universal approximation, continuity, and differentiability are desirable properties of any computational framework, including those that rise from human cognition and/or are inspired by nature. Emotional machines constitute one such framework, but few studies have addressed their mathematical properties. Here, we propose a Continuous Radial Basis Emotional Neural Network (CRBENN) that benefits from the universal approximation property, continuous output, and simple structure of RBF; while keeping the fast response properties of emotion-based approaches. As such, CRBENN is amenable to a wide array of challenging problems in systems engineering and artificial intelligence. Here, we propose a CRBENN-based direct adaptive robust emotional neuro-control approach (DARENC) for a class of uncertain nonlinear systems. Stability is theoretically established using Lyapunov analysis of the closed-loop system. DARENC is then applied to control an inverted pendulum system, and the performance of the controller is numerically compared with several competing fuzzy, neural, and emotional controllers. The simulation results indicate improved tracking performance, better disturbance rejection, and less control effort. Finally, DARENC is implemented on a real-world 3-PSP (spherical-prismatic-spherical) parallel robot in our laboratory. The experimental results show the satisfactory performance of the robot in tracking the desired trajectory with low control effort.																	0952-1976	1873-6769				MAR	2020	89								103447	10.1016/j.engappai.2019.103447													
J								Cross multi-scale locally encoded gradient patterns for off-line text-independent writer identification	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Handwritten documents; Text-independent; Off-line writer identification; Feature extraction; Dissimilarity measure; Hamming distance	ORIENTED GRADIENTS; FEATURES; CLASSIFICATION; DESCRIPTORS; RECOGNITION; EXTRACTION; HISTOGRAMS; RETRIEVAL; CODEBOOK	Writer identification is experiencing a revival of activity in recent years and continues to attract great deal of attention as a challenging and important area of research in the field of forensic and authentication. In this work, we introduce a reliable off-line system for text-independent writer identification of handwritten documents. Feature engineering is an essential component of a pattern recognition system, which can enhance or decrease the classification performance. A well-designed and defined feature extraction method improves the classification task. This paper proposes, for feature extraction, an effective, yet high-quality and conceptually simple feature image descriptor referred to as Cross multi-scale Locally encoded Gradient Patterns (CLGP). The proposed CLGP feature extraction method, which is expected to better represent salient local writing structure, operates at small observation regions (i.e., connected component sub-images) of the writing sample. CLGP histogram feature vectors computed from all these observation regions in all writing samples are considered as classification inputs to identify query writers using the Nearest Neighbor Classifier (1-NN). Our system is evaluated on six standard databases (IFN/ENIT, AHTID/MW, CVL, IAM, Firemaker, and ICDAR2011) including handwritten samples in Arabic, English, French, Greek, German, and Dutch languages. Comparing the identification performance with old and recent state-of-the-art methods, the proposed system achieves the highest performance on IFN/ENIT, AHTID/MW, and ICDAR2011 databases, and demonstrates competitive performance on IAM, CVL, and Firemaker databases.																	0952-1976	1873-6769				MAR	2020	89								103459	10.1016/j.engappai.2019.103459													
J								Minimizing makespan in a Flow Shop Sequence Dependent Group Scheduling problem with blocking constraint	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Group scheduling; Meta-heuristic algorithm; Linear programming; Optimization	MANUFACTURING CELL; GENETIC ALGORITHM; EVOLUTIONARY ALGORITHMS; FAMILY; LINE; OPTIMIZATION; PARAMETERS; TIME	Flow Shop Sequence Dependent Group Scheduling (FSDGS) problems gathered much attention from the body of literature in recent years. Nevertheless, the combination of blocking constraint and Group Technology (GT) principles has not been faced by academics so far. The aim of the present paper is to propose an original meta-heuristic approach for minimizing makespan in a FSDGS problem with blocking constraint. To this end, a novel Parallel Self-Adaptive Genetic Algorithm (PSAGA) which adaptively varies the genetic parameters along the evolutionary mechanism was devised. Validation of the proposed metaheuristics was performed by means of the global optima generated by a proper mixed integer linear programming model. An extended experimental campaign, also supported by a specific statistical analysis, demonstrates the effectiveness of the proposed approach compared to other meta-heuristics arising from the relevant literature.																	0952-1976	1873-6769				MAR	2020	89								103413	10.1016/j.engappai.2019.103413													
J								Integrating overlapping community discovery and role analysis: Bayesian probabilistic generative modeling and mean-field variational inference	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Overlapping community discovery; Role analysis; Link explanation and prediction; Generative probabilistic modeling; Bayesian network analysis	NERVOUS-SYSTEM; NETWORKS	The joint modeling of community discovery and role analysis was shown useful to explain, predict and reason on network topology. Nonetheless, earlier research on the integration of both tasks suffers from major limitations. Foremost, a key aspect of role analysis, i.e., the strength of role-to-role interactions, is ignored. Moreover, two fundamental properties of networks are disregarded, i.e., heterogeneity in the connectivity structure of communities and the growing link probability with node involvement in common communities. Additionally, scalability with network size is limited. In this manuscript, we incrementally develop two new machine learning approaches to deal with the foresaid issues. The proposed approaches consist in performing inference under as many Bayesian generative models of networks with overlapping communities and roles. Under both models, nodes are associated with communities and roles through suitable affiliations, that are dichotomized for link directionality. The strength of such affiliations is captured through nonnegative latent random variables, drawn from Gamma priors. Besides, link establishment is explained by both models through Poisson distributions. In particular, under the second model, the parameterizing rate of the Poisson distribution also accommodates the strength of role-to role interactions, as captured via latent mixed-membership stochastic blockmodeling. On sparse networks, the adoption of the Poisson distribution expedites model inference. On this point, mean-field variational inference is derived and implemented as a coordinate-ascent algorithm, for the exploratory and unsupervised analysis of node affiliations. Comparative experiments on several real-world networks demonstrate the superiority of the proposed approaches in community discovery, link prediction as well as scalability.																	0952-1976	1873-6769				MAR	2020	89								103437	10.1016/j.engappai.2019.103437													
J								Improved magnetic charged system search optimization algorithm with application to satellite formation flying	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Metaheuristic physics-inspired algorithm; Constrained optimization; Trajectory planning; Satellite formation flying	PARTICLE SWARM OPTIMIZATION; RENDEZVOUS TRAJECTORIES; DIFFERENTIAL EVOLUTION; GRAVITATIONAL SEARCH; OPTIMAL-DESIGN; SPACECRAFT; COLONY; MANEUVERS; FLATNESS	This paper is devoted to the implementation and application of an improved version of the metaheuristic algorithm called magnetic charged system search. Some modifications and novelties are introduced and tested. Firstly, the authors' attempt is to develop a self-adaptive and user-friendly algorithm which can automatically set all the preliminary parameters (such as the numbers of particles, the maximum iterations number) and the internal coefficients. Indeed, some mathematical laws are proposed to set the parameters and many coefficients can dynamically change during the optimization process based on the verification of internal conditions. Secondly, some strategies are suggested to enhance the performances of the proposed algorithm. A chaotic local search is introduced to improve the global best particle of each iteration by exploiting the features of ergodicity and randomness. Moreover, a novel technique is proposed to handle bad-defined boundaries; in fact, the possibility to self-enlarge the boundaries of the optimization variables is considered, allowing to achieve the global optimum even if it is located on the boundaries or outside. The algorithm is tested through some benchmark functions and engineering design problems, showing good results, followed by an application regarding the problem of time-suboptimal manoeuvres for satellite formation flying, where the inverse dynamics technique, together with the B-splines, is employed. This analysis proves the ability of the proposed algorithm to optimize control problems related to space engineering, obtaining better results with respect to more common and used algorithms in literature.																	0952-1976	1873-6769				MAR	2020	89								103473	10.1016/j.engappai.2020.103473													
J								Machine-tool condition monitoring with Gaussian mixture models-based dynamic probabilistic clustering	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Concept drift; Condition monitoring; Data stream; Dynamic clustering; Gaussian mixture model; Machining operation	DATA STREAMS; TIME-SERIES	The combination of artificial intelligence with data, computing power, and new algorithms can provide important tools for solving engineering problems, such as machine-tool condition monitoring. However, many of these problems require algorithms that can perform in highly dynamic scenarios where the data streams have extremely high sampling rates from different types of variables. The unsupervised learning algorithm based on Gaussian mixture models called Gaussian-based dynamic probabilistic clustering (GDPC) is one of these tools. However, this algorithm may have major limitations if a large amount of concept drifts associated with transients occurs within the data stream. GDPC becomes unstable under these conditions, so we propose a new algorithm called GDPC+ to increase its robustness. GDPC+ represents an important improvement because we introduce: (a) automatic selection of the number of mixture components based on the Bayesian information criterion (BIC), and (b) concept drift transition stabilization based on Cauchy-Schwarz divergence integrated with the Dickey Fuller test. Thus, GDPC+ can perform better in highly dynamic scenarios than GDPC in terms of the number of false positives. The behavior of GDPC+ was investigated using random synthetic data streams and in a real data stream-based condition monitoring obtained from a machine-tool that produces engine crankshafts at high speed. We found that the initial temporal window size can be used to adapt the algorithm to different analytical requirements. The clustering results were also investigated by induction of the rules generated by the repeated incremental pruning to produce error reduction (RIPPER) algorithm in order to provide insights from the underlying monitored process and its associated concept drifts.																	0952-1976	1873-6769				MAR	2020	89								103434	10.1016/j.engappai.2019.103434													
J								A novel Island Model based on Coral Reefs Optimization algorithm for solving the unequal area facility layout problem	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										UA-FLP; Facility layout; Island model; Coral Reefs Optimization; Meta-heuristics	BAY STRUCTURE REPRESENTATION; GENETIC ALGORITHM; SUBSTRATE LAYERS; DESIGN-PROBLEMS; BLOCK LAYOUT; SLICING TREE; TABU SEARCH; SIMULATION	This paper proposes a novel approach to address the Unequal Area Facility Layout Problem (UA-FLP), based on the combination of both an Island Model and a Coral Reefs Optimization (CRO) algorithm. Two different versions of this Island Model based on Coral Reefs Optimization Algorithm (IMCRO) are proposed and applied to the UA-FLP. The structure of flexible bays has been selected as effective encoding to represent the facility layouts within the algorithm. The two versions of the proposed approach have been tested in 22 UA-FLP cases, considering small, medium and large size categories. The empirical results obtained are compared with previous state of the art algorithms, in order to show the performance of the IMCRO. From this comparison, it can be extracted that both versions of the proposed IMCRO algorithm show an excellent performance, accurately solving the UA-FLP instances in all the size categories.																	0952-1976	1873-6769				MAR	2020	89								103445	10.1016/j.engappai.2019.103445													
J								Data-driven oriented optimization of resource allocation in the forging process using Bi-objective Evolutionary Algorithm	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Resource allocation; Searching strategy; Information flow; Bi-objective Evolutionary Algorithm	GENETIC ALGORITHMS; PARAMETERS	Resource allocation in the forging process of the steel production industry is an important element of the material supply in upstream processes, and the subsequent processing of semi-finished products downstream. However, the existing literature rarely discusses issues related to this problem. In this study, the information flow is built by referring to specifications and process logic, which is a kind of pre-processing in data analysis flow in order to break the initial barrier of resource allocation in forging. In addition, Bi-objective Evolutionary Algorithm (BOEA) is proposed to optimize the resource allocation in the forging process. Using the built information flow, the available multiple forging process resources can be effectively connected, and information of available resource combinations can be established for orders. Since real users have preferences for different objectives in practice, experiment results show that the proposed BOEA can deal with these preferences by effectively optimizing both the remnants (the remaining materials) and the execution cost, and the profit contribution is also proved by effective cost savings.																	0952-1976	1873-6769				MAR	2020	89								103469	10.1016/j.engappai.2019.103469													
J								A fitting model based intuitionistic fuzzy rough feature selection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Rough set; Fuzzy set; Intuitionistic fuzzy set; Degree of dependency; Feature selection	ATTRIBUTE REDUCTION; UNCERTAINTY MEASURES; SET APPROACH; ALGORITHM	Feature subset selection is an essential machine learning approach aimed at the process of dimensionality reduction of the input space. By removing irrelevant and/or redundant variables, not only it enhances model performance, but also facilitates its improved interpretability. The fuzzy set and the rough set are two different but complementary theories that apply the fuzzy rough dependency as a criterion for performing feature subset selection. However, this concept can only maintain a maximal dependency function. It cannot preferably illustrate the differences in object classification and does not fit a particular dataset well. This problem was handled by using a fitting model for feature selection with fuzzy rough sets. However, intuitionistic fuzzy set theory can deal with uncertainty in a much better way when compared to fuzzy set theory as it considers positive, negative and hesitancy degree of an object simultaneously to belong to a particular set. Therefore, in the current study, a novel intuitionistic fuzzy rough set model is proposed for handling above mentioned problems. This model fits the data well and prevents misclassification. Firstly, intuitionistic fuzzy decision of a sample is introduced using neighborhood concept. Then, intuitionistic fuzzy lower and upper approximations are constructed using intuitionistic fuzzy decision and parameterized intuitionistic fuzzy granule. Furthermore, a new dependency function is established. Moreover, a greedy forward algorithm is given using the proposed concept to calculate reduct set. Finally, this algorithm is applied to the benchmark datasets and a comparative study with the existing algorithm is presented. From the experimental results, it can be observed that the proposed model provides more accurate reduct set than existing model.																	0952-1976	1873-6769				MAR	2020	89								103421	10.1016/j.engappai.2019.103421													
J								Three-dimensional pavement crack detection based on primary surface profile innovation optimized dual-phase computing	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										3D pavement crack detection; Primary surface profile; Dual-phase computing; Curve fitting	DIGITAL IMAGE CORRELATION	Accurate pavement crack detection has long been a challenging task, causing significant difficulties to the pavement management sectors in the managerial decision making. The high complexity of the crack's characteristics and the less effective of the crack analytical tools are the two crucial aspects to be accounted for. Recently, three-dimensional (3D) technology based high precision crack detection methodologies has undergone extensive developments. Nevertheless, none of those methods has taken into the errors caused by the data collection systems into consideration, resulting in a less satisfying performance. Hence, the primary objective of this research is to outline the Primary Surface Profile (PSP) optimized dual-phase computing 3D crack detection methodology. Two years ago, variations caused by the automatic 3D data collection systems were observed, so researchers proposed PSP based data filtering algorithm. Therefore, this research is the upgrade solution of the previous innovation regarding the unbiased 3D pavement crack detection. Firstly, the dual-phase computing approach is proposed in dealing with the non-variance 3D data. Then, the self-adaptive 3D PSP generation method is introduced. Finally, PSP is embedded in the dual-phase computing method for performance optimization. For performance assessment, both precisions and recalls of the proposed approach are compared with conventional method for transverse, longitudinal, and map crack detections. Even crack detection precisions are found for both methods, which are all higher than 0.9. However, the recalls of the proposed method (transverse cracks:0.973, longitudinal cracks:0.981, map cracks:0.940) are significantly outperforming non-optimized dual-phase computing method (transverse cracks: 0.682, longitudinal cracks: 0.789, map cracks:0.811).																	0952-1976	1873-6769				MAR	2020	89								103376	10.1016/j.engappai.2019.103376													
J								New mixed-coding PSO algorithm for a self-adaptive and automatic learning of Mamdani fuzzy rules	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Mamdani fuzzy system; PSO algorithm; Optimization; Automatic learning; Semantic interpretability	PARTICLE SWARM OPTIMIZATION; INVERTED PENDULUM; SYSTEMS; IDENTIFICATION; DESIGN; CONTROLLER; SUGENO; INFERENCE; MODEL; INTERPRETABILITY	Thanks to its algorithmic performances, PSO algorithm becomes a popular tune tool for fuzzy systems in literature. However, it still encounters many complications, especially when dealing with Mamdani fuzzy system type because of its nature. The Mamdani fuzzy system is known as a linguistic model where the semantic meaning of the fuzzy rules is an intrinsic characteristic that must be retained during the learning process, while seeking for high accuracy. Therefore, to tune the Mamdani fuzzy system, it is very crucial to well represent each rule in a way that preserves this characteristic firstly, and to look for a search mechanism to optimize them throughout this topic secondly. In this paper, we introduce a new and promising approach to optimize the Mamdani fuzzy systems without a need of any prior knowledge. To the best of our knowledge, this approach is the first to optimize simultaneously the membership functions, the scaling factor parameters and the fuzzy rule conclusions with a mixed-coding PSO algorithm by combining a special monitoring function and a self-adaptive threshold. The proposed approach is validated by a comparative study with other design strategies taken from Box-Jenkins gas furnace system literature and two theoretical examples in addition to a real-time control of the inverted pendulum Feedback 33-200. The obtained results proved the potential and the effectiveness of the proposed approach.																	0952-1976	1873-6769				MAR	2020	89								103417	10.1016/j.engappai.2019.103417													
J								Genetic programming based feature construction methods for foreground object segmentation	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Genetic programming; Feature construction; Foreground object segmentation; Bloat control	FEATURE-SELECTION; CLASSIFICATION	Foreground object segmentation is a crucial preprocessing step for many high-level computer vision tasks, e.g. object recognition. It is still challenging to achieve accurate segmentation, especially for complex images (e.g. with high variations). Feature construction can help to improve the segmentation performance by extracting more distinctive features for foreground/background regions from the original features. However, commonly-used feature construction methods (e.g. principle component analysis) often involve certain assumptions/constraints, and the constructed features cannot be interpreted. To address these problems, genetic programming (GP) is employed in this paper, which is a well-suited feature construction technique. The aim of this work is to design new feature construction methods using GP, and analyse/compare popular GP-based feature construction methods for foreground object segmentation, especially on complex image datasets with high variations. Specifically, one new feature construction method that incorporates the subtree technique in GP is designed, which can construct multiple features simultaneously (called SubtMFC, Subtree Multiple Feature Construction). Moreover, a parsimony pressure technique is introduced to improve SubtMFC for bloat control (a common issue for GP-based methods), which forms the method, PSubtMFC (Parsimony SubtMFC). In addition, comparison of popular GP-based feature construction methods for foreground object segmentation is conducted for the first time. Results show that SubtMFC achieves better or similar performance compared with three reference methods. In addition, compared with SubtMFC that does not control bloat, PSubtMFC can significantly reduce the solution size while maintain similar performance in the segmentation accuracy. The GP-based feature construction framework is further extended for feature representation based knowledge transfer, which can handle the problem of the scare labelled training data. Moreover, after GP is thoroughly investigated on benchmark datasets with one type of foreground objects (i.e. the Weizmann horse dataset and Pascal aeroplane dataset), it is considered whether the GP methods can perform well on datasets containing multiple types of foreground objects. Compared with three other well-performing GP-based feature construction methods, the proposed method achieves better or comparable results for the given segmentation tasks. In addition, this paper thoroughly compares/analyses popular GP-based feature construction methods for complex figureground segmentation for the first time. Moreover, further analyses on the input features frequently used by the GP-evolved feature construction functions reflect the effectiveness of the extracted high-level features.																	0952-1976	1873-6769				MAR	2020	89								103334	10.1016/j.engappai.2019.103334													
J								A heuristic algorithm combining Pareto optimization and niche technology for multi-objective unequal area facility layout problem	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Facility layout problem; Heuristic algorithm; Multi-objective optimization; Pareto optimal; Global optimization	GENETIC ALGORITHM; SEARCH; SYSTEM; REPRESENTATION	The unequal area facility layout problem (UA-FLP) is the problem of placing departments with different areas in a facility so that departments satisfy some given objectives and constraints. In this paper, two objectives including the material handling cost and the closeness rating are optimized. Based on the quasi-physical strategy, we introduce an extrusive elastic potential energy based on the overlapping distance between departments into the layout system. After a novel handling approach of the non-overlapping constraint formed by executing the gradient method with an adaptive step length and subsequent department deformation strategy is developed to deal with the interference among departments and between any department and the facility, the problem is first converted into an optimization problem without the non-overlapping constraint. Then, we use a new heuristic algorithm that combines the local search based on the Pareto optimization and the global optimum search based on the niche technology to obtain Pareto-optimal solutions of the problem. In the proposed heuristic algorithm, in order to overcome the shortcomings of low efficient search toward the diversity of solutions in classical Pareto optimization method, we propose a heuristic layout updating strategy and a niche technology. To improve the convergence of the algorithm to the Pareto front, a mechanism of evolution of population named a feasible layout bank in the algorithm based on the local search and global optimum search is proposed. Two sets of representative instances from the literature with the size of the problem up to 62 departments are tested. The experimental results show that the proposed heuristic algorithm is an effective method for solving the multi-objective UA-FLP.																	0952-1976	1873-6769				MAR	2020	89								103453	10.1016/j.engappai.2019.103453													
J								Refraction-learning-based whale optimization algorithm for high-dimensional problems and parameter estimation of PV model	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Whale optimization algorithm; Refraction learning; High-dimensional optimization; Engineering design optimization; Photovoltaic model; Parameter estimation	PARTICLE SWARM OPTIMIZATION; ARTIFICIAL BEE COLONY; BACKTRACKING SEARCH ALGORITHM; GREY WOLF OPTIMIZER; DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION; DESIGN; STRATEGY; VELOCITY; CELLS	Whale optimization algorithm (WOA) is a relatively new meta-heuristic optimization algorithm which mimics the hunting behavior of humpback whales. This paper presents a modified version of WOA, called RLWOA, for solving high-dimensional optimization problems. The proposed RLWOA adopts a modified conversion parameter update rule that relies on Logistic model to balance between diversity and convergence during the search process, and a new refraction-learning strategy based on the principle of refraction of light is proposed to help the population jump out of a local optimum. The experiments on a set of benchmark test functions with various features, i.e., 12 widely used benchmark functions with 100, 1000, and 10000 dimensions, two practical engineering design problems, and parameter estimation problem of photovoltaic model. The comparisons demonstrate that the proposed RLWOA shows better or at least competitive performance against the standard WOA, WOA variants and other state-of-the-art meta-heuristic algorithms for solving high-dimensional numerical optimization, practical engineering design optimization, and photovoltaic model parameter estimation problems.																	0952-1976	1873-6769				MAR	2020	89								103457	10.1016/j.engappai.2019.103457													
J								A soft set based VIKOR approach for some decision-making problems under complex neutrosophic environment	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Complex neutrosophic soft set; Complex neutrosophic aggregation; Complex neutrosophic soft union; Complex neutrosophic soft intersection; Score function; VIKOR method	WEIGHT	Applications in various fields of neutrosophic soft set theory enhance its appreciation to the researchers. Although, this uncertain solving tool can accomplish several types of real-life problems, but not able to deal with the decision-making problems in which considering an additional information of a corresponding parameter is needed to get a proper decision from a problem. But, complex neutrosophic soft sets can handle such type of decision-making problems. Consequently, in this study, we have given concentration on solving soft set based decision-making problems in the field of complex neutrosophic environment. Firstly, we have introduced some basic set-theoretic operations of complex neutrosophic sets including different types of unions, intersections and aggregations. Then, a new definition of score function of a complex neutrosophic number has been proposed. Additionally, the above-defined unions and intersections of complex neutrosophic sets have been stated for complex neutrosophic soft sets. Finally, by utilizing these proposed notions, we have offered a complex neutrosophic soft VIKOR approach to get a compromise optimal solution for single as well as multiple decision-maker based problems. Our proposed approach has been clarified by several real life-related problems including medical diagnosis problem, sustainable manufacturing material selection problem, company's manager selection problem, etc. The feasibility and effectiveness of our proposed approach have also been included in the article.																	0952-1976	1873-6769				MAR	2020	89								103432	10.1016/j.engappai.2019.103432													
J								Cost of selfishness in the allocation of cities in the Multiple Travelling Salesmen Problem	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Centralised Organisation (CO); Decentralised Organisation (DO); Selfishness; Multiple Travelling Salesmen Problem (MTSP)		The decision to centralise or decentralise human organisations needs to be based on quantified evidence, yet little is available in the literature. We provide such data in a variant of the Multiple Travelling Salesmen Problem (MTSP) in which we study how the allocation sub-problem may be decentralised among selfish salesmen. Our contributions are: (i) this modification of the MTSP to include selfishness; (ii) the proposition of organisations to solve this modified MTSP; and (iii) the comparison of these organisations. Our 5 organisations may be summarised as follows: (i) OptDecentr is a pure Centralised Organisation (CO) in which a Central Authority (CA) finds the best solution that could be found by a Decentralised Organisation (DO); (ii) Cluster and (iii) Auction are CO/DO hybrids; and (iv) P2P and (v) CNP are pure DO. The sixth and seventh organisations are used as benchmarks: (vi) NoRealloc is a pure DO which ignores the allocation problem; and (vii) FullCentr is a pure CO which solves a different problem, viz., the traditional MTSP. Comparing the efficiency of pairs of these mechanisms quantifies the price of decentralising an organisation. In particular, our model of selfishness in OptDecentr, with 5 (respectively, 9) salesmen, makes the total route length 30% (respectively, 60%) longer than the traditional MTSP in FullCentr when the computation time is limited to 30 min. With this time limit, our results also seem to indicate that the level of coercion of the CA impacts the total route length more than the level of centralisation.																	0952-1976	1873-6769				MAR	2020	89								103429	10.1016/j.engappai.2019.103429													
J								Real-time EEG classification via coresets for BCI applications	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Machine learning; Coreset; Data structures; On-line learning; Electroencephalogram (EEG); Brain computer interface (BCI)	SPATIAL-PATTERN; APPROXIMATION ALGORITHMS; EXTRACTION	A brain-computer interface (BCI) based on the motor imagery (MI) paradigm translates a subject's motor intention into a control signal by classifying the electroencephalogram (EEG) signals of different tasks. However, most existing systems use either (i) a high-quality algorithm to train the data off-line and run only the classification in real-time since the off-line algorithm is too slow, or (ii) low-quality heuristics that are sufficiently fast for real-time training but introduce relatively large classification error. In this work, we propose a novel processing pipeline that allows real-time and parallel learning of EEG signals using high-quality but potentially inefficient algorithms. This is done by forging a link between BCI and coresets, a technique that originated in computational geometry for handling streaming data via data summarization. We suggest an algorithm that maintains the representation of such coresets tailored to handle the EEG signal which enables (i) real-time and continuous computation of the common spatial pattern (CSP) feature extraction method on a coreset representation of the signal (instead of the signal itself), (ii) improvement of CSP algorithm efficiency with provable guarantees by applying the CSP algorithm on the coreset, and (iii) real-time addition of the data trials (EEG data windows) to the coreset. For simplicity, we focus on the CSP algorithm, which is a classic algorithm. Nevertheless, we expect that our coreset will be extended to other algorithms in future papers. In the experimental results, we show that our system can indeed learn EEG signals in real-time in, for example, a 64-channel setup with hundreds of time samples per second.																	0952-1976	1873-6769				MAR	2020	89								103455	10.1016/j.engappai.2019.103455													
J								DFNet: Discriminative feature extraction and integration network for salient object detection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Salient object detection; Deep convolutional neural networks; Fully convolutional neural networks; Attention guidance	MODEL	Despite the powerful feature extraction capability of Convolutional Neural Networks, there are still some challenges in saliency detection. In this paper, we focus on two aspects of challenges: i) Since salient objects appear in various sizes, using single-scale convolution would not capture the right size. Moreover, using multi-scale convolutions without considering their importance may confuse the model. ii) Employing multi-level features helps the model use both local and global context. However, treating all features equally results in information redundancy. Therefore, there needs to be a mechanism to intelligently select which features in different levels are useful. To address the first challenge, we propose a Multi-scale Attention Guided Module. This module not only extracts multi-scale features effectively but also gives more attention to more discriminative feature maps corresponding to the scale of the salient object. To address the second challenge, we propose an Attention-based Multi-level Integrator Module to give the model the ability to assign different weights to multi-level feature maps. Furthermore, our Sharpening Loss function guides our network to output saliency maps with higher certainty and less blurry salient objects, and it has far better performance than the Cross-entropy loss. For the first time, we adopt four different backbones to show the generalization of our method. Experiments on five challenging datasets prove that our method achieves the state-of-the-art performance. Our approach is fast as well and can run at a real-time speed.																	0952-1976	1873-6769				MAR	2020	89								103419	10.1016/j.engappai.2019.103419													
J								An Evolutionary Neuro-Fuzzy C-means Clustering Technique	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Evolutionary optimization; Artificial neural network; Fuzzy C-means clustering; Optimal cluster number; Variable size reduction	METAHEURISTIC ALGORITHM; VALIDITY INDEX; OPTIMIZATION; EFFICIENCY; NETWORKS	One of the standard approaches for data analysis in unsupervised machine learning techniques is cluster analysis or clustering, where the data possessing similar features are grouped into a certain number of clusters. Among several significant ways of performing clustering, Fuzzy C-means (FCM) is a methodology, where every data point is hypothesized to be associated with all the clusters through a fuzzy membership function value. FCM is performed by minimizing an objective functional by optimally estimating the decision variables namely, the membership function values and cluster representatives, under a constrained environment. With this approach, a marginal increase in the number of data points leads to an enormous increase in the size of decision variables. This explosion, in turn, prevents the application of evolutionary optimization solvers in FCM, which thereby leads to inefficient data clustering. In this paper, a Neuro-Fuzzy C-Means Clustering algorithm (NFCM) is presented to resolve the issues mentioned above by adopting a novel Artificial Neural Network (ANN) based clustering approach. In NFCM, a functional map is constructed between the data points and membership function values, which enables a significant reduction in the number of decision variables. Additionally, NFCM implements an intelligent framework to optimally design the ANN structure, as a result of which, the optimal number of clusters is identified. Results of 9 different data sets with dimensions ranging from 2 to 30 are presented along with a comprehensive comparison with the current state-of-the-art clustering methods to demonstrate the efficacy of the proposed algorithm.																	0952-1976	1873-6769				MAR	2020	89								103435	10.1016/j.engappai.2019.103435													
J								Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Machine learning; Parallel computing; Extreme learning machines; Stochastic learning; Regression; Classification; Big data	PARTICLE SWARM OPTIMIZATION; GRADIENT DESCENT; ALGORITHMS	Artificial hydrocarbon networks (AHN) a supervised learning method inspired on organic chemical structures and mechanisms - have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 10,000x times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.																	0952-1976	1873-6769				MAR	2020	89								103427	10.1016/j.engappai.2019.103427													
J								An effective clustering method based on data indeterminacy in neutrosophic set domain	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Data clustering; Neutrosophic theory; Data indeterminacy; Image segmentation	IMAGE SEGMENTATION; PATTERN-RECOGNITION; LIVER IMAGE; ALGORITHM; BOUNDARY; UNCERTAINTY	In this work, a new clustering algorithm is proposed based on neutrosophic set (NS) theory. The main contribution is to use NS to handle boundary and outlier points as challenging points of clustering methods. In the first step, a new definition of data indeterminacy (indeterminacy set) is proposed in NS domain based on density properties of data. Lower indeterminacy is assigned to data points in dense regions and vice versa. In the second step, indeterminacy set is presented for a proposed cost function in NS domain by considering a set of main clusters and a noisy cluster. In the proposed cost function, two conditions based on distance from cluster centers and value of indeterminacy, are considered for each data point. In the third step, the proposed cost function is minimized by gradient descend methods. Data points are clustered based on their membership degrees. Outlier points are assigned to noise cluster; and boundary points are assigned to main clusters with almost same membership degrees. To show the effectiveness of the proposed method, three types of datasets including diamond, UCI and image datasets are used. Results demonstrate that the proposed cost function handles boundary and outlier points with more accurate membership degrees and outperforms existing state of the art clustering methods in all datasets.																	0952-1976	1873-6769				MAR	2020	89								103411	10.1016/j.engappai.2019.103411													
J								A novel incremental Kernel Nonparametric SVM model (iKN-SVM) for data classification: An application to face detection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Incremental learning; Classification; Support Vector Machines; Nonparametric discriminant analysis; Kernel-based methods; Face detection	DISCRIMINANT-ANALYSIS; VIDEO SURVEILLANCE; RECOGNITION; ALGORITHM	In this paper, we propose a novel incremental classifier to overcome problems associated with batch techniques, along with issues related to data spread that Kernel Support Vector Machines (KSVM) may encounter. Basically, we present a Kernel SVM-based model that learns incrementally, as new data is available over time, in order to handle dynamic and large data effectively and reduce the computational time. The proposed model deals with the data spread issues by introducing near-global variations, from the scatter matrices of the Kernel Nonparametric Discriminant Analysis (KNDA), into the optimization problem of incremental KSVM, while considering local characteristics of the data provided by KSVM. Besides, our model has a quadratic convex optimization problem with one global solution. Furthermore, an extensive comparison of the model with other state-of-the-art incremental and batch algorithms on various datasets, has been carried out, in order to show its advantages and effectiveness for classification tasks. Moreover, an evaluation of the proposed method on face detection is provided.																	0952-1976	1873-6769				MAR	2020	89								103468	10.1016/j.engappai.2019.103468													
J								Incremental model-based global dual heuristic programming with explicit analytical calculations applied to flight control	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Global dual heuristic programming; Flight control; Incremental technique; Analytical calculation; Artificial neural network	ALGORITHM; SYSTEMS	A novel adaptive dynamic programming method, called incremental model-based global dual heuristic programming, is proposed to generate a self-learning adaptive flight controller, in the absence of sufficient prior knowledge of system dynamics. An incremental technique is employed for online local dynamics identification, instead of the artificial neural networks commonly used in global dual heuristic programming, to enable a fast and precise learning. On the basis of the identified model, two neural networks are adopted to facilitate the implementation of the self-learning controller, by approximating the cost-to-go and the control policy, respectively. The required derivatives of cost-to-go are computed by explicit analytical calculations based on differential operations. Both methods are applied to an online attitude tracking control problem of a nonlinear aerospace system and the results show that the proposed method outperforms conventional global dual heuristic programming in tracking precision, online learning speed, robustness to different initial states and adaptability for fault-tolerant control problems.																	0952-1976	1873-6769				MAR	2020	89								103425	10.1016/j.engappai.2019.103425													
J								Combinatorial search for selecting the structure of models of dynamical systems with equation discovery	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Combinatorial optimization; Combinatorial search; Computational scientific discovery; Equation discovery; Symbolic regression; Knowledge representation; Process-based modeling; Dynamical systems	ARTIFICIAL-INTELLIGENCE; IDENTIFICATION; KNOWLEDGE; NETWORK; SWARM	Automated modeling aims at the induction of mathematical models, both their structure and parameter values, from time-series measurements of observed system variables. In this paper, we address the task of model structure selection, i.e., selecting an optimal structure from a user-specified finite set of alternative model structures, using various approaches to combinatorial search. We propose a mapping of the set of candidate model structures to a fixed-length, vector representation allowing the use of an arbitrary search algorithm as a solver of the structure selection task. We perform a comparative analysis of the performance of thirteen variants of several search algorithms, ranging from ones with high intensification, i.e., focus on neighborhood of the best candidate solutions, to ones with high diversification, i.e., focus on covering the entire search space. The empirical analysis involves eight tasks of reconstructing known models of dynamical systems from synthetic and measured data. The results of the analysis show that search algorithms involving moderate diversification methods have superior performance on the structure selection task. The empirical analysis also reveals that this finding is related to specific properties of the search space of candidate model structures.																	0952-1976	1873-6769				MAR	2020	89								103423	10.1016/j.engappai.2019.103423													
J								Audio content analysis for unobtrusive event detection in smart homes	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Smart homes; Ambient assisted living; Audio signal processing; Feature extraction; Feature selection; Deep learning	CONVOLUTIONAL NEURAL-NETWORKS; ACTIVITY RECOGNITION	Environmental sound signals are multi-source, heterogeneous, and varying in time. Many systems have been proposed to process such signals for event detection in ambient assisted living applications. Typically, these systems use feature extraction, selection, and classification. However, despite major advances, several important questions remain unanswered, especially in real-world settings. This paper contributes to the body of knowledge in the field by addressing the following problems for ambient sounds recorded in various real-world kitchen environments: (1) which features and which classifiers are most suitable in the presence of background noise? (2) what is the effect of signal duration on recognition accuracy? (3) how do the signal-to-noise-ratio and the distance between the microphone and the audio source affect the recognition accuracy in an environment in which the system was not trained? We show that for systems that use traditional classifiers, it is beneficial to combine gammatone frequency cepstral coefficients and discrete wavelet transform coefficients and to use a gradient boosting classifier. For systems based on deep learning, we consider 1D and 2D Convolutional Neural Networks (CNN) using mel-spectrogram energies and mel-spectrograms images as inputs, respectively, and show that the 2D CNN outperforms the 1D CNN. We obtained competitive classification results for two such systems. The first one, which uses a gradient boosting classifier, achieved an F1-Score of 90.2% and a recognition accuracy of 91.7%. The second one, which uses a 2D CNN with mel-spectrogram images, achieved an F1-Score of 92.7% and a recognition accuracy of 96%.																	0952-1976	1873-6769				MAR	2020	89								103226	10.1016/j.engappai.2019.08.020													
J								Predicting customer absence for automobile 4S shops: A lifecycle perspective	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										4S shop; Repair and maintenance; CRM; Recurrent neural network; Behavioral model	RECURRENT NEURAL-NETWORKS; CHURN PREDICTION; RELATIONSHIP MANAGEMENT; SEGMENTATION; SERVICES; MODEL	Repair and maintenance services are among the most lucrative aspects of the entire automobile business chain. However, in the context of fierce competition, customer chums have led to the bankruptcy of several 4S (sales, spare parts, services, and surveys) shops. In this regard, a six-year dataset is utilized to study customer behaviors to aid managers identify and retain valuable but potential customer churn through a customized retention solution. First, we define the absence and presence behaviors of customers and thereafter generate absence data according to customer habits; this makes it possible to treat the customer absence prediction problem as a classification problem. Second, the repeated absence and presence behaviors of customers are considered as a whole from a lifecycle perspective. A modified recurrent neural network (RNN-2L) is proposed; it is more efficient and reasonable in structure compared with traditional RNN. The time-invariant customer features and the sequential lifecycle features are handled separately; this provides a more sensible specification of the RNN structure from a behavioral interpretation perspective. Third, a customized retention solution is proposed. By comparing the proposed model with those that are conventional, it is found that the former outperforms the latter in terms of area under the curve (AUC), confusion matrix, and amount of time consumed. The proposed customized retention solution can achieve significant profit increase. This paper not only elucidates the customer relationship management in the automobile aftermarket (where the absence and presence behaviors are infrequently considered), but also presents an efficient solution to increase the predictive power of conventional machine learning models. The latter is achieved by considering behavioral and business perspectives.																	0952-1976	1873-6769				MAR	2020	89								103405	10.1016/j.engappai.2019.103405													
J								Multiple Universum Empirical Kernel Learning	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Multiple kernel learning; Empirical kernel mapping; Universum learning; Imbalanced data; Pattern recognition	SUPPORT VECTOR MACHINE; CONSISTENCY	This paper proposes a novel framework called Multiple Universum Empirical Kernel Learning (MUEKL) that combines the Universum learning with Multiple Empirical Kernel Learning (MEKL) for the first time to inherit the advantages of both techniques. The proposed MUEKL not only obtained supplementary information of multiple feature spaces through MEKL, but also obtained priori information of samples by Universum learning. MUEKL incorporates a novel method, Imbalanced Modified Universum (IMU), to generate more efficient Universum samples by introducing the imbalanced ratio of data. MUEKL develops the basic multiple kernel learning framework by introducing a regularization of Universum data. The function of the introduced regularization is to adjust the classifier boundary closer to the Universum data to alleviate the influence of the imbalanced data. Moreover, MUEKL performs excellent generalization for both the imbalanced and balanced problems. Extensive experiments verify the effectiveness of the MUEKL and IMU.																	0952-1976	1873-6769				MAR	2020	89								103461	10.1016/j.engappai.2019.103461													
J								Multi-phase trajectory optimization for an aerial-aquatic vehicle considering the influence of navigation error	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Aerial-aquatic vehicle; Multi-phase trajectory optimization; Navigation error; Teach & learn-based optimization; Terrain matching	METAHEURISTIC ALGORITHM; EVOLUTIONARY; STRATEGY	The environment-induced multi-phase trajectory optimization problem is studied in this paper, and the underwater target tracking task is focused on. The task is finished by an aerial-aquatic coaxial eight-rotor vehicle and is divided into two phases, i.e., the diving phase and the underwater navigation phase. The dynamic model and constraints on angular velocity of rotor in each phase are established to understand the motion characteristic. Then the model of navigation information and terrain matching are contained in the trajectory optimization model to reflect the influence of underwater navigation error on the quality of trajectory. Correspondingly, the forms of collision detection and cost function are changed to adapt to the inaccurate navigation information. To obtain the trajectory with the minimum terminal position error, an improved teach & learn-based optimization (ITLBO) algorithm is developed to strengthen the influence of individual historical optimal solution. Besides, Chebyshev collocation points are applied to determine the locations of control variables. Simulation results demonstrate that the established navigation error-based trajectory optimization model can reflect the real situation of multi-phase task. Especially, it is able to calculate the collision probability between the vehicle and the obstacle when GPS is unavailable underwater, thus ensuring the safety of underwater navigation. Compare to other common effective algorithms, the proposed ITLBO algorithm is in general more suitable for solving this problem because it is swarm-based and can obtain good solution without worrying about the inappropriate values of user-defined parameters.																	0952-1976	1873-6769				MAR	2020	89								103404	10.1016/j.engappai.2019.103404													
J								Self-adaption neighborhood density clustering method for mixed data stream with concept drift	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Data stream; Concept drift; Rough set; Clustering analysis; Neighborhood entropy	ROUGH; SELECTION	Clustering analysis is an important data mining method for data stream. In this paper, a self-adaption neighborhood density clustering method for mixed data stream is proposed. The method uses a significant metric criteria to make categorical attribute values become numeric and then the dimension of data is reduced by a nonlinear dimensionality reduction method. In the clustering method, each point is evaluated by neighborhood density. The k points are selected from the data set with maximum mutual distance after k is determined according to rough set. In addition, a new similarity measure based on neighborhood entropy is presented. The data points can be partitioned into the nearest cluster and the algorithm adaptively adjusts the clustering center points by clustering error. The experimental results show that the proposed method can obtain better clustering results than the comparison algorithms on the most data sets and the experimental results prove that the proposed algorithm is effective for data stream clustering.																	0952-1976	1873-6769				MAR	2020	89								103451	10.1016/j.engappai.2019.103451													
J								Dynamic Bayesian network for robust latent variable modeling and fault classification	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Robust information extraction; Dynamic Bayesian network; Outliers; Non-Gaussian data modeling; Fault classification	PRINCIPAL COMPONENT ANALYSIS; HIDDEN MARKOV MODEL; GAUSSIAN MIXTURE MODEL; FED-BATCH FERMENTATION; MISSING DATA; PCA; ANALYTICS; FRAMEWORK	This work deals with robust dynamic probabilistic modeling and fault classification for process data. In dynamic processes, observed variables can be numerous in amount and correlated with each other in both variable-wise and time-wise. While multivariate statistical analysis methods such as principle component analysis (PCA) are widely used to handle variable-wise correlations and also for dimension reduction purpose, the time-wise correlation among process data is typically addressed by constructing dynamical models, e.g. time-series data model, state space model, etc. In this paper, the robust probabilistic principle component analysis (RPPCA) model is introduced for feature extraction from contaminated process data, suffered from outliers, disturbances, heave noises, etc. A dynamic Bayesian network (DBN) is then constructed, with incorporation of a mixture of Gaussian components for approximation of the non-Gaussian characteristics of latent variables. Based on the developed robust dynamic Bayesian network model, a fault classification scheme is proposed. To validate the effectiveness and feasibility of the new method, two well-known benchmark case studies are carried out. Simulation results show that robust dynamic method performs better in outlier contaminated situations, where the performance has been improved by 10%-20% in most cases.																	0952-1976	1873-6769				MAR	2020	89								103475	10.1016/j.engappai.2020.103475													
J								Photo-voltaic power daily predictions using expanding PDE sum models of polynomial networks based on Operational Calculus	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Uncertainty modelling; Partial differential equation; Polynomial neural network; Operational calculus PDE conversion; Laplace transformation	NUMERICAL FORECASTS; SOLAR IRRADIANCE; MULTISTEP	Photo-Voltaic (PV) power production is subject to the current local weather situation which result in the amount of solar radiation components possible to convert by PV modules. Numerical Weather Prediction (NWP) systems are usually run every 6 h to provide course local 24-48-hour forecasts. Statistical models, developed with spatial historical data, can convert or post-process these NWP data to predict PV power for a plant specific situation. Statistical predictions are more precise if rely on the latest weather observations and power measurements as the accuracy of NWP cloudiness is mostly inadequate for PV plant operation and the forecast errors are only magnified. Differential Polynomial Neural Network (D-PNN) is a novel neurocomputing technique based on analogies with brain pulse signal processing. It can model complex patterns without reducing significantly the data dimensionality as regression and soft-computing methods do. D-PNN decomposes the general Partial Differential Equation (PDE), being able to describe the local atmospheric dynamics, into node specific 2nd order sub-PDEs. These are converted using adapted procedures of Operational Calculus to obtain the Laplace images of unknown node functions, which are inverse transformed to obtain the originals. D-PNN can select from dozens of input variables to produce applicable sum PDE components which can extend, step by step, its composite models towards the optima. The PDE models are developed with historical spatial data from the estimated optimal lengths of daily training periods to process the last day input data and predict Clear Sky Index 24-hours ahead. They obtain a better prediction accuracy than simplified statistical solutions which allow to predict in horizon of a few hours only.																	0952-1976	1873-6769				MAR	2020	89								103409	10.1016/j.engappai.2019.103409													
J								Applying graph-based differential grouping for multiobjective large-scale optimization	SWARM AND EVOLUTIONARY COMPUTATION										Differential grouping; Graph-based differential grouping; Multiobjective optimization; Large-scale optimization	EVOLUTIONARY ALGORITHMS; COOPERATIVE COEVOLUTION; DESIGN	An increasing number of multiobjective large-scale optimization problems (MOLSOPs) are emerging. Optimization based on variable grouping and cooperative coevolution is a good way to address MOLSOPs, but few attempts have been made to decompose the variables in MOLSOPs. In this paper, we propose multiobjective graph-based differential grouping with shift (mogDG-shift) to decompose the large number of variables in an MOLSOP. We analyze the variable properties, then detect the interactions among variables, and finally group the variables based on their properties and interactions. We modify the decision variable analyses (DVA) in the multiobjective evolutionary algorithm based on decision variable analyses (MOEA/DVA), extend graph-based differential grouping (gDG) to MOLSOPs, and test the method on many MOLSOPs. The experimental results show that mogDG-shift can achieve 100% grouping accuracy for LSMOP and DTLZ as well as almost all WFG instances, which are much better than DVA. We further combine mogDG-shift with two representative multiobjective evolutionary algorithms: the multiobjective evolutionary algorithm based on decomposition (MOEA/D) and the non-dominated sorting genetic algorithm II (NSGA-II). Compared with the original algorithms, the algorithms combined with mogDG-shift show improved optimization performance.																	2210-6502	2210-6510				MAR	2020	53								100626	10.1016/j.swevo.2019.100626													
J								Development of particle swarm and topology optimization-based modeling for mandibular distractor plates	SWARM AND EVOLUTIONARY COMPUTATION										Patient-specific mandibular distraction osteogenesis; Optimization of the screw configuration and the osteotomy line; Particle swarm optimization; Topology optimization; Stabilization of callus	STRESS-DISTRIBUTION; OSTEOGENESIS; FIXATION; COMPLICATIONS; IMPLANT; BONE; DEFORMITIES; RECONSTRUCTION; STABILIZATION; PREDICTION	Mandibular Distraction Osteogenesis (MDO) is a common clinical procedure to correct mandibular retrognathia. However, since there is not a gold standard for determining the screw positions for current MDO operations, deviation of distraction direction and malocclusion increases. This case results in need of additional operations that affect the callus stability. In these cases, relapse risk increases and remodelling period gets longer. On the other hand, large volume of the distractor plates results in more invasive treatment and negatively affects the patients' comfort. To overcome these problems, this study offers a new method including; virtual surgery simulation, determining the optimum screw configuration using particle swarm optimization loop linked between MATLAB-PYTHON-ANSYS programs and the design of distractor plate geometry with topology optimization. In order to test the proposed method, two different Finite Element (FE) models, CM and OM, were established based on conventional and optimum method, respectively. FEA results of the current study reveals that OM has 33.56% less displacement compared to CM, and the most critical screw in terms of screw loosening for OM has 35.29% less strain value than CM. These outcomes show OM shows superior callus stability in comparison with CM. On the other hand, redesign of the distractor plates using topology optimization according to the best screw positions provides 43.32% reduction in the total implant volume which means reduced cost and a less invasive MDO operation. Therefore, the clinical use of this protocol is expected to increase the success of the operation by shortening the recovery period.																	2210-6502	2210-6510				MAR	2020	53								100645	10.1016/j.swevo.2020.100645													
J								Investigating the equivalence between PBI and AASF scalarization for multi-objective optimization	SWARM AND EVOLUTIONARY COMPUTATION										Evolutionary multi-objective optimization; Multi-criteria decision making; Achievement scalarizing function; Penalized boundary intersection; Scalarization	MANY-OBJECTIVE OPTIMIZATION; EVOLUTIONARY ALGORITHM; DECOMPOSITION	Scalarization refers to a generic class of methods to combine multiple conflicting objectives into one in order to find a Pareto optimal solution to the original problem. Augmented achievement scalarizing function (AASF) is one such method used popularly in the multi-criterion decision-making (MCDM) field. In evolutionary multi-objective optimization (EMO) literature, scalarization methods such as penalty boundary intersection (PBI) are commonly used to compare similar solutions within a population. Both AASF and PBI methods require a reference point and a reference direction for their calculation. In this paper, we aim to analytically derive and understand the commonalities between these two metrics and gain insights into the limitations of their standard parametric forms. We show that it is possible to find an equivalent modified AASF formulation for a given PBI parameter and vice versa for bi-objective problems. Numerical experiments are presented to validate the theory developed. We further discuss the challenges in extending this to higher objectives and show that it is still possible to achieve limited equivalence along symmetric reference vectors. The study connects the two philosophies of solving multi-objective optimization problems, provides a means to gain a deeper understanding of both these measures, and expands their parametric range to provide more flexibility of controlling the search behavior of the EMO algorithms.																	2210-6502	2210-6510				MAR	2020	53								100630	10.1016/j.swevo.2019.100630													
J								Solving the multi-objective flexible job shop scheduling problem with a novel parallel branch and bound algorithm	SWARM AND EVOLUTIONARY COMPUTATION										Branch and bound; Flexible job shop problem; Multiple objective programming; Scheduling; Shared memory programming	GENETIC ALGORITHM; MEMETIC ALGORITHM; OPTIMIZATION	This work presents a novel parallel branch and bound algorithm to efficiently solve to optimality a set of instances of the multi-objective flexible job shop scheduling problem for the first time, to the very best of our knowledge. It makes use of the well-known NSGA-II algorithm to initialize its upper bound. The algorithm is implemented for shared-memory architectures, and among its main features, it incorporates a grid representation of the solution space, and a concurrent priority queue to store and dispatch the pending sub-problems to be solved. We report the optimal Pareto front of thirteen well-known instances from the literature, which were unknown before. They will be very useful for the scientific community to provide more accuracy in the performance measurement of their algorithms. Indeed, we carefully analyze the performance of NSGA-II on these instances, comparing the results against the optimal ones computed in this work. Extensive computational experiments show that the proposed algorithm using 24 cores achieves a speedup of 15.64x with an efficiency of 65.20%.																	2210-6502	2210-6510				MAR	2020	53								100632	10.1016/j.swevo.2019.100632													
J								Survivable networks via on-line real-time evolution of dual air-ground swarm	SWARM AND EVOLUTIONARY COMPUTATION										Airborne relay network; Network connectivity; Swarm behavior; Real-time genetic algorithm		The use of unmanned airborne agents as relays for ground agents to ensure ground network survivability is gaining traction at both theoretical and practical levels, in research that targets contexts like search and rescue in disaster areas, farming with autonomous equipment, surveillance, internet of things, military operations, autonomous transportation systems, and many others. This comes with some challenges, which include the dynamics of the ground unit behaviors, the scalability of the system, the mobility model of the airborne agents, and the integration between ground and air agents. This paper contributes to addressing the above challenges by using a bio-inspired approach that combines swarm intelligence and evolutionary computation for providing ground network survivability for a wide range of ground movement patterns. The proposed approach models ground and airborne agents as a dual air-ground swarm that uses boids-like rules, and optimizes the movement of the airborne agents using an on-line real-time genetic algorithm with shadow simulation and prediction. Arguably, the proposed approach provides system scalability both size-wise and context-wise, while also offering a certain amount of integration between the ground and air swarms of agents. The results of the investigation demonstrate that the methods employed endow the airborne agents with the needed capability to ensure network survivability for complex ground activity, including resilience to changes in the ground movement pattern and good responsiveness to activities that have no pattern at all, such as uniform random walks.																	2210-6502	2210-6510				MAR	2020	53								100642	10.1016/j.swevo.2019.100642													
J								Role of swarm and evolutionary algorithms for intrusion detection system: A survey	SWARM AND EVOLUTIONARY COMPUTATION										Intrusion detection system; Challenges; Swarm and evolutionary algorithms; Future directions; Genetic algorithm; Ant colony optimization; Particle swarm optimization; Artificial bee colony; Firefly algorithm; Bat algorithm; Flower pollination algorithm	ANT COLONY OPTIMIZATION; ARTIFICIAL BEE COLONY; SUPPORT VECTOR MACHINES; FEATURE-SELECTION; FIREFLY ALGORITHM; GENETIC ALGORITHM; COMPUTATION; PERFORMANCE; MODEL; TECHNOLOGY	The growth of data and categories of attacks, demand the use of Intrusion Detection System(IDS) effectively using Machine Leaming(ML) and Deep Learning(DL) techniques. Apart from the ML and DL techniques, Swarm and Evolutionary (SWEVO) Algorithms have also shown significant performance to improve the efficiency of the IDS models. This survey covers SWEVO-based IDS approaches such as Genetic Algorithm(GA), Ant Colony Optimization(ACO), Particle Swarm Optimization(PSO), Artificial Bee Colony Optimization(ABC), Firefly Algorithm(FA), Bat Algorithm(BA), and Flower Pollination Algorithm(FPA). The paper also discusses applications of the SWEVO in the field of IDS along with challenges and possible future directions.																	2210-6502	2210-6510				MAR	2020	53								100631	10.1016/j.swevo.2019.100631													
J								On explaining machine learning models by evolving crucial and compact features	SWARM AND EVOLUTIONARY COMPUTATION										Feature construction; Interpretable machine learning; Genetic programming; GOMEA	FEATURE CONSTRUCTION	Feature construction can substantially improve the accuracy of Machine Learning (ML) algorithms. Genetic Programming (GP) has been proven to be effective at this task by evolving non-linear combinations of input features. GP additionally has the potential to improve ML explainability since explicit expressions are evolved. Yet, in most GP works the complexity of evolved features is not explicitly bound or minimized though this is arguably key for explainability. In this article, we assess to what extent GP still performs favorably at feature construction when constructing features that are (1) Of small-enough number, to enable visualization of the behavior of the ML model; (2) Of small-enough size, to enable interpretability of the features themselves; (3) Of sufficient informative power, to retain or even improve the performance of the ML algorithm. We consider a simple feature construction scheme using three different GP algorithms, as well as random search, to evolve features for five ML algorithms, including support vector machines and random forest. Our results on 21 datasets pertaining to classification and regression problems show that constructing only two compact features can be sufficient to rival the use of the entire original feature set. We further find that a modern GP algorithm, GP-GOMEA, performs best overall. These results, combined with examples that we provide of readable constructed features and of 2D visualizations of ML behavior, lead us to positively conclude that GP-based feature construction still works well when explicitly searching for compact features, making it extremely helpful to explain ML models.																	2210-6502	2210-6510				MAR	2020	53								100640	10.1016/j.swevo.2019.100640													
J								A many-objective evolutionary algorithm with diversity-first based environmental selection	SWARM AND EVOLUTIONARY COMPUTATION										Many-objective optimization; Evolutionary algorithm; Convergence; Diversity; Adaptive angle penalized distance	NONDOMINATED SORTING APPROACH; DECOMPOSITION	Environmental selection in Pareto-based many-objective evolutionary algorithms generally employ Pareto-dominance relation to first consider the convergence and give higher priority to convergence than diversity. When the many-objective optimization problem has a complicated Pareto front, this selection strategy can easily miss the promising areas and converge into a subregion of the Pareto front. To address this issue, we propose a many-objective evolutionary algorithm with diversity-first based environmental selection. Different from the existing selection strategies, the environmental selection procedure in the proposed algorithm adopts a diversity-first-and-convergence-second principle, which first selects the representative solutions that having better diversity and then considers using the well-converged solutions to replace them in subregions. This selection-replacement strategy can maintain the diversity and make contribution to the convergence. In addition, a selection criterion, termed adaptive angle penalized distance, is designed to judge whether the replacement is implemented or not. The proposed algorithm is compared with five state-of-the-art many-objective evolutionary algorithms on a large number of test problems with various characteristics. Experimental studies demonstrate that the proposed algorithm has competitive performance on many-objective optimization problems.																	2210-6502	2210-6510				MAR	2020	53								100641	10.1016/j.swevo.2019.100641													
J								A fast and accurate explicit kernel map	APPLIED INTELLIGENCE										Kernel; Explicit cosine map; Random fourier features; Anomaly detection; Matrix sketching	ANOMALY DETECTION; FREQUENT	Kernel functions are powerful techniques that have been used successfully in many machine learning algorithms. Explicit kernel maps have emerged as an alternative to standard kernel functions in order to overcome the latter's scalability issues. An explicit kernel map such as Random Fourier Features (RFF) is a popular method for approximating shift invariant kernels. However, it requires large run time in order to achieve good accuracy. Faster and more accurate variants of it have also been proposed recently. All these methods are still approximations to a shift invariant kernel. Instead of an approximation, we propose a fast, exact and explicit kernel map called Explicit Cosine Map (ECM). The advantage of this exact map is manifested in the form of performance improvements in kernel based algorithms. Furthermore, its explicit nature enables it to be used in streaming applications. Another explicit kernel map called Euler kernel map is also proposed. The effectiveness of both kernel maps is evaluated in the application of streaming Anomaly Detection (AD). The AD results indicate that ECM based algorithm achieves better AD accuracy than previous algorithms, while being faster.																	0924-669X	1573-7497				MAR	2020	50	3					647	662		10.1007/s10489-019-01538-w													
J								Semantic and syntactic analysis in learning representation based on a sentiment analysis model	APPLIED INTELLIGENCE										Aspect based sentiment analysis; Knowledge representation; Representation learning; Sparse coding approach; Word embedding		The rapid development of e-commerce gives researchers confidence that customers will be willing to share more and more online data, which in turn, would allow for improved mining algorithms. Many companies also foresee vast profits in mining data from online interaction, behavior, and activity. Opinion mining, also known as sentiment analysis, means automatically detecting and understanding personal expressions about a product or service from customer textual reviews. Recently, aspect-based sentiment analysis has become widely interesting to researchers, particularly with respect to embedded words. Algorithms such as word2vec and GloVe perform well when it comes to capturing analogies and toward lexical semantics in general. However, more complex algorithms are needed to address this issue more precisely, using larger corpora and special kinds of data. This paper introduces a knowledge representation approach that centers on aspect rating and weighting. The study focuses on how to understand the nature of sentimental representation using a multilayer architecture. We present a model that uses a mixture of semantic and syntactic components to capture both semantic and sentimental information. This model shares its probability foundation with the words recognized by word2vec and builds on our prior work concerning opinion-aspect relation analysis. This new algorithm is designed specifically, however, to discover sentiment-enriched embedding rather than word similarities. Experiments were performed using a review dataset from the electronic domain. Results show that the model achieved both appropriate levels of detail and rich representation capabilities.																	0924-669X	1573-7497				MAR	2020	50	3					663	680		10.1007/s10489-019-01540-2													
J								Energy-based structural least squares MBSVM for classification	APPLIED INTELLIGENCE										Multi-class classification problem; Multiple birth support vector machine; Twin support vector machine; Least square; Structural information	SUPPORT VECTOR MACHINES	Multiple birth support vector machine (MBSVM) is an extension of twin support vector machine on multi-class classification problem. In MBSVM, the size of each QP problem is restricted by the number of patterns in one of the K classes, so the computational complexity of MBSVM is much lower and the training speed of it is faster than the existing multi-class SVM. However, MBSVM neglects the structural information of data which may contain some significant prior knowledge for training classifiers. In this paper, we first present an improved version of structural least square twin support vector machine (S-LSTWSVM), called energy-based structural least square twin support vector machine (ES-LSTWSVM), which converts the constraints of the S-LSTWSVM into an energy-based model by introducing an energy for each hyperplane. Then we use the strategy of "rest-versus-one" in MBSVM to extend ES-LSTWSVM into the multi-class classification, called energy-based structural least squares MBSVM (ESLS-MBSVM). In order to prove the validity of ESLS-MBSVM, the experiment has been performed on UCI datasets. The experimental results show that our ESLS-MBSVM is effective and has good classification performance. In order to better illustrate the experimental results, we use Friedman test and ROC analysis for statistical comparisons.																	0924-669X	1573-7497				MAR	2020	50	3					681	697		10.1007/s10489-019-01536-y													
J								Triangular coil pattern of local radius of gyration face for heterogeneous face recognition	APPLIED INTELLIGENCE										Heterogeneous face recognition; Radius of gyration; Local triangular coil binary pattern; Illumination; Rotation; Noise; Invariant	ILLUMINATION-INVARIANT; VARYING ILLUMINATION; SKETCH; BIOMETRICS; DIFFUSION; MODELS	This paper puts forward a novel methodology for Heterogeneous Face Recognition (HFR), where we present a new-fangled image representation technique called the Local Radius of Gyration Face (LRGF), which has been theoretically proved to be invariant to changes in illumination, rotation and noise. Finally, a novel Local Triangular Coil Binary Pattern (LTCBP) is presented so as to apprehend the local variations of the LRGF attributes, and the method has been entitled as the Triangular Coil Pattern of Local Radius of Gyration Face (TCPLRGF). The proposed algorithm has been tested on a number of challenging databases to study the precision of the TCPLRGF method under varying condition of illumination, rotation, noise and also the recognition accuracy of sketch-photo and NIR-VIS image. The Rank-1 recognition accuracy of 98.27% on CMU-PIE Database, 98.09% on Extended Yale B Database, 96.35% on AR Face Database, 100% on CUHK Face Sketch (CUFS) Database, 89.01% on LFW Database and 98.74% on the CASIA-HFB NIR-VIS Database exhibits the supremacy of the proposed strategy in Heterogeneous Face Recognition (HFR) under various conditions, compared to other recent state-of-the-art methods. For reckoning the similarity measure between images, a hybridized approach amalgamating the Jaccard Similarity method and the standardized L-1 norm approach has been taken into account.																	0924-669X	1573-7497				MAR	2020	50	3					698	716		10.1007/s10489-019-01545-x													
J								An effective distance based feature selection approach for imbalanced data	APPLIED INTELLIGENCE										Imbalanced data; Feature selection; Effective distance; Classification; Jeffreys divergence	CLASSIFICATION; GENERATION; MODEL	Class imbalance is one of the critical areas in classification. The challenges become more severe when the data set has a large number of features. Traditional classifiers generally favour the majority class because of skewed class distributions. In recent years, feature selection is being used to select the appropriate features for better classification of minority class. However, these studies are limited to imbalance that arise between the classes. In addition to between class imbalance, within class imbalance, along with large number of features, adds additional complexity and results in poor performance of the classifier. In the current study, we propose an effective distance based feature selection method (ED-Relief) that uses a sophisticated distance measure, in order to tackle simultaneous occurrence of between and within class imbalance. This method has been tested on a variety of simulated experiments and real life data sets and the results are compared with the traditional Relief method and some of the well known recent distance based feature selection methods. The results clearly show the superiority of the proposed effective distance based feature selection method.																	0924-669X	1573-7497				MAR	2020	50	3					717	745		10.1007/s10489-019-01543-z													
J								Exploiting skew-adaptive delimitation mechanism for learning expressive classification rules	APPLIED INTELLIGENCE										Adaptive mechanism; Expressivity; Poisson process; Rule term boundaries; Skewed distribution		The expressivity of machine learning algorithms is considered to be critical in intelligent data analysis tasks for practical application. As an alternative set of classification rule learning algorithms to conventional decision tree, Prism family of algorithms induce modular rules concisely, thus exhibiting good expressiveness for human users. However, existing Prism rule induction techniques are limited by the assumption of Gaussian distribution for quantitative attributes, and may not be available for real life data analyzing, in which skewness is commonly observed. For this reason, we investigate a skew-adaptive mechanism for rule term boundary delimitation in Prism inductive learning. The propose algorithm, called P2-Prism, could learn expressive classification rules directly from quantitative data beyond Gaussian distribution. By employing statistical inference characteristics of Poisson process, our mechanism provides a significant contribution to classification rule inductive learning with adaption of skewed data distribution. The experimental evaluation of our algorithm demonstrates its skew-adaptive superiority on benchmark datasets, comparing with state-of-the-art algorithms. Furthermore, it is shown that P2-Prism is a robust classifier in the presence of various levels of noise, which further reveals its adaptability to the skewness of data distribution.																	0924-669X	1573-7497				MAR	2020	50	3					746	758		10.1007/s10489-019-01533-1													
J								Optimizing multicast routing tree on application layer via an encoding-free non-dominated sorting genetic algorithm	APPLIED INTELLIGENCE										Application layer multicast; Genetic algorithm; Multi-objective optimization	NETWORKS	The task of Application Layer Multicast (ALM) routing is to establish a proper routing tree on application layer network, which transmits data packages from a source to multiple destinations. ALM routing tree is instable due to the end-hosts' departure or failure. In view of this, we formulated the ALM routing as a multi-objective optimization problem, where the aim is to optimize the ALM routing tree's topological structure for minimizing its transmission delay and instability simultaneously. A novel encoding-free non-dominated sorting genetic algorithm is proposed for solving our formulated optimization problem. For achieving encoding-free, genotypes are directly represented as tree-like phenotypes in our proposed algorithm. Accordingly, the genetic operators acting on genotypes, like crossover and mutation, need to be redesigned to adapt the tree-like genotypes. The worst-case time complexity of the proposed algorithm is theoretically analyzed and exhaustive simulation results manifest that our proposed algorithm is capable of obtaining high-quality Pareto front. Besides, several interesting issues, such as how to select the final solution out of the obtained Pareto front and the reason why GP is not used, are also discussed.																	0924-669X	1573-7497				MAR	2020	50	3					759	777		10.1007/s10489-019-01547-9													
J								Cluster-based Kriging approximation algorithms for complexity reduction	APPLIED INTELLIGENCE										Kriging; Gaussian process regression; Fuzzy clustering; Clustering; Model trees; Time complexity	SIMULATION; DENSITY; MODELS	Kriging or Gaussian Process Regression is applied in many fields as a non-linear regression model as well as a surrogate model in the field of evolutionary computation. However, the computational and space complexity of Kriging, that is cubic and quadratic in the number of data points respectively, becomes a major bottleneck with more and more data available nowadays. In this paper, we propose a general methodology for the complexity reduction, called cluster Kriging, where the whole data set is partitioned into smaller clusters and multiple Kriging models are built on top of them. In addition, four Kriging approximation algorithms are proposed as candidate algorithms within the new framework. Each of these algorithms can be applied to much larger data sets while maintaining the advantages and power of Kriging. The proposed algorithms are explained in detail and compared empirically against a broad set of existing state-of-the-art Kriging approximation methods on a well-defined testing framework. According to the empirical study, the proposed algorithms consistently outperform the existing algorithms. Moreover, some practical suggestions are provided for using the proposed algorithms.																	0924-669X	1573-7497				MAR	2020	50	3					778	791		10.1007/s10489-019-01549-7													
J								Multi-channel biomimetic visual transformation for object feature extraction and recognition of complex scenes	APPLIED INTELLIGENCE										Multi-channel biomimetic visual transformation; Feature extraction; Complex scenes; Object recognition; Object hitting map (OHM)	NEURAL-NETWORKS; INVARIANT; DESCRIPTORS; ROTATION; MEMORY; TRANSLATION; SALIENCY; MODEL; GABOR	Object recognition occurs accurately with human visual neural mechanism despite in different complex background interference. For computer system, it is still a challenging work of object recognition and classification. Recently, many methods for object recognition based on human visual perception mechanism are presented. However, most methods cannot achieve a better recognition accuracy when object images are corrupted by some background interferences. Therefore, it is necessary to propose a method for object recognition of complex scene. Inspired by biomimetic visual mechanism and visual memory, a multi-channel biomimetic visual transformation (MCBVT) is proposed in this paper. MCBVT involves three channels. Firstly, some algorithms including orientation edge detection (OED), local spatial frequency detection (LSFD) and weighted centroid coordinate calculation are adopted for two stage's visual memory maps creations during the first channel, where some visual memory points are stored in memory map. Secondly, an object hitting map (OHM) is built in the second channel and the OHM is an edge image without background interference. After that, the first stage's visual memory hitting map is obtained through execute back-tracking second stage's visual memory map. Furthermore, an OHM is constructed through back-tracking with common memory points in first stage's visual memory map and first stage's visual memory hitting map. Thirdly, the OED and LSFD algorithms are conducted to extract a feature map of OHM in the third channel. Consequently, the final feature map is reshaped into a feature vector, which is used for object recognition. Additionally, several image database experiments are implemented, the recognition accuracy for alphanumeric, MPEG-7 and GTSRB database are 93.33%, 91.33 and 90% respectively. Moreover, same object images in different backgrounds share with highly similar feature maps. On the contrary, different object images with complex backgrounds through MCBVT show different feature maps. The experiments reveal a better selectivity and invariance of MCBVT features. In summary, the proposed MCBVT provides a new framework of feature extraction. Background interference of object image is eliminated through the first and second channel, which is a new method for background noise reduction. Meanwhile, the results show that the proposed MCBVT method is better than other feature extraction methods. The contributions of this paper is significant in computational intelligence for the further work.																	0924-669X	1573-7497				MAR	2020	50	3					792	811		10.1007/s10489-019-01550-0													
J								Transfer learning based 3D fuzzy multivariable control for an RTP system	APPLIED INTELLIGENCE										Rapid thermal Processing; 3D fuzzy logic controller; Multi-output SVR; Multi-output fuzzy rule extraction; Distributed parameter system	WAFER TEMPERATURE UNIFORMITY; CONTROL DESIGN; KNOWLEDGE; METHODOLOGY; DOMAIN	Rapid thermal processing (RTP) is an important process in the fabrication of semiconductor devices. It is difficult to achieve temperature uniformity control of the wafer in RTP since the system is a highly nonlinear process with strong spatial distribution. In this study, a transfer learning-based three-dimensional (3D) fuzzy multivariable control scheme is proposed for the temperature uniformity control of an RTP system. In difference to the traditional expert-knowledge based design, a two-level framework of transfer learning methodology is constructed to design the 3D fuzzy multivariable controller (3D FMC) with the help of a multi-output support vector regression (M-SVR). The 3D FMC defines a qualitative spatial fuzzy structure that will be transferred to the M-SVR. On the other hand, the structure parameters of the M-SVR will be learned from data and transferred to design quantitative parameters of the 3D FMC. Under the framework of transfer learning, the control laws (e.g. human control experience) hidden in spatio-temporal data can be extracted and formulated back into multi-output 3D fuzzy rules. The proposed method provides an effective integration of the spatial fuzzy inference and the transfer learning for 3D FLC design. The newly developed method is applied to the temperature uniformity control of a rapid thermal chemical vapor deposition (RTCVD) system at the set temperature 1000K, and the maximum non-uniformity along the wafer radius is close to 1K.																	0924-669X	1573-7497				MAR	2020	50	3					812	829		10.1007/s10489-019-01557-7													
J								A new modeling and inference approach for the belief rule base with attribute reliability	APPLIED INTELLIGENCE										Belief rule-based model with attribute reliability (BRB-r); Attribute reliability; Systematic uncertainty; Auto regressive (AR) model	EVIDENTIAL REASONING APPROACH; METHODOLOGY; DECISION; SYSTEM; ERROR	A belief rule-based (BRB) model with attribute reliability (BRB-r) has been developed recently, where the systematic uncertainty is regarded as attribute reliability by extending the traditional BRB model. The BRB-r model provides a framework to deal with the systematic uncertainty, but the drawbacks in modeling and inference reduces the accuracy of it. This paper proposed a new modeling and inference approach to improve the effectiveness of the BRB-r. This approach is constituted by two parts: data processing and BRB inference. In the data processing, the attribute reliability is calculated based on the auto regressive model, while the parameters of BRB-r are optimized using the differential evolution algorithm. In the BRB inference, a new attribute reliability fusion algorithm is proposed, which can effectively integrate attribute reliability into the BRB model and ensure the rationality in different situations. A benchmark case about pipeline leak detection and a practical case about condition monitoring are studied to demonstrate the rationality and feasibility of the proposed approach to the BRB-r model.																	0924-669X	1573-7497				MAR	2020	50	3					976	992		10.1007/s10489-019-01586-2													
J								Genetically optimized parameter estimation of mathematical model for multi-joints hip-knee exoskeleton	ROBOTICS AND AUTONOMOUS SYSTEMS										Parameter estimation; Lower Limb Exoskeleton; Optimization; Genetic algorithm	REHABILITATION; DESIGN; TIME	Achieving precise parameters of multi-joints actuators for Hip-Knee Exoskeleton (HKE) is a crucial process due to its non-linear characteristics. In this paper, a Genetic Algorithm (GA) based optimization is used for parameter estimation of the mathematical model for a four-Degree of Freedom (DoF) multi-joint HKE, which is a type of Lower Limb Exoskeleton (LLE). Mathematical model for electromechanical, mechanical, and electrical components of the HKE has been formulated, and its parameters are estimated using GA and experimental method. An objective function is determined based on the difference between the simulated and actual angular trajectory for each joint. The performance of the mathematical model is examined with different voltages under the range of 4 V to 8 V for hip and knee, respectively. Furthermore, the performance of the estimated model is compared with Particle Swarm Optimization (PSO). The results and numerical analysis demonstrated that the estimated model by GA and PSO with varying voltages predicted the actual angular trajectory with acceptable error, while GA provides the more accurate model. It can be ascertained that the proposed method of estimation for mathematical model of the HKE is applicable to identify its parameters, and useful for designing a control system. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103425	10.1016/j.robot.2020.103425													
J								Virtual-joint based motion similarity criteria for human-robot kinematics mapping	ROBOTICS AND AUTONOMOUS SYSTEMS										Robotic imitation; Kinematics mapping; Motion similarity; Dissimilar embodiments; Human-robot cooperation	IMITATION; TELEOPERATION	Motion mapping is an important part in human-robot cooperation. In this paper, a novel concept of virtual-joint based similarity criteria is proposed for flexible and efficient kinematics mapping between dissimilar embodiments, including different degrees of freedom (DOFs), different body morphology, and so on. Virtual joints are defined respectively in both the demonstrator and the imitator, with the same number. In virtual joints, the neglecting, re-ordering and repetitive usage of DOFs could be realized through the virtual decomposing matrices. Each virtual joint of the demonstrator and the corresponding one of the imitator formed a virtual joint pair. The Total Metric of Motion Similarity is the weighted sum of the metrics defined for each virtual joint pairs. Unlike traditional joint-space or Cartesian-space based metrics describing motion similarity solely at the DOF kinematic mode level, virtual-joint-based metrics can be adopted to describe different aspects of motion similarity between dissimilar agents, both in joint space and in Cartesian space. Two experiments are conducted to illustrate the effectiveness of the proposed approach. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103412	10.1016/j.robot.2019.103412													
J								Operational space analysis of human muscular effort in robot assisted reaching tasks	ROBOTICS AND AUTONOMOUS SYSTEMS										Human performance augmentation; Rehabilitation robotics; Dynamics	INVERSE OPTIMAL-CONTROL; HUMAN MOTION; MUSCLE	Human motor performance is a key area of investigation in both biomechanics and robotics. In robotics, understanding human muscular control is important to synthesize prosthetic motions and ensure safe human-robot interaction. Building controllable biomechanical models can help in quantifying the characteristics of a subject's motion and in designing effective treatments, like motion training. This paper presents the task-based motion analysis of muscular effort using an upper-body musculoskeletal model, validated through motion capture experiments and dynamic simulations. To study the contribution of robotic assistance in improving human motor skills, the muscular effort of the task of reaching with and without robotic assistance was investigated for 10 subjects. Reduction of 21.4% in the arm muscular effort was observed for the tasks with robotic assistance. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103429	10.1016/j.robot.2020.103429													
J								Magnetic crawler climbing detection robot basing on metal magnetic memory testing technology	ROBOTICS AND AUTONOMOUS SYSTEMS										Climbing robot; Overcoming obstacles; Nondestructive testing; High payload	HIGH-PAYLOAD; LOCOMOTION; INSPECTION	Failure detection of high facilities always presents a tremendous challenge. Climbing-wall robot with detection capacity has become a main approach. But owing to their limitations in overcoming obstacles and complicated wall situation, reliable wall-climbing property and precise detection abilities are the most basic demand for achieving this function. Hence, further research is required to enhance robot capabilities in overcoming obstacles and accurate detection signal. The paper presents a new climbing-wall detection robot mechanism. The wall-climbing robot consists of two climbing modules. The two climbing modules are connected by anti-overturning mechanism to provide a capacity of anti-overturning during overcoming obstacle. The detection mechanism is installed at the bottom of the robot. Detailed design issues are presented with analyses of the design parameters. Transition displacement of anti-overturning mechanism and force transfer equation are derived, and stable operating conditions are verified. The abilities of flat surface locomotion, anti-overturning, preload and detection capacity are validated by using experiments. Experiment results show that the prototype achieves 10kg payload capacity on vertical surfaces and can overcome 10mm obstacle. 1mm x 1mm circular groove can be found. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103439	10.1016/j.robot.2020.103439													
J								Human-robot cooperative control based on sEMG for the upper limb exoskeleton robot	ROBOTICS AND AUTONOMOUS SYSTEMS										Human-robot cooperative control; Exoskeleton robot; Wearable robot; Surface electromyography(sEMG); Joint torque estimation; Joint state detector	JOINT MOMENTS; MUSCLE FORCES; EMG; MODELS; RECOGNITION; KINEMATICS; EXTREMITY; MOVEMENTS; SUPPORT; SYSTEM	An exoskeleton robot is a mechanical structure that integrates with the exterior of the human body to improve the wearer's muscular power. The key to ensure performances and comfort of the system is human-robot cooperation. This paper proposes a human-robot cooperative control method based on sEMG (surface Electromyography) signals to drive a pneumatic upper limb exoskeleton to act in accordance with the wearer's motion intentions. The intended movement information of the human is estimated by combining the regression method with the classification method. Based on the joint torque estimation model which is originated from the Hill-type musculoskeletal model, the regression method is used to estimate the joint's desired torque by merging the sEMG signal with the joint angle. To avoid shaking and keep the robot's limbs in the static condition, a classification method with the support vector machine is developed to find out the joint state that the human intends to keep. It was then applied to the exoskeleton's elbow joint flexion and extension movement experiments to verify the controller's effectiveness. The experimental results demonstrate that the controller can estimate human's motion intention accurately and is appropriate for the human-robot collaboration. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103350	10.1016/j.robot.2019.103350													
J								Min-max time efficient inspection of ground vehicles by a UAV team	ROBOTICS AND AUTONOMOUS SYSTEMS											INTERCEPT; ASSIGNMENT	We present a control design for N unmanned aerial vehicles (UAVs) tasked with an inspection of M ground moving vehicles. The location of each ground vehicle is known to each UAV, but the navigation and intent of each ground vehicle are unknown, therefore, this uncertainty has to be anticipated in each UAV's navigation. We use the minimum time stochastic optimal control to navigate each UAV towards the inspection of each ground vehicle. Based on this control, we formulate assignments of ground vehicles to be inspected by UAVs as an optimization problem to inspect all ground vehicles in the minimum expected time. Accounting for ground vehicle uncertain trajectories, we update the optimal assignment by a Markov inequality rule. The rule prevents the possibility of indefinite updating of assignments without finishing the inspection of all vehicles. On the other hand, it updates an assignment if it leads to a statistically significant improvement of the inspection expected time. The presented approach is illustrated with numerical examples. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103370	10.1016/j.robot.2019.103370													
J								A programmable central pattern generator with bounded output	ROBOTICS AND AUTONOMOUS SYSTEMS										Online trajectory generation; Central pattern generator; Oscillator synchronization; Bounded output oscillator	INSPIRED CONTROL; DISCRETE; MODELS; SYSTEM	Despite extensive studies on cyclic tasks in robotics, definitive solutions for the problem of trajectory generation for periodic motions have not been achieved so far. In this paper, we present an approach for online trajectory generation from a library of desired periodic trajectories. The proposed approach consists of a Central Pattern Generator (CPG) architecture ensuring entrainment of any periodic trajectory, smooth motion modulation and observing position and velocity limits of the robot. The proposed CPG is composed of a synchronized network of novel bounded output oscillatory systems. Every oscillatory system is a three-dimensional dynamical system encoding a one-dimensional periodic function as a stable limit cycle. We also use the state transformation method to bound the oscillator's output and its first time derivative. Finally, we present a synchronization technique to construct a synchronized network of the proposed oscillators for generating multi dimensional periodic functions. Using Lyapunov based arguments, we prove that the proposed CPG ensures stability, convergence, and synchronization of the desired trajectory. The soundness of the proposed oscillator and the resulting CPG are validated both in simulations and experiments on the humanoid robot iCub. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103423	10.1016/j.robot.2020.103423													
J								Collaborative infotaxis: Searching for a signal-emitting source based on particle filter and Gaussian fitting	ROBOTICS AND AUTONOMOUS SYSTEMS										Cognition difference; Bayesian estimation; Collaborative infotaxis; Particle filter; Gaussian fitting	RECONSTRUCTION; LOCALIZATION; VEHICLES; STRATEGY	To effectively leverage the spatio-temporal sensing capabilities of the team searching for a signal-emitting source, this paper presents a collaborative search method, in which each robot employs the weighted social Bayesian estimation and executes the distributed infotaxis search for the source. Cognition difference between robots, measuring the dissimilarity of probability maps, is specially introduced to obtain the heterogeneous weights of Bayesian estimation. However, the requirement of exchanging the whole probability map presents additional challenges in computation and communication for real-time applications. In this work, a solution for fast low-cost collaborative infotaxis method based on a combination of particle filter and Gaussian fitting is proposed. A particle filter is first employed for the representation of the source probability distribution, which makes the infotaxis strategy computationally tractable for large complex spaces using the limited and tractable amount of randomly drawn particles. By fitting a Gaussian density to the particles, each robot obtains the likelihood weight for social Bayesian estimation by only reporting the mean and the covariance matrix of Gaussian distribution rather than exchanging the whole probability maps. The simulation shows the proposed collaborative infotaxis can achieve an efficient search behavior in complex environments using a small number of particles and a lower communication bandwidth. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103414	10.1016/j.robot.2019.103414													
J								A dual-mode soft gripper for food packaging	ROBOTICS AND AUTONOMOUS SYSTEMS										Soft gripper; Grasping; Suction; Food packaging; Automation	ROBOTIC GRIPPER; DESIGN	Robotics and automation in the food industry is not as widely applied as in other industries, such as automotive and electrical industries, due to the large variations in the shape and properties of food materials and the frequent alterations of food products. Robotic end effectors that can adapt to these variations and handle multiple types of food materials are in high demand. Therefore, we propose a dual-mode soft gripper made of rubber material that can grasp and suck different types of objects. The gripper consists of four soft fingers, fabricated with rubber material using casting process, each of which is designed as a combination of a PenuNet bending actuator and a suction pad located at the fingertip. We introduce a new design for the air paths, which play an important role in the proper function of the soft finger. Finite element (FE) simulations were performed to confirm the finger design. Experimental tests were conducted to evaluate single finger bending, gripper lifting force, and grasping and sucking actions for various types of food materials. Results show that the soft gripper can lift a 273.97-g hot dog in the grasping mode, as well as a 512.62-g bagged Kernel corn and a 1072.65-g Macbook Air in the suction mode. It can adapt to approximately circular and square targets, such as a piece of fried chicken and an orange, when the soft fingers are in a perpendicular configuration. While in a parallel configuration, the gripper can successfully handle elongated targets, such as a hot dog. An experiment is also presented to demonstrate the automatic packaging of a Japanese boxed lunch, which requires both grasping and suction modes to be employed. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103427	10.1016/j.robot.2020.103427													
J								Multi-agent sensitivity enhanced iterative best response: A real-time game theoretic planner for drone racing in 3D environments	ROBOTICS AND AUTONOMOUS SYSTEMS										Game theoretic motion planning; Nash equilibrium; Multi-robot systems		This paper presents a real-time game theoretic motion planning approach that enables an autonomous drone to race competitively against an arbitrary number of opponent drones along a 2D or 3D racecourse. Our method computes an approximate Nash equilibrium in the space of robot trajectories to maximally advance the ego robot while taking into account the opponents' intentions and responses. The core of our solution is a "sensitivity enhanced" iterative best response algorithm that the ego robot uses to repeatedly plan its own trajectory and infer opponents' trajectories, ultimately seeking a Nash equilibrium in the joint space of trajectories for all the drones. The algorithm includes a term that allows the ego vehicle to gain advantage by exploiting the influence of the ego drone's trajectory on the adversaries' objectives through the shared collision avoidance constraints among the vehicles. We also propose two methods for accelerating this computationally intensive iterative algorithm using (i) parallel computing with multiple CPU cores, and (ii) a neural network model that learns to predict trajectories close to the Nash equilibrium through offline training examples. Extensive simulation studies are conducted to benchmark the performance of our game theoretic planner and the statistical results show that our approach largely outperforms a baseline model predictive control algorithm that does not account for the opponents' reactions. Hardware experiments with 4 quadrotor robots on a 3D racecourse are performed to show the applicability of our method in real-time robotic systems. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103410	10.1016/j.robot.2019.103410													
J								Design and performance analysis of a parallel wrist rehabilitation robot (PWRR)	ROBOTICS AND AUTONOMOUS SYSTEMS										Wrist rehabilitation; Parallel mechanism; Velocity Jacobian matrices; Workspace analysis; Wearable convenience	STROKE; COMPATIBILITY; EXOSKELETON	Wrist rehabilitation robots are essential for assisting patients with stoke or wrist injuries. Such devices compensate for deficiencies in manual rehabilitation training, and reduce the workload of rehabilitation physicians. A parallel wrist rehabilitation robot (PWRR) driven by two pneumatic actuators is developed in this paper, consisting of two rotational degrees of freedom for the movements of flexion/extension (F/E) and radial/ulnar deviation (R/U). All components connected to the forearm or the wrist adopt an open structure to improve the wearable convenience, and the PWRR is suitable for most patients, especially those with hypertonia. To determine the PWRR range of motion, the physiological motion space (PMS) of the wrist joint in autonomous and boundary elliptical movements is measured with the help of a VICON motion capture system. The PMS in boundary motions processes an elliptical shape, and the ulnar deviations occupy the most range of motion. The theoretical workspace (TWS) of PWRR is then calculated and designed based on the kinematic model and the distribution characteristics of PMS. In addition, two indices are introduced to evaluate the kinematic performance of PWRR. A PWRR prototype is developed based on the optimal geometrical parameters and detailed structures. Its effective workspace (EWS), which has more clinical significance, is acquired by measuring the F/E and R/U movements during autonomic movements. The EWS, is smaller than TWS due to the physical structure, volume, and interference of mechanical elements. Besides, EWS can nearly encircle PMS, and satisfies all single-axis rehabilitations and compound motions of the wrist complex. The two indices, motion isotropy d(a) and condition number kappa, within TWS change smoothly with no mutation, suggesting that PWRR is sufficiently kinematically isotropic, and has no singularity configuration. The analysis shows that the developed PWRR can be applied widely in the wrist rehabilitation. (C) 2019 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				MAR	2020	125								103390	10.1016/j.robot.2019.103390													
J								Polynomial rewritings from expressive Description Logics with closed predicates to variants of Datalog	ARTIFICIAL INTELLIGENCE										Description Logics; Datalog; Closed predicates; Ontology-mediated query answering; Query rewriting; Succinctness; Relative expressiveness	COMPLEXITY; DL	In many scenarios, complete and incomplete information coexist. For this reason, the knowledge representation and database communities have long shown interest in simultaneously supporting the closed- and the open-world views when reasoning about logic theories. Here we consider the setting of querying possibly incomplete data using logic theories, formalized as the evaluation of an ontology-mediated query (OMQ) that pairs a query with a theory, sometimes called an ontology, expressing background knowledge. This can be further enriched by specifying a set of closed predicates from the theory that are to be interpreted under the closed-world assumption, while the rest are interpreted with the open-world view. In this way we can retrieve more precise answers to queries by leveraging the partial completeness of the data. The central goal of this paper is to understand the relative expressiveness of ontology-mediated query languages in which the ontology part is written in the expressive Description Logic (DL) ALCHOI and includes a set of closed predicates. We consider a restricted class of conjunctive queries. Our main result is to show that every query in this non-monotonic query language can be translated in polynomial time into DATALOG with negation as failure under the stable model semantics. To overcome the challenge that DATALOG has no direct means to express the existential quantification present in ALCHOI, we define a two-player game that characterizes the satisfaction of the ontology, and design a DATALOG query that can decide the existence of a winning strategy for the game. If there are no closed predicates in the case of querying an ALCHOI knowledge base our translation yields a positive disjunctive DATALOG program of polynomial size. To the best of our knowledge, unlike previous translations for related fragments with expressive (non-Horn) DLs, these are the first polynomial time translations. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				MAR	2020	280								103220	10.1016/j.artint.2019.103220													
J								The Hanabi challenge: A new frontier for AI research	ARTIFICIAL INTELLIGENCE										Multi-agent learning; Challenge paper; Reinforcement learning; Games; Theory of mind; Communication; Imperfect information; Cooperative	ARCADE LEARNING-ENVIRONMENT; COMPREHENSIVE SURVEY; REINFORCEMENT; GAME; GO; POKER	From the early days of computing, games have been important testbeds for studying how well machines can do sophisticated decision making. In recent years, machine learning has made dramatic advances with artificial agents reaching superhuman performance in challenge domains like Go, Atari, and some variants of poker. As with their predecessors of chess, checkers, and backgammon, these game domains have driven research by providing sophisticated yet well-defined challenges for artificial intelligence practitioners. We continue this tradition by proposing the game of Hanabi as a new challenge domain with novel problems that arise from its combination of purely cooperative gameplay with two to five players and imperfect information. In particular, we argue that Hanabi elevates reasoning about the beliefs and intentions of other agents to the foreground. We believe developing novel techniques for such theory of mind reasoning will not only be crucial for success in Hanabi, but also in broader collaborative efforts, especially those with human partners. To facilitate future research, we introduce the open-source Hanabi Learning Environment, propose an experimental framework for the research community to evaluate algorithmic advances, and assess the performance of current state-of-the-art techniques. (C) 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).																	0004-3702	1872-7921				MAR	2020	280								103216	10.1016/j.artint.2019.103216													
J								Relative inconsistency measures	ARTIFICIAL INTELLIGENCE										Logic; Inconsistency measure; Relative measures; Postulates		The literature on inconsistency measures has ignored a distinction, that is, differentiating absolute measures and relative measures. An absolute measure gives the total amount of inconsistency in the knowledge base but a relative measure computes, by some criteria, the proportion of the base that is inconsistent. To compare the inconsistency measures, researchers have proposed postulates for such measures. We split these postulates into three groups: ones (including two new postulates) that relative measures should satisfy, ones inappropriate for relative measures, and ones that relative measures may satisfy. We obtain some new results upon the relationships between these groups of postulates. On these grounds, we introduce a formal definition for relative inconsistency measures. We consider some relative measures previously proposed and define several new ones that serve as examples. We show that all of these measures satisfy the new formal definition. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				MAR	2020	280								103231	10.1016/j.artint.2019.103231													
J								When autonomous agents model other agents: An appeal for altered judgment coupled with mouths, ears, and a little more tape	ARTIFICIAL INTELLIGENCE										Agent modeling; Autonomous agents; Multi-agent systems	SOCIAL DILEMMAS; COOPERATION; REGRET	Agent modeling has rightfully garnered much attention in the design and study of autonomous agents that interact with other agents. However, despite substantial progress to date, existing agent-modeling methods too often (a) have unrealistic computational requirements and data needs; (b) fail to properly generalize across environments, tasks, and associates; and (c) guide behavior toward inefficient (myopic) solutions. Can these challenges be overcome? Or are they just inherent to a very complex problem? In this reflection, I argue that some of these challenges may be reduced by, first, modeling alternative processes than what is often modeled by existing algorithms and, second, considering more deeply the role of non-binding communication signals. Additionally, I believe that progress in developing autonomous agents that effectively interact with other agents will be enhanced as we develop and utilize a more comprehensive set of measurement tools and benchmarks. I believe that further development of these areas is critical to creating autonomous agents that effectively model and interact with other agents. (C) 2019 The Author. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).																	0004-3702	1872-7921				MAR	2020	280								103219	10.1016/j.artint.2019.103219													
J								Reasoning about uncertain parameters and agent behaviors through encoded experiences and belief planning	ARTIFICIAL INTELLIGENCE										Planning under uncertainty; Partial observability; Cooperative multi-agent system; Parameter estimation; Object manipulation; Model adaptation	FRAMEWORK	Robots are expected to handle increasingly complex tasks. Such tasks often include interaction with objects or collaboration with other agents. One of the key challenges for reasoning in such situations is the lack of accurate models that hinders the effectiveness of planners. We present a system for online model adaptation that continuously validates and improves models while solving tasks with a belief space planner. We employ the well known online belief planner POMCP. Particles are used to represent hypotheses about the current state and about models of the world. They are sufficient to configure a simulator to provide transition and observation models. We propose an enhanced particle reinvigoration process that leverages prior experiences encoded in a recurrent neural network (RNN). The network is trained through interaction with a large variety of object and agent parametrizations. The RNN is combined with a mixture density network (MDN) to process the current history of observations in order to propose suitable particles and models parametrizations. The proposed method also ensures that newly generated particles are consistent with the current history. These enhancements to the particle reinvigoration process help alleviate problems arising from poor sampling quality in large state spaces and enable handling of dynamics with discontinuities. The proposed approach can be applied to a variety of domains depending on what uncertainty the decision maker needs to reason about. We evaluate the approach with experiments in several domains and compare against other state-of-the-art methods. Experiments are done in a collaborative multi-agent and a single agent object manipulation domain. The experiments are performed both in simulation and on a real robot. The framework handles reasoning with uncertain agent behaviors and with unknown object and environment parametrizations well. The results show good performance and indicate that the proposed approach can improve existing state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				MAR	2020	280								103228	10.1016/j.artint.2019.103228													
J								The computational complexity of Angry Birds	ARTIFICIAL INTELLIGENCE										Computational complexity; AI and games; Physics simulation games; Game playing; Angry Birds		The physics-based simulation game Angry Birds has been heavily researched by the AI community over the past five years, and has been the subject of a popular AI competition that is currently held annually as part of a leading AI conference. Developing intelligent agents that can play this game effectively has been an incredibly complex and challenging problem for traditional AI techniques to solve, even though the game is simple enough that any human player could learn and master it within a short time. In this paper we analyse how hard the problem really is, presenting several proofs for the computational complexity of Angry Birds. By using a combination of several gadgets within this game's environment, we are able to demonstrate that the decision problem of solving general levels for different versions of Angry Birds is either NP-hard, PSPACE-hard, PSPACE-complete or EXPTIME-hard. Proof of NP-hardness is by reduction from 3-SAT, whilst proof of PSPACE-hardness is by reduction from True Quantified Boolean Formula (TQBF). Proof of EXPTIME-hardness is by reduction from G2, a known EXPTIME-complete problem similar to that used for many previous games such as Chess, Go and Checkers. To the best of our knowledge, this is the first time that a single-player game has been proven EXPTIME-hard. This is achieved by using stochastic game engine dynamics to effectively model the real world, or in our case the physics simulator, as the opponent against which we are playing. These proofs can also be extended to other physics-based games with similar mechanics. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				MAR	2020	280								103232	10.1016/j.artint.2019.103232													
J								SCCWalk: An efficient local search algorithm and its improvements for maximum weight clique problem	ARTIFICIAL INTELLIGENCE										The maximum weight clique problem; Local search; Strong configuration checking; Walk perturbation procedure; Massive graph	RANDOM CONSTRAINT SATISFACTION; CONFIGURATION CHECKING; WINNER DETERMINATION; BOUND ALGORITHM; SET	The maximum weight clique problem (MWCP) is an important generalization of the maximum clique problem with wide applications. In this study, we develop two efficient local search algorithms for MWCP, namely SCCWalk and SCCWalk4L, where SCCWalk4L is improved from SCCWalk for large graphs. There are two main ideas in SCCWalk, including strong configuration checking (SCC) and walk perturbation. SCC is a new variant of a powerful strategy called configuration checking for local search. The walk perturbation procedure is used to lead the algorithm to leave the current area and come into a new area of feasible solution space. Moreover, to improve the performance on massive graphs, we apply a low-complexity heuristic called best from multiple selection to select the swapping vertex pair quickly and effectively, resulting in the SCCWalk4L algorithm. In addition, SCCWalk4L uses two recent reduction rules to decrease the scale of massive graphs. We carry out experiments to evaluate our algorithms on several popular benchmarks, which are divided into two groups, including classical benchmarks of small graphs namely DIMACS, BHOSLIB, winner determination problem, and graphs derived from clustering aggregation, as well as massive graphs, including a suite of massive real-world graphs and large-scale FRB graphs. Experiments show that, compared to state-of-the-art heuristic algorithms and exact algorithm, the proposed algorithms perform better on classical benchmarks, and obtain the best solutions for most massive graphs. (C) 2019 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				MAR	2020	280								103230	10.1016/j.artint.2019.103230													
J								Improved Teaching Learning Based Optimization and Its Application in Parameter Estimation of Solar Cell Models	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Evolutionary computation; parameter estimation; solar cell model; teaching learning based optimization	DIFFERENTIAL EVOLUTION; DISPATCH PROBLEM; ALGORITHM; IDENTIFICATION; STRATEGY; PATH	Weak global exploration capability is one of the primary drawbacks in teaching learning based optimization (TLBO). To enhance the search capability of TLBO, an improved TLBO (ITLBO) is introduced in this study. In ITLBO, a uniform random number is replaced by a normal random number, and a weighted average position of the current population is chosen as the other teacher. The performance of ITLBO is compared with that of five meta-heuristic algorithms on a well-known test suite. Results demonstrate that the average performance of ITLBO is superior to that of the compared algorithms. Finally, ITLBO is employed to estimate parameters of two solar cell models. Experiments verify that ITLBO can provide competitive results.																	1079-8587	2326-005X				MAR	2020	26	1					1	12		10.31209/2018.100000042													
J								Application Centric Virtual Machine Placements to Minimize Bandwidth Utilization in Datacenters	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Bandwidth Allocation; Datacenters; Resources Optimization; VM Placement	CLOUD	An efficient placement of virtual machines (VMs) in a cloud datacenter is important to maximize the utilization of infrastructure. Most of the existing work maximises the number of VMs to place on a minimum number of physical machines (PMs) to reduce energy consumption. Recently, big data applications become popular which are mostly hosted on cloud datacenters. Big data applications are deployed on multiple VMs and considered data and communication intensive applications. These applications can consume most of the datacenter bandwidth if VMs do not place close to each other. In this paper, we investigate the use of different VM placement methods to decrease the usage of bandwidth in different sizes of datacenters. We implemented and evaluated five different VM placement algorithms. Our comprehensive set of experiments show a significant decrease in bandwidth ranging from 65% to 78% can be achieved using the extended implementations of the knapsack and first fit VM placement methods.																	1079-8587	2326-005X				MAR	2020	26	1					13	25		10.31209/2018.100000047													
J								Model Predictive Control for Nonlinear Energy Management of a Power Split hybrid Electric Vehicle	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Energy management; dynamic programming; linear time-varying mode; model predictive control; sequential quadratic programming	CONTROL STRATEGIES; SYSTEM; HEV	Model predictive control (MPC), owing to the capability of dealing with nonlinear and constrained problems, is quite promising for optimization. Different MPC strategies are investigated to optimize HEV nonlinear energy management for better fuel economy. Based on Bellman's principle, dynamic programming is firstly used in the limited horizon to obtain optimal solutions. By considering MPC as a nonlinear programming problem, sequential quadratic programming (SQP) is used to obtain the descent directions of control variables and the current control input is further derived. To reduce computation and meet the requirements of real-time control, the nonlinear model of the system is approximated to be linear and linear time-varying (LTV) MPC strategy is studied. Simulation results demonstrate that the nonlinear MPC using SQP algorithm has best fuel economy, while the MPC using approximated linear model is superior in saving computation time.																	1079-8587	2326-005X				MAR	2020	26	1					27	39		10.31209/2018.100000062													
J								African Buffalo Optimization Algorithm for Collision-Avoidance in Electric Fish	INTELLIGENT AUTOMATION AND SOFT COMPUTING										African Buffalo Optimization; Collision-avoidance; Computational Intelligence; Electric fish; Neuroscience; Travelling Salesman's Problems	ACTIVE ELECTROLOCATION; IMPLEMENTATION	This paper presents the African Buffalo Optimization algorithm for collision avoidance among electric fishes. Collision-avoidance in electric fish finds correlation with the Travelling Salesman avoiding the cities he has earlier visited. Collision avoidance in electric is akin to collision-avoidance in modem day driverless cars being promoted by Google Incorporation and other similar companies. The concept of collision-avoidance is also very useful to persons with visual impairment as it will help them avoid collision with objects, vehicles, persons, especially other visually-impaired. After a number of experimental procedures using the concept of the travelling salesman's problem to simulate collision-avoidance in electric fish, this study concludes that the African Buffalo Optimization is a veritable tool for simulating collision-avoidance in electric fishes.																	1079-8587	2326-005X				MAR	2020	26	1					41	51		10.31209/2018.100000059													
J								Laparoscopic Training Exercises Using HTC VIVE	INTELLIGENT AUTOMATION AND SOFT COMPUTING										HTC VIVE; Laparoscopic training; Virtual reality		Laparoscopic surgery is a relatively new field in developing countries. There is a scarcity of laparoscopically trained doctors due to a lack of training and resources available in hospitals. Training and evaluation of medical professionals to develop laparoscopic surgical skills are important and essential as it improves the success rate and reduces the risk during real surgery. The purpose of this research is to develop a series of training exercises based on virtual reality using HTC Vive headset to emulate real-world training of doctors. This virtual training not only gives the trainee doctors mastery in their profession but also decreases the chances of complications during laparoscopic surgery. After practicing on our simulator for three trials, doctors report enhancement in the following skills: time to complete a task, precision, efficiency of a task, and the recorded movements of surgical instruments using both hands. Our simulator is comparatively low cost as compared to the available simulator in the local market																	1079-8587	2326-005X				MAR	2020	26	1					53	59		10.31209/2019.100000149													
J								C5.0 Decision Tree Model Using Tsallis Entropy and Association Function for General and Medical Dataset	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Data Mining; Association Function; Classification; Decision Tree; Entropy		Real world data consists of lot of impurities. Entropy measure will help to handle impurities in a better way. Here, data selection is done by using Naive Bayes' theorem. The sample which has posterior probability value greater than that of the threshold value is selected. C5.0 decision tree classifier is taken as base and modified the Gain calculation function using Tsallis entropy and Association function. The proposed classifier model provides more accuracy and smaller tree for general and Medical dataset. Precision value obtained for Medical dataset is more than that of existing method.																	1079-8587	2326-005X				MAR	2020	26	1					61	70		10.31209/2019.100000153													
J								Enhancing the Classification Accuracy in Sentiment Analysis with Computational Intelligence Using Joint Sentiment Topic Detection with MEDLDA	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Accuracy; Classification; Machine Learning methods; Reviews; Sentiments; Sentiment analysis		Web mining is the process of integrating the information from web by traditional data mining methodologies and techniques. Opinion mining is an application of natural language processing to extract subjective information from web. Online reviews require efficient classification algorithms for analysing the sentiments, which does not perform an in-depth analysis in current methods. Sentiment classification is done at document level in combination with topics and sentiments. It is based on weakly supervised Joint Sentiment-Topic mode which extends the topic model Maximum Entropy Discrimination Latent Dirichlet Allocation by constructing an additional sentiment layer. It is assumed that topics generated are dependent on sentiment distributions and the words generated are conditioned on the sentiment topic pairs. MEDLDA is used to increase the accuracy of topic modeling.																	1079-8587	2326-005X				MAR	2020	26	1					71	79		10.31209/2019.100000152													
J								Finding Temporal Influential Users in Social Media Using Association Rule Learning	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Social Media; Association Rule Mining; Influential Users; Bloggers; Apriori		The social media has become an integral part of our daily life. The social web users interact and thus influence each other influence in many aspects. Blogging is one of the most important features of the social web. The bloggers share their views, opinions and ideas in the form of blog posts. The influential bloggers are the leading bloggers who influence the other bloggers in their online communities. The relevant literature presents several studies related to identification of top influential bloggers in last decade. The research domain of finding the top influential bloggers mainly focuses on feature centric models. This research study proposes to apply association rule learning for finding the temporal influential bloggers. The widely used Apriori algorithm is applied using Oracle data miner to find the frequent pattern of bloggers having blog activities together and then we find who influences others based on the rules learned from the association rule mining. The use of standard evaluation measures such as accuracy, precision and F1 score verifies the results. This research study uses the standard dataset of TechCrunch which is a real world blog. The results confirm that the association rule mining can produce rules which help to find the temporal influential bloggers in the blogosphere who are consistent on regular basis. The proposed method achieved accuracy as high as 98% for confidence level of 90%. The identification of the top influential bloggers has enormous applications in advertising, online marketing, e-commerce, promoting a political agenda, influencing elections and affect the government policies.																	1079-8587	2326-005X				MAR	2020	26	1					87	98		10.31209/2019.100000130													
J								Implementation of Local Area VR Environment using Mobile HMD and Multiple Kinects	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Virtual Reality; Mobile HMD; Multi-Kinect		Recently, the development of HMDs such as Oculus Rift, HTC Vive, and PSVR has led to an increase in the interest of people in virtual reality (VR), and many related studies have been published. This leads to an additional cost increase in configuring the VR system. Also, space problems are caused. When the treadmill is installed, additional space is required, which may adversely affect the popularization of VR. In this paper, we propose a local area VR environment that solves cost and space problems using human tracking using several Kinect and solves the hygiene problems using smartphone-based mobile HMD.																	1079-8587	2326-005X				MAR	2020	26	1					99	105		10.31209/2019.100000131													
J								A Novel Knowledge-Based Battery Drain Reducer for Smart Meters	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Smart grid; Smart meter; Battery Energy; Semantic Web (SW); Relational Database to RDF	JHELUM RIVER; IMPACTS; CLIMATE	The issue of battery drainage in the gigantic smart meters network such as semantic-aware IoT-enabled smart meter has become a serious concern in the smart grid framework. The grid core migrates existing tabular datasets i.e., Relational data to semantic-aware tuples in its Resource Description Framework (RDF) format, for effective integration among multiple components to work aligned with IoT. For this purpose, WWW Consortium (W3C) recommends two specifications as mapping languages. However, both specifications use entire RDB schema to generate data transformation mapping patterns and results large quantity of unnecessary transformation. As a result, smart meters use huge computing resources, maximum energy capacity and come across battery drain problems. This paper proposes a novel semantic-aware battery drain optimization strategy 'SPARQL Auto R2RML Mapping (SARM)' that generates custom RDF patterns with precise metadata and avoids use of full schema along with optimized usage of network resources through (i) selective metadata migration, and (ii) optimal battery usage. The proposed approach effectively increases battery life with a balanced proportion of energy consumption and reduces meter load congestion which happens to be another vital reason of battery drain problem. The presented knowledge-based battery drain prevention strategy is evaluated over an RDB dataset using three types of SPARQL queries; Basic, Nested and Join. Furthermore, the R2RML processors evaluated SARM over the most recent Berlin SPARQL Benchmark datasets which depicts that SARM is efficient 40.4% in mapping generation time and 10.46% in average planning time than default RDB2RDF transformations. Finally, SARM significantly improves total execution time of RDB2RDF migration with an efficiency of 8.82% and conserves battery drain by 18.5% over the smart grid data cluster.																	1079-8587	2326-005X				MAR	2020	26	1					107	119		10.31209/2019.100000132													
J								A Method for Planning the Routes of Harvesting Equipment using Unmanned Aerial Vehicles	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Artificial Neural Networks; Nonlinear Scheme of Compromises; Precision Farming Systems; Unmanned Aerial Vehicles; Unmanned Harvesting Equipment	VEGETATION; PLATFORM; IMAGERY; HEIGHT	The widespread distribution of precision farming systems necessitates improvements in the methods for the control of unmanned harvesting equipment (UHE). While unmanned aerial vehicles (UAVs) provide an effective solution to this problem, there are many challenges in the implementation of technology. This paper considers the problem of identifying optimal routes of UHE movement as a multicriteria evaluation problem, which can be solved by a nonlinear scheme of compromises. The proposed method uses machine learning algorithms and statistical processing of the spectral characteristics obtained from UAV digital images. Developed method minimizes the resources needed for a harvesting campaign and reduces the costs of fuel consumption.																	1079-8587	2326-005X				MAR	2020	26	1					121	132		10.31209/2019.100000133													
J								Distinction Between Real Faces and Photos by Analysis of Face Data	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Virtual Reality; Mobile HMD; Multi-Kinect		Biometric user authentication using the face has been applied mainly to access control systems. However, access is allowed even when a photo is presented instead of an actual face. This can facilitate illegal access including attending as a substitute or substitute authentication. An alternative approach has been implemented to solve this problem. The approach determines between a real face and a photo of a face using a UV sensor but this requires substantial cost and installation process because additional hardware (the UV sensor) is necessary. This paper proposes a three-step approach to identify between a real image and a photo. Step 1 determines authenticity using the background data and eliminating the face data. Step 2 determines authenticity using eyelid blinking on the face and facial gestures. Step 3 authorizes the user by extracting the feature points on the face.																	1079-8587	2326-005X				MAR	2020	26	1					133	139		10.31209/2019.100000134													
J								Word Embedding Based Knowledge Representation with Extracting Relationship Between Scientific Terminologies	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Word Embedding; Text Mining; Web Technology; Big Data; Information Retrieval	MANAGEMENT	With the trends of big data era, many people want to acquire the reliable and refined information from web environments. However, it is difficult to find appropriate information because the volume and complexity of web information is increasing rapidly. So many researchers are focused on text mining and personalized recommendation for extracting users' interests. The proposed approach extracted semantic relationship between scientific terminologies with word embedding approach. We aggregated science data in BT for supporting users' wellness. In our experiments, query expansion is performed with relationship between scientific terminologies with user's intention.																	1079-8587	2326-005X				MAR	2020	26	1					141	147		10.31209/2019.100000135													
J								Noise Cancellation Based on Voice Activity Detection Using Spectra Variation for Speech recognition in Smart Home Devices	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Noise cancellation; Non-stationary noise reduction; Smart home device; Spectral subtraction; Speech recognition; Voice activity detection		Variety types of smart home devices have a main function of a human-machine interaction by speech recognition. Speech recognition system may be vulnerable to rapidly changing noises in home environments. This study proposes an efficient noise cancellation approach to eliminate the noises directly on the devices in real time. Firstly, we propose an advanced voice activity detection (VAD) technique to efficiently detect speech and non-speech regions on the basis of spectral property of speech signals. The VAD is then employed to enhance the conventional spectral subtraction method by steadily estimating noise signals in non-speech regions. On several experiments, our approach achieved superior performance compared to the conventional noise reduction approaches.																	1079-8587	2326-005X				MAR	2020	26	1					149	159		10.31209/2019.100000136													
J								Variable Block Scheme for Minimizing File I/O	INTELLIGENT AUTOMATION AND SOFT COMPUTING										Operating system; File System; Storage; variable-block		In the conventional operating system, file modification overhead is very high because data block should be rewritten to the storage system when we delete or insert several bytes in disk system. To reduce the overhead of file modification, we have to provide byte stream operation to the block device, which can delete bytes of data without block-alignment consideration. In this paper, we explain a variable length block scheme to modify the contents of a file in a situation where some data is deleted. The variable length block is a technique that minimizes block writing by creating a bumper area in a block to save the contents of all files in a situation where some bytes are deleted and storing only the block where the modification occurred. With this approach, we can mimics byte stream operation on block-based disk storage system. In experiment result, we show that the performance of the proposed system is superior to conventional file system.																	1079-8587	2326-005X				MAR	2020	26	1					161	168		10.31209/2019.100000137													
