PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Super-resolution reconstruction of single anisotropic 3D MR images using residual convolutional neural network	NEUROCOMPUTING										Magnetic resonance imaging; Super-resolution reconstruction; Convolutional neural network; Residual learning; Multi-modality super-resolution		High-resolution (HR) magnetic resonance (MR) imaging is an important diagnostic technique in clinical practice. However, hardware limitations and time constraints often result in the acquisition of anisotropic MR images. It is highly desirable but very challenging to enhance image spatial resolution in medical image analysis for disease diagnosis. Recently, studies have shown that deep convolutional neural networks (CNN) can significantly boost the performance of MR image super-resolution (SR) reconstruction. In this paper, we present a novel CNN-based anisotropic MR image reconstruction method based on residual learning with long and short skip connections. The proposed network can effectively alleviate the vanishing gradient problem of deep networks and learn to restore high-frequency details of MR images. To reduce computational complexity and memory usage, the proposed network utilizes cross-plane selfsimilarity of 3D T1-weighted (T1w) MR images. Based on experiments on simulated and clinical brain MR images, we demonstrate that the proposed network can significantly improve the spatial resolution of anisotropic MR images with high computational efficiency. The network trained on T1w MR images is able to effectively reconstruct both SR T1w and T2-weighted (T2w) images, exploiting image features for multi-modality reconstruction. Moreover, the experimental results show that the proposed method outperforms classical interpolation methods, non-local means method (NLM), and sparse coding based algorithm in terms of peak signal-to-noise-ratio, structural similarity image index, intensity profile, and small structures. The proposed method can be efficiently applied to SR reconstruction of thick-slice MR images in the out-of-plane views for radiological assessment and post-acquisition processing. (c) 2019 Published by Elsevier B.V.																	0925-2312	1872-8286				JUN 7	2020	392						209	220		10.1016/j.neucom.2018.10.102													
J								A framework for hierarchical division of retinal vascular networks	NEUROCOMPUTING										Retinal vessels; Framework; Hierarchical division; Classification; Bifurcations	VESSEL SEGMENTATION; BLOOD-VESSELS; BIFURCATIONS; IMAGES; MODEL	Human retinal vascular network plays an important role in ophthalmology diagnosis. For example, in the diagnosis of ophthalmology, the severity of the disease has a direct correlation with the lesion location, in the sense that the closer the lesion area is to the optic disk, the higher will be the severity of the disease. If a framework is able to provide the hierarchical structure of the retinal vascular network, then the severity of disease can be quantified by leveraging the hierarchical characteristics of vessels in the vicinity of the lesion location. Thus, in this paper, an executable framework is recommended for the hierarchical division of the retinal vascular networks. Specifically, a supervised method based on deep neural network is used for retinal blood vessel segmentation. A graph-based method is also applied to generate vascular trees from the segmented retinal vessels. As part of our proposed approach, we present two algorithms: the potential landmark detection algorithm (PLDA) is used to identify the bifurcations and crossings; and the adaptive hierarchical classification algorithm (AHCA) is used in the hierarchical characteristics classification of vascular bifurcations. By classifying the hierarchical characteristics of vascular bifurcation, the hierarchical characteristics of the vessel segments containing these bifurcations are identified. Thus, the hierarchical division of retinal vascular network is realized. When applied to two publicly available datasets, DRIVE and STARE, the proposed framework achieves an accurate rate of 98.99% and sensitivity rate of 92.17%. (c) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						221	232		10.1016/j.neucom.2018.11.113													
J								Analysis of tuberculosis severity levels from CT pulmonary images based on enhanced residual deep learning architecture	NEUROCOMPUTING										Deep learning; Residual deep learning network; Classification; 3D block-based image classification; Tuberculosis (TB); Severity score of TB	CLASSIFICATION; CHEST	This research investigates the application of CT pulmonary images to the detection and characterisation of TB at five levels of severity, in order to monitor the efficacy of treatment. To contend with smaller datasets (i.e. in hundreds) and the characteristics of CT TB images in which abnormalities occupy only limited regions, a 3D block-based residual deep learning network (ResNet) coupled with injection of depth information (depth-ResNet) at each layer was implemented. Progress in evaluation has been accomplished in two ways. One is to assess the proposed depth-ResNet in prediction of severity scores and another is to analyse the probability of high severity of TB. For the former, delivered results are of 92.70 +/- 5.97% and 67.15 +/- 1.69% for proposed depth-ResNet and ResNet-50 respectively. For the latter, two additional measures are put forward, which are calculated using (1) the overall severity (1 to 5) probability, and (2) separate probabilities of both high severity (scores of 1 to 3) and low severity (scores of 4 and 5) respectively, when scores of 1 to 5 are mapped into initial probabilities of (0.9, 0.7, 0.5, 0.3, 0.2) respectively. As a result, these measures achieve the averaged accuracies of 75.88% and 85.29% for both methods respectively. (c) 2019ElsevierB.V. Allrightsreserved.																	0925-2312	1872-8286				JUN 7	2020	392						233	244		10.1016/j.neucom.2018.12.086													
J								Lung adenocarcinoma diagnosis in one stage	NEUROCOMPUTING										Lung adenocarcinoma diagnosis; Feature pyramid network	CANCER STATISTICS; NODULE DETECTION; IMAGES	Early detection of lung cancer is the most promising path to increase the chance of survival for patients. Accurate lung nodule detection in computed tomography (CT) images is a crucial step in diagnosing lung cancer. CNN based CADe systems diagnose lung nodules in two stages by using one network for detection and another following network for classification or false positive reduction. Besides costly construction, two-stage systems can only find a single-scale location including many surrounding contexts for each nodule, which leads to a limited accuracy when classifying small nodules. In this paper, we construct a one-stage framework relying on feature pyramid network (FPN) for the diagnosis of lung adenocarcinoma (LA). The proposed network has two advantages, (i) it can localize and classify LAs simultaneously. (ii) it generates feature maps with high resolution, from which robust classification is reached since tight coverage takes less contextual information. The performance of the proposed one-stage diagnostic network is verified on a lung adenocarcinoma dataset. Experimental results show that it achieves higher sensitives than two-stage frameworks. (c) 2019 Published by Elsevier B.V.																	0925-2312	1872-8286				JUN 7	2020	392						245	252		10.1016/j.neucom.2018.11.110													
J								Fine-tuning Pre-trained Convolutional Neural Networks for Gastric Precancerous Disease Classification on Magnification Narrow-band Imaging Images	NEUROCOMPUTING										Precancerous and early cancerous gastric lesions Microvascular morphologies; Fine-tuning; CNNs; M-NBI images	TEXTURE DESCRIPTORS; COLOR CONSTANCY	Gastric cancer(GC) is the fourth leading cause of cancer death worldwide. To prevent the occurrence of advanced GCs, there is a need for immediate detection and treatment of gastric precancerous and early cancerous lesions. Magnification endoscopy with narrow-band imaging (M-NBI) system as an advanced diagnostic imaging technology is widely used in evaluating gastric lesion types, which can interpret gastric lesion characteristics by enhancing contrasts between vessels and mucosal surfaces. Based on microvascular morphologies presented on M-NBI images, physicians can manually diagnose gastric lesions; but this is a tough work for unexperienced doctors and it is lacking of objectivity. In this study, we propose a transfer learning framework by fine-tuning pre-trained convolutional neural networks (CNNs) to classify gastric M-NBI images into three classes: chronic gastritis (CGT), low grade neoplasia (LGN) and early gastric cancer (EGC). The method we choose is used to compare with three kinds of traditional handcraft texture feature extraction methods and CNN models trained directly by our dataset. Results show that the performance of fine-tuned CNNs outperforms traditional handcraft features and trained CNNs. Experiments also illustrate that ResNet50 can achieve 0.96 accuracy, 0.92, 0.91 and 0.99 f1-scores for classifying M-NBI images into CGT, LGN and EGC. In conclusion, the proposed framework is suit for multi-classification tasks of gastric M-NBI images. (c) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						253	267		10.1016/j.neucom.2018.10.100													
J								CcNet: A cross-connected convolutional network for segmenting retinal vessels using multi-scale features	NEUROCOMPUTING										Cross-connection; Retinal vessel segmentation; Convolutional network; Robust; Fast	BLOOD-VESSELS; SEGMENTATION; IMAGES	Retinal vessel segmentation (RVS) helps the diagnosis of diabetic retinopathy, which can cause visual impairment and even blindness. Some problems are hindering the application of automatic RVS, including accuracy, robustness and segmentation speed. In this paper, we propose a cross-connected convolutional neural network (CcNet) for the automatic segmentation of retinal vessel trees. In the CcNet, convolutional layers extract the features and predict the pixel classes according to those learned features. The CcNet is trained and tested with full green channel images directly. The cross connections between primary path and secondary path fuse the multi-level features. The experimental results on two publicly available datasets (DRIVE: Sn = 0.7625, Acc = 0.9528; STARE: Sn = 0.7709, Acc = 0.9633) are higher than those of most state-of-the-art methods. In the cross-training phase, CcNte's accuracy fluctuations (Delta Accs) on DRIVE and STARE are 0.0042 and 0.007, respectively, which are relatively small compared with those of published methods. In addition, our algorithm has faster computing speed (0.063 s) than those listed algorithms using a GPU (graphics processing unit). These results reveal that our algorithm has potential in practical applications due to promising segmentation performances including advanced specificity, accuracy, robustness and fast processing speed. (c) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						268	276		10.1016/j.neucom.2018.10.098													
J								Deep learning for variational multimodality tumor segmentation in PET/CT	NEUROCOMPUTING										Tumor segmentation; PET/CT images; Variational method; Deep learning; Information fusion	IMAGE SEGMENTATION; PATHOLOGICAL RESPONSE; ESOPHAGEAL CANCER; ACTIVE CONTOURS; CT; GRAPH; FEATURES; MODEL; CNN	Positron emission tomography/computed tomography (PET/CT) imaging can simultaneously acquire functional metabolic information and anatomical information of the human body. How to rationally fuse the complementary information in PET/CT for accurate tumor segmentation is challenging. In this study, a novel deep learning based variational method was proposed to automatically fuse multimodality information for tumor segmentation in PET/CT. A 3D fully convolutional network (FCN) was first designed and trained to produce a probability map from the CT image. The learnt probability map describes the probability of each CT voxel belonging to the tumor or the background, and roughly distinguishes the tumor from its surrounding soft tissues. A fuzzy variational model was then proposed to incorporate the probability map and the PET intensity image for an accurate multimodality tumor segmentation, where the probability map acted as a membership degree prior. A split Bregman algorithm was used to minimize the variational model. The proposed method was validated on a non-small cell lung cancer dataset with 84 PET/CT images. Experimental results demonstrated that: (1) Only a few training samples were needed for training the designed network to produce the probability map; (2) The proposed method can be applied to small datasets, normally seen in clinic research; (3) The proposed method successfully fused the complementary information in PET/CT, and outperformed two existing deep learning-based multimodality segmentation methods and other multimodality segmentation methods using traditional fusion strategies (without deep learning); (4) The proposed method had a good performance for tumor segmentation, even for those with Fluorodeoxyglucose (FDG) uptake inhomogeneity and blurred tumor edges (two major challenges in PET single modality segmentation) and complex surrounding soft tissues (one major challenge in CT single modality segmentation), and achieved an average dice similarity indexes (DSI) of 0.86 +/- 0.05, sensitivity (SE) of 0.86 +/- 0.07, positive predictive value (PPV) of 0.87 +/- 0.10, volume error (VE) of 0.16 +/- 0.12, and classification error (CE) of 0.30 +/- 0.12. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						277	295		10.1016/j.neucom.2018.10.099													
J								Computer aided Alzheimer's disease diagnosis by an unsupervised deep learning technology	NEUROCOMPUTING										Deep learning; Unsupervised learning; Convolutional neural network; Alzheimer's disease prediction; Magnetic Resonance Imaging data; Computer aided diagnosis	CLASSIFICATION; CONNECTIVITY; DEMENTIA; MRI	Deep learning technologies have played more and more important roles in Computer Aided Diagnosis (CAD) in medicine. In this paper, we tackled the problem of automatic prediction of Alzheimer's Disease (AD) based on Magnetic Resonance Imaging (MRI) images, and propose a fully unsupervised deep learning technology for AD diagnosis. We first implement the unsupervised Convolutional Neural Networks (CNNs) for feature extraction, and then utilize the unsupervised predictor to achieve the final diagnosis. In the proposed method, two kinds of data forms, one slice and three orthogonal panels (TOP) of MRI image, are employed as the input data respectively. Experimental results run on all the 1075 subjects in database of the Alzheimer's Disease Neuroimaging Initiative (ADNI 1 1.5T) show that the proposed method with one slice data yields the promising prediction results for AD vs. MCI (accuracy 95.52%) and MCI vs. NC (accuracy 90.63%), and the proposed methods with TOP data yields the best overall prediction results for AD vs. MCI (accuracy 97.01%) and MCI vs. NC (accuracy 92.6%). (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						296	304		10.1016/j.neucom.2018.11.111													
J								Brain tumor segmentation with deep convolutional symmetric neural network	NEUROCOMPUTING										Brain tumor segmentation; Symmetric; Deep convolutional neural networks; Magnetic resonance imaging	MODEL	Gliomas are the most frequent primary brain tumors, which have a high mortality. Surgery is the most commonly used treatment. Magnetic resonance imaging (MRI) is especially useful to assess gliomas and evaluate the success of the treatment in clinical practice. So accurately segmenting the brain tumor from MRI images is the key to clinical diagnostics and treatment planning. However, a large quantity of data produced by MRI prevents manual segmentation in a reasonable time. So automatic approaches are required for quick and effective segmentation. But the spatial and structural variability among brain tumors bring a challenge to automatically segment MRI images. Deep Convolutional Neural Network (DCNN) can achieve complex function mapping. This contributes to response to the challenge. Therefore, DCNN is the commonly used method in brain tumor segmentation. Although a large number of DCNN based methods have been proposed, these methods mainly aim to improve the quality of the image features extracted by DCNN. Actually, these methods usually ignore the prior knowledge in medical images, and the simple prior knowledge in brain tumor segmentation is that most of the tumor regions in images are left-right asymmetry. Based on this, in this paper, a novel deep convolutional neural network which combines symmetry have been proposed to automatically segment brain tumors. Our neural networks, called Deep Convolutional Symmetric Neural Network (DCSNN), extends DCNN based segmentation networks by adding symmetric masks in several layers. Our proposal was validated in the BRATS 2015 database, and we also give some baselines. The results are evaluated by dice similarity coefficient metric (DSC). And our proposed method achieved a competitive result with average DSC of 0.852. Furthermore, our method only takes about 10.8 s to segment a patient case. Although our method is not the best performance in BRATS 2015 challenge, as far as we know, our method outperforms other recent DCNN-based methods. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						305	313		10.1016/j.neucom.2019.01.111													
J								Bin loss for hard exudates segmentation in fundus images	NEUROCOMPUTING										Hard exudates segmentation; Diabetic retinopathy; Bin loss; Deep learning; Fundus image	COLOR RETINAL IMAGES; DIABETIC-RETINOPATHY; PHOTOGRAPHS	Diabetic retinopathy is one of the leading reasons that causes blindness. And the segmentation of hard exudates in color fundus images is crucial for early diagnosis of diabetic retinopathy, which is a difficult task due to its uncertainty in size, shape and contrast. Class-balanced cross entropy (CBCE) loss is the most popular objective function for image segmentation task to solve the class-unbalance problem. However, we show that background pixels tend to be misclassified to hard exudates in CBCE since the loss for a misclassified background pixels is much smaller than that for a misclassified hard exudate pixel, which is called loss-unbalance problem here. A top-k loss is proposed in this paper, which considers the cases of both class-unbalance and loss-unbalance by focusing more over the hard-to-classify pixels. Moreover, a fast version of the top-k loss, named bin loss, is implemented for efficiency, which reduces the time complexity from O(nlog n) of top-k loss to O(n), where n is the number of background pixels. We evaluated the proposed bin loss over two public datasets for hard exudates segmentation task, including e-ophtha EX and IDRiD. Furthermore, three popular models for image segmentation, HED, DeepLab v2, and FCRN, were used to evaluate the versatility of bin loss. Extensive experiments show that each model with the proposed bin loss performs better than that with CBCE loss, which demonstrates bin loss is versatile so that it can be applied to different models for performance improvement. Specially, for DeepLab over e-ophtha EX, the F-score increases 5.2 percentage points, and the area under the SE-PPV curve (AUC) increases 10.6 percentage points. Moreover, the AUC increases more than 4 percentage points over IDRiD dataset for both DeepLab and FCRN. The source code of bin loss is available at: https://github.com/guomugong/bin_loss. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						314	324		10.1016/j.neucom.2018.10.103													
J								AdaResU-Net: Multiobjective adaptive convolutional neural network for medical image segmentation	NEUROCOMPUTING										Multiobjective optimization; Convolutional neural networks; Deep learning; Medical image segmentation; Hyperparameter optimization; Evolutionary algorithms	PROSTATE SEGMENTATION; EVOLUTIONARY; EFFICIENT; SHAPE; MRI	Adapting an existing convolutional neural network architecture to a specific dataset for medical image segmentation remains a challenging task that requires extensive expertise and time to fine-tune the hyperparameters. Hyperparameter optimization approaches that automate the search have been proposed but have mainly focused on optimizing the segmentation performance. However, optimizing the network size is also important to prevent unnecessary and costly computational operations. In this paper, we present a multiobjective adaptive convolutional neural network (AdaResU-Net) for medical image segmentation that is able to automatically adapt to new datasets while minimizing the size of the network. The proposed AdaResU-Net is comprised of a fixed architecture that combines the structure of the state-of-the-art U-Net with a residual learning framework to improve information propagation and promote an efficient training. Then, a multiobjective evolutionary algorithm (MEA) that optimizes both segmentation accuracy and model size is proposed to evolve the AdaResU-Net networks with different hyperparameters. The presented model is tested on two publically available medical image datasets and compared with the U-Net. Results show that the AdaResU-Net achieves better segmentation performance with less than 30% the number of trainable parameters. Additionally, the MEA algorithm generated configurations that are smaller and perform better or equally well than configurations generated with a Bayesian hyperparameter optimization approach. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				JUN 7	2020	392						325	340		10.1016/j.neucom.2019.01.110													
J								Semi-supervised Dual-Branch Network for image classification	KNOWLEDGE-BASED SYSTEMS										Semi-supervised learning; Deep learning; Learned feature distribution mismatch		In this work, we reveal an essential problem rarely discussed in current semi-supervised learning literatures: the learned feature distribution mismatch problem between labeled samples and unlabeled samples. It is common knowledge that learning from the limited labeled data easily leads to overfitting. However, the difference between the inferred labels of unlabeled data and the ground truths of labeled data may make the learned features of labeled and unlabeled data have different distributions. This distribution mismatch problem may destroy the assumption of smoothness widely used in semi-supervised field, resulting in unsatisfactory performance. In this paper, we propose a novel Semi-supervised Dual-Branch Network (SDB-Net), in which the first branch is trained with labeled and unlabeled data, and the other is trained with the predictions of unlabeled data generated from the first branch only. To avoid the different distributions between ground-truth labels and inferred labels for the unlabeled data, we proposed an effective co-consistency loss to overcome the mismatch problem and a mix-consistency loss to make each branch learn a consistent feature representation. Meanwhile, we designed an augmentation supervised loss for the first branch to further alleviate the mismatch problem. With the designed three kinds of losses, the proposed SDB-Net can be efficiently trained. The experimental results on three benchmark datasets, such as CIFAR-10, CIFAR-100 and SVHN, show the superior performance of the proposed SDB-Net. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105837	10.1016/j.knosys.2020.105837													
J								Quantum recurrent encoder-decoder neural network for performance trend prediction of rotating machinery	KNOWLEDGE-BASED SYSTEMS										Quantum recurrent encoder-decoder neural network (QREDNN); Artificial intelligence; Attention mechanism; Quantum neuron; Performance trend prediction; Rotating machinery	REMAINING USEFUL LIFE; FAULT-DIAGNOSIS; DEGRADATION ASSESSMENT; INTELLIGENCE	Traditional neural networks generally neglect the primary and secondary relationships of input information and process the information indiscriminately, which leads to their bad nonlinear approximation capacity and low generalization ability. As a result, traditional neural networks always show poor prediction accuracy in the performance degradation trend prediction of rotating machinery (RM). In view of this, a novel neural network called quantum recurrent encoder-decoder neural network (QREDNN) is proposed in this paper. In QREDNN, the attention mechanism is used to simultaneously reconstruct encoder and decoder of QREDNN, so that QREDNN can fully excavate and pay attention to important information but suppress the interference of redundant information to obtain better nonlinear approximation capacity. On the other hand, the quantum neuron is used to construct a new quantum gated recurrent unit (QGRU) in which activation values and weights are represented by quantum rotation matrices. The QGRU can traverse the solution space more finely and has a lot of multiple attractors, so it can replace the traditional recurrent unit of the encoder and decoder and enhance the generalization ability and response speed of QREDNN. Moreover, the Levenberg-Marquardt (LM) algorithm is introduced to improve the update speeds of the rotation angles of quantum rotation matrices and the attention parameters of QREDNN. Based on the superiorities of QREDNN, a new performance trend prediction method for RM is proposed, in which the denoised fuzzy entropy (DFE) of vibration acceleration signal of RM is input into QREDNN as the performance degradation feature for predicting the performance degradation trend of RM. The examples of predicting the performance trend of rolling bearings demonstrate the effectiveness of our proposed method. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105863	10.1016/j.knosys.2020.105863													
J								A Dynamic Parameter Enhanced Network for distant supervised relation extraction	KNOWLEDGE-BASED SYSTEMS										Distant supervision; Relation extraction; Dynamic parameter; Style shift; Long-tail relation		Distant Supervised Relation Extraction (DSRE) is usually formulated as a problem about classifying a bag of sentences that contains two query entities into the predefined relation classes. Most existing methods consider those relation classes as distinct semantic categories while ignoring their potential connections to query entities. In this paper, we propose to leverage this connection to improve the relation extraction accuracy. Our key ideas are twofold: (1) For sentences belonging to the same relation class, the keywords to express the relation can vary according to the input query entities, i.e., style shift. To account for this style shift, the model can adjust its parameters in accordance with entity types. (2) Some relation classes are semantically similar, and the entity types appear in one relation may also appear in others. Therefore, it can be trained across different relation classes and further enhance those classes with few samples, i.e., long-tail relations. To unify these two arguments, we developed a novel Dynamic Parameter Enhanced Network (DPEN) for Relation Extraction, which introduces a parameter generator that can dynamically generates the network parameters according to the input query entity types and relation classes. By using this mechanism, the network can simultaneously handle the style shift problem and enhance the prediction accuracy for long-tail relations. Through extensive experiments, our method which is built on the top of the non-BERT-based or BERT-based models, can achieve superior performance over the state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105912	10.1016/j.knosys.2020.105912													
J								Multi-modal generative adversarial network for zero-shot learning	KNOWLEDGE-BASED SYSTEMS										Zero-shot learning; Multi-modal generative adversarial network; Feature fusion		In this paper, we propose a novel approach for Zero-Shot Learning (ZSL), where the test instances are from the novel categories that no visual data are available during training. The existing approaches typically address ZSL by embedding the visual features into a category-shared semantic space. However, these embedding-based approaches easily suffer from the "heterogeneity gap" issue since a single type of class semantic prototype cannot characterize the categories well. To alleviate this issue, we assume that different class semantics reflect different views of the corresponding class, and thus fuse various types of class semantic prototypes resided in different semantic spaces with a feature fusion network to generate pseudo visual features. Through the adversarial mechanism of the real visual features and the fused pseudo visual features, the complementary semantics in various spaces are effectively captured. Experimental results on three benchmark datasets demonstrate that the proposed approach achieves impressive performances on both traditional ZSL and generalized ZSL tasks. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105847	10.1016/j.knosys.2020.105847													
J								A multi-context representation approach with multi-task learning for object counting	KNOWLEDGE-BASED SYSTEMS										Object counting; Multi-task learning; Multi-context representation; Appearance context; Multi-scale semantic		Object counting is a fundamental while challenging computer vision task, as it requires the object appearance information as well as semantic understanding of the object. In this paper, we propose an end-to-end multi-context embedding deep network for object counting(MCENet), which observes the object counting task from the three different perspectives to count the number of vehicles in the traffic video frame, or to estimate the number of the pedestrian in the largely congested scene. The first sub-network of MCENet extracts the potential features for the appearance context and the semantic context from different-level layers. The two different-level features from the first sub-network are transferred into the two parallel and complementary sub-networks, which are used to model the appearance context and semantic context for final counting. And thus the multiple contexts are represented and embedded to assist the counting task. Extensive experimental evaluations are reported in this paper, using up to three different object counting benchmarks, which show the proposed approach achieves a competitive performance in all these heterogeneous scenarios. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105927	10.1016/j.knosys.2020.105927													
J								Fuzzy clustering based on feature weights for multivariate time series	KNOWLEDGE-BASED SYSTEMS										Multivariate time series; Fuzzy clustering; Feature weight; Data mining	SEARCH; MODEL	As an important set of techniques for data mining, time series clustering methods had been studied by many researchers. Although most existing solutions largely focus on univariate time series clustering, there has been a surge in interest in the clustering of multivariate time series data. In this paper, a feature-weighted clustering method is proposed based on two distance measurement methods called dynamic time warping (DTW) and shape-based distance (SDB). There are four stages in the proposed clustering algorithm. First, we pick cluster centers by the pop clustering method called clustering by fast search and find of density peaks (DPC). Next, by considering the overall matching of multivariate time series, a fuzzy membership matrix is generated by performing DTW on all variables. We then reconsider the contribution of each independent dimension by utilizing SBD to measure distances within each dimension and construct multiple fuzzy membership matrices. Finally, we utilize a traditional fuzzy clustering algorithm called fuzzy c-means to cluster the fuzzy membership matrices and generate clustering results. Simultaneously, a feature weight calculation method and novel equation for constructing fuzzy membership matrices are applied during the clustering process. We compare the proposed method to other clustering methods and the results indicate that the proposed method can improve clustering accuracy for multivariate time series datasets. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105907	10.1016/j.knosys.2020.105907													
J								An effective framework based on local cores for self-labeled semi-supervised classification	KNOWLEDGE-BASED SYSTEMS										Semi-supervised learning (SSL); Semi-supervised classification (SSC); Self-labeled; Local cores; Natural neighbors	NEIGHBOR; IMPROVE; SEARCH	Semi-supervised self-labeled methods apply unlabeled data to improve the performance of classifiers which are trained by labeled data alone. Nevertheless, applying unlabeled data may deteriorate the prediction accuracy. One of the causes is that there are insufficient labeled data for training an initial classifier in self-labeled methods. However, existing solutions for this problem of lacking sufficient initial labeled data still have technical defects. For example, they fail to deal with non-spherical data and improve insufficient initial labeled data effectively, when initial labeled data are extremely scarce. In this paper, we propose an effective semi-supervised self-labeled framework based on local cores, aiming to solve the problem of lacking adequate initial labeled data in self-labeled methods and overcome existing technical defects above. Main ideas of our framework include two sides: (a) inadequate initial labeled data are improved by adding predicted local cores to them, where local cores are predicted by active labeling or co-labeling; (b) we use any semi-supervised self-labeled method to train a given classifier on improved labeled data and updated unlabeled data. In our framework, local cores roughly reveal the data distribution, which helps the proposed framework work on spherical or non-spherical data sets. In addition, local cores also help our framework improve insufficient initial labeled data effectively, even when initial labeled data are extremely scarce. Experiments show that the proposed framework is compatible with tested self-labeled methods, and can help self-labeled methods train a k nearest neighbor or support vector machine, when initial labeled data are insufficient. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105804	10.1016/j.knosys.2020.105804													
J								Data alignments in machinery remaining useful life prediction using deep adversarial neural networks	KNOWLEDGE-BASED SYSTEMS										Remaining useful life prediction; Rotating machines; Deep learning; Adversarial training; Data alignment	INTELLIGENT FAULT-DIAGNOSIS; PROGNOSTICS; BEARINGS; FUZZY; PERFORMANCE	Recently, intelligent data-driven machinery prognostics and health management have been attracting increasing attention due to the great merits of high accuracy, fast response and easy implementation. While promising prognostic performance has been achieved, the first predicting time for remaining useful life is generally difficult to be determined, and the data distribution discrepancy between different machines is mostly ignored, which leads to deterioration in prognostics. In this paper, a deep learning-based prognostic method is proposed to address the problems. Generative adversarial networks are used to learn the distributions of data in machine healthy states, and a health indicator is proposed to determine the first predicting time. Afterwards, adversarial training is further introduced to achieve data alignments of different machine entities in order to extract generalized prognostic knowledge. Experiments of remaining useful life prediction on two rotating machinery datasets are implemented, and the promising prognostic results validate the effectiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105843	10.1016/j.knosys.2020.105843													
J								Document-level multi-topic sentiment classification of Email data with BiLSTM and data augmentation	KNOWLEDGE-BASED SYSTEMS										Sentiment classification; Email sentiment; Multi-topic sentiment; Bidirectional LSTM; Data augmentation		Email data has unique characteristics, involving multiple topics, lengthy replies, formal language, high variance in length, high duplication, anomalies, and indirect relationships that distinguish it from other social media data. In order to better model Email documents and to capture complex sentiment structures in the content, we develop a framework for document-level multi-topic sentiment classification of Email data. Note that, a large volume of labeled Email data is rarely publicly available. We introduce an optional data augmentation process to increase the size of datasets with synthetically labeled data to reduce the probability of overfitting and underfitting during the training process. To generate segments with topic embeddings and topic weighting vectors as inputs for our proposed model, we apply both latent Dirichlet allocation topic modeling and semantic text segmentation to post-process Email documents. Empirical results obtained with multiple sets of experiments, including performance comparison against various state-of-the-art algorithms with and without data augmentation and diverse parameter settings, are analyzed to demonstrate the effectiveness of our proposed framework. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105918	10.1016/j.knosys.2020.105918													
J								Enhancing QUasi-Affine TRansformation Evolution (QUATRE) with adaptation scheme on numerical optimization	KNOWLEDGE-BASED SYSTEMS										Adaptation scheme; Stochastic algorithm; Numerical optimization; QUATRE structure	PARTICLE SWARM OPTIMIZER; DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION; ALGORITHM; PARAMETERS; CROSSOVER	Optimization problems exists extensively in real life, especially in science and engineering. Over the past decades, various optimization techniques have been developed to solve complex optimization problems in different areas especially that are unable to be solved by traditional methods. QUasi-Affine TRansformation Evolutionary (QUATRE) algorithm is a new novel evolution structure for global optimization, which is a swarm based algorithm and use quasi-affine transformation approach for evolution. Nevertheless, there are still some weaknesses in these QUATRE variants. This paper presents a novel E-QUATRE algorithm in which an automatically generated evolution matrix with self-adaptive mechanism and an adaptive control parameter F are proposed for the enhancement of the QUATRE algorithm. Moreover, this paper also discusses the relationship between QUATRE algorithm, Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithm, all of which are also famous swarm based Stochastic Algorithms (SAs). Algorithm validation is conducted under CEC2013 test suite on single-objective numerical optimization, and E-QUATRE algorithm is compared with several famous Particle Swarm Optimization (PSO) variants, Differential Evolution (DE) variants and QUATRE variants. The experiment results indicate that the proposed E-QUATRE algorithm has a better performance than these swarm based algorithms with fixed population. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105908	10.1016/j.knosys.2020.105908													
J								Feature selection with limited bit depth mutual information for portable embedded systems	KNOWLEDGE-BASED SYSTEMS										Reduced precision; Mutual information; Feature selection; Portable embedded systems; Internet of things; Edge computing		Since wearable computing systems have grown in importance in the last years, there is an increased interest in implementing machine learning algorithms with reduced precision parameters/computations. Not only learning, also feature selection, most of the times a mandatory preprocessing step in machine learning, is often constrained by the available computational resources. This work considers mutual information - one of the most common measures of dependence used in feature selection algorithms - with a limited number of bits. In order to test the procedure designed, we have implemented it in several well-known feature selection algorithms. Experimental results over several synthetic and real datasets demonstrate that low bit representations are sufficient to achieve performances close to that of double precision parameters and thus open the door for the use of feature selection in embedded platforms that minimize the energy consumption and carbon emissions. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105885	10.1016/j.knosys.2020.105885													
J								BCV-Predictor: A bug count vector predictor of a successive version of the software system	KNOWLEDGE-BASED SYSTEMS										Number of bugs prediction; Bug count vector; Deep learning; Regression; Long short term memory (LSTM)	DEFECT PREDICTION; NEURAL-NETWORKS; MODELS; IMBALANCE; NUMBER	Predicting the number of bugs in a software system intensifies the software quality and turns down the testing effort required in software development. It reduces the overall cost of software development. The evolution of hardware, platform, and user requirements leads to develop the next version of a software system. In this article, we formulate a problem and its novel solution, i.e., we are considering the prediction of the bug count vector of a successive version of a software system. After predicting the bug count vector in the next version of a software, the developer team leader can adequately allocate the developers in respective fault dense modules, in a more faulty dense module, more number of developers required. We have conducted our experiment over seven PROMISE repository datasets of different versions. We build metadata using a concatenation of different versions of the same software system for conducting experiments. We proposed a novel architecture using deep learning called BCV-Predictor. BCV-Predictor predicts the bug count vector of the next version software system; it is trained using metadata. To the best of our knowledge, no such work has been done in these aspects. We also address overfitting and class imbalance problem using random oversampling method and dropout regularization techniques. We conclude that BCV-Predictor is conducive to predicting the bug count vector of the next version of the software. We found five out of seven meta datasets reaches to more than 80% accuracy. In all seven meta datasets, Mean Squared Error (MSE) lies from 0.71 to 4.715, Mean Absolute Error (MAE) lies from 0.22 to 1.679, MSE and MAE over validation set lie between 0.84 to 4.865, and 0.22 to 1.709 respectively. We also compared the performance of BCV-Predictor with eleven baselines techniques and found the proposed approach outperform on most of the meta-datasets. (C) 2020 Published by Elsevier B.V.																	0950-7051	1872-7409				JUN 7	2020	197								105924	10.1016/j.knosys.2020.105924													
J								Weakly supervised learning for image keypoint matching using graph convolutional networks	KNOWLEDGE-BASED SYSTEMS										Feature matching; Keypoints; Mismatch removal; Deep neural networks	CONSENSUS	Matching between two sets of features from a pair of images is a fundamental and critical step in most computer vision tasks. Existing attempts typically establish a set of putative correspondences with the nearest-neighbor rule in feature spaces and then try to find a subset of reliable matches. However, when there are large camera angles, repetitive structures, and illumination changes existing in the two images of the same scene, recently proposed feature matching approaches do not work well to find good correspondences, especially with a higher proportion of false-positive matches in the putative set. To address these problems, we propose a novel weakly supervised Graph Convolutional Siamese Network Matcher, called GCSNMatcher, to learn the correct correspondences for image feature matching. In particular, GCSNMatcher can directly work on unstructured keypoint sets and further exploit geometric information among sparse interest points by constructing dynamic neighborhood graph structures to enhance the ability of the feature representation of each keypoint. With channelwised symmetric aggregation operations in our graph convolutional neural networks, the performance of our matcher does not vary under different permutations of unordered keypoint sets. Empirical studies on Yahoo's YFCC100M benchmark dataset demonstrate that our matcher can give a more robust performance for image matching tasks than those state-of-the-art methods, even when it is trained on small datasets. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105871	10.1016/j.knosys.2020.105871													
J								Deep multiplex graph infomax: Attentive multiplex network embedding using global information	KNOWLEDGE-BASED SYSTEMS										Network embedding; Multiplex network; Infomax principle		Network embedding has recently garnered attention due to the ubiquity of the networked data in the real-world. A network is useful for representing the relationships among objects, and these network include social network, publication network, and protein-protein interaction network. Most existing network embedding methods assume that only a single type of relation exists between nodes. However, we focus on the fact that two nodes in a network can be connected by multiple types of relations; such a network is called multi-view network or multiplex network. Although several existing work consider the multiplexity of a network, they overlook node attributes, resort to node labels for training, and fail to model the global properties of a graph. In this work, we present an unsupervised network embedding method for attributed multiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that maximizes the mutual information between local patches of a graph, and the global representation of the entire graph. Building on top of DGI, we devise a systematic way to jointly integrate the node embeddings from multiple graphs by introducing (1) the consensus regularization framework that minimizes the disagreements among the relation-type specific node embeddings, and (2) the universal discriminator that discriminates true samples regardless of the relation types. We also show that the attention mechanism infers the importance of each relation type, and thus can be useful for filtering unnecessary relation types as a preprocessing step. We perform comprehensive experiments not only on unsupervised downstream tasks, such as clustering and similarity search, but also a supervised downstream task, i.e., node classification, and demonstrate that DMGI outperforms the state-of-the-art methods, even though DMGI is fully unsupervised. The source code is can be found here https://github.com/pcy1302/DMCI. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105861	10.1016/j.knosys.2020.105861													
J								A multi-level fusion based decision support system for academic collaborator recommendation	KNOWLEDGE-BASED SYSTEMS										Collaborator recommendation; Meta-path analysis; Random walk with restart (RWR); Topic modeling; Rank-based fusion; LSTM model	ARTICLE RECOMMENDATION; SOCIAL NETWORK; INFORMATION; EVOLUTION; DESIGN	In academia, researchers collaborate with their peers to improve the quality of research and thereby enhance academic profiles. However, information overload in big scholarly data poses a challenge in identifying potential researchers for fruitful collaboration. In this article, we introduce a multi-level fusion-based model for collaborator recommendation, DRACoR (Deep learning and Random walk based Academic Collaborator Recommender). DRACoR fuses deep learning and biased random walk model to provide the recommendation for potential collaborators that share similar research interests at the peer level. We run a topic model on abstracts and Doc2Vec on titles on year-wise publications to capture the dynamic research interests of researchers. Author-author cosine similarity is computed from the feature vectors extracted from abstracts and titles and is then used to weigh edges in the author-author graph (AAG). We also aggregate various meta-path features with profile-aware features to bias the random walk behavior. Finally, we employ a random walk with restart(RWR) to recommend top N collaborators where the edge weights are used to bias the random walker's behavior. Extensive experiments on DBLP and hep-th datasets demonstrate the effectiveness of our proposed DRACoR model against various state-of-the-art methods in terms of precision, recall, F1-score, MRR, and nDCG. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105784	10.1016/j.knosys.2020.105784													
J								Deep density-based image clustering	KNOWLEDGE-BASED SYSTEMS										Deep clustering; Density-based clustering; Feature learning	FAST SEARCH; ALGORITHM	Recently, deep clustering, which is able to perform feature learning that favors clustering tasks via deep neural networks, has achieved remarkable performance in image clustering applications. However, the existing deep clustering algorithms generally need the number of clusters in advance, which is usually unknown in real-world tasks. In addition, the initial cluster centers in the learned feature space are generated by k-means. This only works well on spherical clusters and probably leads to unstable clustering results. In this paper, we propose a two-stage deep density-based image clustering (DDC) framework to address these issues. The first stage is to train a deep convolutional autoencoder (CAE) to extract low-dimensional feature representations from high-dimensional image data, and then apply t-SNE to further reduce the data to a 2-dimensional space favoring density-based clustering algorithms. In the second stage, we propose a novel density-based clustering technique for the 2-dimensional embedded data to automatically recognize an appropriate number of clusters with arbitrary shapes. Concretely, a number of local clusters are generated to capture the local structures of clusters, and then are merged via their density relationship to form the final clustering result. Experiments demonstrate that the proposed DDC achieves comparable or even better clustering performance than state-of-the-art deep clustering methods, even though the number of clusters is not given. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105841	10.1016/j.knosys.2020.105841													
J								Identifying legitimate Web users and bots with different traffic profiles - an Information Bottleneck approach	KNOWLEDGE-BASED SYSTEMS										Web user; Web bot; Internet robot; Bot detection; Machine learning; Unsupervised learning	ROBOT DETECTION; DISCOVERY	Recent studies reported that about half of Web users nowadays are intelligent agents (Web bots). Many bots are impersonators operating at a very high sophistication level, trying to emulate navigational behaviors of legitimate users (humans). Moreover, bot technology continues to evolve which makes bot detection even harder. To deal with this problem, many advanced methods for differentiating bots from humans have been proposed, a large part of which relies on supervised machine learning techniques. In this paper, we propose a novel approach to identify various profiles of bots and humans which combines feature selection and unsupervised learning of HTTP-level traffic patterns to develop a user session classification model. Session clustering is performed with the agglomerative Information Bottleneck (aIB) algorithm, as well as with some other reference algorithms. The model is then used to classify new sessions to one of the profiles and to label the sessions as performed by bots or humans. An extensive experimental study, based on real server log data, demonstrates the ability of aIB clustering to distinguish user profiles and confirms high performance of the classification model in terms of accuracy, F1, recall, and precision. (C) 2020 The Authors. Published by Elsevier B.V.																	0950-7051	1872-7409				JUN 7	2020	197								105875	10.1016/j.knosys.2020.105875													
J								ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition	KNOWLEDGE-BASED SYSTEMS										Named entity recognition; Deep neural network; Gated-CNN; Adversarial training		Named Entity Recognition (NER) is a challenging task that extracts named entities from unstructured text data, including news, articles, social comments, etc. The NER system has been studied for decades. Recently, the development of Deep Neural Networks and the progress of pre-trained word embedding have become a driving force for NER. Under such circumstances, how to make full use of the information extracted by word embedding requires more in-depth research. In this paper, we propose an Adversarial Trained LSTM-CNN (ASTRAL) system to improve the current NER method from both the model structure and the training process. In order to make use of the spatial information between adjacent words, Gated-CNN is introduced to fuse the information of adjacent words. Besides, a specific Adversarial training method is proposed to deal with the overfitting problem in NER. We add perturbation to variables in the network during the training process, making the variables more diverse, improving the generalization and robustness of the model. Our model is evaluated on three benchmarks, CoNLL-03, OntoNotes 5.0, and WNUT-17, achieving state-of-the-art results. Ablation study and case study also show that our system can converge faster and is less prone to overfitting. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105842	10.1016/j.knosys.2020.105842													
J								ADRL: An attention-based deep reinforcement learning framework for knowledge graph reasoning	KNOWLEDGE-BASED SYSTEMS										Knowledge graph; Knowledge reasoning; Reinforcement learning; Deep learning; Attention	GAME; GO	Knowledge graph reasoning is one of the key technologies for knowledge graph construction, which plays an important part in application scenarios such as vertical search and intelligent question answering. It is intended to infer the desired entity from the entities and relations that already exist in the knowledge graph. Most current methods for reasoning, such as embedding-based methods, globally embed all entities and relations, and then use the similarity of vectors to infer relations between entities or whether given triples are true. However, in real application scenarios, we require a clear and interpretable target entity as the output answer. In this paper, we propose a novel attention-based deep reinforcement learning framework (ADRL) for learning multi-hop relational paths, which improves the efficiency, generalization capacity, and interpretability of conventional approaches through the structured perception of deep learning and relational reasoning of reinforcement learning. We define the entire process of reasoning as a Markov decision process. First, we employ CNN to map the knowledge graph to a low-dimensional space, and a message-passing mechanism to sense neighbor entities at each level, and then employ LSTM to memorize and generate a sequence of historical trajectories to form a policy and value functions. We design a relational module that includes a self-attention mechanism that can infer and share the weights of neighborhood entity vectors and relation vectors. Finally, we employ the actor-critic algorithm to optimize the entire framework. Experiments confirm the effectiveness and efficiency of our method on several benchmark data sets. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105910	10.1016/j.knosys.2020.105910													
J								Predicting hypoglycemic drugs of type 2 diabetes based on weighted rank support vector machine	KNOWLEDGE-BASED SYSTEMS										Multi-label learning; Weighted rank support vector machine; Type 2 diabetes; Hypoglycemic drugs; Therapeutic schemes	LEARNING APPROACH; CLASSIFICATION; SYSTEM	Diabetes has become a disease that seriously endangers people's health, then how to control the content of glycemic is an important issue. Since the treatment scheme of patient is usually a combination of multiple hypoglycemic drugs, multi-label learning is an effective method to solve this problem. By analyzing the type 2 diabetes data set including 2443 diabetics provided by the Chinese People's Liberation Army General Hospital, we find that the defined daily dose system (DDDs) of drugs is an imbalanced problem, traditional multi-label methods easily leads to poor prediction results. In order to overcome the shortcoming, a weighted rank support vector machine (WRankSVM) is proposed in this paper. We firstly define the weight of each label and then give each sample different weight according to relevant-irrelevant label pair. This method ensures that the prediction results on drugs with higher DDDs are as accurate as possible. Compared with the other six popular multi-label methods, our WRank-SVM can effectively predict the schemes for hypoglycemic drugs of type 2 diabetes. Meanwhile, receiver operating characteristic (ROC) curve is employed to statistically show the effectiveness of the model. Finally, the correlation between labels and features is further analyzed, and 13 important features are selected to improve the average precision of our proposed algorithm. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105868	10.1016/j.knosys.2020.105868													
J								Robust active contours driven by order-statistic filtering energy for fast image segmentation	KNOWLEDGE-BASED SYSTEMS										Image segmentation; Active contour model; Level set method; Order-statistic filtering energy; Edge force function	FITTING ENERGY; MODEL-DRIVEN; ALGORITHMS; LAPLACIAN; EVOLUTION	In this paper, a robust active contour model driven by order-statistic filtering (OSF) energy is proposed for fast image segmentation. The main idea of the order-statistic filtering energy is to construct the edge force function (EFF) to quickly and adaptively attract curves to evolve towards the boundaries of targets. Besides, because the EFF is computed before iterations, therefore, segmentation speed of the OSF model improves greatly. Furthermore, an optimized regularization term and an optimized length term are used in the OSF model to replace the traditional penalty and length term, respectively. Experiments on some synthetic and real images show that the OSF model can segment images with intensity inhomogeneity quickly and precisely. In addition, several experiments also show that the OSF model is robust to initial contour and parameters. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105882	10.1016/j.knosys.2020.105882													
J								Construction of three-way attribute partial order structure via cognitive science and granular computing	KNOWLEDGE-BASED SYSTEMS										Partial order structure; Concept cognitive learning; Three-way decision; Granular computing; Cognitive science; Artificial intelligence	CONCEPT LATTICES; DECISION; MODEL; INFORMATICS; ACQUISITION; REDUCTION	Partial order formal structure analysis (POFSA), as an emerging model of concept cognitive learning, has been extensively used in the field of knowledge processing. However, along with the development of information storage and network technology, the knowledge that people can master is growing dramatically, and it is difficult to effectively process the expanding knowledge just through one single theory. Therefore, this paper explores the construction method of a three-way attribute partial order structure (APOS) via multi granularity by incorporating the ideas of three-way decision (3WD) and granular computing (GrC) into the theory of POFSA. First, for a specific formal context, by taking object set as the whole domain and using attributes and their respective extensions to constitute granule, granular layers can be formed based on the binary relations of equivalence or compatibility between granules. Then, according to the partial order relations between the granules of different granular layers, the corresponding granular structure APOS can be generated. Finally, using the idea of 3WD to reasonably eliminate the cross connections between different branches of APOS, a three-way APOS via multi granularity can be constructed. In addition, based on the generation algorithm of the three-way APOS, the knowledge processing of several data sets from UCI have been conducted and discussed. Through discussion and experiment, it can be concluded that, the three-way APOS via multi granularity can not only improve the efficiency of knowledge processing, but also make the results of knowledge processing more reasonable. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105859	10.1016/j.knosys.2020.105859													
J								Fractional-order calculus-based flower pollination algorithm with local search for global optimization and image segmentation	KNOWLEDGE-BASED SYSTEMS										Flower pollination algorithm; Local search; Meta-heuristic; Image segmentation; Fractional calculus; Optimization; Algorithm; Benchmark	PARTICLE SWARM OPTIMIZATION	Introducing a novel approach to enhance the diversification and intensification propensities of the flower pollination algorithm (FPA) is the main aim of this paper. Therefore, the fractional-order (FO) calculus features are adopted to enhance the basic FPA local search ability and adaptive modify the harmonization coefficient among the FPA exploration and exploitation cores. The proposed Fractional-order FPA (FO-FPA) is examined in a number of experiments. Firstly, FO-FPA is tested with thirty-six benchmark functions with several dimensions. The proposed FO-FPA is compared with recent proved techniques based on several statistical measures and non parametric tests. Secondly, FO-FPA is implemented for a real application of the image segmentation and its results compared with state-of-the-art multi-level thresholding algorithms. The comparisons divulge the remarkable influence of merging FO with the basic FPA in improving the quality of the solutions and the acceleration of the convergence speed. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105889	10.1016/j.knosys.2020.105889													
J								Knowledge extraction and insertion to deep belief network for gearbox fault diagnosis	KNOWLEDGE-BASED SYSTEMS										Gearbox fault diagnosis; Deep learning; Deep belief network; Knowledge discovery; Feature learning	CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; AUTOENCODERS; OPTIMIZATION; TRANSFORM; ALGORITHM	Deep neural network (DNN) with a complex structure and multiple nonlinear processing units has achieved great success for feature learning in machinery fault diagnosis. Due to the "black box" problem in DNNs, there are still many obstacles to the application of DNNs in fault diagnosis. This paper proposes a new DNN model, knowledge-based deep belief network (KBDBN), which inserts confidence and classification rules into the deep network structure. This not only enables the model to have good pattern recognition performance but also to adaptively determine the network structure and obtain a good understanding of the features learned by the deep network. The knowledge extraction algorithm is proposed to offer a good representation of layerwise networks (i.e., restricted Boltzmann machines (RBMs)). The layerwise extraction can produce an improvement in feature learning of RBMs. Moreover, the extracted confidence rules that characterize the deep network offers a novel method for insertion of prior knowledge in the deep RBM. The classification knowledge extracted from the data is further inserted into the classification layer of DBN. KBDBN is used to generate the discriminant features from the data and then construct a complex mapping between vibration signals and gearbox defects. The testing results of KBDBN on a gearbox test rig not only effectively extracts knowledge from the deep network, but also shows better classification performance than the typical classifiers and DBNs. Moreover, the interpretable network model helps us understand what DBN has learned from vibration signals and then makes it be applied easily in real-world cases. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105883	10.1016/j.knosys.2020.105883													
J								Aeronautical relay health state assessment model based on belief rule base with attribute reliability	KNOWLEDGE-BASED SYSTEMS										Health state assessment; Aeronautical relay; Sensitivity analysis; Belief rule base (BRB); Attribute reliability	EVIDENTIAL REASONING APPROACH; SENSITIVITY-ANALYSIS; FAULT-TREE; INFERENCE; SYSTEMS; METHODOLOGY	Health state assessment is a key issue in health management of aeronautical relay subject to complex interference environment. The input reliability of assessment model has direct connection with the assessment result and the reliability of the assessment model. Due to the limitation of resources and monitoring technology, it is impossible to simultaneously improve the reliabilities of all the characteristics. Thus, some important characteristics should be sorted by the role they play in the assessment model. Implementing the quantitatively analysis of the influence of the input reliability can provide guidance. The belief rule base model with attribute reliability (BRB-r) provides such a modeling framework and analysis method. It is one of the expert systems that can aggregate unreliable quantitative data and expert knowledge and has traceability between the model input and output. Thus, in this paper, a new health state assessment model based on BRB-r for aeronautical relay is developed for the first time where the calculation method of model reliability is further developed. Then, to quantitatively analyze the effectiveness of the input reliability on the model output and the model reliability, the sensitivity analysis of attribute reliability is deduced based on the first-order local sensitivity method. The obtained sensitivity coefficient of attribute reliability represents its effectiveness on the constructed health state assessment model and can provide guidance in health management for aeronautical relay under limited resource. A case study of health sate estimation of the JRC-7M aeronautical relay is conducted to illustrate the application of the new model. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				JUN 7	2020	197								105869	10.1016/j.knosys.2020.105869													
J								Visual sensor intelligent module based image transmission in industrial manufacturing for monitoring and manipulation problems	JOURNAL OF INTELLIGENT MANUFACTURING										Intelligent module smart system; Data transmission; Data compression intelligent sensor; Visual sensing automation; Coding; Regression	INTERNET	Due to technology advancement, smart visual sensing required in terms of data transfer capacity, energy-efficiency, security, and computational-efficiency. The high-quality image transmission in visual sensor networks (VSNs) consumes more space, energy, transmission delay which may experience the various security threats. Image compression is a key phase of visual sensing systems that needs to be effective. This motivates us to propose a fast and efficient intelligent image transmission module to achieve the energy-efficiency, minimum delay, and bandwidth utilization. Compressive sensing (CS) introduced to speedily compressed the image to reduces the consumption of energy, time minimization, and efficient bandwidth utilization. However, CS cannot achieve security against the different kinds of threats. Several methods introduced since the last decade to address the security challenges in the CS domain, but efficiency is a key requirement considering the intelligent manufacturing of VSNs. Furthermore, the random variables selected for the CS having the problem of recovering the image quality due to the accumulation of noise. Thus concerning the above challenges, this paper introduced a novel one-way image transmission module in multiple input multiple output that provides secure and energy-efficient with the CS model. The secured transmission in the CS domain proposed using the security matrix which is called a compressed secured matrix and perfect reconstruction with the random matrix measurement in the CS. Experimental results outwards that the intelligent module provides energy-efficient, secured transmission with low computational time as well as a reduced bit error rate.																	0956-5515	1572-8145															10.1007/s10845-020-01590-1		JUN 2020											
J								Is position important? deep multi-task learning for aspect-based sentiment analysis	APPLIED INTELLIGENCE										Aspect-based sentiment analysis; Multi-task; Deep learning; Position	ALGORITHM	The position information of aspect is essential and useful for aspect-based sentiment analysis, while how to model the position of the aspect effectively during aspect-based sentiment analysis has not been well studied. Inspired by the intuition that the position prediction can help boost the performance of aspect-based sentiment analysis, we propose a D eep M ulti-T ask L earning (DMTL) model, which handles sentiment prediction (SP) and position prediction (PP) simultaneously. In particular, we first use a shared layer to learn the common features of the two tasks. Then, two task-specific layers are utilized to learn the features specific to the tasks and perform position prediction and sentiment prediction in parallel. Inspired by autoencoder structure, we design a position-aware attention and a deep bi-directional LSTM (DBi-LSTM) model for sentiment prediction and position prediction respectively to capture the position information better. Extensive experiments on four benchmark datasets show that our approach can effectively improve the performance of aspect-based sentiment analysis compared with the strong baselines.																	0924-669X	1573-7497				OCT	2020	50	10					3367	3378		10.1007/s10489-020-01760-x		JUN 2020											
J								Two-level fusion big data compression and reconstruction framework combining second-generation wavelet and lossless compression	COMPLEX & INTELLIGENT SYSTEMS										Large-scale fuzzy information system; Data compression and reconstruction; Second-generation wavelet; Lossless compression and reconstruction; Two-level fusion framework; Aircraft health management	LIFTING SCHEME; CONSTRUCTION; TRANSFORM; SYSTEM	In view of the characteristics of big data, fuzziness, and real time of data acquisition and transmission in the fuzzy information system faced by aircraft health management, to reduce the load of airborne data processing and transmission system under the condition of limited airborne computing resources and strong time constraints, the data collected by the airborne system are first compressed, and the amount of data are reduced before transmission and reconstructed after transmission. In view of the situation that the compression ratio of primary data compression is too small and the compression time is too long for large-scale fuzzy systems to meet the transmission requirements of the system, this paper combines the advantages of lossy compression method which consumes less time and lossless compression method which has higher compression ratio, and innovatively proposes a two-level data compression and reconstruction framework combining lossy compression and lossless compression. The optimization analysis is carried out. Taking a real aero-engine health sample as an example, the validity, scientificity, and robustness of the proposed framework are verified by comparing with data compression and reconstruction algorithm based on redundant sparse representation and compressed sensing.																	2199-4536	2198-6053				OCT	2020	6	3					607	620		10.1007/s40747-020-00158-z		JUN 2020											
J								Investigation of rotated local Gabor features in face recognition using fusion techniques	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Rotated local gabor XOR patterns (RLGXP); Local XOR pattern (LXP); Cell-based Fisher's linear discriminant (CFLD); Facial feature points (FFP); Face recognition accuracy; Precision; Recall; Score level fusion; Feature level fusion	BINARY PATTERNS; PCA	One of the major challenges related to face recognition is the effective face representation. In this paper, a new rotation algorithm is proposed to make the slanting face to upright position. Gabor features have been identified to be effective for face recognition. To investigate the prospective of Gabor phase and its combination with magnitude for face recognition, Rotated Local Gabor XOR patterns (RLGXP), which encodes the Rotated Gabor phase by using the local XOR pattern (LXP) operator is first proposed, which increases the effectiveness of face representation. Then, Cell-based Fishers linear discriminant (CFLD) to reduce the dimensionality of the proposed descriptor is introduced. Finally, by using CFLD, local patterns of Rotated Gabor magnitude and phase for face recognition are combined. This proposed approach is evaluated on MIT, GTAVE, PIE, CMU and Home databases. Moreover, to enhance the effectiveness of face representation through feature design (RLGXP), the Gabor filter parameters like mask size, scale and orientation are very important. The effectiveness of the rotating local Gabor model + CFLD method was verified for upslopes and uprights of different data sets. The analysis of face feature representation using the RLGXP + CFLD method basically depends on the phase range, the appropriate choice of the number of sub-cells per pattern map and size of neasret region. Here, the sensitivity analysis used for the above three parameters is best selected and executed. This paper also investigates the effect of different Gabor filter parameters on face recognition accuracy. Parameter Selection Investigation result proves that Gabor wavelets comprising 5 scales and 8 orientations have been chosen to extract Facial Feature Points (FFP). The final result shows that Rotated Local Gabor Features provides the best face recognition accuracy.																	1868-5137	1868-5145															10.1007/s12652-020-02134-4		JUN 2020											
J								An automated neural network based technique for identifying fundus hemorrhage (NNTFH)	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Data mining; Image processing; Machine learning; Neural network	CLASSIFICATION; BLINDNESS	Retina, the thin membranous tissue layer occupying the back of human eyes, provides vision to humans. As the age of a person increases the eyes may encounter a secondary growth, creating impairments in vision. Human eyes are prone to several diseases like retinal detachment or tear, glaucoma, macular degeneration or hole, diabetic retinopathy etc., where identifying retinal diseases at an early stage is necessary. The increasing number of eye affected patients and effective diagnosis imposes a challenge on the clinical routines of treatment and monitoring after diagnosis. It is possible to diagnose eye diseases from retinal images with the help of machine learning techniques. This paper proposes a novel technique called NNTFH which is an automated neural network based technique for identifying hemorrhage of the eyes from Eye images. The initial phase of NNTFH, selects the pixel count and density from medical eye images and then classifies impaired eyes where it uses a neural network model. The retinal images are classified as normal or with exudates or eyes with Hemorrhage.																	1868-5137	1868-5145															10.1007/s12652-020-02168-8		JUN 2020											
J								Hybrid convolutional neural network (CNN) and long-short term memory (LSTM) based deep learning model for detecting shilling attack in the social-aware network	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Shilling attack; Deep learning model; Recommender systems; User profiles; User ratings; Convolutional neural network (CNN); Long-short term memory (LSTM)		In social aware network (SAN) paradigm, the fundamental activities concentrate on exploring the behavior and attributes of the users. This investigation of user characteristic aids in the design of highly efficient and suitable protocols. In particular, the shilling attack introduces a high degree of vulnerability into the recommender systems. The shilling attackers use the reviews, user ratings and forged user generated content data for the computation of recommendation rankings. The detection of shilling attack in recommender systems is considered to be essential for sustaining their fairness and reliability. In specific, the collaborative filtering strategies utilized for detecting shilling attackers through efficient user behavior mining are considered as the predominant methodologies in the literature. In this paper, a hybrid convolutional neural network (CNN) and long-short term memory (LSTM)-based deep learning model (CNN-LSTM) is proposed for detecting shilling attack in recommender systems. This deep learning model utilizes the transformed network architecture for exploiting the deep-level attributes derived from user rated profiles. It overcomes the limitations of the existing shilling attack detection methods which mostly focuses on identifying spam users by designing features artificially in order to enhance their efficiency and robustness. It is also potent in elucidating deep-level features for efficiently detecting shilling attacks by accurately elaborating the user ratings. The experimental results confirmed the significance of the proposed CNN-LSTM approach by accurately detecting most of the obfuscated attacks compared to the state-of-art algorithms used for investigation.																	1868-5137	1868-5145															10.1007/s12652-020-02164-y		JUN 2020											
J								Content-Based Document Image Retrieval Based on Document Modeling	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Document modeling; Language model; Document image retrieval; Multinomial distribution; N-gram model		Recently, language models have gained importance in the field of information retrieval. In this paper, we propose a generic language model to improve a content-based document retrieval system. In this approach, character images are extracted, clustered, and analyzed to form high-level semantic terms using a statistical document model. This model simulates the long-term relationships between characters. Documents are then indexed according to these terms, and a query document is proposed to retrieve the relevant documents. The query document can be a single keyword, or it can be synthesized from a text string. The aim is to generate a semantic representation from low-level image pixels through pattern matching and document modeling. The conventional approach of generating semantic terms in document retrieval includes every possible symbol sequence in the feature representation. Comparatively, our approach can considerably reduce the dimensions of the feature space while producing retrieval results comparable to those of the conventional and state-of-the-art approaches.																	0925-9902	1573-7675				OCT	2020	55	2					287	306		10.1007/s10844-020-00600-1		JUN 2020											
J								Identification and Modeling of the Airbrake of an Experimental Unmanned Aircraft	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Aircraft airbrake; Dynamic test bench; System identification; Simulation; Flight test results		This paper presents the modeling, system identification, simulation and flight testing of the airbrake of an unmanned experimental aircraft in frame of the FLEXOP H2020 EU project. As the aircraft is equipped with a jet engine with slow response an airbrake is required to increase deceleration after speeding up the aircraft for flutter testing in order to remain inside the limited airspace granted by authorities for flight testing. The airbrake consists of a servo motor, an opening mechanism and the airbrake control surface itself. After briefly introducing the demonstrator aircraft, the airbrake design and the experimental test benches the article gives in depth description of the modeling and system identification referencing also previous work. System identification consists of the determination of the highly nonlinear (saturated and load dependent) servo actuator dynamics and the nonlinear aerodynamic and mechanical characteristics including stiffness and inertia effects. New contributions relative to the previous work are a unified servo angular velocity limit model considering opening against the load or closing with it, the detailed construction and evaluation of airbrake normal and drag force models considering the whole deflection and aircraft airspeed range, the presentation of a unified aerodynamic - mechanic nonlinearity model giving direct relation between airbrake angle, dynamic pressure and servo torque and the transfer function-based modeling of stiffness and inertial effects in the mechanism. The identified servo dynamical model includes system delay, inner saturation, the aforementioned load dependent angular velocity limit model and a transfer function model. The servo model was verified based-on test bench measurements considering the whole opening angle and dynamic load range of the airbrake. New, unpublished measurements with gradually increasing servo load as the servo moves are also considered to verify the model in more realistic circumstances. Then the full airbrake model is constructed and tested in simulation to check realistic behavior. In the next step the airbrake model integrated into the nonlinear simulation model of the FLEXOP aircraft is tested by flying simulated test trajectories with the baseline controller of the aircraft in software-in-the-loop (SIL) Matlab simulation. First, the standalone airbrake simulation is compared to the SIL results to verify flawless integration of airbrake model into the nonlinear aircraft simulation. Then deceleration times with and without airbrake are compared underlining the usefulness of the airbrake in the test mission. Finally, real flight data is used to verify and update the airbrake model and show the effectiveness of the airbrake.																	0921-0296	1573-0409				OCT	2020	100	1					259	287		10.1007/s10846-020-01204-1		JUN 2020											
J								On the Generalized Essential Matrix Correction: An Efficient Solution to the Problem and Its Applications	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Generalized essential matrix; General camera models; Pose estimation; Steepest descent type; Orthogonal constraints	POSE ESTIMATION; OPTIMIZATION; ALGORITHMS; GEOMETRY; CAMERAS	This paper addresses the problem of finding the closest generalized essential matrix from a given 6x6 matrix, with respect to the Frobenius norm. To the best of our knowledge, this nonlinear constrained optimization problem has not been addressed in the literature yet. Although it can be solved directly, it involves a large number of constraints, and any optimization method to solve it would require much computational effort. We start by deriving a couple of unconstrained formulations of the problem. After that, we convert the original problem into a new one, involving only orthogonal constraints, and propose an efficient algorithm of steepest descent type to find its solution. To test the algorithms, we evaluate the methods with synthetic data and conclude that the proposed steepest descent-type approach is much faster than the direct application of general optimization techniques to the original formulation with 33 constraints and to the unconstrained ones. To further motivate the relevance of our method, we apply it in two pose problems (relative and absolute) using synthetic and real data.																	0924-9907	1573-7683				OCT	2020	62	8					1107	1120		10.1007/s10851-020-00961-w		JUN 2020											
J								Multimodal, visuo-haptic games for abstract theory instruction: grabbing charged particles	JOURNAL ON MULTIMODAL USER INTERFACES										Haptics; Electromagnetism; Visuo-haptic user interface; Gamification; Computer simulation; Computer-based learning	EDUCATION	An extensive metamorphosis is currently taking place in the education industry due to the rapid adoption of different technologies and the proliferation of new student-instructor and student-student interaction models. While traditional face-to-face interaction is still the norm, mobile, online and virtual augmentations are increasingly adopted worldwide. Moreover, with the advent of gaming technology besides the 3D visual paradigm, the "touch" and "feel" paradigm is slowly taking its place in the user interface design through gamification. While haptic (force feedback) devices were barely available a decade ago outside research laboratories, the rapid rise in gaming technology has driven the cost significantly lower enabling the spread of these devices in many households and the wide public. This article presents a novel haptic-based training tool implemented as a gaming scenario to assist students in learning of abstract concepts in Physics. The focus is on electromagnetism as one of the fundamental forces in nature and specifically the abstractions used as building blocks around the Lorentz force. Experimental results suggest that by introducing well designed visual-haptic interfaces in presenting abstract concepts, students become better engaged in the classrooms and superior learning outcomes can be achieved.																	1783-7677	1783-8738															10.1007/s12193-020-00327-x		JUN 2020											
J								Quantitative Variants of Language Equations and their Applications to Description Logics Extending Unification in Description Logics	KUNSTLICHE INTELLIGENZ											AUTOMATA	Unification in description logics (DLs) has been introduced as a novel inference service that can be used to detect redundancies in ontologies, by finding different concepts that may potentially stand for the same intuitive notion. Together with the special case of matching, they were first investigated in detail for the DL FL0, where these problems can be reduced to solving certain language equations. In this thesis, we extend this service in two directions. In order to increase the recall of this method for finding redundancies, we introduce and investigate the notion of approximate unification, which basically finds pairs of concepts that "almost" unify, in order to account for potential small modelling errors. The meaning of "almost" is formalized using distance measures between concepts. We show that approximate unification in FL0 can be reduced to approximately solving language equations, and devise algorithms for solving the latter problem for particular distance measures. Furthermore, we make a first step towards integrating background knowledge, formulated in so-called TBoxes, by investigating the special case of matching in the presence of TBoxes of different forms. We acquire a tight complexity bound for the general case, while we prove that the problem becomes easier in a restricted setting. To achieve these bounds, we take advantage of an equivalence characterization of FL0 concepts that is based on formal languages. Even though our results on the approximate setting cannot deal with TBoxes yet, we prepare the framework that future research can build on.																	0933-1875	1610-1987				SEP	2020	34	3			SI		405	409		10.1007/s13218-020-00664-9		JUN 2020											
J								onto2problog: A Probabilistic Ontology-Mediated Querying System using Probabilistic Logic Programming	KUNSTLICHE INTELLIGENZ											COMPILATION; INFERENCE	We present onto2problog, a tool that supports ontology-mediated querying of probabilistic data via probabilistic logic programming engines. Our tool supports conjunctive queries on probabilistic data under ontologies encoded in the description logic ELHdr, thus capturing a large part of the OWL 2 EL profile.																	0933-1875	1610-1987															10.1007/s13218-020-00670-x		JUN 2020											
J								A novel content-based image retrieval approach for classification using GLCM features and texture fused LBP variants	NEURAL COMPUTING & APPLICATIONS										PSO; CBIR; Classification; Feature selection	LOCAL BINARY PATTERNS; SPOTTED HYENA OPTIMIZER; ALGORITHM; ADAPTATION; FACE	This paper presents a content-based image retrieval technique that focuses on extraction and reduction in multiple features. To obtain multi-level decomposition of the image by extracting approximation and correct coefficients, discrete wavelet transformation is applied to the RGB channels initially. Therefore, both approximation and correct coefficients are applied to the dominant rotated local binary pattern termed as texture descriptor which is computationally effective and rotationally invariant. For a local neighbor patch, a rotation invariance function image is obtained by measuring the descriptor relative to the reference. The proposed approach contains the complete structural information extracted from the local binary patterns and also extracts the additional information using the information of magnitude, thereby achieving extra discriminative power. Then, GLCM description is used by obtaining the dominant rotated local binary pattern image to extract the statistical characteristics for texture image classification. The proposed technique is applied to CORAL dataset with the help of particle swarm optimization-based feature selector to minimize the number of features that can be used during the classification process. The three classifiers, i.e., support vector machine, K-nearest neighbor, and decision tree, are trained and tested. The comparison is based in terms of Accuracy, precision, recall, and F-measure performance metrics for classification. Experimental results show that the proposed approach achieves better accuracy, precision, recall, and F-measure values for most of the CORAL dataset classes.																	0941-0643	1433-3058															10.1007/s00521-020-05017-z		JUN 2020											
J								A parametric recurrent neural network scheme for solving a class of fuzzy regression models with some real-world applications	SOFT COMPUTING										Fuzzy regression model; Fuzzy number; Recurrent neural network; Stability; Convergence	LEAST-SQUARES; NONLINEAR-REGRESSION; CONSUMPTION ESTIMATION; POLYNOMIAL REGRESSION; OPTIMIZATION PROBLEMS; PROGRAMMING-PROBLEMS; PERFORMANCE; COEFFICIENTS; ALGORITHM; FRAMEWORK	In this paper, a hybrid scheme based on recurrent neural networks for approximate fuzzy coefficients (parameters) of fuzzy linear and polynomial regression models with fuzzy output and crisp inputs is presented. Here, a neural network is first constructed based on some concepts of convex optimization and stability theory. The suggested neural network model guarantees to find the approximate parameters of the fuzzy regression problem. The existence and convergence of the trajectories of the neural network are studied. The Lyapunov stability for the neural network is also shown. Some illustrative examples provide a further demonstration of the effectiveness of the method.																	1432-7643	1433-7479				AUG	2020	24	15			SI		11159	11187		10.1007/s00500-020-05008-1		JUN 2020											
J								Response probability enhances robustness in decentralized threshold-based robotic swarms	SWARM INTELLIGENCE										Response probability; Response threshold; Redundancy; Robustness; Threshold-based systems; Decentralized task allocation; Swarm robotics; Multi-agent systems	DIVISION-OF-LABOR; ORGANIZED TASK ALLOCATION; REINFORCEMENT; COORDINATION; MODELS	In this paper, we investigate how response probability may be used to improve the robustness of reactive, threshold-based robotic swarms. In swarms where agents have differing thresholds, adding a response probability is expected to distribute task experiences among more agents, which can increase the robustness of the swarm. If the lowest threshold agents for a task become unavailable, distributing task experience among more agents increases the chance that there are other agents in the swarm with experience on the task, which reduces performance decline due to the loss of experienced agents. We begin with a mathematical analysis of such a system and show that, for a given swarm and task demand, we can estimate the response probability values that ensure team formation and meet robustness constraints. We then verify the expected behavior on an agent based model of a foraging problem. Results indicate that response probability may be used to tune the tradeoff between system performance and system robustness.																	1935-3812	1935-3820				SEP	2020	14	3					233	258		10.1007/s11721-020-00182-2		JUN 2020											
J								Adaptive Frequency Tracking Control with Fuzzy PI Compound Controller for Magnetically Coupled Resonant Wireless Power Transfer	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Wireless power transfer; Magnetically coupled resonant; Detuning; Fuzzy PI	SYSTEMS	In the magnetically coupled resonant wireless power transfer (MCR-WPT) system, parameter variations of the resonant network will cause the resonant frequency drift, which will make the system in the detuning state. The detuning will increase the required capacity of the power supply and reduce the transfer efficiency of the system. To solve this problem, this paper analyzes the relation between the input impedance angle of the primary side and the resonant state and proposes an adaptive frequency tracking control (AFTC) method based on the fuzzy PI compound controller. In this method, a fuzzy PI compound controller is used to control the impedance angle (theta = 0), which can make the operating frequency to track the resonant frequency, so that the MCR-WPT system can maintain in the resonant state. The experimental results show that the AFTC method can make the operating frequency to track the resonant frequency faster and accurately during the parameter variations so that the MCR-WPT system can maintain in the resonant state and achieve the higher output power and system efficiency.																	1562-2479	2199-3211															10.1007/s40815-020-00890-1		JUN 2020											
J								Probably Partially True: Satisfiability for Lukasiewicz Infinitely-Valued Probabilistic Logic and Related Topics	JOURNAL OF AUTOMATED REASONING										Fuzzy logics; Probabilistic fuzzy logics; Multivalued logics; Probabilistic multivalued logics; Lukasiewicz Infinitely-valued Logic	PROOF	We study probabilistic-logic reasoning in a context that allows for "partial truths", focusing on computational and algorithmic properties of non-classical Lukasiewicz Infinitely-valued Probabilistic Logic. In particular, we study the satisfiability of joint probabilistic assignments, which we call LIPSAT. Although the search space is initially infinite, we provide linear algebraic methods that guarantee polynomial size witnesses, placing LIPSAT complexity in the NP-complete class. An exact satisfiability decision algorithm is presented which employs, as a subroutine, the decision problem for Lukasiewicz Infinitely-valued (non probabilistic) logic, that is also an NP-complete problem. We investigate efficient representation of rational McNaughton functions in Lukasiewicz Infinitely-valued Logic modulo satisfiability.																	0168-7433	1573-0670				OCT	2020	64	7			SI		1269	1286		10.1007/s10817-020-09558-9		JUN 2020											
J								Proof-Producing Synthesis of CakeML from Monadic HOL Functions	JOURNAL OF AUTOMATED REASONING										Interactive theorem proving; Program synthesis; ML; Higher-order logic	HIGHER-ORDER LOGIC	We introduce an automatic method for producing stateful ML programs together with proofs of correctness from monadic functions in HOL. Our mechanism supports references, exceptions, and I/O operations, and can generate functions manipulating local state, which can then be encapsulated for use in a pure context. We apply this approach to several non-trivial examples, including the instruction encoder and register allocator of the otherwise pure CakeML compiler, which now benefits from better runtime performance. This development has been carried out in the HOL4 theorem prover.																	0168-7433	1573-0670				OCT	2020	64	7			SI		1287	1306		10.1007/s10817-020-09559-8		JUN 2020											
J								An AAC Mobile-Based Application for People with Intellectual Disability: A Case Study in Brazil	ADVANCES IN HUMAN-COMPUTER INTERACTION											CHILDREN	Augmentative and Alternative Communication (AAC) techniques are employed to mediate communication with people who have communication disorders, as in cases of intellectual disability. Although there are various digital solutions that promote alternative communication options for individuals with communication disorders, only a few of them have been specifically designed or targeted to people with intellectual disability (ID). This work is motivated by the lack of AAC solutions contributing to the rehabilitation processes of individuals with intellectual disability in Brazil. The study presents a mobile-based AAC solution conceived as a tool to assist the rehabilitation process of people with ID. The design was based on user-centered design principles and accessibility standards. The System Usability Scale (SUS) questionnaire was used to evaluate the solution. Four specialists and twenty-five students participated in this study. The proposed solution shows the potential educational value for professionals who assist individuals with intellectual disability in Brazil.																	1687-5893	1687-5907				JUN 5	2020	2020								8932707	10.1155/2020/8932707													
J								A novel data representation framework based on nonnegative manifold regularisation	CONNECTION SCIENCE										Cognitive learning; clustering; matrix factorisation; optimisation methods; regularisation	RECOGNITION; PROTECTION	Representation learning techniques have been frequently applied in multimedia content analysis and retrieval. In this study, an efficient multimedia data clustering method is presented, which consists of two independent algorithms. First, we propose a new representation framework by incorporating sparse coding and manifold regularisation in an optimisation objective function, the cluster indicator matrix is estimated by introducingsparsity norm coarsely. Second, we refine the estimated cluster indicator matrix by performing spectral rotation such that an optimal assignment for clustering can be learned. Compared with existing methods, we have the following merits: our method takes into account the global matrix reconstruction information and locality manifold information simultaneously. Therefore, global and locality information both are respected. Additionally, theoretical justification about the novel representation method is presented in this study. Comprehensive experiments demonstrate the effectiveness and efficiency of our method in comparison with the state-of-the-art clustering methods on six real-world image datasets.																	0954-0091	1360-0494															10.1080/09540091.2020.1772722		JUN 2020											
J								Stable feature selection based on instance learning, redundancy elimination and efficient subsets fusion	NEURAL COMPUTING & APPLICATIONS										Feature selection; High dimensionality; Instance-based learning; Stability	CANCER; RELEVANCE	Feature selection is frequently used as a preprocessing step to data mining and is attracting growing attention due to the increasing amounts of data emerging from different domains. The large data dimensionality increases the noise and thus the error of learning algorithms. Filter methods for feature selection are specially very fast and useful for high-dimensional datasets. Existing methods focus on producing feature subsets that improve predictive performance, but they often suffer from instability. Instance-based filters, for example, are considered as one of the most effective methods that rank features based on instances neighborhood. However, as the feature weight fluctuates with the instances, small changes in training data result in a different selected subset of features. By another hand, some other filters generate stable results but lead to a modest predictive performance. The absence of a trade-off between stability and classification accuracy decreases the reliability of the feature selection results. In order to deal with this issue, we propose filter methods that improve stability of feature selection while preserving an optimal predictive accuracy and without increasing the complexity of the feature selection algorithms. The proposed approaches first use the strength of instance learning to identify initial sets of relevant features, and the advantage of aggregation techniques to increase the stability of the final set in a second stage. Two classification algorithms are used to evaluate the predictive performance of our proposed instance-based filters compared to state-of-the-art algorithms. The obtained results show the efficiency of our methods in improving both classification accuracy and feature selection stability for high-dimensional datasets.																	0941-0643	1433-3058															10.1007/s00521-020-04971-y		JUN 2020											
J								Action recognition on continuous video	NEURAL COMPUTING & APPLICATIONS										Deep learning; Action recognition		Video action recognition has been a challenging task over the years. The challenge herein is not only due to the complication in increasing information in videos but also the requirement of an efficient method to retain information over a longer-term where human action would take to perform. This paper proposes a novel framework, named as long-term video action recognition (LVAR) to perform generic action classification in the continuous video. The idea of LVAR is introducing a partial recurrence connection to propagate information within every layer of a spatial-temporal network, such as the well-known C3D. Empirically, we show that this addition allows the C3D network to access long-term information, and subsequently improves action recognition performance with videos of different length selected from both UCF101 and miniKinetics datasets. Further confirmation of our approach is strengthened with experiments on untrimmed video from the Thumos14 dataset.																	0941-0643	1433-3058															10.1007/s00521-020-04982-9		JUN 2020											
J								High temporal resolution rainfall-runoff modeling using long-short-term-memory (LSTM) networks	NEURAL COMPUTING & APPLICATIONS										Hydrologic analysis; GSSHA; Recurrent neural network; Machine learning	NEURAL-NETWORKS; PREDICTION; FORECASTS	Accurate and efficient models for rainfall-runoff (RR) simulations are crucial for flood risk management. Most rainfall models in use today are process-driven; i.e., they solve either simplified empirical formulas or some variation of the St. Venant (shallow water) equations. With the development of machine-learning techniques, we may now be able to emulate rainfall models using, for example, neural networks. In this study, a data-driven RR model using a sequence-to-sequence long-short-term-memory (LSTM) network was constructed. The model was tested for a watershed in Houston, TX, known for severe flood events. The LSTM network's capability in learning long-term dependencies between the input and output of the network allowed modeling RR with high resolution in time (15 min). Using 10-year precipitation from 153 rainfall gages and river channel discharge data (more than 5.3 million data points), and by designing several numerical tests, the developed model performance in predicting river discharge was tested. The model results were also compared with the output of a process-driven model gridded surface subsurface hydrologic analysis (GSSHA). Moreover, physical consistency of the LSTM model was explored. The model results showed that the LSTM model was able to efficiently predict discharge and achieve good model performance. When compared to GSSHA, the data-driven model was more efficient and robust in terms of prediction and calibration. Interestingly, the performance of the LSTM model improved (test Nash-Sutcliffe model efficiency from 0.666 to 0.942) when a selected subset of rainfall gages based on the model performance, were used as input instead of all rainfall gages.																	0941-0643	1433-3058															10.1007/s00521-020-05010-6		JUN 2020											
J								Traffic classification in server farm using supervised learning techniques	NEURAL COMPUTING & APPLICATIONS										Traffic classification; Denial of service; Support vector machine; Machine learning	DDOS DETECTION; ATTACKS; FRAMEWORK; DEFENSE; SYSTEM	Server farms used in web hosting and commercial applications connect multiple servers. Edge computing being a realm of cloud technology is orchestrated with server farms to enhance network efficiency. Edge computing increases the availability of cloud resources and Internet services. The higher availability of services and their ease of access deeply affect the user's requesting behavior. The anomalous requesting behavior is creating malicious traffic, and enormous amount of such traffics at server farm denies the services to the legitimate users. Categorizing the incoming traffic into malicious and non-malicious traffic at server farm is the foremost criteria to eliminate the attacks, which in turn improves the QoS of the server farm. In the light of preventing the biased usage of the server farm, this paper proposes a SVM classifier based on requesting statistics. The proposed classifier discovers the attacks that deny services to legitimate users in two levels, based on the user's request behavior. The pattern of arrival, its statistical characteristics and security misbehaviors are investigated at both levels. An incremental learning algorithm is proposed to enhance the learning plasticity of the proposed classifier. The experimental results illustrate that the performance of the proposed two-level classifier with respect to classification accuracy is competently improved with incremental learning.																	0941-0643	1433-3058															10.1007/s00521-020-05030-2		JUN 2020											
J								An efficient neural-network model for real-time fault detection in industrial machine	NEURAL COMPUTING & APPLICATIONS										Fault detection; Stator inter-turn fault (SITF); Neural network; Activation function; Pattern recognition; Squirrel-cage induction motor	INDUCTION-MOTORS; DIAGNOSIS	Induction machines have extensive demand in industries as they are used for large-scale production and, therefore, vulnerable to both electrical and mechanical faults. Automated continuous condition monitoring of industrial machines to identify these faults has become one of the key areas in research for the past decade. Among various faults, early-stage identification of insulation failure in stator winding is of significant demand as it is often occurring and accounts for 37% of the overall machine failures. Also, this fault, if identified at its incipient stage, can predominantly improvise machine downtime and maintenance cost. In the proposed work, stator current signal data in the time domain from the experimental setup of both healthy and faulty induction machines are used to train the artificial neural-network models in order to identify the machine's condition. Reducing the time required to train the neural network, features are extracted from the raw current signal data and then fed to the classifiers. Various performance characteristics of eleven neural-network models such as the number of features, number of epoch runs, training time, activation functions, learning rate, model loss function, and accuracy concerning each model are quantified. Only a few neural networks could classify a healthy and a faulty induction machine with 94.73% efficiency on generalization the neural-network model with the raw data, whereas 98.43% efficiency with the statistical featured data.																	0941-0643	1433-3058															10.1007/s00521-020-05033-z		JUN 2020											
J								Twitter alloy steel disambiguation and user relevance via one-class and two-class news titles classifiers	NEURAL COMPUTING & APPLICATIONS										Text classification; User relevance; Machine learning; Social media analytics	MICROBLOGGING DATA; SENTIMENT; IMPACT	This paper addresses the nontrivial task of Twitter financial disambiguation (TFD), which is relevant to filter financial domain tweets (e.g., alloy steel or coffee prices) when no unique identifiers (e.g., cashtags) are adopted. To automate TFD, we propose a transfer learning approach that uses freely labeled news titles to train diverse one-class and two-class classification methods. These include different text handling transforms, adaptations of statistical measures and modern machine learning methods, including support vector machines (SVM), deep autoencoders and multilayer perceptrons. As a case study, we analyzed the domain of alloy steel prices, collecting a recent Twitter dataset. Overall, the best results were achieved by a two-class SVM fed with TFD statistical measures and topic model features, obtaining an 80% and 71% discrimination level when tested with 11,081 and 3000 manually labeled tweets. The best one-class performance (78% and 69% for the same test tweets) was obtained by a term frequency-inverse document frequency classifier (TF-IDFC). These models were further used to generate a Financial User Relevance rank (FUR) score, aiming to filter relevant users. The SVM and TF-IDFC FUR models obtained a predictive user discrimination level of 80% and 75% when tested with a manually labeled test sample of 418 users. These results confirm the proposed joint TFD-FUR approach as a valuable tool for the selection of Twitter texts and users for financial social media analytics (e.g., sentiment analysis, detection of influential users).																	0941-0643	1433-3058															10.1007/s00521-020-04991-8		JUN 2020											
J								Modeling of complex internal logic for knowledge base completion	APPLIED INTELLIGENCE										Knowledge base completion; Semantic gap; Knowledge subgraph; Multi-hop attention mechanism; Reinforcement learning		Knowledge base completion has been an active research topic for knowledge graph. However, existing methods are of low learning and generalization abilities, and neglect the rich internal logic between entities and relationships. To solve the above problems, this paper proposes the modeling of complex internal logic for knowledge base completion. This method first integrates the semantic information into the knowledge representation model and strengthens the credibility scores of the positive and negative triples with the semantic gap, which not only makes the model converge faster, but also can obtain the knowledge representation of the fusion semantic information; and then we put forward the concept of knowledge subgraph, through the memory network and multi-hop attention mechanism, the knowledge information in the knowledge subgraph and the to-be-complemented triple are merged. In the process of model training, we have different training methods from the classical memory network, and added reinforcement learning. The reciprocal of the correct reasoning knowledge information in the model output is used as the reward value, and the final training model complements the triple information. The high computing capability of knowledge representation, the high learning and generalization abilities of the memory network and the multi-hop attention mechanism are also utilized in the method. The experimental results on data sets FB15k and WN18 show that the present method performs well in knowledge base completion and can effectively improve Hits@10 and MRR values. We also verified the practicability of the proposed method in the recommendation system and question answering system base on knowledge base, and have achieved good results.																	0924-669X	1573-7497				OCT	2020	50	10					3336	3349		10.1007/s10489-020-01734-z		JUN 2020											
J								A novel discrete whale optimization algorithm for solving knapsack problems	APPLIED INTELLIGENCE										Whale optimization algorithm; Meta-heuristic algorithm; V -shaped function; 0-1knapsack problem; Discounted {0-1} knapsack problem	DIFFERENTIAL EVOLUTION; BINARY	Whale optimization algorithm (WOA) is a recently proposed meta-heuristic algorithm which imitates the hunting behavior of humpback whales. Due to its characteristic advantages, it has found its place in the mature population-based methods in many scientific and engineering fields. Because WOA was proposed for continuous optimization, it cannot be directly used to solve discrete optimization problems. For this purpose, we first give a new V -shaped function by drawing lesson from the existing discretization methods, which transfer a real vector to an integer vector. On this basis, we propose a novel discrete whale optimization algorithm (DWOA). DWOA uses the new proposed V -shaped function to generate an integer vector, and it can be used to solve discrete optimization problems with solution space {0,1, horizontal ellipsis ,m(1)}x{0,1, horizontal ellipsis ,m(2)}x horizontal ellipsis x{0,1, horizontal ellipsis ,m(n)}. To verify effectiveness of DWOA for the 0-1 knapsack problem and the discount {0-1} knapsack problem, we solve their benchmark instances from published literature and compare with the state-of-the-art algorithms. The comparison results show that the DWOA has more superiority than existing algorithms for the two kinds of knapsack problems.																	0924-669X	1573-7497				OCT	2020	50	10					3350	3366		10.1007/s10489-020-01722-3		JUN 2020											
J								Non-goal oriented dialogue agents: state of the art, dataset, and evaluation	ARTIFICIAL INTELLIGENCE REVIEW										Natural language processing; Dialogue management systems; Language modeling; Machine learning; Deep learning; Dialogue agent	NEURAL-NETWORKS; LANGUAGE	Dialogue agent, a derivative of intelligent agent in the field of computational linguistics, is a computer program that is capable of generating responses and performing conversation in natural language. The field of computational linguistics is flourishing due to the intensive growth of dialogue agents; the most potential one is providing voice controlled smart personal assistant service for handsets and homes. The agents are usable, accessible but perform task-related short conversations. Non-goal-oriented dialogue agents are designed to imitate extended human-human conversations, also called as chit-chat, to provide the consumer with a satisfactory experience on the conversation quality. The design of such agents is primarily defined by a language model, unlike goal-oriented dialogue agents that employees slot based or ontology-based frameworks, hence most of the methods are data-driven. This paper surveys the current state of the art of non-goal-oriented dialogue systems specifically data-driven methods, the most prevalent being deep learning. This paper aims at (a) providing an insight of recent methods and architectures proposed for building context and modeling response along with a comprehensive review of the state of the art (b) examine the type of data set and evaluation methods available (c) present the challenges and limitation that the recent models, dataset and evaluation methods constitute.																	0269-2821	1573-7462															10.1007/s10462-020-09848-z		JUN 2020											
J								An Approach Towards Decision-Making and Shortest Path Problems Based on T-Spherical Fuzzy Information	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										T-spherical fuzzy set; Fuzzy graph; Picture fuzzy graph; T-spherical fuzzy graph	AGGREGATION OPERATORS; ALGORITHM; SETS	In this paper, we propose some developments in fuzzy graph theory. An original notion of a T-spherical fuzzy graph is presented as a commonality of fuzzy graph, an intuitionistic fuzzy graph and a picture fuzzy graph. The originality, the imperativeness and the importance of this notion are discussed by showing some results, giving examples and graphical analysis. Some theoretical terms of graphs such as a T-spherical fuzzy subgraph, a complement of T-SFG, degree of T-SFG are clarified and their attributes and aspects are analyzed. Interestingly, three types of decision-making problems using the framework of T-SFGs are studied. These problems include the problem of the shortest path, the safe root for an airline journey and the problem of supply chain management in a T-spherical fuzzy network. The comparison of this new approach towards these problems with existing approaches is also established. A new algorithm is put forward in the event of T-SFGs and is used to seek out the shortest path problem. The overall analysis of the suggested notion under the prevailing theory is conducted. The advantages of the proposed approach are discussed based on the existing tools and a short comparison of the new with existing tools is established.																	1562-2479	2199-3211				JUL	2020	22	5					1521	1534		10.1007/s40815-020-00820-1		JUN 2020											
J								Influence Paths of Marine Ranching Ecological Security in China Based on Probabilistic Linguistic Term Sets and Qualitative Comparative Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Marine ranching; Ecological security; Influence path; Probabilistic linguistic term sets; Qualitative comparative analysis	STOCK ENHANCEMENT; RESTORATION; RIVER; QCA	Marine ranching can increase the harvesting capacity of many species and help achieve planned and purposeful production of marine resources. However, marine ranching ecological security (MRES) has received limited attention, which has affected the management of marine ranching. To provide decision support for the management of MRES in China, we obtained the influence paths of MRES in China using probabilistic linguistic term sets (PLTSs) and qualitative comparative analysis (QCA). The DPSIR (Driver-Pressure-State-Impact-Response) framework was employed to construct the evaluation index system of MRES, and PLTSs were used to describe the multiple values resulting from three threshold setting methods. We selected 17 samples of marine ranching enterprises in China to apply our method and input their data into multi-value QCA to identify the influence paths of MRES relating to those enterprises. We found that there exists an influence path (configuration) that causes a high level of MRES, namely F-1{2}*F-2{2}*similar to F-3*F-4{2}*F-5{1,2}. This means that for a high level of MRES, the driver, pressure and impact factors should be at their best levels, and the state factor can be at the normal level. MRES was at the high level whether the response factor was normal or positive. Our findings generate theoretical and practical implications managing MRES.																	1562-2479	2199-3211															10.1007/s40815-020-00894-x		JUN 2020											
J								Requirements-preserving design automation for multiprocessor embedded system applications	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Embedded systems; Design automation; Parallel computing; Requirements; preservation; Task scheduling; OpenMP		The number of processors is increasing, but the usefulness of parallel computation is not better leveraged due to the inflexibility of design and implementation for multiprocessor embedded system applications. A higher level abstraction (i.e., a parallel programming framework) can ease the programmers to define parallelism for tasks in an application but designers still face the complexity of mapping high-level requirements to the syntax and semantics of a parallel programming interface. Nevertheless, embedded system applications execute various periodic tasks that are carried out repeatedly within a certain time interval and these tasks may be able to run in parallel to utilize the system efficiently. Therefore, in this paper, we propose a parallel loop-based task construct approach to automate the design process of embedded system applications from AADL models for a parallel programming framework. To illustrate the applicability of our mechanism, we use a well-known parallel programming interface called OpenMP to demonstrate the automation process in mapping tasks over multiple processor cores. To ensure meeting high-level requirements of embedded system applications, we analyze the existing OpenMP scheduling mechanisms and propose a layer of adaptation. We show that our proposed adaptation layer facilitates a tighter execution time bound for time-sensitive tasks or a better throughput for tasks that require higher quality of service. Thus, the proposed design automation framework is applicable for a variety of applications with different quality of service (QoS) requirements preserved at the lower level.																	1868-5137	1868-5145															10.1007/s12652-020-02086-9		JUN 2020											
J								Rule based auto-scalability of IoT services for efficient edge device resource utilization	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Edge computing; Container; Resource management; Auto-scalability		Conveying the workload of IoT systems from the cloud to edge nodes have been widely adopted by industrial and academic sectors. This tendency is generally promoted to meet the requirements of some time-sensitive use cases such as IoT healthcare applications. However, IoT devices at the edge network are likely to be resource-limited, as well as, they perform under an extremely heterogeneous environment in terms of the connected devices and the deployed software modules. Thus, both of the aforementioned concerns have considerably led to hindering the deployment process of services on IoT edge devices. In this paper, we propose an approach to facilitate a scalable and lightweight solution for service deployment for efficient resource utilization on IoT edge nodes. Our solution is based on the container concept, and we adopt the cluster concept to define a group of IoT edge devices. Containers are lightweight virtualization technique that enables services to be packaged and deployed with their dependencies regardless of the hosts infrastructure, as well as, they facilitate the service communication and the update process. Furthermore, containers are supported by some means of orchestration such as swarm. These orchestration tools can be configured to enable services deployment and resources sharing among IoT edge devices falling within the same cluster. However, they lack elasticity in terms of auto-scaling up/down of services instances in corresponding to the resource utilization of all cluster elements, as well as, service performance metrics. Our approach overcomes these limitations by following an auto-scaling process based on MAPE-K loop, which is based on our proposed rule model to generate a scaling plan by analyzing collected performance metrics of a cluster. Our evaluation shows the efficiency of the proposed approach in adapting the system performance to meet service performance requirements and the availability of system resources.																	1868-5137	1868-5145															10.1007/s12652-020-02100-0		JUN 2020											
J								Cooperative spectrum sensing optimization based adaptive neuro-fuzzy inference system (ANFIS) in cognitive radio networks	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Wideband spectrum sensing; Cognitive radio; ANFIS model; Adaptive multi-coset sampling; Cooperative sensing		The tremendous growth of the wireless communications and their applications stimulate the urgent need to keep on the available radio spectrum. As a result, cognitive radio (CR) technologies are proposed and developed to manage the limitation of the available spectrum by methods of sensing and sharing the free channels. Wideband spectrum sensing algorithms have a great impact of detecting the vacant channels of the whole spectrum simultaneously. Cooperative sensing techniques are introduced based on sharing users' sensing outcomes among other users. Therefore, it represents an efficient method to overcome signal shadowing and fading problems. Recently, artificial intelligence (AI) techniques are considered to improve the quality of service (QoS) parameters in cognitive radio networks. In this paper, an adaptive Neuro-Fuzzy interference system (ANFIS) algorithm is proposed in the process of decision-making to detect the optimal and accurate free channels. ANFIS model is trained with some pertinent features over a Music-like channel power level (P-MU(k)), channel identity number (k), and channel repetition number. Consequently, the second stage is introduced by applying ANFIS technique on the adaptive blind cooperative wideband spectrum sensing basis to select the optimum required number of cooperative users with increasing performance based on the detected signal to noise ratio (SNR) level per secondary user. Simulation is based on Simulink of five users with different SNR due to fading and shadowing problems. Simulation results proved that, the proposed technique based on cooperative spectrum sensing algorithm with ANFIS model for detection outperformed other traditional detection techniques.																	1868-5137	1868-5145															10.1007/s12652-020-02121-9		JUN 2020											
J								Secure routing scheme with multi-dimensional trust evaluation for wireless sensor network	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Sensor; Trust; Reputation; Attacks; Energy efficiency	INTERNET; THINGS; MODEL	Security has been always a major concern in wireless network irrespective of evolving safety protocols, which motivates various researchers to explore an effective security solution. Existing encryption-based solution offers security but at the cost of resources which are sometime highly limited in communication devices. Therefore, this paper discusses about trust evaluation that is one of the critical operations for ascertaining the degree of security strength offered by the sensor nodes in Wireless Sensor Network (WSN). Existing research work has been carried out to find a strong connection between the resource efficiency and the critical security approaches; however, these approaches are not proven for lightweight energy efficient security scheme. Therefore, the proposed system developed using analytical approach offers a secured communication scheme that evaluates the comprehensive trust value for the target relay node followed by reputation value from the neighboring node in order to perform an effective selection of legitimate relay node. The authentication process has been carried out using progressive key-generation process while the resource efficiency is maintained by developing multi-dimensional trust computation. The essential contribution of the proposed model is to offer an effective balance between resource efficiency and trust-reputation based security strengthening features. The outcome shows that proposed model offers 75% of retention of energy-efficient nodes with more predictable energy dissipation trend. It also offers 82% of reduction of energy fluctuation during the entire operation which is again found to be 35% faster than existing approaches. The simulated outcome of study exhibits that proposed system offers better data transmission performance with significant energy efficiency in comparison to existing scheme.																	1868-5137	1868-5145															10.1007/s12652-020-02169-7		JUN 2020											
J								Bearing fault diagnosis base on multi-scale CNN and LSTM model	JOURNAL OF INTELLIGENT MANUFACTURING										Bearing fault diagnosis; Convolutional neural network; Recurrent neural network; Deep learning; Feature fusion	FEATURE-EXTRACTION; CLASSIFICATION; WAVELET; IDENTIFICATION; TRANSFORM	Intelligent fault diagnosis methods based on signal analysis have been widely used for bearing fault diagnosis. These methods use a pre-determined transformation (such as empirical mode decomposition, fast Fourier transform, discrete wavelet transform) to convert time-series signals into frequency domain signals, the performance of dignostic system is significantly rely on the extracted features. However, extracting signal characteristic is fairly time consuming and depends on specialized signal processing knowledge. Although some studies have developed highly accurate algorithms, the diagnostic results rely heavily on large data sets and unreliable human analysis. This study proposes an automatic feature learning neural network that utilizes raw vibration signals as inputs, and uses two convolutional neural networks with different kernel sizes to automatically extract different frequency signal characteristics from raw data. Then long short-term memory was used to identify the fault type according to learned features. The data is down-sampled before inputting into the network, greatly reducing the number of parameters. The experiment shows that the proposed method can not only achieve 98.46% average accuracy, exceeding some state-of-the-art intelligent algorithms based on prior knowledge and having better performance in noisy environments.																	0956-5515	1572-8145															10.1007/s10845-020-01600-2		JUN 2020											
J								Formal modelling of a sheet metal smart manufacturing system by using Petri nets and first-order predicate logic	JOURNAL OF INTELLIGENT MANUFACTURING										Smart CAD; CAM; High-level petri nets; Object-oriented programming; First-order predicate logic; Process planning; Layout design	INTELLIGENT CONCURRENT DESIGN; PACKING; ALGORITHM; FRAMEWORK; HYBRID	This study introduces a developed method to a smart computer-aided design/manufacturing (CAD/CAM) system, where layout design, process planning, and comprehensive computerized numerical control (CNC) code generation can be implemented to satisfy laser cutting holes, tapping, irregular and complicated profile processing, engraving, and burr back-scraping. The smart CAD/CAM(SCAM) system is developed as a commercial software product or application and firstly applied to flexible sheet metal machining center (BGL 130R). In this study, a formal modeling method involving Petri nets and first-order predicate logic is proposed to develop the smart manufacturing system. High-level Petri nets are employed to achieve the formal application architecture design of data flow for various functions, and the first-order logic used to represent the process plan is defined and deduced according to the machining methods. The developed system possesses the following characteristics: (1) a sound and complete deductive system to implement various types of trajectory planning, automatic generation, and validation of the CNC code; (2) a convenient design input environment and readiness for re-design and modification by adding specific design functions and using standard design procedures on a widely used CAD/CAM package; (3) helpful for designers in sheet metal layout designing, layout interference detection, process planning validation, preprocess manufacturing operation of CNC code generation, and autodefinition of storable file names; and (4) formal and simple in human-computer interaction, automatic and intelligent in process operations, and satisfactory in terms of the requirements of the flexible sheet metal machining center (BGL 130R).																	0956-5515	1572-8145															10.1007/s10845-020-01602-0		JUN 2020											
J								A transformation of human operation approach to inform system design for automation	JOURNAL OF INTELLIGENT MANUFACTURING										Task analysis; Human factors; Clustering; Task function; Process design; Automation; Manufacturing	HIERARCHICAL TASK-ANALYSIS; INDUSTRY 4.0; REQUIREMENTS; MODEL; CONTEXT	Design of automation system relies on experts' knowledge and experience accumulated from past solutions. In designing novel solutions, however, it is difficult to apply past knowledge and achieve design right-first-time, therefore wasting valuable resources and time. SADT/IDEF0 models are commonly used by automation experts to model manufacturing systems based on the manual process. However, function generalisation without benchmarking is difficult for experts particularly for complex and highly skilled-based tasks. This paper proposes a functional task abstraction approach to support automation design specification based on human factor attributes. A semi-automated clustering approach is developed to identify key functions from an observed manual process. The proposed approach is tested on five different automation case studies. The results indicate the proposed method reduces inconsistency in task abstraction when compared to the current approach that relies on the experts, which are further validated against the solutions generated by automation experts.																	0956-5515	1572-8145															10.1007/s10845-020-01568-z		JUN 2020											
J								Study on Green's relations in ordered semihypergroups	SOFT COMPUTING										Ordered semihypergroup; Green's relation; a-maximal hyperideal	REGULAR EQUIVALENCE-RELATIONS; PRIME IDEALS; HYPERIDEALS; SEMIGROUPS; HYPERGROUPS; CONGRUENCES	In this paper, we study the hyper versions of Green's relations in ordered semihypergroups in detail. The Green's relations R,L,J and H in ordered semihypergroups are first introduced, and the relations between them are given. Furthermore, we investigate the properties of Green's relations in ordered semihypergroups. Particularly, we illustrate the Green's relation R (resp. L) in an ordered semihypergroup S is not necessarily a left (resp. right) congruence on S by counterexamples. Meanwhile, we also provide a sufficient condition that makes the above conclusion true. Finally, we introduce the concept of a-maximal hyperideals of an ordered semihypergroup, and discuss its related properties by terms of the Green's relation J.																	1432-7643	1433-7479				AUG	2020	24	15			SI		11189	11197		10.1007/s00500-020-05035-y		JUN 2020											
J								A pattern recognition model to distinguish cancerous DNA sequences via signal processing methods	SOFT COMPUTING										Cancer; DNA sequence; Anti-notch filter; Discrete Fourier transform; Pattern recognition	SUPPORT VECTOR MACHINES; PROTEIN-CODING REGIONS; PREDICTION; CLASSIFICATION; IDENTIFICATION; SOFTWARE; HEALTHY; NETWORK; GENES	Cancer is one of the life-threatening diseases caused by changes in the structure of genetic components of the cell. DNA sequences are one of the most important factors in the formation and spread of this disease. The signal processing approach is one of the scientific fields that has been developed in the last two decades in the analysis of DNA sequences. In this research, a hybrid model of discrete Fourier transform and anti-notch digital filter has been used for this purpose. The aim of using these techniques is to model an approach that can distinguish cancerous samples from non-cancerous ones. In other words, a pattern recognition model is designed to discriminate cancerous cell samples based on the features of protein coding regions of DNA sequences. Some computational and statistical techniques have been used in feature extraction and feature selection stages. Despite the proposed model simplicity, it doesn't face conventional challenges such as high computational complexity or memory dissipation. Case studies have been tested with the least possible feature, depending on the nature of the features. Experimental results and features relationship led to the proposal of the SVM classifier to discriminate two categories. The output features and classification show good discrimination results among the cancerous and non-cancerous samples. One of the main advantages of the proposed model is the independence of its performance over the data length. Evaluation and validation results indicate the high accuracy and precision of the proposed method which emphasizes the biological genetic mutation nature of cancer.																	1432-7643	1433-7479				NOV	2020	24	21					16315	16334		10.1007/s00500-020-04942-4		JUN 2020											
J								RecDNN: deep neural network for image reconstruction from limited view projection data	SOFT COMPUTING										Deep learning; Deep neural network; Algebraic reconstruction technique; Image reconstruction; Limited projection views	LOW-DOSE CT; 3-DIMENSIONAL RECONSTRUCTION; ART; ALGORITHM	Improving the quality of reconstruction, even in a limited projection view, has become one of the prime objectives in computed tomography. Projection data over 180 degrees are always not practicable in many practical applications including medical imaging. Iterative approaches, such as algebraic reconstruction techniques (ART), are useful in the limited view scenarios; however, these approaches resulted in the streaking artifacts. Deep learning has paved a path to achieve high efficiency and accuracy for reconstruction with limited view projection data. Convolutional neural networks such as U-Net, residual neural networks and adversarial neural networks are being widely used for image reconstruction. U-Net and residual neural network for limited projection views have been found compute intensive and also produces a noisy image. The convergence of the adversarial neural network in case of the inverse problem is very slow; hence, the training is compute intensive. A deep neural network for image reconstruction (RecDNN) is proposed in this manuscript for a limited view case. The proposed architecture is designed to give reconstruction with minimal artifacts. The objective is to give a good quality of textural and contrast information about the reconstructed object. The image reconstruction has been addressed as inverse problem as well as optimization problem. The stochastic gradient method is applied to achieve image reconstruction. The proposed approach has been compared to the traditional transform-based approaches as well as the current deep learning methods for image reconstruction. Experimental results show that the proposed architecture is performing better than the existing approaches, as well as the state-of-the-art architectures available for image reconstruction. Experimental results also show that for the same number of projection views, the proposed architecture reconstructs the object with higher quality as compared to existing architectures for image reconstruction.																	1432-7643	1433-7479				NOV	2020	24	22					17205	17220		10.1007/s00500-020-05013-4		JUN 2020											
J								Hybrid model to improve the river streamflow forecasting utilizing multi-layer perceptron-based intelligent water drop optimization algorithm	SOFT COMPUTING										Streamflow; Estimation; Time series models; Machine learning techniques; Intelligent water drop; Multi-layer perceptron	FUZZY INFERENCE SYSTEM; SUPPORT VECTOR MACHINE; NEURAL-NETWORKS; FLOW; PREDICTION; QUEENSLAND; ANFIS	Artificial intelligence (AI) models have been effectively applied to predict/forecast certain variable in several engineering applications, in particular, where this variable is highly stochastic in nature and complex to identify utilizing classical mathematical model, such as river streamflow. However, the existing AI models, such as multi-layer perceptron neural network (MLP-NN), are basically incomprehensible and facing problem when applied for time series prediction or forecasting. One of the main drawbacks of the MLP-NN model is the ability of the used default optimization algorithm [gradient decent algorithm (GDA)] to search for the optimal weight and bias values associated with each neuron within the MLP-NN architecture. In fact, GDA is a first-order iteration algorithm that usually trapped in local minima, especially when the time series is highly stochastic as in the river streamflow historical records. As a result, the overall performance of the MLP-NN model experienced inaccurate prediction or forecasting for the desired output. Moreover, due to the possibility of overfitting with MLP model which may lead to poor performance of prediction of the unseen input pattern, there is need to introduce new augmented algorithm capable of identifying the complexity of streamflow data and improve the prediction accuracy. Therefore, in this study, a replacement for the GDA with advanced optimization algorithm, namely intelligent water drop (IWD), is proposed to enhance the searching procedure for the global optima. The new proposed forecasting model is, namely MLP-IWD. Two different historical rivers streamflow data have been collected from Nong Son and Thanh My stations on the Vu Gia Thu Bon river basin for period between (1978 and 2016) in order to examine the performance of the proposed MLP-IWD model. In addition, in order to evaluate the performance of the proposed MLP-IWD model under different conditions, four different scenarios for the model input-output architecture have been investigated. Results showed that the proposed MLP-IWD model outperformed the classical MLP-NN model and significantly improve the forecasting accuracy for the river streamflow. Finally, the proposed model could be generalized and applied in different rivers worldwide.																	1432-7643	1433-7479															10.1007/s00500-020-05058-5		JUN 2020											
J								Digital hermeneutics for the new age of cinema	AI & SOCIETY										Cinema; Moving image; Visual; Digital media; Multistability; Postphenomenology		Philosophical and technoculture studies surrounding the existential understanding of the human-technology-world experience have seen a slow but steady increase that makes a turn to material hermeneutics in the second decade of the twenty-first century (Ihde in Postphenomenology: essays in the postmodern context. Northwestern University Press, Evanston, 1993; Capurro in AI Soc 25(1):35-42, 2010; Romele in Digital hermeneutics: philosophical investigations in new media and technologies. Routledge, Abingdon, 2020; among others). This renewed focus makes sense because human-technology-world experiences need to be interpreted. And many of these are more complicated to study, precisely because technology is at the root of the experiences. One interesting subset of technologies is media technologies, also called digital media, which intertwines the device and the content to mediate together in the world (Irwin in Digital media: human-technology connection. Lexington Books, Lanham, 2016). Visual media technologies and media content, together, through what is called moving image technologies, create virtual role-playing, virtual and augmented reality, video games, and social media focused worlds that have become central experiences in contemporary culture. Just as image-based scientific instruments read the world in different ways, so to do these visual mediated experiences. How might this comingled "reading" of technology explain the digital film language and experience? I contend that understanding the existential "early" film experience helps understand the new age of cinema, with implications for digital media, digital representation of the visual, and technoscience and technoculture studies. The material hermeneutics perspective called postphenomenology is one way to study these visually focused human-technology-world perceptual and interpretive experiences. Don Ihde's methodological framework (1990, 1993, 1996, 2002, 2010, 2012, 2016, 2019) is both an idea from technoscience studies and a set of nuanced vocabulary that helps to explore and reveal variations, patterns, and trajectories of the whole-body experience of technology. This use case will first explore traditional cinema and then the "new age" term "moving image", to learn more about this complicated and radically transforming technological experience. Work by Don Ihde and Vivian Sobchack is considered.																	0951-5666	1435-5655															10.1007/s00146-020-00993-1		JUN 2020											
J								A Real-Time Rerouting Method for Drone Flights Under Uncertain Flight Time	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Chance constrained programming; Drone; Rerouting; Uncertain flight time	VEHICLE	This paper proposes a method for real-time rerouting drone flights under uncertain flight times. The battery runtime that remains of a drone in real-time may be insufficient to complete its flight mission. This may be due to external factors, such as unexpected severe weather or obstacles that move into the drone's flight path. Under unexpected situations, such as these, the drone cannot safely return to its depot, as planned. To ensure that the drone makes a safe return and that the flight mission is a success, there must be a real-time rerouting process for a drone's flight path in response to unforeseeable circumstances. Hence, this paper proposes a real-time rerouting process consisting of two optimization models that generate an optimal alternative flight path for a drone that has insufficient remaining battery runtime. The first model is used to find an optimal flight path to visit all remaining target waypoints. If the first model fails to obtain a feasible solution, the second model is implemented to find an optimal flight path to minimize the number of unvisited waypoints. To confine the total flight (travel) time to the insufficient battery runtime, both models include the constraint associated with uncertain flight (travel) times between waypoints. To capture this uncertainty, this paper proposes a chance constrained programming (CCP) approach under the assumption of a known mean, variance, and flight time intervals. Numerical examples show how the proposed rerouting process works, and the CCP method results in more conservative solutions as compared to the deterministic approach.																	0921-0296	1573-0409															10.1007/s10846-020-01214-z		JUN 2020											
J								Dynamic Cooperative Transportation Control Using Friction Forces of n Multi-Rotor Unmanned Aerial Vehicles	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Cooperative transportation; Unmanned aerial vehicle; Friction constraint; Disturbance observer	MANIPULATORS	We address a cooperative transport control problem involving three or more unmanned aerial vehicles (UAVs). We realize the transportation of an object that cannot be carried with a small number of UAVs. To improve scalability and real-time performance, we propose a controller that does not require optimization calculations. The attitude and position of the transported object are controlled by contact forces with the UAVs. The control system comprises two steps in which (1) a force is allocated to each UAV and (2) UAVs realize the force allocation using a decentralized disturbance observer-based controller. A friction cone constraint related to static friction is considered using the redundant degree of freedom in the force allocation. The effectiveness of the controller is verified in numerical simulations.																	0921-0296	1573-0409															10.1007/s10846-020-01212-1		JUN 2020											
J								Background Subtraction using Adaptive Singular Value Decomposition	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Image processing; Background subtraction; Singular value decomposition	ROBUST-PCA; IMAGE	An important task when processing sensor data is to distinguish relevant from irrelevant data. This paper describes a method for an iterative singular value decomposition that maintains a model of the background via singular vectors spanning a subspace of the image space, thus providing a way to determine the amount of new information contained in an incoming frame. We update the singular vectors spanning the background space in a computationally efficient manner and provide the ability to perform blockwise updates, leading to a fast and robust adaptive SVD computation. The effects of those two properties and the success of the overall method to perform a state-of-the-art background subtraction are shown in both qualitative and quantitative evaluations.																	0924-9907	1573-7683				OCT	2020	62	8					1159	1172		10.1007/s10851-020-00967-4		JUN 2020											
J								An empirical model in intrusion detection systems using principal component analysis and deep learning models	COMPUTATIONAL INTELLIGENCE										deep learning; logistic regression; principal component analysis; random forest; support vector machine		Data are a main resource of a computer system, which can be transmitted over network from source to destination. While transmitting, it faces lot of security issues such as virus, malware, infection, error, and data loss. The security issues are the attacks that have to be detected and eliminated in efficient way to guarantee the secure transmission. The attack detection rates of existing Intrusion Detection Systems (IDS) are low, because the number of unknown attacks are high when compared to the known attacks in the network. Thus, recent researchers focus more on evaluation of known attacks attributes, that will help in identification of the attacks. But the difficulty here is the nature of the IDS datasets. The difficulty in any IDS dataset is to, too many attributes, irrelevant and unstructured in nature. So analyzing such attributes leads to a time consuming process and that produces an inefficient result. This article presents a combined approach Principle Component Analysis and Deep learning (PCA-DL) model to address above issues. The proposed PCA-DL method has achieved the accuracy 92.6% on detecting the attacks correctly.																	0824-7935	1467-8640															10.1111/coin.12342		JUN 2020											
J								Multi-Agent Cooperation for an Active Perception Based on Driving Behavior: Application in a Car-Following Behavior	APPLIED ARTIFICIAL INTELLIGENCE											MODEL	Perception is presented as a predominant concern in the functioning of a driving system, where it is necessary to understand how the information, events, and actions of each influence the state of the environment and the objectives of the driver, immediately and in the near future. In this context, we present in this paper a driving model composed of five layers which ensure the autonomy and road safety of a driver agent, in particular, we are interested in this article in the concept of perception which is translated by the first three layers of our driving model, which are: visual perception, comprehension and projection, where the execution of these three layers is based on the driving behavior adopted by the driver agent, which is in our case the car-following driving behavior. Furthermore, we present in this paper two simulation scenarios, the first one is realized based on urban area conditions, and the second one is conducted by using Next Generation SIMulation (NGSIM) dataset of a highway in Los Angeles, California. In this context, the experimental results present the effectiveness of our driving model based on the imitation of human behavior and according to reducing the duration of perception.																	0883-9514	1087-6545				AUG 23	2020	34	10					710	729		10.1080/08839514.2020.1771837		JUN 2020											
J								Visual Landmarks are Exaggerated: A Theoretical and Empirical View on the Meaning of Landmarks in Human Wayfinding	KUNSTLICHE INTELLIGENZ										Landmarks; Wayfinding; Spatial cognition; Modality; Visual; Auditory; Olfactory; Multimodal integration; System 1 and system 2 thinking	STRUCTURAL SALIENCE	Are landmarks exaggerated in human wayfinding? Daniel R. Montello says yes, and I basically agree with his opinion. However, I do agree on a different level. My aim for this discussion article is to point out why landmarks are indeed exaggerated in this research context and I will try to approach this claim from several perspectives. First, the research focus in this field is, unfortunately, mainly on visual landmarks. Second, other modalities than vision-e.g., auditory and/or olfactory senses-can be used for landmark-based wayfinding. Third, we need to clearly differentiate between conscious/effortful and unconscious/automatic processing of spatial information in the context of landmark-based wayfinding. Finally, I will suggest that landmarks, even if exaggerated in the visual domain, are (still) of significant importance in human wayfinding and spatial cognition.																	0933-1875	1610-1987															10.1007/s13218-020-00668-5		JUN 2020											
J								Wireless Sensor Network Based Smart Grid Supported by a Cognitively Driven Load Management Decision Making	NEURAL PROCESSING LETTERS										Cognitive radio; Decision making; Optimization; Smart grid; Spectrum allocation; Spectrum sensing	OPTIMIZATION; ALGORITHM; INTERNET; PROTOCOL	The Smart Grid (SG) provides the bi-directional flow of data to overcome problems like shortage of electricity, electricity billing, managing fault, home automation so on. For the transfer of data, the integration of Cognitive Radio (CR) in sensor networks makes efficient communication possible in real-time monitoring. SG uses different technologies like WiFi, cellular network, ZigBee, optical cables depending upon the area of application. For effective communication, CR is used to allocate the unutilized spectrum from the Primary User to the Secondary User by sensing. This paper proposes a technique called Fuzzy Long Sort Term Memory based Crow Search Optimization Algorithm (FLSTM-CSOA) to allocate the best available spectrum with minimum delay. By comparing our proposed method with the existing technique, the simulation result shows that the FLSTM-CSOA has better performance in terms of BER (10(-1)), throughput (200 kbps), and latency (10 ms).																	1370-4621	1573-773X				AUG	2020	52	1			SI		663	678		10.1007/s11063-020-10270-3		JUN 2020											
J								CALA-FOMF: a continuous action-set learning automata-based approach to finding optimized membership functions for fuzzy association rules in web usage data	SOFT COMPUTING										Continuous action-set learning automata; Fuzzy association rule; Membership function; Web usage mining	ALGORITHM; FRAMEWORK; LOG	Web usage data usually contain quantitative values, and this implies that fuzzy logic can be used to represent such values. The time spent by users on each web page is a part of web usage data, which can be used to analyze users' browsing behavior. In existing research on fuzzy web mining, the time duration of web pages is shown as trapezoidal membership functions (TMFs), and the number and parameters of TMFs are already predefined. TMFs of each web page are different from those of other web pages. Therefore, instead of using predefined TMFs, in this study, we proposed a new algorithm called CALA-FOMF to find both the number of TMFs and their optimized parameters to mine fuzzy association rules in web usage data using a team of continuous action-set learning automata (CALA). CALA-FOMF contained two steps. In the first step, using a team of CALA, we introduced a new framework. The proposed framework obtained the number of TMFs as inputs and found their optimized parameters. The proposed framework was able to reduce the search space and eliminate inappropriate membership functions during the learning process. In the second step, we proposed a new algorithm using the proposed framework to find an appropriate number of TMFs and their optimized parameters. The performance of the CALA-FOMF approach was compared with that of the fuzzy web mining algorithm, which used uniform TMFs. Experiments on datasets with different sizes confirmed that the proposed CALA-FOMF increased the efficiency of mining fuzzy association rules by extracting optimized TMFs.																	1432-7643	1433-7479															10.1007/s00500-020-05064-7		JUN 2020											
J								Genomic signal processing of microarrays for cancer gene expression and identification using cluster-fuzzy adaptive networking	SOFT COMPUTING										Genomic signal processing; Microarray data; Kalman filter; Grid density-based clustering; Fuzzy interference system and partition coefficient	ARTIFICIAL NEURAL-NETWORKS; PERFORMANCE ANALYSIS; CLASSIFICATION; SELECTION; MODEL; DNA	Genomic signal processing (GSP) is a functioning exploration area of recent times and a settled technique of digital signal processing for gathering information from genomic sequences. The recognition and identification of biological signals and analysis of sequences are the fundamental objectives of using GSP. Microarray data are typically used in GSP; microarray study decides genes that cause a specific disease and helps in anticipating and diagnosing a disease, and characterization of diseases. Microarray information is incredible innovation where information handled to an enormous number with plenty of genes. Recent research works show that microarray handling will be helpful for the classification of cancer genes. Different machine learning and artificial intelligence techniques are likewise used to distinguish the tumours and cancer cells. In this examination, the genomic signal processing is carried out utilizing cluster-fuzzy adaptive networking techniques. The major purpose of this research work is to evaluate the microarray data sets for recognizing the cancer genes. The microarray data set is generated using leukaemia, colon, prostate, breast cancer and lymphoma. Initially, the noise in the microarray is filtered and smoothened by utilizing a Kalman filter followed by an optimal clustering technique such as grid density-based clustering that is applied for clustering the microarray data sets. The clustered data of microarray are classified by adaptive neuro fuzzy interference system (ANFIS) for gene sequencing process of cancer identification. The adaptive network systems are developed based on autonomous networking concepts to change the static system into a dynamic. The efficiency of clustering is evaluated in terms of cluster indexes namely partition entropy, partition coefficient, Xie and Beni. The presented ANFIS is assessed in terms of precision, accuracy, recall, sensitivity, F-score and specificity. The proposed initiated methodology is mathematically designed and executed in the MATLAB platform and run for various test runs. During the implementation, the performance of cluster and classification efficiency of proposed techniques are compared with the existing strategies like fuzzy c-means with ANN and density-based clustering with ANN, respectively. Ultimately, the performance outcomes demonstrated that the proposed method can provide effective and optimal classification and identification of microarray cancer genes through genomic signal processing than the conventional methods, respectively.																	1432-7643	1433-7479															10.1007/s00500-020-05068-3		JUN 2020											
J								Children's perceptions of social robots: a study of the robots Pepper, AV1 and Tessa at Norwegian research fairs	AI & SOCIETY										Social robots; Human-robot interaction; Pepper; AV1; Tessa; Norway	TECHNOLOGIES; CARE	This article studies perceptual differences of three social robots by elementary school children of ages 6-13 years (n = 107) at research fairs. The autonomous humanoid robot Pepper, an advanced social robot primarily designed as a personal assistant with movement and mobility, is compared to the teleoperated AV1 robot-designed to help elementary school children who cannot attend school to have a telepresence through the robot-and the flowerpot robot Tessa, used in the eWare system as an avatar for a home sensor system and dedicated to people with dementia living alone. These three robots were shown at the Norwegian national research fair, held in every major Norwegian city annually, where children were able to interact with the robots. Our analysis is based on quantitative survey data of the school children concerning the robots and qualitative discussions with them. By comparing three different types of social robots, we found that presence can be differently understood and conceptualized with different robots, especially relating to their function and "aliveness." Additionally, we found a strong difference when relating robots to personal relations to one's own grandparents versus older adults in general. We found children's perceptions of robots to be relatively positive, curious and exploratory and that they were quite reflective on their own grandparent having a robot.																	0951-5666	1435-5655															10.1007/s00146-020-00998-w		JUN 2020											
J								CHIRPS: Explaining random forest classification	ARTIFICIAL INTELLIGENCE REVIEW										XAI; Model interpretability; Random forests; Classification; Frequent patterns	CLASSIFIERS; RULES	Modern machine learning methods typically produce "black box" models that are opaque to interpretation. Yet, their demand has been increasing in the Human-in-the-Loop processes, that is, those processes that require a human agent to verify, approve or reason about the automated decisions before they can be applied. To facilitate this interpretation, we propose Collection of High Importance Random Path Snippets (CHIRPS); a novel algorithm for explaining random forest classification per data instance. CHIRPS extracts a decision path from each tree in the forest that contributes to the majority classification, and then uses frequent pattern mining to identify the most commonly occurring split conditions. Then a simple, conjunctive form rule is constructed where the antecedent terms are derived from the attributes that had the most influence on the classification. This rule is returned alongside estimates of the rule's precision and coverage on the training data along with counter-factual details. An experimental study involving nine data sets shows that classification rules returned by CHIRPS have a precision at least as high as the state of the art when evaluated on unseen data (0.91-0.99) and offer a much greater coverage (0.04-0.54). Furthermore, CHIRPS uniquely controls against under- and over-fitting solutions by maximising novel objective functions that are better suited to the local (per instance) explanation setting.																	0269-2821	1573-7462				DEC	2020	53	8					5747	5788		10.1007/s10462-020-09833-6		JUN 2020											
J								An Effective Semi-fragile Watermarking Method for Image Authentication Based on Lifting Wavelet Transform and Feed-Forward Neural Network	COGNITIVE COMPUTATION										Watermarking; Image authentication and restoration; Tamper detection and recovery; Lifting wavelet transform; Halftone technique; Feed-forward neural network	TAMPER DETECTION; SCHEME; ALGORITHM; SVD; LOCALIZATION	Digital watermarking is a significant issue in the field of information security and avoiding the misuse of images in the world of Internet and communication. This paper proposes a novel watermarking method for tamper detection and recovery using semi-fragile data hiding, based on lifting wavelet transform (LWT) and feed-forward neural network (FNN). In this work, first, the host image is decomposed up to one level using LWT, and the discrete cosine transform (DCT) is applied to each 2x2 blocks of diagonal details. Next, a random binary sequence is embedded in each block as the watermark by correlating DC coefficients. In the authentication stage, first, the geometry is analyzed by using speeded up robust features (SURF) algorithm and extract watermark bits by using FNN. Afterward, logical exclusive or operation between original and extracted watermark is applied to detect tampered region. Eventually, in the recovery stage, tampered regions are recovered using the inverse halftoning technique. The performance and efficiency of the method and its robustness against various geometric, non-geometric, and hybrid attacks are reported. From the experimental results, it can be seen that the proposed method is superior in terms of robustness and quality of the watermarked and recovered images, respectively, compared to the state-of-the-art methods. Besides, imperceptibility has been improved by using different correlation steps as the gain factor for flat (smooth) and texture (rough) blocks. Based on the advantages exhibited, the proposed method outperforms the related works, in terms of superiority, efficiency, and effectiveness for tamper detection and recovery-based applications.																	1866-9956	1866-9964				JUL	2020	12	4					863	890		10.1007/s12559-019-09700-9		JUN 2020											
J								Segmenting the manufacturing industries and measuring the performance: using interval-valued triangular fuzzy TOPSIS method	COMPLEX & INTELLIGENT SYSTEMS										Triangular interval-valued fuzzy TOPSIS method; Chi square; Performance; Segmenting; Manufacturing industries	INFORMATION-TECHNOLOGY CAPABILITY; DECISION-MAKING; OPERATIONS; EXTENSION	In this globalized scenario, the overall performance of the manufacturing industries is the backbone of the development of the countries' economies. In this research, the authors' main objective of the study is to segment the manufacturing industries by using the triangular interval-valued fuzzy TOPSIS Method and find out the factors determining its performance. The researchers have collected the data from 350 manufacturing industries located in Puducherry, India. They applied a Simple Random sampling method by using a structured questionnaire from manufacturing industries. To analyze the data, the researchers used software packages like Excel, SPSS and LISREL 8.72. The researchers applied Confirmatory Factor Analysis, Triangular Interval-Valued Fuzzy TOPSIS Method, Chi square and Correspondent Analysis to conclude the result. Based on the factors loadings of the items, the contribution made by the items in respect of Performance may be ranked as Sales growth, Market share, Profit margin and Return on investment. With the help of Triangular Interval-Valued Fuzzy TOPSIS Method researchers segmented the manufacturing industries into three groups and by using the Chi square analysis the researchers found that the five demographics characteristics like Number of years in Business (Company), Scale of industry, Kind of manufacturing, Number of employees and location of the production plant of the respondents and these are significantly associated with segmenting the manufacturing industries and determine the performance of manufacturing industries.																	2199-4536	2198-6053				OCT	2020	6	3					591	606		10.1007/s40747-020-00157-0		JUN 2020											
J								On consistency and priority weights for interval probabilistic linguistic preference relations	FUZZY OPTIMIZATION AND DECISION MAKING										Probabilistic linguistic term sets (PLTs); Probabilistic linguistic preference relation (PLPR); Probabilistic Linguistic Geometric Consistency Index (PLGCI); Consistency measures; Interval weights	TERM SETS	When expressing preferences with different probability weights for different linguistic terms, only partial assessment information is usually to be provided. Then the probability information can be normalized to the interval probability, hence, using interval probabilistic linguistic term sets (IPLTs) is more appropriate. Considering this situation, interval probabilistic linguistic preference relation (IPLPR) is proposed. To measure the consistency of IPLPR, the consistency definition of IPLPR is put forward. For the consistent IPLPR, from which an expected consistent PLPR can be obtained, we can obtain interval weights as the final priorities by using the pairs of linear programming models. We also create the probabilistic linguistic geometric consistency index (PLGCI) of PLPRs to judge whether the IPLPR is satisfactorily consistent. For an unsatisfied consistency IPLPR, the adjusting algorithm is proposed. Probability information is firstly considered to be adjusted. If it is not possible to achieve satisfactory consistency through the adjustment of probability information, then the linguistic terms will be adjusted. In addition to examples of different situations, such as the consistency, satisfactory consistency and consistency improvement, the application example is also given to show the practicability of the proposed methods.																	1568-4539	1573-2908															10.1007/s10700-020-09328-7		JUN 2020											
J								Flood hazard assessment based on fuzzy clustering iterative model and chaotic particle swarm optimization	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Flood hazard assessment; Evolutionary computation; Particle Swarm Optimization (PSO); Fuzzy clustering Iterative (FCI); Chaotic map	ALGORITHM	The target of flood hazard assessment is to establish appropriate casualty evaluation models for managing flood and alleviating loss affected by flood. Existing challenges on evaluating flood hazard level focus on how to achieve a stable and high-resolution result according to the incompatibilities between multiple attribute indicators. Base on the chaotic optimization theory, this study presents a chaotic particle swarm optimization (CPSO) algorithm to deal with a fuzzy clustering iterative model (CPSO-FCI) for evaluating flood hazards. By using a celebrated logistic chaotic map and a penalty function, the target function can be tackled more perfectly. The effectiveness of the novel hybrid method is evaluated by three representative test functions and two sets of practical flood disaster samples in China. Simulation results and comparisons show that the presented CPSO based on the logistic map is competitive and stable in performance with standard particle swarm optimization (PSO) and other advanced PSO-type approaches introduced in the literature. High resolution continuous flood rating results are obtained for fine-tune flood management.																	1868-5137	1868-5145															10.1007/s12652-020-02109-5		JUN 2020											
J								IoT using machine learning security enhancement in video steganography allocation for Raspberry Pi	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Machine learning framework; IoT; Artificial intelligence; Raspberry Pi; USB webcam		Billions of physical gadgets are by and by associated with the Internet molding the Internet of Things (IoT). These gadgets are making a more proportion of helpful or pointless data. The transmission and getting ready of this data is a trying errand. Diverse IoT applications and future research bearing are in like manner talked. One of the unquestionable application parts of IoT framework is in the Security Sector. It is basic to an uncommon negligible exertion answer for check wrongdoing and assurance security to people from the home, military, business, and so on. This paper using Raspberry Pi IoT establishment includes the portrayal driven progression process for AI Security System. It remarks the livelihoods of client end demand, for instance, to securely transmit information through the layers of IoT designing. It goes for giving a low-control, monetarily sense and normal IoT dependent on security AI system which helps proximity ID, unmistakable 98% evidence and confirmation of pariahs. The course of action makes usage of USB Webcam as an image getting unit, electric entryway hit as an actuator which gives application programming interfaces (APIs) to collect game plans which is flawless with IoT foundation of improvement for video steganography distribution for Raspberry Pi.																	1868-5137	1868-5145															10.1007/s12652-020-02126-4		JUN 2020											
J								Flexible development of location-based mobile augmented reality applications with AREA Implementation of a serious game shows the flexibility of AREA	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobile augmented reality; Location-based algorithms; Mobile application engineering; Serious game; Mobile augmented reality game		Mobile applications have garnered a lot of attention in the last years. The computational capabilities of mobile devices are the mainstay to develop completely new application types. The provision of augmented reality experiences on mobile devices paves one alley in this field. For example, in the automotive domain, augmented reality applications are used to experience, inter alia, the interior of a car by moving a mobile device around. The device's camera then detects interior parts and shows additional information to the customer within the camera view. Another application type that is increasingly utilized is related to the combination of serious games with mobile augmented reality functions. Although the latter combination is promising for many scenarios, technically, it is a complex endeavor. In the AREA (Augmented Reality Engine Application) project, a kernel was implemented that enables location-based mobile augmented reality applications. Importantly, this kernel provides a flexible architecture that fosters the development of individual location-based mobile augmented reality applications. The work at hand shows the flexibility of AREA based on a developed serious game. Furthermore, the algorithm framework and major features of it are presented. As the conclusion of this paper, it is shown that mobile augmented reality applications require high development efforts. Therefore, flexible frameworks like AREA are crucial to develop respective applications in a reasonable time.																	1868-5137	1868-5145															10.1007/s12652-020-02094-9		JUN 2020											
J								Cost-oriented robotic assembly line balancing problem with setup times: multi-objective algorithms	JOURNAL OF INTELLIGENT MANUFACTURING										Assembly line balancing; Robotic assembly line; Setup times; Multi-objective optimization; Metaheuristics	GENETIC ALGORITHM; HEURISTIC METHODS; MATHEMATICAL-MODEL; ENERGY-CONSUMPTION; SCHEDULING TASKS; CYCLE TIME; METAHEURISTICS; CARBON	Robots are extensively used during the era of Industry 4.0 to achieve high productivity, better quality and lower cost. While designing a robotic assembly line, production managers are concerned about the cost involved in such a system development. Most of the research reported till date did not consider purchasing cost while optimizing the design of a robotic assembly line. This study presents the first attempt to study the cost-oriented robotic assembly line balancing problem with setup times to minimize the cycle time and total purchasing cost simultaneously. A mixed-integer linear programming model is developed to formulate this problem. The elitist non-dominated sorting genetic algorithm (NSGA-II) and improved multi-objective artificial bee colony (IMABC) algorithm are developed to achieve a set of Pareto solutions for the production managers to utilize for selecting the better design solution. The proposed IMABC develops new employed bee phase and scout phase, which selects one solution in the permanent Pareto archive to replace the abandoned solution, to enhance exploration and exploitation. The comparative study on a set of generated instances demonstrates that the proposed model is capable of achieving the proper tradeoff between line efficiency and purchasing cost, and the proposed NSGA-II and IMABC achieve competing performance in comparison with several other multi-objective algorithms.																	0956-5515	1572-8145															10.1007/s10845-020-01598-7		JUN 2020											
J								Milling force prediction model based on transfer learning and neural network	JOURNAL OF INTELLIGENT MANUFACTURING										Cutting force; Neural network; Transfer learning; Prediction	SURFACE-ROUGHNESS; CUTTING FORCES; REGRESSION; STEEL; WEAR	In recent years, the growing popularity of artificial neural networks has urged more and more researchers to try introduce these methods to the machining field, with some of them actually producing good results. The acquisition of cutting data often means higher cost and time, limiting the application of neural network in the machining sector, to a certain extent. In this paper, for the task of cutting force prediction, a "transfer network" was established, based on data obtained by simulation, combined with the theory and method in the field of transfer learning. Compared to "ordinary network", that is, traditional back-propagation neural network based on experimental samples alone, transfer network exhibits obvious performance advantages. On one hand, this means that, using the same experimental samples, the prediction error of transfer network will be controlled; while on the other hand, when the same prediction error is achieved, the number of experimental samples required by the transfer network will be less.																	0956-5515	1572-8145															10.1007/s10845-020-01595-w		JUN 2020											
J								TOPSIS Evaluation System of Logistics Transportation Based on an Ordered Representation of the Polygonal Fuzzy Set	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Polygonal fuzzy set; Ordered representation; Euclidean metric; Logistics transportation; Positive (negative) ideal solution; Degree of relative closeness; TOPSIS method	ATTRIBUTE DECISION-MAKING; MODELS	The polygonal fuzzy set is an effective tool to approximate the general fuzzy set by means of a finite number of ordered real numbers. It not only overcomes the shortcomings (which does not satisfy the closeness) of arithmetic operations of fuzzy sets based on Zadeh extension principle, but also realizes the non-linear operation of general fuzzy sets by an ordered representation of the polygonal fuzzy set. In this paper, the definition, geometric interpretation, ordered representation and arithmetic operations of the polygonal fuzzy sets are introduced for the first time, and the method of solving polygonal fuzzy sets and their ordered representation based on convex fuzzy sets are given by an example. Second, a new Euclidean metric of polygonal fuzzy sets is proposed, and the approximation accuracy of polygonal fuzzy sets to convex fuzzy sets is discussed. In addition, the linear function describing transportation cost index information of logistics companies is obtained through the ordered representation of Gauss membership function, and according to the ordered representation a new normalization method for the polygonal decision matrix is given. Finally, the method of solving the positive (negative) ideal solution and degree of relative closeness of the polygonal decision matrix is suggested by the weighted Euclidean distance. Then a new TOPSIS evaluation system is established, and the effectiveness of the proposed method is illustrated by an example of logistics transportation.																	1562-2479	2199-3211				JUL	2020	22	5					1565	1581		10.1007/s40815-020-00861-6		JUN 2020											
J								Fuzzy Moderation and Moderated-Mediation Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Moderator variable; Moderation analysis; Moderated-mediation analysis; Fuzzy moderation analysis; Fuzzy moderated-mediation analysis; Fuzzy number; Fuzzy data; Fuzzy least squares estimation (FLSE)	LEAST-SQUARES ESTIMATION; BEHAVIOR; MEMBERS	In the causal relationship, a mediator variable is a variable that causes mediation in the dependent and the independent variables. If x is a predictor and y is a response variable, then w is a moderator variable that influences the causal relationship of x and y. A moderator variable is a variable that affects the strength of the relationship between a dependent and independent variable. When there are many complicated causal relations, a mediation analysis or a moderation analysis can be performed considering the existence of mediators or moderators. Moreover, when both mediators and moderators exist, a mediation-moderation analysis can be performed. The existence of these variables occurs in many fields, including social science, medical science, and natural science, etc. However, the values of such variables used are often observed as fuzzy numbers rather than as crisp numbers (real numbers). So in many cases, fuzzy analysis is required because observations are observed with ambiguous values, but in the meantime, only models that use crisp numbers rather than fuzzy numbers have been used. This paper proposes fuzzy moderation analysis and fuzzy moderated-mediation analysis as the first attempts of the moderation and moderated-mediation analysis using fuzzy data. The proposed models can also be used for science and engineering, medical data, but it can also be applied to the humanities fields, where a lot of ambiguous data are observed. For example, data from the humanities fields such as marketing, education or psychology, the data are observed based on a human's mind. Nevertheless, they have been analyzed using crisp data so far. In this paper, we define several fuzzy moderation models and fuzzy mediation-moderation models considering various situations based on fuzzy least squares estimation (FLSE). In addition, the validity of the proposed model is shown in some examples; it compares the results with existing analysis using crisp data.																	1562-2479	2199-3211				SEP	2020	22	6			SI		1948	1960		10.1007/s40815-020-00848-3		JUN 2020											
J								Design of Kinematic Controller Based on Parameter Tuning by Fuzzy Inference System for Trajectory Tracking of Differential-Drive Mobile Robot	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Kinematic controller; Differential-drive mobile robots; Lyapunov stability theory; Fuzzy technique		This paper proposes a new kinematic controller (KC) when designing an autonomous mobile robot with type of differential-drive model in trajectory tracking control. The KC is responsible for creating the reference values of velocities transmitted to the robot dynamics. To design the KC, we present a simple and effective way of actualizing the KC based on the extended nonlinear kinematic model of the differential-drive mobile robots. The stability of the tracking system with the proposed KC is proved based on the Lyapunov stability theory. Moreover, the fuzzy technique is also applied to the KC to enhance the quality of the tracking control when the reference trajectory has rapid changes in terms of coordinates or velocities. In this study, the computer simulation results show the high feasibility of the proposed KC.																	1562-2479	2199-3211				SEP	2020	22	6			SI		1972	1978		10.1007/s40815-020-00842-9		JUN 2020											
J								Simple and fast spectrophotometric method based on chemometrics for the measurement of multicomponent adsorption kinetics	JOURNAL OF CHEMOMETRICS										adsorption kinetics; multiway partial least squares; quercetin; rutin; UV-Vis spectrophotometer	PERFORMANCE LIQUID-CHROMATOGRAPHY; PHASE-ADSORPTION; FLAVONOIDS; QUERCETIN; ANTHOCYANINS; PURIFICATION; SPECTROSCOPY; POLYPHENOLS; ISOTHERM; RESINS	UV-Vis spectrophotometry has been widely applied in the quantitative analysis of different analytes in many fields, but it still faces challenges in the analysis of multicomponent solutions due to strong spectral overlap and low selectivity. In this paper, UV-Vis spectrophotometric method combined with chemometrics algorithms was established for the simultaneous determination of liquid-phase adsorption kinetics of multicomponent for the first time. Partial least squares (PLS), stepwise regression, and multiway PLS (N-PLS) models were established by using the original spectrum and processed spectrum pretreated by two different methods. The prediction results were validated by high-performance liquid chromatography (HPLC). N-PLS model showed the best prediction ability and the prediction relative error was within 9%. Adsorption kinetics studies indicated that the pseudo-second-order model can describe the adsorption behavior of rutin and quercetin on AB-8 resin more accurately. This method was fast, low cost, accurate and reliable, simple, and efficient for the determination of multicomponent liquid-phase adsorption kinetics.																	0886-9383	1099-128X				AUG	2020	34	8							e3249	10.1002/cem.3249		JUN 2020											
J								Towards the cognitive and psychological perspectives of crowd behaviour: a vision-based analysis	CONNECTION SCIENCE										Crowd behaviour analysis; smart surveillance; crowd psychology; cognitive computing; cognitive psychology	ANOMALY DETECTION; NEURAL-NETWORKS; SYSTEM; LOCALIZATION; PERSONALITY; MODEL	Smart and proactive surveillance of crowds has turned up into greater importance in recent years due to the increase in urban population and immutable crowd disasters. Although the behaviours that emerged in a crowd are often unpredictable, researches in computer vision try to figure out this emergent behaviour based on the psychological and cognitive aspects of the crowd. This review is intended to analyse the insights shared from these aspects for analysing crowd behaviour. We also try to uncover the crowd psychological theories present in the literature that largely helps in determining the non-adaptive crowd behaviours. Further, this paper discusses an outlook of state-of-the-art psychological, cognitive computing and cognitive psychological approaches of crowd behaviour analysis. This paper also provides a discussion on the benchmark datasets available for vision-based crowd analysis. The comprehensive discussion and insights based on crowd psychology and cognition will provide a deep understanding of the fundamental prospects of smart crowd behaviour analysis.																	0954-0091	1360-0494															10.1080/09540091.2020.1772723		JUN 2020											
J								Generalized dice similarity measures for q-rung orthopair fuzzy sets with applications	COMPLEX & INTELLIGENT SYSTEMS										Pythagorean fuzzy sets; q-Rung orthopair fuzzy sets; Dice similarity measures; Generalized dice similarity measures	AGGREGATION OPERATORS; DISTANCE; ENTROPY	Recently, Yager has established that the notion of q-rung orthopair fuzzy set (q-ROFS) is more accomplished than pythagorean fuzzy set (PyFS) and intuitionistic fuzzy set (IFS) to cope with awkward and complicated information in real decision theory. This notion works with yes-, no- and refusal-type fuzzy information. The constraint of q-ROFS is that the sum of n-power of the truth grade and the n-power of the falsity grade is bounded to unit interval. Generalized dice similarity measures are complimentary concepts quantifying the difference and closeness of q-ROFSs. In this paper, we suggested a number of novel dice similarity measures (DSMs) in the surroundings of the q-ROFS, and we examined some prevailing dice similarity measures and their limitations. In addition, we took the DSMs broad view to some globalized dice similarity measures (GDSMs), and we examined some of their particular cases. We employed the novel suggested GDSMs to the best selections of items on identification problems, and we analyzed their acquired consequences. There is a development of novel work in which many situations are evaluated, and from this perspective, the suggested work is changed into already prevailing work. This study also examines the merits of novel DSMs and the limitations for DSMs of IFSs and PyFSs. The comparison between established measures with existing measures is explored and their graphical interpretations are also discussed to show the reliability and effectiveness of the explored measures.																	2199-4536	2198-6053				OCT	2020	6	3					545	558		10.1007/s40747-020-00145-4		JUN 2020											
J								New ranking method for normal intuitionistic sets under crisp, interval environments and its applications to multiple attribute decision making process	COMPLEX & INTELLIGENT SYSTEMS										Multiple attribute decision-making; Interval-valued set; Normal distribution functions; Normal intuitionistic fuzzy set; Score function	SCORE FUNCTION; FUZZY-SETS; ACCURACY FUNCTION	The aim of this paper is to present novel algorithms for solving the multiple attribute decision-making problems under the normal intuitionistic fuzzy set environment. Normal intuitionistic and interval-valued intuitionistic sets are the essential mechanisms for influencing the decision-making queries with anonymous and indeterminant data by engaging a degree of membership and non-membership of normal distribution data in quantitative terms. Holding these features in mind and united the idea of hesitation degree, this paper presents some improved score functions to rank the normal intuitionistic and interval-valued intuitionistic sets. The advantage of these proposed functions is to overwhelm the weakness of the existing functions and will aid to rank the given objects in a more consistent way. The numerous salient features of the proposed functions are studied. Later, we develop two new algorithms for interval-valued as well as crisp numbers based on the proposed functions to solve multiple attribute decision-making problems. The given approaches have been confirmed with numerical examples and the advantages, as well as comparative analysis, are furnished to shows its influence over existing approaches.																	2199-4536	2198-6053				OCT	2020	6	3					559	571		10.1007/s40747-020-00150-7		JUN 2020											
J								Success prediction of android applications in a novel repository using neural networks	COMPLEX & INTELLIGENT SYSTEMS										Repository; Success and failure; Successful application; Failed application; Data set; Android		Nowadays, Android applications play a major role in software industry. Therefore, having a system that can help companies predict the success probability of such applications would be useful. Thus far, numerous research works have been conducted to predict the success probability of desktop applications using a variety of machine learning techniques. However, since features of desktop programs are different from those of mobile applications, they are not applicable to mobile applications. To our knowledge, there has not been a repository or even a method to predict the success probability of Android applications so far. In this research, we introduce a repository composed of 100 successful and 100 unsuccessful apps of Android operating system in Google PlayStore (TM) including 34 features per application. Then, we use the repository to a neural network and other classification algorithms to predict the success probability. Finally, we compare the proposed method with the previous approaches based on the accuracy criterion. Experimental results show that the best accuracy which we achieved is 99.99%, which obtained when we used MLP and PCA, while the best accuracy achieved by the previous work in desktop platforms was 96%. However, the time complexity of the proposed approach is higher than previous methods, since the time complexities of NPR and MLP are O(n(3)) and O(nph(k)oi), respectively.																	2199-4536	2198-6053				OCT	2020	6	3					573	590		10.1007/s40747-020-00154-3		JUN 2020											
J								Bio-inspired artificial pheromone system for swarm robotics applications	ADAPTIVE BEHAVIOR										Pheromone communication; bio-inspired; swarm robotics; artificial pheromone	COMMUNICATION; WOMEN; BEE; ANT	Pheromones are chemical substances released into the environment by an individual animal, which elicit stereotyped behaviours widely found across the animal kingdom. Inspired by the effective use of pheromones in social insects, pheromonal communication has been adopted to swarm robotics domain using diverse approaches such as alcohol, RFID tags and light. COS phi is one of the light-based artificial pheromone systems which can emulate realistic pheromones and environment properties through the system. This article provides a significant improvement to the state-of-the-art by proposing a novel artificial pheromone system that simulates pheromones with environmental effects by adopting a model of spatio-temporal development of pheromone derived from a flow of fluid in nature. Using the proposed system, we investigated the collective behaviour of a robot swarm in a bio-inspired aggregation scenario, where robots aggregated on a circular pheromone cue with different environmental factors, that is, diffusion and pheromone shift. The results demonstrated the feasibility of the proposed pheromone system for use in swarm robotic applications.																	1059-7123	1741-2633														UNSP 1059712320918936	10.1177/1059712320918936		JUN 2020											
J								The socio-normative nature of representation	ADAPTIVE BEHAVIOR										Internal representation; social normativity; enactivism; teleosemantics; anti-representationalism; Charles Sanders Peirce	COGNITIVE NEUROSCIENCE; SIMILARITY	This article tries to offer a different perspective on the issue of what it means for some physical structure to be a representation. In the first sections, it will be shown how and why this issue is still far from settled. This will be done by emphasizing the-what I will call-metaphysically promiscuous character of representation. For although representations are typically assumed to be some sort of physical objects or structures, on closer inspection, the notion of representation is used in such a variety of ways that its fundamental metaphysical status is far from obvious. Proceeding from these observations, it will be argued that, even though "representation" pre-theoretically indeed often picks out objects, their representational status is best not understood in terms of their physical properties or their causal-functional profile. It will be argued that, what it means for some physical structure to be-as a matter of fact-a representation, only first becomes intelligible in relation to certain socio-normative practices in which the cognitive capacity to relate to something as something it is not is prescriptively called upon. Moreover, an answer to the oft-heard question of what makes something (i.e., some physical object or structure) a representation is readily available, provided we take into account certain cognitive abilities, as well as a socio-normative context in which these abilities are normatively regulated. It will be concluded that at the fundamental metaphysical level, the phenomenon of representation is best understood as a triadic relation which involves, but does not reduce to, certain physical objects or structures. Finally, this socio-normative account of representation will be compared with two dominant notions of representation within cognitive science: symbolic representation and S-representation.																	1059-7123	1741-2633														1059712320922364	10.1177/1059712320922364		JUN 2020											
J								TEAGS: time-aware text embedding approach to generate subgraphs	DATA MINING AND KNOWLEDGE DISCOVERY										Time-aware word embedding; Neural networks; Subgraph generation; Latent models; Propagation graphs	MAINTENANCE; ANALYTICS; SYSTEMS	Contagions (e.g. virus and gossip) spread over the nodes in propagation graphs. We can use temporal-textual contents of nodes to compute the edge weights and generate subgraphs with highly relevant nodes. This is beneficial to many applications. Yet, challenges abound. First, the propagation pattern between each pair of nodes may change by time. Second, not always the same contagion propagates. Hence, current text mining approaches including topic-modeling cannot effectively compute the edge weights. Third, since the propagation is affected by time, the word-word co-occurrence patterns may differ in various temporal dimensions which adversely impacts the performance of word embedding approaches. We argue that multi-aspect temporal dimensions (hour, day, etc) should be considered to better calculate the correlation weights between the nodes. In this work, we devise a novel framework that on the one hand, integrates a time-aware word embedding component to construct the word vectors through multiple temporal facets, and on the other hand, uses a time-only multi-facet generative model to compute the weights. Subsequently, we propose a Max-Heap Graph cutting algorithm to generate subgraphs. We validate our model through experiments on real-world datasets. The results show that our model can generate the subgraphs more effective than other rivals and temporal dynamics must be adhered in the modeling of the dynamical processes.																	1384-5810	1573-756X				JUL	2020	34	4					1136	1174		10.1007/s10618-020-00688-7		JUN 2020											
J								ABBA: adaptive Brownian bridge-based symbolic aggregation of time series	DATA MINING AND KNOWLEDGE DISCOVERY										Time series; Symbolic aggregation; Dimension reduction; Brownian bridge	REPRESENTATION	A new symbolic representation of time series, called ABBA, is introduced. It is based on an adaptive polygonal chain approximation of the time series into a sequence of tuples, followed by a mean-based clustering to obtain the symbolic representation. We show that the reconstruction error of this representation can be modelled as a random walk with pinned start and end points, a so-called Brownian bridge. This insight allows us to make ABBA essentially parameter-free, except for the approximation tolerance which must be chosen. Extensive comparisons with the SAX and 1d-SAX representations are included in the form of performance profiles, showing that ABBA is often able to better preserve the essential shape information of time series compared to other approaches, in particular when time warping measures are used. Advantages and applications of ABBA are discussed, including its in-built differencing property and use for anomaly detection, and Python implementations provided.																	1384-5810	1573-756X				JUL	2020	34	4					1175	1200		10.1007/s10618-020-00689-6		JUN 2020											
J								An efficient approach for sentiment analysis using machine learning algorithm	EVOLUTIONARY INTELLIGENCE										Semantic analysis; Machine learning algorithms; Preprocessing; Accuracy; Optimization	ECOSYSTEM	Sentimental analysis determines the views of the user from the social media. It is used to classify the content of the text into neutral, negative and positive classes. Various researchers have used different methods to train and classify twitter dataset with different results. Particularly when time is taken as constraint in some applications like airline and sales, the algorithm plays a major role. In this paper an optimization based machine learning algorithm is proposed to classify the twitter data. The process was done in three stages. In the first stage data is collected and preprocessed, in the second stage the data is optimized by extracting necessary features and in the third stage the updated training set is classified into different classes by applying different machine learning algorithms. Each algorithm gives different results. It is observed that the proposed method i.e., sequential minimal optimization with decision tree gives good accuracy of 89.47% compared to other machine learning algorithms.																	1864-5909	1864-5917															10.1007/s12065-020-00429-1		JUN 2020											
J								Event-Triggered Adaptive Fuzzy Tracking Control for Nonlinear Systems	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Tracking control; Event-triggered control; Adaptive fuzzy control	BACKSTEPPING CONTROL; FEEDBACK; NETWORK	In this paper, the problem of event-triggered adaptive fuzzy tracking control for nonlinear systems with external disturbance is explored. The fuzzy logic system method is utilized to design the event-triggered adaptive controller under two different event-triggered mechanisms to ensure that the tracking error converges to zero in any small neighborhood, and all the signals in the closed loop systems are bounded. In addition, two different ways are given to prove that the Zeno phenomenon will not occur. Finally, two simulation examples are given to demonstrate the validity of the proposed control scheme.																	1562-2479	2199-3211				JUL	2020	22	5					1389	1399		10.1007/s40815-020-00872-3		JUN 2020											
J								An Attitudinal Nonlinear Integral and Applications in Decision Making	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy measures; Nonlinear integrals; Attitudinal character; Generalized golden rule representative values; Interactive multi-criteria decision making	VALUES; SETS	In the field of information fusion and decision making, integral is very common and important for aggregating a large variety of information. The integral to be used is usually nonlinear due to the nonadditive measure determined by the real world. In this study, we put forward a new nonlinear integral, which is first expressed as an interval, containing the infimum and supremum of the integrand on the nonadditive measure. Furthermore, an attitudinal nonlinear integral is defined by introducing the subjective attitude of the decision maker based on the integral interval obtained. A multi-criteria decision-making (MCDM) method considering the interaction between attribute features is developed based on the proposed attitudinal nonlinear integral and a case study is provided to demonstrate the usefulness of the decision-making method. Inspired by the golden rule representation, we define the generalized golden rule representative value of the interval integral and use it to solve the problem in the case study to illustrate its usefulness.																	1562-2479	2199-3211															10.1007/s40815-020-00862-5		JUN 2020											
J								Modified ride-NN optimizer for the IoT based plant disease detection	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet of things; Plant disease detection; Segmentation; SCA; RideNN	RECOGNITION; SUPERPIXEL	Internet of Things (IoT) has emerged prolifically in the recent years as they aid in lot of applications. In reference to the agriculture sector, automated technologies for the plant disease recognition have varying benefits, and at the same time has potential challenges. In this work, an automated plant disease detection model has been developed for the IoT environment. The proposed scheme places the nodes over the simulation environment for capturing the plant leaf images. The system maintains a sink node, which collects the information from the automated plant disease detection module and helps in IoT based monitoring. The images from the nodes are pre-processed through the median filter for making it suitable for the plant disease detection. Then, the segmentation is done over the image, and from the image, segment level and the pixel level features are extracted. This work develops a novel classifier, named sine cosine algorithm based rider neural network (SCA based RideNN) for the disease detection such that the weights in the neural network are chosen optimally. The entire detection performance is validated using the metrics, like accuracy, sensitivity, specificity, and energy of nodes on different IoT environments. The simulation results reveal that the proposed approach has improvement detection performance with the accuracy of 0.9156.																	1868-5137	1868-5145															10.1007/s12652-020-02051-6		JUN 2020											
J								Computer aided manufacturing method for surface silicon steel inspection based on an efficient anisotropic diffusion algorithm	JOURNAL OF INTELLIGENT MANUFACTURING										Silicon steel images; Texture; Defect detection; Anisotropic diffusion; Image filtering; Saliency map	DEFECT DETECTION; FILTER; IMAGE; MODEL	Quality control in silicon steel manufacturing process is a crucial step. The application of image processing techniques is very useful in steel inspection and manufacturing. It has established to be the most reliable and promising solution for the development of an automatic defect detection. Since the surface of the silicon steel strip has a cluttered background and defects with small sizes, flaws detection becomes a complex task. In this paper a novel rapid algorithm based on anisotropic diffusion and saliency map is proposed for detection of defects in images of hot rolled silicon steel. The algorithm first adopted a saliency map to enhance defects. Then the computed saliency map was employed in the anisotropic diffusion coefficient function as an orientation guide of the diffusion flow. The aim behind using salient feature is that a small defect can frequently attract attention of human eyes which permits to identify defects in high textured image. Finally, the defects were extracted using a local threshold operator. To verify the validity of the proposed algorithm, extensive experiments were realized on an image database of silicon steel strip then a comparison with traditional diffusion algorithms was given. Experimental results show that this method achieves accuracy and outperforms traditional methods in terms of accuracy and robustness.																	0956-5515	1572-8145															10.1007/s10845-020-01601-1		JUN 2020											
J								A cyber-physical system deployment based on pull strategies for one-of-a-kind production with limited resources	JOURNAL OF INTELLIGENT MANUFACTURING										Pull strategy; One-of-a-kind production; Cyber-physical system; Lean production	HYBRID FLOW-SHOP; CONWIP; RELEASE; DESIGN	In smart manufacturing practices, finding a balance between the size of cyber-physical system (CPS) deployment and the performance of production systems is the preliminary goal pursued by some small or medium-sized one-of-a-kind production enterprises with limited resources in implementing the transformation of smart production systems. To achieve this goal, we first address the pull control strategies in lean production systems as a principle to guide the CPS deployment for shop floors. Specifically, we use the Path-based bottleneck (PBB), Constant work-in-process (CONWIP), and Capacity-slack CONWIP (CSC) as pull CPS deployment schemes, in which the CSC is a modified CONWIP strategy that integrates the order review function of the PBB. We summarize the characteristics of these pull control strategies and analyze important roles in guiding the CPS deployment. Then, we compare the performance of the three pull control strategies by simulation. Our findings show that it is feasible to get the balance between the size of CPS deployment and the system performance through a suitable pull control strategy to guide CPS deployment. Finally, we introduce a case of a strander manufacturer and use the case data to estimate the performance and implementation costs of the CPS deployment schemes which are guided by pull control strategies.																	0956-5515	1572-8145															10.1007/s10845-020-01589-8		JUN 2020											
J								A novel real-time fall detection method based on head segmentation and convolutional neural network	JOURNAL OF REAL-TIME IMAGE PROCESSING										Computer vision; Fall detection; Head segmentation; Real-time image processing; Time series motion features	HASHING-BASED APPROACH; SERVICE RECOMMENDATION; SURVEILLANCE	As the computer vision develops, real-time fall detection based on computer vision has become increasingly popular in recent years. In this paper, a novel real-time indoor fall detection method based on computer vision by using geometric features and convolutional neural network (CNN) is proposed. Gaussian mixture model (GMM) is applied to detect the human target and find out the minimum external elliptical contour. Differently from the traditional fall detection method based on geometric features, we consider the importance of the head in fall detection and propose to use two different ellipses to represent the head and the torso, respectively. Three features including the long and short axis ratio, the orientation angle and the vertical velocity are extracted from the two different ellipses in each frame, respectively, and fused into a motion feature based on time series. In addition, a shallow CNN is applied to find out the correlation between the two elliptic contour features for detecting indoor falls and distinguishing some similar activities. Our novel method can effectively distinguish some similar activities in real time, which cannot be distinguished by some traditional methods based on geometric features, and has a better detection rate.																	1861-8200	1861-8219															10.1007/s11554-020-00982-z		JUN 2020											
J								Powering DNA strand-displacement reactions with a continuous flow reactor	NATURAL COMPUTING										DNA strand-displacement; Microreactor; Microfluidics; DNA computation	ENZYME-BIOCATALYZED REACTIONS; LOGIC GATES; NETWORKS; COMPUTATION; CIRCUITS; CELLS	Living systems require a sustained supply of energy and nutrients to survive. These nutrients are ingested, transformed into low-energy waste products, and excreted. In contrast, synthetic DNA strand-displacement reactions typically run within closed systems provided with a finite initial supply of reactants. Once the reactants are consumed, all net reactions halt and the system ceases to function. Here we run DNA strand-displacement reactions in a continuous flow reactor, infusing fresh reactants and withdrawing waste, enabling the system to dynamically update its outputs in response to changing inputs. Running DNA strand-displacement reactions inside of continuous flow reactors allows the system to be re-used for multiple rounds of computation, which could enable the execution of more elaborate information processing tasks, including single-rail negation and sequential logic circuits.																	1567-7818	1572-9796															10.1007/s11047-020-09795-2		JUN 2020											
J								Deep metric learning for open-set human action recognition in videos	NEURAL COMPUTING & APPLICATIONS										Human action recognition; Open-set recognition; Metric learning; Extreme value machine	SUPPORT	Human action recognition (HAR) is a topic widely studied in computer vision and pattern recognition. Despite the success of recent models for this issue, most of them approach HAR from the closed-set perspective. The closed-set recognition works under the assumption that all classes are known a priori and they appear during the training and test phase. Unlike most previous works, we approach HAR from the open-set perspective, that is, previously unknown classes are considered in the model. Additionally, feature extraction for HAR in the context of open set is still underexplored in the recent literature, since one needs to represent known classes with a low intra-class variance to reject unknown examples. To achieve this task, we propose a deep metric learning model named triplet inflated 3D convolutional neural network (TI3D), which builds upon the well-known I3D model. TI3D is a representation learning model that takes as input video sequences and outputs 256-dimensional representations. We perform extensive experiments and statistical comparisons on the UCF-101 dataset using a 30-fold cross-validation procedure in 25 different scenarios with varying degrees of openness and a varying number of training and test classes. Results reveal that the proposed TI3D achieves better performance than non-metric learning models in terms of F-1 score and Youdens index, indicating a promising approach for open-set video action recognition.																	0941-0643	1433-3058															10.1007/s00521-020-05009-z		JUN 2020											
J								Real-time state-of-health monitoring of lithium-ion battery with anomaly detection, Levenberg-Marquardt algorithm, and multiphase exponential regression model	NEURAL COMPUTING & APPLICATIONS										Anomaly detection; Lithium-ion battery; Levenberg-Marquardt algorithm; Multiphase exponential regression; State of health; Voltage; Temperature	USEFUL LIFE PREDICTION; CHARGE ESTIMATION; NEURAL-NETWORKS; PROGNOSTICS; TEMPERATURE; RESISTANCE; VOLTAGE; FILTER	The state of health (SOH) of lithium-ion (Li+) battery prediction plays significant roles in battery management and the determination of the durability of the battery in service. This study used segmentation-type anomaly detection, the Levenberg-Marquardt (LM) algorithm, and multiphase exponential regression (MER) model to determine SOH of the Li+ batteries. By determining the changepoint boundaries using the characteristic values such as voltage transition rate (VTR), temperature transition rate (TTR), and charge capacities of the Li+ battery at the changepoint timestamps, we determined the parametric values of the biphasic MER. The characteristic transition rate values, which depend on the transition probabilities of the rolling standard deviations of the measured voltage and temperature, were later utilized with the matching charge capacities to model various training-testing dataset combinations. This helped to estimate the SOH of the battery at different life-cycle phases. This study also developed a technique for real-time estimation of the remaining useful life of the battery by using the MER model parameters, VTR, and TTR which were previously unseen parametric values of the Li+ battery. The result obtained from the proposed model indicates that our technique will be effective for online SOH estimation of Li+ batteries.																	0941-0643	1433-3058															10.1007/s00521-020-05031-1		JUN 2020											
J								Enhancing performance of cell formation problem using hybrid efficient swarm optimization	SOFT COMPUTING										Cell formation problem; Exceptional elements; Grouping efficacy; Hybrid optimization; Monarch butterfly; Firefly algorithm	GENETIC ALGORITHM; ALTERNATIVE ROUTINGS; NEIGHBORHOOD SEARCH; MATHEMATICAL-MODEL; FIREFLY ALGORITHM; EFFICACY; NUMBER	Cellular manufacturing design is apprehensive about the conception and activity of cells to take the benefits of adaptability, effective flow, and high creation rate. The way toward forming manufacturing cells with the greatest efficiency is the most critical strides in cellular manufacturing. In this paper, a new monarch butterfly optimization (MBO) and firefly (FF)-based meta-heuristic is proposed to solve a multi-objective cell formation problem (CFP). This hybridized MBO-FF acquires optimal arrangements in a worthy measure of time, particularly for big size problems also focused to enhance the working of CFP. This algorithm is competent to investigate the search space viably and recognize the global optimal within a short measure of time. Here, percentage of exceptional elements, machine utilization, grouping efficacy and cell efficiency are measured for the performance enhancement. Computational outcome of the presented MBO-FF herein demonstrates superior or equivalent to the benchmark instance collected from the literature.																	1432-7643	1433-7479				NOV	2020	24	21					16679	16690		10.1007/s00500-020-05059-4		JUN 2020											
J								The use of local information sharing on soccer game optimization	SOFT COMPUTING										Local information sharing; Nearby player; Soccer game optimization; Unconstraint continuous problems	POWER POINT TRACKING; GENETIC ALGORITHM; PV SYSTEMS; METAHEURISTICS; COLONY	Research that focuses on the performance improvement of metaheuristics is important to gain understanding on the characteristic of specific algorithm. Better understanding of metaheuristics method will bring benefit when it comes to implement the methods to solve real problems. This paper studies the effect of local information sharing on the performance of soccer game optimization with suitable control parameter settings. A novel method, called soccer game optimization with local information sharing (SGOLS), has been proposed in this paper. The method implements local information derived from several nearby players to conduct move forward. Therefore, the move forward will consider the position of the ball dribbler, the previous best player position as well as the position of players nearby. The proposed method is evaluated based on 20 unconstraint continuous problems, consisting of unimodal function and multimodal functions, and compared to SGO, PSO and DE. The experiment result reveals that the local information sharing could enhance intensification search in SGOLS. The proposed methods perform better in high-dimensionality problems than SGO, PSO and DE. However, the use of local information consumes more computational times than the SGO and PSO, but it is still faster than DE.																	1432-7643	1433-7479															10.1007/s00500-020-05060-x		JUN 2020											
J								Learning the Clustering of Longitudinal Shape Data Sets into a Mixture of Independent or Branching Trajectories	INTERNATIONAL JOURNAL OF COMPUTER VISION										Longitudinal data analysis; Mixture model; Branching population; Stochastic optimization; Statistical model; Riemannian manifold	PROGRESSION; MANIFOLDS; MODELS	Given repeated observations of several subjects over time, i.e. a longitudinal data set, this paper introduces a new model to learn a classification of the shapes progression in an unsupervised setting: we automatically cluster a longitudinal data set in different classes without labels. Our method learns for each cluster an average shape trajectory (or representative curve) and its variance in space and time. Representative trajectories are built as the combination of pieces of curves. This mixture model is flexible enough to handle independent trajectories for each cluster as well as fork and merge scenarios. The estimation of such non linear mixture models in high dimension is known to be difficult because of the trapping states effect that hampers the optimisation of cluster assignments during training. We address this issue by using a tempered version of the stochastic EM algorithm. Finally, we apply our algorithm on different data sets. First, synthetic data are used to show that a tempered scheme achieves better convergence. We then apply our method to different real data sets: 1D RECIST score used to monitor tumors growth, 3D facial expressions and meshes of the hippocampus. In particular, we show how the method can be used to test different scenarios of hippocampus atrophy in ageing by using an heteregenous population of normal ageing individuals and mild cognitive impaired subjects.																	0920-5691	1573-1405				DEC	2020	128	12					2794	2809		10.1007/s11263-020-01337-8		JUN 2020											
J								Transferrable Feature and Projection Learning with Class Hierarchy for Zero-Shot Learning	INTERNATIONAL JOURNAL OF COMPUTER VISION										Zero-shot learning; Class hierarchy; Recurrent neural network; Deep feature learning; Projection function learning; Few-shot learning	CLASSIFICATION; DATABASE	Zero-shot learning (ZSL) aims to transfer knowledge from seen classes to unseen ones so that the latter can be recognised without any training samples. This is made possible by learning a projection function between a feature space and a semantic space (e.g. attribute space). Considering the seen and unseen classes as two domains, a big domain gap often exists which challenges ZSL. In this work, we propose a novel inductive ZSL model that leverages superclasses as the bridge between seen and unseen classes to narrow the domain gap. Specifically, we first build a class hierarchy of multiple superclass layers and a single class layer, where the superclasses are automatically generated by data-driven clustering over the semantic representations of all seen and unseen class names. We then exploit the superclasses from the class hierarchy to tackle the domain gap challenge in two aspects: deep feature learning and projection function learning. First, to narrow the domain gap in the feature space, we define a recurrent neural network over superclasses and then plug it into a convolutional neural network for enforcing the superclass hierarchy. Second, to further learn a transferrable projection function for ZSL, a novel projection function learning method is proposed by exploiting the superclasses to align the two domains. Importantly, our transferrable feature and projection learning methods can be easily extended to a closely related task-few-shot learning (FSL). Extensive experiments show that the proposed model outperforms the state-of-the-art alternatives in both ZSL and FSL tasks.																	0920-5691	1573-1405				DEC	2020	128	12					2810	2827		10.1007/s11263-020-01342-x		JUN 2020											
J								Anti-synchronization of a Class Of Fuzzy Memristive Competitive Neural Networks with Different Time Scales	NEURAL PROCESSING LETTERS										Memristor; Fuzzy competitive neural network; Lyapunov functional; Anti-synchronization	STATE STABILITY ANALYSIS; PHASE SYNCHRONIZATION; DYNAMICS; SYSTEMS; ORDER; DISCRETE	In this paper, we investigate a class of fuzzy memristive competitive neural networks with different time scales. Based on Lyapunov functional and differential inclusions, two proper controllers are designed to achieve the anti-synchronization of systems. Some novel results have been obtained for anti-synchronization. Finally, an example is given to illustrate the effectiveness of our main results.																	1370-4621	1573-773X				AUG	2020	52	1			SI		647	661		10.1007/s11063-020-10269-w		JUN 2020											
J								Hierarchical classifier design for speech emotion recognition in the mixed-cultural environment	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE										Speech emotion classification; hierarchical classification system; integrated corpus environment	CROSS-CORPUS	Recognition of emotion in speech is a difficult task due to many speaker factors like gender, age, and the cultural background (nationality, ethnicity, and region) as well as the acoustical environment. Among these factors, the cultural background of the speaker has a strong influence on the expression of emotion. The reason for the unsatisfactory performance of an emotion recognition engine built using mixed-cultural samples can be traced back to this. To address this issue, a two-level hierarchical engine has been designed to identify emotion from the speech of different cultural backgrounds. The first level of the hierarchical engine is a culture identification system, which identifies the corpus of an input utterance. As most of the speakers involved in the construction of a specific corpus are from the same locality and cultural background, we assume that a corpus represents the cultural background of the speakers of the corpus constructed. Based on the response of the first level classifier, the input utterance is forwarded to an appropriate corpus-specific emotion recognition engine, in the second level. Each corpus-specific emotion recognition system is a discriminative, multiclass SVM classifier, trained with the emotional utterances of that particular corpus. The system has been tested with five different corpora, collected from diverse cultural backgrounds, namely EMO-DB, SAVEE, IITKGP-SEC, Spanish corpus S0329, and CMU's Woogles corpus. The system achieved an accuracy of 82.01% which is an improvement of 13.38% over monolithic approaches.																	0952-813X	1362-3079															10.1080/0952813X.2020.1764630		JUN 2020											
J								Neural embedding collaborative filtering for recommender systems	NEURAL COMPUTING & APPLICATIONS										Collaborative filtering; Neural embedding; Matrix factorization; Implicit feedback		The main purpose of collaborative filtering algorithm is to provide a personalized recommender system based on past interactions of each user (e.g., clicks and purchases). Among various collaborative filtering techniques, matrix factorization is widely adopted in diverse applications. This technique has superior characteristics, including applying latent feature vectors to represent users or items and projecting users and items into a shared latent feature space. In the present study, a matrix factorization model with the neural embedding called the neural embedding collaborative filtering (NECF) is proposed. In order to evaluate the performance of the proposed method, a probabilistic auto-encoder is initially applied to achieve unsupervised learning to generate the neural embedding vector from the user-item data. Secondly, these vectors are combined with a regression model based on single point negative sampling to represent the latent feature vectors of the user with regression coefficients. Moreover, an inner product is applied on latent features of users and items to determine the correlations between them. It should be indicated that the NECF is generic so that it can express and generalize the matrix factorization under its framework. In the present study, a ridge regression learning is applied on latent features of each user. The experimental results on two benchmark data sets show that the proposed model outperforms other state-of-the-art methods.																	0941-0643	1433-3058				NOV	2020	32	22			SI		17043	17057		10.1007/s00521-020-04920-9		JUN 2020											
J								Battle royale optimization algorithm	NEURAL COMPUTING & APPLICATIONS										Battle royale; Optimization; Swarm intelligence; Metaheuristic	HEURISTIC OPTIMIZATION; INSPIRED ALGORITHM; GENETIC ALGORITHM	Recently, several metaheuristic optimization approaches have been developed for solving many complex problems in various areas. Most of these optimization algorithms are inspired by nature or the social behavior of some animals. However, there is no optimization algorithm which has been inspired by a game. In this paper, a novel metaheuristic optimization algorithm, named BRO (battle royale optimization), is proposed. The proposed method is inspired by a genre of digital games knowns as "battle royale." BRO is a population-based algorithm in which each individual is represented by a soldier/player that would like to move toward the safest (best) place and ultimately survive. The proposed scheme has been compared with the well-known PSO algorithm and six recent proposed optimization algorithms on nineteen benchmark optimization functions. Moreover, to evaluate the performance of the proposed algorithm on real-world engineering problems, the inverse kinematics problem of the 6-DOF PUMA 560 robot arm is considered. The experimental results show that, according to both convergence and accuracy, the proposed algorithm is an efficient method and provides promising and competitive results.																	0941-0643	1433-3058															10.1007/s00521-020-05004-4		JUN 2020											
J								A two-step abstractive summarization model with asynchronous and enriched-information decoding	NEURAL COMPUTING & APPLICATIONS										Neural network; Abstractive summarization; Asynchronous decoder model; Enriched-information decoding		Most sequence-to-sequence abstractive summarization models generate the summaries based on the source article and the generated words, but they often neglect the future information implied in the un-generated words, which means that they lack the ability of "lookahead." In this paper, we present a novel summarization model with "lookahead" ability to fully employ the implied future information. Our model takes two steps: (1) in the first step, an asynchronous decoder model with a no ground truth guiding backward decoder that explicitly produces and exploits the future information is trained. (2) in the inference process, in addition to the joint probability of the generated sequence, an enriched-information decoding method is proposed to further take future ROUGE reward of the un-generated words into account. Furthermore, the future ROUGE reward is predicted by a novel reward-predict model, and it takes the hidden states of the pre-trained asynchronous decoder model as input. Experimental results show that our two-step summarization model achieves new state-of-the-art results on CNN/Daily Mail dataset and the generalization of our model on test-only DUC-2002 datasets achieves higher scores than the state-of-the-art model.																	0941-0643	1433-3058															10.1007/s00521-020-05005-3		JUN 2020											
J								A hybrid approach for search and rescue using 3DCNN and PSO	NEURAL COMPUTING & APPLICATIONS										Search and rescue; Unmanned aerial vehicle; Drone-based surveillance; Particle swarm optimization (PSO); Action recognition; Convolution neural network	PARTICLE SWARM OPTIMIZATION; SVM	Search and rescue are essential applications of disaster management in which people are evacuated from the disaster-prone area to a safer place. This overall process of search and rescue can be more efficient if an automated system can quickly locate the human or area where rescue is required. To provide a faster and accurate search of those places, this paper proposes a novel approach to search and rescue using automated drone surveillance. In this paper, a complex scene classification problem is solved using the proposed 3DCNN model. The proposed model uses spatial as well as temporal features of the video for the classification of the scene as help or non-help in the natural disaster. Due to the unavailability of such kind of dataset, it is impossible to train the model. Therefore, it is essential to develop a dataset for search and rescue. The proposed dataset is a first and unique dataset for scene classification using drone surveillance. The major contribution of this paper is (1) a novel 3DCNN powered model for scene classification in drone surveillance, (2) to develop the required dataset for the training of scene classification model, and (3) particular swarm optimization (PSO)-based hyper-parameter tuning for getting the best value of multiple parameters used for training the model. Our hybridization of parameter tuning with PSO helps for the convergence of parameter values of proposed 3DCNN model, and the proposed scene classification model (3DCNN+PSO) is applied to the dataset. The proposed model gives an impressive performance to help situation identification with 98% training and 99% validation accuracy.																	0941-0643	1433-3058															10.1007/s00521-020-05001-7		JUN 2020											
J								Improving neural machine translation for low-resource Indian languages using rule-based feature extraction	NEURAL COMPUTING & APPLICATIONS										Recurrent neural network; Linguistic feature extraction; Deep learning; Rule-based system; Sanskrit-Hindi translation	POS TAGGER; SANSKRIT	Languages help to unite the world socially, culturally and technologically. Different natives communicate in different languages; there is a tremendous requirement for inter-language information translation process to transfer and share information and ideas. Though Sanskrit is an ancient Indo-European language, a significant amount of work for processing the information is required to explore the full potential of this language to open vistas in computational linguistics and computer science domain. In this paper, we have proposed and presented the machine translation system for translating Sanskrit to the Hindi language. The developed technique uses linguistic features from rule-based feed to train neural machine translation system. The work is novel and applicable to any low-resource language with rich morphology. It is a generic system covering various domains with minimal human intervention. The performance analysis of work is performed on automatic and linguistic measures. The results show that proposed and developed approach outperforms earlier work for this language pair.																	0941-0643	1433-3058															10.1007/s00521-020-04990-9		JUN 2020											
J								A MCMEIF-LT model for risk assessment based on linguistic terms and risk attitudes	APPLIED INTELLIGENCE										Risk assessment; Risk matrix; Information fusion; Risk attitudes; Linguistic terms; Fuzzy numbers	RANKING FUZZY NUMBERS; GROUP DECISION-MAKING; REPRESENTATION MODEL; AGGREGATION; SIMILARITY; WEIGHTS; UTILITY; EXPERTS; SAFETY; SETS	Due to the limitation of assessors' knowledge and the uncertainty of risks, risk assessment data reasonably are given in the form of linguistic terms, safety risk assessment in petrochemical industry is often a multi-criterion and multi-expert information fusion based on linguistic terms(MCMEIF-LT) problem. A novel model dealing with the MCMEIF-LT problem is presented in this paper. Firstly, the individual linguistic assessment distributions are fused to collective distributions and multiple criteria are fused to a comprehensive criterion. In the fusion process, the objective weights of assessment experts are calculated with using the credibilities of assessment data and the attitudes of decision makers are considered. Secondly, a Fuzzy Number Weighted Ordered Weighted Aggregation(FN-WOWA) operator which can transform a fuzzy number into a crisp value is proposed. In the FN-WOWA operator, the utility function can incorporate the assessors' loss-based risk attitudes and the membership function can reflect the importance of the values in the integrated fuzzy number. Based on crisp values, a risk matrix is constructed. Finally, a real application is demonstrated to show the flexibility and practicality of the MCMEIF-LT model.																	0924-669X	1573-7497				OCT	2020	50	10					3318	3335		10.1007/s10489-020-01737-w		JUN 2020											
J								Neural multi-task collaborative filtering	EVOLUTIONARY INTELLIGENCE										Multi-task; Deep learning; Collaborative filtering; Neural networks		In recommendation systems, the rating matrix is often very sparse. Collaborative filtering recommendation algorithms cannot be applied to sparse matrices or used in cold start problems. Although the users' trust relationships provide some useful additional information for recommendation systems, the existing research has not incorporated the rating matrix and trust relationships well. The trust relationship itself also has the problem of data sparsity. With a focus on the problem of sparsity and low accuracy in collaborative filtering algorithms, this paper proposes a general framework, called neural multi-task collaborative filtering (NMCF), which can simultaneously predict the rating and trust relationships. That is, the rating of the same user in e-commerce platforms and the trust relationships in social networks promote and complement each other and help to improve the prediction accuracy of both. The study results for three datasets of real-world show that our algorithm performs better in recommendation, and the accuracy of the proposed algorithm is significantly improved compared with that of the comparison models.																	1864-5909	1864-5917															10.1007/s12065-020-00409-5		JUN 2020											
J								Human posture recognition based on multiple features and rule learning	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Human posture recognition; Multiple features; Rule learning	POSE	The use of skeleton data for human posture recognition is a key research topic in the human-computer interaction field. To improve the accuracy of human posture recognition, a new algorithm based on multiple features and rule learning is proposed in this paper. Firstly, a 219-dimensional vector that includes angle features and distance features is defined. Specifically, the angle and distance features are defined in terms of the local relationship between joints and the global spatial location of joints. Then, during human posture classification, the rule learning method is used together with the Bagging and random subspace methods to create different samples and features for improved classification performance of sub-classifiers for different samples. Finally, the performance of our proposed algorithm is evaluated on four human posture datasets. The experimental results show that our algorithm can recognize many kinds of human postures effectively, and the results obtained by the rule-based learning method are of higher interpretability than those by traditional machine learning methods and CNNs.																	1868-8071	1868-808X				NOV	2020	11	11					2529	2540		10.1007/s13042-020-01138-y		JUN 2020											
J								An efficient group signcryption scheme supporting batch verification for securing transmitted data in the Internet of Things	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Security; IoT communication network; Group signcryption; IoT devices; Transmitted data; Privacy preservation	SMART CITY; IOT; PRIVACY; CHALLENGES	This paper presents a novel secure and privacy-preserving scheme for enhancing the security of transmitted data in an Internet of Things (IoT) environment. The proposed scheme combines a short group signature scheme with a signcryption method to represent an efficient short group signcryption (SGSC) technique with added security features. The proposed scheme supports aggregation and batch verification to eliminate the issue of increasing the computation delay from which the current IoT system suffers, particularly when the number of connected devices are increased. Detailed security analysis has shown that the proposed SGSC scheme is robust against many security and privacy threats in the IoT communication network, and can achieve more security features compared with currently available group signature schemes. The proposed scheme shows high efficiency in terms of computational cost in verifying a large number of messages within a short time frame.																	1868-5137	1868-5145															10.1007/s12652-020-02076-x		JUN 2020											
J								An enhanced computer-assisted lung cancer detection method using content based image retrieval and data mining techniques	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cancer; Lung cancer; Lung tumor; Adaptive thresholding segmentation; Support vector machine (SVM) classification; Content-based information retrieval (CBIR); Pattern matching; Data mining; Image processing		Cancer is a sickness brought about by an uncontrolled division of eccentric cells in any part of human body. It is in the top of few places in the killer disease list and pervades in the entire world, but still on the rise. Most of the cases an early detection of lung cancer is cumbersome. This research paper is aimed to present an effective and an efficient way of computer-assisted detection method for lung cancer. In this research we used a set of lung computed tomography scanned images as inputs, obtained from lung image archives and applied image processing techniques such as feature extraction, segmentation. In this approach, a proper combination of Adaptive thresholding segmentation algorithm has been used for segmenting input images, a well-known Support Vector Machine image classification algorithm has been used for lung tumor classification and Content-based image retrieval technique has been used to compare lung image features such as contract, intensity, texture and shape. A set of patient personal data is included to get more accurate and correct prediction results, and it is dealt with data mining approach. The proposed segmentation method shows improved prediction results.																	1868-5137	1868-5145															10.1007/s12652-020-02123-7		JUN 2020											
J								MitM detection and defense mechanism CBNA-RF based on machine learning for large-scale SDN context	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										SDN; MitM attack; Random Forest; machine learning; CBNA; ODL Controller	NETWORK INTRUSION DETECTION; PREVENTION TECHNIQUE; SECURITY; IMPLEMENTATION; CHALLENGES; ATTACKS	Software defined network (SDN) is a promising new network abstraction that aims to improve and facilitate network management. Due to its centralized architecture and the lack of intelligence on the data plane, SDN suffers from many security issues that slows down its deployment. Man in the Middle (MitM) attack is considered as one of the most devastating attacks in an SDN context. In fact, MitM attack allows the attackers to capture, duplicate and spoof flows by targeting southbound interfaces and SDN nodes. Furthermore, it's very difficult to detect MitM attacks since it is performed passively at the SDN level. To reduce the impact of this attack, we generally set up security policies and authentication mechanisms. However, these techniques are not applicable for a large scale SDN architecture as they require complexes and static configurations and as they negatively influence on network performance. In this paper, we propose an intrusion detection and prevention framework by using machine learning techniques to detect and stop MitM attempts. To do so, we build a context-based node acceptance based on the random forest model (CBNA-RF), which helps to setting-up appropriate security policies and to automating defense operations on a large-scale SDN context. This mechanism can realize a quick and early detection of MitM attacks by automatically detecting malicious nodes without affecting performances. The evaluation of the proposed framework demonstrates that our model can correctly classify and detect malicious connections and nodes while keeping high accuracy and precision scores.																	1868-5137	1868-5145															10.1007/s12652-020-02099-4		JUN 2020											
J								Fuzzy assisted fog and cloud computing with MIoT system for performance analysis of health surveillance system	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Fog and cloud computing; Internet of things; Healthcare surveillance system	INTERNET; MODEL	The clouds are the most common medium for aggregating, storing and analyzing data from the Internet of Things (MIoT) based medical therapy applications used by patients or pharmaceutical knowledge in the conventional health care monitoring network. Mobile Web infrastructure, remote communication, and networking can cause data and other delays. In addition, a slight delay in response to the analyzed data could lead to incorrect decisions about care in case of an emergency that could jeopardize the life of the patient. Recently, an indirect coat of fog or edge projection has been utilized for the dispersed accessing and depositing data of MIoT to resolve networking and contact delays. Fuzzy Assisted Fog and Cloud Computing (FAFCC) with MIoT devices become the most favored traditional healthcare surveillance system approach. In this paper, it provides an application model for such a framework to illustrate how machine assets cost reduction is assured while efficiency limitations are guaranteed. Health access requests held in a fuzzy assisted fog-cloud delivery system. This model is established on a fuzzy system and can determine the minimum amount of computing assets needed to meet fog along with cloud projections agreement on Employment Level (SLA). The proposed model is approved and checked via distinct action simulator Java Modeling Tools (JMT). The results show that the proposed model can predict the response time of the system and accurately define the number of computing resources for health data services to achieve better performance.																	1868-5137	1868-5145															10.1007/s12652-020-02156-y		JUN 2020											
J								Fuzzy logic and Fog based Secure Architecture for Internet of Things (FLFSIoT)	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet of Things (IoT); Security; Fog supported IoT; Fuzzy logic; Distributed denial of service (DDoS) attack; Collusion attack; Real-time attack detection; FLFSIoT	INTRUSION DETECTION; ATTACK; SYSTEM	Motivated by the recent explosion of interest around the Internet of Things (IoT), this paper is focused on the dynamics of its security. It is a fact that at present, there is a dearth of consolidated and methodical visions for assuring the security of IoT. This owes to its unique characteristics like interdependence of IoT devices and services, device heterogeneity, mobility, affinity to owners, pervasiveness, and unattended nature. The constraints of energy, memory, bandwidth and computability further complicate this picture. The strategies available in the literature today do not entirely consider this intricate nature of IoT environments. Moreover, uncertainty is not adequately acknowledged by the researchers while designing the security procedures for IoT, even though most of the IoT related security problems stem from an uncertain environment. This paper focuses on addressing this uncertainty, along with the other major security issues of IoT. It gives detailed categorization of the attacks in IoT. To this end, a Fuzzy Logic and Fog based Secure Architecture for IoT (FLFSIoT) has been proposed in this paper that works in real-time. In FLFSIoT, fuzzy logic has been used to alleviate the uncertainty of belonging to one crisp cluster of an edge node and for detecting various classical attacks. The Fog supported IoT architecture has been used to make FLFSIoT intrinsically more secure in comparison to the cloud-supported IoT by omitting the latency and other issues. As such, this work feeds the benefits of fuzzy log and fog computing into the carving of a generic solution to the IoT's security problem. The efficiency of FLFSIoT has been evaluated against the Distributed Denial of Service (DDoS) and Collusion attacks, and it has been observed that it gives more accurate results than the existing benchmarks.																	1868-5137	1868-5145															10.1007/s12652-020-02128-2		JUN 2020											
J								Low Cost Easy-to-Install Indoor Positioning System	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Indoor positioning system; Image processing; Calibration	LOCATION SYSTEMS; NAVIGATION	In this study, an image processing based indoor positioning system (IPS) scheme is presented. Real-time image of uniquely coded passive reflective tags which are illuminated by an infrared projector is used to calculate the instantaneous position of an object. The system simultaneously provides real-time position data and identifies unregistered tags and makes it possible to use these tags in later frames. The ideal state of the method is to determine the position using the tags with known locations. However, for ease of installation, known tags are placed only at certain reference points and positions of the remaining tags are calculated by applying a proposed auto-registration procedure. Such an approach provides a high level of ease of installation to the presented method. The satisfactory positioning accuracy level obtained in the experimental results also enables the proposed method to be evaluated as a powerful indoor positioning system.																	0921-0296	1573-0409				OCT	2020	100	1					131	144		10.1007/s10846-020-01193-1		JUN 2020											
J								Fuzzy Adaptive Neurons Applied to the Identification of Parameters and Trajectory Tracking Control of a Multi-Rotor Unmanned Aerial Vehicle Based on Experimental Aerodynamic Data	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Trajectory tracking; Identification of parameters; Drone; Unmanned aerial vehicle (UAV); Fuzzy adaptive neurons (FANs); Experimental aerodynamic data	MODEL	The propulsion subsystem of multi-rotor Unmanned Aerial Vehicles (UAV) is one of the most complex due to the aerodynamic, aero-elastic and electromechanical elements it comprises. Therefore, accurate models of this subsystem can be difficult to work with. Therefore, simplified models are normally used for the design of control and navigation algorithms. Considering this, the effectiveness of these algorithms is heavily dependent on the identification process used for the estimation of the parameters of the simplified propulsion model. On the other hand, the novel method of fuzzy adaptive neurons (FANs) have interesting characteristics that make them attractive for applications in which a fast response and good precision are required. In this article, the identification of the parameters of the propulsion system and the trajectory tracking of a multi-rotor UAV using FANs is explored. The efficient learning algorithm of the FANs is applied to identify the parameters of a simplified model of the propulsion system and to the self-tuning proportional integral derivative (PID) controllers of the trajectory tracking system. The proposed simplified model with the identified parameters is tested with experimental data obtained with low speed wind tunnels. The proposed PID controllers with self-tuning gains defined by the algorithm of the FANs for trajectory tracking system, are verified with simulations in MATLAB/Simulink (R) environment. The results showed that the parameter identification and trajectory tracking with PID controllers with self-tuning gains defined by the algorithm of the FANs, are suitable for estimating the parameters of the simplified model and track the trajectory with better error reduction than a classical PID controller.																	0921-0296	1573-0409				NOV	2020	100	2					647	665		10.1007/s10846-020-01198-w		JUN 2020											
J								Drone Reconfigurable Architecture (DRA): a Multipurpose Modular Architecture for Unmanned Aerial Vehicles (UAVs)	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										UAV; Aerial robots; Drones; Reconfigurable robots; Modular robots		This work proposes the Drone Reconfigurable Architecture (DRA), which is a modular architecture for UAVs with electrical, mechanical, and computational specifications. The theoretical aspects of the architecture are introduced through a case study with practical implementations aiming to design a multi-rotor UAV, which also includes the manufacturing steps of a functional prototype. Our proposal can be used in a scenario where the capacity of physical reconfiguration of a UAV would confer an enormous advantage to these aircraft in terms of applicability. This happens in the case where each task typically requires a robot with a particular physical architecture (number and position of propellers, autonomy, thrust, sensors, and communication). Results of a set of tests with an aircraft assembly are presented to verify the versatility of the proposed architecture, demonstrating the better performance of these aircraft when compared with conventional UAVs. The proposed methodology allows applications in a variety of scenarios like cargo transportation, support, agriculture, publicity, pest control, surveillance, inspection, and entertainment, between others. In these scenarios, although a software with some generic components could easily control drones to perform all of them, it is unthinkable to consider that a single drone with a particular physical structure would be able to be adapted to all of the tasks necessary (as path following, localization, and mapping).																	0921-0296	1573-0409				SEP	2020	99	3-4			SI		517	534		10.1007/s10846-019-01129-4		JUN 2020											
J								A Measure of Q-convexity for Shape Analysis	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Shape descriptor; Shape analysis; Convexity measure; Q-convexity; Algorithms	POLYOMINOES	In this paper, we study three basic novel measures of convexity for shape analysis. The convexity considered here is the so-called Q-convexity, that is, convexity by quadrants. The measures are based on the geometrical properties of Q-convex shapes and have the following features: (1) their values range from 0 to 1; (2) their values equal 1 if and only if the binary image is Q-convex; and (3) they are invariant by translation, reflection, and rotation by 90 degrees. We design a new algorithm for the computation of the measures whose time complexity is linear in the size of the binary image representation. We investigate the properties of our measures by solving object ranking problems and give an illustrative example of how these convexity descriptors can be utilized in classification problems.																	0924-9907	1573-7683				OCT	2020	62	8					1121	1135		10.1007/s10851-020-00962-9		JUN 2020											
J								Real-time segmentation of remote sensing images with a combination of clustering and Bayesian approaches	JOURNAL OF REAL-TIME IMAGE PROCESSING										Remote sensing images; Segmentation; Clustering; Bayesian approach	MEAN-SHIFT; CLASSIFICATION; MODEL; OPTIMIZATION; SUPERPIXELS; MULTISCALE	In the area of remote sensing image processing, accurate segmentation of high-resolution remote sensing images in real time remains a challenging problem and numerous approaches have been developed for the problem. This paper proposes a new unsupervised approach that can efficiently analyze a remote sensing image and provide accurate segmentation results. The approach performs segmentation in three stages. In the first stage, an image is partitioned into blocks of equal sizes. The mean values of the R, G and B components of the pixels in each block are computed to form a feature vector of the block. A preliminary segmentation result is obtained by clustering the feature vectors with a simple clustering algorithm. In the second stage, a Bayesian approach is applied to refine the preliminary segmentation result. In the final stage, a graph-based method is utilized to recognize regions with complex texture structures. The performance of this approach has been tested on a few benchmark datasets, and its segmentation accuracy is compared with that of many state-of-the-art segmentation tools for remote sensing images. The testing results show that the overall segmentation accuracy of the proposed approach is higher than that of the other tools, and real-time analysis suggests that the approach is promising for real-time applications. An implementation of the approach in MATLAB is freely available upon request.																	1861-8200	1861-8219															10.1007/s11554-020-00990-z		JUN 2020											
J								fNIRS-based classification of mind-wandering with personalized window selection for multimodal learning interfaces	JOURNAL ON MULTIMODAL USER INTERFACES										Mind-wandering; Functional near-infrared spectroscopy; fNIRS; Attention-aware systems	NEAR-INFRARED SPECTROSCOPY; ABSENT MIND; BRAIN; ATTENTION; GAMES	Automatic detection of an individual's mind-wandering state has implications for designing and evaluating engaging and effective learning interfaces. While it is difficult to differentiate whether an individual is mind-wandering or focusing on the task only based on externally observable behavior, brain-based sensing offers unique insights to internal states. To explore the feasibility, we conducted a study using functional near-infrared spectroscopy (fNIRS) and investigated machine learning classifiers to detect mind-wandering episodes based on fNIRS data, both on an individual level and a group level, specifically focusing on automated window selection to improve classification results. For individual-level classification, by using a moving window method combined with a linear discriminant classifier, we found the best windows for classification and achieved a mean F1-score of 74.8%. For group-level classification, we proposed an individual-based time window selection (ITWS) algorithm to incorporate individual differences in window selection. The algorithm first finds the best window for each individual by using embedded individual-level classifiers and then uses these windows from all participants to build the final classifier. The performance of the ITWS algorithm is evaluated when used with eXtreme gradient boosting, convolutional neural networks, and deep neural networks. Our results show that the proposed algorithm achieved significant improvement compared to the previous state of the art in terms of brain-based classification of mind-wandering, with an average F1-score of 73.2%. This builds a foundation for mind-wandering detection for both the evaluation of multimodal learning interfaces and for future attention-aware systems.																	1783-7677	1783-8738															10.1007/s12193-020-00325-z		JUN 2020											
J								SATPin: Axiom Pinpointing for Lightweight Description Logics Through Incremental SAT	KUNSTLICHE INTELLIGENZ										Pinpointing; SAT; Description logics		One approach to axiom pinpointing (AP) in description logics is its reduction to the enumeration of minimal unsatisfiable subformulas, allowing for the deployment of highly optimized methods from SAT solving. Exploiting the properties of AP, we further optimize incremental SAT solving, resulting in speedups of several orders of magnitude: through persistent incremental solving the solver state is updated lazily when adding clauses or assumptions. This adaptation consistently improves the runtime of the tool by an average factor of 3.8, and a maximum of 38. SATPin, our system, was tested over large biomedical ontologies and performed competitively.																	0933-1875	1610-1987				SEP	2020	34	3			SI		389	394		10.1007/s13218-020-00669-4		JUN 2020											
J								PSSA: Polar Coordinate Salp Swarm Algorithm for Curve Design Problems	NEURAL PROCESSING LETTERS										Salp swarm optimizer; Polar coordinates algorithm; Polar equation; Curve approximation; Metaheuristic	OPTIMIZATION; MODEL	This paper proposes a modified optimization algorithm called polar coordinate salp swarm algorithm (PSSA). The main inspiration of PSSA is the aggregation chain and foraging trajectory of salp is spiral. Some curves are extremely complex when represented in Cartesian coordinate system, but if they are expressed in polar coordinates, it becomes very simple and easy to handle, and polar coordinates are widely used in scientific computing and engineering issues. It will be more intuitive and convenient if use polar coordinates to define the foraging and aggregation process of salps. At the same time, different from other algorithms proposed in the past, the PSSA directly initialize individuals in polar space instead of using mapping functions to convert to polar coordinates, change the position of particles by updating polar angles and polar diameters. This algorithm is tested on two complex polar coordinate equations, several curve approximation problems and engineering design problems using PSSA. The experimental results illustrated that the proposed PSSA algorithm is superior to the state-of-the-art metaheuristic algorithms in terms of the performance measures.																	1370-4621	1573-773X				AUG	2020	52	1			SI		615	645		10.1007/s11063-020-10271-2		JUN 2020											
J								Novel OGBEE-based feature selection and feature-level fusion with MLP neural network for social media multimodal sentiment analysis	SOFT COMPUTING										Sentiment analysis; OMSANN; OGBEE; MLP; Feature extraction; Optimal solution; Accuracy	PREDICTION; ALGORITHM; MODEL	Numerous public networks, namely Instagram, YouTube, Facebook, Twitter, etc., share their own feelings and idea as videotapes, posts, and pictures. In future research, adapting to such data and mining valuable information from it will be an undeniably troublesome errand. This paper proposes a novel audio-video-textual-based multimodal sentiment analysis approach. The proposed approach investigates the sentiments that are collected from the web recordings that utilize audio, video, and textual modalities for further extraction. A feature-level fusion technique is employed in fusing the extracted features from different modalities. Therefore, the extracted features are optimally chosen by using a novel oppositional grass bee optimization (OGBEE) algorithm to obtain the best optimal feature set. Here, 12 benchmark functions are developed to validate the numerical efficiency and the effectiveness of a novel OGBEE algorithm for various aspects. Moreover, our proposed approach utilizes multilayer perceptron-based neural network (MLP-NN) for sentiment classification. The experimental analysis reveals that the proposed approach provides better classification accuracy of about 95.2% with less computational time.																	1432-7643	1433-7479															10.1007/s00500-020-05049-6		JUN 2020											
J								Weighted k-nearest neighbor based data complexity metrics for imbalanced datasets	STATISTICAL ANALYSIS AND DATA MINING										Bayes error; class imbalance; classification; complexity metrics; data complexity; data-level algorithms; imbalance ratio; overlapping; small disjuncts; undersampled	CLASSIFICATION; SELECTION	Empirical behavior of a classifier depends strongly on the characteristics of the underlying imbalanced dataset; therefore, an analysis of intrinsic data complexity would appear to be vital in order to choose classifiers suitable for particular problems. Data complexity metrics (CMs), a fairly recent proposal, identify dataset features which imply some difficulty for the classification task and identify relationships with classifier accuracy. In this paper, we introduce two CMs for imbalanced datasets, which help in explaining the factors responsible for the deterioration in classifier performance. These metrics are based on the weighted k-nearest neighbors approach. The experiments are performed in MATLAB software using 48 simulated datasets and 22 real-world datasets for different choices of neighborhood size k considered as 3, 5, 7, 9, 11. The results help to illustrate the usefulness of the proposed metrics.																	1932-1864	1932-1872				AUG	2020	13	4					394	404		10.1002/sam.11463		JUN 2020											
J								Medical Supplier Selection with a Group Decision-Making Method Based on Incomplete Probabilistic Linguistic Preference Relations	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Incomplete probabilistic linguistic preference relation; Group decision-making; Additive consistency; Medical supplier selection	OF-THE-ART; TERM SETS; CONSISTENCY; CONSENSUS	In hospital operation management, the medical supplier selection is a significant problem in which experts' domain knowledge plays a critical role in selecting medical suppliers. The probabilistic linguistic preference relation (PLPR) whose elements are probabilistic linguistic term sets (PLTSs) is an effective tool to express experts' preferences on alternatives based on pairwise comparisons. Due to the lack of knowledge of experts and the limit information of alternatives, some preference information may be missing and thus the incomplete PLPR (InPLPR) is constructed. In this study, a group decision-making (GDM) method with InPLPRs is proposed to deal with a practical medical supplier selection problem. To achieve this goal, we first propose a method to check whether an InPLPR is acceptable. Then, a procedure is developed to complete the acceptable InPLPR based on the property of additive consistency and a social strategy is proposed to complete the unacceptable InPLPR. Afterward, a GDM model based on InPLPRs is constructed in which the aggregation phase and exploitation phase are conducted by the probabilistic linguistic weighted averaging (PLWA) operator. Besides, an approach for calculating the weights of experts is proposed considering the characteristics of InPLPRs. Finally, we illustrate the proposed GDM model by a practical case about the medical supplier selection. A comparative analysis is presented to demonstrate the advantages of our method.																	1562-2479	2199-3211															10.1007/s40815-020-00885-y		JUN 2020											
J								Augmenting and Automating Corpus Enrichment	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Subjective content descriptions; corpus enrichment; text mining		An agent in pursuit of a task may work with a reference library containing documents associated with additional data that provide location-specific explanations about the content. Faced with a new document, an agent has to decide whether to include the new document in its reference library. Basing the decision on words, topics, or entities has shown not to lead to a balanced performance for varying documents. In this paper, we present an approach for automatically enriching new documents with data associated to documents in a reference library. Additionally, we analyze these data to classify new documents into categories to help an agent in deciding whether to include the new document in its reference library.																	1793-351X	1793-7108				JUN	2020	14	2			SI		173	197		10.1142/S1793351X20400061													
J								Predicting Domain Specific Personal Attitudes and Sentiment	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Personal attitude; natural disaster; sentiment analysis; microblog		Microblog activity logs are useful to determine user's interest and sentiment towards specific and broader category of events such as natural disaster and national election. In this paper, we present a corpus model to show how personal attitudes can be predicted from social media or microblog activities for a specific domain of events such as natural disasters. More specifically, given a user's tweet and an event, the model is used to predict whether the user will be willing to help or show a positive attitude towards that event or similar events in the future. We present a new dataset related to a specific natural disaster event, i.e. Hurricane Harvey, that distinguishes user's tweets into positive and non-positive attitudes. We build Term Embeddings for Tweet (TEmT) to generate features to model personal attitudes for arbitrary user's tweets. In addition, we present sentiment analysis on the same disaster event dataset using enhanced feature learning on TEmT generated features by applying Convolutional Neural Network (CNN). Finally, we evaluate the effectiveness of our method by employing multiple classification techniques and comparative methods on the newly created dataset.																	1793-351X	1793-7108				JUN	2020	14	2			SI		199	222		10.1142/S1793351X20400073													
J								Incorporating Verb Semantic Information in Visual Question Answering Through Multitask Learning Paradigm	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Visual Question Answering; verb semantics; data augmentation; deep learning; multi-task learning		Visual Question Answering (VQA) concerns providing answers to Natural Language questions about images. Several deep neural network approaches have been proposed to model the task in an end-to-end fashion. Whereas the task is grounded in visual processing, if the question focuses on events described by verbs, the language understanding component becomes crucial. Our hypothesis is that models should be aware of verb semantics, as expressed via semantic role labels, argument types, and/or frame elements. Unfortunately, no VQA dataset exists that includes verb semantic information. Our first contribution is a new VQA dataset (imSituVQA) that we built by taking advantage of the imSitu annotations. The imSitu dataset consists of images manually labeled with semantic frame elements, mostly taken from FrameNet. Second, we propose a multi-task CNN-LSTM VQA model that learns to classify the answers as well as the semantic frame elements. Our experiments show that semantic frame element classification helps the VQA system avoid inconsistent responses and improves performance. Third, we employ an automatic semantic role labeler and annotate a subset of the VQA dataset (VQA(sub)). This way, the proposed multi-task CNN-LSTM VQA model can be trained with the VQA(sub) as well. The results show a slight improvement over the single-task CNN-LSTM model.																	1793-351X	1793-7108				JUN	2020	14	2			SI		223	248		10.1142/S1793351X20400085													
J								Towards Programming in Natural Language: Learning New Functions from Spoken Utterances	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Programming in natural language; natural language understanding; end-user programming; conversational interfaces; spoken language understanding; natural language processing; computational linguistics; naturalistic programming; machine learning; neural networks; intelligent systems; artificial intelligence		Systems with conversational interfaces are rather popular nowadays. However, their full potential is not yet exploited. For the time being, users are restricted to calling predefined functions. Soon, users will expect to customize systems to their needs and create own functions using nothing but spoken instructions. Thus, future systems must understand how laypersons teach new functionality to intelligent systems. The understanding of natural language teaching sequences is a first step toward comprehensive end-user programming in natural language. We propose to analyze the semantics of spoken teaching sequences with a hierarchical classification approach. First, we classify whether an utterance constitutes an effort to teach a new function or not. Afterward, a second classifier locates the distinct semantic parts of teaching efforts: declaration of a new function, specification of intermediate steps, and superfluous information. For both tasks we implement a broad range of machine learning techniques: classical approaches, such as Naive Bayes, and neural network configurations of various types and architectures, such as bidirectional LSTMs. Additionally, we introduce two heuristic-based adaptations that are tailored to the task of understanding teaching sequences. As data basis we use 3168 descriptions gathered in a user study. For the first task convolutional neural networks obtain the best results (accuracy: 96.6%); bidirectional LSTMs excel in the second (accuracy: 98.8%). The adaptations improve the first-level classification considerably (plus 2.2% points).																	1793-351X	1793-7108				JUN	2020	14	2			SI		249	272		10.1142/S1793351X20400097													
J								Transitive Topic Modeling with Conversational Structure Context: Discovering Topics that are Most Popular in Online Discussions	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Online discussions; topic modeling; conversational structure		With the explosive growth of online discussions published everyday on social media platforms, comprehension and discovery of the most popular topics have become a challenging problem. Conventional topic models have had limited success in online discussions because the corpus is extremely sparse and noisy. To overcome their limitations, we use the discussion thread tree structure and propose a "popularity" metric to quantify the number of replies to a comment to extend the frequency of word occurrences, and the "transitivity" concept to characterize topic dependency among nodes in a nested discussion thread. We build a Conversational Structure Aware Topic Model (CSATM) based on popularity and transitivity to infer topics and their assignments to comments. Experiments on real forum datasets are used to demonstrate improved performance for topic extraction with six different measurements of coherence and impressive accuracy for topic assignments.																	1793-351X	1793-7108				JUN	2020	14	2			SI		273	293		10.1142/S1793351X20400103													
J								Managing Machine Learning Workflow Components	INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING										Machine learning; workflow management; Hyperknowledge		Machine Learning Workflows (MLWfs) have become an essential and disruptive approach in problem-solving over several industries. However, the development process of MLWfs may be complex, time-consuming, and error-prone. To handle this problem, we introduce machine learning workflow management (MLWfM) as a technique to aid the development and reuse of MLWfs and their components through three aspects: representation, execution, and creation. We introduce our approach to structure MLWfs' components and metadata in order to aid component retrieval and reuse of new MLWfs. We also consider the execution of these components within a tool. A hybrid knowledge representation, called Hyperknowledge, frames our methodology, supporting the three MLWfM's aspects. To validate our approach, we show a practical use case in the Oil & Gas industry. In addition, to evaluate the feasibility of the proposed technique, we create a dataset of MLWfs executions and discuss the MLWfM's performance in loading and querying this dataset.																	1793-351X	1793-7108				JUN	2020	14	2			SI		295	309		10.1142/S1793351X20400115													
J								Nonequilibrium Statistical Mechanics of Continuous Attractors	NEURAL COMPUTATION											NEURAL-NETWORKS; DYNAMICS; MEMORY; PLACE; MODEL; REPRESENTATION; HIPPOCAMPUS; COMPUTATION; NAVIGATION; STABILITY	Continuous attractors have been used to understand recent neuroscience experiments where persistent activity patterns encode internal representations of external attributes like head direction or spatial location. However, the conditions under which the emergent bump of neural activity in such networks can bemanipulated by space and time-dependent external sensory or motor signals are not understood. Here, we find fundamental limits on how rapidly internal representations encoded along continuous attractors can be updated by an external signal. We apply these results to place cell networks to derive a velocity-dependent nonequilibrium memory capacity in neural networks.																	0899-7667	1530-888X				JUN	2020	32	6					1033	1068		10.1162/neco_a_01280													
J								First Passage Time Memory Lifetimes for Multistate, Filter-Based Synapses	NEURAL COMPUTATION											INTEGRATE-AND-EXPRESS; SYNAPTIC PLASTICITY; NEURAL-NETWORKS; STOCHASTIC-MODEL; CAPACITY; DYNAMICS; CASCADE; SWITCH; FALL; RISE	Models of associative memory with discrete state synapses learn new memories by forgetting old ones. In contrast to non-integrative models of synaptic plasticity, models with integrative, filter-based synapses exhibit an initial rise in the fidelity of recall of stored memories. This rise to a peak is driven by a transient process and is then followed by a return to equilibrium. In a series of papers, we have employed a first passage time (FPT) approach to define and study memory lifetimes, incrementally developing our methods, from both simple and complex binary-strength synapses to simple multistate synapses. Here, we complete this work by analyzing FPT memory lifetimes in multistate, filter-based synapses. To achieve this, we integrate out the internal filter states so that we can work with transitions only in synaptic strength. We then generalize results on polysynaptic generating functions from binary strength to multistate synapses, allowing us to examine the dynamics of synaptic strength changes in an ensemble of synapses rather than just a single synapse. To derive analytical results for FPT memory lifetimes, we partition the synaptic dynamics into two distinct phases: the first, pre-peak phase studied with a drift-only approximation, and the second, post-peak phase studied with approximations to the full strength transition probabilities. These approximations capture the underlying dynamics very well, as demonstrated by the extremely good agreement between results obtained by simulating our model and results obtained from the Fokker-Planck or integral equation approaches to FPT processes.																	0899-7667	1530-888X				JUN	2020	32	6					1069	1143		10.1162/neco_a_01283													
J								Efficient Position Decoding Methods Based on Fluorescence Calcium Imaging in the Mouse Hippocampus	NEURAL COMPUTATION											SPIKE TRAIN INFERENCE; SPATIAL TOPOLOGY; PLACE CELLS; CODES; DECONVOLUTION; MEMORY; REPLAY	Large-scale fluorescence calcium imaging methods have become widely adopted for studies of long-term hippocampal and cortical neuronal dynamics. Pyramidal neurons of the rodent hippocampus show spatial tuning in freely foraging or head-fixed navigation tasks. Development of efficient neural decoding methods for reconstructing the animal's position in real or virtual environments can provide a fast readout of spatial representations in closed-loop neuroscience experiments. Here, we develop an efficient strategy to extract features from fluorescence calcium imaging traces and further decode the animal's position. We validate our spike inference-free decoding methods in multiple in vivo calcium imaging recordings of the mouse hippocampus based on both supervised and unsupervised decoding analyses. We systematically investigate the decoding performance of our proposed methods with respect to the number of neurons, imaging frame rate, and signal-to-noise ratio. Our proposed supervised decoding analysis is ultrafast and robust, and thereby appealing for real-time position decoding applications based on calcium imaging.																	0899-7667	1530-888X				JUN	2020	32	6					1144	1167		10.1162/neco_a_01281													
J								Independently Interpretable Lasso for Generalized Linear Models	NEURAL COMPUTATION											VARIABLE SELECTION; BREAST-CANCER; REGRESSION; REGULARIZATION; PREDICTION; SPARSITY; RECOVERY; TUMOR	Sparse regularization such as l(1) regularization is a quite powerful and widely used strategy for high-dimensional learning problems. The effectiveness of sparse regularization has been supported practically and theoretically by several studies. However, one of the biggest issues in sparse regularization is that its performance is quite sensitive to correlations between features. Ordinary l(1) regularization selects variables correlated with each other under weak regularizations, which results in deterioration of not only its estimation error but also interpretability. In this letter, we propose a new regularization method, independently interpretable lasso (IILasso), for generalized linear models. Our proposed regularizer suppresses selecting correlated variables, so that each active variable affects the response independently in the model. Hence, we can interpret regression coefficients intuitively, and the performance is also improved by avoiding overfitting. We analyze the theoretical property of the IILasso and show that the proposed method is advantageous for its sign recovery and achieves almost minimax optimal convergence rate. Synthetic and real data analyses also indicate the effectiveness of the IILasso.																	0899-7667	1530-888X				JUN	2020	32	6					1168	1221		10.1162/neco_a_01279													
J								Salient Slices: Improved Neural Network Training and Performance with Image Entropy	NEURAL COMPUTATION												As a training and analysis strategy for convolutional neural networks (CNNs), we slice images into tiled segments and use, for training and prediction, segments that both satisfy an information criterion and contain sufficient content to support classification. In particular, we use image entropy as the information criterion. This ensures that each tile carries as much information diversity as the original image and, for many applications, serves as an indicator of usefulness in classification. To make predictions, a probability aggregation framework is applied to probabilities assigned by the CNN to the input image tiles. This technique, which we call Salient Slices, facilitates the use of large, high-resolution images that would be impractical to analyze unmodified; provides data augmentation for training, which is particularly valuable when image availability is limited; and the ensemble nature of the input for prediction enhances its accuracy.																	0899-7667	1530-888X				JUN	2020	32	6					1222	1237		10.1162/neco_a_01282													
J								Finding key players in complex networks through deep reinforcement learning	NATURE MACHINE INTELLIGENCE											NODES	Finding an optimal set of nodes, called key players, whose activation (or removal) would maximally enhance (or degrade) a certain network functionality, is a fundamental class of problems in network science. Potential applications include network immunization, epidemic control, drug design and viral marketing. Due to their general NP-hard nature, these problems typically cannot be solved by exact algorithms with polynomial time complexity. Many approximate and heuristic strategies have been proposed to deal with specific application scenarios. Yet, we still lack a unified framework to efficiently solve this class of problems. Here, we introduce a deep reinforcement learning framework FINDER, which can be trained purely on small synthetic networks generated by toy models and then applied to a wide spectrum of application scenarios. Extensive experiments under various problem settings demonstrate that FINDER significantly outperforms existing methods in terms of solution quality. Moreover, it is several orders of magnitude faster than existing methods for large networks. The presented framework opens up a new direction of using deep learning techniques to understand the organizing principle of complex networks, which enables us to design more robust networks against both attacks and failures. A fundamental problem in network science is how to find an optimal set of key players whose activation or removal significantly impacts network functionality. The authors propose a deep reinforcement learning framework that can be trained on small networks to understand the organizing principles of complex networked systems.																		2522-5839				JUN	2020	2	6					317	324		10.1038/s42256-020-0177-2													
J								Deep learning incorporating biologically inspired neural dynamics and in-memory computing	NATURE MACHINE INTELLIGENCE											BACKPROPAGATION; NETWORKS; FEATURES; MODEL; POWER	Spiking neural networks (SNNs) incorporating biologically plausible neurons hold great promise because of their unique temporal dynamics and energy efficiency. However, SNNs have developed separately from artificial neural networks (ANNs), limiting the impact of deep learning advances for SNNs. Here, we present an alternative perspective of the spiking neuron that incorporates its neural dynamics into a recurrent ANN unit called a spiking neural unit (SNU). SNUs may operate as SNNs, using a step function activation, or as ANNs, using continuous activations. We demonstrate the advantages of SNU dynamics through simulations on multiple tasks and obtain accuracies comparable to, or better than, those of ANNs. The SNU concept enables an efficient implementation with in-memory acceleration for both training and inference. We experimentally demonstrate its efficacy for a music-prediction task in an in-memory-based SNN accelerator prototype using 52,800 phase-change memory devices. Our results open up an avenue for broad adoption of biologically inspired neural dynamics in challenging applications and acceleration with neuromorphic hardware. Spiking neural networks and in-memory computing are both promising routes towards energy-efficient hardware for deep learning. Wozniak et al. incorporate the biologically inspired dynamics of spiking neurons into conventional recurrent neural network units and in-memory computing, and show how this allows for accurate and energy-efficient deep learning.																		2522-5839				JUN	2020	2	6					325	+		10.1038/s42256-020-0187-0													
J								Augmenting vascular disease diagnosis by vasculature-aware unsupervised learning	NATURE MACHINE INTELLIGENCE											PHOTOACOUSTIC TOMOGRAPHY; VESSEL SEGMENTATION; BLOOD-FLOW; ALGORITHM; IMAGES; BRAIN	Vascular disease is one of the leading causes of death and threatens human health worldwide. Imaging examination of vascular pathology with reduced invasiveness is challenging due to the intrinsic vasculature complexity and non-uniform scattering from bio-tissues. Here, we report VasNet, a vasculature-aware unsupervised learning algorithm that augments pathovascular recognition from small sets of unlabelled fluorescence and digital subtraction angiography images. VasNet adopts a multi-scale fusion strategy with a domain adversarial neural network loss function that induces biased pattern reconstruction by strengthening features relevant to the retinal vasculature reference while weakening irrelevant features. VasNet delivers the outputs 'Structure + X' (where X refers to multi-dimensional features such as blood flows, the distinguishment of blood dilation and its suspicious counterparts, and the dependence of new pattern emergence on disease progression). Therefore, explainable imaging output from VasNet and other algorithm extensions holds the promise to augment medical diagnosis, as it improves performance while reducing the cost of human expertise, equipment and time consumption. Vascular abnormalities are challenging for diagnostic imaging due to the complexity of vasculature and the non-uniform scattering from biological tissues. The authors present an unsupervised learning algorithm for vascular feature recognition from small sets of biomedical images acquired from different modalities. They demonstrate the utility of their diagnostic approach on vascular images of thrombosis, internal bleeding and colitis.																		2522-5839				JUN	2020	2	6					337	+		10.1038/s42256-020-0188-z													
J								A novel machine learning framework for automated biomedical relation extraction from large-scale literature repositories	NATURE MACHINE INTELLIGENCE											NEURAL-NETWORKS; DATABASE; SYNTAX	A lot of scientific literature is unstructured, which makes extracting information for biomedical databases difficult. Hong and colleagues show that a distant supervision approach, using latent tree learning and recurrent units, can extract drug-target interactions from literature that were previously unknown. Knowledge about the relations between biomedical entities (such as drugs and targets) is widely distributed in more than 30 million research articles and consistently plays an important role in the development of biomedical science. In this work, we propose a novel machine learning framework, named BERE, for automatically extracting biomedical relations from large-scale literature repositories. BERE uses a hybrid encoding network to better represent each sentence from both semantic and syntactic aspects, and employs a feature aggregation network to make predictions after considering all relevant statements. More importantly, BERE can also be trained without any human annotation via a distant supervision technique. Through extensive tests, BERE has demonstrated promising performance in extracting biomedical relations, and can also find meaningful relations that were not reported in existing databases, thus providing useful hints to guide wet-lab experiments and advance the biological knowledge discovery process.																		2522-5839				JUN	2020	2	6					347	+		10.1038/s42256-020-0189-y													
J								Predicting tumour mutational burden from histopathological images using multiscale deep learning	NATURE MACHINE INTELLIGENCE											CANCER; IMMUNOTHERAPY	Tumour mutational burden (TMB) is an important biomarker for predicting the response to immunotherapy in patients with cancer. Gold-standard measurement of TMB is performed using whole exome sequencing (WES), which is not available at most hospitals because of its high cost, operational complexity and long turnover times. We have developed a machine learning algorithm, Image2TMB, which can predict TMB from readily available lung adenocarcinoma histopathological images. Image2TMB integrates the predictions of three deep learning models that operate at different resolution scales (x5, x10 and x20 magnification) to determine if the TMB of a cancer is high or low. On a held-out set of patients, Image2TMB achieves an area under the precision recall curve of 0.92, an average precision of 0.89, and has the predictive power of a targeted sequencing panel of similar to 100 genes. This study demonstrates that it is possible to infer genomic features from histopathology images, and potentially opens avenues for exploring genotype-phenotype relationships.																		2522-5839				JUN	2020	2	6					356	362		10.1038/s42256-020-0190-5													
J								Evaluating the Effects of Modern Storage Devices on the Efficiency of Parallel Machine Learning Algorithms	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Machine learning; data mining; MapReduce; performance; parallel algorithms; flash memory; SSDs; 3D XPoint; Distributed Storage	MAPREDUCE FRAMEWORK; PERFORMANCE; SSDS	Big Data analytics is presently one of the most emerging areas of research for both organizations and enterprises. The requirement for deployment of efficient machine learning algorithms over huge amounts of data led to the development of parallelization frameworks and of specialized libraries (like Mahout and MLlib) which implement the most important among these algorithms. Moreover, the recent advances in storage technology resulted in the introduction of high-performing devices, broadly known as Solid State Drives (SSDs). Compared to the traditional Hard Drives (HDDs), SSDs offer considerably higher performance and lower power consumption. Motivated by these appealing features and the growing necessity for efficient large-scale data processing, we compared the performance of several machine learning algorithms on MapReduce clusters whose nodes are equipped with HDDs, SSDs, and devices which implement the latest 3D XPoint technology. In particular, we evaluate several dataset preprocessing methods like vectorization and dimensionality reduction, two supervised classifiers, Naive Bayes and Linear Regression, and the popular k-Means clustering algorithm. We use an experimental cluster equipped with the three aforementioned storage devices under different configurations, and two large datasets, Wikipedia and HIGGS. The experiments showed that the benefits which derive from the usage of SSDs depend on the cluster setup and the nature of the applied algorithms.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060008	10.1142/S0218213020600088													
J								Assigning and Scheduling Service Visits in a Mixed Urban/Rural Setting	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Maintenance scheduling; service planning; travelling repair person	CARE	This paper(a) describes a maintenance scheduling application, which was developed to-gether with an industrial partner. This is a highly combinatorial decision process, to plan and schedule the work of a group of travelling repair technicians, which perform preventive and corrective maintenance tasks at customer locations. Customers are located both in urban areas, where many customers are in close proximity, and in sparsely populated rural areas, where the travel time between customer sites is significant. To balance the workload for the agents, we must consider both the productive working time, as well as the travel between locations. As the monolithic problem formulation is unmanageable, we introduce a problem decomposition into multiple sequential steps, that is compatible with current management practice. We present and compare different models for the solution steps, and discuss results on datasets provided by the industrial partner.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060007	10.1142/S0218213020600076													
J								Heterogeneous Island Models and Their Application to Recommender Systems and Electric Vehicle Charging	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Evolutionary algorithms; parallel algorithms; recommender systems; electric vehicle charging		In this paper we describe a general framework for parallel optimization based on the island model of evolutionary algorithms. The framework runs a number of optimization methods in parallel with periodic communication. In this way, it essentially creates a parallel ensemble of optimization methods. At the same time, the system contains a planner that decides which of the available optimization methods should be used to solve the given optimization problem and changes the distribution of such methods during the run of the optimization. Thus, the system effectively solves the problem of online parallel portfolio selection. The proposed system is evaluated in a number of common benchmarks with various problem encodings as well as in two real-life problems - the optimization in recommender systems and the training of neural networks for the control of electric vehicle charging.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060010	10.1142/S0218213020600106													
J								Acoustic Diversity Classification Using Machine Learning Techniques: Towards Automated Marine Big Data Analysis	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Marine big data; deep learning; signal classification; transfer learning; acoustic; image processing	CLIMATE-CHANGE	During the last years, big data has become the new emerging trend that increasingly attracting the attention of the R&D community in several fields (e.g., image processing, database engineering, data mining, artificial intelligence). Marine data is part of these fields which accommodates this growth, hence the appearance of marine big data paradigm that monitoring advocates the assessment of human impact on marine data. Nonetheless, supporting acoustic sounds classification is missing in such environment, with taking into account the diversity of such data (i.e., sounds of living undersea species, sounds of human activities, and sounds of environmental effects). To overcome this issue, we propose in this paper an approach that efficiently allowing acoustic diversity classification using machine learning techniques. The aim is to reach an automated support of marine big data analysis. We have conducted a set of experiments, using a real marine dataset, in order to validate our approach and show its effectiveness and efficiency. To do so, three machine learning techniques are employed: (i) classic machine learning models (i.e., k-nearest neighbor and support vector machine), (ii) deep learning based on convolutional neural networks, and (iii) transfer learning based on the reuse of pretrained models.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060011	10.1142/S0218213020600118													
J								Sparse Deep Neural Network Optimization for Embedded Intelligence	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										First order optimization; l(1) regularization; model compression; deep neural network; embedded systems		Deep neural networks become more popular as its ability to solve very complex pattern recognition problems. However, deep neural networks often need massive computational and memory resources, which is main reason resulting them to be difficult efficiently and entirely running on embedded platforms. This work addresses this problem by saving the computational and memory requirements of deep neural networks by proposing a variance reduced (VR)-based optimization with regularization techniques to compress the requirements of memory of models within fast training process. It is shown theoretically and experimentally that sparsity-inducing regularization can be effectively worked with the VR-based optimization whereby in the optimizer the behaviors of the stochastic element is controlled by a hyper-parameter to solve non-convex problems.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060002	10.1142/S0218213020600027													
J								Logical Encoding of Argumentation Frameworks with Higher-order Attacks and Evidential Supports	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Abstract argumentation; higher-order interactions; logical theory	SEMANTICS; ACCEPTABILITY; GRAPHS	We propose a logical encoding of argumentation frameworks with higher-order interactions (i.e. attacks/supports whose targets are arguments or other attacks/supports) with an evidential meaning for supports. Our purpose is to separate the logical expression of the meaning of an attack or an evidential support (simple or higher-order) from the logical expression of acceptability semantics. We consider semantics which specify the conditions under which the arguments (resp. the attacks/supports) are considered as accepted, directly on the extended framework, without translating the original frame- work into a Dung's argumentation framework. We characterize the output of a given framework in logical terms (namely as particular models of a logical theory). Our proposal applies to the particular case of Dung's frameworks, enabling to recover standard extensions.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060003	10.1142/S0218213020600039													
J								Building High Performance Explainable Machine Learning Models for Social Media-based Substance Use Prediction	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Human behavior; personal traits; social media; substance use disorders; explainable AI; causal inference	SELECTION; TRAITS; LATENT	Social media contain rich information that can be used to help understand human mind and behavior. Social media data, however, are mostly unstructured (e.g., text and image) and a large number of features may be needed to represent them (e.g., we may need millions of unigrams to represent social media texts). Moreover, accurately assessing human behavior is often difficult (e.g., assessing addiction may require medical diagnosis). As a result, the ground truth data needed to train a supervised human behavior model are often difficult to obtain at a large scale. To avoid overfitting, many state-of-the-art behavior models employ sophisticated unsupervised or self-supervised machine learning methods to leverage a large amount of unsupervised data for both features learning and dimension reduction. Unfortunately, despite their high performance, these advanced machine learning models often rely on latent features that are hard to explain. Since understanding the knowledge captured in these models is important to behavior scientists and public health providers, we explore new methods to build machine learning models that are not only accurate but also interpretable. We evaluate the effectiveness of the proposed methods in predicting Substance Use Disorders (SUD). We believe the methods we proposed are general and applicable to a wide range of data-driven human trait and behavior analysis applications.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060009	10.1142/S021821302060009X													
J								ITE: A Lightweight Implementation of Stratified Reasoning for Constructive Logical Operators	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Constraint programming; constructive disjunction; stratified reasoning	CONSTRAINT	Constraint Programming (CP) is a powerful declarative programming paradigm where inference and search are interleaved to find feasible and optimal solutions to various type of constraint systems. However, handling logical connectors with constructive information in CP is notoriously difficult. This paper presents If Then Else (ITE), a lightweight implementation of stratified constructive reasoning for logical connectives. Stratification is introduced to cope with the risk of combinatorial explosion of constructing information from nested and combined logical operators. ITE is an open-source library built on top of SICStus Prolog clpfd, which proposes various operators, including constructive disjunction and negation, constructive implication and conditional. These operators can be used to express global constraints and to benefit from constructive reasoning for more domain pruning during constraint filtering. Even though ITE is not competitive with specialized filtering algorithms available in some global constraints implementations, its expressiveness allows users to easily define well-tuned constraints with powerful deduction capabilities. Our extended experimental results show that ITE is more efficient than available generic approaches that handle logical constraint systems over finite domains.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060060	10.1142/S0218213020600064													
J								Interval Tests and Contractors Based on Optimality Conditions for Bound-Constrained Global Optimization	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Bound-constrained global optimization; continuous optimization; branch-and-bound algorithm; interval methods; monotonicity test; constraint propagation	CONSISTENCY; SELECTION	We study the problem of finding the global optimum of a nonlinear real function over an interval box by means of complete search techniques, namely interval branch-and-bound algorithms. Such an algorithm typically generates a tree of boxes from the initial box by alternating branching steps and contraction steps in order to remove non optimal sub-boxes. In this paper, we introduce a new contraction method that is designed to handle the boundary of the initial box where a minimizer may not be a stationary point. This method exploits the first-order optimality conditions and we show that it subsumes the classical monotonicity test based on interval arithmetic. A new branch-andbound algorithm has been implemented in the interval solver Realpaver. An extensive experimental study based on a set of standard benchmarks is presented.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060001	10.1142/S0218213020600015													
J								Possibilistic Networks: Computational Analysis of MAP and MPE Inference	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Complexity; possibilistic networks; MAP inference; MPE inference	COMPLEXITY	Possibilistic graphical models are powerful modeling and reasoning tools for uncertain information based on possibility theory. In this paper, we provide an analysis of computational complexity of MAP and MPE queries for possibilistic networks. MAP queries stand for maximum a posteriori explanation while MPE ones stand for most plausible explanation. We show that the decision problems of answering MAP and MPE queries in both min-based and product-based possibilistic networks is NP-complete. Definitely, such results represent an advantage of possibilistic graphical models over probabilistic ones since MAP queries are NP PP -complete in Bayesian networks. Our proofs for querying min-based possibilistic networks make use of reductions from the 3SAT problem to querying possibilistic networks decision problem. Moreover, the provided reductions may be useful for the implementation of MAP and MPE inference engines based on the satisfiability problem solvers. As for product-based networks, the provided proofs are incremental and make use of reductions from SAT and its weighted variant WMAXSAT.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060005	10.1142/S0218213020600052													
J								Enhanced Unsatisfiable Cores for QBF: Weakening Universal to Existential Quantifiers	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										QBF; unsatisfiable cores; quantifier weakening		We introduce an enhanced notion of unsatisfiable cores for QBF in prenex CNF that allows to weaken universal quantifiers to existential quantifiers in addition to the traditional removal of clauses. The resulting unsatisfiable cores can be different from those of the traditional notion in terms of syntax, standard semantics, and proof-based semantics. This not only gives rise to explanations of unsatisfiability but, via duality, also leads to diagnoses and repairs of unsatisfiability that are not obtained with traditional unsatisfiable cores. We use a source-to-source transformation on QBF in PCNF such that the weakening of universal quantifiers to existential quantifiers in the original formula corresponds to the removal of clauses in the transformed formula. This makes any tool or method for the computation of unsatisfiable cores of the traditional notion available for the computation of unsatisfiable cores of our enhanced notion. We implement our approach as an extension to the QBF solver DepQBF, and we perform an extensive experimental evaluation on a subset of QBFLIB. We illustrate with several case studies that helpful information can be provided by unsatisfiable cores of our enhanced notion.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060012	10.1142/S021821302060012X													
J								Selecting and Combining Classifiers Based on Centrality Measures	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS										Multiple classifier systems; fusion; selection; diversity; centrality measures	ALGORITHMS	Centrality measures have been helping to explain the behavior of objects, given their relation, in a wide variety of problems, since sociology to chemistry. This work considers U these measures to assess the importance of every classifier belonging to an ensemble of classifiers, aiming to improve a Multiple Classifier System (MCS). Assessing the classifier's importance by employing centrality measures, inspired two different approaches: one for selecting classifiers and another for fusion. The selection approach, called Centrality Based Selection (CBS), adopts a trade-off between the classifier's accuracy and their diversity. The sub-optimal selected subset presents good results against selection methods from the literature, being superior in 67.22% of the cases. The second approach, the integration, is named Centrality Based Fusion (CBF). This approach is a weighted combination method, which is superior to literature in 70% of the cases.																	0218-2130	1793-6349				JUN	2020	29	3-4			SI				2060004	10.1142/S0218213020600040													
J								Integrated Formal Tools for Software Architecture Smell Detection	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										Software smells; software architecture; ontology web language; model checking; modiability; smell detection		The architecture smells are the poor design practices applied to the software architecture design. The smells in software architecture design can be cascaded to cause the issues in the system implementation and signicantly affect the maintainability and reliability attribute of the software system. The prevention of architecture smells at the design phase can therefore improve the overall quality of the software system. This paper presents a framework that supports the detection of architecture smells based on the formalization of architecture design. Our modeling specication supports representing both structural and behavioral aspect of software architecture design; it allows the smells to be analyzed and detected with the provided tools. Our framework has been applied to seven architecture smells that violate different design principles. The evaluation has been conducted and the result shows that our detection approach gives accurate results and performs well on different size of models. With the proposed framework, other architecture smells can be defined and detected using the process and tools presented in this paper.																	0218-1940	1793-6403				JUN	2020	30	6			SI		723	763		10.1142/S0218194020400057													
J								Semantic Service Search in IT Crowdsourcing Platform: A Knowledge Graph-Based Approach	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										Semantic search; IT service crowdsourcing; knowledge graph; query expansion; learning to rank		Understanding user's search intent in vertical websites like IT service crowdsourcing platform relies heavily on domain knowledge. Meanwhile, searching for services accurately on crowdsourcing platforms is still difficult, because these platforms do not contain enough information to support high-performance search. To solve these problems, we build and leverage a knowledge graph named ITServiceKG to enhance search performance of crowdsourcing IT services. The main ideas are to (1) build an IT service knowledge graph from Wikipedia, Baidupedia, CN-DBpedia, StuQ and data in IT service crowdsourcing platforms, (2) use properties and relations of entities in the knowledge graph to expand user query and service information, and (3) apply a listwise approach with relevance features and topic features to re-rank the search results. The results of our experiments indicate that our approach outperforms the traditional search approaches.																	0218-1940	1793-6403				JUN	2020	30	6			SI		765	783		10.1142/S0218194020400069													
J								Exploiting Declarative Mapping Rules for Generating GraphQL Servers with Morph-GraphQL	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										OBDA; Declarative Mappings; GraphQL	SEMANTICS	In the last decade, REST has become the most common approach to provide web services, yet it was not originally designed to handle typical modern applications (e.g. mobile apps). GraphQL was proposed to reduce the number of queries and data exchanged in comparison with REST. Since its release in 2015, it has gained momentum as an alternative approach to REST. However, generating and maintaining GraphQL resolvers is not a simple task. First, a domain expert has to analyze a dataset, design the corresponding GraphQL schema and map the dataset to the schema. Then, a software engineer (e.g. GraphQL developer) implements the corresponding GraphQL resolvers in a specific programming language. In this paper, we present an approach to exploit the information from mappings rules (relation between target and source schema) and generate a GraphQL server. These mapping rules construct a virtual knowledge graph which is accessed by the generated GraphQL resolvers. These resolvers translate the input GraphQL queries into the queries supported by the underlying dataset. Domain experts or software developers may benefit from our approach: a domain expert does not need to involve software developers to implement the resolvers, and software developers can generate the initial version of the resolvers to be implemented. We implemented our approach in the Morph-GraphQL framework and evaluated it using the LinGBM benchmark.																	0218-1940	1793-6403				JUN	2020	30	6			SI		785	803		10.1142/S0218194020400070													
J								Semantics-Driven Programming of Self-Adaptive Reactive Systems	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										Context modeling; context-awareness; semantic modeling; semantic sensor networks; ontologies; models@runtime; reactive systems; self-adaptive systems		In recent years, new classes of highly dynamic, complex systems are gaining momentum. These classes include, but are not limited to IoT, smart cities, cyber-physical systems and sensor networks. These systems are characterized by the need to express behaviors driven by external and/or internal changes, i.e. they are reactive and context-aware. A desirable design feature of these systems is the ability of adapting their behavior to environment changes. In this paper, we propose an approach to support adaptive, reactive systems based on semantic runtime representations of their context, enabling the selection of equivalent behaviors, i.e. behaviors that have the same effect on the environment. The context representation and the related knowledge are managed by an engine designed according to a reference architecture and programmable through a declarative definition of sensors and actuators. The knowledge base of sensors and actuators (hosted by an RDF triplestore) is bound to the real world by grounding semantic elements to physical devices via REST APIs. The proposed architecture along with the defined ontology tries to address the main problems of dynamically reconfigurable systems by exploiting a declarative, queryable approach to enable runtime reconfiguration with the help of (a) semantics to support discovery in heterogeneous environment, (b) composition logic to define alternative behaviors for variation points, (c) bi-causal connection life-cycle to avoid dangling links with the external environment. The proposal is validated in a case study aimed at designing an edge node for smart buildings dedicated to cultural heritage preservation.																	0218-1940	1793-6403				JUN	2020	30	6			SI		805	834		10.1142/S0218194020400082													
J								Semantic Restful Service Composition Using Task Specification	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										RESTful service composition; RESTful service discovery; semantic annotation; graph database	SIMILARITY	Existing Web API search engines allow only category-based browsing and keyword- or tag-based searches for RESTful services. In other words, they do not enable the discovery or composition of real-world RESTful services by application developers. This paper outlines a novel scheme, called Transformation-Annotation-Discovery (TAD), which transforms Open-API (Swagger) documents related to RESTful services into a graph structure and then automatically annotates the semantic concepts on graph nodes using Latent Dirichlet Allocation (LDA) and WordNet. TAD can then be used for service composition based on the user requirements specified in two modules: a service discovery chain and logical-operation-based composition. The service discovery chain uses the Hungarian algorithm to assess service interface compatibility in order to facilitate the retrieval of services capable of bridging the gap between specified user requirements and the discovered services. The logical-operation-based composition module identifies services that semantically fit the user requirements, based on the structure of the service flow. Those candidate services are then sent to service discovery chains to enable the simultaneous search for potential composition solutions. System prototype and experiment results demonstrate the feasibility and efficacy of the proposed scheme.																	0218-1940	1793-6403				JUN	2020	30	6			SI		835	857		10.1142/S0218194020400094													
J								Software Agent-Centric Semantic Social Network for Cyber-Physical Interaction and Collaboration	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING										Social computing; social network; social agent; Socio-Cyber-Physical system; Semantic Web; ontology; healthcare	HEALTH-CARE; ONTOLOGY; MANAGEMENT; SYSTEM; MEDIA; USER; ARTIFACTS; FUTURE; TOOLS; WEB	Considerable research has recently focused on integrating cyber-physical systems in a social context. However, several challenges remain concerning appropriate methodologies, frameworks and techniques for supporting socio-cyber-physical collaboration. Existing systems do not recognize how cyber-physical resources can be socially connected so that they interact in collaborative decision-making like humans. Furthermore, the lack of semantic representations for heterogeneous cyber-social-collaborative networks limits integration, interoperability and knowledge discovery from their underlying data sources. Semantic Web ontology models can help to overcome this limitation by semantically describing and interconnecting cyber-physical objects and human participants in a social space. This research addresses the establishment of both cyber-physical and human relationships and their interactions within a social-collaborative network. We discuss how nonhuman resources can be represented as socially connected nodes and utilized by software agents. A software agent-centric Semantic Social-Collaborative Network (SSCN) is then presented that provides functionality to represent and manage cyber-physical resources in a social network. It is supported by an extended ontology model for semantically describing human and nonhuman resources and their social interactions. A software agent has been implemented to perform some actions on behalf of the nonhuman resources to achieve cyber-physical collaboration. It is demonstrated within a real-world decision support system, GRiST (www.egrist.org), used by mental-health services in the UK.																	0218-1940	1793-6403				JUN	2020	30	6			SI		859	893		10.1142/S0218194020400100													
J								UC-Merced Image Classification with CNN Feature Reduction Using Wavelet Entropy Optimized with Genetic Algorithm	TRAITEMENT DU SIGNAL										CNN; feature reduction; entropy; genetic algorithm; UC Merced dataset	FEATURE-EXTRACTION; NEURAL-NETWORKS; RECOGNITION; TRANSFORM; SYSTEM	The classification of high-resolution and remote sensed terrain images with high accuracy is one of the greatest challenges in machine learning. In the present study, a novel CNN feature reduction using Wavelet Entropy Optimized with Genetic Algorithm (GA-WEE-CNN) method was used for remote sensing images classification. The optimal wavelet family and optimal value of the parameters of the Wavelet Sure Entropy (WSE), Wavelet Nom Entropy (WNE), and Wavelet Threshold Entropy (WTE) were calculated, and given to classifiers such as K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). The efficiency of the proposed hybrid method was tested using the UC-Merced dataset. 80% of the data were used as training data, and a performance rate of 98.8% was achieved with SVM classifier, which has been the highest ratio compared to all studies using same dataset so far with only 18 features. These results proved the advantage of the proposed method.																	0765-0019	1958-5608				JUN	2020	37	3					347	353		10.18280/ts.370301													
J								Extraction of Dynamical Information and Classification of Heart Rate Variability Signals Using Scale Based Permutation Entropy Measures	TRAITEMENT DU SIGNAL										classification; complexity analysis; heart rate variability; improved multiscale permutation entropy; multiscale permutation entropy	TIME-SERIES; FAILURE; KERNEL; COMPLEXITY	The dynamical fluctuations in the Heart Rate Variability (HRV) signals show structures at multiple time scales revealing that complexity of the autonomic nervous system control of the heart is multiscale and hierarchical. Multiscale Entropy (MSE) and its variant Composite MSE (CMSE) were proposed to quantify the complexity at multiple time scales, however, these measures failed to quantify complexity accurately for short duration signals at large temporal scales. To address the downsides of MSE and CMSE, Multiscale Permutation Entropy (MPE) and Improved MPE (IMPE) were proposed. The preliminary results reveal that MPE and IMPE were able to distinguish healthy and pathological subjects, however, further studies are needed to investigate the robustness of these measures. In this study, we investigate the robustness of scale based PE measures in terms of dynamical information, induction of undefined entropy estimates for short duration signals and to classify HRV signals under different physiological and pathological conditions. The results were compared with SE, PE, MSE and CMSE. The MPE and IMPE along with MSE and CMSE provided accurate dynamical information. The results revealed that MPE and IMPE resolved the issue of inducing undefined entropy estimates and are robust in classifying healthy and different pathological subjects.																	0765-0019	1958-5608				JUN	2020	37	3					355	365		10.18280/ts.370302													
J								Infrared Small Target Detection Based on Four-Direction Overlapping Group Sparse Total Variation	TRAITEMENT DU SIGNAL										infrared small target detection; robust principal component analysis (RPCA); total variation (TV); four-direction overlapping group	SEGMENTATION; REMOVAL; NOISE	This paper aims to develop an efficient, robust and reliable infrared detection method for small targets. Firstly, the data structure of infrared images with small targets was analyzed in details. Then, the infrared small target detection was converted into the decomposition of the robust principal component analysis (RPCA), and the objective function was constructed with the idea of variation. Next, a regularization term called four-direction overlapping group sparse total variation (OGSTV) was created, and a TV4OGS-RPCA model was designed for infrared small target detection. Experimental results prove that our model can effectively separate small targets from the background, and accurately pinpoint the small targets in infrared images.																	0765-0019	1958-5608				JUN	2020	37	3					367	377		10.18280/ts.370303													
J								A New Approach for Extracting and Characterizing Fetal Electrocardiogram	TRAITEMENT DU SIGNAL										wavelet transform; source separation time-scale; electrocardiogram characterization	BLIND SEPARATION	This paper presents a new approach for extracting and characterizing the fetal electrocardiogram from a mixture of maternal and fetal electrocardiograms, which is of very low amplitude and therefore its medical characterization would be very difficult and unreliable. This method is based on time-scale analysis by using Continuous Wavelet Transform and the Scalogram. Previous work in this field has only investigated on time and time-frequency methods using the Short Fourier Transform, which does not give convincing and accurate results for biomedical signals that require high precision because any part of the extracted signal may indicate a dangerous pathology. The effectiveness of this approach lies in the fact that the time-scale analysis or scalogram of fetal-maternal electrocardiogram mixture has several energetic zones corresponding either to the electrical activity of the heart of the fetus or of her mother, which it facilitates considerably the use of these diagrams in order to separate maternal and fetal electrocardiograms. Compared to other more recent, the results found by simulations are very interesting and the extracted signal corresponds approximately to the source. As a consequence, we can characterize and extract all useful medical parameters. More importantly, our approach can be implemented on real time life by using embedded system such as Raspberry and Digital Signal Processor.																	0765-0019	1958-5608				JUN	2020	37	3					379	386		10.18280/ts.370304													
J								Big Data-Driven Feature Extraction and Clustering Based on Statistical Methods	TRAITEMENT DU SIGNAL										big data-driven; feature extraction; video retrieval; background scenes; foreground objects	IMAGE RETRIEVAL; TEXTURE; CLASSIFICATION; DESCRIPTORS; PATTERN	Big data-driven feature extraction is a challenging process because it contains a variety and voluminous of data. But, in the current scenario of the Internet and the multimedia data-driven necessitates handling of complex data. Nowadays, it becomes a significant challenge to the Internet-based service provider to store voluminous data. To overcome this difficulty, this article provides a novel technique for big data-driven feature extraction, based on statistical methods. At first, the proposed method preprocesses the given input key-frame, that is, normalizes and removes noise. The noise-removed key-frames are separated into background scenes and forefront objects; features are extracted from the background scenes and forefront objects. The extracted features formulated as a feature vector. To validate the extracted features that whether it correctly represents the specific frame or similar frames, the feature vector is associated with the feature vectors in the feature vector catalogue. The proposed feature extraction method matches and retrieves the frames from the video database. It yields average correct retrieval rate of 95.29 per cent. The results obtained from experiments show that the proposed feature extraction method gives the average retrieval precision of 95.29 per cent. The enactment of the proposed feature extraction method is analogous to the existing methods.																	0765-0019	1958-5608				JUN	2020	37	3					387	394		10.18280/ts.370305													
J								A Face Detection Method Based on Image Processing and Improved Adaptive Boosting Algorithm	TRAITEMENT DU SIGNAL										face detection; image processing; adaptive boosting (AdaBoost) algorithm; weak classifier	ADABOOST; CLASSIFICATION; NOISE	In face detection, the Adaptive Boosting (AdaBoost) algorithm consumes a long training time and faces a high false positive rate. To solve these problems, this paper puts forward an improved AdaBoost face detection method. Firstly, the original image was preprocessed to eliminate the effects of light and noise, improving the image detection effect. Next, a dual threshold weak classifier was designed to replace the single threshold weak classifier. The designed classifier identifies thresholds more accurately and reduce the number of threshold searches, making the algorithm faster in convergence and more efficient in training and detection. Then, the authors optimized the weighting coefficient formula of weak classifiers, focusing on the recognition ability of positive samples and the reliability of weak classifiers. Through the optimization, the algorithm can achieve a low false alarm rate (FAR) under a given low false recognition rate (FRR). After that, two thresholds were used to classify the error range of samples. To increase the weights of large error samples, the original weights of samples were multiplied with different weighting coefficients. In this way, the abnormal samples are more likely to be detected in the next round of training. Simulation results show that the proposed face detection algorithm boasts a high detection accuracy, and consumes a short time in training and detection.																	0765-0019	1958-5608				JUN	2020	37	3					395	403		10.18280/ts.370306													
J								A Novel Metaheuristic Algorithm for Edge Detection Based on Artificial Bee Colony Technique	TRAITEMENT DU SIGNAL										edge detection; meta-heuristic methods; artificial bee colony (ABC) optimization; Otsu's method; multilevel thresholds; color space	SEGMENTATION; OPTIMIZATION; INTELLIGENCE; ENTROPY	Many techniques have been proposed in image edge detection's area, but until today, there is no universal or optimal methods that satisfy all the constraints. Each one had its limitations and its inconvenient. So, in order to create a system that offers a better quality of boundaries detecting in images, we used the Artificial Bee Colony's (ABC) algorithm with Otsu's multilevel thresholding method in different color spaces ABC-Otsu. The performance of the approach is compared with the Ant Colony optimization algorithm (ACO). Berkeley (BSDS500), Oxford-17 Flowers and Drive data-sets were used for experimentation. The theoretical analysis and the experimental results are encouraging and demonstrated that our method outperformed these techniques. Also, the execution time is improved and the obtained results show good qualities too.																	0765-0019	1958-5608				JUN	2020	37	3					405	412		10.18280/ts.370307													
J								Study the Influence of Gender and Age in Recognition of Emotions from Algerian Dialect Speech	TRAITEMENT DU SIGNAL										ADED; emotion; HNR; KNN; LDA; recognition; speech; SVM	CLASSIFICATION; PROSODY; SIGNAL	Speech emotions Recognition is a very interesting area of research. In this work, the influence of gender and age on the speech emotions recognition in Algerian Dialect is studied. And on the other hand, the influence of speech emotion types on the classification of gender and age is also studied. An Algerian Dialect Emotional Database (ADED) is used in this work. ADED database is exploited for extracting the features that used in the systems of recognition and classification. These features are the statistic values of pitch and intensity, unvoiced frames, jitter, shimmer, HNR and MFCCs parameters. Analyzes based on gender and age are made to detect the influence of the four emotions on the parameters extracted. A parallel classifier composed of three classifiers, Support Vector Machines (SVM), K-Nearest Neighbor (KNN), and Linear Discriminant Analysis (LDA) is used in the recognition and classification systems. The results obtained show us that the performance of emotions recognition systems is influenced by gender and age i.e. the distinction between each gender class and each age interval in the recognition systems improves the performance compared to the systems without distinction. It was showed in the results also that the classifications of gender classes and age intervals were strongly influenced by the type of emotion.																	0765-0019	1958-5608				JUN	2020	37	3					413	423		10.18280/ts.370308													
J								A Novel Face Recognition Algorithm for Imbalanced Small Samples	TRAITEMENT DU SIGNAL										feature extraction; face recognition; convolutional neural network (CNN); imbalanced small samples	NEURAL-NETWORKS	Deep learning (DL) has become a hotspot in the research of image recognition. However, the DL strategy must be trained with lots of samples that are distributed evenly across classes, i.e. subjected to balanced distribution. Therefore, this paper attempts to design a method to satisfactorily recognize faces in imbalanced small samples. Firstly, the deep convolutional generative adversarial network (DCGAN) was improved to generate data samples with similar distribution as the original training data, creating a balanced training set of sufficient labelled samples. Then, transfer learning was performed to transform the AlexNet, which is pretrained on big dataset, to the balanced target dataset of small samples. Next, the previous convolutional layer was frozen as a feature extractor, and the truncated normal distribution was reinitialized for the next fully-connected layer. Simulations on face recognition show that our method achieved higher recognition rate and less serious overfitting than ordinary CNNs.																	0765-0019	1958-5608				JUN	2020	37	3					425	432		10.18280/ts.370309													
J								Finger Vein Recognition by Combining Anisotropic Diffusion and a New Feature Extraction Method	TRAITEMENT DU SIGNAL										anisotropic diffusion; biometrics; feature extraction; finger vein recognition; HVTP features	ENHANCEMENT; NETWORK; FUSION; FILTER; GABOR	In recent years, Finger Vein (FV) Recognition System is frequently used where personal security is required. Image distortion caused by light scattering in the tissue is one of the major problems about the visibility of the FV. In this study, Homomorphic Filter and Anisotropic Diffusion are used for removing the light scattering problem in our captured FV image and to increase the visibility of the veined region. Novelty of the study is proposing two new features: Horizontal Total Proportion (HTP) and Vertical Total Proportion (VTP). These two new features were used together with both spatial and frequency domain features and it was observed that the success rates obtained by our attributes were significantly increased. Experimental results demonstrate that the proposed HTP and VTP features are effective and reliable to improve the classification success in FV recognition problem. According to the experiments, the use of Perona-Malik and Homomorphic Filter together has been shown to reduce the light scattering problem and improve vascular visibility by removing the noise in the finger vein image. In this study, four different classifiers are used: Complex Tree, Ensemble, Support Vector Machines (SVM), K-Nearest Neighbors (KNN). The best success rate was achieved by using the KNN classifier.																	0765-0019	1958-5608				JUN	2020	37	3					433	441		10.18280/ts.370310													
J								A Computationally Efficient Estimation Algorithm for Direction of Arrival in Double Parallel Linear Array	TRAITEMENT DU SIGNAL										direction of arrival (DOA); double parallel linear array (DPLA); joint cross-covariance matrix (JCCM); root-multiple signal classification (MUSIC) algorithm	2-D DOA ESTIMATION	The direction of arrival (DOA) is traditionally estimated by subspace algorithms. However, the computation of subspace algorithms is complicated by eigenvalue decomposition (EVD) or singular value decomposition (SVD). To simplify subspace algorithms, this paper proposes a fast one-dimensional (1D) DOA estimation algorithm for double parallel linear array (DPLA). In our algorithm, the equivalent noise subspace is constructed by processing the first column elements of the joint cross-covariance matrix (JCCM), and the DOA is estimated, using the root-multiple signal classification (MUSIC) algorithm. The algorithm effectively simplifies and speeds up the computation by eliminating EVD or SVD. Simulation results confirm that our algorithm can improve the accuracy and reduce the time of DOA estimation. The research results have great application potential in DOA estimation tasks.																	0765-0019	1958-5608				JUN	2020	37	3					443	449		10.18280/ts.370311													
J								An Illumination Insensitive Normalization Approach to Face Recognition Using Locality Sensitive Discriminant Analysis	TRAITEMENT DU SIGNAL										face recognition; image gradients; illumination normalization; reflectance model; LSDA	FEATURE-EXTRACTION; PCA; PERFORMANCE	In this paper, a novel algorithm for face recognition is proposed in case of the images having illumination artifacts. First homomorphic filtering is done on the input face images to achieve partial illumination insensitivity. The fraction of the value of the image gradient to the original image intensity is evaluated to get an illumination independent normalized image. Here, gradient-domain is preferred since it explicitly accounts for the relationship between neighboring pixel points in the image. Then, Locality Sensitive Discriminant Analysis (LSDA) is applied to analyze the class relationship between data points. The proposed method performs very well, even if the number of training images is not sufficient. The experimental results on the extended Yale B database show that a significant improvement has been achieved in the recognition rate by making them illumination independent.																	0765-0019	1958-5608				JUN	2020	37	3					451	460		10.18280/ts.370312													
J								A Deep Learning Based Hybrid Approach for COVID-19 Disease Detections	TRAITEMENT DU SIGNAL										Covid-19; deep learning; image processing; Resnet50; hybrid model	CONFUSION MATRIX; CLASSIFICATION; CANCER	COVID-19 appeared in December 19, 2019 in Wuhan, China. This disease has spread to almost all countries in a short time. Countries take a series of stringent measures, including the prohibition of going out to prevent the virus that spreads COVID-19 disease. In this paper, we aimed to diagnose COVID-19 disease from X_RAY images by using deep learning architectures. In addition, 96.30% accuracy rate has been achieved with the hybrid architecture we have improved. While developing the hybrid model, the last 5 layers of Resnet 50 architecture were ejected. 10 layers were added in place of the 5 layers that were removed. The count of layers, which is 177 in the Resnet50 architecture, has been increased to 182 in the hybrid model Thanks to these layer changes made in Resnet50, the accuracy rate has been increased more. Classification was performed with AlexNet, Resnet50, GoogLeNet, VGG16 and developed hybrid architectures using COVID-19 Chest X-Ray dataset and Chest X-Ray images (Pneumonia) datasets. As a result, when other scientific works in the literature are examined, it is finalized that the improved hybrid method offers better results than other deep learning architectures and can be used in computer-aided systems to diagnose COVID-19 disease.																	0765-0019	1958-5608				JUN	2020	37	3					461	468		10.18280/ts.370313													
J								A Target Positioning Method for Industrial Robot Based on Multiple Visual Sensors	TRAITEMENT DU SIGNAL										industrial robot; multiple visual sensors (MVSs); target positioning; feature point matching	MULTISENSOR; MODEL	Flexible start-up is the future trend of production automation. To realize intelligent and flexible operations, industrial robot must position the target rapidly and accurately. Otherwise, it is impossible for the robot to operate automatically in complex environment. This paper designs a novel target positioning method that enables industrial robot to position its target with high precision and fast speed. Firstly, the target images were preprocessed through enhancement, histogram equalization, and filtering. Next, the target motion areas (TMAs) captured by the system of multiple visual sensors (MVSs) were subject to information fusion, and the feature points of fused image were matched and optimized. After that, the fused image was recognized and described by speeded up robust features (SURF)fast retina key-point (FREAK) algorithm. Finally, a two-dimensional (2D) data model was established based on the centroid coordinates of the fused image. Experimental results prove that our method can effectively and accurately position target in complex environment, while simplifying size measurement and speeding up computation. The research results provide a reference for image collection and information fusion by MVSs system in other fields.																	0765-0019	1958-5608				JUN	2020	37	3					469	475		10.18280/ts.370314													
J								Sequences with Perfect Periodic Auto and Cross Correlation Properties	TRAITEMENT DU SIGNAL										periodic autocorrelation; cross-correlation; periodic ambiguity function; zero-correlation zone (ZCZ); synthesized sequences	AMBIGUITY FUNCTION; SIGNALS; DESIGN; CODES	Perfect binary or ternary sequences exhibit an impulse-like Periodic Autocorrelation Function (PACF). Signals with perfect periodic autocorrelation properties are useful in many applications in communications and radar fields. The additional complexity in the design of radar signals is to take care of the cross-correlation properties when multiple radars are sharing the same frequency band. This paper proposes the waveform design approach related to the multi-radar network, when radars are employing coherent pulse train or CW waveforms. Such practical scenario demands the design of waveforms which have perfect autocorrelation and cross-correlation properties. Construction procedure, correlation properties and detection performance of such sequences are presented in this paper.																	0765-0019	1958-5608				JUN	2020	37	3					477	484		10.18280/ts.370315													
J								A Novel Detection Method for Weak Harmonic Signal with Chaotic Noise	TRAITEMENT DU SIGNAL										chaotic noise; wireless network; weak signal; harmonic signals; signal detection; bit error rate (BER)	RECONSTRUCTION; ALGORITHM; DYNAMICS	The bit error induced by the chaotic noise is a serious problem among weak harmonic signal detection methods for wireless network environment. To solve the problem, this paper puts forward a weak harmonic signal detection method for network environment with chaotic noise. Firstly, the real-time transmission signal was collected from the wireless network, and the noise signal was extracted and suppressed in the light of the chaotic features of the signal. In this way, the detection accuracy of weak harmonic signal will not be affected by the noise signal. Then, the detection amplitude and frequency were determined according to the effective values of harmonic components and harmonic frequency, facilitating the detection of weak harmonic signal. Experimental results show that our method outputted a lower bit error rate (BER) than existing methods in weak harmonic signal detection, and outperformed the contrastive methods in reliability and performance.																	0765-0019	1958-5608				JUN	2020	37	3					485	491		10.18280/ts.370316													
J								A New Framework for Recognizing Normal and Epileptic Seizure from Eye Movement Signals Using Genetic Based Convolutional Neural Network	TRAITEMENT DU SIGNAL										epileptic seizure; feature extraction; genetic algorithm; wiener filter	CLASSIFICATION; STIMULATION	The unusual disturbance caused in the neuronal electrical activities inside the brain may lead to epileptic seizures. It is difficult to recognize normal epileptic seizures, as it requires extreme care to identify the epileptic seizure with precise and genuine manner The existing work did not bridge the gap how accurate the eyeball movement signals can help the detection of epileptic seizure. In this paper, the Electrooculography (EOG) signals are processed to implement a method to predict epileptic seizure. The proposed method epileptic seizure detection using genetic based convolutional neural network (ESD-GCNN) helps in finding the epileptic seizure accurately from the eyeball movement signals. The Normalized Data Nonlinearity (NDN)-LMS is employed in the noise reduction process. During the saccade feature extraction and fixation feature extraction, the proposed method ensures the precision of epileptic seizure detection. The genetic-based CNN helps to make perfect decisions on the existence of epileptic seizure. The proposed research work and the entire research analysis is evaluated in MATLAB environment and the intention is to obtain optimal efficiency for veracity of epileptic seizure detection, compared to current research strategies.																	0765-0019	1958-5608				JUN	2020	37	3					493	501		10.18280/ts.370317													
J								An Automatic Recognition Method for Students' Classroom Behaviors Based on Image Processing	TRAITEMENT DU SIGNAL										classroom behavior analysis; head pose; facial expression; image processing	HEAD POSE ESTIMATION	The classroom behaviors of students are the key objects in teaching analysis. It is very important to quantify such behaviors in an intuitive and dynamic manner This paper summarizes the typical classroom behaviors of students, and specifies the steps to preprocess the collected sample images on these behaviors. Then, it is decided to discriminate students' classroom behaviors by head poses and facial expressions. Next, a positioning method for facial feature points was developed based on deep convolutional neural network (D-CNN) and cascading, and the head poses and facial expressions were analyzed and recognized. Our method was compared with other facial expression recognition algorithms. The results show that our method is more robust and accurate than the contrastive algorithms.																	0765-0019	1958-5608				JUN	2020	37	3					503	509		10.18280/ts.370318													
J								An Improved R-Peaks Marking Method Using Fourier Decomposition and Teager Energy Operator	TRAITEMENT DU SIGNAL										Fourier decomposition method; Hilbert Transform; Teager Energy Operator; Zero Cross Detector; R-peaks	ECG SIGNALS; QRS; TRANSFORM; REMOVAL	The exact discovery of R-peak becomes very much crucial while extracting prominent features from Electrocardiogram (ECG) signal. However, identification of R-peaks precisely becomes more challenging due to contamination of noise and fragmented QRS complexes. This paper presents an improved method of marking R-peaks. Initially, an efficient Fourier Decomposition Methodology (FDM) is used for removing noise. The accuracy of finding R-peaks can be improved by enhancing the QRS complexes using Teager Energy Operator. Hilbert Transform and Zero Cross Detector (ZCD) are used for marking the R-peaks. The MIT-BIH arrhythmia database is used for validating the proposed scheme and attained 99.97% accuracy, 99.98% of sensitivity and 99.98% of positive predictivity. The findings proved that proposed method is superior as compared to the proven techniques in the literature.																	0765-0019	1958-5608				JUN	2020	37	3					511	518		10.18280/ts.370319													
J								Identification and Classification of Surface Cracks on Concrete Members Based on Image Processing	TRAITEMENT DU SIGNAL										surface cracks on concrete members; image; processing; image segmentation; crack; identification and classification		The crack identification and classification are essential to the discovery and maintenance of early defects in concrete members. This paper designs a novel method that supports accurate identification and classification of surface cracks on concrete members. Specifically, each sample image was preprocessed through cropping and neighborhood operation, subject to gray adaptive thresholding, and further processed based on morphological gradient and local gray value dissimilarity. Next, the Gauss-Laplace algorithm was employed to extract the contours of the surface cracks, and each image was matched with the normalized crack templates one by one. Finally, a densely connected neural network of transfer learning was introduced to rapidly classify the surface cracks on concrete members. The effectiveness and accuracy of our method were fully demonstrated through experiments. The research findings provide a reference for surface crack identification and classification in other fields.																	0765-0019	1958-5608				JUN	2020	37	3					519	525		10.18280/ts.370320													
J								Unsupervised Text Feature Selection Using Memetic Dichotomous Differential Evolution	ALGORITHMS										feature selection; optimization; hybridization; wrapper; filter; memetic	OPTIMIZATION ALGORITHM	Feature Selection (FS) methods have been studied extensively in the literature, and there are a crucial component in machine learning techniques. However, unsupervised text feature selection has not been well studied in document clustering problems. Feature selection could be modelled as an optimization problem due to the large number of possible solutions that might be valid. In this paper, a memetic method that combines Differential Evolution (DE) with Simulated Annealing (SA) for unsupervised FS was proposed. Due to the use of only two values indicating the existence or absence of the feature, a binary version of differential evolution is used. A dichotomous DE was used for the purpose of the binary version, and the proposed method is named Dichotomous Differential Evolution Simulated Annealing (DDESA). This method uses dichotomous mutation instead of using the standard mutation DE to be more effective for binary purposes. The Mean Absolute Distance (MAD) filter was used as the feature subset internal evaluation measure in this paper. The proposed method was compared with other state-of-the-art methods including the standard DE combined with SA, which is named DESA in this paper, using five benchmark datasets. The F-micro, F-macro (F-scores) and Average Distance of Document to Cluster (ADDC) measures were utilized as the evaluation measures. The Reduction Rate (RR) was also used as an evaluation measure. Test results showed that the proposed DDESA outperformed the other tested methods in performing the unsupervised text feature selection.																		1999-4893				JUN	2020	13	6							131	10.3390/a13060131													
J								Efficient Probabilistic Joint Inversion of Direct Current Resistivity and Small-Loop Electromagnetic Data	ALGORITHMS										joint inversion; Kalman ensemble generator; geophysics; resistivity; electromagnetics; Monte Carlo; Bayesian inversion		Often, multiple geophysical measurements are sensitive to the same subsurface parameters. In this case, joint inversions are mostly preferred over two (or more) separate inversions of the geophysical data sets due to the expected reduction of the non-uniqueness in the joint inverse solution. This reduction can be quantified using Bayesian inversions. However, standard Markov chain Monte Carlo (MCMC) approaches are computationally expensive for most geophysical inverse problems. We present the Kalman ensemble generator (KEG) method as an efficient alternative to the standard MCMC inversion approaches. As proof of concept, we provide two synthetic studies of joint inversion of frequency domain electromagnetic (FDEM) and direct current (DC) resistivity data for a parameter model with vertical variation in electrical conductivity. For both studies, joint results show a considerable improvement for the joint framework over the separate inversions. This improvement consists of (1) an uncertainty reduction in the posterior probability density function and (2) an ensemble mean that is closer to the synthetic true electrical conductivities. Finally, we apply the KEG joint inversion to FDEM and DC resistivity field data. Joint field data inversions improve in the same way seen for the synthetic studies.																		1999-4893				JUN	2020	13	6							144	10.3390/a13060144													
J								Fibers of Failure: Classifying Errors in Predictive Processes	ALGORITHMS										topological data analysis; mapper; predictive model; interpretable machine learning	ELECTRIC-ARC FURNACE; TOPOLOGY	Predictive models are used in many different fields of science and engineering and are always prone to make faulty predictions. These faulty predictions can be more or less malignant depending on the model application. We describe fibers of failure (FIFA), a method to classify failure modes of predictive processes. Our method uses MAPPER, an algorithm from topological data analysis (TDA), to build a graphical model of input data stratified by prediction errors. We demonstrate two ways to use the failure mode groupings: either to produce a correction layer that adjusts predictions by similarity to the failure modes; or to inspect members of the failure modes to illustrate and investigate what characterizes each failure mode. We demonstrate FIFA on two scenarios: a convolutional neural network (CNN) predicting MNIST images with added noise, and an artificial neural network (ANN) predicting the electrical energy consumption of an electric arc furnace (EAF). The correction layer on the CNN model improved its prediction accuracy significantly while the inspection of failure modes for the EAF model provided guiding insights into the domain-specific reasons behind several high-error regions.																		1999-4893				JUN	2020	13	6							150	10.3390/a13060150													
J								Compression of Next-Generation Sequencing Data and of DNA Digital Files	ALGORITHMS										data compression; Next-Generation Sequencing data; DNA; genomes	GENOMIC DATA	The increase in memory and in network traffic used and caused by new sequenced biological data has recently deeply grown. Genomic projects such as HapMap and 1000 Genomes have contributed to the very large rise of databases and network traffic related to genomic data and to the development of new efficient technologies. The large-scale sequencing of samples of DNA has brought new attention and produced new research, and thus the interest in the scientific community for genomic data has greatly increased. In a very short time, researchers have developed hardware tools, analysis software, algorithms, private databases, and infrastructures to support the research in genomics. In this paper, we analyze different approaches for compressing digital files generated by Next-Generation Sequencing tools containing nucleotide sequences, and we discuss and evaluate the compression performance of generic compression algorithms by confronting them with a specific system designed by Jones et al. specifically for genomic file compression:Quip. Moreover, we present a simple but effective technique for the compression of DNA sequences in which we only consider the relevant DNA data and experimentally evaluate its performances.																		1999-4893				JUN	2020	13	6							151	10.3390/a13060151													
J								Optimization Algorithms for Detection of Social Interactions	ALGORITHMS										community detection; optimization; modularity optimization; complex networks; metaheuristics; immunological-inspired computation	COMMUNITY STRUCTURE; NETWORKS; FISSION	Community detection is one of the most challenging and interesting problems in many research areas. Being able to detect highly linked communities in a network can lead to many benefits, such as understanding relationships between entities or interactions between biological genes, for instance. Two different immunological algorithms have been designed for this problem, called OPT-IA and HYBRID-IA, respectively. The main difference between the two algorithms is the search strategy and related immunological operators developed: the first carries out a random search together with purely stochastic operators; the last one is instead based on a deterministic Local Search that tries to refine and improve the current solutions discovered. The robustness of OPT-IA and HYBRID-IA has been assessed on several real social networks. These same networks have also been considered for comparing both algorithms with other seven different metaheuristics and the well-known greedy optimization LOUVAIN algorithm. The experimental analysis conducted proves that OPT-IA and HYBRID-IA are reliable optimization methods for community detection, outperforming all compared algorithms.																		1999-4893				JUN	2020	13	6							139	10.3390/a13060139													
J								Short-Term Wind Speed Forecasting Using Statistical and Machine Learning Methods	ALGORITHMS										additive quantile regression averaging; forecasts combination; machine learning; point and interval forecasting; renewable energy; wind energy	PREDICTION; ENERGY; MODELS	Wind offers an environmentally sustainable energy resource that has seen increasing global adoption in recent years. However, its intermittent, unstable and stochastic nature hampers its representation among other renewable energy sources. This work addresses the forecasting of wind speed, a primary input needed for wind energy generation, using data obtained from the South African Wind Atlas Project. Forecasting is carried out on a two days ahead time horizon. We investigate the predictive performance of artificial neural networks (ANN) trained with Bayesian regularisation, decision trees based stochastic gradient boosting (SGB) and generalised additive models (GAMs). The results of the comparative analysis suggest that ANN displays superior predictive performance based on root mean square error (RMSE). In contrast, SGB shows outperformance in terms of mean average error (MAE) and the related mean average percentage error (MAPE). A further comparison of two forecast combination methods involving the linear and additive quantile regression averaging show the latter forecast combination method as yielding lower prediction accuracy. The additive quantile regression averaging based prediction intervals also show outperformance in terms of validity, reliability, quality and accuracy. Interval combination methods show the median method as better than its pure average counterpart. Point forecasts combination and interval forecasting methods are found to improve forecast performance.																		1999-4893				JUN	2020	13	6							132	10.3390/a13060132													
J								An Application of a Modified Gappy Proper Orthogonal Decomposition on Complexity Reduction of Allen-Cahn Equation	ALGORITHMS										model order reduction; Allen-Cahn equation; proper orthogonal decomposition; discrete empirical interpolation method; gappy proper orthogonal decomposition	MODEL ORDER REDUCTION; DISCRETE EMPIRICAL INTERPOLATION; PARABOLIC PDE SYSTEMS; NONLINEAR MODEL; APPROXIMATION; PROJECTION; POD	This work considers model reduction techniques that can substantially decrease computational cost in simulating parmetrized Allen-Cahn equation. We first employ the proper orthogonal decomposition (POD) approach to reduce the number of unknowns in the full-order discretized system. Since POD cannot reduce the computational complexity of nonlinearity in Allen-Cahn equation, we also apply discrete empirical interpolation method (DEIM) to approximate the nonlinear term for a substantial reduction in overall simulation time. However, in general, the POD-DEIM approach is less accurate than the POD approach, since it further approximates the nonlinear term. To increase the accuracy of the POD-DEIM approach, this work introduces an extension of the DEIM approximation based on the concept of Gappy POD (GPOD), which is optimal in the least-squares sense. The POD-GPOD approach is tested and compared with the POD and POD-DEIM approaches on Allen-Cahn equation for both cases of fixed parameter value and varying parameter values. The modified GPOD approximation introduced in this work is demonstrated to improve accuracy of DEIM without sacrificing too much efficiency on the computational speedup, e.g., in one of our numerical tests, the POD-GPOD approach provides an approximate solution to the parmetrized Allen-Cahn equation 200 times faster than the full-order system with average error of order O (10(-4)). The POD-GPOD approach is therefore shown to be a promising technique that compromises between the accuracy of POD approach and the efficiency of POD-DEIM approach.																		1999-4893				JUN	2020	13	6							148	10.3390/a13060148													
J								A Recursive Least-Squares Algorithm for the Identification of Trilinear Forms	ALGORITHMS										adaptive filters; recursive least-squares (RLS) algorithm; system identification; tensor decomposition; trilinear forms	TENSOR DECOMPOSITIONS	High-dimensional system identification problems can be efficiently addressed based on tensor decompositions and modelling. In this paper, we design a recursive least-squares (RLS) algorithm tailored for the identification of trilinear forms, namely RLS-TF. In our framework, the trilinear form is related to the decomposition of a third-order tensor (of rank one). The proposed RLS-TF algorithm acts on the individual components of the global impulse response, thus being efficient in terms of both performance and complexity. Simulation results indicate that the proposed solution outperforms the conventional RLS algorithm (which handles only the global impulse response), but also the previously developed trilinear counterparts based on the least-mean-squares algorithm.																		1999-4893				JUN	2020	13	6							135	10.3390/a13060135													
J								A Survey on Approximation in Parameterized Complexity: Hardness and Algorithms	ALGORITHMS										parameterized complexity; approximation algorithms; hardness of approximation	LOCAL SEARCH YIELDS; TOTAL FLOW-TIME; K-MEANS; INDEPENDENT SET; EFFICIENT APPROXIMATION; UNIFIED FRAMEWORK; STEINER TREE; INAPPROXIMABILITY; APPROXIMABILITY; SCHEMES	Parameterization and approximation are two popular ways of coping with NP-hard problems. More recently, the two have also been combined to derive many interesting results. We survey developments in the area both from the algorithmic and hardness perspectives, with emphasis on new techniques and potential future research directions.																		1999-4893				JUN	2020	13	6							146	10.3390/a13060146													
J								An Algorithm for Fuzzy Negations Based-Intuitionistic Fuzzy Copula Aggregation Operators in Multiple Attribute Decision Making	ALGORITHMS										intuitionistic fuzzy sets; fuzzy negations; copula; intuitionistic fuzzy Archimedean copula aggregation operators; multiple attribute decision making	MODEL	In this paper, we develop a novel computation model of Intuitionistic Fuzzy Values with the usage of fuzzy negations and Archimedean copulas. This novel computation model's structure is based on the extension of the existing operations of intuitionistic fuzzy values with some classes of fuzzy negations. Many properties of the proposed operations are investigated and proved. Additionally, in this paper we introduce the concepts of intuitionistic fuzzy Archimedean copula weighted arithmetic and geometric aggregation operators based on fuzzy negations, including a further analysis of their properties. Finally, using a case study from an already published paper we found that our method has many advantages.																		1999-4893				JUN	2020	13	6							154	10.3390/a13060154													
J								Late Acceptance Hill-Climbing Matheuristic for the General Lot Sizing and Scheduling Problem with Rich Constraints	ALGORITHMS										matheuristic; late acceptance hill-climbing; lot sizing; scheduling; rework; lifetime constraints; optimization framework	SEQUENCE-DEPENDENT SETUP; GENETIC ALGORITHM; OPTIMIZATION; POPMUSIC; SOLVE	This paper considers the general lot sizing and scheduling problem with rich constraints exemplified by means of rework and lifetime constraints for defective items (GLSP-RP), which finds numerous applications in industrial settings, for example, the food processing industry and the pharmaceutical industry. To address this problem, we propose the Late Acceptance Hill-climbing Matheuristic (LAHCM) as a novel solution framework that exploits and integrates the late acceptance hill climbing algorithm and exact approaches for speeding up the solution process in comparison to solving the problem by means of a general solver. The computational results show the benefits of incorporating exact approaches within the LAHCM template leading to high-quality solutions within short computational times.																		1999-4893				JUN	2020	13	6							138	10.3390/a13060138													
J								Dynamic Ring Exploration with (H, S) View	ALGORITHMS										distributed algorithms; dynamic networks; 1-interval connected rings; mobile agent; exploration		The researches about a mobile entity (called agent) on dynamic networks have attracted a lot of attention in recent years. Exploration which requires an agent to visit all the nodes in the network is one of the most fundamental problems. While the exploration of dynamic networks with complete information or with no information about network changes has been studied, an agent with partial information about the network changes has not been considered yet despite its practical importance. In this paper, we consider the exploration of dynamic networks by a single agent with partial information about network changes. To the best of our knowledge, this is the very first work to investigate the exploration problem with such partial information. As a first step in this research direction, we focus on 1-interval connected rings as dynamic networks in this paper. We assume that the single agent has partial information called the(H,S)view by which it always knows whether or not each of the links withinHhops is available in each of the nextStime steps. In this setting, we show that H+S >= n and S >= inverted right perpendicular n/2 inverted leftt perpendicular (n is the size of the network) are necessary and sufficient conditions to explore 1-interval connected rings. Moreover, we investigate the upper and lower bounds of the exploration time. It is proven that the exploration time is O(n(2)) for inverted right perpendicular n/2 inverted leftt perpendicular <= S < 2H'-1,O(n(2)/H + n H) for S >= max (inverted right perpendicular n/2 inverted leftt perpendicular, 2H'-1), O(n(2)/H + n log H) for S >= n-1, and Omega(n(2)/H) for any S where H' = min (H, inverted right perpendicular n/2 inverted leftt perpendicular).																		1999-4893				JUN	2020	13	6							141	10.3390/a13060141													
J								Study of Quasi-Static Magnetization with the Random-Field Ising Model	ALGORITHMS										Ising model; quasi-static magnetization; magnetic simulations; hysteresis modeling	HYSTERESIS; AVALANCHES	The topic of this paper is modeling based on Hamiltonian spin interactions. Preliminary studies on the identification of quasi-static magnetizing field in a magnetic system were presented. The random-field Ising model was then used to simulate the simplified ferromagnetic structure. The validation of algorithms and simulation tests were carried out for the 2D and the 3D model spaces containing at least 10(6) unit cells. The research showed that the response of a slowly driven magnetic system did not depend on the external field sweep rate. Changes in the spatial magnetization of the lattice were very similar below a certain rate of the external field change known as the quasi-static boundary. The observed differences in obtained magnetization curves under quasi-static conditions stemmed from the random nature of the molecular field and the avalanche-like magnetization process																		1999-4893				JUN	2020	13	6							134	10.3390/a13060134													
J								Binary Time Series Classification with Bayesian Convolutional Neural Networks When Monitoring for Marine Gas Discharges	ALGORITHMS										deep learning; Bayesian convolutional neural network; uncertainty quantification; time series classification; CO2-leak detection	ANOMALY DETECTION; CO2; QUANTIFY; IMPACTS; STORAGE; TRANSFORMATION; PROBABILITY; STRATEGIES; ECOSYSTEM; DROPOUT	The world's oceans are under stress from climate change, acidification and other human activities, and the UN has declared 2021-2030 as the decade for marine science. To monitor the marine waters, with the purpose of detecting discharges of tracers from unknown locations, large areas will need to be covered with limited resources. To increase the detectability of marine gas seepage we propose a deep probabilistic learning algorithm, a Bayesian Convolutional Neural Network (BCNN), to classify time series of measurements. The BCNN will classify time series to belong to a leak/no-leak situation, including classification uncertainty. The latter is important for decision makers who must decide to initiate costly confirmation surveys and, hence, would like to avoid false positives. Results from a transport model are used for the learning process of the BCNN and the task is to distinguish the signal from a leak hidden within the natural variability. We show that the BCNN classifies time series arising from leaks with high accuracy and estimates its associated uncertainty. We combine the output of the BCNN model, the posterior predictive distribution, with a Bayesian decision rule showcasing how the framework can be used in practice to make optimal decisions based on a given cost function.																		1999-4893				JUN	2020	13	6							145	10.3390/a13060145													
J								Parallelized Swarm Intelligence Approach for Solving TSP and JSSP Problems	ALGORITHMS										optimization agents; parallel computations; traveling salesman problem; job-shop scheduling; Scala; Apache Spark	ANT COLONY OPTIMIZATION; SHOP SCHEDULING PROBLEM; ALGORITHM; SYSTEMS	One of the possible approaches to solving difficult optimization problems is applying population-based metaheuristics. Among such metaheuristics, there is a special class where searching for the best solution is based on the collective behavior of decentralized, self-organized agents. This study proposes an approach in which a swarm of agents tries to improve solutions from the population of solutions. The process is carried out in parallel threads. The proposed algorithm-based on the mushroom-picking metaphor-was implemented using Scala in an Apache Spark environment. An extended computational experiment shows how introducing a combination of simple optimization agents and increasing the number of threads may improve the results obtained by the model in the case of TSP and JSSP problems.																		1999-4893				JUN	2020	13	6							142	10.3390/a13060142													
J								Metric Embedding Learning on Multi-Directional Projections	ALGORITHMS										deep metric learning; one-shot learning; multi-directional image projections; object matching; object re-identification	IMAGE	Image based instance recognition is a difficult problem, in some cases even for the human eye. While latest developments in computer vision-mostly driven by deep learning-have shown that high performance models for classification or categorization can be engineered, the problem of discriminating similar objects with a low number of samples remain challenging. Advances from multi-class classification are applied for object matching problems, as the feature extraction techniques are the same; nature-inspired multi-layered convolutional nets learn the representations, and the output of such a model maps them to a multidimensional encoding space. A metric based loss brings same instance embeddings close to each other. While these solutions achieve high classification performance, low efficiency is caused by memory cost of high parameter number, which is in a relationship with input image size. Upon shrinking the input, the model requires less trainable parameters, while performance decreases. This drawback is tackled by using compressed feature extraction, e.g., projections. In this paper, a multi-directional image projection transformation with fixed vector lengths (MDIPFL) is applied for one-shot recognition tasks, trained on Siamese and Triplet architectures. Results show, that MDIPFL based approach achieves decent performance, despite of the significantly lower number of parameters.																		1999-4893				JUN	2020	13	6							133	10.3390/a13060133													
J								A Distributed Approach to the Evasion Problem	ALGORITHMS										evasion path; distributed algorithm	SENSOR NETWORKS; COVERAGE PROBLEM	The Evasion Problem is the question of whether-given a collection of sensors and a particular movement pattern over time-it is possible to stay undetected within the domain over the same stretch of time. It has been studied using topological techniques since 2006-with sufficient conditions for non-existence of an Evasion Path provided by de Silva and Ghrist; sufficient and necessary conditions with extended sensor capabilities provided by Adams and Carlsson; and sufficient and necessary conditions using sheaf theory by Krishnan and Ghrist. In this paper, we propose three algorithms for the Evasion Problem: one distributed algorithm extension of Adams' approach for evasion path detection, and two different approaches to evasion path enumeration.																		1999-4893				JUN	2020	13	6							149	10.3390/a13060149													
J								Numerically Efficient Fuzzy MPC Algorithm with Advanced Generation of Prediction-Application to a Chemical Reactor	ALGORITHMS										prediction; process control; model predictive control; fuzzy systems; fuzzy control; nonlinear control	OPTIMIZATION; SYSTEMS; MODELS	In Model Predictive Control (MPC) algorithms, control signals are generated after solving optimization problems. If the model used for prediction is linear then the optimization problem is a standard, easy to solve, quadratic programming problem with linear constraints. However, such an algorithm may offer insufficient performance if applied to a nonlinear control plant. On the other hand, if a model used for prediction is nonlinear, then non-convex optimization problem must be solved at each algorithm iteration. Then the numerical problems may occur during solving it and the time needed to calculate the control signals cannot be determined. Therefore approaches based on linearized models are preferred in practical applications. A fuzzy algorithm with an advanced generation of the prediction is proposed in the article. The prediction is obtained in such a way that the algorithm is formulated as a quadratic optimization problem but offers performance very close to that of the MPC algorithm with nonlinear optimization. The efficiency of the proposed approach is demonstrated in the control system of a nonlinear chemical control plant-a CSTR (Continuous Stirred-Tank Reactor) with van de Vusse reaction.																		1999-4893				JUN	2020	13	6							143	10.3390/a13060143													
J								Novel Graph Model for Solving Collision-Free Multiple-Vehicle Traveling Salesman Problem Using Ant Colony Optimization	ALGORITHMS										Traveling salesman problem; collision-free trajectory; augmented graph; augmented edge; Ant colony optimization; multiple-vehicles system	ROUTING PROBLEM; AVOIDANCE; ALGORITHM	In this paper, a novel graph model to figure Collision-Free Multiple Traveling Salesman Problem (CFMTSP) is proposed. In this problem, a group of vehicles start from different nodes in an undirected graph and must visit each node in the graph, following the well-known Traveling Salesman Problem (TSP) fashion without any collision. This paper's main objective is to obtain free-collision routes for each vehicle while minimizing the traveling time of the slowest vehicle. This problem can be approached by applying speed to each vehicle, and a novel augmented graph model can perform it. This approach accommodates not only the position of nodes and inter-node distances, but also the speed of all the vehicles is proposed. The proposed augmented graph should be able to be used to perform optimal trajectories, i.e., routes and speeds, for all vehicles. An ant colony optimization (ACO) algorithm is used on the proposed augmented graph. Simulations show that the algorithm can satisfy the main objective. Considered factors, such as limitation of the mission successfulness, i.e., the inter-vehicle arrival time on a node, the number of vehicles, and the numbers of vehicles and edges of the graph are also discussed.																		1999-4893				JUN	2020	13	6							153	10.3390/a13060153													
J								Improved Convergence Speed of a DCD-Based Algorithm for Sparse Solutions	ALGORITHMS										dichotomous coordinate descent; leading DCD; cyclic DCD; sparse systems	COMPLEXITY	To solve a system of equations that needs few updates, such as sparse systems, the leading dichotomous coordinate descent (DCD) algorithm is better than the cyclic DCD algorithm because of its fast speed of convergence. In the case of sparse systems requiring a large number of updates, the cyclic DCD algorithm converges faster and has a lower error level than the leading DCD algorithm. However, the leading DCD algorithm has a faster convergence speed in the initial updates. In this paper, we propose a combination of leading and cyclic DCD iterations, the leading-cyclic DCD algorithm, to improve the convergence speed of the cyclic DCD algorithm. The proposed algorithm involves two steps. First, by properly selecting the number of updates of the solution vector used in the leading DCD algorithm, a solution is obtained from the leading DCD algorithm. Second, taking the output of the leading DCD algorithm as the initial values, an improved soft output is generated by the cyclic DCD algorithm with a large number of iterations. Numerical results demonstrate that when the solution sparsity gamma is in the interval[1/8,6/8], the proposed leading-cyclic DCD algorithm outperforms both the existing cyclic and leading DCD algorithms for all iterations.																		1999-4893				JUN	2020	13	6							136	10.3390/a13060136													
J								Local Comparison between Two Ninth Convergence Order Algorithms for Equations	ALGORITHMS										Banach space; high convergence order algorithms; semi-local convergence	ITERATIVE METHODS; NEWTONS METHOD; SYSTEMS; VARIANTS; DYNAMICS	A local convergence comparison is presented between two ninth order algorithms for solving nonlinear equations. In earlier studies derivatives not appearing on the algorithms up to the 10th order were utilized to show convergence. Moreover, no error estimates, radius of convergence or results on the uniqueness of the solution that can be computed were given. The novelty of our study is that we address all these concerns by using only the first derivative which actually appears on these algorithms. That is how to extend the applicability of these algorithms. Our technique provides a direct comparison between these algorithms under the same set of convergence criteria. This technique can be used on other algorithms. Numerical experiments are utilized to test the convergence criteria.																		1999-4893				JUN	2020	13	6							147	10.3390/a13060147													
J								DS Evidence Theory-Based Energy Balanced Routing Algorithm for Network Lifetime Enhancement in WSN-Assisted IOT	ALGORITHMS										wireless sensor networks; Internet of Things (IOT); routing; DS evidence theory; prolong network lifetime	WIRELESS SENSOR NETWORKS; PROTOCOL	Wireless sensor networks (WSNs) can provide data acquisition for long-term environment monitoring, which are important parts of Internet of Things (IoT). In the WSN-assisted IoT, energy efficient routing algorithms are required to maintain a long network lifetime. In this paper, a DS evidence theory-based energy balanced routing algorithm for network lifetime enhancement (EBRA-NLE) in WSN-assisted IOT is proposed. From the perspective of energy balance and minimization of routing path energy consumption, three attribute indexes are established to evaluate the forward neighboring nodes. Then a route selection method based on DS evidence theory is developed to comprehensively evaluate the nodes and select the optimal next hop. In order to avoid missing the ideal solution because of the excessive difference between the index values, the sine function is used to adjust this difference. The simulation results show that the proposed EBRA-NLE has certain advantages in prolonging network lifetime and balancing energy between nodes.																		1999-4893				JUN	2020	13	6							152	10.3390/a13060152													
J								Sparse Logistic Regression: Comparison of Regularization and Bayesian Implementations	ALGORITHMS										logistic regression; sparse regularization; relevance vector machine (RVM); least absolute shrinkage and selection operator (LASSO)	OPTIMIZATION METHODS; VARIABLE SELECTION; ADAPTIVE LASSO; CLASSIFICATION; FRAMEWORK	In knowledge-based systems, besides obtaining good output prediction accuracy, it is crucial to understand the subset of input variables that have most influence on the output, with the goal of gaining deeper insight into the underlying process. These requirements call for logistic model estimation techniques that provide a sparse solution, i.e., where coefficients associated with non-important variables are set to zero. In this work we compare the performance of two methods: the first one is based on the well known Least Absolute Shrinkage and Selection Operator (LASSO) which involves regularization with an l(1) norm; the second one is the Relevance Vector Machine (RVM) which is based on a Bayesian implementation of the linear logistic model. The two methods are extensively compared in this paper, on real and simulated datasets. Results show that, in general, the two approaches are comparable in terms of prediction performance. RVM outperforms the LASSO both in term of structure recovery (estimation of the correct non-zero model coefficients) and prediction accuracy when the dimensionality of the data tends to increase. However, LASSO shows comparable performance to RVM when the dimensionality of the data is much higher than number of samples that is p >> n.																		1999-4893				JUN	2020	13	6							137	10.3390/a13060137													
J								A Relaxation of uresin and Dubois' Asynchronous Fixed-Point Theory in Agda	JOURNAL OF AUTOMATED REASONING										Asynchronous; Iterative algorithms; Formalisation; Agda	ALGORITHMS; SEMANTICS	uresin and Dubois' paper "Parallel Asynchronous Algorithms for Discrete Data" shows how a class of synchronous iterative algorithms may be transformed into asynchronous iterative algorithms. They then prove that the correctness of the resulting asynchronous algorithm can be guaranteed by reasoning about the synchronous algorithm alone. These results have been used to prove the correctness of various distributed algorithms, including in the fields of routing, numerical analysis and peer-to-peer protocols. In this paper we demonstrate several ways in which the assumptions that underlie this theory may be relaxed. Amongst others, we (i) expand the set of schedules for which the asynchronous iterative algorithm is known to converge and (ii) weaken the conditions that users must prove to hold to guarantee convergence. Furthermore, we demonstrate that two of the auxiliary results in the original paper are incorrect, and explicitly construct a counter-example. Finally, we also relax the alternative convergence conditions proposed by Gurney based on ultrametrics. Many of these relaxations and errors were uncovered after formalising the work in the proof assistant Agda. This paper describes the Agda code and the library that has resulted from this work. It is hoped that the library will be of use to others wishing to formally verify the correctness of asynchronous iterative algorithms.																	0168-7433	1573-0670				JUN	2020	64	5			SI		857	877		10.1007/s10817-019-09536-w													
J								Formal Reasoning Under Cached Address Translation	JOURNAL OF AUTOMATED REASONING										TLB; Cached address translation; Program verification; Isabelle; HOL; ARM		Operating system (OS) kernels achieve isolation between user-level processes using hardware features such as multi-level page tables and translation lookaside buffers (TLBs). The TLB caches address translation, and therefore correctly controlling the TLB is a fundamental security property of OS kernels-yet all large-scale formal OS verification projects we are aware of leave the correct functionality of TLB as an assumption. In this paper, we present a verified sound abstraction of a detailed concrete model of the memory management unit (MMU) of the ARMv7-A architecture. This MMU abstraction revamps our previous address space specific MMU abstraction to include new software-visible TLB features such as caching of globally-mapped and partial translation entries in a two-stage TLB. We use this abstraction as the underlying model to develop a logic for reasoning about low-level programs in the presence of cached address translation. We extract invariants and necessary conditions for correct TLB operation that mirrors the informal reasoning of OS engineers. We systematically show how these invariants adapt to global and partial translation entries. We show that our program logic reduces to a standard logic for user-level reasoning, reduces to side-condition checks for kernel-level reasoning, and can handle typical OS kernel tasks such as context switching.																	0168-7433	1573-0670				JUN	2020	64	5			SI		911	945		10.1007/s10817-019-09539-7													
J								A prototype knockoff filter for group selection with FDR control	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										variable selection; false discovery rate (FDR); group variable selection; knockoff filter; linear regression	FALSE DISCOVERY RATE	In many applications, we need to study a linear regression model that consists of a response variable and a large number of potential explanatory variables, and determine which variables are truly associated with the response. In Foygel Barber & Candes (2015, Ann. Statist., 43, 2055-2085), the authors introduced a new variable selection procedure called the knockoff filter to control the false discovery rate (FDR) and proved that this method achieves exact FDR control. In this paper, we propose a prototype knockoff filter for group selection by extending the Reid-Tibshirani (2016, Biostatistics, 17, 364-376) prototype method. Our prototype knockoff filter improves the computational efficiency and statistical power of the Reid-Tibshirani prototype method when it is applied for group selection. In some cases when the group features are spanned by one or a few hidden factors, we demonstrate that the Principal Component Analysis (PCA) prototype knockoff filter outperforms the Dai-Foygel Barber (2016, 33rd International Conference on Machine Learning (ICML 2016)) group knockoff filter. We present several numerical experiments to compare our prototype knockoff filter with the Reid-Tibshirani prototype method and the group knockoff filter. We have also conducted some analysis of the knockoff filter. Our analysis reveals that some knockoff path method statistics, including the Lasso path statistic, may lead to loss of power for certain design matrices and a specially designed response even if their signal strengths are still relatively strong.																	2049-8764	2049-8772				JUN	2020	9	2					271	288		10.1093/imaiai/iaz012													
J								Non-convex low-rank matrix recovery with arbitrary outliers via median-truncated gradient descent	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										median-truncated gradient descent; low-rank matrix recovery; non-convex approach; robust algorithms; outliers	COMPLETION	Recent work has demonstrated the effectiveness of gradient descent for directly recovering the factors of low-rank matrices from random linear measurements in a globally convergent manner when initialized properly. However, the performance of existing algorithms is highly sensitive in the presence of outliers that may take arbitrary values. In this paper, we propose a truncated gradient descent algorithm to improve the robustness against outliers, where the truncation is performed to rule out the contributions of samples that deviate significantly from the sample median of measurement residuals adaptively in each iteration. We demonstrate that, when initialized in a basin of attraction close to the ground truth, the proposed algorithm converges to the ground truth at a linear rate for the Gaussian measurement model with a near-optimal number of measurements, even when a constant fraction of the measurements are arbitrarily corrupted. In addition, we propose a new truncated spectral method that ensures an initialization in the basin of attraction at slightly higher requirements. We finally provide numerical experiments to validate the superior performance of the proposed approach.																	2049-8764	2049-8772				JUN	2020	9	2					289	325		10.1093/imaiai/iaz009													
J								Network topology inference using information cascades with limited statistical knowledge	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										network topology inference; information cascades; information diffusion; graph theory	INFECTION SOURCE	We study the problem of inferring network topology from information cascades, in which the amount of time taken for information to diffuse across an edge in the network follows an unknown distribution. Unlike previous studies, which assume knowledge of these distributions, we only require that diffusion along different edges in the network be independent together with limited moment information (e.g. the means). We introduce the concept of a separating vertex set for a graph, which is a set of vertices in which for any two given distinct vertices of the graph there exists a vertex whose distance to them is different. We show that a necessary condition for reconstructing a tree perfectly using distance information between pairs of vertices is given by the size of an observed separating vertex set. We then propose an algorithm to recover the tree structure using infection times whose differences have means corresponding to the distance between two vertices. To improve the accuracy of our algorithm, we propose the concept of redundant vertices, which allows us to perform averaging to better estimate the distance between two vertices. Though the theory is developed mainly for tree networks, we demonstrate how the algorithm can be extended heuristically to general graphs. Simulations using synthetic and real networks and experiments using real-world data suggest that our proposed algorithm performs better than some current state-of-the-art network reconstruction methods.																	2049-8764	2049-8772				JUN	2020	9	2					327	360		10.1093/imaiai/iaz005													
J								Robust 1-bit compressed sensing via hinge loss minimization	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										1-bit compressed sensing; structured empirical risk minimization; hinge loss; Gaussian width; Mendelson's small ball method	SIGNAL RECOVERY; CONVEX GEOMETRY; RECONSTRUCTION	This work theoretically studies the problem of estimating a structured high-dimensional signal x(0) is an element of R-n from noisy 1-bit Gaussian measurements. Our recovery approach is based on a simple convex program which uses the hinge loss function as data fidelity term. While such a risk minimization strategy is very natural to learn binary output models, such as in classification, its capacity to estimate a specific signal vector is largely unexplored. A major difficulty is that the hinge loss is just piecewise linear, so that its 'curvature energy' is concentrated in a single point. This is substantially different from other popular loss functions considered in signal estimation, e.g. the square or logistic loss, which are at least locally strongly convex. It is therefore somewhat unexpected that we can still prove very similar types of recovery guarantees for the hinge loss estimator, even in the presence of strong noise. More specifically, our non-asymptotic error bounds show that stable and robust reconstruction of x(0) can be achieved with the optimal oversampling rate O(m(-1/2)) in terms of the number of measurements m. Moreover, we permit a wide class of structural assumptions on the ground truth signal, in the sense that x(0) can belong to an arbitrary bounded convex set K subset of R-n. The proofs of our main results rely on some recent advances in statistical learning theory due to Mendelson. In particular, we invoke an adapted version of Mendelson's small ball method that allows us to establish a quadratic lower bound on the error of the first-order Taylor approximation of the empirical hinge loss function.																	2049-8764	2049-8772				JUN	2020	9	2					361	422		10.1093/imaiai/iaz010													
J								Near-optimal recovery of linear and N-convex functions on unions of convex sets	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										non-parametric estimation; linear functional estimation; convex optimization	NONPARAMETRIC-ESTIMATION; DENSITY; RESTORATION; EMISSION; RATES	In this paper we build provably near-optimal, in the minimax sense, estimates of linear forms and, more generally, 'N-convex functionals' (an example being the maximum of several fractional-linear functions) of unknown 'signal' from indirect noisy observations, the signal assumed to belong to the union of finitely many given convex compact sets. Our main assumption is that the observation scheme in question is good in the sense of Goldenshluger et al. (2015, Electron. J. Stat., 9, 1645-1712), the simplest example being the Gaussian scheme, where the observation is the sum of linear image of the signal and the standard Gaussian noise. The proposed estimates, same as upper bounds on their worst-case risks, stem from solutions to explicit convex optimization problems, making the estimates 'computation-friendly'.																	2049-8764	2049-8772				JUN	2020	9	2					423	453		10.1093/imaiai/iaz011													
J								Analysis of hard-thresholding for distributed compressed sensing with one-bit measurements	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										joint sparsity; one-bit quantization; hard-thresholding; compressed sensing	SIGNAL RECOVERY; RECONSTRUCTION	A simple hard-thresholding operation is shown to be able to uniformly recover L signals x(1), ..., x(L) is an element of R-n that share a common support of size s from m = O(s) one-bit measurements per signal if L >= ln(en/s). This result improves the single signal recovery bounds with m = O(s ln(en/s)) measurements in the sense that asymptotically fewer measurements per non-zero entry are needed. Numerical evidence supports the theoretical considerations.																	2049-8764	2049-8772				JUN	2020	9	2					455	471		10.1093/imaiai/iaz004													
J								Size-independent sample complexity of neural networks	INFORMATION AND INFERENCE-A JOURNAL OF THE IMA										neural networks; deep learning; sample complexity; Rademacher complexity	VC DIMENSION; BOUNDS; WEIGHTS; 2-LAYER	We study the sample complexity of learning neural networks by providing new bounds on their Rademacher complexity, assuming norm constraints on the parameter matrix of each layer. Compared to previous work, these complexity bounds have improved dependence on the network depth and, under some additional assumptions, are fully independent of the network size (both depth and width). These results are derived using some novel techniques, which may be of independent interest.																	2049-8764	2049-8772				JUN	2020	9	2					473	504		10.1093/imaiai/iaz007													
J								A Novel Nature-Inspired Technique Based on Mushroom Reproduction for Constraint Solving and Optimization	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Constraint optimization; metaheuristics; evolutionary computation	PARTICLE SWARM OPTIMIZATION; GENETIC ALGORITHMS; ANT COLONY; SEARCH ALGORITHM; SIMULATION; INTEGER; SCHEME; MODEL	Constraint optimization consists of looking for an optimal solution maximizing a given objective function while meeting a set of constraints. In this study, we propose a new algorithm based on mushroom reproduction for solving constraint optimization problems. Our algorithm, that we call Mushroom Reproduction Optimization (MRO), is inspired by the natural reproduction and growth mechanisms of mushrooms. This process includes the discovery of rich areas with good living conditions allowing spores to grow and develop their own colonies. Given that constraint optimization problems often suffer from a high-time computation cost, we thoroughly assess MRO performance on well-known constrained engineering and real-world problems. The experimental results confirm the high performance of MRO, comparing to other known meta-heursitcs, in dealing with complex optimization problems.																	1469-0268	1757-5885				JUN	2020	19	2							2050010	10.1142/S1469026820500108													
J								Application of a Chaotic Quantum Bee Colony and Support Vector Regression to Multipeak Maximum Power Point Tracking Control Method Under Partial Shading Conditions	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Partial shading; multipeak characteristics; maximum power point tracking; chaotic quantum-inspired artificial bee colony; parameter optimization	SWARM OPTIMIZATION; MPPT	In view of the multipeak characteristics of a photovoltaic (PV) array P-V curve under local shadow conditions and that the traditional maximum power point tracking (MPPT) algorithm cannot effectively track the maximum power point of the curve, a multipeak MPPT algorithm based on a chaotic quantum bee colony and support vector regression (SVR) is proposed. By constructing and analyzing the mathematical model of a photovoltaic array under a local shadow, the P-V characteristic equation of the photovoltaic array is obtained. The improved strategy of the artificial bee colony algorithm is studied, and the improved chaotic quantum bee colony algorithm (CQABC) is applied to the optimization of SVR parameters; this application improves the accuracy and generalization performance of the maximum power point prediction model based on SVR. The calculation process of the multipeak MPPT algorithm based on CQABC-SVR is given, and the effectiveness of the algorithm is verified by simulation and testing. The experimental results show that the algorithm can accurately track the global maximum power point under uniform illumination or local shadow conditions, effectively overcoming the problem of traditional MPPT algorithms easily falling into local extrema.																	1469-0268	1757-5885				JUN	2020	19	2							2050014	10.1142/S1469026820500145													
J								Deep Network based on Long Short-Term Memory for Time Series Prediction of Microclimate Data inside the Greenhouse	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Long short-term memory; time series prediction; deep learning network; microclimate greenhouse mathematical model	NEURAL-NETWORKS; SYSTEMS; OPTIMIZATION	An enhanced architecture of recurrent neural network based on Long Short-Term Memory (LSTM) is suggested in this paper for predicting the microclimate inside the greenhouse through its time series data. The microclimate inside the greenhouse largely affected by the external weather variations and it has a great impact on the greenhouse crops and its production. Therefore, it is a massive importance to predict the microclimate inside greenhouse as a preceding stage for accurate design of a control system that could fulfill the requirements of suitable environment for the plants and crop managing. The LSTM network is trained and tested by the temperatures and relative humidity data measured inside the greenhouse utilizing the mathematical greenhouse model with the outside weather data over 27 days. To evaluate the prediction accuracy of the suggested LSTM network, different measurements, such as Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), are calculated and compared to those of conventional networks in references. The simulation results of LSTM network for forecasting the temperature and relative humidity inside greenhouse outperform over those of the traditional methods. The prediction results of temperature and humidity inside greenhouse in terms of RMSE approximately are 0.16 and 0.62 and in terms of MAE are 0.11 and 0.4, respectively, for both of them.																	1469-0268	1757-5885				JUN	2020	19	2							2050013	10.1142/S1469026820500133													
J								A Hybrid Machine Learning Approach for Flood Risk Assessment and Classification	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Clustering; visualization; knowledge discovery; ANFIS; k-means; data science; SOM		Communities globally experience devastating effects, high monetary loss and loss of lives due to incidents of flood and other hazards. Inadequate information and awareness of flood hazard make the management of flood risks arduous and challenging. This paper proposes a hybridized analytic approach via unsupervised and supervised learning methodologies, for the discovery of pieces of knowledge, clustering and prediction of flood severity levels (FSL). A two-staged unsupervised learning based on k-means and self-organizing maps (SOM) was performed on the unlabeled flood dataset. K-means based on silhouette criterion discovered top three representatives of the optimal numbers of clusters inherent in the flood dataset. Experts' judgment favored four clusters, while Squared Euclidean distance was the best performing distance measure. SOM provided cluster visuals of the input attributes within the four different groups and transformed the dataset into a labeled one. A 5-layered Adaptive Neuro Fuzzy Inference System (ANFIS) driven by hybrid learning algorithm was applied to classify and predict FSL. ANFIS optimized by Genetic Algorithm (GA) produced root mean squared error (RMSE) of 0.323 and Error Standard Deviation of 0.408 while Particle Swarm Optimized ANFIS model produced 0.288 as the RMSE, depicting 11% improvement when compared with GA optimized model. The result shows significant improvement in the classification and prediction of flood risks using single ML tool.																	1469-0268	1757-5885				JUN	2020	19	2							2050012	10.1142/S1469026820500121													
J								Spatial Relational Attention Using Fully Convolutional Networks for Image Caption Generation	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Spatial relation; attention-based model; image caption generation		Attention-based encoder-decoder framework has greatly improved image caption generation tasks. The attention mechanism plays a transitional role by transforming static image features into sequential captions. To generate reasonable captions, it is of great significance to detect spatial characteristics of images. In this paper, we propose a spatial relational attention approach to consider spatial positions and attributes. Image features are firstly weighted by the attention mechanism. Then they are concatenated with contextual features to form a spatial-visual tensor. The tensor is feature extracted by a fully convolutional network to produce visual concepts for the decoder network. The fully convolutional layers maintain spatial topology of images. Experiments conducted on the three benchmark datasets, namely Flickr8k, Flickr30k and MSCOCO, demonstrate the effectiveness of our proposed approach. Captions generated by the spatial relational attention method precisely capture spatial relations of objects.																	1469-0268	1757-5885				JUN	2020	19	2							2050011	10.1142/S146902682050011X													
J								Enhanced Forecasting Accuracy of Fuzzy Time Series Model Based on Combined Fuzzy C-Mean Clustering with Particle Swam Optimization	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Enrolments; forecasting; FTS; fuzzy logical relationships; PSO; FCM	LOGICAL RELATIONSHIPS; ENROLLMENTS	Over the past 25 years, numerous fuzzy time series forecasting models have been proposed to deal the complex and uncertain problems. The main factors that affect the forecasting results of these models are partition universe of discourse, creation of fuzzy relationship groups and defuzzification of forecasting output values. So, this study presents a hybrid fuzzy time series forecasting model combined particle swarm optimization (PSO) and fuzzy C-means clustering (FCM) for solving issues above. The FCM clustering is used to divide the historical data into initial intervals with unequal size. After generating interval, the historical data is fuzzified into fuzzy sets with the aim to serve for establishing fuzzy relationship groups according to chronological order. Then the information obtained from the fuzzy relationship groups can be used to calculate forecasted value based on a new defuzzification technique. In addition, in order to enhance forecasting accuracy, the PSO algorithm is used for finding optimum interval lengths in the universe of discourse. The proposed model is applied to forecast three well-known numerical datasets (enrolments data of the University of Alabama, the Taiwan futures exchange-TAIFEX data and yearly deaths in car road accidents in Belgium). These datasets are also examined by using some other forecasting models available in the literature. The forecasting results obtained from the proposed model are compared to those produced by the other models. It is observed that the proposed model achieves higher forecasting accuracy than its counterparts for both first-order and high-order fuzzy logical relationship.																	1469-0268	1757-5885				JUN	2020	19	2							2050017	10.1142/S1469026820500170													
J								Application of Deep Learning Technique in an Intrusion Detection System	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Intrusion Detection System (IDS); deep learning technique; attack detection; Distributed Denial of Service attack	GENETIC-ALGORITHM	Comprehensive development of computer networks causes the increment of Distributed Denial of Service (DDoS) attacks. These types of attacks can easily restrict communication and computing. Among all the previous researches, the accuracy of the attack detection has not been properly addressed. In this study, deep learning technique is used in a hybrid network-based Intrusion Detection System (IDS) to detect intrusion on network. The performance of the proposed technique is evaluated on the NSL-KDD and ISCXIDS 2012 datasets. We performed traffic visual analysis using Wireshark tool and did some experimentations to prove the superiority of the proposed method. The results have shown that our proposed method achieved higher accuracy in comparison with other useful machine learning techniques.																	1469-0268	1757-5885				JUN	2020	19	2							2050016	10.1142/S1469026820500169													
J								A Multilevel Image Thresholding Approach Based on Crow Search Algorithm and Otsu Method	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS										Image segmentation; image thresholding; Otsu method; Crow Search Algorithm; multilevel thresholding		Image segmentation is one of the fundamental problems in the image processing, which identifies the objects and other structures in the image. One of the widely used methods for image segmentation is image thresholding that can separate pixels based on the specified thresholds. Otsu method calculates the thresholds to divide two or multiple classes based on between-class variance maximization and within-class variance minimization. However, increasing the number of thresholds, surging the computational time of the segmentation. To combat this drawback, the combination of Otsu and the evolutionary algorithm is usually beneficial. Crow Search Algorithm (CSA) is a novel, and efficient swarm-based metaheuristic algorithm that inspired from the way crows storing and retrieving food. In this paper, we proposed a hybrid method based on employing CSA and Otsu for multilevel thresholding. The obtained results compared with the combination of the Otsu method with three other evolutionary algorithms consisting of improved Particle Swarm Optimization (PSO), Firefly Algorithm (FA), and also the fuzzy version of FA. Our evaluation on the five benchmark images shows competitive/improved results both in time and uniformity.																	1469-0268	1757-5885				JUN	2020	19	2							2050015	10.1142/S1469026820500157													
J								Parallel computation of Watershed Transform in weighted graphs on shared memory machines	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image segmentation; Parallel algorithms; Real-time performance; Watershed cuts; Shared memory multicore architecture	ALGORITHM	Watershed Transform is a widely used image segmentation technique that is known to be very data intensive and time consuming. The M-border Kernel Algorithm computes watersheds in the framework of Edge-Weighted Graphs and allows to preserve the topology of the initial map. Parallelization represents an effective solution to accelerate it. However, this task remains challenging due to the nature of this technique. In this paper, we address this problem. We start by analyzing the data dependency issues that this algorithm raises when dealing with parallel execution. With respect to that, we propose a parallelization strategy that opts for vertex scanning instead of edges scanning of the graph while preserving the thinning paradigm on which the M-border Kernel Algorithm is based. We show that this strategy overcomes the problem of the simultaneous lowering of two adjacent M-border edges that may occur when edge scan is used. The implementation of the proposed algorithm on a shared memory multicore architecture proves its effectiveness in terms of speedup. In fact, the experimental results show that a speedup factor of 5.55 is achieved using eight processors for 2048x2048 images over the performance of the sequential algorithm using a single processor on the same architecture. Furthermore, the gain in terms of execution time and thus speedup is guaranteed whatever is the size of images on which the algorithm is applied. In fact, a speedup factor of 5.55 is obtained for 2048x2048 images, 5.11 for 1024x1024 images and 4.45 for 512x512 images using eight cores.																	1861-8200	1861-8219				JUN	2020	17	3					527	542		10.1007/s11554-018-0804-x													
J								An initialization method for the latent vectors in probabilistic matrix factorization for sparse datasets	EVOLUTIONARY INTELLIGENCE										Probabilistic matrix factorization; Latent vectors; Recommendation systems; Sparsity	RECOMMENDER	Recommendation-based e-commerce applications have been utilized by many companies to increase their sales performance. Probabilistic matrix factorization (PMF) is a widely-used method for collaborative filtering in recommendation systems. Although the method's performance has been demonstrated successfully in many challenging datasets including Netflix, they are not able to perform well in large sparse datasets where there is considerably low number of rating information. As a remedy, numerous advancements of PMF were proposed which incorporated side information into latent vectors as priors in order to ensure richer prior information in them. However, in cases where such side information is inaccessible, PMF-based algorithms do not perform well. In this study, we propose two new initialization methods for PMF which take into consideration the distribution statistics of user product ratings to enrich latent vectors. The experiments show that the proposed solutions give better results to those in the literature in very sparse datasets.																	1864-5909	1864-5917				JUN	2020	13	2			SI		269	281		10.1007/s12065-019-00299-2													
J								Single-image crowd counting: a comparative survey on deep learning-based approaches	INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL										Crowd counting; Computer vision; Deep learning; Literature review	DENSITY	Crowd counting is an attracting computer vision problem. Solutions to crowd counting hold high adaptability to other counting problems such as traffic counting and cell counting. Numerous methods have been proposed for the problem. Deep learning-based methods play a significant role in recent advancement. However, no existing literature reviews capture their sophisticated development by challenges. In this paper, we discuss and categorize recent deep learning works in crowd counting by considering how they address the challenges.																	2192-6611	2192-662X				JUN	2020	9	2			SI		63	80		10.1007/s13735-019-00181-y													
J								VARIABLE-STRUCTURE REPETITIVE CONTROL FOR DISCRETE-TIME LINEAR SYSTEMS WITH MULTIPLE-PERIOD EXOGENOUS SIGNALS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										repetitive control; variable-structure control; multiple-period signals; fast transient response; robustness	LEARNING CONTROL; CONTROL SCHEME; H-INFINITY; DESIGN; OBSERVER	A new method to construct a discrete-time variable-structure repetitive controller for a class of linear systems perturbed by multiple-period exogenous signals is presented. The proposed control scheme combines the features of the discrete-time multiple-period repetitive control (MP-RC) and variable-structure control (VSC) techniques. The MP-RC part is assigned to simultaneously track and reject periodic signals consisting of multiple uncorrelated fundamental frequencies. The VSC part is then integrated to provide a fast transient response and robustness against plant parameter variations. Stability and robustness analyses are also elaborated to ensure that the resulting closed-loop system satisfies the desired control objectives. Moreover, it is shown through an example that the repetitive control system constructed using the proposed control method can effectively track a sinusoidal reference signal despite the presence of a multiple-period disturbance.																	1641-876X	2083-8492				JUN	2020	30	2					207	218		10.34768/amcs-2020-0016													
J								APPLICATION OF THE DRAZIN INVERSE TO THE ANALYSIS OF POINTWISE COMPLETENESS AND POINTWISE DEGENERACY OF DESCRIPTOR FRACTIONAL LINEAR CONTINUOUS-TIME SYSTEMS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										pointwise completeness; pointwise degeneracy; fractional systems; descriptor systems	INVARIANT	The Drazin inverse of matrices is applied to the analysis of pointwise completeness and pointwise degeneracy of fractional descriptor linear continuous-time systems. It is shown that (i) descriptor linear continuous-time systems are pointwise complete if and only if the initial and final states belong to the same subspace, and (ii) fractional descriptor linear continuous-time systems are not pointwise degenerated in any nonzero direction for all nonzero initial conditions. The discussion is illustrated with examples of descriptor linear electrical circuits.																	1641-876X	2083-8492				JUN	2020	30	2					219	223		10.34768/amcs-2020-0017													
J								DECENTRALIZED STATIC OUTPUT TRACKING CONTROL OF INTERCONNECTED AND DISTURBED TAKAGI-SUGENO SYSTEMS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										interconnected Takagi-Sugeno systems; decentralized static outputs tracking controllers; H-infinity criterion; LMIs	LARGE-SCALE SYSTEMS; CONTROL DESIGN; STABILIZATION	This article describes a new procedure for the design of decentralized output-feedback tracking controllers for a class of interconnected Takagi-Sugeno (TS) fuzzy systems with external bounded disturbances and measurement noise. The main idea consists in transforming the decentralized tracking control problem, by using the descriptor redundancy formulation, to a robust decentralized stabilization one. The non-parallel distributed compensation (non-PDC) controllers proposed here are synthesized to satisfy robust H-infinity tracking performance with disturbance attenuation. The decentralized controllers design conditions are given in terms of LMIs via extended quadratic Lyapunov functions. Finally, simulations are presented: two numerical examples are dedicated to compare the conservatism of the proposed approach regarding the previous results available in the literature; then, the effectiveness of the decentralized controller design methodology is illustrated with a closed-loop simulation of two inverted pendulums connected by a spring.																	1641-876X	2083-8492				JUN	2020	30	2					225	238		10.34768/amcs-2020-0018													
J								DECENTRALIZED AND DISTRIBUTED ACTIVE FAULT DIAGNOSIS: MULTIPLE MODEL ESTIMATION ALGORITHMS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										fault diagnosis; large scale systems; multiple models	SYSTEMS	The paper focuses on active fault diagnosis (AFD) of large scale systems. The multiple model framework is considered and two architectures are treated: the decentralized and the distributed one. An essential part of the AFD algorithm is state estimation, which must be supplemented with a mechanism to achieve feasible implementation in the multiple model framework. In the paper. the generalized pseudo Bayes and interacting multiple model estimation algorithms are considered. They are reformulated for a given model of a large scale system. Performance of both AFD architectures is analyzed for different combinations of multiple model estimation algorithms using a numerical example.																	1641-876X	2083-8492				JUN	2020	30	2					239	249		10.34768/amcs-2020-0019													
J								ON THREE METHODS FOR BOUNDING THE RATE OF CONVERGENCE FOR SOME CONTINUOUS-TIME MARKOV CHAINS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										inhomogeneous continuous-time Markov chains; weak ergodicity; Lyapunov functions; differential inequalities; forward Kolmogorov system	PERTURBATION BOUNDS; PERFORMANCE ANALYSIS; INHOMOGENEOUS BIRTH; QUEUING-SYSTEMS; STABILITY; TRUNCATIONS; QUEUES	Consideration is given to three different analytical methods for the computation of upper bounds for the rate of convergence to the limiting regime of one specific class of (in)homogeneous continuous-time Markov chains. This class is particularly well suited to describe evolutions of the total number of customers in (in)homogeneous M/M/S queueing systems with possibly state-dependent arrival and service intensities, batch arrivals and services. One of the methods is based on the logarithmic norm of a linear operator function; the other two rely on Lyapunov functions and differential inequalities, respectively. Less restrictive conditions (compared with those known from the literature) under which the methods are applicable are being formulated. Two numerical examples are given. It is also shown that. for homogeneous birth-death Markov processes defined on a finite state space with all transition rates being positive, all methods yield the same sharp upper bound.																	1641-876X	2083-8492				JUN	2020	30	2					251	266		10.34768/amcs-2020-0020													
J								STABILIZATION ANALYSIS OF IMPULSIVE STATE-DEPENDENT NEURAL NETWORKS WITH NONLINEAR DISTURBANCE: A QUANTIZATION APPROACH	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										state-dependent neural networks; quantized input; stabilization	SYNCHRONIZATION; STABILITY	In this paper, the problem of feedback stabilization for a class of impulsive state-dependent neural networks (ISDNNs) with nonlinear disturbance inputs via quantized input signals is discussed. By constructing quasi-invariant sets and attracting sets for ISDNNs, we design a quantized controller with adjustable parameters. In combination with a suitable ISS-Lyapunov functional and a hybrid quantized control strategy, we propose novel criteria on input-to-state stability and global asymptotical stability for ISDNNs. Our results complement the existing ones. Numerical simulations are reported to substantiate the theoretical results and effectiveness of the proposed strategy.																	1641-876X	2083-8492				JUN	2020	30	2					267	279		10.34768/amcs-2020-0021													
J								FLEXIBLE RESAMPLING FOR FUZZY DATA	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										bootstrap; fuzzy data; fuzzy numbers; fuzzy sample; imprecise data; resampling	EXPECTED VALUE; BOOTSTRAP; INTERVAL; ALGORITHMS; VARIABLES	In this paper, a new methodology for simulating bootstrap samples of fuzzy numbers is proposed. Unlike the classical bootstrap, it allows enriching a resampling scheme with values from outside the initial sample. Although a secondary sample may contain results beyond members of the primary set, they are generated smartly so that the crucial characteristics of the original observations remain invariant. Two methods for generating bootstrap samples preserving the representation (i.e., the value and the ambiguity or the expected value and the width) of fuzzy numbers belonging to the primary sample are suggested and numerically examined with respect to other approaches and various statistical properties.																	1641-876X	2083-8492				JUN	2020	30	2					281	297		10.34768/amcs-2020-0022													
J								ROUGH SETS BASED ON GALOIS CONNECTIONS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										rough sets; Galois connections; approximation operators	FUZZY RELATION EQUATIONS; FORMAL CONCEPT ANALYSIS; MATHEMATICAL MORPHOLOGY; ATTRIBUTE; APPROXIMATIONS; DEFINITION; REDUCTION	Rough set theory is an important tool to extract knowledge from relational databases. The original definitions of approximation operators are based on an indiscernibility relation, which is an equivalence one. Lately. different papers have motivated the possibility of considering arbitrary relations. Nevertheless, when those are taken into account, the original definitions given by Pawlak may lose fundamental properties. This paper proposes a possible solution to the arising problems by presenting an alternative definition of approximation operators based on the closure and interior operators obtained from an isotone Galois connection. We prove that the proposed definition satisfies interesting properties and that it also improves object classification tasks.																	1641-876X	2083-8492				JUN	2020	30	2					299	313		10.34768/amcs-2020-0023													
J								NEW MODELS AND ALGORITHMS FOR RNA PSEUDOKNOT ORDER ASSIGNMENT	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										RNA pseudoknot order; conflict graph; vertex coloring; maximum independent set; integer programming	SECONDARY STRUCTURES; STRUCTURE PREDICTION; GRAPH-THEORY; 3D; NETWORKS; DYNAMICS; SIMILARITIES; RNACOMPOSER; STABILITY; PLATFORM	The pseudoknot is a specific motif of the RNA structure that highly influences the overall shape and stability of a molecule. It occurs when nucleotides of two disjoint single-stranded fragments of the same chain, separated by a helical fragment, interact with each other and form base pairs. Pseudoknots are characterized by great topological diversity, and their systematic description is still a challenge. In our previous work, we have introduced the pseudoknot order a new coefficient representing the topological complexity of the pseudoknotted RNA structure. It is defined as the minimum number of base pair set decompositions, aimed to obtain the unknotted RNA structure. We have suggested how it can be useful in the interpretation and understanding of a hierarchy of RNA folding. However, it is not trivial to unambiguously identify pseudoknots and determine their orders in an RNA structure. Therefore, since the introduction of this coefficient, we have worked on the method to reliably assign pseudoknot orders in correspondence to the mechanisms that control the biological process leading to their formation in the molecule. Here, we introduce a novel graph coloring-based model for the problem of pseudoknot order assignment. We show a specialized heuristic operating on the proposed model and an alternative integer programming algorithm. The performance of both approaches is compared with that of state-of-the-art algorithms which so far have been most efficient in solving the problem in question. We summarize the results of computational experiments that evaluate our new methods in terms of classification quality on a representative data set originating from the non-redundant RNA 3D structure repository.																	1641-876X	2083-8492				JUN	2020	30	2					315	324		10.34768/amcs-2020-0024													
J								BOUNDED-ABSTAINING CLASSIFICATION FOR BREAST TUMORS IN IMBALANCED ULTRASOUND IMAGES	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										breast ultrasound (BUS) images; reliable diagnosis; abstaining classification; imbalanced datasets	SPECKLE NOISE-REDUCTION; TEXTURAL FEATURES; CANCER; DIAGNOSIS; PREDICTION; BENIGN; ELASTOGRAPHY; REJECTION; MODEL	Computer-aided breast ultrasound (BUS) diagnosis remains a difficult task. One of the challenges is that imbalanced BUS datasets lead to poor performance, especially with regard to low accuracy in the minority (malignant tumor) class. Missed diagnosis of malignant tumors can cause serious consequences, such as delaying treatment and increasing the risk of death. Moreover, many diagnosis methods do not consider classification reliability; thus, some classifications may have a large uncertainty. To resolve such problems, a bounded-abstaining classification model is proposed. It maximizes the area under the ROC curve (AUC) under two abstention constraints. A total of 219 (92 malignant and 127 benign) BUS images are collected from the First Affiliated Hospital of Harbin Medical University, China. The experiment tests BUS datasets of three imbalance levels, and the performance contours are analyzed. The results demonstrate that AUC-rejection curves are less affected by class imbalance than accuracy-rejection curves. Compared with the state-of-the-art, the proposed method yields a significantly larger AUC and G-mean using imbalanced BUS datasets.																	1641-876X	2083-8492				JUN	2020	30	2					325	336		10.34768/amcs-2020-0025													
J								DEFORMED SOLITONS OF A TYPICAL SET OF (2+1)-DIMENSIONAL COMPLEX MODIFIED KORTEWEG-DE VRIES EQUATIONS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										(2+1)-dimensional complex modified Korteweg-de Vries equation; Darboux transformation; deformed soliton solution	DARBOUX TRANSFORMATION; RATIONAL SOLUTIONS; KDV EQUATION; WAVES; FIBER	Deformed soliton solutions are studied in a typical set of (2+1)-dimensional complex modified Korteweg-de Vries (cmKdV) equations. Through constructing the determinant form of the n-fold Darboux transformation for these (2+1)-dimensional cmKdV equations, we obtain general order-n deformed soliton solutions using zero seeds. With no loss of generality, we focus on order-1 and order-2 deformed solitons. Three types of order-1 deformed solitons, namely, the polynomial type, the trigonometric type, and the hyperbolic type, are derived. Meanwhile, their dynamical behaviors, including amplitude, velocity, direction, periodicity, and symmetry, are also investigated in detail. In particular, the formulas of vertical bar q([1])vertical bar and trajectories are provided analytically, which are involved by an arbitrary smooth function f (y + 4 lambda(2)t). For order-2 cases, we obtain the general analytical expressions of deformed solitons. Two typical solitons, possessing different properties in temporal symmetry. are discussed.																	1641-876X	2083-8492				JUN	2020	30	2					337	350		10.34768/amcs-2020-0026													
J								SOLUTION OF AN INVERSE KINEMATICS PROBLEM USING DUAL QUATERNIONS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										dual quaternions; kinematics; simulation; robotics; screw theory	MANIPULATORS	The paper proposes a solution to an inverse kinematics problem based on dual quaternions algebra. The method, relying on screw theory, requires less calculation effort compared with commonly used approaches. The obtained kinematic description is very concise, and the singularity problem is avoided. The dual quaternions formalism is applied to the problem decomposition and description. As an example, the kinematics problem of a multi-DOF serial manipulator is considered. Direct and inverse kinematics problems are solved using division into sub-problems. Each new sub-problem proposed is concerned with rotation about two subsequent axes by a given amount. The presented example verifies the correctness and feasibility of the proposed approach.																	1641-876X	2083-8492				JUN	2020	30	2					351	361		10.34768/amcs-2020-0027													
J								A LINEAR PROGRAMMING METHODOLOGY FOR APPROXIMATE DYNAMIC PROGRAMMING	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										linear programming; approximate dynamic programming; control applications; neural networks		The linear programming (LP) approach to solve the Bellman equation in dynamic programming is a well-known option for finite state and input spaces to obtain an exact solution. However, with function approximation or continuous state spaces, refinements are necessary. This paper presents a methodology to make approximate dynamic programming via LP work in practical control applications with continuous state and input spaces. There are some guidelines on data and regressor choices needed to obtain meaningful and well-conditioned value function estimates. The work discusses the introduction of terminal ingredients and computation of lower and upper bounds of the value function. An experimental inverted-pendulum application will be used to illustrate the proposal and carry out a suitable comparative analysis with alternative options in the literature.																	1641-876X	2083-8492				JUN	2020	30	2					363	375		10.34768/amcs-2020-0028													
J								IMAGE CIPHER APPLICATIONS USING THE ELLIPTICAL CURVE AND CHAOS	INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE										elliptic curve; chaos; entropy; discrete Fourier transform; image ciphering	ENCRYPTION ALGORITHM; HYPER-CHAOS; SCHEME; COMPRESSION; ATTACK	A novel symmetric cryptosystem of the substitution permutation network type is presented for image encryption in 14 rounds. An algorithm is developed to generate 15 keys to encrypt images where each key is the image size. These keys are calculated using an elliptic curve with a constant zero value. The proposed curve is non-singular, non-supersingular, nor trace one. Chaos is employed to find a generating element in a cyclic subgroup and it is produced using the logistic map equation. In addition, a 16 x 16 substitution box is constructed using both chaos and an algorithm that defines a bijective function. The following tools are used in order to measure the degree of randomness of the encrypted figures: entropy, correlation, the discrete Fourier transform and a goodness-of-fit test with the chi-square distribution. Furthermore, an image size variable permutation is applied in the first round, and its inverse in the fourteenth.																	1641-876X	2083-8492				JUN	2020	30	2					377	391		10.34768/amcs-2020-0029													
J								Comparison of Machine Learning Models to Predict Risk of Falling in Osteoporosis Elderly	FOUNDATIONS OF COMPUTING AND DECISION SCIENCES										GaitRite data; Prognosis falls; Computational methods; Osteoporosis	PHYSICAL PERFORMANCE-MEASURES; NETWORK; WALKING	Falls are a multifactorial cause of injuries for older people. Subjects with osteoporosis are more vulnerable to falls. The focus of this study is to investigate the performance of the different machine learning models built on spatiotemporal gait parameters to predict falls particularly in subjects with osteoporosis. Spatiotemporal gait parameters and prospective registration of falls were obtained from a sample of 110 community dwelling older women with osteoporosis (age 74.3 +/- 6.3) and 143 without osteoporosis (age 68.7 +/- 6.8). We built four different models, Support Vector Machines, Neuronal Networks, Decision Trees, and Dynamic Bayesian Networks (DBN), for each specific set of parameters used, and compared them considering their accuracy, precision, recall and F-score to predict fall risk. The F-score value shows that DBN based models are more efficient to predict fall risk, and the best result obtained is when we use a DBN model using the experts' variables with FSMC's variables, mixed variables set, obtaining an accuracy of 80%, and recall of 73%. The results confirm the feasibility of computational methods to complement experts' knowledge to predict risk of falling within a period of time as high as 12 months.																	0867-6356	2300-3405				JUN	2020	45	2					65	77		10.2478/fcds-2020-0005													
J								Numerical Solution of SDRE Control Problem - Comparison of the Selected Methods	FOUNDATIONS OF COMPUTING AND DECISION SCIENCES										State-dependent Riccati equations; Nonlinear systems; Numerical analysis	DEPENDENT RICCATI EQUATION	Methods for solving non-linear control systems are still being developed. For many industrial devices and systems, quick and accurate regulators are investigated and required. The most effective and promising for nonlinear systems control is a State-Dependent Riccati Equation method (SDRE). In SDRE, the problem consists of finding the suboptimal solution for a given objective function considering nonlinear constraints. For this purpose, SDRE methods need improvement. In this paper, various numerical methods for solving the SDRE problem, i.e. algebraic Riccati equation, are discussed and tested. The time of computation and computational effort is presented and compared considering selected nonlinear control plants.																	0867-6356	2300-3405				JUN	2020	45	2					79	95		10.2478/fcds-2020-0006													
J								An enhanced differential evolution algorithm with adaptation of switching crossover strategy for continuous optimization	FOUNDATIONS OF COMPUTING AND DECISION SCIENCES										Continuous optimization; enhanced differential evolution algorithm; control parameter adaptation; switching crossover strategy	GLOBAL OPTIMIZATION; SYSTEMS; PARAMETER; EQUATIONS	Designing an efficient optimization method which also has a simple structure is generally required by users for its applications to a wide range of practical problems. In this research, an enhanced differential evolution algorithm with adaptation of switching crossover strategy (DEASC) is proposed as a general-purpose population-based optimization method for continuous optimization problems. DEASC extends the solving ability of a basic differential evolution algorithm (DE) whose performance significantly depends on user selection of the control parameters: scaling factor, crossover rate and population size. Like the original DE, the proposed method is aimed at efficiency, simplicity and robustness. The appropriate population size is selected to work in accordance with good choices of the scaling factors. Then, the switching crossover strategy of using low or high crossover rates are incorporated and adapted to suit the problem being solved. In this manner, the adaptation strategy is just a convenient add-on mechanism. To verify the performance of DEASC, it is tested on several benchmark problems of various types and difficulties, and compared with some well-known methods in the literature. It is also applied to solve some practical systems of nonlinear equations. Despite its much simpler algorithmic structure, the experimental results show that DEASC greatly enhances the basic DE. It is able to solve all the test problems with fast convergence speed and overall outperforms the compared methods which have more complicated structures. In addition, DEASC also shows promising results on high dimensional test functions.																	0867-6356	2300-3405				JUN	2020	45	2					97	124		10.2478/fcds-2020-0007													
J								Division-by-q dichotomization for interval uncertainty reduction by cutting off equal parts from the left and right based on expert judgments under short-termed observations	FOUNDATIONS OF COMPUTING AND DECISION SCIENCES										interval uncertainty reduction; dichotomization; cutting off parts of an interval; expert procedure; expert judgments; parameter adjustment; statistical stability	IDENTIFICATION; PROBABILITY; COVERAGE	A problem of reducing interval uncertainty is considered by an approach of cutting off equal parts from the left and right. The interval contains admissible values of an observed object's parameter. The object's parameter cannot be measured directly or deductively computed, so it is estimated by expert judgments. Terms of observations are short, and the object's statistical data are poor. Thus an algorithm of flexibly reducing interval uncertainty is designed via adjusting the parameter by expert procedures and allowing to control cutting off. While the parameter is adjusted forward, the interval becomes progressively narrowed after every next expert procedure. The narrowing is performed via division-by-q dichotomization cutting off the q(-1)-th parts from the left and right. If the current parameter's value falls outside of the interval, forward adjustment is canceled. Then backward adjustment is executed, where one of the endpoints is moved backwards. Adjustment is not executed when the current parameter's value enclosed within the interval is simultaneously too close to both left and right endpoints. If the value is "trapped" like that for a definite number of times in succession, the early stop fires.																	0867-6356	2300-3405				JUN	2020	45	2					125	155		10.2478/fcds-2020-0008													
J								Lightning search algorithm-based contextually fused multilevel image segmentation	APPLIED SOFT COMPUTING										Context; Multi-level segmentation; 1D; 2D; And 3D otsu; Image fusion; Local contrast; And image thresholding	OPTIMIZATION; OTSU; SELECTION; ENTROPY; DECOMPOSITION; HISTOGRAM; KAPURS	In this paper, a new well-organized fusion-based 3D Otsu energy thresholding prototypical for multilevel color image segmentation by means of lightning search algorithm (LSA) has been projected. Although, 3D Otsu works by means of between-class variances over the help of 3-D histogram but the performance is not satisfactory. As a result, the energy curve model is implemented, that works on contextual information of an image. However, using the concept of energy curve for 3D Otsu produces better result, but at the cost of complexity and also correspondingly the complication level for pick out appropriate thresholds is high. To overcome this limitation, the concept of LSA optimization algorithm is introduced. LSA is a fresh optimization process encouraged by the winding characteristics of lightening through a thunderstorm. In this paper, LSA is used to shorten the delinquent of comprehensive exploration for finding the finest thresholds. In addition to this, to enhance the quality of multi-level segmented image the concept of fusion based on local contrast is introduced. In this paper, 1D, 2D and 3D-Otsu methods using numerous optimization algorithms are implemented with energy curve and fusion based approach and compared with proposed fusion based energy 3D Otsu method using LSA algorithm. Experimental outputs demonstrate that the proposed Fusion-Energy-3D Otsu-LSA algorithm is outperforms and it can be established by comparing the well-known fidelity constraints of an image. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106243	10.1016/j.asoc.2020.106243													
J								A development on multimodal optimization technique and its application in structural damage detection	APPLIED SOFT COMPUTING										Multimodal optimization; Artificial Bee Colony algorithm; Niche identification technique; Depth First Search; Damage detection	GENETIC ALGORITHM; FAULT-DIAGNOSIS; IDENTIFICATION; SEARCH	In this paper, a heuristic algorithm fusing with niche identification (NIT) and Artificial Bee Colony (ABC) technique is developed to solve multimodal optimization problems, and is then applied for structural damage detection. In order to improve the detection accuracy of the proposed algorithm, the Depth First Search (DFS) is adopted, and a new particle update scheme is proposed to maintain the diversity of particle populations. The effectiveness and robustness of the algorithm for multimodal optimization are demonstrated by the well-known benchmark functions. Case studies on structural damage detection are carried out using ANSYS-powered data. Simulation results show that, even for the contaminated data or extreme damage scenarios (e.g., the adjacent damages), the DFS-based nNIT with ABC technique can lead to a satisfactory result. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106264	10.1016/j.asoc.2020.106264													
J								A cascaded deep convolution neural network based CADx system for psoriasis lesion segmentation and severity assessment	APPLIED SOFT COMPUTING										Psoriasis; Lesion segmentation and severity assessment; U-Net; Cascaded DCNN; CADx system	RISK	The design of an efficient computer-aided diagnosis (CADx) system for psoriasis severity assessment demands both accurate segmentation and classification of psoriasis lesions. Recently, few studies have been conducted to design automatic CADx systems for psoriasis severity assessment using traditional machine learning approaches. However, these approaches are highly featured dependent and require extensive and careful feature extraction. Among a large number of features extracted, assessing the features which contribute significantly to the classifier performing is a difficult and time-consuming task. Large features lead to poor generalization, due to high inter and intra-class variation of psoriasis skin lesions. This makes the task of implementing a reliable CADx system challenging. In such similar cases, Deep learning-based approaches have been proven better because of their ability to learn and make intelligent decisions automatically. In this study, a fully automated deep learning-based CADx system for psoriasis has been proposed. The system combines three modules in a single framework for achieving different objectives namely; recognition of psoriasis and non-psoriasis disease, automatic segmentation of psoriatic lesion, and its severity assessment. The modified U-Net and modified VGG-16 model have been implemented and trained for the segmentation and classification task respectively. The severity assessment module is capable of extracting discriminative features specifically related to the psoriatic lesion, which is automatically segmented by the segmentation module. The performance of the proposed CADx framework has been extensively evaluated on an extensive psoriasis dataset using k-fold cross-validation procedure. The appropriateness of the proposed system has been justified in terms of its performance at each of the three stages along with benchmarking against previously reported systems. Further, the system accuracy and reliability index has been evaluated for a dataset of varying size to validate the consistency of the proposed system. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106240	10.1016/j.asoc.2020.106240													
J								Statistical and machine learning models in credit scoring: A systematic literature survey	APPLIED SOFT COMPUTING										Credit scoring; Statistical learning; Machine learning; Deep learning; Systematic literature survey	CONVOLUTIONAL NEURAL-NETWORKS; RESTRICTED BOLTZMANN MACHINE; FEATURE-SELECTION; BANKRUPTCY PREDICTION; GENETIC ALGORITHM; ROUGH SET; CLASSIFIER ENSEMBLES; MAXIMUM-LIKELIHOOD; TIME-SERIES; RISK	In practice, as a well-known statistical method, the logistic regression model is used to evaluate the credit-worthiness of borrowers due to its simplicity and transparency in predictions. However, in literature, sophisticated machine learning models can be found that can replace the logistic regression model. Despite the advances and applications of machine learning models in credit scoring, there are still two major issues: the incapability of some of the machine learning models to explain predictions; and the issue of imbalanced datasets. As such, there is a need for a thorough survey of recent literature in credit scoring. This article employs a systematic literature survey approach to systematically review statistical and machine learning models in credit scoring, to identify limitations in literature, to propose a guiding machine learning framework, and to point to emerging directions. This literature survey is based on 74 primary studies, such as journal and conference articles, that were published between 2010 and 2018. According to the meta-analysis of this literature survey, we found that in general, an ensemble of classifiers performs better than single classifiers. Although deep learning models have not been applied extensively in credit scoring literature, they show promising results. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106263	10.1016/j.asoc.2020.106263													
J								A new weighted distance-based approximation methodology for flow shop scheduling group decisions under the interval-valued fuzzy processing time	APPLIED SOFT COMPUTING										Flow shop scheduling; Weighted distance-based approximation; Decision-makers' weights; Interval-valued fuzzy sets	ANT COLONY OPTIMIZATION; EFFICIENT HEURISTICS; ALGORITHM; EXTENSION; SELECTION; STRATEGY; TOPSIS; SETS; SIMILARITY; MAKESPAN	Scheduling plays a significant role in production planning. This paper introduces a new extension of a weighted distance-based approximation (WBDA) methodology to determine the sequence of jobs in flow shop scheduling problems. Furthermore, a new version of WDBA is used to specify the decision-makers' weights. In reality, there are many inherent uncertainties in the processing time owing to the batch loading, the capacity of processing unit, operator skills, transformation quality of raw materials in the production systems, imperfect information regarding systems, transportation lag, traffic jam, machine disablements, arrival of new jobs, and resources deficiencies. In this situation, interval-valued fuzzy sets (IVFSs) are employed for considering the uncertainty of practical conditions. Finally, an illustrative example of the literature under different weight schemes is adopted and solved to address the strengths of the introduced methodology better. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106248	10.1016/j.asoc.2020.106248													
J								A feature-fusion framework of clinical, genomics, and histopathological data for METABRIC breast cancer subtype classification	APPLIED SOFT COMPUTING										Breast cancer subtyping; Classification; Genetic data; Histopathological images; METABRIC	GENE-EXPRESSION DATA; FEATURE-SELECTION; PCA	Breast cancer is the most common cancer type attacking women worldwide. Also, breast cancer has been phenotypically classified into five subtypes. Each subtype group has unique characteristics that demonstrate the heterogeneity present within the breast cancer tumour. In 2012, the American Association for Cancer Research provided a population based molecular integrative clusters for the METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) dataset, resulting in ten subtypes. Previous work on the METABRIC dataset used only gene expression data to figure out the effective genes for each subtype, without applying integration to benefit from all data sources. The objective of this paper is to present a breast cancer subtype classification model that applies feature fusion on the METABRIC datasets, namely clinical, gene expression, Copy Number Aberrations (CNA), Copy Number Variations (CNV), and histopathological images. State-of-the-art machine learning classifiers were applied on different data profiles, including Linear-SVM, Radial-SVM, Random Forests (RF), Ensemble SVM (E-SVM), and Boosting. The highest accuracy achieved for IntClust subtyping was 88.36% using Linear-SVM, applied on the data profile with features fused from the clinical, gene expression, CNA, and CNV datasets, with a Jaccard and Dice scores of 0.802 and 0.8835, respectively. On the other hand, for the Pam50 subtyping, an accuracy of 97.1% was achieved, Jaccard score ranging from 0.9439 to 0.9472, and Dice score of 0.971, using Linear-SVM and E-SVM classifiers, with several data profiles that include features from histopathological images. Conclusively, the significance of our study is to validate that using feature fusion from various METABRIC datasets improves breast cancer subtypes classification performance. Moreover, histopathological images give promising results on Pam50 subtypes, and it is expected to improve the accuracy for IntClust subtyping when applied on a higher population. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106238	10.1016/j.asoc.2020.106238													
J								A surrogate-assisted particle swarm optimization using ensemble learning for expensive problems with small sample datasets	APPLIED SOFT COMPUTING										Small sample datasets; Ensemble learning; Expensive problems; Surrogate model	MEMBRANE EVOLUTIONARY ALGORITHM; DESIGN	Solving the real-world optimization problems often needs a large number of expensive function evaluations (FEs) by using evolutionary algorithms (EAs). To alleviate this difficulty, surrogate-assisted EAs (SAEAs) have attracted more and more attention from academia and industry. However, the existing SAEAs need a large amount of sample points to construct surrogate model within the expected times of FEs, otherwise it cannot achieve satisfactory prediction accuracy. Few SAEAs can reduce the times of expensive FEs while a high-quality surrogate model is constructed using a small number of sample points. In this paper, a novel SAEAs inspired from ensemble learning is proposed. In the proposed algorithm, the small sample date set is divided into multiple subsets, and the surrogate model is trained on each subset. Two new model management strategies based on ensemble learning are applied to global search and local search respectively. Two search methods are cleverly combined to form a high precision surrogate ensemble. In order to verify the performance of the proposed method, we performed comprehensive tests on eight benchmark functions from 10 to 50 dimensions, and compared their result with the five state-of-the-art SAEAs. Experimental results demonstrate that the proposed method shows superior performance in a majority of benchmarks when only a limited computational budget is available. In addition, we apply the proposed algorithm to three real-time optimization problems. The results of each problem are compared with the solutions to verify the effectiveness of the algorithm in solving engineering application problems. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106242	10.1016/j.asoc.2020.106242													
J								Adaptive Fuzzy-Wavelet Neural Network identification core for reinforced control of general arbitrarily switched nonlinear Multi Input-Multi Output Dynamic Systems	APPLIED SOFT COMPUTING										Switched system control; Undetectable switching; Fuzzy-wavelet neural networks; Intelligent control; MIMO sliding mode control	MODEL-PREDICTIVE CONTROL; TRACKING CONTROL; DESIGN; STABILIZATION	In control of switched systems with undetectable switching signals, robustness and precision are on two different sides of a spectrum. In one hand, robustness to significant modeling uncertainties arising from undetectability of switching modes can be attained by designing the control scheme for worst-case switching configurations. On the other hand, such a control scheme would potentially be overly conservative and imprecise. A natural solution to this problem is pinpointing active switched dynamics at any given moment. However, this is no trivial task. In this study, we propose that the aforementioned problems can be overcome by designing a control scheme that prioritizes appropriate objectives according to operating conditions. In other words, the control scheme adjusts itself such that either of robustness to unknowable switching or increased tracking precision is selected as the primary control objective. As a result, the control model can be considered as dual-mode featuring a safe control mode and a precise control mode. In precise control mode, a model generation scheme using a modified Fuzzy-Wavelet Neural Network (FWNN) for Multi Input-Multi Output (MIMO) systems is incorporated for precise estimation of active dynamics which potentially features unknowable switching dynamics, external disturbances and parametric modeling uncertainty. However, this approximate model cannot be used immediately since convergence of the FWNN-based model to actual system dynamics takes place after a limited interval. In such periods (which often correspond to discontinuities in switching dynamics and references), using the FWNN scheme is perilous. Therefore, a robust discrete-time sliding mode control (DSMC) is used to ensure stabilization of closed-loop system in all potential modes of switched dynamics at the cost of reduced tracking precision. In combination, the dual-mode scheme ensures robust stabilization in safe control modes corresponding to transient-state stage and accurate tracking in steady-state stage of system response based on the proposed precise mode scheme. Numerical and experimental examples highlight the key features and improvements of the presented control algorithm. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106265	10.1016/j.asoc.2020.106265													
J								A one-class classification decision tree based on kernel density estimation	APPLIED SOFT COMPUTING										One-class classification; Decision trees; Kernel density estimation; Explainable artificial intelligence	SUPPORT; VARIABILITY; ENSEMBLES	One-class Classification (OCC) is an important field of machine learning which aims at predicting a single class on the basis of its lonely representatives and potentially some additional counter-examples. OCC is thus opposed to traditional classification problems involving two or more classes, and addresses the issue of class unbalance. There is a wide range of one-class models which give satisfaction in terms of performance. But at the time of explainable artificial intelligence, there is an increasing need for interpretable models. The present work advocates a novel one-class model which tackles this challenge. Within a greedy and recursive approach, our proposal for an explainable One-Class decision Tree (OC-Tree) rests on kernel density estimation to split a data subset on the basis of one or several intervals of interest. Thus, the OC-Tree encloses data within hyper-rectangles of interest which can be described by a set of rules. Against state-of-the-art methods such as Cluster Support Vector Data Description (ClusterSVDD), One-Class Support Vector Machine (OCSVM) and isolation Forest (iForest), the OC-Tree performs favorably on a range of benchmark datasets. Furthermore, we propose a real medical application for which the OC-Tree has demonstrated effectiveness, through the ability to tackle interpretable medical diagnosis aid based on unbalanced datasets. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106250	10.1016/j.asoc.2020.106250													
J								Ultra-high reliable optimization based on Monte Carlo Tree Search over Nakagami-m Fading	APPLIED SOFT COMPUTING										MSCA; MDP; MCTS; Resource allocation; URLLC	ACHIEVING HIGH AVAILABILITY; NETWORKS; POWER; COMMUNICATION; RELIABILITY; DIVERSITY; COMP	Supporting the ultra-reliable and low-latency communications (URLLCs) has become one of the major goals for future wireless networks. In this paper, we present an analytical reliability model for user equipment (UE) connecting multiple base stations (BSs) with multi-stream carrier aggregation (MSCA) technology. We first derive a closed-form expression for reliability characterization using signal-tointerference-plus-noise (SINR) model over Nakagami-m fading. We then formulate a joint resource allocation problem to maximize reliability, considering UE association, sub-carrier assignment and discrete power allocation. With distributed decision making (DDM) theory, we decouple it into two sub-problems, and each sub-problem is formulated as a separate Markov Decision Problem (MDP). We further propose the Monte Carlo Tree Search (MCTS) method to find the optimal solution for each sub-problem. The iterative joint optimization method based on DDM is also proposed. Our simulation results show that the reliability with MSCA increases with increasing the number of sub-carriers, as well as increasing the power allocation. We also show that our algorithm is an effective way in finding the optimal resource allocation for reliability improvement. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106244	10.1016/j.asoc.2020.106244													
J								On the feasibility of using evolvable hardware for hardware Trojan detection and prevention	APPLIED SOFT COMPUTING										Evolvable Hardware (EH); Virtual Reconfigurable Circuit (VRC); Hardware security; Hardware Trojan Horse (HTH); Field-Programmable Gate Array (FPGA)	DESIGN METHODOLOGY; CIRCUIT; TRUST	Evolvable hardware (EH) architectures are capable of changing their configuration and behavior dynamically based on inputs from the environment. In this paper, we investigate the feasibility of using EH to prevent Hardware Trojan Horses (HTHs) from being inserted, activated, or propagated in a digital electronic chip. HTHs are malicious hardware components that intend to leak secret information or cause malfunctioning at run-time in the chip in which they are integrated. We hypothesize that EH can detect internal circuit errors at run-time and reconfigure to a state in which the errors are no longer present. We implement a Virtual Reconfigurable Circuit (VRC) on a Field-Programmable Gate Array (FPGA) that autonomously and periodically reconfigures itself based on an Evolutionary Algorithm (EA). New VRC configurations are generated with an on-chip EA engine. We show that the presented approach is applicable in a scenario in which (1) the HTH-critical areas in the circuit are known in advance, and (2) the VRC is a purely combinatorial circuit, as opposed to the on-chip memory holding the golden reference, which requires one or more cycles to be read/written. We compare two different approaches for protecting the system against HTHs: Genetic Programming (GP) and Cartesian Genetic Programming (CGP). The paper reports on experiments on four benchmark circuits and gives an overview of both the limitations and the added value of the presented approaches. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106247	10.1016/j.asoc.2020.106247													
J								Evaluating deep models for absenteeism prediction of public security agents	APPLIED SOFT COMPUTING										Absenteeism; Deep learning; Machine learning; Prediction	TURNOVER	Absenteeism is a complex phenomenon characterized by the physical absence of the individual, usually at his workplace. Such absences generally lead to innumerable personal, social, and economic losses, particularly in public security institutions, where incidence is higher than the one verified in other occupational categories. Identifying preponderant absenteeism factors and allowing preventive actions to be carried out effectively may be beneficial to these institutions and their agents. Such knowledge could be acquired hypothetically by exploiting large human resources data sets. In this paper, we investigate the potential of machine learning classifiers to identify security workers prone to long-term absenteeism. Such predictors shall make decisions based on the professional history of each agent, which is extracted from databases of public security institutions. In our study, we performed experiments on a database comprised of 6 years of professional data from workers of the Military Police of Alagoas, Brazil. We evaluated deep models, including variations of Multilayer Perceptrons (MLP), Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM), and compared with baseline Support-Vector Machines (SVM) classifiers. We show results revealing that the best architectures achieve up to 78% of accuracy. Also, experiments indicated that the use of data accumulated over several years improves the accuracy of the prediction of absenteeism. Finally, we conclude that such results encourage the usage of deep learning techniques to predict absenteeism and support the implementation of effective prevention measures in these institutions. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106236	10.1016/j.asoc.2020.106236													
J								A new fractional-order general type-2 fuzzy predictive control system and its application for glucose level regulation	APPLIED SOFT COMPUTING										General Type-2 Fuzzy Logic Controller; Type-1 diabetes; Learning algorithm; Fractional-order; Stability analysis	ARTIFICIAL PANCREAS; MINIMAL-MODEL; LOGIC; SYNCHRONIZATION; OPTIMIZATION; ALGORITHM; DESIGN	In this paper a new robust fractional-order predictive controller is presented and employed to regulate the glucose level in type-1 diabetes. The dynamics of the system is fully unknown an it is online estimated by a fractional-order model using interval Type-2 (T2) fuzzy logic system. The proposed control system is composed of two main controllers which are the predictive General T2 Fuzzy Logic Controller (GT2-FLC) and compensator controller. In this structure, the main controller is the GT2-FLC which is optimized via the Biogeography-based Optimization (BBO) algorithm such that to minimize a cost function in a fixed prediction horizon. The compensator controller is designed to guarantee the closed-loop asymptotic stability. The performance of proposed control strategy is examined on the modified Bergman's model of some patients with time-varying parameters, external noise perturbation and meal disturbances. The effectiveness of the proposed control scheme is verified and is compared with the other T2 fuzzy and well-known model predictive controllers. The results of the paper clearly show the superiority of the proposed T2 fuzzy logic control system. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106241	10.1016/j.asoc.2020.106241													
J								An improved scheme for digital mammogram classification using weighted chaotic salp swarm algorithm-based kernel extreme learning machine	APPLIED SOFT COMPUTING										Digital mammogram; Wavelet packet transform; Kernel extreme learning machine; Chaotic map salp swarm algorithm	WAVELET ENTROPY; OPTIMIZATION ALGORITHM; TEXTURE CLASSIFICATION; TRANSFORM; IDENTIFICATION; FEATURES	Over the past years, the surge in the necessity for early detection and diagnosis of breast cancer has resulted in many innovative research directions. According to the World Health Organization, an early and accurate detection of breast cancer successfully leads to a correct decision towards its treatment. Development of computer-aided diagnosis (CAD) system is considered to be a major stead in current research practice to abet medical practitioners in decision-making. This paper proposes an improved CAD framework to correctly classify the digital mammograms into normal or abnormal, and further, benign or malignant. The proposed scheme employs a block-based discrete wavelet packet transform (BDWPT) to extract the features, namely, the Shannon entropy, Tsallis entropy, Renyi entropy, and energy. Then, principal component analysis (PCA) technique is utilized to extract the discriminating features from the original feature vector. Subsequently, an optimized wrapper-based kernel extreme learning machine (KELM) using a weighted chaotic salp swarm algorithm (WC-SSA) is proposed as classifier to classify the digital mammograms. Since the efficacy of KELM algorithm depends on its two important parameters, namely, the penalty parameter and the kernel parameter, the prime objective of the proposed work is to obtain the optimized value of the aforementioned parameters as well as to select the most relevant features from the reduced feature vector simultaneously. The proposed scheme is evaluated on three publicly available standard datasets, namely, MIAS, DDSM, and BCDR to validate the efficacy of the proposed BDWPT+PCA+WC-SSA-KELM scheme. The performance of the proposed model is evaluated in terms of different metrics, namely, classification accuracy, sensitivity, specificity, area under curve (AUC), Matthew's correlation coefficient (MCC), and F-measure via a 5 x 5 stratified cross-validation approach. From the experimental results and their analysis, it is observed that for the normal-abnormal category, the proposed technique results in an accuracy of 99.62% and 99.92% for MIAS and DDSM, respectively, whereas in the case of benign-malignant classification, the proposed method yields an accuracy of 99.28%, 99.63%, 99.60% for MIAS, DDSM, and BCDR datasets, respectively. Further, it is also observed that the proposed WC-SSA-KELM scheme exhibits superior performance as compared to that of its counterparts. Additionally, two well-known statistical analyses, namely, ANOVA and Friedman tests are performed to demonstrate that the performance of the proposed scheme is significantly better than that of the other existing schemes. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106266	10.1016/j.asoc.2020.106266													
J								Feature selection based on regularization of sparsity based regression models by hesitant fuzzy correlation	APPLIED SOFT COMPUTING										Hesitant fuzzy correlation; Classification; Sparsity based models	CLASSIFICATION; PREDICTORS; SETS	In this paper, the Ridge, LASSO and Elastic Net regression methods are adapted for the task of selecting feature. In order to enhance the feature selection performance via these methods, a Hesitant Fuzzy Correlation Matrix (HFCM) is added to the objective functions of these models for addressing the minimum redundancy of features. To this end, the fuzzy C-means clustering is utilized, and the obtained fuzzy clusters are projected on the features in a way that the number of fuzzy Membership Functions (MF) for each feature is equal to the number of clusters. Then, the projected MFs on each feature are considered as a Hesitant Fuzzy Set (HFS), and thereby the hesitant fuzzy correlation between features is calculated. Afterward, the obtained HFCM is employed in the regression methods for securing the minimum redundancy of features. Eventually, the accuracies of the selected features, achieved by these methods, are determined by three different classification models such as Naive Bayes, SVM and Decision Tree. A large number of experiments are conducted over twenty-four classification datasets to demonstrate the efficiency and applicability of using HFCM in some classical regression methods. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106255	10.1016/j.asoc.2020.106255													
J								A benchmark suite for designing combinational logic circuits via metaheuristics	APPLIED SOFT COMPUTING										Benchmark suite; Combinational logic circuits; Evolvable hardware; Performance evaluation	OPTIMIZATION	The evolvable hardware literature reports several methods for the evolution of digital circuits. However, there is a large variability in the set of problems and the appropriate metrics used for the evaluation of the results. In this paper, we propose a set of representative problems to comparatively evaluate metaheuristics when designing Combinational Logic Circuits (CLCs). We also define a set of performance measurements and descriptive statistics to analyze the results found by the search techniques. As a case study, we compare Cartesian Genetic Programming variants applied to this domain. The results highlight the benefits of the proposed heterogeneous benchmark suite in the analysis of metaheuristics when designing CLCs. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106246	10.1016/j.asoc.2020.106246													
J								Design of modeling error PDF based fuzzy neural network for effluent ammonia nitrogen prediction	APPLIED SOFT COMPUTING										Modeling error PDF; Fuzzy neural network; Adaptive learning rate; Convergence analysis; Effluent ammonia nitrogen	SOFT COMPUTING METHOD; PERFORMANCE EVALUATION; OPTIMIZATION; MACHINE; SYSTEM	To predict the effluent ammonia nitrogen (NH4-N) of wastewater treatment process (WWTP), the soft computing methods are widely used, in which the mean square error (MSE) is usually adopted as the performance criterion. However, the MSE based methods cannot fully utilize the statistic information of data and are vulnerable to the nonzero-mean noise. To address these issues, the modeling-error probability density function based fuzzy neural network (PDF-FNN) is proposed in this paper. Firstly, the modeling error PDF criterion is generated to minimize the spatial deviation between the modeling error distribution and the predefined target. Then, a gradient descent method with adaptive learning rate is presented to update the parameters of PDF-FNN. Furthermore, the convergence of PDF-FNN is analyzed from a mathematical point of view. Finally, a nonlinear system modeling and the effluent NH4-N prediction in WWTP are applied to prove the effectiveness of the proposed PDF-FNN. The results indicate that the PDF-FNN has better prediction accuracy and model stability than other methods, especially in the noisy environment. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106239	10.1016/j.asoc.2020.106239													
J								Estimating missing data using novel correlation maximization based methods	APPLIED SOFT COMPUTING										Missing values; Imputation; Correlation; Regression	FUZZY C-MEANS; K-NEAREST NEIGHBORS; VALUE IMPUTATION; GENETIC ALGORITHM; VALUES; CLASSIFICATION; REGRESSION; FRAMEWORK; SELECTION; PATTERNS	The accurate estimation of missing data plays a vital role in ensuring a high level of data quality. The missing values should be imputed before performing data mining, machine learning, and other data processing tasks. Ten correlation-based imputation methods are proposed in this paper. All of these methods try to maximize the correlation between a missing feature and other features. The maximization is achieved by selecting segments of data that have strong correlations. The proposed approach involves the following main steps to impute each missing instance. First, a base set is selected from complete instances. Second, data segments with strong correlations are generated using the base set and the rest of the complete instances. Finally, each missing value is imputed by applying linear models to the discovered segments of data. This study considers seven real datasets from different fields with different missing rates. The imputation quality of the proposed methods is compared to those of seven other imputation approaches in terms of three well-known evaluation criteria. The experimental results reveal that the proposed approach has better imputation performance than competing imputation techniques in most cases. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106249	10.1016/j.asoc.2020.106249													
J								A novel multi-focus image fusion by combining simplified very deep convolutional networks and patch-based sequential reconstruction strategy	APPLIED SOFT COMPUTING										Multi-focus image fusion; Convolutional neural networks; Patch-based sequential reconstruction strategy; Evaluation metrics	PERFORMANCE; TRANSFORM; PCNN	Multi-focus image fusion is an important approach to obtain the composite image with all objects in focus, and it can be treated as an image segmentation problem, which is solved by convolutional neural networks (CNN). For CNN-based multi-focus image fusion methods, public training dataset does not exist, and the network model determines the recognition accuracy of the focused and defocused pixels. Considering these problems, we proposed a novel CNN-based multi-focus image fusion method by combining simplified very deep convolutional networks and patch-based sequential reconstruction strategy in this study. Firstly, the defocused images with five blurred levels were simulated by the Gaussian filter, and a novel training dataset was constructed for multi-focus image fusion. Secondly, the very deep convolutional networks model was simplified to design a Siamese CNN model, and this model was used to recognize the focused and defocused pixels. Thirdly, the focused and defocused regions were detected by the patch-based sequential reconstruction strategy, and the final decision map was refined by the morphological operator. Finally, the multi-focus image fusion was performed. Lytro dataset as a public multi-focus image dataset was used to prove the validation of the proposed method. Information entropy, mutual information, universal image quality index, visual information fidelity, and edge retention were adopted as evaluation metrics, and the proposed method was compared with state-of-the-art methods. Experimental results demonstrated that the proposed method can achieve state-of-the-art fusion results in terms of visual quality and objective assessment. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106253	10.1016/j.asoc.2020.106253													
J								Imbalanced credit risk evaluation based on multiple sampling, multiple kernel fuzzy self-organizing map and local accuracy ensemble	APPLIED SOFT COMPUTING										Credit risk evaluation; Class-imbalanced data; Multiple sampling; Multiple kernel fuzzy self-organizing map; Local accuracy ensemble	NEURAL-NETWORK; C-MEANS; PREDICTION; CLASSIFICATION; SMOTE; CLASSIFIERS; INFERENCE; SELECTION; EXAMPLE; MODELS	Credit risk evaluation model is generally regarded as a valid method for business risk management. Although the most of literatures about credit risk evaluation always use class-balanced data as sample sets, the study on class-imbalanced datasets is more suitable for actual situation. This paper proposes a new ensemble model to evaluate class-imbalanced credit risk, which integrates multiple sampling, multiple kernel fuzzy self-organizing map and local accuracy ensemble. To preprocess imbalanced sample sets of credit risk evaluation, multiple sampling approaches (synthetic minority over-sampling technique, under sampling and hybrid sampling) are improved and integrated to acquire balanced datasets. To construct more suitable base classifiers, multiple kernel functions (Gaussian, Polynomial and Sigmoid) respectively are used to improve fuzzy self-organizing map. Then, the balanced sample sets are respectively processed by the improved base classifiers to acquire different prediction results. The local accuracy ensemble method is employed to dynamically synthesize these prediction results to obtain final result. The new ensemble model can further avoid over-fitting and information loss, be more suitable to handle the dataset including different financial indicators, and acquire the stable and satisfactory prediction result for imbalanced credit risk evaluation In the empirical research, this paper adopts the financial data from Chinese listed companies, and makes the comparative analysis with the relative models step by step. The results can prove that the new ensemble model presented by this article has better performance than other methods in terms of evaluating the imbalanced credit risk. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106262	10.1016/j.asoc.2020.106262													
J								Optimal power flow using the AMTPG-Jaya algorithm	APPLIED SOFT COMPUTING										AMTPG-Jaya; Optimum power flow; Meta-heuristic algorithms; Optimization; Artificial intelligence	OPTIMIZATION ALGORITHM; SINGLE; SOLVE; REAL	This work proposes the implementation of a recently invented meta-heuristic optimization solver namely, an adaptive multiple teams perturbation-guiding Jaya (AMTPG-Jaya) technique to tackle with diverse single goal optimum power flow (OPF) forms. The AMTPG-Jaya solver employs numerous populations named as teams to investigate the search domain. Each team is guided by a number of movement equations (exploration pathways). The algorithm adjusts the number of teams along with the approaching to the finest so-far nominee solution. In this study, an original AMTPG-Jaya inspired approach to handle the OPF formulation is suggested. The efficacy of the AMTPG-Jaya solver is scrutinized and tested on two well-known standard power systems with different goal functions. The optimization outcomes reveal that the AMTPG-Jaya is able to reach an optimal solution with brilliant convergence speed. In addition, a robustness examination is implemented to evaluate the reliability of the AMTPG-Jaya solver. The simulation results disclose the dominance and potential of the AMTPG-Jaya over many solvers recently stated in the previous publications with regard to solution quality and validity. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106252	10.1016/j.asoc.2020.106252													
J								A new multi-criteria decision model based on incomplete dual probabilistic linguistic preference relations	APPLIED SOFT COMPUTING										5G; Incomplete dual probabilistic linguistic preference relations; Repairing; Consistency; Dual probabilistic linguistic envelopment analysis	DATA ENVELOPMENT ANALYSIS; CROSS-EFFICIENCY; CONSISTENCY; SELECTION; DEA; ALGORITHMS; CHINESE; UNITS; RISK	The use of dual probabilistic linguistic term sets (DPLTSs) to represent the use's preferences in decision making can reflect the decision maker's cognitive certainty and uncertainty. Additionally, the appearance of incomplete preferences is a recurring phenomenon that must be taken into account if you want to make a successful decision. This paper presents a new multi-criteria decision model based on the incomplete dual probabilistic linguistic preference relations (IDPLPRs). We first propose a step-by-step repairing method to repair the linguistic section and probabilistic section of IDPLPRs separately. The superiority is that this step-by-step method conforms to the principle of element generation. After that, the consistency index based on the distance measure between the dual probabilistic linguistic preference relations (DPLPRs) is defined to check and improve the consistency of DPLPRs. Then the weights of criteria can be obtained by information fusion. Moreover, we construct optimistic and pessimistic data envelopment analysis models under the dual probabilistic linguistic environment to do the sorting process. Optimistic and pessimistic data envelopment analysis models can demonstrate the efficiency of each decision-making unit (DMU) from the perspective of the most and least favorable. Finally, we simulate a cased of 5G industry market to help enterprises choose appropriate 5G partners by using proposed methods. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106237	10.1016/j.asoc.2020.106237													
J								A decomposition-based memetic algorithm using helper objectives for shortwave radio broadcast resource allocation problem in China	APPLIED SOFT COMPUTING										Shortwave radio broadcast resource allocation; Parallel multi-objective memetic algorithm; Helper objectives; Decomposition method; Diversity matrix	LOCAL SEARCH; OPTIMIZATION; MULTIOBJECTIVIZATION; SELECTION; STRATEGY	Shortwave radio broadcast resource allocation (SRBRA) is an NP-hard combinatorial optimization problem with practical significance in many countries. The aim of SRBRA is to allocate radio programs to transmission devices so as to broadcast all radio programs felicitously with a maximized objective of total qualified monitoring sites. To solve such an issue presented by the State Administration of Press, Publication, Radio, Film and Television (SAPPRFT) in China, the authors propose a parallel multi-objective memetic algorithm based on helper objective assistance and decomposition technique, called pMMA-HD. Specifically, a multi-objective evolutionary optimization framework is used to maintain the diversity in a single objective problem, where the authors add a helper objective function on the diversity metric. Then, the decomposition method is performed to settle this transformational multi-objective problem effectively, and a diversity matrix is preserved in order to provide sufficient candidates for a decision maker to select from. To approach the pareto front, an efficient local search with a guided perturbation is integrated after the evolutionary process. Considering the natural characteristics of evolutionary algorithms (EAs), a thread-based parallel version of MMA-HD is carefully designed to improve the computational efficiency. Experiments are performed on real-world benchmarks to compare pMMA-HD with three categories of algorithms: one exact solver clasp, two canonical multi-objective algorithms and three local search methods. Afterwards, the experiments on parameters tuning are conducted based on the Taguchi method of design-of-experiment. Besides, the validation of strategies are investigated and the robustness of solutions is further analyzed. The experimental results on the real-world dataset validate the efficiency of pMMA-HD by updating 33 best-known solutions. (C) 2020 Elsevier B.V. All rights reserved.																	1568-4946	1872-9681				JUN	2020	91								106251	10.1016/j.asoc.2020.106251													
J								DARPA's Impact on Artificial Intelligence	AI MAGAZINE												The Defense Advanced Research Project Agency's (DARPA) mission is to make pivotal investments leading to research breakthroughs that support national security. DARPA artificial intelligence (AI) programs have emphasized the need for machines to perceive and interact with the world around them; to frame problems and to arrive at solutions and decisions based on reasoning; to implement those decisions, perhaps through consultation with a human or another machine; to learn; to explain the rationale for decisions; to adhere to rules of ethical behavior defined for humans; to adapt to dynamic environments; and, to do all of this in real-time. In short, DARPA has always been interested in AI frameworks that integrate AI and computer science technologies, and the application of those frameworks to DARPA-hard problems. In this article, we describe the significant role that DARPA has played in the establishment of AI, and introduce six articles that explore DARPA's Three Waves of AI.																	0738-4602					SUM	2020	41	2					3	8															
J								Knowledge Representation and Reasoning - A History of DARPA Leadership	AI MAGAZINE												A fundamental goal of artificial intelligence research and development is the creation of machines that demonstrate what humans consider to be intelligent behavior. Effective knowledge representation and reasoning methods are a foundational requirement for intelligent machines. The development of these methods remains a rich and active area of artificial intelligence research in which advances have been motivated by many factors, including interest in new challenge problems, interest in more complex domains, shortcomings of current methods, improved computational support, increases in requirements to interact effectively with humans, and ongoing funding from the Defense Advanced Research Projects Agency and other agencies. This article highlights several decades of advances in knowledge representation and reasoning methods, paying particular attention to research on planning and on the impact of the Defense Advanced Research Projects Agency's support.																	0738-4602					SUM	2020	41	2					9	21															
J								Human Language Technology	AI MAGAZINE												Human language technology encompasses a wide array of speech and text processing capabilities. The Defense Advanced Research Projects Agency's pioneering research on automatic transcription, translation, and content analysis were major artificial intelligence success stories that changed science fiction into social fact. During a 40-year period, 10 seminal DARPA programs produced breakthrough capabilities that were further improved and widely deployed in popular consumer products, as well as in many commercial, industrial, and governmental applications. The Defense Advanced Research Projects Agency produced the core enabling technologies by setting crisp, aggressive, and quantitative technical objectives; by providing strong multiyear funding; and by using the Defense Advanced Research Projects Agency's Common Task Method, which was powerful, efficient, and easy to administer. To achieve these breakthroughs, multidisciplinary academic and industrial research teams working in parallel took advantage of increasingly large and diverse sets of linguistic data and rapidly increasing computational power to develop and use increasingly sophisticated forms of machine learning. This article describes the progression of technical advances underlying key successes and the seminal programs that produced them.																	0738-4602					SUM	2020	41	2					22	35															
J								DARPA's Role in Machine Learning	AI MAGAZINE											ALGORITHM	Machine learning methods provide a way for artificial intelligence systems to learn from experience. This article describes four threads of machine learning research supported and guided by the Defense Advanced Research Projects Agency - probabilistic modeling for speech recognition, probabilistic relational models, the integration of multiple machine learning approaches into a task-specific system, and neural network technology. These threads illustrate the Defense Advanced Research Projects Agency way of creating timely advances in a field.																	0738-4602					SUM	2020	41	2					36	48															
J								Vision and Robotics	AI MAGAZINE											SHAPE	Vision and robotics has the well-defined goal of meeting or exceeding human-level capabilities in perception, locomotion, and manipulation. Not surprisingly, that is perhaps easier said than done. Beginning in the 1970s, the Defense Advanced Research Projects Agency started the ambitious Imaging Understanding program that would continue for more than 20 years. The Imaging Understanding program began with fundamental research and slowly evolved into a host of more applied efforts with specific systems goals. Robotics programs followed a similar arc as the early research-oriented programs generated capabilities from which practical systems could be built. A culmination of the vision and robotics research was the Defense Advanced Research Projects Agency Grand Challenge, which turned the impossibility of a self-driving car into an imminent reality. This article tells the story of how some of the modern-day technologies we enjoy today trace their evolution from research sponsored by the Defense Advanced Research Projects Agency over the last 40 years.																	0738-4602					SUM	2020	41	2					49	65															
J								Integrated Artificial Intelligence Systems	AI MAGAZINE												From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA's Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot's Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple's Siri. These efforts created complex, richly-integrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA's persistent long-term support for this essential premise of AI.																	0738-4602					SUM	2020	41	2					66	82															
J								On Crashing the Barrier of Meaning in Artificial Intelligence	AI MAGAZINE												In 1986, the mathematician and philosopher Gian-Carlo Rota wrote, "I wonder whether or when artificial intelligence will ever crash the barrier of meaning" (Rota 1986). Here, the phrase "barrier of meaning" refers to a belief about humans versus machines: Humans are able to actually understand the situations they encounter, whereas even the most advanced of today's artificial intelligence systems do not yet have a humanlike understanding of the concepts that we are trying to teach them. This lack of understanding may underlie current limitations on the generality and reliability of modern artificial intelligence systems. In October 2018, the Santa Fe Institute held a three-day workshop, organized by Barbara Grosz, Dawn Song, and myself, called Artificial Intelligence and the Barrier of Meaning. Thirty participants from a diverse set of disciplines - artificial intelligence, robotics, cognitive and developmental psychology, animal behavior, information theory, and philosophy, among others - met to discuss questions related to the notion of understanding in living systems and the prospect for such understanding in machines. In the hope that the results of the workshop will be useful to the broader community, this article summarizes the main themes of discussion and highlights some of the ideas developed at the workshop.																	0738-4602					SUM	2020	41	2					86	92															
J								Two Workshops, a Report, and a 100-Year Study of Artificial Intelligence and Society	AI MAGAZINE												The purpose of this article is to report on the findings of two workshops exploring the evolution of artificial intelligence technologies - specifically used in care-driven or predictive applications - and their impacts on society as a whole, organized as part of the AI100's 100-year-long study of artificial intelligence. Workshop participants concluded that care cannot be commodified or reduced into outcome-oriented tasks and can therefore not be encoded into technology; additionally, participants determined that regulation of predictive artificial intelligence technologies is required to maintain their benefit and trustworthiness. The aim of these workshops is to encapsulate both the ups and downs of these technologies. The study organizers and participants feel their role is to bring the integration of artificial intelligence technology into societal values to the forefront of discussions for its future.																	0738-4602					SUM	2020	41	2					93	95															
J								Adaptive Learning Technologies	AI MAGAZINE												Adaptive learning refers to technologies that dynamically adjust to the level or type of course content based on an individual's abilities or skill attainment, in ways that accelerate a learner's performance with both automated and instructor interventions. This column explores adaptive learning, its close relationship to artificial intelligence, and points to several results from artificial intelligence that have been used to build effective adaptive learning systems. The pairing of massive open online courses and adaptive learning has revealed new technical and pedagogical challenges that are currently being explored in various research projects.																	0738-4602					SUM	2020	41	2					96	98															
J								Multilingual and Interlingual Semantic Representations for Natural Language Processing: A Brief Introduction	COMPUTATIONAL LINGUISTICS												We introduce theComputational Linguisticsspecial issue on Multilingual and Interlingual Semantic Representations for Natural Language Processing. We situate the special issue's five articles in the context of our fast-changing field, explaining our motivation for this project. We offer a brief summary of the work in the issue, which includes developments on lexical and sentential semantic representations, from symbolic and neural perspectives.																	0891-2017	1530-9312				JUN	2020	46	2					249	255		10.1162/coli_a_00373													
J								Unsupervised Word Translation with Adversarial Autoencoder	COMPUTATIONAL LINGUISTICS												Crosslingual word embeddings learned from monolingual embeddings have a crucial role in many downstream tasks, ranging from machine translation to transfer learning. Adversarial training has shown impressive success in learning crosslingual embeddings and the associated word translation task without any parallel data by mapping monolingual embeddings to a shared space. However, recent work has shown superior performance for non-adversarial methods in more challenging language pairs. In this article, we investigate adversarial autoencoder for unsupervised word translation and propose two novel extensions to it that yield more stable training and improved results. Our method includes regularization terms to enforce cycle consistency and input reconstruction, and puts the target encoders as an adversary against the corresponding discriminator. We use two types of refinement procedures sequentially after obtaining the trained encoders and mappings from the adversarial training, namely, refinement with Procrustes solution and refinement with symmetric re-weighting. Extensive experimentations with high- and low-resource languages from two different data sets show that our method achieves better performance than existing adversarial and non-adversarial approaches and is also competitive with the supervised system. Along with performing comprehensive ablation studies to understand the contribution of different components of our adversarial model, we also conduct a thorough analysis of the refinement procedures to understand their effects.																	0891-2017	1530-9312				JUN	2020	46	2					257	288		10.1162/coli_a_00374													
J								LessLex: Linking Multilingual Embeddings to SenSe Representations of LEXical Items	COMPUTATIONAL LINGUISTICS											WORD; SIMILARITY; CORPUS	We present LESSLEX, a novel multilingual lexical resource. Different from the vast majority of existing approaches, we ground our embeddings on a sense inventory made available from the BabelNet semantic network. In this setting, multilingual access is governed by the mapping of terms onto their underlying sense descriptions, such that all vectors co-exist in the same semantic space. As a result, for each term we have thus the "blended" terminological vector along with those describing all senses associated to that term. LESSLEX has been tested on three tasks relevant to lexical semantics: conceptual similarity, contextual similarity, and semantic text similarity. We experimented over the principal data sets for such tasks in their multilingual and crosslingual variants, improving on or closely approaching state-of-the-art results. We conclude by arguing that LESSLEX vectors may be relevant for practical applications and for research on conceptual and lexical access and competence.																	0891-2017	1530-9312				JUN	2020	46	2					289	333		10.1162/coli_a_00375													
J								LINSPECTOR: Multilingual Probing Tasks for Word Representations	COMPUTATIONAL LINGUISTICS												Despite an ever-growing number of word representation models introduced for a large number of languages, there is a lack of a standardized technique to provide insights into what is captured by these models. Such insights would help the community to get an estimate of the downstream task performance, as well as to design more informed neural architectures, while avoiding extensive experimentation that requires substantial computational resources not all researchers have access to. A recent development in NLP is to use simple classification tasks, also called probing tasks, that test for a single linguistic feature such as part-of-speech. Existing studies mostly focus on exploring the linguistic information encoded by the continuous representations of English text. However, from a typological perspective the morphologically poor English is rather an outlier: The information encoded by the word order and function words in English is often stored on a subword, morphological level in other languages. To address this, we introduce 15 type-level probing tasks such as case marking, possession, word length, morphological tag count, and pseudoword identification for 24 languages. We present a reusable methodology for creation and evaluation of such tests in a multilingual setting, which is challenging because of a lack of resources, lower quality of tools, and differences among languages. We then present experiments on several diverse multilingual word embedding models, in which we relate the probing task performance for a diverse set of languages to a range of five classic NLP tasks: POS-tagging, dependency parsing, semantic role labeling, named entity recognition, and natural language inference. We find that a number of probing tests have significantly high positive correlation to the downstream tasks, especially for morphologically rich languages. We show that our tests can be used to explore word embeddings or black-box neural models for linguistic cues in a multilingual setting. We release the probing data sets and the evaluation suite LINSPECTOR with.																	0891-2017	1530-9312				JUN	2020	46	2					335	385		10.1162/coli_a_00376													
J								A Systematic Study of Inner-Attention-Based Sentence Representations in Multilingual Neural Machine Translation	COMPUTATIONAL LINGUISTICS												Neural machine translation has considerably improved the quality of automatic translations by learning good representations of input sentences. In this article, we explore a multilingual translation model capable of producing fixed-size sentence representations by incorporating an intermediate crosslingual shared layer, which we refer to as attention bridge. This layer exploits the semantics from each language and develops into a language-agnostic meaning representation that can be efficiently used for transfer learning. We systematically study the impact of the size of the attention bridge and the effect of including additional languages in the model. In contrast to related previous work, we demonstrate that there is no conflict between translation performance and the use of sentence representations in downstream tasks. In particular, we show that larger intermediate layers not only improve translation quality, especially for long sentences, but also push the accuracy of trainable classification tasks. Nevertheless, shorter representations lead to increased compression that is beneficial in non-trainable similarity tasks. Similarly, we show that trainable downstream tasks benefit from multilingual models, whereas additional language signals do not improve performance in non-trainable benchmarks. This is an important insight that helps to properly design models for specific applications. Finally, we also include an in-depth analysis of the proposed attention bridge and its ability to encode linguistic properties. We carefully analyze the information that is captured by individual attention heads and identify interesting patterns that explain the performance of specific settings in linguistic probing tasks.																	0891-2017	1530-9312				JUN	2020	46	2					387	424		10.1162/coli_a_00377													
J								Abstract Syntax as Interlingua: Scaling Up the Grammatical Framework from Controlled Languages to Robust Pipelines	COMPUTATIONAL LINGUISTICS											ENGLISH	.Abstract syntax is an interlingual representation used in compilers. Grammatical Framework (GF) applies the abstract syntax idea to natural languages. The development of GF started in 1998, first as a tool for controlled language implementations, where it has gained an established position in both academic and commercial projects. GF provides grammar resources for over 40 languages, enabling accurate generation and translation, as well as grammar engineering tools and components for mobile and Web applications. On the research side, the focus in the last ten years has been on scaling up GF to wide-coverage language processing. The concept of abstract syntax offers a unified view on many other approaches: Universal Dependencies, WordNets, FrameNets, Construction Grammars, and Abstract Meaning Representations. This makes it possible for GF to utilize data from the other approaches and to build robust pipelines. In return, GF can contribute to data-driven approaches by methods to transfer resources from one language to others, to augment data by rule-based generation, to check the consistency of handannotated corpora, and to pipe analyses into high-precision semantic back ends. This article gives an overview of the use of abstract syntax as interlingua through both established and emerging NLP applications involving GF.																	0891-2017	1530-9312				JUN	2020	46	2					425	486		10.1162/coli_a_00378													
J								Fair Is Better than Sensational: Man Is to Doctor as Woman Is to Doctor	COMPUTATIONAL LINGUISTICS												Analogies such asman is to king as woman is to Xare often used to illustrate the amazing power of word embeddings. Concurrently, they have also been used to expose how strongly human biases are encoded in vector spaces trained on natural language, with examples likeman is to computer programmer as woman is to homemaker. Recent work has shown that analogies are in fact not an accurate diagnostic for bias, but this does not mean that they are not used anymore, or that their legacy is fading. Instead of focusing on the intrinsic problems of the analogy task as a bias detection tool, we discuss a series of issues involving implementation as well as subjective choices that might have yielded a distorted picture of bias in word embeddings. We stand by the truth that human biasesarepresent in word embeddings, and, of course, the need to address them. But analogies are not an accurate tool to do so, and the way they have been most often used has exacerbated some possibly non-existing biases and perhaps hidden others. Because they are still widely popular, and some of them have become classics within and outside the NLP community, we deem it important to provide a series of clarifications that should put well-known, and potentially new analogies, into the right perspective.																	0891-2017	1530-9312				JUN	2020	46	2					487	498		10.1162/coli_a_00379													
J								The Limitations of Stylometry for Detecting Machine-Generated Fake News	COMPUTATIONAL LINGUISTICS												Recent developments in neural language models (LMs) have raised concerns about their potential misuse for automatically spreading misinformation. In light of these concerns, several studies have proposed to detect machine-generated fake news by capturing their stylistic differences from human-written text. These approaches, broadly termed stylometry, have found success in source attribution and misinformation detection in human-written texts. However, in this work, we show that stylometry is limited against machine-generated misinformation. Whereas humans speak differently when trying to deceive, LMs generate stylistically consistent text, regardless of underlying motive. Thus, though stylometry can successfully prevent impersonation by identifying text provenance, it fails to distinguish legitimate LM applications from those that introduce false information. We create two benchmarks demonstrating the stylistic similarity between malicious and legitimate uses of LMs, utilized in auto-completion and editing-assistance settings.(1)Our findings highlight the need for non-stylometry approaches in detecting machine-generated misinformation, and open up the discussion on the desired evaluation benchmarks.																	0891-2017	1530-9312				JUN	2020	46	2					499	510		10.1162/coli_a_00380													
J								Dual Indicators to Analyze AI Benchmarks: Difficulty, Discrimination, Ability, and Generality	IEEE TRANSACTIONS ON GAMES										Artificial intelligence; Games; Benchmark testing; Task analysis; Adaptation models; Guidelines; Indexes; Artificial intelligence (AI) benchmarks; AI evaluation; generality; item response theory (ITR)	ITEM RESPONSE THEORY; GAME; COMPETITION	With the purpose of better analyzing the result of artificial intelligence (AI) benchmarks, we present two indicators on the side of the AI problems, difficulty and discrimination, and two indicators on the side of the AI systems, ability and generality. The first three are adapted from psychometric models in item response theory (IRT), whereas generality is defined as a new metric that evaluates whether an agent is consistently good at easy problems and bad at difficult ones. We illustrate how these key indicators give us more insight on the results of two popular benchmarks in AI, the Arcade Learning Environment (Atari 2600 games) and the General Video Game AI competition, and we include some guidelines to estimate and interpret these indicators for other AI benchmarks and competitions.																	2475-1502	2475-1510				JUN	2020	12	2					121	131		10.1109/TG.2018.2883773													
J								Self-Adaptive Monte Carlo Tree Search in General Game Playing	IEEE TRANSACTIONS ON GAMES										Games; Resource management; Evolutionary computation; Tuners; Monte Carlo methods; Optimization; Combinatorial multi-armed bandit (CMAB); evolutionary algorithms; general game playing (GGP); Monte Carlo methods; N-tuple systems; on-line parameter tuning	STRATEGY	Many enhancements for Monte Carlo tree search (MCTS) have been applied successfully in general game playing (GGP). MCTS and its enhancements are controlled by multiple parameters that require extensive and time-consuming offline optimization. Moreover, as the played games are unknown in advance, offline optimization cannot tune parameters specifically for single games. This paper proposes a self-adaptive MCTS strategy (SA-MCTS) that integrates within the search a method to automatically tune search-control parameters online per game. It presents five different allocation strategies that decide how to allocate available samples to evaluate parameter values. Experiments with 1 s play-clock on multiplayer games show that for all the allocation strategies the performance of SA-MCTS that tunes two parameters is at least equal to or better than the performance of MCTS tuned offline and not optimized per-game. The allocation strategy that performs the best is N-Tuple Bandit Evolutionary Algorithm (NTBEA). This strategy also achieves a good performance when tuning four parameters. SA-MCTS can be considered as a successful strategy for domains that require parameter tuning for every single problem, and it is also a valid alternative for domains where offline parameter tuning is costly or infeasible.																	2475-1502	2475-1510				JUN	2020	12	2					132	144		10.1109/TG.2018.2884768													
J								"Are You Playing a Shooter Again?!" Deep Representation Learning for Audio-Based Video Game Genre Recognition	IEEE TRANSACTIONS ON GAMES										Games; Feature extraction; Task analysis; Acoustics; Monitoring; YouTube; Sports; Audio classification; convolutional neural network (CNN); deep learning; game genre classification	CLASSIFICATION; AI	In this paper, we present a novel computer audition task: audio-based video game genre classification. The aim of this study is threefold: 1) to check the feasibility of the proposed task; 2) to introduce a new corpus: The Game Genre by Audio + Multimodal Extracts (G(2) AME), collected entirely from social multimedia; and 3) to compare the efficacy of various acoustic feature spaces to classify the G(2) AME corpus into six game genres using a linear support vector machine classifier. For the classification we extract three different feature representations from the game audio files: 1) Knowledge-based acoustic features; 2) Deep Spectrum features; and 3) quantized Deep Spectrum features using Bag-of-Audio-Words. The Deep Spectrum features are a deep-learning-based representation derived from forwarding the visual representations of the audio instances, in particular spectrograms, mel-spectrograms, chromagrams, and their deltas through deep task-independent pretrained CNNs. Specifically, activations of fully connected layers from three common image classification CNNs, GoogLeNet, AlexNet, and VGG16 are used as feature vectors. Results for the six-genre classification problem indicate the suitability of our deep learning approach for this task. Our best method achieves an accuracy of up to 66.9% unweighted average recall using tenfold cross-validation.																	2475-1502	2475-1510				JUN	2020	12	2					145	154		10.1109/TG.2019.2894532													
J								Toward Personalized Adaptive Gamification: A Machine Learning Model for Predicting Performance	IEEE TRANSACTIONS ON GAMES										Task analysis; Games; Adaptation models; Predictive models; Machine learning; Data models; Training; Facial expression; gamification; machine learning; performance	TASK COMPLEXITY; ENGAGEMENT; GAMES; EXPERIENCE; EFFICACY; FEATURES	Personalized adaptive gamification has the potential to improve individuals' motivation and performance. Current methods aim to predict the perceived affective state (i.e., emotion) of an individual in order to improve their motivation and performance by tailoring an application. However, existing methods may struggle to predict the state of an individual that it has not been trained for. Moreover, the affective state that correlates to good performance may vary based on individuals and task characteristics. Given these limitations, this paper presents a machine learning method that uses task information and an individual's facial expression data to predict his/her performance on a gamified task. The training data used to generate the adaptive-individual-task model is updated every time new data from an individual is acquired. This approach helps to improve the model's prediction accuracy and account for variations in facial expressions across individuals. A case study is presented that demonstrates the feasibility and performance of the model. The results indicate that the model is able to predict the performance of individuals, before completing a task, with an accuracy of 0.768. The findings support the use of adaptive models that dynamically update their training data set and consider task information and individuals' facial expression data.																	2475-1502	2475-1510				JUN	2020	12	2					155	168		10.1109/TG.2018.2883661													
J								Comparison Training for Computer Chinese Chess	IEEE TRANSACTIONS ON GAMES										Chinese chess; comparison training; machine learning; n-tuple networks	GO	This paper describes the application of modified comparison training for automatic feature weight tuning. The final objective is to improve the evaluation functions used in Chinese chess programs. First, we apply n-tuple networks to extract features. N-tuple networks require very little expert knowledge through its large numbers of features, while simultaneously allowing easy access. Second, we propose a modified comparison training into which tapered eval is incorporated. Experiments show that with the same features and the same Chinese chess program, the automatically tuned feature weights achieved a win rate of 86.58% against the hand-tuned features. The above trained version was then improved by adding additional features, most importantly n-tuple features. This improved version achieved a win rate of 81.65% against the trained version without additional features.																	2475-1502	2475-1510				JUN	2020	12	2					169	176		10.1109/TG.2019.2893430													
J								Crawling in Rogue's Dungeons With Deep Reinforcement Techniques	IEEE TRANSACTIONS ON GAMES										Actor-Critic with Experience Replay (ACER); Asynchronous Advantage Actor-Critic (A3C); attention; deep reinforcement learning; dungeon; experience replay; labyrinth; maze; partially observable Markov decision process (MDP); Rogue; sparsity of rewards		This paper is a report of our extensive experimentation, during the last two years, of deep reinforcement techniques for training an agent to move in the dungeons of the famous Rogue video game. The challenging nature of the problem is tightly related to the procedural, random generation of new dungeon maps at each level, which forbids any form of level-specific learning and forces us to address the navigation problem in its full generality. Other interesting aspects of the game from the point of view of automatic learning are the partially observable nature of the problem since maps are initially not visible and get discovered during exploration, and the problem of sparse rewards, requiring the acquisition of complex, nonreactive behaviors involving memory and planning. In this paper, we develop on previous works to make a more systematic comparison of different learning techniques, focusing in particular on Asynchronous Advantage Actor-Critic and Actor-Critic with Experience Replay (ACER). In a game like Rogue, sparsity of rewards is mitigated by the variability of the dungeon configurations (sometimes, by luck, exit is at hand); if this variability can be tamed-as ACER, better than other algorithms, seems able to do-the problem of sparse rewards can be overcome without any need of intrinsic motivations.																	2475-1502	2475-1510				JUN	2020	12	2					177	186		10.1109/TG.2019.2899159													
J								Learning the Game of Go by Scalable Network Without Prior Knowledge of Komi	IEEE TRANSACTIONS ON GAMES										Board value network; computer Go; knowledge transfer; noKomi; policy network; reinforcement learning; scalable network		AlphaGo trains a value network to predict the win rate of the current state with 7.5 komi on a 19 x 19 board. The komi of most rectangular boards is unknown, so we do not know who the winner is at the end of the game. We need to use the human experience to guess a komi and then train the value network with this komi. Therefore, the accuracy of the value network is related to the accuracy of the guess. This article uses the board value network to calculate the score of the current state and tries to maximize the score. Then, we do not need to guess the komi. We also modify the network structure to support the board with arbitrary board size as input. Furthermore, we can transfer knowledge of the small board to the large board. We propose an algorithm that can adapt to the bonus rule. We have experimentally proved that our method is effective on a small board and has the ability to transfer knowledge to the large board. In order to better understand the learning process, we visualize the policy and score of some major branches. Finally, we show the solution that our program obtained on 6 x 6, 6 x 7, and 7 x 8 boards.																	2475-1502	2475-1510				JUN	2020	12	2					187	198		10.1109/TG.2020.2992858													
J								Winning Is Not Everything: Enhancing Game Development With Intelligent Agents	IEEE TRANSACTIONS ON GAMES										Games; Training; Task analysis; Reinforcement learning; Art; Conferences; Artificial intelligence; A* search; deep learning; imitation learning (IL); multiagent learning; nonplayer character (NPC); playtesting; reinforcement learning (RL)	VALUE-ITERATION; GO	Recently, there have been several high-profile achievements of agents learning to play games against humans and beat them. In this article, we study the problem of training intelligent agents in service of game development. Unlike the agents built to "beat the game," our agents aim to produce human-like behavior to help with game evaluation and balancing. We discuss two fundamental metrics based on which we measure the human-likeness of agents, namely skill and style, which are multifaceted concepts with practical implications outlined in this article. We report four case studies in which the style and skill requirements inform the choice of algorithms and metrics used to train agents; ranging from A* search to state-of-the-art deep reinforcement learning (RL). Furthermore, we, show that the learning potential of state-of-the-art deep RL models does not seamlessly transfer from the benchmark environments to target ones without heavily tuning their hyperparameters, leading to linear scaling of the engineering efforts, and computational cost with the number of target domains.																	2475-1502	2475-1510				JUN	2020	12	2					199	212		10.1109/TG.2020.2990865													
J								A Mobile Game for Automatic Emotion-Labeling of Images	IEEE TRANSACTIONS ON GAMES										Games; Autism; Emotion recognition; Medical treatment; Training; Databases; Pediatrics; Autism; crowdsourcing; emotion; mobile; domain adaptation; machine learning; deep learning	AUTISM; RECOGNITION	In this short paper, we describe challenges in the development of a mobile charades-style game for delivery of social training to children with autism spectrum disorder (ASD). Providing real-time feedback and adapting game difficulty in response to the child's performance necessitates the integration of emotion classifiers into the system. Due to the limited performance of existing emotion recognition platforms for children with ASD, we propose a novel technique to automatically extract emotion-labeled frames from video acquired from game sessions, which we hypothesize can be used to train new emotion classifiers to overcome these limitations. Our technique, which uses probability scores from three different classifiers and meta information from game sessions, correctly identified 83% of frames compared to a baseline of 51.6% from the best emotion classification API evaluated in this paper.																	2475-1502	2475-1510				JUN	2020	12	2					213	218		10.1109/TG.2018.2877325													
J								Infinite Loot Box: A Platform for Simulating Video Game Loot Boxes	IEEE TRANSACTIONS ON GAMES										Games; Visualization; Visual effects; Open source software; Currencies; Industries; Media; Loot box; loot box audio; loot box embellishment; loot box graphics; loot box juiciness; loot box visuals		Loot boxes are garnering increased attention in both the industry and media. One focal point of the discussion is whether loot boxes should be considered a form of gambling. While parallels can be drawn between loot boxes and random reward schedules, researchers have argued that the "glorification" aspect of loot boxes that have heightened player awareness (e.g., opening a box, a pack of cards, or spinning a wheel) of randomness is a relatively new trend in games. However, there is currently a dearth of empirical research on loot boxes. We make two contributions in this paper: 1) Infinite Loot Box, an open-source Unity platform for experimenting with loot boxes created from scratch; and 2) a 2 x 2 experiment (high/low visual effects x high/low audial effects; N = 1235). We find that high audial effects significantly increase the number of loot boxes opened. Neither audial nor visual effects were found to significantly impact other variables. These contributions push forward our understanding of loot boxes and their contextual factors.																	2475-1502	2475-1510				JUN	2020	12	2					219	224		10.1109/TG.2019.2913320													
J								Toward development of PreVoid alerting system for nocturnal enuresis patients: A fuzzy-based approach for determining the level of liquid encased in urinary bladder	ARTIFICIAL INTELLIGENCE IN MEDICINE										Bladder non-destructive testing (NDT); Fuzzy classifier; Error correcting output codes; Nocturnal enuresis; Intelligent systems; Discriminant feature analysis; Medical wearable sensors	NONLINEAR PROPAGATION; ULTRASOUND BLADDER; IN-VITRO; THERMOMETRY; FIELDS; SIGNAL	Preventive and accurate assessment of bladder voiding dysfunctions necessitates measuring the amount of liquid encapsulated within urinary bladder walls in a non-invasive and real-time manner. The real-time monitoring of urine levels helps patients with urological disorders such as Nocturnal Enuresis (NE) by preventing the occurrence of enuresis via a pre-void stage alerting system. Although some advances have been achieved toward developing a non-invasive approach for determining the amount of accumulated urine inside the bladder, there is still a lack of an easy-to-implement technique which is suitable to embed in a wearable pre-warning device. This study aims to develop a machine-learning empowered technique to quantify to what extent an individual's bladder is filled by observing the filling-voiding pattern of a patient over a training period. In this experiment, a pulse-echo sonar element is used to generate ultrasound pulses while the probe surface is positioned perpendicular to the bladder's position. From the reflected echoes, four features which show sufficient sensitiveness and therefore could be modulated noticeably by different levels of liquid encased in the bladder, are extracted. The extracted features are then fed into a novel intelligent decision support system- known as FECOC - which is based on hybridization of fuzzy inference systems (FIS) and error correcting output codes (ECOC). The proposed scheme tends to achieve better results when examined in real case studies.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101819	10.1016/j.artmed.2020.101819													
J								Graph Fourier transform of fMRI temporal signals based on an averaged structural connectome for the classification of neuroimaging	ARTIFICIAL INTELLIGENCE IN MEDICINE										Graph signal processing; Machine learning; Resting-state analysis; Neuroimaging; Classification	AUTISM	Graph signal processing (GSP) is a framework that enables the generalization of signal processing to multivariate signals described on graphs. In this paper, we present an approach based on Graph Fourier Transform (GFT) and machine learning for the analysis of resting-state functional magnetic resonance imaging (rs-fMRI). For each subject, we use rs-fMRI time series to compute several descriptive statistics in regions of interest (ROI). Next, these measures are considered as signals on an averaged structural graph built using tractography of the white matter of the brain, defined using the same ROI. GFT of these signals is computed using the structural graph as a support, and the obtained feature vectors are subsequently benchmarked in a supervised learning setting. Further analysis suggests that GFT using structural connectivity as a graph and the standard deviation of fMRI time series as signals leads to more accurate supervised classification using a world-wide multi-site database known as ABIDE (Autism Brain Imaging Data Exchange) when compared to several other statistical metrics. Moreover, the proposed approach outperforms several approaches, based on using functional connectomes or complex functional network measures as features for classification.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101870	10.1016/j.artmed.2020.101870													
J								A trusted medical image super-resolution method based on feedback adaptive weighted dense network	ARTIFICIAL INTELLIGENCE IN MEDICINE										Medical image super-resolution; Trusted medical image reconstruction; Deep convolutional neural network; Feedback mechanism; Adaptive weighting	RESOLUTION	High-resolution (HR) medical images are preferred in clinical diagnoses and subsequent analysis. However, the acquisition of HR medical images is easily affected by hardware devices. As an effective and trusted alternative method, the super-resolution (SR) technology is introduced to improve the image resolution. Compared with traditional SR methods, the deep learning-based SR methods can obtain more clear and trusted HR images. In this paper, we propose a trusted deep convolutional neural network-based SR method named feedback adaptive weighted dense network (FAWDN) for HR medical image reconstruction. Specifically, the proposed FAWDN can transmit the information of the output image to the low-level features by a feedback connection. To explore advanced feature representation and reduce the feature redundancy in dense blocks, an adaptive weighted dense block (AWDB) is introduced to adaptively select the informative features. Experimental results demonstrate that our FAWDN outperforms the state-of-the-art image SR methods and can obtain more clear and trusted medical images than comparative methods.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101857	10.1016/j.artmed.2020.101857													
J								FDSR: A new fuzzy discriminative sparse representation method for medical image classification	ARTIFICIAL INTELLIGENCE IN MEDICINE										Discriminative sparse representation; Fuzzy dictionary learning; Medical image classification; Inter-class difference; Intra-class similarity	BRAIN-TUMORS; SEGMENTATION; DICTIONARY; UNCERTAINTY; FUSION; SYSTEM; MRI	Recent developments in medical image analysis techniques make them essential tools in medical diagnosis. Medical imaging is always involved with different kinds of uncertainties. Managing these uncertainties has motivated extensive research on medical image classification methods, particularly for the past decade. Despite being a powerful classification tool, the sparse representation suffers from the lack of sufficient discrimination and robustness, which are required to manage the uncertainty and noisiness in medical image classification issues. It is tried to overcome this deficiency by introducing a new fuzzy discriminative robust sparse representation classifier, which benefits from the fuzzy terms in its optimization function of the dictionary learning process. In this work, we present a new medical image classification approach, fuzzy discriminative sparse representation (FDSR). The proposed fuzzy terms increase the inter-class representation difference and the intraclass representation similarity. Also, an adaptive fuzzy dictionary learning approach is used to learn dictionary atoms. FDSR is applied on Magnetic Resonance Images (MRI) from three medical image databases. The comprehensive experimental results clearly show that our approach outperforms its series of rival techniques in terms of accuracy, sensitivity, specificity, and convergence speed.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101876	10.1016/j.artmed.2020.101876													
J								CT window trainable neural network for improving intracranial hemorrhage detection by combining multiple settings	ARTIFICIAL INTELLIGENCE IN MEDICINE										Cr window estimator; Lesion classification; Intracranial hemorrhage; Combination of multiple window settings; Convolutional neural network; End-to-end diagnostic radiology learning	ACUTE STROKE; TOMOGRAPHY	Window settings to rescale and contrast stretch raw data from radiographic images such as Computed Tomography (CT), X-ray and Magnetic Resonance images is a crucial step as data pre-processing to examine abnormalities and diagnose diseases. We propose a distant-supervised method for determining automatically the best window settings by attaching a window estimator module (WEM) to a deep convolutional neural network (DCNN)-based lesion classifier and training them in conjunction. Aside from predicting a flexible window setting for each raw image, we statistically identify the top four window settings by calculating the mean and standard deviations for the entire dataset. Images are scaled on each of the top settings estimated by WEM and following lesion classifiers are subsequently trained. We study the effects of only using the flexible window, the single fixed window as either a known default window used by radiologists or an estimated mean value, and two different approaches to combine results from the top window settings to improve the detection of intracranial hemorrhage (ICH) from brain CT images. Experimental results showed that using the top four window settings identified from the window estimator module and combining the results had the best performance.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101850	10.1016/j.artmed.2020.101850													
J								Deep learning in generating radiology reports: A survey	ARTIFICIAL INTELLIGENCE IN MEDICINE										Convolutional neural network; Deep learning; Natural language processing; Radiology; Recurrent neural network	SEGMENTATION	Substantial progress has been made towards implementing automated radiology reporting models based on deep learning (DL). This is due to the introduction of large medical text/image datasets. Generating radiology coherent paragraphs that do more than traditional medical image annotation, or single sentence-based description, has been the subject of recent academic attention. This presents a more practical and challenging application and moves towards bridging visual medical features and radiologist text. So far, the most common approach has been to utilize publicly available datasets and develop DL models that integrate convolutional neural networks (CNN) for image analysis alongside recurrent neural networks (RNN) for natural language processing (NLP) and natural language generation (NLG). This is an area of research that we anticipate will grow in the near future. We focus our investigation on the following critical challenges: understanding radiology text/image structures and datasets, applying DL algorithms (mainly CNN and RNN), generating radiology text, and improving existing DL based models and evaluation metrics. Lastly, we include a critical discussion and future research recommendations. This survey will be useful for researchers interested in DL, particularly those interested in applying DL to radiology reporting.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101878	10.1016/j.artmed.2020.101878													
J								Regularized-Ncut: Robust and homogeneous functional parcellation of neonate and adult brain networks	ARTIFICIAL INTELLIGENCE IN MEDICINE										Regularized-Ncut; Functional parcellation; Low SNR; Homogeneity; Neonate; Intra-Network connectivity	RESTING-STATE NETWORKS; FMRI DATA; CONNECTIVITY; ORGANIZATION; ARCHITECTURE; VALIDATION; CORTEX; MRI; IDENTIFICATION; EMERGENCE	Brain network parcellation based on resting-state functional MRI (rs-fMRI) is affected by noise, resulting in spurious small patches and decreased functional homogeneity within each network. Obtaining robust and homogeneous parcellation of neonate brain is more difficult, because neonate rs-fMRI is associated with relatively higher level of noise and no prior knowledge from a functional neonate atlas is available as spatial constraints. To meet these challenges, we developed a novel data-driven Regularized Normalized-cut (RNcut) method. RNcut is formulated by adding two regularization terms, a smoothing term using Markov random fields and a small-patch removal term, to conventional normalized-cut (Ncut) method. The RNcut and competing methods were tested with simulated datasets with known ground truth and then applied to both adult and neonate rs-fMRI datasets. Based on the parcellated networks generated by RNcut, infra-network connectivity was quantified. The test results from simulated datasets demonstrated that the RNcut method is more robust (p < 0.01) to noise and can delineate parcellated functional networks with significantly better (p < 0.01) spatial contiguity and significantly higher (p < 0.01) functional homogeneity than competing methods. Application of RNcut to neonate and adult rs-fMRI dataset revealed distinctive functional brain organization of neonate brains from that of adult brains. Collectively, we developed a novel data-driven RNcut method by integrating conventional Ncut with two regularization terms, generating robust and homogeneous functional parcellation without imposing spatial constraints. A broad range of brain network applications and analyses, especially neonate and infant brain parcellation with noisy and large sample of datasets, can potentially benefit from this RNcut method.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101872	10.1016/j.artmed.2020.101872													
J								How to identify and treat data inconsistencies when eliciting health-state utility values for patient-centered decision making	ARTIFICIAL INTELLIGENCE IN MEDICINE										Health-state utilities; Quality-Adjusted life years (QALYs); Shared decision making; Cost/utility analysis; Patient-Centered healthcare; Quadratic optimization	RISK PROSTATE-CANCER; INITIAL TREATMENT; MEN	Background: Health utilities express the perceptions patients have on the impact potential adverse events of medical treatments may have on their quality of life. Being able to accurately assess health utilities is crucial when deciding what is the best treatment when multiple and diverse treatment options exist, or when performing a cost / utility analysis. Due to the emotional and other complexities that may exist when such data are elicited, the values of the health utilities may be inaccurate and cause inconsistencies. Existing literature indicates that such inconsistencies may be very frequent. However, no method has been developed for dealing with such inconsistencies in an effective manner. Methods: Given a set of health utilities, this paper first explores ways for determining if there are any inconsistencies in their values. It also proposes a number of quadratic optimization approaches to best estimate the actual (and hence unknown) values when a set of initial health utility values are provided by the patient and certain inconsistencies have been detected. This is achieved by readjusting the initial values in a way that is minimal and also satisfies certain consistency requirements. Results: The proposed methods are applied on an illustrative example related to localized prostate cancer. Data from some published studies were used to illustrate how a set of initial values can be analyzed. This analysis aims at readjusting them in a minimal manner that would also satisfy some key numerical constraints pertinent to health utility values. Conclusions: The numerical results and the computational complexities of the proposed models indicate that the proposed approaches are practical as they involve quadratic optimization modeling. These approaches are novel as the problem of addressing numerical inconsistencies in the elicitation process of health utilities has not been addressed adequately. The approaches are also critical in shared decision making and also when performing cost / utility analyses because health utilities play a central role in determining the quality-adjusted life years when making decisions in these healthcare domains.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101882	10.1016/j.artmed.2020.101882													
J								Speckle reduction of OCT via super resolution reconstruction and its application on retinal layer segmentation	ARTIFICIAL INTELLIGENCE IN MEDICINE										Speckle reduction; OCT; Retinal layer segmentation	OPTICAL COHERENCE TOMOGRAPHY; IMAGES; FILTER; ENHANCEMENT; NOISE	Optical coherence tomography (OCT) is a rapidly developing non-invasive three dimensional imaging approach, and it has been widely used in examination and diagnosis of eye diseases. However, speckle noise are often inherited from image acquisition process, and may obscure the anatomical structure, such as the retinal layers. In this paper, we propose a novel method to reduce the speckle noise in 3D OCT scans, by introducing a new super-resolution approach. It uses a multi-frame fusion mechanism that merges multiple scans for the same scene, and utilizes the movements of sub-pixels to recover missing signals in one pixel, which significantly improves the image quality. To evaluate the effectiveness of the proposed speckle noise reduction method, we have applied it for the application of retinal layer segmentation. Results show that the proposed method has produced promising enhancement performance, and enable deep learning-based methods to obtain more accurate retinal layer segmentation results.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101871	10.1016/j.artmed.2020.101871													
J								Classification of myocardial infarction based on hybrid feature extraction and artificial intelligence tools by adopting tunable-Q wavelet transform (TQWT), variational mode decomposition (VMD) and neural networks	ARTIFICIAL INTELLIGENCE IN MEDICINE										Electrocardiography (ECG); Myocardial infarction (MI) detection; Tunable Q-factor wavelet transform (TQWT); Variational mode decomposition (VMD); Phase space reconstruction (PSR); Cardiac system dynamics	CORONARY-ARTERY-DISEASE; PHASE-SPACE RECONSTRUCTION; ECG SIGNAL CLASSIFICATION; EEG SIGNALS; AUTOMATED DETECTION; FEATURE-SELECTION; 12-LEAD ELECTROCARDIOGRAM; CARDIAC-ARRHYTHMIAS; GENETIC ALGORITHM; DIAGNOSIS	Cardiovascular diseases (CVD) is the leading cause of human mortality and morbidity around the world, in which myocardial infarction (MI) is a silent condition that irreversibly damages the heart muscles. Currently, electrocardiogram (ECG) is widely used by the clinicians to diagnose MI patients due to its inexpensiveness and non-invasive nature. Pathological alterations provoked by MI cause slow conduction by increasing axial resistance on coupling between cells. This issue may cause abnormal patterns in the dynamics of the tip of the cardiac vector in the ECG signals. However, manual interpretation of the pathological alternations induced by MI is a time-consuming, tedious and subjective task. To overcome such disadvantages, computer-aided diagnosis techniques including signal processing and artificial intelligence tools have been developed. In this study we propose a novel technique for automatic detection of MI based on hybrid feature extraction and artificial intelligence tools. Tunable quality factor (Q-factor) wavelet transform (TQWT), variational mode decomposition (VMD) and phase space reconstruction (PSR) are utilized to extract representative features to form cardiac vectors with synthesis of the standard 12-lead and Frank XYZ leads. They are combined with neural networks to model, identify and detect abnormal patterns in the dynamics of cardiac system caused by MI. First, 12-lead ECG signals are reduced to 3-dimensional VCG signals, which are synthesized with Frank XYZ leads to build a hybrid 4-dimensional cardiac vector. Second, this vector is decomposed into a set of frequency subbands with a number of decomposition levels by using the TQWT method. Third, VMD is employed to decompose the subband of the 4-dimensional cardiac vector into different intrinsic modes, in which the first intrinsic mode contains the majority of the cardiac vector's energy and is considered to be the predominant intrinsic mode. It is selected to construct the reference variable for analysis. Fourth, phase space of the reference variable is reconstructed, in which the properties associated with the nonlinear cardiac system dynamics are preserved. Three-dimensional (3D) PSR together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in cardiac system dynamics between normal (healthy) and MI cardiac vector signals. Fifth, cardiac system dynamics can be modeled and identified using neural networks, which employ the ED of 3D PSR of the reference variable as the input features. The difference of cardiac system dynamics between healthy control and MI cardiac vector is computed and used for the detection of MI based on a bank of estimators. Finally, data sets, which include conventional 12-lead and Frank XYZ leads ECG signal fragments from 148 patients with MI and 52 healthy controls from PTB diagnostic ECG database, are used for evaluation. By using the 10-fold cross-validation style, the achieved average classification accuracy is reported to be 97.98%. Currently, ST segment evaluation is one of the major and traditional ways for the MI detection. However, there exist weak or even undetectable ST segments in many ECG signals. Since the proposed method does not rely on the information of ST waves, it can serve as a complementary MI detection algorithm in the intensive care unit (ICU) of hospitals to assist the clinicians in confirming their diagnosis. Overall, our results verify that the pro- posed features may satisfactorily reflect cardiac system dynamics, and are complementary to the existing ECG features for automatic cardiac function analysis.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101848	10.1016/j.artmed.2020.101848													
J								ECG-based multi-class arrhythmia detection using spatio-temporal attention-based convolutional recurrent neural network	ARTIFICIAL INTELLIGENCE IN MEDICINE										Arrhythmia detection; ECG; Convolution neural network; Spatio-temporal attention module; Recurrent neural network	CLASSIFICATION; FEATURES; ELECTROCARDIOGRAM; MIXTURE	Automatic arrhythmia detection based on electrocardiogram (ECG) is of great significance for early prevention and diagnosis of cardiac diseases. Recently, deep learning methods have been applied to arrhythmia detection and obtained great success. Among them, convolutional neural network (CNN) is an effective method for extracting features due to its local connectivity and parameter sharing. In addition, recurrent neural network (RNN) is another commonly used method, which is applied to process time-series signal. The stacking of both CNN and RNN has been proved to be more effective in mull-class arrhythmia detection. However, these networks ignored the fact that different channels and temporal segments of a feature map extracted from the 12-lead ECG signal contribute differently to cardiac arrhythmia detection, and thus, the classification performance could be greatly improved. To address this issue, spatio-temporal attention-based convolutional recurrent neural network (STA-CRNN) is proposed to focus on representative features along both spatial and temporal axes. STA-CRNN consists of CNN subnetwork, spatio-temporal attention modules and RNN subnetwork. The experiment result shows that, STA-CRNN reaches an average F-1 score of 0.835 in classifying 8 types of arrhythmias and normal rhythm. Compared with the state-of-the-art methods based on the same public dataset, STA-CRNN achieves an obvious improvement on identifying most of arrhythmias. Also, it is demonstrated by visualization that the learned features through STA-CRNN are in line with clinical judgement. STA-CRNN provides a promising method for automatic arrhythmia detection, which has a potential to assist cardiologists in the diagnosis of arrhythmias.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101856	10.1016/j.artmed.2020.101856													
J								Upper-limb functional assessment after stroke using mirror contraction: A pilot study	ARTIFICIAL INTELLIGENCE IN MEDICINE										Biological signal processing; sEMG; Stroke; Bilateral arms bias	MYOELECTRIC CONTROL; SURFACE EMG; PROSTHESES; RECOVERY	The clinical assessment after stroke depends on the rating scale, usually lack of quantitative feedback such as biomedical signal captured from stroke patients. This study attempts to develop a unified assessment framework for persons after stroke via surface electromyography (sEMG) bias from bilateral limbs, based on four types of selected movements, namely forward lift arm, lateral lift arm, forearm internal/external rotation, forearm pronation/supination. Eleven healthy subjects and six stroke patients are recruited to participate in the experiment to perform the bilateral-mirrored paradigm with six channels of sEMG signals recorded from each of their arms. The linear discriminant analysis (LDA), random forest algorithm (RF) and support vector machine (SVM) are adopted, trained and used for stroke patients qualitative recognition. The bilateral bias diagnosis algorithm (BBDA) is developed to evaluate the stroke severity quantitatively based on the similarity index (SI) of the sEMG. The results reveal that (1) the sEMG feature bias of bilateral arms for stroke patients is different from that of healthy people; (2) the RF and SVM demonstrate a better performance with an average recognition accuracy of 0.92 +/- 0.12 and 0.93 +/- 0.12 than LDA (0.84 +/- 0.20) in distinguishing stroke patients from healthy subjects; (3) there is a strong positive correlation between SI and the Fugl-Meyer score (r = 0.93). These research findings indicate that the dominant qualitative assessment after stroke could be complementary by its counterpart quantitative solutions, and stroke rehabilitation could be automated with less involvement of professional therapists.																	0933-3657	1873-2860				JUN	2020	106								UNSP 101877	10.1016/j.artmed.2020.101877													
J								Analysing the Combined Health, Social and Economic Impacts of the Corovanvirus Pandemic Using Agent-Based Social Simulation	MINDS AND MACHINES											CRISIS	During the COVID-19 crisis there have been many difficult decisions governments and other decision makers had to make. E.g. do we go for a total lock down or keep schools open? How many people and which people should be tested? Although there are many good models from e.g. epidemiologists on the spread of the virus under certain conditions, these models do not directly translate into the interventions that can be taken by government. Neither can these models contribute to understand the economic and/or social consequences of the interventions. However, effective and sustainable solutions need to take into account this combination of factors. In this paper, we propose an agent-based social simulation tool, ASSOCC, that supports decision makers understand possible consequences of policy interventions, but exploring the combined social, health and economic consequences of these interventions.																	0924-6495	1572-8641				JUN	2020	30	2					177	194		10.1007/s11023-020-09527-6													
J								Sustainability assessment in the presence of undesirable factors over time: A case on gas companies	EXPERT SYSTEMS										data envelopment analysis; efficiency; sustainability; undesirable outputs	DATA ENVELOPMENT ANALYSIS; PERFORMANCE EVALUATION; EFFICIENCY ANALYSIS; OUTPUTS; SYSTEMS; ENERGY; MODEL	Sustainability is an essential ingredient for long-term success of firms, and its assessment has a significant impact on decision making and sustainability management. In the current paper, a data envelopment analysis-based approach is proposed to assess the sustainability of systems over several periods when undesirable outputs are present in the process. Indeed, sustainability is assessed in each period and, as a whole, simultaneously. Furthermore, social, economic, and environmental efficiency scores of multiperiod systems are evaluated in each period. The weak disposability assumption is used to handle undesirable outputs. Also, the current study concerns socio-economic, socioenvironmental, and eco-environmental factors in addition to economic, social, and environmental aspects. A real-world application on Iranian gas companies is used to illustrate the applicability of the proposed approach.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12316	10.1111/exsy.12316													
J								Analysis of the environmental efficiency in China based on the DEA cross-efficiency approach under different policy objectives	EXPERT SYSTEMS										cross-evaluation strategy; data envelopment analysis; dynamic correlation; technology heterogeneity; undesirable outputs	DATA ENVELOPMENT ANALYSIS; PRODUCTION TECHNOLOGY HETEROGENEITY; META-FRONTIER; UNDESIRABLE OUTPUTS; ENERGY EFFICIENCY; WINDOW ANALYSIS; POWER-PLANTS; INDUSTRY; PRODUCTIVITY; PERFORMANCE	The existing studies on environmental efficiency evaluation generally have the problem of efficiency overestimation. To solve this problem, a new data envelopment analysis (DEA) cross-efficiency approach with undesirable outputs is developed to evaluate environmental efficiency from the perspectives of both self-evaluation and peer evaluation. Then, three new evaluation strategies, namely, economic development strategy, environmental protection strategy, and win-win strategy, are proposed to reflect the needs of decision makers under different policy objectives. The proposed cross-efficiency approach with different evaluation strategies not only realizes the cross evaluation of environmental efficiency, but also guarantees the relative uniqueness of the optimal solution on the basis of the preferences of decision makers. Combining the metafrontier DEA approach and DEA window analysis, a new cross-efficiency analytical framework is constructed to gradually analyse the influences of policy objectives, technology heterogeneity, and dynamic correlation on the environmental efficiency. Subsequently, the environmental efficiency of China's economic development during 2006-2015 is in-depth analysed on the basis of the proposed analytical framework, and some interesting conclusions, and some useful suggestions are obtained.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12461	10.1111/exsy.12461													
J								Sustainability assessment of Iranian petrochemical companies in stock exchange: A data envelopment analysis-based approach	EXPERT SYSTEMS										network data envelopment analysis; petrochemical companies; relative efficiency; sustainable development	MEASURING EFFICIENCY; PERFORMANCE; DEA; MODEL; CHINA	The assessment of efficiency is always of particular importance according to different indicators from different perspectives. There are various techniques for evaluating petrochemical companies, among which the data envelopment analysis technique is one of the best techniques that can be used to calculate the relative efficiency of a set of decision-making units with network structures. In the present paper, seven petrochemical companies listed in the Iranian stock exchange were analysed. These companies were evaluated in terms of financial performance and sustainable development, and their relative efficiency was calculated during 2015-2016. According to the obtained results, only Marun Petrochemical Co. was found to be efficient in all areas and years. The results also showed that four companies were efficient in financial terms over the period under study. In the general conclusion regarding the companies' performance, Marun was ranked first, Jam was ranked second, and Zagros was ranked third.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12359	10.1111/exsy.12359													
J								Sustainability of Chinese airlines: A modified slack-based measure model for CO(2)emissions	EXPERT SYSTEMS										airline sustainability; Chinese airlines; CO(2)emissions; data envelopment analysis (DEA); slack-based measure; super efficiency	UNDESIRABLE FACTORS; FUEL EFFICIENCY; 2-STAGE TOPSIS; DEA; EMISSIONS; DEOPTIM	Sustainable airline operations have become an increasingly important issue in recent years. With this respect, several initiatives for reducing pollutant emissions-such as carbon dioxide (CO2)-in the airline industry are now under consideration by regulators, policymakers, and companies. The impact of these initiatives upon efficiency levels of airline operations is still being analysed by different authors. This article is focused on the efficiency assessment of 13 major Chinese airlines from 2008 to 2015, applying a modified slack-based measure model to account for CO(2)emissions. The impact of contextual variables related to the airline's age, fleet mix, stock market governance, ownership type, network span, and whether or not it has undergone a previous merger and acquisition process is tested by means of a stochastic non-linear robust regression approach. Findings suggest that sustainability in Chinese airline operations is dependent upon a number of economic factors such as learning curve, economies of scale, technology type, and network management. Policy implications are derived for Chinese airlines.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12302	10.1111/exsy.12302													
J								A fuzzy-clustering-based hierarchical i-vector/probabilistic linear discriminant analysis system for text-dependent speaker verification	EXPERT SYSTEMS										fuzzy clustering; hierarchy system; i-vector; text-dependent speaker verification	COMBINING EVIDENCE; FEATURES; EXTRACTION; MFCC	In the i-vector/probabilistic linear discriminant analysis (PLDA) technique, the PLDA backend classifier is modelled on i-vectors. PLDA defines an i-vector subspace that compensates the unwanted variability and helps to discriminate among speaker-phrase pairs. The channel or session variability manifested in i-vectors are known to be nonlinear in nature. PLDA training, however, assumes the variability to be linearly separable, thereby causing loss of important discriminating information. Besides, the i-vector estimation, itself, is known to be poor in case of short utterances. This paper attempts to address these issues using a simple hierarchy-based system. A modified fuzzy-clustering technique is employed to divide the feature space into more characteristic feature subspaces using vocal source features. Thereafter, a separate i-vector/PLDA model is trained for each of the subspaces. The sparser alignment owing to subspace-specific universal background model and the relatively reduced dimensions of variability in individual subspaces help to train more effective i-vector/PLDA models. Also, vocal source features are complementary to mel frequency cepstral coefficients, which are transformed into i-vectors using mixture model technique. As a consequence, vocal source features and i-vectors tend to have complementary information. Thus using vocal source features for classification in a hierarchy tree may help to differentiate some of the speaker-phrase classes, which otherwise are not easily discriminable based on i-vectors. The proposed technique has been validated on Part 1 of RSR2015 database, and it shows a relative equal error rate reduction of up to 37.41% with respect to the baseline i-vector/PLDA system.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12524	10.1111/exsy.12496													
J								Dynamic efficiency evaluation of state-level business incubators in China by using a slacks-based measure approach	EXPERT SYSTEMS										business incubators; carry-over variable; data envelopment analysis; dynamic efficiency; slacks-based measure	PERFORMANCE	It is important to evaluate the efficiency of business incubators for their performance improvement. Because few enterprises can successfully graduate from the incubation process in one incubation period, the incubating enterprises will be carried over to the successive periods. In this context, the number of incubating enterprises can be regarded as a carry-over variable linking different incubation periods, which can also be treated as an undesirable output in the current period. This paper proposes a dynamic slacks-based measure model to evaluate the efficiency of China's state-level business incubators during 2010-2012. The empirical results show that neglecting new entrants and the typical carry-over variable may underestimate the incubation system's efficiency. Moreover, the operational efficiency of China's state-level business incubators is relatively low, which is largely caused by the lower pure technical efficiency. There exist great disparities between pure technical efficiency and scale efficiency for all considered incubators in China. Some important insights and policy suggestions are presented.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12285	10.1111/exsy.12285													
J								Qualitative hesitant fuzzy group decision making: An additively consistent probability and consensus-based perspective	EXPERT SYSTEMS										additive consistency; consensus; group decision making; HFLPR; 0-1-MPMs	LINGUISTIC PREFERENCE RELATIONS; MULTIPLICATIVE CONSISTENCY; PRIORITY WEIGHTS; SUPPORT MODEL; TERM SETS; AGGREGATION; OPERATORS	Hesitant fuzzy linguistic preference relations (HFLPRs) can efficiently denote the hesitant qualitative judgments of decision makers. Consistency and consensus are two critical topics in group decision making (GDM) with preference relations. This paper uses the additively consistent concept for linguistic fuzzy preference relations (LFPRs) to give an additive consistency definition for HFLPRs. To judge the additive consistency of HFLPRs, 0-1 mixed programming models (0-1-MPMs) are constructed. Meanwhile, additive-consistency-based 0-1-MPMs to ascertain missing values in incomplete HFLPRs are established. Following the consistent probability of LFPRs, an algorithm to calculate the linguistic priority weighting vector is presented. In consideration of the consensus of GDM, a consistency-probability-distance-measure-based consensus index is defined, and an interactive improving consensus method is provided. Finally, a method for GDM with HFLPRs is offered that can address incomplete and inconsistent cases. Meanwhile, numerical examples are offered, and comparative analysis is made.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12510	10.1111/exsy.12510													
J								How does environmental regulation affect environmental performance? A case study of China's regional energy efficiency	EXPERT SYSTEMS										data envelopment analysis; energy efficiency; environmental productivity; environmental regulation	MULTILATERAL PRODUCTIVITY COMPARISONS; UNDESIRABLE OUTPUTS; GREEN PRODUCTIVITY; CO2 EMISSIONS; INNOVATION; DEA; GROWTH; ALLOCATION; INTENSITY; SECTORS	Environmental regulation has been recognized as an important way to directly improve environmental performance or indirectly impact environmental performance through increasing environmental innovation. The present paper constructs an energy and carbon emission total factor productivity index using the Malmquist-Luenberger productivity index and data envelopment analysis. The proposed technique is used to measure the environmental performance of 30 Chinese provinces during the period 2010-2015. The energy and carbon emission total factor productivity measure is divided into a pure technical efficiency index and a technical progress index to provide detailed environmental performance information. Then an ordinary least squares model is adopted to analyse the impact of environmental regulation on environmental innovation operation and environmental performance by hypothesis testing. The empirical results show that environmental regulation and environmental innovation have positive direct effects on environmental performance and that market-based environmental regulation has a positive indirect effect on environmental performance by increasing environmental innovation.																	0266-4720	1468-0394				JUN	2020	37	3			SI				e12326	10.1111/exsy.12326													
J								An Epigenetic Approach to Semantic Categories	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Semantics; Force; Legged locomotion; Shape; Syntactics; Cognition; Knowledge representation; language learning; robots; semantics	CONCEPTUAL SPACES; LANGUAGE STRUCTURE; NUMBER; RECOGNITION; DYNAMICS; HUMANS; MODELS	It is argued that early language learning in children emerges from five primary knowledge structures: 1) space; 2) objects; 3) actions; 4) number; and 5) events. These structures constitute the basis for the semantic domains that are used to form categories that represent the meanings of early words. The domains are naturally modeled in conceptual spaces that are based on geometric notions rather than on symbolic representations. It is shown how these semantics domains can be used to generate an epigenetic model of language acquisition. The four first primary knowledge systems are used for prepositions, nouns, verbs, and quantifiers, respectively, while events form the meanings of declarative sentences. This semantic model leads to direct recommendations for how the model can be implemented in robots and other artificial systems.																	2379-8920	2379-8939				JUN	2020	12	2					139	147		10.1109/TCDS.2018.2833387													
J								Quantifying the Role of Vocabulary Knowledge in Predicting Future Word Learning	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Vocabulary; Predictive models; Biological neural networks; Dogs; Linguistics; Knowledge engineering; Cognitive development; language acquisition; lexical acquisition; neural networks; word learning	LEXICAL DEVELOPMENT; LATE-TALKING; LANGUAGE; CONNECTIONIST; CHILDREN; SUPPORT; INPUT; NORMS; KINDS	Can we predict the words a child is going to learn next given information about the words that a child knows now? Do different representations of a child's vocabulary knowledge affect our ability to predict the acquisition of lexical items for individual children? Past research has often focused on population statistics of vocabulary growth rather than prediction of words an individual child is likely to learn next. We consider a neural network approach to predict vocabulary acquisition. Specifically, we investigate how best to represent the child's current vocabulary in order to accurately predict future learning. The models we consider are based on qualitatively different sources of information: descriptive information about the child, the specific words a child knows, and representations that aim to capture the child's aggregate lexical knowledge. Using longitudinal vocabulary data from children aged 15-36 months, we construct neural network models to predict which words are likely to be learned by a particular child in the coming month. Many models based on child-specific vocabulary information outperform models with child information only, suggesting that the words a child knows influence prediction of future language learning. These models provide an understanding of the role of current vocabulary knowledge on future lexical growth.																	2379-8920	2379-8939				JUN	2020	12	2					148	159		10.1109/TCDS.2019.2928023													
J								Neurocomputational Models Capture the Effect of Learned Labels on Infants' Object and Category Representations	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Visualization; Haptic interfaces; Data models; Training; Computational modeling; Encoding; Computer architecture; Cognitive development; connectionist model; label status; language development; representational development	LINGUISTIC LABELS; CATEGORIZATION; SIMILARITY; EXPERIENCE; MECHANISMS; SHAPE; ATTENTION; LANGUAGE; WORDS	The effect of labels on nonlinguistic representations is the focus of substantial theoretical debate in the developmental literature. A recent empirical study demonstrated that ten-month-old infants respond differently to objects for which they know a label relative to unlabeled objects. One account of these results is that infants' label representations are incorporated into their object representations, such that when the object is seen without its label, a novelty response is elicited. These data are compatible with two recent theories of integrated label-object representations, one of which assumes labels are features of object representations, and one which assumes labels are represented separately, but become closely associated across learning. Here, we implement both of these accounts in an auto-encoder neurocomputational model. Simulation data support an account in which labels are features of objects, with the same representational status as the objects' visual and haptic characteristics. Then, we use our model to make predictions about the effect of labels on infants' broader category representations. Overall, we show that the generally accepted link between internal representations and looking times may be more complex than previously thought.																	2379-8920	2379-8939				JUN	2020	12	2					160	168		10.1109/TCDS.2018.2882920													
J								Integrating Image-Based and Knowledge-Based Representation Learning	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Visualization; Knowledge representation; Brain modeling; Task analysis; Head; Knowledge based systems; Computational modeling; Attention mechanisms and development; embodied cognition; generation of representation during development		A variety of brain areas is involved in language understanding and generation, accounting for the scope of language that can refer to many real-world matters. In this paper, we investigate how regularities among real-world entities impact emergent language representations. Specifically, we consider knowledge bases, which represent entities and their relations as structured triples, and image representations, which are obtained via deep convolutional networks. We combine these sources of information to learn representations of an image-based knowledge representation learning (IKRL) model. An attention mechanism lets more informative images contribute more to the image-based representations. Evaluation results show that the model outperforms all baselines on the tasks of knowledge graph (KG) completion and triple classification. In analyzing the learned models, we found that the structure-based and image-based representations integrate different aspects of the entities and the attention mechanism provides robustness during learning.																	2379-8920	2379-8939				JUN	2020	12	2					169	178		10.1109/TCDS.2019.2906685													
J								Teach Your Robot Your Language! Trainable Neural Parser for Modeling Human Sentence Processing: Examples for 15 Languages	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Robots; Adaptation models; Task analysis; Semantics; Training; Reservoirs; Dogs; Artificial intelligence; artificial neural networks; cognitive robotics; human-robot interaction; learning systems; machine learning; morphology; natural language processing; neural networks; recurrent neural networks; robot learning; supervised learning	STATE; CONSTRUCTIONS	We present a recurrent neural network (RNN) that performs thematic role assignment and can be used for human-robot interaction (HRI). The RNN is trained to map sentence structures to meanings (e.g., predicates). Previously, we have shown that the model is able to generalize on English and French corpora. In this article, we investigate its ability to adapt to various languages originating from Asia or Europe. We show that it can successfully learn to parse sentences related to home scenarios in 15 languages, namely English, German, French, Spanish, Catalan, Basque, Portuguese, Italian, Bulgarian, Turkish, Persian, Hindi, Marathi, Malay, and Mandarin Chinese. Moreover, in the corpora, we have deliberately included variable complex sentences in order to explore the flexibility of the predicate-like output representations. This demonstrates that: 1) the learning principle of our model is not limited to a particular language (or particular sentence structures), but more generic in nature and 2) it can deal with various kind of representations (not only predicates), which enables users to adapt it to their own needs. As the model is inspired from neuroscience and language acquisition theories, this generic and language-independent aspect makes it a good candidate for modeling human sentence processing. Finally, we discuss the potential implementation of the model in a grounded robotic architecture.																	2379-8920	2379-8939				JUN	2020	12	2					179	188		10.1109/TCDS.2019.2957006													
J								The Subject-Object Asymmetry Revisited: Experimental and Computational Approaches to the Role of Information Structure in Children's Argument Omissions	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Shape; Animals; Computational modeling; Pragmatics; Registers; Aging; Task analysis; Argument omission; computational models of language learning; experimental pragmatics; information structure; language development; model of syntax acquisition in children (MOSAIC); null subjects; object drop; subject-object asymmetry	MARKING; GERMAN; ENGLISH; DUTCH	In two studies, we investigated the relation between information structure and argument omission in German child language in order to quantify to what extent the subject-object hypothesis (i.e., subjects are omitted more often than objects) is influenced by discourse pragmatics. Twenty four children took part in an elicited production study in which they produced transitive subject-verb-object and object-verb-subject sentences. Both constructions are instances of a topic-comment information structure. The results showed that 3;6 year-old children omitted subjects and objects alike when the arguments assumed topics status and were placed in utterance-initial position. In a second study, we then assessed whether a model of language learning implemented with a recency bias (resulting in learning from the end of utterances) would produce similar omission rates of initial arguments. The model was found to be sensitive to the frequency with which both word orders occurred in the input: initial objects were omitted more often than initial subjects, the pattern found in German caregiver speech. The results suggest that argument omission is heavily influenced by information structure and that a subject-object asymmetry per se does not exist.																	2379-8920	2379-8939				JUN	2020	12	2					189	197		10.1109/TCDS.2019.2938924													
J								Social Reinforcement in Artificial Prelinguistic Development: A Study Using Intrinsically Motivated Exploration Architectures	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Robot sensing systems; Haptic interfaces; Natural languages; Biological system modeling; Computer architecture; Space exploration; Intrinsic motivations; prelinguistic social development; sensorimotor exploration; somesthetic senses; vocal development	INFANT VOCALIZATION; ACQUISITION	This paper introduces an intrinsically motivated sensorimotor exploration architecture which considers social reinforcement and motor constraint awareness. The main objective is to study the influence of social interactions during artificial early prelinguistic development. We argue that this architecture contributes to explain development from voiceless to sequence of vowels vocalizations. A cognitive developmental perspective is considered emphasizing embodied cognition and sensorimotor exploratory behaviors. For a new-born agent, motor constraints are unknown. However, the agent is endowed with a somatosensory system that indicates if a motor configuration was reached or not. This information is used to model and predict constraint violations. Furthermore, the architecture considers imitative behaviors that constrain the search space during exploration. Interaction occurs when the learner sensory production is similar to a sensory unit relevant to communication. In that case, the instructor perceives this similitude and reformulates with the relevant sensory unit. When the learner perceives an utterance by the instructor, it attempts to imitate it. Two systems are considered for experimentation: 1) a toy example and 2) a simulated vocal tract. In general, our results suggest that constraint awareness and social reinforcement contribute to achieve less redundant exploration, lower exploration and evaluation errors, and a clearer picture of developmental transitions.																	2379-8920	2379-8939				JUN	2020	12	2					198	208		10.1109/TCDS.2018.2883249													
J								Beyond the Self: Using Grounded Affordances to Interpret and Describe Others' Actions	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Robot sensing systems; Robot kinematics; Cognition; Grasping; Cognitive systems; Probabilistic logic; Affordances; embodied cognition; gestures; humanoid robots; language acquisition through development	DEVELOPMENTAL ROBOTICS; OBJECT AFFORDANCES; COOPERATION; PERCEPTION; IMITATION; LANGUAGE; SYSTEM; BRAIN; MODEL	In this paper, we propose a developmental approach that allows a robot to interpret and describe the actions of human agents by reusing previous experience. The robot first learns the association between words and object affordances by manipulating the objects in its environment. It then uses this information to learn a mapping between its own actions and those performed by a human in a shared environment. It finally fuses the information from these two models to interpret and describe human actions in light of its own experience. In our experiments, we show that the model can be used flexibly to do inference on different aspects of the scene. We can predict the effects of an action on the basis of object properties. We can revise the belief that a certain action occurred, given the observed effects of the human action. In an early action recognition fashion, we can anticipate the effects when the action has only been partially observed. By estimating the probability of words given the evidence and feeding them into a predefined grammar, we can generate relevant descriptions of the scene. We believe that this is a step toward providing robots with the fundamental skills to engage in social collaboration with humans.																	2379-8920	2379-8939				JUN	2020	12	2					209	221		10.1109/TCDS.2018.2882140													
J								When Object Color Is a Red Herring: Extraneous Perceptual Information Hinders Word Learning via Referent Selection	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Color; Shape; Task analysis; Colored noise; Image color analysis; Robots; Glass; Desirable difficulties; extraneous information; modeling; shape bias; word learning	YOUNG-CHILDREN; SLOW; ACQUISITION; INSIGHTS; CONTEXT; MODEL; SHAPE; RETENTION; NOVELTY; ACCOUNT	Learning words from ambiguous naming events is difficult. In such situations, children struggle with not attending to task irrelevant information when learning object names. This paper reduces the problem space of learning names for object categories by holding color constant between the target and other extraneous objects. We examine how this influences two types of word learning (retention and generalization) in both 30-month-old children (Experiment 1) and the iCub humanoid robot (Experiment 2). Overall, all children and iCub performed well on the retention trials, but they were only able to generalize the novel names to new exemplars of the target categories if the objects were originally encountered in sets with objects of the same colors, not if the objects were originally encountered in sets with objects of different colors. These data demonstrate that less information presented during the learning phase narrows the problem space and leads to better word learning success for both children and iCub. Findings are discussed in terms of cognitive load and desirable difficulties.																	2379-8920	2379-8939				JUN	2020	12	2					222	231		10.1109/TCDS.2019.2894507													
J								Adults Use Cross-Situational Statistics for Word Learning in a Conservative Way	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Training; Task analysis; Object recognition; Uncertainty; Gaze tracking; Expectation-maximization algorithms; Psychology; Adults; cross-situational word learning (XSL); expectation-maximization (EM) algorithm; eye tracking; Propose-but-Verify (PbV)	EYE-MOVEMENTS; CONSTRAINTS	This paper examined how much adults rely on cross-situational information in word learning by comparing their gaze behavior in a word learning task with models of four learning strategies. We manipulated the input type of situations (consecutive versus interleaved) and the co-occurrence frequencies between words and objects so that adult learners could infer correct word-object mappings based on cross-situational information. There are two key findings. First, an exposure-by-exposure analysis of gaze behavior during the word learning procedure revealed that most participants collected sufficient cross-situational information before they developed a preference for one particular word-object mapping, with consecutive as well as interleaved situations. Second, a classification approach in which individual gaze behavior was attributed to different word learning strategies showed that participants relied mostly on a conservative cross-situational learning (XSL) strategy, compared to Associative XSL, Propose-but-Verify, and Random strategies. Adults relied on Conservative XSL when presented with consecutive and interleaved situations, but they shifted toward Associative XSL when presented with interleaved situations.																	2379-8920	2379-8939				JUN	2020	12	2					232	242		10.1109/TCDS.2018.2870161													
J								Joint Attention in Hearing Parent-Deaf Child and Hearing Parent-Hearing Child Dyads	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Auditory system; Pediatrics; Cochlear implants; Assistive technology; Face; Gesture recognition; Visualization; Interaction; joint attention; language learning; multimodal cue integration	NEAR-INFRARED SPECTROSCOPY; INDIVIDUAL-DIFFERENCES; LANGUAGE-DEVELOPMENT; GAZE; TODDLERS; MOTHERS	In this paper, we characterize establishment of joint attention in hearing parent-deaf child dyads and hearing parent-hearing child dyads. Deaf children were candidates for cochlear implantation who had not yet been implanted and who had no exposure to formal manual communication (e.g., American Sign Language). Because many parents whose deaf children go through early cochlear implant surgery do not themselves know a visual language, these dyads do not share a formal communication system based in a common sensory modality prior to the child's implantation. Joint attention episodes were identified during free play between hearing parents and their hearing children (N = 4) and hearing parents and their deaf children (N = 4). Attentional episode types included successful parent-initiated joint attention, unsuccessful parent-initiated joint attention, passive attention, successful child-initiated joint attention, and unsuccessful child-initiated joint attention. Group differences emerged in both successful and unsuccessful parent-initiated attempts at joint attention, parent passive attention, and successful child-initiated attempts at joint attention based on proportion of time spent in each. These findings highlight joint attention as an indicator of early communicative efficacy in parent-child interaction for different child populations. We discuss the active role parents and children play in communication, regardless of their hearing status.																	2379-8920	2379-8939				JUN	2020	12	2					243	249		10.1109/TCDS.2018.2877658													
J								Self-Supervised Vision-Based Detection of the Active Speaker as Support for Socially Aware Language Acquisition	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Visualization; Cognitive systems; Acoustics; Face; Detectors; Hidden Markov models; Robots; Active speaker detection and localization; cognitive systems and development; language acquisition through development; transfer learning	ATTENTION	This paper presents a self-supervised method for visual detection of the active speaker in a multiperson spoken interaction scenario. Active speaker detection is a fundamental prerequisite for any artificial cognitive system attempting to acquire language in social settings. The proposed method is intended to complement the acoustic detection of the active speaker, thus improving the system robustness in noisy conditions. The method can detect an arbitrary number of possibly overlapping active speakers based exclusively on visual information about their face. Furthermore, the method does not rely on external annotations, thus complying with cognitive development. Instead, the method uses information from the auditory modality to support learning in the visual domain. This paper reports an extensive evaluation of the proposed method using a large multiperson face-to-face interaction data set. The results show good performance in a speaker dependent setting. However, in a speaker independent setting the proposed method yields a significantly lower performance. We believe that the proposed method represents an essential component of any artificial cognitive system or robotic platform engaging in social interactions.																	2379-8920	2379-8939				JUN	2020	12	2					250	259		10.1109/TCDS.2019.2927941													
J								Multimodal Turn-Taking: Motivations, Methodological Challenges, and Novel Approaches	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Pediatrics; Organizations; Systematics; Buildings; Sensitivity; Timing; Iris; Communication; contingency; interaction formats; turn-taking	LANGUAGE; GAZE; INFANTS; MOTHERS; COMMUNICATION; VOCALIZATIONS; ORGANIZATION; ATTENTION; SPEECH	In this paper, we note that despite being a multimodal phenomenon, turn-taking has still been investigated mostly as being unimodal. Based on theoretical positions emphasizing that communication is organized jointly by interaction partners, we identify the challenge of assessing human sequential behavior: 1) spread across different modalities and 2) co-constructed with a partner. By analyzing a corpus of mother-child dyads with cross recurrence quantification analysis and frequent pattern mining, we offer novel steps toward understanding multimodal turn-taking.																	2379-8920	2379-8939				JUN	2020	12	2					260	271		10.1109/TCDS.2019.2892991													
J								Concrete Action Representation Model: From Neuroscience to Robotics	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Robot kinematics; Robot sensing systems; Task analysis; Neurons; Spinal cord; Generators; Action representation; motor control; neurorobotics; robot learning	CENTRAL PATTERN GENERATOR; MOTOR CORTEX; LOCOMOTOR CONTROL; BASAL GANGLIA; MOVEMENT; MUSCLE; ARM; NEURONS; WALKING; DRIVEN	How can robotics benefit from neuroscience to build a unified framework that computes actions for both locomotion and manipulation tasks? Inspired by the hierarchical neural control of movement from cortex to spinal cord, we propose a model that generates a concrete action representation in robotics. The action program is composed of four basic modules: 1) pattern selection; 2) spatial coordination; 3) temporal coordination; and 4) sensory motor adaptation. The first and the fourth are considered for behavior initiation. The model is implemented on a humanoid robot to generate rhythmic and nonrhythmic movements. The robot is able to perform tasks like perturbation recovery, and drawing based on different motor programs generated by the same model. Unifying motor control in robotics through a hierarchical structure increases the capacity to gain an accurate and deep understanding of transfer of motor skills between different tasks.																	2379-8920	2379-8939				JUN	2020	12	2					272	284		10.1109/TCDS.2019.2896300													
J								Applying a Psychotherapeutic Theory to the Modeling of Affective Intelligent Agents	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Modeling; Mood; Cognition; Regulation; Intelligent agents; Proposals; Adaptation models; Belief-desire-intention (BDI) agents; emotions; human behavior; mood; personality; regulation	INDIVIDUAL-DIFFERENCES; ARCHITECTURE; PERSONALITY	In this paper, we propose the application of a well-known psychotherapeutic model, the Ellis's ABC theory, to the modeling of intelligent agents. The final aim is to be able to simulate human realistic behavior in situations in which varied reactions are possible and are determined by several factors such as personality, affective state, prior experiences, and regulation capabilities. The proposed framework, called ABC-EBDI, is the result of integrating the ABC theory into a BDI framework. Other affective theories have also been taken into account to support the modeling of personality, mood, and affect regulation. The distinguishing feature of the proposed framework is the classification of the agent's cognitive-affective process as either rational or irrational. This process will lead to functional emotions and adaptive conduct, in the first case, and dysfunctional emotions and maladaptive conduct in the second. While the ABC-EBDI framework may be used in different application domains due to its characteristics it can be particularly useful in mental health application. A prototype has been implemented and applied to simulate a bad news scenario. A first evaluation with specialists has been carried out with promising results.																	2379-8920	2379-8939				JUN	2020	12	2					285	299		10.1109/TCDS.2019.2911643													
J								Interactions With Reconfigurable Modular Robots Enhance Spatial Reasoning Performance	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Training; Task analysis; Robots; Cognition; Shape; Electroencephalography; Games; Electroencephalograph (EEG); human-robot interaction; mental rotation; reconfigurable modular robots (RMRobots); spatial ability	MENTAL ROTATION; EEG; ABILITY; GENDER; BAND	Reconfigurable modular robots (RMRobots) can change their shape and functionality (e.g., locomotion styles) to fit different environments, and have been widely investigated in applications, such as exploration and inspection. In this paper, we present a new application of RMRobots for improving human spatial ability which plays a significant role in developing an individual's performance and achievement in science, technology, engineering, and mathematics (STEM). Two user studies are conducted, and the results show that: 1) the task performance of interacting with RMRobots has a significant positive relationship with mental rotation, a widely used measure of spatial ability; and 2) interacting with RMRobots can effectively improve the performance on a task related to spatial reasoning skills according to behavioral data and electroencephalograph (EEG) indices. Our presented study broadens RMRobot research in the area of human-robot interaction.																	2379-8920	2379-8939				JUN	2020	12	2					300	310		10.1109/TCDS.2019.2914162													
J								Facial Expression Recognition via Deep Action Units Graph Network Based on Psychological Mechanism	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Psychology; Feature extraction; Gold; Face recognition; Task analysis; Correlation; Face; Action units (AUs); deep graph-based network; facial expression recognition (FER); facial graph representation; psychological mechanism	FACE	Facial expression recognition (FER) is currently a very attractive research field in cognitive psychology and artificial intelligence. In this paper, an innovative FER algorithm called deep action units graph network (DAUGN) is proposed based on psychological mechanism. First, a segmentation method is designed to divide the face into small key areas, which are then converted into corresponding AU-related facial expression regions. Second, the local appearance features of these critical regions are extracted for further action units (AUs) analysis. Then, an AUs facial graph is constructed to represent expressions by taking the AU-related regions as vertices and the distances between each two landmarks as edges. Finally, the adjacency matrices of facial graph are put into a graph-based convolutional neural network to combine the local-appearance and global-geometry information, which greatly improving the performance of FER. Experiments and comparisons on CK+, MMI, and SFEW data sets reveal that the DAUGN achieves more competitive results than several other popular approaches.																	2379-8920	2379-8939				JUN	2020	12	2					311	322		10.1109/TCDS.2019.2917711													
J								Regression-Based Continuous Driving Fatigue Estimation: Toward Practical Implementation	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Fatigue; Electroencephalography; Estimation; Electrodes; Feature extraction; Brain modeling; Support vector machines; Driving fatigue estimation; dry electrode; dynamic time warping (DTW); electroencephalography (EEG); regression; wireless transmission	DRIVER FATIGUE; MENTAL FATIGUE; TIME-SERIES; EEG; ALGORITHM; SYSTEM	Mental fatigue in drivers is one of the leading causes that give rise to traffic accidents. Electroencephalography (EEG)-based driving fatigue studies showed promising performance in fatigue monitoring. However, complex methodologies are not suitable for practical implementation. In our simulation-based setup that retained the constraints of real driving, we took a step closer to fatigue estimation in a practical scenario. We adopted a preprocessing pipeline with low computational complexity, which can be easily and practically implemented in real time. Moreover, regression-based continuous fatigue estimation was achieved using power spectral features in conjunction with time as the fatigue label. We sought to compare three regression models and three time windows to demonstrate their effects on the performance of fatigue estimation. Dynamic time warping was proposed as a new measure for evaluating the performance of fatigue estimation. The results derived from the validation of the proposed framework on 19 subjects showed that our proposed framework was promising toward practical implementation. Fatigue estimation by the support vector regression with radial basis function kernel and 5-s window length achieved the best performance. We also provided a comprehensive analysis on the spatial distribution of channels and frequency bands mostly contributing to fatigue estimation, which can inform the feature and channel reduction for real-time fatigue monitoring in practical driving. After reducing the number of electrodes by 75%, the proposed framework retained comparable performance in fatigue estimation. This paper demonstrates the feasibility and adaptability of our proposed framework in practical implementation of mental fatigue estimation.																	2379-8920	2379-8939				JUN	2020	12	2					323	331		10.1109/TCDS.2019.2929858													
J								Perceptual Modeling of Tinnitus Pitch and Loudness	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Biological system modeling; Computational modeling; Data models; Auditory system; Phantoms; Adaptation models; Mathematical model; Linear mixed effects (LMEs) model; perceptual model; tinnitus; tinnitus loudness; tinnitus pitch	DORSAL COCHLEAR NUCLEUS; NOISE-INDUCED HYPERACTIVITY; HIDDEN HEARING-LOSS; INTENSE SOUND; COMPUTATIONAL MODEL; LATERAL INHIBITION; NERVE-FIBERS; PLASTICITY; EXPOSURE; MECHANISMS	Tinnitus is the phantom perception of sound, experienced by 10%-15% of the global population. Computational models have been used to investigate the mechanisms underlying the generation of tinnitus-related activity. However, existing computational models have rarely benchmarked the modeled perception of a phantom sound against recorded data relating to a person's perception of tinnitus characteristics, such as pitch or loudness. This article details the development of two perceptual models of tinnitus. The models are validated using empirical data from people with tinnitus and the models' performance is compared with the existing perceptual models of tinnitus pitch. The first model extends existing perceptual models of tinnitus, while the second model utilizes an entirely novel approach to modeling tinnitus perception using a linear mixed effects (LMEs) model. The LME model is also used to model the perceived loudness of the phantom sound which has not been considered in previous models. The LME model creates an accurate model of tinnitus pitch and loudness and shows that both tinnitus-related activity and individual perception of sound are factors in the perception of the phantom sound that characterizes tinnitus.																	2379-8920	2379-8939				JUN	2020	12	2					332	343		10.1109/TCDS.2020.2964841													
J								Domain Adaptation for EEG Emotion Recognition Based on Latent Representation Similarity	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Electroencephalography; Brain modeling; Emotion recognition; Adaptation models; Training; Feature extraction; Neural networks; Domain adaptation; electroencephalogram (EEG); emotion recognition; neural network; transfer learning	DIFFERENTIAL ENTROPY FEATURE; DEPRESSION; BRAIN	Emotion recognition has many potential applications in the real world. Among the many emotion recognition methods, electroencephalogram (EEG) shows advantage in reliability and accuracy. However, the individual differences of EEG limit the generalization of emotion classifiers across subjects. Moreover, due to the nonstationary characteristic of EEG, the signals of one subject change over time, which is a challenge to acquire models that could work across sessions. In this article, we propose a novel domain adaptation method to generalize the emotion recognition models across subjects and sessions. We use neural networks to implement the emotion recognition models, which are optimized by minimizing the classification error on the source while making the source and the target similar in their latent representations. Considering the functional differences of the network layers, we use adversarial training to adapt the marginal distributions in the early layers and perform association reinforcement to adapt the conditional distributions in the last layers. In this way, we approximately adapt the joint distributions by simultaneously adapting marginal distributions and conditional distributions. The method is compared with multiple representatives and recent domain adaptation algorithms on benchmark SEED and DEAP for recognizing three and four affective states, respectively. The experimental results show that the proposed method reaches and outperforms the state of the arts.																	2379-8920	2379-8939				JUN	2020	12	2					344	353		10.1109/TCDS.2019.2949306													
J								Intraindividual Completion Time Modulates the Prediction Error Negativity in a Virtual 3-D Object Selection Task	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Task analysis; Visualization; Electroencephalography; Australia; Three-dimensional displays; Computer science; Artificial intelligence; Cognitive conflict; completion time; electroencephalogram (EEG); error-related positive potential (Pe); prediction error negativity (PEN); virtual reality (VR)	ERP COMPONENTS; POTENTIALS; FEEDBACK	A prediction error negativity (PEN) can be observed in the human electroencephalogram when there is a mismatch between the predicted and the perceived changes in the environment. Our previous study using a virtual object selection task demonstrated an impact of the level of avatar realism on the PEN, reflecting a mismatch between visual and proprioceptive feedback about the object selection. To investigate the role of temporal integration of different sensory information on the PEN, this article investigated the impact of task completion times on the PEN amplitude, using the same virtual object selection task. Trials from each participant were divided into slow trials and fast trials based on the task completion time, and their associated PEN amplitudes were separately aggregated and analyzed. The result shows that PEN amplitudes are significantly more pronounced in slow trials than in fast trials. This finding suggests that task completion times modulate the PEN amplitude-a long task completion time allowed for a better integration of information from both visual and proprioceptive systems as the basis to detect a mismatch between the expected hand trajectory during a reaching motion and the perceived visual feedback in the virtual environment.																	2379-8920	2379-8939				JUN	2020	12	2					354	360		10.1109/TCDS.2020.2991301													
J								A Concealed Information Test System Based on Functional Brain Connectivity and Signal Entropy of Audio-Visual ERP	IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS										Electroencephalography; Entropy; Complexity theory; Biological neural networks; Brain-computer interfaces; Pattern recognition; Brain-computer interface (BCI); concealed information test (CIT); event-related potential (ERP); functional connectivity; quantum neural networks (QNNs)	GUILTY KNOWLEDGE; LIE DETECTION; EEG SIGNALS; NEURAL-NETWORKS; CLASSIFICATION; RESPONSES; P300	Deception is a human behavior and its cognitive process and mechanism involve complex neuronal activities of the brain. In this article, we develop a simple and feasible concealed information test (CIT) method which is based on the audio-visual event-related potentials (ERPs) and its spatial and temporal features. The main purpose of this article is to extend a pattern recognition method with functional network parameters and global feature entropy of the EEG signals from the whole brain. At the same time, a novel quantum neural network (QNN) classifier was developed to distinguish the guilty and innocent conditions. Functional connectivity can provide extra information of interdependence between different brain regions from the spatial dimension, and entropy can reflect the complexity of the whole brain from the temporal dimension. 20 subjects participated in the CIT experiment and 30 channel ERPs were recorded. A high accuracy of 87.67% was got in recognizing the concealed information, which was higher than 85.43% for basic features, demonstrated the effectiveness of this article. Future studies should further clarify the connectivity difference and further improve the accuracy of the QNN classifier for CIT.																	2379-8920	2379-8939				JUN	2020	12	2					361	370		10.1109/TCDS.2020.2991359													
J								Offline Data-Driven Multiobjective Optimization: Knowledge Transfer Between Surrogates and Generation of Final Solutions	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Knowledge transfer; Task analysis; Data models; Sociology; Statistics; Evolutionary computation; Knowledge transfer; multiobjective evolutionary algorithms (MOEAs); multisurrogate; offline data-driven optimization	EVOLUTIONARY OPTIMIZATION; BUILDING-BLOCKS; ALGORITHM; MODEL; APPROXIMATION	In offline data-driven optimization, only historical data is available for optimization, making it impossible to validate the obtained solutions during the optimization. To address these difficulties, this paper proposes an evolutionary algorithm assisted by two surrogates, one coarse model and one fine model. The coarse surrogate (CS) aims to guide the algorithm to quickly find a promising subregion in the search space, whereas the fine one focuses on leveraging good solutions according to the knowledge transferred from the CS. Since the obtained Pareto optimal solutions have not been validated using the real fitness function, a technique for generating the final optimal solutions is suggested. All achieved solutions during the whole optimization process are grouped into a number of clusters according to a set of reference vectors. Then, the solutions in each cluster are averaged and outputted as the final solution of that cluster. The proposed algorithm is compared with its three variants and two state-of-the-art offline data-driven multiobjective algorithms on eight benchmark problems to demonstrate its effectiveness. Finally, the proposed algorithm is successfully applied to an operational indices optimization problem in beneficiation processes.																	1089-778X	1941-0026				JUN	2020	24	3					409	423		10.1109/TEVC.2019.2925959													
J								Multisource Selective Transfer Framework in Multiobjective Optimization Problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Task analysis; Satellites; Search problems; Acceleration; Sociology; Statistics; Estimation of distribution algorithm (EDA); multiobjective optimization; multisource transfer; transfer optimization; Wasserstein distance (WD)	DISTRIBUTION ALGORITHM; EVOLUTIONARY ALGORITHMS; LAYOUT OPTIMIZATION; PREDICTION; HYBRID; CLASSIFICATION; SEARCH	For complex system design [e.g., satellite layout optimization design (SLOD)] in practical engineering, when launching a new optimization instance with another parameter configuration from the intuition of designers, it is always executed from scratch which wastes much time to repeat the similar search process. Inspired by transfer learning which can reuse past experiences to solve relevant tasks, many researchers pay more attention to explore how to learn from past optimization instances to accelerate the target one. In real-world applications, there have been numerous similar source instances stored in the database. The primary question is how to measure the transferability from numerous sources to avoid the notorious negative transferring. To obtain the relatedness between source and target instance, we develop an optimization instance representation method named centroid distribution, which is by the aid of the probabilistic model learned by elite candidate solutions in estimation of distribution algorithm (EDA) during the evolutionary process. Wasserstein distance is employed to evaluate the similarity between the centroid distributions of different optimization instances, based on which, we present a novel framework called multisource selective transfer optimization with three strategies to select sources reasonably. To choose the suitable strategy, four selection suggestions are summarized according to the similarity between the source and target centroid distribution. The framework is beneficial to choose the most suitable sources, which could improve the search efficiency in solving multiobjective optimization problems. To evaluate the effectiveness of the proposed framework and selection suggestions, we conduct two experiments: 1) comprehensive empirical studies on complex multiobjective optimization problem benchmarks and 2) a real-world SLOD problem. Suggestions for strategy selection coincide with the experiment results, based on which, we propose a mixed strategy to deal with the negative transfer in the experiments successfully. The results demonstrate that our proposed framework achieves competitive performance on most of the benchmark problems in convergence speed and hypervolume values and performs best on the real-world applications among all the comparison algorithms.																	1089-778X	1941-0026				JUN	2020	24	3					424	438		10.1109/TEVC.2019.2926107													
J								Adapting Reference Vectors and Scalarizing Functions by Growing Neural Gas to Handle Irregular Pareto Fronts	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Evolutionary computation; Sociology; Shape; Search problems; Pareto optimization; Decomposition-based multiobjective evolutionary optimization; growing neural gas (GNG); irregular Pareto front	NONDOMINATED SORTING APPROACH; OPTIMIZATION ALGORITHM; BOUNDARY INTERSECTION; LOCAL SEARCH; MOEA/D; SELECTION; SURFACE	The performance of decomposition-based multiobjective evolutionary algorithms (MOEAs) often deteriorates clearly when solving multiobjective optimization problems with irregular Pareto fronts (PFs). The main reason is the improper settings of reference vectors and scalarizing functions. In this paper, we propose a decomposition-based MOEA guided by a growing neural gas network, which learns the topological structure of the PF. Both reference vectors and scalarizing functions are adapted based on the topological structure to enhance the evolutionary algorithm's search ability. The proposed algorithm is compared with eight state-of-the-art optimizers on 34 test problems. The experimental results demonstrate that the proposed method is competitive in handling irregular PFs.																	1089-778X	1941-0026				JUN	2020	24	3					439	453		10.1109/TEVC.2019.2926151													
J								Feature Extraction and Selection for Parsimonious Classifiers With Multiobjective Genetic Programming	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Classification; ensemble; feature extraction (FE); feature selection (FS); multiobjective genetic programming (MOGP)	FITNESS FUNCTIONS; CLASSIFICATION; EVOLUTIONARY; PREDICTION; DISCOVERY; CANCER; RULES; TESTS	The objectives of this paper are to investigate the capability of genetic programming to select and extract linearly separable features when the evolutionary process is guided to achieve the same and to propose an integrated system for that. We decompose a c-class problem into c binary classification problems and evolve c sets of binary classifiers employing a steady-state multiobjective genetic programming with three minimizing objectives. Each binary classifier is composed of a binary tree and a linear support vector machine (SVM). The features extracted by the feature nodes and some of the function nodes of the tree are used to train the SVM. The decision made by the SVM is considered the decision of the corresponding classifier. During crossover and mutation, the SVM-weights are used to determine the usefulness of the corresponding nodes. We also use a fitness function based on Golub's index to select useful features. To discard less frequently used features, we employ unfitness functions for the feature nodes. We compare our method with 34 classification systems using 18 datasets. The performance of the proposed method is found to be better than 432 out of 570, i.e., 75.79% of comparing cases. Our results confirm that the proposed method is capable of achieving our objectives.																	1089-778X	1941-0026				JUN	2020	24	3					454	466		10.1109/TEVC.2019.2927526													
J								Data Structures for Direct Spanning Tree Representations in Mutation-Based Evolutionary Algorithms	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Dynamic tree data structures; evolutionary algorithms (EAs); tree representations		Optimization methods for spanning tree problems may require efficient data structures. The node-depth-degree representation (NDDR) has achieved relevant results for direct spanning tree representation together with evolutionary algorithms (EAs). Its two mutation operators have average time O(root n), where n is the number of vertices of the graph, while similar operators implemented by predecessor arrays, a typical tree data structure, have time O(n). Dynamic trees are also relevant when investigating tree representations since they have low time complexity, but there is no proper extension of them for EAs. Using aspects of both a dynamic tree and NDDR, namely, Euler tours and structural sharing, we propose a data structure called 2LETT, whose mutation operators have time O(root n) in the worst case. Experiments with the mutation operators using 2LETT, predecessor arrays, and NDDR are carried out for graphs with up to 300 000 vertices. For a mutation operator that exchanges any two valid edges, predecessor arrays present the best performance for random trees with fewer than 10 000 vertices; while 2LETT has the best performance for trees with more than 10 000 vertices. Especially, noteworthy is the fact that 2LETT is the only structure whose running time is independent of tree diameter.																	1089-778X	1941-0026				JUN	2020	24	3					467	478		10.1109/TEVC.2019.2928991													
J								An Estimation of Distribution Algorithm for Mixed-Variable Newsvendor Problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Estimation of distribution algorithm (EDA); histogram model; mixed-variable optimization problem; newsvendor problem; orthogonal experiment design	MULTIPRODUCT NEWSBOY PROBLEM; PARTICLE SWARM OPTIMIZATION; CONSTRAINED OPTIMIZATION; DISCOUNT; DEMAND	As one of the classical problems in the economic market, the newsvendor problem aims to make maximal profit by determining the optimal order quantity of products. However, the previous newsvendor models assume that the selling price of a product is a predefined constant and only regard the order quantity as a decision variable, which may result in an unreasonable investment decision. In this article, a new newsvendor model is first proposed, which involves of both order quantity and selling price as decision variables. In this way, the newsvendor problem is reformulated as a mixed-variable nonlinear programming problem, rather than an integer linear programming problem as in previous investigations. In order to solve the mixed-variable newsvendor problem, a histogram model-based estimation of distribution algorithm (EDA) called EDA(mvn) is developed, in which an adaptive-width histogram model is used to deal with the continuous variables and a learning-based histogram model is applied to deal with the discrete variables. The performance of EDA(mvn) was assessed on a test suite with eight representative instances generated by the orthogonal experiment design method and a real-world instance generated from real market data of Alibaba. The experimental results show that, EDA(mvn) outperforms not only the state-of-the-art mixed-variable evolutionary algorithms, but also a commercial software, i.e., Lingo.																	1089-778X	1941-0026				JUN	2020	24	3					479	493		10.1109/TEVC.2019.2932624													
J								Evolutionary Multiobjective Optimization With Robustness Enhancement	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Uncertainty; Robustness; Evolutionary computation; Perturbation methods; Aircraft; Safety; Evolutionary algorithms (EAs); multiobjective optimization; robust optimization; uncertainty	ALGORITHM; FRAMEWORK; DESIGN	Uncertainty is an important feature abstracted from real-world applications. Multiobjective optimization problems (MOPs) with uncertainty can always be characterized as robust MOPs (RMOPs). Over recent years, multiobjective optimization evolutionary algorithms (EAs) have demonstrated the success in solving MOPs. However, most of them do not consider disturbance in the design. In order to handling the uncertainty in the optimization problem, we first give a thorough analysis of three important issues on robust optimization. Then, a novel EA called multiobjective optimization EA with robustness enhancement is developed, where the seamless integration of robustness and optimality is achieved by a proposed novel archive updating mechanism applied on the evolutionary process as well as the new robust optimal front building strategy designed to construct the final robust optimal front. Furthermore, the new designed archive updating mechanism makes the robust optimization process free of the enormous computational workload induced from sampling. The experimental results on a set of benchmark functions show the superiority of the proposed design in terms of both solutions' quality under the disturbance and computational efficiency in solving RMOPs.																	1089-778X	1941-0026				JUN	2020	24	3					494	507		10.1109/TEVC.2019.2933444													
J								A Niching Memetic Algorithm for Multi-Solution Traveling Salesman Problem	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Urban areas; Optimization; Sociology; Statistics; Geometry; Traveling salesman problems; Memetics; Memetic algorithm; multimodal optimization (MMOP); multi-solution traveling salesman problem (MSTSP); neighborhood niching strategy	ANT COLONY OPTIMIZATION; FINDING MULTIPLE SOLUTIONS; MULTIMODAL OPTIMIZATION; DECOMPOSITION; EVOLUTION; STRATEGY	Multi-solution problems extensively exist in practice. Particularly, the traveling salesman problem (TSP) may possess multiple shortest tours, from which travelers can choose one according to their specific requirements. However, very few efforts have been devoted to the multi-solution problems in the discrete domain. In order to fill this research gap and to effectively tackle the multi-solution TSP, we propose a niching memetic algorithm in this article. The proposed algorithm is characterized by a niche preservation technique to enable the parallel search of multiple optimal solutions; an adaptive neighborhood strategy to balance the exploration and exploitation; a critical edge-aware method to provide effective guidance to the reproduction; and a selective local search strategy to improve the search efficiency. To evaluate the performance of the proposed algorithm, we conduct comprehensive experiments on a recently published multi-solution optimization test suite. The experimental results show that our algorithm outperforms other compared algorithms. Furthermore, the proposed algorithm is adopted to tackle problems from the well-known TSPLIB library to obtain a set of distinct but good solutions.																	1089-778X	1941-0026				JUN	2020	24	3					508	522		10.1109/TEVC.2019.2936440													
J								Evolutionary Network Embedding Preserving Both Local Proximity and Community Structure	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Linear programming; Optimization; Evolutionary computation; Complex networks; Clustering algorithms; Search problems; Prediction algorithms; Community structure; dimension reduction; evolutionary algorithm; link prediction; network embedding; node classification; node clustering	MULTIOBJECTIVE GENETIC ALGORITHM; MODULARITY	The complex network is an important tool to represent relational data in nature and human society, which has been widely applied in various real-world application scenarios. A key issue for analyzing the features of networks is to represent the characteristic information in the network with rationality. Network embedding, attracting plenty of attention recently, aims to convert network information into a low-dimensional space while maintaining the structure and properties of the network maximally. Most of the existing network embedding methods intend to preserve the pairwise relationship or similarity between nodes, but the community structure, which is one of the most important features of complex networks, is largely ignored. In this article, we propose a novel network embedding method based on evolutionary algorithm (EA), termed as EA-NECommunity, which can preserve both the local proximity of nodes and the community structure of the network by optimizing a carefully designed objective function. The number of communities in the network can be automatically determined without any prior knowledge. Moreover, taking the intrinsic properties of the network embedding problems in mind, we design a local search operator based on multidirectional search which can effectively find feasible solutions. In the experiments, we first visualize the embedding representation obtained by different algorithms, and then use the problems of node clustering, node classification, and link prediction to further validate the quality of the embedding representation obtained. The experimental results show that EA-NECommunity outperforms other state-of-the-art algorithms on both the real life and synthetic networks.																	1089-778X	1941-0026				JUN	2020	24	3					523	535		10.1109/TEVC.2019.2937455													
J								Underestimation-Assisted Global-Local Cooperative Differential Evolution and the Application to Protein Structure Prediction	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Linear programming; Sociology; Statistics; Proteins; Optimization; Convergence; Space exploration; Cooperation; differential evolution (DE); evolutionary algorithm (EA); protein structure prediction (PSP); underestimation	CUTTING ANGLE METHOD; SURROGATE MODEL; ALGORITHM; OPTIMIZATION; PARAMETERS; ENSEMBLE; NEIGHBORHOOD; EXPLORATION	Various mutation strategies show distinct advantages in differential evolution (DE). The cooperation of multiple strategies in the evolutionary process may be effective. This article presents an underestimation-assisted global and local cooperative DE to simultaneously enhance the effectiveness and efficiency. In the proposed algorithm, two phases, namely, the global exploration and the local exploitation, are performed in each generation. In the global phase, a set of trial vectors is produced for each target individual by employing multiple strategies with strong exploration capability. Afterward, an adaptive underestimation model with an self-adapted slope control parameter is proposed to evaluate these trial vectors, the best of which is selected as the candidate. In the local phase, the better-based strategies guided by individuals that are better than the target individual are designed. For each individual accepted in the global phase, multiple trial vectors are generated by using these strategies and filtered by the underestimation value. The cooperation between the global and local phases includes two aspects. First, both of them concentrate on generating better individuals for the next generation. Second, the global phase aims to locate promising regions quickly while the local phase serves as a local search for enhancing convergence. Moreover, a simple mechanism is designed to determine the parameter of DE adaptively in the searching process. Finally, the proposed approach is applied to predict the protein 3-D structure. The experimental studies on classical benchmark functions, CEC test sets, and protein structure prediction problem show that the proposed approach is superior to the competitors.																	1089-778X	1941-0026				JUN	2020	24	3					536	550		10.1109/TEVC.2019.2938531													
J								Handling Imbalance Between Convergence and Diversity in the Decision Space in Evolutionary Multimodal Multiobjective Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Pareto optimization; Convergence; Benchmark testing; Minimization; Evolutionary computation; Computer science; Convergence; decision space diversity; density estimation; evolutionary multimodal multiobjective optimization (EMMO); test problems	ALGORITHM; DECOMPOSITION; BEHAVIOR; EMOA; SET	There may exist more than one Pareto optimal solution with the same objective vector to a multimodal multiobjective optimization problem (MMOP). The difficulties in finding such solutions can be different. Although a number of evolutionary multimodal multiobjective algorithms (EMMAs) have been proposed, they are unable to solve such an MMOP due to their convergence-first selection criteria. They quickly converge to the Pareto optimal solutions which are easy to find and therefore lose diversity in the decision space. That is, such an MMOP features an imbalance between achieving convergence and preserving diversity in the decision space. In this article, we first present a set of imbalanced distance minimization benchmark problems. Then we propose an evolutionary algorithm using a convergence-penalized density method (CPDEA). In CPDEA, the distances among solutions in the decision space are transformed based on their local convergence quality. Their density values are estimated based on the transformed distances and used as the selection criterion. We compare CPDEA with five state-of-the-art EMMAs on the proposed benchmarks. Our experimental results show that CPDEA is clearly superior in solving these problems.																	1089-778X	1941-0026				JUN	2020	24	3					551	565		10.1109/TEVC.2019.2938557													
J								A Divide-and-Conquer Evolutionary Algorithm for Large-Scale Virtual Network Embedding	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Evolutionary computation; Substrates; Heuristic algorithms; Classification algorithms; Search problems; Bandwidth; Graph matching; large-scale optimization; metaheuristics; virtual network embedding (VNE)	COOPERATIVE COEVOLUTION; NODE; DECOMPOSITION	The subgraph isomorphism problems, which aim to map subgraphs to a given graph, are widely seen in many applications and are usually nondeterministic polynomial-time complete (NP-complete). As a representative extension of the subgraph isomorphism problem, virtual network embedding (VNE) is a key problem in datacenter scheduling and network virtualization. Existing metaheuristic approaches to VNE problems tend to schedule networks as a whole. But when the problem scale grows, the performance of these approaches may degenerate due to the curse of dimensionality. In this article, we intend to propose a divide-and-conquer evolutionary algorithm with overlapping decomposition (ODEA) to solve large-scale VNE problems. First, realizing the fact that the decision variables in graph-based optimization problems like VNE are usually nonseparable, an overlapping decomposition method is introduced by investigating the characteristic of the network structure. In this method, the critical elements which have tight connections to many other nodes can belong to multiple subcomponents. As a result, the decision variables with tight connections can always be evolved together in multiple subcomponents. Second, to combine the subsolutions into a complete feasible solution, a competitive strategy is devised. Through the competition among critical elements, the optimizing information is shared among subcomponents, which can further improve the effectiveness of ODEA. The proposed ODEA can adopt different metaheuristics as the optimizer, and we conduct experiments on both the scenarios with a single virtual network and with a series of online networks. The experimental results verify that ODEA can significantly improve the performance of different metaheuristics in large-scale VNE problems.																	1089-778X	1941-0026				JUN	2020	24	3					566	580		10.1109/TEVC.2019.2941824													
J								Runtime Analysis of Crowding Mechanisms for Multimodal Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Crowding methods; generalized crowding; probabilistic crowding; runtime analysis; theory	DRIFT ANALYSIS; MUTATION	Many real-world optimization problems lead to multimodal domains and require the identification of multiple optima. Crowding methods have been developed to maintain population diversity, to investigate many peaks in parallel and to reduce genetic drift. We present the first rigorous runtime analyses of probabilistic crowding and generalized crowding, embedded in a (mu+1) EA. In probabilistic crowding the offspring compete with their parent in a fitness-proportional selection. Generalized crowding decreases the fitness of the inferior solution by a scaling factor during selection. We consider the bimodal function TwoMax and introduce a novel and natural notion for functions with bounded gradients. For a broad range of such functions we prove that probabilistic crowding needs exponential time with overwhelming probability to find solutions significantly closer to any global optimum than those found by random search. Even when the fitness function is scaled exponentially, probabilistic crowding still fails badly. Only if the exponential's base is linear in the problem size, probabilistic crowding becomes efficient on TwoMax. A similar threshold behavior holds for generalized crowding on TwoMax with respect to the scaling factor. Our theoretical results are accompanied by experiments for TwoMax showing that the threshold behaviors also apply to the best fitness found.																	1089-778X	1941-0026				JUN	2020	24	3					581	592		10.1109/TEVC.2019.2914606													
J								Analysis of the (mu/mu(I), lambda)-sigma-Self-Adaptation Evolution Strategy With Repair by Projection Applied to a Conically Constrained Problem	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Conically constrained problem; evolution strategies (ESs); intermediate recombination; repair by projection		A theoretical performance analysis of the (mu/mu(I), lambda)-sigma-self-adaptation evolution strategy (sigma SA-ES) is presented considering a conically constrained problem. Infeasible offspring are repaired using projection onto the boundary of the feasibility region. Closed-form approximations are used for the one-generation progress of the evolution strategy. Approximate deterministic evolution equations are formulated for analyzing the strategy's dynamics. By iterating the evolution equations with the approximate one-generation expressions, the evolution strategy's dynamics can be predicted. The derived theoretical results are compared to experiments for assessing the approximation quality. It is shown that in the steady state the (mu/mu(I), lambda)-sigma SA-ES exhibits a performance as if the ES were optimizing a sphere model. Unlike the nonrecombinative (1, lambda)-ES, the parental steady state behavior does not evolve on the cone boundary but stays away from the boundary to a certain extent.																	1089-778X	1941-0026				JUN	2020	24	3					593	602		10.1109/TEVC.2019.2930316													
J								Understanding Hypervolume Behavior Theoretically for Benchmarking in Evolutionary Multi/Many-Objective Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Benchmark testing; Optimization; Shape; Measurement; Evolutionary computation; Face; Decision making; Benchmarking; hypervolume (HV); many-objective optimization; multiobjective optimization	SELECTION; INDICATOR; ALGORITHM	Hypervolume (HV) is one of the most commonly used metrics for evaluating the Pareto front (PF) approximations generated by multiobjective evolutionary algorithms. Even so, HV is a resultant of a complex interplay between the PF shape, number of objectives, and user-specified reference points which, if not well understood, may lead to misinformed inferences about benchmarking performance. In order to understand this behavior, some previous studies have investigated such interactions empirically. In this letter, a new and unconventional approach is taken for gaining further insights about HV behavior. The key idea is to develop theoretical formulas for certain linear (equilateral simplex) and quadratic (orthant) PFs in two specific orientations: 1) regular and 2) inverted. These PFs represent a large number of problems in the existing DTLZ and WFG suites commonly used for benchmarking. The numerical experiments are presented to demonstrate the utility of the proposed work in benchmarking, and in understanding the contributions of the different regions of the PFs, such as corners, edges, as well explaining the contrast between the HV behaviors for regular versus inverted PFs. This letter provides a foundation and computationally fast means to undertake parametric studies to understand various aspects of HV.																	1089-778X	1941-0026				JUN	2020	24	3					603	610		10.1109/TEVC.2019.2931191													
J								Semisupervised Approach to Surrogate-Assisted Multiobjective Kernel Intuitionistic Fuzzy Clustering Algorithm for Color Image Segmentation	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Clustering algorithms; Linear programming; Image segmentation; Kernel; Color; Evolutionary computation; Computational modeling; Color image segmentation; intuitionistic fuzzy clustering; kernel metric; kriging model; multiobjective optimization; semisupervised mechanism; surrogate-assisted evolutionary algorithm	EVOLUTIONARY ALGORITHMS; OPTIMIZATION	Multiobjective evolutionary algorithms (MOEAs) are effective optimization methods. To improve the segmentation performance and time efficiency of MOEAs-based fuzzy clustering algorithms for color images, a semisupervised surrogate-assisted multiobjective kernel intuitionistic fuzzy clustering ((SMKIFC)-M-3) algorithm is proposed in this article. The main contributions of (SMKIFC)-M-3 can be summarized as follows: 1) semisupervised kernel intuitionistic fuzzy objective functions are constructed for optimization to search satisfactory segmentation results; 2) to reduce the computational cost, the Kriging model is used to predict the values of objective functions instead of directly calculating the expensive objective functions; 3) a semisupervised selection strategy and a semisupervised model management mechanism are proposed to balance the convergence and diversity and improve the predicted accuracy of the Kriging model, respectively; and 4) a novel semisupervised kernel intuitionistic fuzzy cluster validity index is defined to select the optimal solution from the final nondominated solution set. Experimental results on two color image libraries demonstrate that (SMKIFC)-M-3 outperforms state-of-the-art methods in segmentation performance and meanwhile possesses a low time cost.																	1063-6706	1941-0034				JUN	2020	28	6					1023	1034		10.1109/TFUZZ.2020.2973121													
J								A Preference-Based Evolutionary Biobjective Approach for Learning Large-Scale Fuzzy Cognitive Maps: An Application to Gene Regulatory Network Reconstruction	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Optimization; Evolutionary computation; Fuzzy cognitive maps; Heuristic algorithms; Measurement uncertainty; Image reconstruction; Genetic algorithms; Fuzzy cognitive maps (FCMs); multiobjective optimization; knee area; evolutionary algorithm; gene regulatory network reconstruction	TIME-SERIES; MEMETIC ALGORITHM; PREDICTION; OPTIMIZATION; HYBRID; KNEES	Learning large-scale fuzzy cognitive maps (FCMs) with the sparse attribute automatically from time series without prior knowledge remains a challenging problem. Most existing automated learning methods were applied to learn small-scale FCMs, and the learned FCMs are much denser than the maps constructed by human experts. Learning FCMs is the procedure of judging whether there are connecting edges and determining the weights of connecting edges. Thus, we transform the problem of learning FCMs into a biobjective optimization problem with two objects of minimizing the measure error and the number of nonzero entries, respectively. To solve this optimization problem, a preference-based iterative thresholding evolutionary biobjective optimization algorithm for learning FCMs is proposed. The strategy focuses on the knee area of the Pareto front (PF) with preference on the solutions near the true sparsity. Moreover, an initialization operator based on random forest is proposed to increase the speed of convergence toward the PF. The experiments on large-scale synthetic data with varying sizes and densities and the application to the gene regulatory network reconstruction problem have been conducted to demonstrate that our proposal matches or exceeds the existing state-of-the-art FCM learning approaches in most cases in terms of four measures, namely, Data_Error, Out_of_Sample_Error, Model Error, and SS_Mean. The Data_Error obtained by the proposed method can achieve 3.07E-06 even when the number of nodes reaches 200. We also demonstrate the effectiveness of the proposed initialization operator and the preference-based strategy, which can result in a fast convergence speed and higher accuracy.																	1063-6706	1941-0034				JUN	2020	28	6					1035	1049		10.1109/TFUZZ.2020.2975482													
J								Multitasking Genetic Algorithm (MTGA) for Fuzzy System Optimization	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Task analysis; Biological cells; Optimization; Sociology; Statistics; Evolutionary computation; Genetic algorithms; Evolutionary multitasking; fuzzy logic controller (FLC); genetic algorithm; multifactorial optimization (MFO); multitask learning	EVOLUTIONARY MULTITASKING	Multitask learning uses auxiliary data or knowledge from relevant tasks to facilitate the learning in a new task. Multitask optimization applies multitask learning an optimization to study how effectively and efficiently tackle the multiple optimization problems, simultaneously. Evolutionary multitasking, or multifactorial optimization, is an emerging subfield of multitask optimization, which integrates evolutionary computation and multitask learning. This article proposes a novel and easy-to-implement multitasking genetic algorithm (MTGA), which copes well with significantly different optimization tasks by estimating and using the bias among them. Comparative studies with eight state-of-the-art single-task and multitask approaches in the literature on nine benchmarks demonstrated that, on average, the MTGA outperformed all of them and had lower computational cost than six of them. Based on the MTGA, a simultaneous optimization strategy for fuzzy system design is also proposed. Experiments on simultaneous optimization of type-1 and interval type-2 fuzzy logic controllers for couple-tank water level control demonstrated that the MTGA can find better fuzzy logic controllers than other approaches.																	1063-6706	1941-0034				JUN	2020	28	6					1050	1061		10.1109/TFUZZ.2020.2968863													
J								An Optimized Type-2 Self-Organizing Fuzzy Logic Controller Applied in Anesthesia for Propofol Dosing to Regulate BIS	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Anesthesia; Brain modeling; Fuzzy sets; Fuzzy logic; Optimization; Surgery; Computational modeling; Anesthesia; genetic programming (GP); optimization; surrogate model (SM); type-2 fuzzy controller	CLOSED-LOOP; SYSTEMS; MODEL; SETS; ALGORITHM	During general anesthesia, anesthesiologists who provide anesthetic dosage traditionally play a fundamental role to regulate bispectral index (BIS). However, in this article, an optimized type-2 self-organizing fuzzy logic controller (SOFLC) is designed for a target controlled infusion pump related to propofol dosing guided by BIS, to realize automatic control of general anesthesia. The type-2 SOFLC combines a type-2 fuzzy logic controller with a self-organizing mechanism to facilitate online training while able to contend with operational uncertainties. A novel data-driven surrogate model and genetic programming-based strategy is introduced for optimizing the type-2 SOFLC parameters offline to handle interpatient variability. A pharmacological model is built for simulation in which different optimization strategies are tested and compared. Simulation results are presented to demonstrate the applicability of our approach and show that the proposed optimization strategy can achieve better control performance in terms of steady-state error and robustness.																	1063-6706	1941-0034				JUN	2020	28	6					1062	1072		10.1109/TFUZZ.2020.2969384													
J								Intelligent Approach to the Prediction of Changes in Biometric Attributes	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Heuristic algorithms; Frequency selective surfaces; Sociology; Statistics; Fuzzy sets; Prediction algorithms; Feature extraction; Aging in biometrics; biometrics; dynamic signature; nature-inspired methods; population-based algorithms (PBAs)	GENETIC ALGORITHMS; SIGNATURE; OPTIMIZATION; MATCHERS	Artificial intelligence methods are used in many fields of applications. One of them is biometrics. It deals with a broadly understood analysis of physical and behavioral biometric characteristics. Behavioral characteristics are particularly important from a practical point of view. They describe, among others, learned behaviors of human beings. They include the ways of signing, lip movement, gait, etc. Such features are difficult to forge, so their use in biometric systems increases security. The dynamics of signing is particularly important because it is considered socially acceptable worldwide. However, the problem associated with its processing results from its possible instability over time, as the signature is likely to evolve. In a situation where the method of signing is only partially altered (and not completely changed), the trend in possible changes can be predicted. In this article, we propose a new approach to predicting such changes. For this purpose, we use the possibilities offered by fuzzy systems (FSs) and population-based algorithms (PBAs). The purpose of applying the PBA is to select parameters and the structure of the FSs and to select reference signatures for each user separately so as to maximize prediction accuracy. Prediction results are included in the final verification of signatures. An important feature of the prediction mechanism is also its ability to interpret the changes occurring in signature handwriting because they are represented by the fuzzy rules base. This type of a flexible and nature-inspired prediction mechanism would be very difficult to implement with the use of other methods. The developed mechanisms can be used in various fields of applications-also in those not related to biometrics.																	1063-6706	1941-0034				JUN	2020	28	6					1073	1083		10.1109/TFUZZ.2019.2955043													
J								Regression-Based Neuro-Fuzzy Network Trained by ABC Algorithm for High-Density Impulse Noise Elimination	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Noise measurement; Microsoft Windows; Noise reduction; Fuzzy neural networks; Artificial bee colony algorithm; Decision trees; Image edge detection; Artificial bee colony (ABC); decision tree (DT); impulse noise; neuro-fuzzy (NF) network	ARTIFICIAL BEE COLONY; SWITCHING MEDIAN FILTER; PEPPER NOISE; MEAN FILTER; IMAGES; REDUCTION; REMOVAL; SALT; OPTIMIZATION; OPERATORS	Salt and pepper (SAP) noise elimination is a crucial step for further image processing and pattern recognition applications. The main aim of this article is to propose a novel SAP noise elimination method which employs a regression-based neuro-fuzzy network for highly corrupted gray scale and color images. In the proposed method, multiple neuro-fuzzy filters trained with artificial bee colony algorithm is combined with a decision tree algorithm. The performance of the proposed filter is compared with a number of well known methods with respect to popular metrics including, structural similarity index, peak signal-to-noise ratio, and correlation on well known test images. The results reveal that the proposed filter has superior performance in terms of all comparison metrics.																	1063-6706	1941-0034				JUN	2020	28	6					1084	1095		10.1109/TFUZZ.2020.2973123													
J								A New Type of Fuzzy-Rule-Based System With Chaotic Swarm Intelligence for Multiclassification of Pain Perception From fMRI	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Pain; Functional magnetic resonance imaging; Optimization; Decoding; Convergence; Feature extraction; Fuzzy logic; Crow search optimization (CSO); functional magnetic resonance imaging (fMRI) decoding; fuzzy rules; pain prediction; self-organizing fuzzy logic prototype (SOFLP)	OPTIMIZATION ALGORITHM; C-MEANS; IDENTIFICATION; INFERENCE; MODEL	Machine learning has been increasingly used in decoding brain states from functional magnetic resonance imaging (fMRI). One important application is to classify the levels of pain perception from patients' fMRI for clinical pain assessment. However, the huge number of fMRI features and the complex relationships between fMRI and pain levels affect the performance of pain classification models heavily. In this article, we introduce a new fuzzy-rule-based hybrid optimization approach for dimension reduction and multiclassification problems using chaotic map, crow search optimization (CSO), and self-organizing fuzzy logic prototype (SOFLP). The approach is named as CCSO-SOFLP. In the proposed approach, chaotic map-based CSO is employed to find the optimal features from ultra-high-dimensional fMRI, and the fuzzy-rule-based SOFLP is employed for multiclassification of pain levels. In this sense, CSO is provided to avoid being stuck in local minima and to increase the computational performance. On the other hand, multilayer SOFLP classifier can continuously learn from new data and identify prototypes from the observed data and use them to build fuzzy rules, to define a suitable local area for each prototype, and to avoid overlapping. The proposed approach is applied on a pain-evoked fMRI data set to classify the levels of pain. Results indicate that the proposed approach can decode levels of pain and identify predictive fMRI patterns with higher accuracy and convergence speed and shorter execution time. Therefore, the new type of fuzzy-rule-based system with chaotic swarm intelligence holds great potential to predict pain perception in clinical uses.																	1063-6706	1941-0034				JUN	2020	28	6					1096	1109		10.1109/TFUZZ.2020.2979150													
J								Optimizing a Neuro-Fuzzy System Based on Nature-Inspired Emperor Penguins Colony Optimization Algorithm	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Optimization; Inference algorithms; Fuzzy systems; Mathematical model; Heating systems; Spirals; Sociology; Adaptive neuro-fuzzy inference system (ANFIS); emperor penguins colony (EPC) algorithm; fuzzy inference system (FIS); nature inspired; neuro-fuzzy system; optimization; Sugeno-type fuzzy	PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION; NETWORK; DESIGN; ANFIS	A neuro-fuzzy system is a learning machine that finds the parameters of a fuzzy system using approximate techniques of neural networks. Both neural network and fuzzy system have common features. These can solve problems that have no mathematical models. Adaptive neuro-fuzzy inference system (ANFIS) is an adaptive network that uses supervised learning on learning algorithm. To achieve effective results with ANFIS, selecting the optimization method in training is very important. Heuristics and metaheuristics algorithms attempt to find the best solution out of all possible solutions to an optimization problem. ANFIS training can be based on nonderivative algorithms. Heuristics and metaheuristics are nonderivative algorithms that can lead to better performance in ANFIS training. Most heuristic and metaheuristic algorithms are taken from the behavior of biological systems or physical systems in nature. The newly released emperor penguins colony (EPC) algorithm is a population-based and nature-inspired metaheuristic algorithm. This algorithm has much potential for solving various problems. In this article, an optimized ANFIS based on the new EPC algorithm is proposed. The optimized ANFIS is compared with other nonderivative algorithms on benchmark data sets. Eventually, the proposed algorithm is used to solve the classical inverted pendulum problem. The results show that the proposed ANFIS based on the EPC algorithm has less error and better performance than other state-of-the-art algorithms in both training and testing phase.																	1063-6706	1941-0034				JUN	2020	28	6					1110	1124		10.1109/TFUZZ.2020.2984201													
J								Multipopulation Nature-Inspired Algorithm (MNIA) for the Designing of Interpretable Fuzzy Systems	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Fuzzy system (FS); interpretability; nature-inspired algorithm (NIA); population-based algorithm (PBA); trapezoid-shaped fuzzy set	LINGUISTIC TERM SETS; BEE COLONY ALGORITHM; DIFFERENTIAL EVOLUTION; CLASSIFICATION SYSTEMS; OPTIMIZATION ALGORITHM; GLOBAL OPTIMIZATION; GENETIC ALGORITHM; FIREFLY ALGORITHM; PID CONTROLLER; SELECTION	The solutions proposed in this article are based on our experience with fuzzy systems (FSs), their interpretability, and population-based algorithms (PBAs). They provide a consistent approach to the design of interpretable FSs. First, PBAs can make a useful tool for selecting both parameters and the FS structure. In practice, such structure is usually chosen by trial and error. Second, in this article, we propose a new multipopulation PBA, which uses a variety of search formulas. This helps to eliminate the problem of incorrect PBA selection. Third, we propose interesting solutions for the interpretability of FSs with trapezoidal membership functions. These functions are well suited for modeling ranges of linguistic variables. We are particularly interested in providing them with original interpretability criteria, which are used by a PBA to design FSs. Furthermore, we offer an original way of setting up trapezoidal functions, which prevents them from overlapping with each other. Fourth, we believe that interpretability can be achieved through a capable extension of fuzzy rules. That is the reason why we used weights and dedicated operators for their processing. In this article, a different extension of the rules base is proposed. It involves adding relation operators (ROs) (e.g., ">" and ">="), which can be used to model linguistic phrases, e.g. "electrical voltage less than or equal to high." An additional task of the PBA is the automatic selection of an RO, which facilitates the extraction of knowledge from the data. The approach proposed in this article was tested using well-known classification benchmarks.																	1063-6706	1941-0034				JUN	2020	28	6					1125	1139		10.1109/TFUZZ.2019.2959997													
J								A New Hybrid Particle Swarm Optimization and Genetic Algorithm Method Controlled by Fuzzy Logic	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Genetic algorithms; Sociology; Statistics; Particle swarm optimization; Optimization; Genetics; Heuristic algorithms; Fuzzy systems; genetic algorithm (GA); hybrid methods; multimodal functions; particle swarm optimization (PSO)	GLOBAL OPTIMIZATION; PERFORMANCE; SEARCH; GA	The performance of the well-known particle swarm optimization (PSO) method can be improved by minimizing the possibility of premature convergence in a local minimum. We can achieve this by modifying some of the particles with crossover and mutation operators used in genetic algorithms. However, the impact of genetic operators on the optimization process should depend on the current state of the PSO algorithm. In this article, we propose to use the neuro-fuzzy system to dynamically determine the strength with which these operators will affect the process of finding the optimal solution. Results obtained for well-known benchmark functions demonstrate the advance of the proposed method over the original PSO algorithm and its selected modifications.																	1063-6706	1941-0034				JUN	2020	28	6					1140	1154		10.1109/TFUZZ.2019.2957263													
J								A Hybrid Intelligent Approach to Integrated Fuzzy Multiple Depot Capacitated Green Vehicle Routing Problem With Split Delivery and Vehicle Selection	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Computational modeling; Genetic algorithms; Fuels; Sustainable development; Mathematical model; Decision making; Vehicle routing; Fuzzy hierarchical technique for order preference by similarity to ideal solution (TOPSIS); fuzzy simulation; genetic algorithm; vehicle routing; vehicle selection	DECISION-MAKING; EXPECTED VALUE; MODEL; TOPSIS	Vehicle routing, being a major concern of any industry with transportation requirements (manufacturing, supply-chain, travel and tourism, etc.), offers immense scope for research. Due consideration of this fact has motivated the development of the approach illustrated hereafter. In this article, a vehicle routing problem (VRP) with generalized fuzzy travel times, multiple depots, split delivery (including inter depot split), and heterogenous, capacitated, alternative fuel driven vehicles, is studied. A hybrid genetic algorithm (GA) is designed to produce efficient solutions. Since traditional methods are incapable of computing the expected values of such fuzzy variables, the technique of fuzzy simulation is incorporated in the GA. Five alternative fuel vehicles-electric, hybrid, diesel, biodiesel, and CNG, are evaluated vis-a-vis multiple criteria using fuzzy hierarchical technique for order preference by similarity to ideal solution (TOPSIS) and their respective scores are input in the hybrid GA for sustainable, apt, and low-cost assignment of vehicles to routes. The algorithm is run for multiple combinations of crossover and mutation probabilities, vehicle capacities, location instances, and number of generations. The experimental results substantiate the robustness of the proposed approach and suffice to project the strength of the computationally challenging model.																	1063-6706	1941-0034				JUN	2020	28	6					1155	1166		10.1109/TFUZZ.2019.2946110													
J								Water Cycle Algorithm Tuned Fuzzy Expert System for Trusted Routing in Smart Grid Communication Network	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Routing; Smart grids; Communication networks; Bayes methods; Expert systems; Data communication; Security; Bayesian theory; Dempster-Shafer theory; fuzzy theory; smart grid communication network; trust management; water cycle algorithm	RULE-BASED SYSTEMS; MANAGEMENT; OPTIMIZATION; SCHEME	Finding an optimal route for reliable data delivery in the smart grid communication network (SGCN) is a challenging task due to its dynamic nature. Even though the rule set (RS) and membership function (MF) framed intuitively in our previous fuzzy logic (FL) approach performs the trusted routing satisfactorily, it consumes computational memory and reduces the energy efficiency of the node. To address this issue, in this article, we proposed a novel trust evaluation framework that employs water cycle algorithm (WCA) for automatic tuning of the rule set and membership function for the decision variable to route the packet in an adaptable manner. Variables like distance, link stability, and node honesty are considered for evaluation using WCA in three iterative processes, namely, exploitation, evaporation, and raining to find the near optimal if-then rules and points for the membership functions. An experimental setup is created using Network Simulator-2 (NS2) to evaluate the performance of the proposed trusted routing algorithm in SGCN. Extensive experiments are conducted for three cases, namely, 1) evaluating RS with fixed MF; 2) evaluating MF with fixed RS; and 3) combined evaluation of MF and RS to evaluate the performance of the proposed model. From the simulation results, it is clear that the RS and MF generated by the proposed model is small and compact enough to provide reliable routing in SGCN.																	1063-6706	1941-0034				JUN	2020	28	6					1167	1177		10.1109/TFUZZ.2020.2968833													
J								Small Lung Nodules Detection Based on Fuzzy-Logic and Probabilistic Neural Network With Bioinspired Reinforcement Learning	IEEE TRANSACTIONS ON FUZZY SYSTEMS										Lung; X-ray imaging; Neural networks; Fuzzy sets; Cancer; Probabilistic logic; Fuzzy systems; Automatic pathology recognition; biomedical image processing; chest X-ray screening fuzzy-logic; probabilistic neural network	COMPUTER-AIDED DETECTION; PULMONARY NODULES; CT IMAGES; CLASSIFICATION; FEATURES; TEXTURE; SHAPE; COMBINATION; MACHINE	Internal organs, like lungs, are very often examined by the use of screening methods. For this purpose, we present an evaluation model based on a composition of fuzzy system combined with a neural network. The input image is evaluated by means of custom rules, which use type-1 fuzzy membership functions. The results are forwarded to a neural network for final evaluation. Our model was validated by using X-ray images with lung nodules. The results show the high performances of our approach with sensitivity and specificity reaching almost 95% and 90%, respectively, with an accuracy of 92.56%. The new methodology lowers the computational demands considerably and increases detection performances.																	1063-6706	1941-0034				JUN	2020	28	6					1178	1189		10.1109/TFUZZ.2019.2952831													
J								A Taxonomy for Neural Memory Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Random access memory; Task analysis; Neural networks; Mathematical model; Markov processes; Taxonomy; Network architecture; Long short-term memory (LSTM); neural RAM; neural stack; recurrent neural network (RNN)	SIMPLE RECURRENT NETWORKS; CONTEXT-FREE; LANGUAGES	An increasing number of neural memory networks have been developed, leading to the need for a systematic approach to analyze and compare their underlying memory structures. Thus, in this paper, we first create a framework for memory organization and then compare four popular dynamic models: vanilla recurrent neural network, long short-term memory, neural stack, and neural RAM. This analysis helps to open the dynamic neural networks' black box from the memory usage prospective. Accordingly, a taxonomy for these networks and their variants is proposed and proved using a unifying architecture. With the taxonomy, both network architectures and learning tasks are classified into four classes, and a one-to-one mapping is built between them to help practitioners select the appropriate architecture. To exemplify each task type, four synthetic tasks with different memory requirements are selected. Moreover, we use some signal processing applications and two natural language processing applications to evaluate the methodology in a realistic setting.																	2162-237X	2162-2388				JUN	2020	31	6					1780	1793		10.1109/TNNLS.2019.2926466													
J								Lightweight Pyramid Networks for Image Deraining	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Rain; Laplace equations; Feature extraction; Learning systems; Task analysis; Knowledge engineering; Computer vision; Deep convolutional neural network (CNN); image pyramid; lightweight networks; rain removal; residual learning	QUALITY ASSESSMENT; RAIN; CLASSIFICATION	Existing deep convolutional neural networks (CNNs) have found major success in image deraining, but at the expense of an enormous number of parameters. This limits their potential applications, e.g., in mobile devices. In this paper, we propose a lightweight pyramid networt (LPNet) for single-image deraining. Instead of designing a complex network structure, we use domain-specific knowledge to simplify the learning process. In particular, we find that by introducing the mature Gaussian-Laplacian image pyramid decomposition technology to the neural network, the learning problem at each pyramid level is greatly simplified and can be handled by a relatively shallow network with few parameters. We adopt recursive and residual network structures to build the proposed LPNet, which has less than 8K parameters while still achieving the state-of-the-art performance on rain removal. We also discuss the potential value of LPNet for other low- and high-level vision tasks.																	2162-237X	2162-2388				JUN	2020	31	6					1794	1807		10.1109/TNNLS.2019.2926481													
J								Design of State-Dependent Switching Laws for Stability of Switched Stochastic Neural Networks With Time-Delays	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Lyapunov-Krasovskii functional; Lyapunov-Razumikhin technique; switched stochastic neural networks (SSNNs); state-dependent switching (SDS); time-delays	EXPONENTIAL STABILITY; NONLINEAR-SYSTEMS; FINITE-TIME; STABILIZATION; SYNCHRONIZATION; DISCRETE	We study the stability properties of switched stochastic neural networks (SSNNs) with time-varying delays whose subsystem is not necessarily stable. We introduce state-dependent switching (SDS) as a tool for stability analysis. Some SDS laws for asymptotic stability and pth moment exponentially stable are designed by employing Lyapunov-Krasovskii (L-K) functional and Lyapunov-Razumikhin (L-R) method, respectively. It is shown that the stability of SSNNs with time-varying delays composed of unstable subsystems can be achieved by using SDS law. The control gains in the designed SDS laws can be derived by solving the LMIs in derived stability criteria. Two numerical examples are provided to demonstrate the effectiveness of the proposed SDS laws.																	2162-237X	2162-2388				JUN	2020	31	6					1808	1819		10.1109/TNNLS.2019.2927161													
J								Approximate Policy-Based Accelerated Deep Reinforcement Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Approximation algorithms; Task analysis; Training; Acceleration; Convergence; Reinforcement learning; Graphics processing units; Approximate policy; deep reinforcement learning (DRL); learning efficiency; value function estimate		In recent years, the deep reinforcement learning (DRL) algorithms have been developed rapidly and have achieved excellent performance in many challenging tasks. However, due to the complexity of network structure and a large amount of network parameters, the training of deep network is time-consuming, and consequently, the learning efficiency of DRL is limited. In this paper, aiming to speed up the learning process of DRL agent, we propose a novel approximate policy-based accelerated (APA) algorithm from the viewpoint of the error analysis of approximate policy iteration reinforcement learning algorithms. The proposed APA is proven to be convergent even with a more aggressive learning rate, making the DRL agent have a faster learning speed. Furthermore, to combine the accelerated algorithm with deep Q-network (DQN), Double DQN and deep deterministic policy gradient (DDPG), we proposed three novel DRL algorithms: APA-DQN, APA-Double DQN, and APA-DDPG, which demonstrates the adaptability of the accelerated algorithm with DRL algorithms. We have tested the proposed algorithms on both discrete-action and continuous-action tasks. Their superior performance demonstrates their great potential in the practical applications.																	2162-237X	2162-2388				JUN	2020	31	6					1820	1830		10.1109/TNNLS.2019.2927227													
J								Graphical Nash Equilibria and Replicator Dynamics on Complex Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Games; Nash equilibrium; Multi-agent systems; Silicon; Complex networks; Sociology; Statistics; Games on networks; graphical replicator dynamics; Nash equilibrium; pairwise-interaction graphical games	EVOLUTIONARY DYNAMICS; GAME DYNAMICS; COORDINATION; COOPERATION; STRATEGY; SYSTEMS	Pairwise-interaction graphical games have been widely used in the study and design of strategic interaction in multiagent systems. With regard to this issue, one entitative problem is actually to understand how the interaction structure of agents affects the strategy configuration of Nash equilibria. This paper intends to study the effect of interaction networks on Nash equilibria in pairwise-interaction graphical games. We first show that interaction networks may induce new strategy equilibria in pairwise-interaction graphical games and then provide graphical conditions for the existence of these network-induced equilibria. Furthermore, to determine Nash equilibria of pairwise-interaction graphical games, a graphical replicator dynamics model is formulated, and its connection with graphical games is established. In detail, it is shown that every Nash equilibrium of the graphical games corresponds to a fixed point of the graphical replicator dynamics and that every asymptotically stable fixed point of the graphical replicator dynamics corresponds to a strict pure Nash equilibrium of the graphical games. The obtained results are applied in understanding coordination in complex networks and determination of structural conflicts in signed graphs. This work may provide new insights into understanding and designing strategy equilibria and dynamics in games on networks.																	2162-237X	2162-2388				JUN	2020	31	6					1831	1842		10.1109/TNNLS.2019.2927233													
J								Deep Spiking Neural Network for Video-Based Disguise Face Recognition Based on Dynamic Facial Movements	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Face recognition; Learning systems; Computational modeling; Brain modeling; Facial muscles; Continuous learning; deep learning; event-driven spike-timing-dependent plasticity (STDP); spiking neural network (SNN); video-based disguise face recognition (VDFR)	OBJECT RECOGNITION; VISION SYSTEMS; FEATURES; CATEGORIZATION; COINCIDENCE; INTEGRATE; NEURONS; STDP	With the increasing popularity of social media and smart devices, the face as one of the key biometrics becomes vital for person identification. Among those face recognition algorithms, video-based face recognition methods could make use of both temporal and spatial information just as humans do to achieve better classification performance. However, they cannot identify individuals when certain key facial areas, such as eyes or nose, are disguised by heavy makeup or rubber/digital masks. To this end, we propose a novel deep spiking neural network architecture in this paper. It takes dynamic facial movements, the facial muscle changes induced by speaking or other activities, as the sole input. An event-driven continuous spike-timing-dependent plasticity learning rule with adaptive thresholding is applied to train the synaptic weights. The experiments on our proposed video-based disguise face database (MakeFace DB) demonstrate that the proposed learning method performs very well, i.e., it achieves from 95% to 100% correct classification rates under various realistic experimental scenarios.																	2162-237X	2162-2388				JUN	2020	31	6					1843	1855		10.1109/TNNLS.2019.2927274													
J								Change Detection in Graph Streams by Learning Graph Embeddings on Constant-Curvature Manifolds	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Manifolds; Geometry; Extraterrestrial measurements; Topology; Monitoring; Data models; Adversarial learning; change detection test (CDT); constant-curvature manifold; graph stream; seizure prediction	NETWORKS	The space of graphs is often characterized by a nontrivial geometry, which complicates learning and inference in practical applications. A common approach is to use embedding techniques to represent graphs as points in a conventional Euclidean space, but non-Euclidean spaces have often been shown to be better suited for embedding graphs. Among these, constant-curvature Riemannian manifolds (CCMs) offer embedding spaces suitable for studying the statistical properties of a graph distribution, as they provide ways to easily compute metric geodesic distances. In this paper, we focus on the problem of detecting changes in stationarity in a stream of attributed graphs. To this end, we introduce a novel change detection framework based on neural networks and CCMs, which takes into account the non-Euclidean nature of graphs. Our contribution in this paper is twofold. First, via a novel approach based on adversarial learning, we compute graph embeddings by training an autoencoder to represent graphs on CCMs. Second, we introduce two novel change detection tests operating on CCMs. We perform experiments on synthetic data, as well as two real-world application scenarios: the detection of epileptic seizures using functional connectivity brain networks and the detection of hostility between two subjects, using human skeletal graphs. Results show that the proposed methods are able to detect even small changes in a graph-generating process, consistently outperforming approaches based on Euclidean embeddings.																	2162-237X	2162-2388				JUN	2020	31	6					1856	1869		10.1109/TNNLS.2019.2927301													
J								Incremental Reinforcement Learning in Continuous Spaces via Policy Relaxation and Importance Weighting	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Task analysis; Learning systems; Heuristic algorithms; Function approximation; Robots; Navigation; Neural networks; Continuous spaces; dynamic environments; importance weighting; incremental reinforcement learning (RL); policy relaxation		In this paper, a systematic incremental learning method is presented for reinforcement learning in continuous spaces where the learning environment is dynamic. The goal is to adjust the previously learned policy in the original environment to a new one incrementally whenever the environment changes. To improve the adaptability to the ever-changing environment, we propose a two-step solution incorporated with the incremental learning procedure: policy relaxation and importance weighting. First, the behavior policy is relaxed to a random one in the initial learning episodes to encourage a proper exploration in the new environment. It alleviates the conflict between the new information and the existing knowledge for a better adaptation in the long term. Second, it is observed that episodes receiving higher returns are more in line with the new environment, and hence contain more new information. During parameter updating, we assign higher importance weights to the learning episodes that contain more new information, thus encouraging the previous optimal policy to be faster adapted to a new one that fits in the new environment. Empirical studies on continuous controlling tasks with varying configurations verify that the proposed method achieves a significantly faster adaptation to various dynamic environments than the baselines.																	2162-237X	2162-2388				JUN	2020	31	6					1870	1883		10.1109/TNNLS.2019.2927320													
J								Generative Memory for Lifelong Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Catastrophic forgetting; generative memory (GM); lifelong learning; neural network	NEURAL-NETWORKS; SYSTEMS; SLEEP	Lifelong learning is a crucial issue in advanced artificial intelligence. It requires the learning system to learn and accumulate knowledge from sequential tasks. The learning system needs to deal with increasingly more domains and tasks. We consider that the key to an effective and efficient lifelong learning system is the ability to memorize and recall the learned knowledge using neural networks. Following this idea, we propose Generative Memory (GM) as a novel memory module, and the resulting lifelong learning system is referred to as the GM Net (GMNet). To make the GMNet feasible, we propose a novel learning mechanism, referred to as P-invariant learning method. It replaces the memory of the real data by a memory of the data distribution, which makes it possible for the learning system to accurately and continuously accumulate the learned experiences. We demonstrate that GMNet achieves the state-of-the-art performance on lifelong learning tasks.																	2162-237X	2162-2388				JUN	2020	31	6					1884	1898		10.1109/TNNLS.2019.2927369													
J								A Maximally Split and Relaxed ADMM for Regularized Extreme Learning Machines	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convex functions; Convergence; Training; Acceleration; Standards; Approximation algorithms; Complexity theory; Alternating direction method of multipliers (ADMM); computational complexity; convergence rate; extreme learning machine (ELM); parallel algorithm	ALTERNATING DIRECTION METHOD; DIRECT EXTENSION; CONVERGENCE; OPTIMIZATION; MULTIPLIERS; REGRESSION; ALGORITHM	One of the salient features of the extreme learning machine (ELM) is its fast learning speed. However, in a big data environment, the ELM still suffers from an overly heavy computational load due to the high dimensionality and the large amount of data. Using the alternating direction method of multipliers (ADMM), a convex model fitting problem can be split into a set of concurrently executable subproblems, each with just a subset of model coefficients. By maximally splitting across the coefficients and incorporating a novel relaxation technique, a maximally split and relaxed ADMM (MS-RADMM), along with a scalarwise implementation, is developed for the regularized ELM (RELM). The convergence conditions and the convergence rate of the MS-RADMM are established, which exhibits linear convergence with a smaller convergence ratio than the unrelaxed maximally split ADMM. The optimal parameter values of the MS-RADMM are obtained and a fast parameter selection scheme is provided. Experiments on ten benchmark classification data sets are conducted, the results of which demonstrate the fast convergence and parallelism of the MS-RADMM. Complexity comparisons with the matrix-inversion-based method in terms of the numbers of multiplication and addition operations, the computation time and the number of memory cells are provided for performance evaluation of the MS-RADMM.																	2162-237X	2162-2388				JUN	2020	31	6					1899	1913		10.1109/TNNLS.2019.2927385													
J								Multistability of Almost Periodic Solution for Memristive Cohen-Grossberg Neural Networks With Mixed Delays	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Almost periodic solution; memristive Cohen-Grossberg neural networks (MCGNNs); mixed delays; multistability	GLOBAL EXPONENTIAL STABILITY; ACTIVATION FUNCTIONS; MULTIPLE EQUILIBRIA; DYNAMICAL BEHAVIORS; GENERAL-CLASS; MULTIPERIODICITY; MEMORY	This paper presents the multistability analysis of almost periodic state solutions for memristive Cohen-Grossberg neural networks (MCGNNs) with both distributed delay and discrete delay. The activation function of the considered MCGNNs is generalized to be nonmonotonic and nonpiecewise linear. It is shown that the MCGNNs with n-neuron have ( K + 1)(n) locally exponentially stable almost periodic solutions, where nature number K depends on the geometrical structure of the considered activation function. Compared with the previous related works, the number of almost periodic state solutions of the MCGNNs is extensively increased. The obtained conclusions in this paper are also capable of studying the multistability of equilibrium points or periodic solutions of the MCGNNs. Moreover, the enlarged attraction basins of attractors are estimated based on original partition. Some comparisons and convincing numerical examples are provided to substantiate the superiority and efficiency of obtained results.																	2162-237X	2162-2388				JUN	2020	31	6					1914	1926		10.1109/TNNLS.2019.2927506													
J								Adaptive Neural Quantized Control for a Class of MIMO Switched Nonlinear Systems With Asymmetric Actuator Dead-Zone	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Switches; MIMO communication; Nonlinear systems; Adaptive systems; Switched systems; Backstepping; Adaptive quantized control; asymmetric actuator dead-zone; backstepping; multiple-input-multiple-output (MIMO); switched nonlinear systems	DYNAMIC SURFACE CONTROL; FEEDBACK TRACKING CONTROL; BACKSTEPPING DESIGN; STABILIZATION; STATE; STABILITY; NETWORKS	This paper concentrates on the adaptive state-feedback quantized control problem for a class of multiple-input-multiple-output (MIMO) switched nonlinear systems with unknown asymmetric actuator dead-zone. In this study, we employ different quantizers for different subsystem inputs. The main challenge of this study is to deal with the coupling between the quantizers and the dead-zone nonlinearities. To solve this problem, a novel approximation model for the coupling between quantizer and dead-zone is proposed. Then, the corresponding robust adaptive law is designed to eliminate this nonlinear term asymptotically. A direct neural control scheme is employed to reduce the number of adaptive laws significantly. The backstepping-based adaptive control scheme is also presented to guarantee the system performance. Finally, two simulation examples are presented to show the effectiveness of our control scheme.																	2162-237X	2162-2388				JUN	2020	31	6					1927	1941		10.1109/TNNLS.2019.2927507													
J								Optimal Power Management Based on Q-Learning and Neuro-Dynamic Programming for Plug-in Hybrid Electric Vehicles	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Batteries; Optimization; Power system management; Fuels; Mathematical model; Artificial neural networks; Machine learning algorithms; Energy optimization; model-free learning; plug-in hybrid electric vehicles (PHEVs); power management; Q-learning; reinforcement learning (RL)	ENERGY MANAGEMENT	Energy optimization for plug-in hybrid electric vehicles (PHEVs) is a challenging problem due to the system complexity and many physical and operational constraints in PHEVs. In this paper, we present a Q-learning-based in-vehicle learning system that is free of physical models and can robustly converge to an optimal energy control solution. The proposed machine learning algorithms combine neuro-dynamic programming (NDP) with future trip information to effectively estimate the expected future energy cost (expected cost-to-go) for a given vehicle state and control actions. The convergences of these learning algorithms were demonstrated on both fixed and randomly selected drive cycles. Based on the characteristics of these learning algorithms, we propose a two-stage deployment solution for PHEV power management applications. Furthermore, we introduce a new initialization strategy, which combines the optimal learning with a properly selected penalty function. This initialization scheme can reduce the learning convergence time by 70%, which is a significant improvement for in-vehicle implementation efficiency. Finally, we develop a neural network (NN) for predicting battery state-of-charge (SoC), rendering the proposed power management controller completely free of physical models.																	2162-237X	2162-2388				JUN	2020	31	6					1942	1954		10.1109/TNNLS.2019.2927531													
J								Variance-Constrained Recursive State Estimation for Time-Varying Complex Networks With Quantized Measurements and Uncertain Inner Coupling	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Couplings; Complex networks; Quantization (signal); State estimation; Measurement uncertainty; Estimation error; Boundedness analysis; optimal state estimation; signal quantization; time-varying stochastic complex networks; uncertain inner coupling; variance-constrained approach	DYNAMICAL NETWORKS; EXPONENTIAL SYNCHRONIZATION; MISSING MEASUREMENTS; NONLINEAR-SYSTEMS; JOINT STATE; DESIGN; INFORMATION; SUBJECT; DELAYS	In this paper, a new recursive state estimation problem is discussed for a class of discrete time-varying stochastic complex networks with uncertain inner coupling and signal quantization under the error-variance constraints. The coupling strengths are allowed to be varying within certain intervals, and the measurement signals are subject to the quantization effects before being transmitted to the remote estimator. The focus of the conducted topic is on the design of a variance-constrained state estimation algorithm with the aim to ensure a locally minimized upper bound on the estimation error covariance at every sampling instant. Furthermore, the boundedness of the resulting estimation error is analyzed, and a sufficient criterion is established to ensure the desired exponential boundedness of the state estimation error in the mean square sense. Finally, some simulations are proposed with comparisons to illustrate the validity of the newly developed variance-constrained estimation method.																	2162-237X	2162-2388				JUN	2020	31	6					1955	1967		10.1109/TNNLS.2019.2927554													
J								Event-Based Adaptive Neural Tracking Control for Discrete-Time Stochastic Nonlinear Systems: A Triggering Threshold Compensation Strategy	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptive systems; Artificial neural networks; Actuators; Stochastic processes; Nonlinear dynamical systems; Adaptive neural control; discrete-time strict-feedback systems; event-based control; stochastic noise; triggering threshold compensation	DYNAMIC SURFACE CONTROL; NETWORK CONTROL; DESIGN; SCHEME	This paper investigates the event-triggered (ET) tracking control problem for a class of discrete-time strict-feedback nonlinear systems subject to both stochastic noises and limited controller-to-actuator communication capacities. The ET mechanism with fixed triggering threshold is designed to decide whether the current control signal should be transmitted to the actuator. A systematic framework is developed to construct a novel adaptive neural controller by directly applying the backstepping procedure to the underlying system. The proposed framework overcomes the noncausality problem, avoids the possible controller-related singularity problem, and gets rid of the neural approximation of the virtual control laws. Under the ET mechanism, the corresponding ET-based actuator is put forward by introducing an ET threshold compensation operator. Such a compensation operator (with an adjustable design parameter) is subtly designed based on a hyperbolic tangent function and a sign function. The threshold compensation error is analytically characterized in terms of a time-varying parameter, and the error bound is shown to be relatively small that is dependent on the adjustable design parameter. Compared with the traditional ET-based actuator without the compensation operator, the proposed ET-based actuator exhibits several distinguished features including: 1) improvement of the tracking accuracy (especially at the triggering instants); 2) further mitigation of the communication load; and 3) enlargement of the allowable range of the ET threshold. These features are illustrated by numerical and practical examples.																	2162-237X	2162-2388				JUN	2020	31	6					1968	1981		10.1109/TNNLS.2019.2927595													
J								Stubborn State Estimation for Delayed Neural Networks Using Saturating Output Errors	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Artificial neural networks; State estimation; Estimation error; Neurons; Delays; Automation; Symmetric matrices; Neural networks (NNs); saturation; state estimation; time-varying delay	TIME-VARYING DELAY; STABILITY ANALYSIS; LINEAR-SYSTEMS; INEQUALITY; SENSOR; CRITERIA; DESIGN	This paper is concerned with the stubborn state estimation of delayed neural networks that subject to a general class of disturbances in measurements, including outliers and impulsive disturbances as its special cases. This class of disturbances may be unbounded, irregular, and assorted; therefore, they can hardly be suppressed by existing identification-based estimation approaches. In this paper, a stubborn state estimator is constructed by intentionally devising a saturation scheme on the injection of output estimation error. The embedded saturation can effectively resist the influences from these measurement disturbances by saturating them. Moreover, the saturation threshold in the designed scheme is not constant but governed by a dynamic equation with parameters to be designed. Benefiting from this adaptiveness, the estimator obtains more freedom in dealing with various disturbances. By combining a novel Lyapunov functional, the generalized sector condition and two latest integral inequalities, a delay-dependent criterion is derived in a less conservative way to check whether the estimation error system with this dynamic saturation is globally stable. A sufficient condition with two tuning scalars is further provided to codesign the gain of the state estimator and the evolution law of the saturation threshold. Finally, two numerical examples are used to illustrate the stubbornness of this state estimator in the presence of measurement outliers or impulsive disturbances.																	2162-237X	2162-2388				JUN	2020	31	6					1982	1994		10.1109/TNNLS.2019.2927610													
J								Impulsive Consensus of Nonlinear Multi-Agent Systems via Edge Event-Triggered Control	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Protocols; Multi-agent systems; Topology; Nonlinear dynamical systems; Convergence; Graph theory; Eigenvalues and eigenfunctions; Edge event-triggered control; impulsive consensus; multi-agent systems (MASs); nonlinear dynamics	DOUBLE-INTEGRATOR DYNAMICS; SAMPLED-DATA CONSENSUS; FINITE-TIME CONSENSUS; NETWORKS; ALGORITHMS	In this paper, we mainly investigate two kinds of consensuses of multi-agent systems (MASs) with nonlinear dynamics based on impulsive control, event-triggered control, and sampled-data control. The two types of impulsive protocols are proposed for the case without and with leader agent. Edge event-triggered technique is presented, where for each communication link, occurrence of edge event can activate the mutual state sampling and controller update of the corresponding agents. The control approach combines the characteristics of impulsive control and edge event-triggered control and is defined as "impulsive edge event-triggered control." It has good performance in robustness against disturbance and reduces the communication cost. The results with the aid of the Lyapunov function approach and stability theory of impulsive control show that if some sufficient conditions are satisfied, the consensus of MASs can be guaranteed and the rate of convergence can be exponentially estimated. Additionally, Zeno-behavior can be eliminated by using impulsive edge event-triggered control, which reduces the burden of event detectors. Finally, two simulations are provided to illustrate the effectiveness and performance of our theoretical analysis.																	2162-237X	2162-2388				JUN	2020	31	6					1995	2004		10.1109/TNNLS.2019.2927623													
J								Learning Markov Blankets From Multiple Interventional Data Sets	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Bayes methods; Markov processes; Australia; Skeleton; Data mining; Learning systems; Task analysis; Bayesian network; causal discovery; Markov blanket (MB); multiple interventional data sets	CAUSAL DISCOVERY; LOCAL CAUSAL; FEATURE-SELECTION; INDUCTION; INFERENCE	Learning Markov blankets (MBs) plays an important role in many machine learning tasks, such as causal Bayesian network structure learning, feature selection, and domain adaptation. Since variables included in the MB of a target variable of interest have causal relationships with the target, the MB can serve as the basis of learning the global structure of a causal Bayesian network or as a reliable and robust feature set for classification, both within the same domain or across domains. In this article, we study the problem of learning the MB of a target variable from multiple interventional data sets. Data sets attained from interventional experiments contain richer causal information than passively observed data (observational data) for MB discovery. However, almost all existing MB discovery methods are designed for learning MBs from a single observational data set. To learn MBs from multiple interventional data sets, we face two challenges: 1) unknown intervention variables and 2) nonidentical data distributions. To address these challenges, we theoretically analyze: 1) under what conditions we can find the correct MB of a target variable and 2) under what conditions we can identify the causes of the target variable via discovering its MB. Based on the theoretical analysis, we propose a new algorithm for learning MBs from multiple interventional data sets, and we present the conditions/assumptions that assure the correctness of the algorithm. To the best of our knowledge, this article is the first to present the theoretical analyses about the conditions for MB discovery in multiple interventional data sets and the algorithm to find the MBs in relation to the conditions. Using benchmark Bayesian networks and real-world data sets, the experiments have validated the effectiveness and efficiency of the proposed algorithm in this article.																	2162-237X	2162-2388				JUN	2020	31	6					2005	2019		10.1109/TNNLS.2019.2927636													
J								Two Projection Neural Networks With Reduced Model Complexity for Nonlinear Programming	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neural networks; Optimization; Computational modeling; Computational complexity; Programming; Manganese; Convex programming; fast computation; global stability; low-dimensional state space; nonconvex programming	L-1 ESTIMATION PROBLEMS; OPTIMIZATION PROBLEMS; SUBJECT; CONVERGENCE; EQUALITY	Recent reports show that projection neural networks with a low-dimensional state space can enhance computation speed obviously. This paper proposes two projection neural networks with reduced model dimension and complexity (RDPNNs) for solving nonlinear programming (NP) problems. Compared with existing projection neural networks for solving NP, the proposed two RDPNNs have a low-dimensional state space and low model complexity. Under the condition that the Hessian matrix of the associated Lagrangian function is positive semi-definite and positive definite at each Karush-Kuhn-Tucker point, the proposed two RDPNNs are proven to be globally stable in the sense of Lyapunov and converge globally to a point satisfying the reduced optimality condition of NP. Therefore, the proposed two RDPNNs are theoretically guaranteed to solve convex NP problems and a class of nonconvex NP problems. Computed results show that the proposed two RDPNNs have a faster computation speed than the existing projection neural networks for solving NP problems.																	2162-237X	2162-2388				JUN	2020	31	6					2020	2029		10.1109/TNNLS.2019.2927639													
J								Precise Measurement of Position and Attitude Based on Convolutional Neural Network and Visual Correspondence Relationship	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Training; Feature extraction; Cameras; Position measurement; Convolutional neural networks; Visualization; Convolutional neural network; generating image encoder; position and attitude measurement; subadded picture	CAMERA CALIBRATION; SYSTEM	Accurate measurement of position and attitude information is particularly important. Traditional measurement methods generally require high-precision measurement equipment for analysis, leading to high costs and limited applicability. Vision-based measurement schemes need to solve complex visual relationships. With the extensive development of neural networks in related fields, it has become possible to apply them to the object position and attitude. In this paper, we propose an object pose measurement scheme based on convolutional neural network and we have successfully implemented end-to-end position and attitude detection. Furthermore, to effectively expand the measurement range and reduce the number of training samples, we demonstrated the independence of objects in each dimension and proposed subadded training programs. At the same time, we generated generating image encoder to guarantee the detection performance of the training model in practical applications.																	2162-237X	2162-2388				JUN	2020	31	6					2030	2041		10.1109/TNNLS.2019.2927719													
J								Error-Based Learning Mechanism for Fast Online Adaptation in Robot Motor Control	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Learning systems; Robot sensing systems; Electronics packaging; Adaptation models; Legged locomotion; Robot kinematics; Adaptive oscillator; central pattern generator (CPG); energy efficiency; frequency adaptation; locomotion; rhythmic task; tracking error	LOCOMOTION CONTROL; OSCILLATOR; NETWORK	Existing state-of-the-art frequency adaptation mechanisms of central pattern generators (CPGs) for robot locomotion control typically rely on correlation-based learning. They do not account for the tracking error that may occur between the actual system motion and CPG output, leading to the loss of precision, unwanted movement, inefficient energy locomotion, and in the worst cases, motor collapse. To overcome this problem, we developed online error-based learning for frequency adaptation of CPGs. The learning mechanism used for error reduction is a novel modification of the dual learner (DL) called dual integral learner (DIL). Being able to reduce tracking and steady-state errors, it can also perform fast and stable learning, adapting the CPG frequency to match the performance of robotic systems. Control parameters of the DIL are more straightforward for complex systems (like walking robots), compared to traditional correlation-based learning, since they correspond to error reduction. Due to its embedded memory, the DIL can relearn quickly and recover spontaneously from the previously learned parameters. All these features are not covered by the existing frequency adaptation mechanisms. We integrated the DIL into a neural CPG-based motor control system for use on different legged robots with various morphologies for evaluation. The results show that: 1) the DIL does not require precise adjustment of its parameters to fit specific robots; and 2) the DIL can automatically and quickly adapt the CPG frequency to the robots such that the entire trajectory of the CPG can be precisely followed with very low tracking and steady-state errors. Consequently, the robots can perform the desired movements with more energy-efficient locomotion compared to the state-of-the-art correlation-based learning mechanism called frequency adaptation through fast dynamical coupling (AFDC). In the future, the proposed error-based learning mechanism for fast online adaptation in robot motor control can be used as a basis for trajectory optimization, universal controllers, and other studies concerning the change of intrinsic or extrinsic parameters.																	2162-237X	2162-2388				JUN	2020	31	6					2042	2051		10.1109/TNNLS.2019.2927737													
J								Discrete Deep Hashing With Ranking Optimization for Image Retrieval	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Image retrieval; Optimization; Hash functions; Semantics; Learning systems; Task analysis; Feature extraction; Category-level Information; discrete deep hashing; image retrieval; ranking information	CODES	For large-scale image retrieval task, a hashing technique has attracted extensive attention due to its efficient computing and applying. By using the hashing technique in image retrieval, it is crucial to generate discrete hash codes and preserve the neighborhood ranking information simultaneously. However, both related steps are treated independently in most of the existing deep hashing methods, which lead to the loss of key category-level information in the discretization process and the decrease in discriminative ranking relationship. In order to generate discrete hash codes with notable discriminative information, we integrate the discretization process and the ranking process into one architecture. Motivated by this idea, a novel ranking optimization discrete hashing (RODH) method is proposed, which directly generates discrete hash codes (e.g., +1/-1) from raw images by balancing the effective category-level information of discretization and the discrimination of ranking information. The proposed method integrates convolutional neural network, discrete hash function learning, and ranking function optimizing into a unified framework. Meanwhile, a novel loss function based on label information and mean average precision (MAP) is proposed to preserve the label consistency and optimize the ranking information of hash codes simultaneously. Experimental results on four benchmark data sets demonstrate that RODH can achieve superior performance over the state-of-the-art hashing methods.																	2162-237X	2162-2388				JUN	2020	31	6					2052	2063		10.1109/TNNLS.2019.2927868													
J								Deep Reinforcement Learning-Based Automatic Exploration for Navigation in Unknown Environment	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Robot sensing systems; Navigation; Entropy; Neural networks; Task analysis; Planning; Automatic exploration; deep reinforcement learning (DRL); optimal decision; partial observation		This paper investigates the automatic exploration problem under the unknown environment, which is the key point of applying the robotic system to some social tasks. The solution to this problem via stacking decision rules is impossible to cover various environments and sensor properties. Learning-based control methods are adaptive for these scenarios. However, these methods are damaged by low learning efficiency and awkward transferability from simulation to reality. In this paper, we construct a general exploration framework via decomposing the exploration process into the decision, planning, and mapping modules, which increases the modularity of the robotic system. Based on this framework, we propose a deep reinforcement learning-based decision algorithm that uses a deep neural network to learning exploration strategy from the partial map. The results show that this proposed algorithm has better learning efficiency and adaptability for unknown environments. In addition, we conduct the experiments on the physical robot, and the results suggest that the learned policy can be well transferred from simulation to the real robot.																	2162-237X	2162-2388				JUN	2020	31	6					2064	2076		10.1109/TNNLS.2019.2927869													
J								Distributed Finite-Time Fault-Tolerant Containment Control for Multiple Unmanned Aerial Vehicles	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Fault tolerance; Fault tolerant systems; Actuators; Aerodynamics; Unmanned aerial vehicles; Artificial neural networks; Convergence; Distributed fault-tolerant containment control; finite-time control; input saturation; neural networks (NNs); unmanned aerial vehicles (UAVs)	NEURAL-NETWORK CONTROL; FLIGHT CONTROL-DESIGN; NONLINEAR-SYSTEMS; TRACKING CONTROL; COOPERATIVE CONTROL; FEEDBACK SYSTEMS; ADAPTIVE-CONTROL; UAVS; STABILIZATION; TECHNOLOGIES	This paper investigates the distributed finite-time fault-tolerant containment control problem for multiple unmanned aerial vehicles (multi-UAVs) in the presence of actuator faults and input saturation. The distributed finite-time sliding-mode observer (SMO) is first developed to estimate the reference for each follower UAV. Then, based on the estimated knowledge, the distributed finite-time fault-tolerant controller is recursively designed to guide all follower UAVs into the convex hull spanned by the trajectories of leader UAVs with the help of a new set of error variables. Moreover, the unknown nonlinearities inherent in the multi-UAVs system, computational burden, and input saturation are simultaneously handled by utilizing neural network (NN), minimum parameter learning of NN (MPLNN), first-order sliding-mode differentiator (FOSMD) techniques, and a group of auxiliary systems. Furthermore, the graph theory and Lyapunov stability analysis methods are adopted to guarantee that all follower UAVs can converge to the convex hull spanned by the leader UAVs even in the event of actuator faults. Finally, extensive comparative simulations have been conducted to demonstrate the effectiveness of the proposed control scheme.																	2162-237X	2162-2388				JUN	2020	31	6					2077	2091		10.1109/TNNLS.2019.2927887													
J								Pinning Synchronization of Directed Coupled Reaction-Diffusion Neural Networks With Sampled-Data Communications	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Synchronization; Artificial neural networks; Delays; Linear matrix inequalities; Learning systems; Directed coupled reaction-diffusion neural networks (CRDNNs); exponential synchronization; linear matrix inequalities (LMIs); pinning sampled-data control; sampled-data communications (SDCs)	TIME-VARYING DELAYS; COMPLEX DYNAMICAL NETWORKS; EXPONENTIAL SYNCHRONIZATION; INEQUALITY; TERMS	This paper focuses on the design of a pinning sampled-data control mechanism for the exponential synchronization of directed coupled reaction-diffusion neural networks (CRDNNs) with sampled-data communications (SDCs). A new Lyapunov-Krasovskii functional (LKF) with some sampled-instant-dependent terms is presented, which can fully utilize the actual sampling information. Then, an inequality is first proposed, which effectively relaxes the restrictions of the positive definiteness of the constructed LKF. Based on the LKF and the inequality, sufficient conditions are derived to exponentially synchronize the directed CRDNNs with SDCs. The desired pinning sampled-data control gain is precisely obtained by solving some linear matrix inequalities (LMIs). Moreover, a less conservative exponential synchronization criterion is also established for directed coupled neural networks with SDCs. Finally, simulation results are provided to verify the effectiveness and merits of the theoretical results.																	2162-237X	2162-2388				JUN	2020	31	6					2092	2103		10.1109/TNNLS.2019.2928039													
J								Distributed Optimization for Disturbed Second-Order Multiagent Systems Based on Active Antidisturbance Control	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Multi-agent systems; Cost function; Convergence; Closed loop systems; Asymptotic stability; Active antidisturbance control; consensus; distributed optimization; mismatched disturbances; multiagent systems	CONVEX-OPTIMIZATION; OPTIMAL CONSENSUS; ALGORITHMS; AGENTS; COORDINATION; NETWORKS; OBSERVER; DESIGN	In this article, the distributed optimization problem is studied for second-order multiagent systems with both mismatched and matched disturbances. For this problem, a distributed active antidisturbance control framework is established, which consists of both disturbance estimation/compensation and distributed feedforward-feedback composite control design. In the first stage, some disturbance estimators are utilized to estimate various types of matched/mismatched disturbances for each agent. In the second stage, for each agent, based on the disturbance estimates, the information exchanges between the neighboring agents, and the gradient of the local cost function only accessible to itself, a kind of distributed composite controllers are proposed. Under these controllers, all the agents' outputs asymptotically reach consensus to the minimizer of the global cost function, which is the sum of all the local cost functions. The closed-loop system convergence is proven based on a new Lyapunov function, convex analysis, and an input-to-state stability criterion. Simulations demonstrate the effectiveness of the proposed control scheme.																	2162-237X	2162-2388				JUN	2020	31	6					2104	2117		10.1109/TNNLS.2019.2951790													
J								Contrastive Hebbian Feedforward Learning for Neural Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neurons; Correlation; Learning systems; Training; Feedforward systems; Feedforward neural networks; Binary stochastic neurons; contrastive divergence; contrastive Hebbian; deep learning		This paper addresses the biological plausibility of both backpropagation (BP) and contrastive Hebbian learning (CHL) used in the Boltzmann machines. The main claim of this paper is that CHL is a general learning algorithm that can be used to steer feedforward networks toward desirable outcomes, and steer them away from undesirable outcomes without any need for the specialized feedback circuit of BP or the symmetric connections used by the Boltzmann machines. After adding perturbations during the learning phase to all the neurons in the network, multiple feedforward outcomes are classified into Hebbian and anti-Hebbian sets based on the network predictions. The algorithm is applied to networks when optimizing a loss objective where BP excels and is also applied to networks with stochastic binary outputs where BP cannot be easily applied. The power of the proposed algorithm lies in its simplicity where both learning and gradient estimation through stochastic binary activations are combined into a single local Hebbian rule. We will also show that both Hebbian and anti-Hebbian correlations are evaluated from the readily available signals that are fundamentally different from CHL used in the Boltzmann machines. We will demonstrate that the new learning paradigm where Hebbian/anti-Hebbian correlations are based on correct/incorrect predictions is a powerful concept that separates this paper from other biologically inspired learning algorithms.																	2162-237X	2162-2388				JUN	2020	31	6					2118	2128		10.1109/TNNLS.2019.2927957													
J								Output Feedback Control for Set Stabilization of Boolean Control Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Output feedback; State feedback; Synchronization; Stability analysis; Trajectory; Learning systems; Tools; Boolean control networks (BCNs); logical systems; output feedback control; semi-tensor product (STP); set stabilization; spanning tree	SPANNING-TREES; DYNAMICS; CONTROLLABILITY; OBSERVABILITY; ALGORITHMS; STABILITY; MODELS	In this paper, the output feedback set stabilization problem for Boolean control networks (BCNs) is investigated with the help of the semi-tensor product (STP) tool. The concept of output feedback control invariant (OFCI) subset is introduced, and novel methods are developed to obtain the OFCI subsets. Based on the OFCI subsets, a technique, named spanning tree method, is further introduced to calculate all possible output feedback set stabilizers. An example concerning lac operon for the bacterium Escherichia coli is given to illustrate the effectiveness of the proposed method. This technique can also be used to solve the state feedback (set) stabilization problem for BCNs. Compared with the existing results, our method can dramatically reduce the computational cost when designing all possible state feedback stabilizers for BCNs.																	2162-237X	2162-2388				JUN	2020	31	6					2129	2139		10.1109/TNNLS.2019.2928028													
J								Adaptive Neural Network Prescribed Performance Bounded-H-infinity Tracking Control for a Class of Stochastic Nonlinear Systems	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Backstepping technique; bounded-H-infinity performance; neural network; prescribed performance control; stochastic nonlinear system	SLIDING MODE CONTROL; FEEDBACK H; DESIGN	This paper aims to give a design strategy on the prescribed performance H-infinity tracking control problem for a class of strict-feedback stochastic nonlinear systems based on the backstepping technique. Generally, by using the backstepping design method, the stochastic nonlinear systems can only be made to be bounded in probability and it is difficult to achieve the H-infinity performance criterion due to the positive constant term appeared in the stability analysis. Thus, a novel concept with regard to the bounded-H-infinity performance is proposed in this paper to overcome the design difficulty. By using the new concept and the adaptive neural network technique as well as Gronwall inequality, an adaptive neural network prescribed performance bounded-H-infinity tracking controller is designed. Therein, neural networks are used to approximate the unknown packaged nonlinear functions. The assumption that the approximation errors of neural networks are square-integrable in some literature is eliminated. The designed controller guarantees that all the signals in the closedloop stochastic nonlinear systems are bounded in probability, the tracking error is constrained into an adjustable neighborhood of the origin with the prescribed performance bounds, and the controlled system has a given H-infinity disturbance attenuation performance for external disturbances. Finally, the simulation results are provided to illustrate the effectiveness and feasibility of the proposed approach.																	2162-237X	2162-2388				JUN	2020	31	6					2140	2152		10.1109/TNNLS.2019.2928594													
J								Adaptive Weighted Sparse Principal Component Analysis for Robust Unsupervised Feature Selection	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										l(2,1)-norm; clustering; feature selection; reconstruction	REGULARIZATION; PCA	Current unsupervised feature selection methods cannot well select the effective features from the corrupted data. To this end, we propose a robust unsupervised feature selection method under the robust principal component analysis (PCA) reconstruction criterion, which is named the adaptive weighted sparse PCA (AW-SPCA). In the proposed method, both the regularization term and the reconstruction error term are constrained by the l(2,1)-norm: the l(2,1)-norm regularization term plays a role in the feature selection, while the l(2,1)-norm reconstruction error term plays a role in the robust reconstruction. The proposed method is in a convex formulation, and the selected features by it can be used for robust reconstruction and clustering. Experimental results demonstrate that the proposed method can obtain better reconstruction and clustering performance, especially for the corrupted data.																	2162-237X	2162-2388				JUN	2020	31	6					2153	2163		10.1109/TNNLS.2019.2928755													
J								Real-Time Object Detection With Reduced Region Proposal Network via Multi-Feature Concatenation	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Object detection; Proposals; Convolution; Computer architecture; Feature extraction; Real-time systems; Deep learning; Multi-feature concatenation; object detection; region proposal network (RPN); weight pruning		In recent years, object detection became more and more important following the successful results from studies in deep learning. Two types of neural network architectures are used for object detection: one-stage and two-stage. In this paper, we analyze a widely used two-stage architecture called Faster R-CNN to improve the inference time and achieve real-time object detection without compromising on accuracy. To increase the computation efficiency, pruning is first adopted to reduce the weights in convolutional and fully connected (FC) layers. However, this reduces the accuracy of detection. To address this loss in accuracy, we propose a reduced region proposal network (RRPN) with dilated convolution and concatenation of multi-scale features. In the assisted multi-feature concatenation, we propose the intra-layer concatenation and proposal refinement to efficiently integrate the feature maps from different convolutional layers; this is then provided as an input to the RRPN. Using the proposed method, the network can find object bounding boxes more accurately, thus compensating for the loss arising from compression. Finally, we test the proposed architecture using ZF-Net and VGG16 as a backbone network on the image sets in PASCAL VOC 2007 or VOC 2012. The results show that we can compress the parameters of the ZF-Net-based network by 81.2% and save 66% of computation. The parameters of VGG16-based network are compressed by 73% and save 77% of computation. Consequently, the inference speed is improved from 27 to 40 frames/s for ZF-Net and 9 to 27 frames/s for VGG16. Despite significant compression rates, the accuracy of ZF-Net is increased from 2.2% to 60.2% mean average precision (mAP) and that of VGG16 is increased from 2.6% to 69.1% mAP.																	2162-237X	2162-2388				JUN	2020	31	6					2164	2173		10.1109/TNNLS.2019.2929059													
J								Tensor Networks for Latent Variable Analysis: Higher Order Canonical Polyadic Decomposition	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Blind source separation; canonical polyadic decomposition; exact conversion; harmonic retrieval; higher order tensor; tensor network; tensor train	CP DECOMPOSITION; CANDECOMP/PARAFAC; ALGORITHMS; SEPARATION; IDENTIFICATION; COMPLEXITY; UNIQUENESS	The canonical polyadic decomposition (CPD) is a convenient and intuitive tool for tensor factorization; however, for higher order tensors, it often exhibits high computational cost and permutation of tensor entries, and these undesirable effects grow exponentially with the tensor order. Prior compression of tensor in-hand can reduce the computational cost of CPD, but this is only applicable when the rank R of the decomposition does not exceed the tensor dimensions. To resolve these issues, we present a novel method for CPD of higher order tensors, which rests upon a simple tensor network of representative interconnected core tensors of orders not higher than 3. For rigor, we develop an exact conversion scheme from the core tensors to the factor matrices in CPD and an iterative algorithm of low complexity to estimate these factor matrices for the inexact case. Comprehensive simulations over a variety of scenarios support the proposed approach.																	2162-237X	2162-2388				JUN	2020	31	6					2174	2188		10.1109/TNNLS.2019.2929063													
J								Two-Stream Deep Hashing With Class-Specific Centers for Supervised Image Search	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Deep learning; hashing; nearest neighbor search; two-stream ConvNet	PARALLEL FRAMEWORK; RETRIEVAL; DECISION; TREES	Hashing has been widely used for large-scale approximate nearest neighbor search due to its storage and search efficiency. Recent supervised hashing research has shown that deep learning-based methods can significantly outperform nondeep methods. Most existing supervised deep hashing methods exploit supervisory signals to generate similar and dissimilar image pairs for training. However, natural images can have large intraclass and small interclass variations, which may degrade the accuracy of hash codes. To address this problem, we propose a novel two-stream ConvNet architecture, which learns hash codes with class-specific representation centers. Our basic idea is that if we can learn a unified binary representation for each class as a center and encourage hash codes of images to be close to the corresponding centers, the intraclass variation will be greatly reduced. Accordingly, we design a neural network that leverages label information and outputs a unified binary representation for each class. Moreover, we also design an image network to learn hash codes from images and force these hash codes to be close to the corresponding class-specific centers. These two neural networks are then seamlessly incorporated to create a unified, end-to-end trainable framework. Extensive experiments on three popular benchmarks corroborate that our proposed method outperforms current state-of-the-art methods.																	2162-237X	2162-2388				JUN	2020	31	6					2189	2201		10.1109/TNNLS.2019.2929068													
J								On Optimal Time-Varying Feedback Controllability for Probabilistic Boolean Control Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Controllability; Probabilistic logic; Optimal control; Boolean functions; Optimization; State feedback; Adaptive control; Controllability; probabilistic Boolean control network (PBCN); semitensor product (STP); stochastic optimal control	DYNAMICS; SYNCHRONIZATION; OBSERVABILITY; DESIGN; STABILIZATION; EXPRESSION; ALGORITHM	This brief studies controllability for probabilistic Boolean control network (PBCN) with time-varying feedback control laws. The concept of feedback controllability with an arbitrary probability for PBCNs is formulated first, and a control problem to maximize the probability of time-varying feedback controllability is investigated afterward. By introducing semitensor product (STP) technique, an equivalent multistage decision problem is deduced, and then a novel optimization algorithm is proposed to obtain the maximum probability of controllability and the corresponding optimal feedback law simultaneously. The advantages of the time-varying optimal controller obtained by the proposed algorithm, compared to the time-invariant one, are illustrated by numerical simulations.																	2162-237X	2162-2388				JUN	2020	31	6					2202	2208		10.1109/TNNLS.2019.2927241													
J								Improved Sliding Mode Control for Finite-Time Synchronization of Nonidentical Delayed Recurrent Neural Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Synchronization; Delays; Biological neural networks; Neurons; Sliding mode control; Learning systems; Recurrent neural networks; Delayed neural networks; finite-time synchronization; Lyapunov stability theory; sliding mode control (SMC)	EXPONENTIAL SYNCHRONIZATION; VARYING DELAY; STABILITY ANALYSIS	This brief further explores the problem of finite-time synchronization of delayed recurrent neural networks with the mismatched parameters and neuron activation functions. An improved sliding mode control approach is presented for addressing the finite-time synchronization problem. First, by employing the drive-response concept and the synchronization error of drive-response systems, a novel integral sliding mode surface is constructed such that the synchronization error can converge to zero in finite time along the constructed integral sliding mode surface. Second, a suitable sliding mode controller is designed by relying on Lyapunov stability theory such that all system state trajectories can be driven onto the predefined sliding mode surface in finite time. Moreover, it is found that the presented control approach can be conveniently verified and does not need to solve any linear matrix inequality (LMI) to guarantee the finite-time synchronization of delayed recurrent neural networks. Finally, three numerical examples are exploited to demonstrate the effectiveness of the presented control approach.																	2162-237X	2162-2388				JUN	2020	31	6					2209	2216		10.1109/TNNLS.2019.2927249													
J								A Projection Neural Network for the Generalized Lasso	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Generalized lasso (GLasso); global convergence; Lyapunov; neural network	OPTIMIZATION PROBLEMS; GRADIENT PROJECTION; ALGORITHM; L(1)	The generalized lasso (GLasso) is an extension of the lasso regression in which there is an l(1) penalty term (or regularization) of the linearly transformed coefficient vector. Finding the optimal solution of GLasso is not straightforward since the penalty term is not differentiable. This brief presents a novel one-layer neural network to solve the generalized lasso for a wide range of penalty transformation matrices. The proposed neural network is proven to be stable in the sense of Lyapunov and converges globally to the optimal solution of the GLasso. It is also shown that the proposed neural solution can solve many optimization problems, including sparse and weighted sparse representations, (weighted) total variation denoising, fused lasso signal approximator, and trend filtering. Disparate experiments on the above problems illustrate and confirm the excellent performance of the proposed neural network in comparison to other competing techniques.																	2162-237X	2162-2388				JUN	2020	31	6					2217	2221		10.1109/TNNLS.2019.2927282													
J								Stress-Testing Memcomputing on Hard Combinatorial Optimization Problems	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Dynamical systems; memcomputing; optimization problems		Memcomputing is a novel computing paradigm that employs time non-local dynamical systems to compute with and in memory. The digital version of these machines [digital memcomputing machines or (DMMs)] is scalable, and is particularly suited to solve combinatorial optimization problems. One of its possible realizations is by means of standard electronic circuits, with and without memory. Since these elements are non-quantum, they can be described by ordinary differential equations. Therefore, the circuit representation of DMMs can also be simulated efficiently on our traditional computers. We have indeed previously shown that these simulations only require time and memory resources that scale linearly with the problem size when applied to finding a good approximation to the optimum of hard instances of the maximum-satisfiability problem. The state-of-the-art algorithms, instead, require exponential resources for the same instances. However, in that work, we did not push the simulations to the limit of the processor used. Since linear scalability at smaller problem sizes cannot guarantee linear scalability at much larger sizes, we have extended these results in a stress-test up to 64 x 10(6) variables (corresponding to about 1 billion literals), namely the largest case that we could fit on a single core of an Intel Xeon E5-2860 with 128 GB of dynamic random-access memory (DRAM). For this test, we have employed a commercial simulator, Falcon of MemComputing, Inc. We find that the simulations of DMMs still scale linearly in both time and memory up to these very large problem sizes versus the exponential requirements of the stateof-the-art solvers. These results further reinforce the advantages of the physics-based memcomputing approach compared with traditional ones.																	2162-237X	2162-2388				JUN	2020	31	6					2222	2226		10.1109/TNNLS.2019.2927480													
J								A Limitation of Gradient Descent Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Additive weight noise; gradient descent algorithms; MNIST; multiplicative weight noise	SYNAPTIC WEIGHT NOISE; FAULT-TOLERANCE; NEURAL-NETWORKS; BACKPROPAGATION; INJECTION; CONVERGENCE; INPUTS	Over decades, gradient descent has been applied to develop learning algorithm to train a neural network (NN). In this brief, a limitation of applying such algorithm to train an NN with persistent weight noise is revealed. Let V(w) be the performance measure of an ideal NN. V(w) is applied to develop the gradient descent learning (GDL). With weight noise, the desired performance measure (denoted as J(w)) is E[ V(w)|w], where w is the noisy weight vector. Applying GDL to train an NN with weight noise, the actual learning objective is clearly not V(w) but another scalar function L(w). For decades, there is a misconception that L(w) = J(w), and hence, the actual model attained by the GDL is the desired model. However, we show that it might not: 1) with persistent additive weight noise, the actual model attained is the desired model as L(w) = J(w); and 2) with persistent multiplicative weight noise, the actual model attained is unlikely the desired model as L(w) = J(w). Accordingly, the properties of the models attained as compared with the desired models are analyzed and the learning curves are sketched. Simulation results on 1) a simple regression problem and 2) the MNIST handwritten digit recognition are presented to support our claims.																	2162-237X	2162-2388				JUN	2020	31	6					2227	2232		10.1109/TNNLS.2019.2927689													
J								Short-term Demand Forecasting for Online Car-hailing Services Using Recurrent Neural Networks	APPLIED ARTIFICIAL INTELLIGENCE												Short-term traffic flow prediction is one of the crucial issues in intelligent transportation system, which is an important part of smart cities. Accurate predictions can enable both the drivers and the passengers to make better decisions about their travel route, departure time, and travel origin selection, which can be helpful in traffic management. Multiple models and algorithms based on time-series prediction and machine learning were applied to this issue and achieved acceptable results. Recently, the availability of sufficient data and computational power motivates us to improve the prediction accuracy via deep-learning approaches. Recurrent neural networks have become one of the most popular methods for time-series forecasting; however, due to the variety of these networks, the question that which type is the most appropriate one for this task remains unsolved. In this paper, we use three kinds of recurrent neural networks including simple RNN units, GRU, and LSTM neural network to predict short-term traffic flow. The dataset from TAP30 Corporation is used for building the models and comparing RNNs with several well-known models, such as DEMA, LASSO, and XGBoost. The results show that all three types of RNNs outperform the others; however, more simple RNNs such as simple recurrent units and GRU perform work better than LSTM in terms of accuracy and training time.																	0883-9514	1087-6545				JUL 28	2020	34	9					674	689		10.1080/08839514.2020.1771522		JUN 2020											
J								Agricultural Model for Allocation of Crops Using Pollination Intelligence Method	APPLIED COMPUTATIONAL INTELLIGENCE AND SOFT COMPUTING											OPTIMIZATION	An agricultural model for allocation of crops is considered in this work using Pollination Intelligence Method. The model was constructed to solve farmer's decision making in allocating crops to a piece of land using market price, known yield of crops, cost incurred during planting, and the total amount of land available. A new class of metaheuristic method called Flower Pollinated Algorithm is also presented in this work to solve the designed model. An improved version of the Flower Pollinated Algorithm called Pollination Intelligence Algorithm using an iterative scheme to override the switch parameter in Flower Pollinated Algorithm is also presented and used in solving the designed model. A case study of a farmer in Ife, Osun State, Nigeria, was used to implement the model, and the results obtained suggested that instead of allocating crops to land randomly based on farmer's intuition, cost of planting, yield of crops, and market price were factors that must be considered by farmers for optimal profit before planting crops.																	1687-9724	1687-9732				JUN 1	2020	2020								4830359	10.1155/2020/4830359													
J								Effective approximation of parametrized closure systems over transactional data streams	MACHINE LEARNING										Data streams; Itemset mining; Closed itemsets; Concept drift detection; Applications	PROBABILITY-INEQUALITIES; FREQUENT; SETS	Strongly closed itemsets, defined by a parameterized closure operator, are a generalization of ordinary closed itemsets. Depending on the strength of closedness, the family of strongly closed itemsets typically forms a tiny subfamily of ordinary closed itemsets that is stable against changes in the input. In this paper we consider the problem of mining strongly closed itemsets from transactional data streams. Utilizing their algebraic and algorithmic properties, we propose an algorithm based on reservoir sampling for approximating this type of itemsets in the landmark streaming setting, prove its correctness, and show empirically that it yields a considerable speed-up over a straightforward naive algorithm without any significant loss in precision and recall. We motivate the problem setting considered by two practical applications. In particular, we first experimentally demonstrate that the above properties, i.e., compactness and stability, make strongly closed itemsets an excellent indicator of certain types of concept drifts in transactional data streams. As a second application we consider computer-aided product configuration, a real-world problem raised by an industrial project. For this problem, which is essentially exact concept identification, we propose a learning algorithm based on a certain type of subset queries formed by strongly closed itemsets and show on real-world datasets that it requires significantly less query evaluations than a naive algorithm based on membership queries.																	0885-6125	1573-0565				JUN	2020	109	6					1147	1177		10.1007/s10994-019-05827-w													
J								Feature ranking for multi-target regression	MACHINE LEARNING										Feature ranking; Multi target regression; Tree based methods; Relief	ENSEMBLES; TREES	In this work, we address the task of feature ranking for multi-target regression (MTR). The task of MTR concerns problems with multiple continuous dependent/target variables, where the goal is to learn a model for predicting all of them simultaneously. This task is receiving an increasing attention from the research community, but performing feature ranking in the context of MTR has not been studied thus far. Here, we study two groups of feature ranking scores for MTR: scores (Symbolic, Genie3 and Random Forest score) based on ensembles (bagging, random forests, extra trees) of predictive clustering trees, and a score derived as an extension of the RReliefF method. We also propose a generic data-transformation approach to MTR feature ranking and thus have two versions of each score. For both groups of feature ranking scores, we analyze their theoretical computational complexity. For the extension of the RReliefF method, we additionally derive some theoretical properties of the scores. Next, we extensively evaluate the scores on 24 benchmark MTR datasets, in terms of the quality of the ranking and the computational complexity of producing it. The results identify the parameters that influence the quality of the rankings, reveal that both groups of methods produce relevant feature rankings, and show that the Symbolic and Genie3 score, coupled with random forest ensembles, yield the best rankings.																	0885-6125	1573-0565				JUN	2020	109	6					1179	1204		10.1007/s10994-019-05829-8													
J								Ranking by inspiration: a network science approach	MACHINE LEARNING										Information diffusion; Bibliographic indexes; Citation networks; Topic modeling	INDEX	Contagion processes have been widely studied in epidemiology and life science in general, but their implications are largely tangible in other research areas, such as in network science and computational social science. Contagion models, in particular, have proven helpful in the study of information diffusion, a very topical issue thanks to its applications to social media/network analysis, viral marketing campaigns, influence maximization and prediction. In bibliographic networks, for instance, an information diffusion process takes place when some authors, that publish papers in a given topic, influence some of their neighbors (coauthors, citing authors, collaborators) to publish papers in the same topic, and the latter influence their neighbors in their turn. This well-accepted definition, however, does not consider that influence in bibliographic networks is a complex phenomenon involving several scientific and cultural aspects. In fact, in scientific citation networks, influential topics are usually considered those ones that spread most rapidly in the network. Although this is generally a fact, this semantics does not consider that topics in bibliographic networks evolve continuously. In fact, knowledge, information and ideas are dynamic entities that acquire different meanings when passing from one person to another. Thus, in this paper, we propose a new definition of influence that captures the diffusion of inspiration within the network. We call it inspiration score, and show its effectiveness in detecting the most inspiring topics, authors, papers and venues in a citation network built upon two large bibliographic datasets. We show that the inspiration score can be used as an alternative or complementary bibliographic index in academic ranking applications.																	0885-6125	1573-0565				JUN	2020	109	6					1205	1229		10.1007/s10994-019-05828-9													
J								Training the Stochastic Kinetic Model of Neuron for Calculation of an Object's Position in Space	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Hodgkin-Huxley model; Markov kinetic formalism; Gradient descent; AHRS; Attitude and heading reference system	HODGKIN-HUXLEY TYPE	In this paper we focus on the stochastic kinetic extension of the well-known Hodgkin-Huxley model of a biological neuron. We show the gradient descent algorithm for training of the neuron model. In comparison with training of the Hodgkin-Huxley model we use only three weights instead of nine. We show that the trained stochastic kinetic model gives equally good results as the trained Hodgkin-Huxley model, while we gain on more concise mathematical description of the training procedure. The trained stochastic kinetic model of neuron is tested in solving the problem of approximation, where for the approximated function the membrane potential obtained using different models of a biological neuron was chosen. Additionally, we present a simple application, in which the trained models of neuron connected with the outputs of a recurrent neural network form a system, which is used to calculate the Euler angles of an object's position in space, based on linear and angular acceleration, direction and the magnitude of Earth's magnetic field.																	0921-0296	1573-0409				JUN	2020	98	3-4					615	626		10.1007/s10846-019-01068-0													
J								A Robust Linear Control Strategy to Enhance Damping of a Series Elastic Actuator on a Collaborative Robot	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Collaborative robots; Tuning rules; Series elastic actuator; Damped control; Robust control	IMPEDANCE CONTROL	Dealing with the physical interaction between humans and robots, Series Elastic Actuators (SEAs) are identified as one solution to overcome many limits, such as reducing contact forces or detect collisions. Nevertheless, the low-damping dynamic of a SEA can lead to undesired behaviours, especially during particular applications where a high level of precision is required. In this paper, a linear control architecture to enhance the damping performance of a SEA is presented. The proposed structure consists in a cascade control where loops are regulated using three types of controllers: PI, PD and a generalized controller specifically designed to damp oscillations. A frequency-domain approach with related constraints could not satisfy the time-domain goal in term of oscillation damping, for this reason an optimization problem able to consider them both is taken into account. A robust design is mandatory to the model mismatch introduced by neglecting coupling between motor. Therefore, robustness constraints are introduced in the optimization procedure. Indeed, the effectiveness of the control architecture is tested on a real compliant robot with six degrees of freedom equipped with as many SEAs. Each test aims to highlight the damping performance of the controlled system while the robot performs various tasks or it is subject to external disturbances.																	0921-0296	1573-0409				JUN	2020	98	3-4					627	641		10.1007/s10846-019-01071-5													
J								A novel Robust Adaptive Control Using RFWNNs and Backstepping for Industrial Robot Manipulators with Dead-Zone	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Industrial robot; Unknown dead-zone; Recurrent wavelet fuzzy neural networks; Adaptive control	WAVELET NEURAL-NETWORKS; SLIDING-MODE CONTROL; SYSTEMS; COMPENSATION; INPUT	This paper proposes a novel robust adaptive-backstepping-recurrent-fuzzy-wavelet-neural-networks controller (ABRFWNNs) based on dead zone compensator for Industrial Robot Manipulators (IRMs) in order to improve high correctness of the position tracking control with the presence of the unknown dynamics, and disturbances. To deal on the unknown dynamics of the robot system problems, the proposed controller used recurrent-fuzzy-wavelet-neural-networks (RFWNNs) to approximate the unknown dynamics. The online adaptive control training laws and estimation of the dead-zone are determined by Lyapunov stability theory and the approximation theory. In this method, the robust sliding-mode-control (SMC) is constructed to optimize parameter vectors, solve the approximation error and higher order terms. Therefore, the stability, robustness, and desired tracking performance of ABRFWNNs for IRMs are guaranteed. The simulations and experiments performed on three-link IRMs are provided in comparison with fuzzy-wavelet-neural-networks (FWNNs) and proportional-integral-derivative (PID) to demonstrate the robustness and effectiveness of the ARBFWNNs.																	0921-0296	1573-0409				JUN	2020	98	3-4					679	692		10.1007/s10846-019-01089-9													
J								Adaptive Extended State Observer-Based Nonsingular Terminal Sliding Mode Control for the Aircraft Skin Inspection Robot	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Adaptive extended state observer; Terminal sliding mode control; Aircraft skin inspection robot	NONLINEAR-SYSTEMS; CLIMBING ROBOT; TRACKING; DESIGN	Many application areas call for robots to carry out tasks for human safety and work reliability. An aircraft skin inspection robot is introduced in this paper, which sticks to the surface of an aircraft by suction adhesion. Since the vibration during movement of the robot limits the measurement accuracy, the purpose of operating adsorption force is to ensure a smooth and fast movement of the robot. Firstly, a minimum adsorption force guaranteeing the safety of the robot is analyzed and an adsorption system with unmeasured states, unknown disturbances, and parameter uncertainties is presented. Secondly, an adaptive extended state observer (ESO) is developed not only to estimate the unmeasured states but also to eliminate the impact of the unknown disturbances and parameter uncertainties. Moreover, the problem of stochastic stability analysis for the estimated error system is also discussed. An adaptive ESO-based nonsingular terminal sliding mode control(NTSMC) is then presented by using Lyapunov synthesis. Finally, the simulation and experimental results show the feasibility of the proposed scheme.																	0921-0296	1573-0409				JUN	2020	98	3-4					721	732		10.1007/s10846-019-01067-1													
J								A Comparative Analysis of Pattern Matching Techniques Towards OGM Evaluation	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Occupancy grid maps; Map registration; SLAM evaluation; Map merging; Image processing		The alignment of two occupancy grid maps generated by SLAM algorithms is a quite researched problem, being an obligatory step either for unsupervised map merging techniques or for evaluation of OGMs (Occupancy Grid Maps) against a blueprint of the environment. This paper provides an overview of the existing automatic alignment techniques of two occupancy grid maps that employ pattern matching. Additionally, an alignment pipeline using local features and image descriptors is implemented, as well as a method to eliminate erroneous correspondences, aiming at producing the correct transformation between the two maps. Finally, map quality metrics are proposed and utilized, in order to quantify the produced map's correctness. A comparative analysis was performed over a number of image processing and OGM-oriented detectors and descriptors, in order to identify the best combinations for the map evaluation problem, performed between two OGMs or between an OGM and a Blueprint map.																	0921-0296	1573-0409				JUN	2020	98	3-4					733	758		10.1007/s10846-019-01053-7													
J								Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Autism Spectrum disorder (ASD); Human robot Interface (HRI); NAO robot; Interactive games; Robot-based games	COLLABORATIVE PLAY; SPECTRUM DISORDER; TECHNOLOGIES	Autism Spectrum Disorder (ASD) is becoming a growing concern worldwide. Parents are often not aware of the different nature of children with ASD and attempt to treat him/her the same way as other children. However, that causes more and more isolation of such children from the social interactions around them, resulting in more secluded and people-phobic behaviors. Nevertheless, similar to other children, children with ASD also like to play with toys. This observation has led to the use of toys in a way that mere playful activities could become sources of learning and skill-building, somewhat serving or assisting in the role of a human teacher. Robots have been observed to be fascinating for all children and compensating for a human companion to a certain extent. In this paper, a short study has been presented involving a humanoid robot programmed for a number of teaching and therapeutic behaviors, such as exercises, singing, explaining, and playing with children. Tests were performed on a small group of 15 children with ASD (ages 7-11) using these activities at a local school for children with special needs for a number of weeks. The objective of the study was to quantify the improvement in a number of behavior and learning parameters when children performed the activities with NAO robot present with the teacher, as opposed to the same type of activities performed by the teacher alone. The performance improvement was quantified in terms of the NAO robot activity as independent variable, and following dependent behavioral variables observed from the responses of children: (a) number of trials, (b) activity response time, (c) response type, and (d) behavior retention. Quantified findings from these tests are reported in this paper against average performance values (based on teachers and psychologists' evaluation). The results of the study have been found to be very encouraging which demonstrates the capability of robotic toys to improve the learning process for children with ASD. The results of this study also encourage the low-cost development and usage of such robotic toy systems for teaching and therapeutic applications that help such children to become better members of society.																	0921-0296	1573-0409				JUN	2020	98	3-4					759	770		10.1007/s10846-019-01075-1													
J								Distributed Cooperative Obstacle Avoidance for Mobile Robots Using Independent Virtual Center Points	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Collision avoidance; Virtual center point	CONSENSUS; SYSTEM	This paper addresses the obstacle avoidance problem of multiple mobile robots. We propose a method to address this problem, using a distributed robotic cooperative obstacle avoidance method with independent virtual center points which are set based on the current state of nearby robots and itself. Mobile robots use two different control modes: an obstacle-free mode, and an obstacle-avoidance mode. The control mode is switched on-line, based on the robot's states which are shared information. Moreover, there is no limit to the number of mobile robots in the system of the proposed method. A control law is designed to guide the mobile robots to away from potential collisions and avoid congestion with other robots. The stability of the system is proved using a Lyapunov function. The effectiveness of the proposed method is evaluated using simulation studies and also real-world experimental verification. Experimental results show that the proposed method enables mobile robots to not only avoid collision with each other, but also significantly reduces the travel time and travel distance for situations with irregular distributions of multiple robots.																	0921-0296	1573-0409				JUN	2020	98	3-4					791	805		10.1007/s10846-019-01084-0													
J								Altitude Information Acquisition of UAV Based on Monocular Vision and MEMS	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										UAV; Altitude information; Data fusion; Monocular vision; MEMS		Altitude information is one of the most important data pieces to realize unmanned aerial vehicle (UAV) autonomous flight. At present, the barometers equipped in the UAVs were used to measure the atmospheric pressure and convert the data to the altitude of UAVs. But the pressure will change drastically when the propeller of the UAV rotate and lead to inaccurate measurement values. In this paper, a UAV height information acquisition method based on the information fusion of monocular vision and a microelectromechanical system (MEMS) is designed, which can obtain accurate height information in the indoor environment and low-altitude outdoor environment. The parallax is obtained by using two images taken in a short time during UAV flight in this method, and the acceleration data measured by the MEMS are used to compute the displacements of the UAV in this time as the baseline. The angle information measured by the MEMS is used to calibrate the images taken by the monocular camera of the UAV. Finally, the altitude information of the UAV is obtained with the theory of binocular stereo vision. Experiments have proven that the altitude information errors obtained by this method at 2 m is approximately 4%, which is less than barometer errors. A new image crop method was proposed to reduce computation, which meets the steady, fast and accurate requirements for practical application. The experiments show that our proposed method can obtain satisfactory results with respect to the state-of-the-art methods.																	0921-0296	1573-0409				JUN	2020	98	3-4					807	818		10.1007/s10846-019-01018-w													
J								A Decorrelated Distributed EKF-SLAM System for the Autonomous Navigation of Mobile Robots	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										SLAM system; Distributed structure; Heading information; EKF; Decorrelation	SIMULTANEOUS LOCALIZATION; FILTERS	This paper proposes a novel distributed EKF-SLAM system that combines the advantages of EKF-SLAM and distributed SLAM systems. The system model of this novel SLAM system has a distributed structure, and each subsystem is a special SLAM system corresponding to every effectively observed landmark by feeding the heading information from a magnetic compass is introduced into the observation equation. Aim at the correlation problem in distributed SLAM system, a decorrelated distributed EKF (DDEKF) was developed to estimate the robot pose and landmarks. DDEKF reconstructs and extends the maximum allocation covariance (MAC) method so that it can be applied to the distributed structure where the number of local filters is dynamically changed. Then, the local filter estimation results are weighted and fused in the main filter to obtain the estimation result. Finally, the experimental tests were performed in an outdoor environment, and the experiment results demonstrate that the proposed novel distributed EKF-SLAM system has a better performance than the existing SLAM system.																	0921-0296	1573-0409				JUN	2020	98	3-4					819	829		10.1007/s10846-019-01069-z													
J								A deep analysis on optimization techniques for appropriate PID tuning to incline efficient artificial pancreas	NEURAL COMPUTING & APPLICATIONS										GA; GSA; PSO; SRA; BSOA; CTOA; GWOA; Optimization; PID controllers	SOFT COMPUTING METHODOLOGIES; ALGORITHM	Juvenile diabetes or a type-1 diabetic can be seen in 5% of the patients, who affected by this form of the disease. The type-1 diabetic can be seen mostly in children and young adults, which continue to spread all over the world. The developments of the artificial pancreas give hope to develop glucose monitoring sensors and insulin pump for those who suffer from severe lack of insulin generation. On the other hand, taking control of blood sugar is a challenging task in which specific factors of the body will limit the ability of closed-loop systems to perform well. This paper presents an investigation of the optimized control strategy to deal with the closed-loop artificial pancreas, which is based on the proportional-integral-derivative (PID). The primary objective of this investigation is to find the best optimized model to maintain the best glucose monitoring and insulin delivery. In order to tune the PID controller to decide on the efficient insulin injection, an investigation was conducted for an optimization algorithm [such as genetic algorithm, gravitational search algorithm, particle swarm optimization, sequential randomized algorithm, brain storm optimization algorithm, class topper optimization, and gray wolf optimization algorithm (GWOA)]. Among these, it is found that the GWOA gives a promising result compare to the other.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7587	7596		10.1007/s00521-018-3687-7													
J								Evolving neuro-fuzzy network for real-time high impedance fault detection and classification	NEURAL COMPUTING & APPLICATIONS										Evolving intelligence; Neuro-fuzzy; Power distribution system; Fault detection	DATA STREAMS; IDENTIFICATION; TRANSFORM	This paper concerns the application of a neuro-fuzzy learning method based on data streams for high impedance fault (HIF) detection in medium-voltage power lines. A wavelet-packet-transform-based feature extraction method combined with a variation of evolving neuro-fuzzy network with fluctuating thresholds is considered for recognition of spatial-temporal patterns in the data. Wavelet families such as Haar, Symlet, Daubechie, Coiflet and Biorthogonal were investigated as a way to provide the most discriminative features for fault detection. The proposed evolving neuro-fuzzy classification model has shown to be particularly suitable for the problem because the HIF environment is subject to concept changes. Different from other statistical and intelligent approaches to the problem, the developed neuro-fuzzy model for HIF classification is not only parametrically, but also structurally adaptive to cope with nonstationarities and novelties. New neurons and connections are incrementally added to the neuro-fuzzy network when necessary for the identification of new patterns, such as faults and usual transients including sag, swell and spikes due to the switching of 3-phase capacitors and energization of transformers. Experimental evaluations compare the proposed classifier with other well-established computational intelligence methods, viz. multilayer perceptron neural network, learning vector quantization neural network and a support vector machine model. Results have shown that the evolving neuro-fuzzy system is effective and robust to changes. The system is able to maintain its detection and classification accuracy even in situations in which other classifiers exhibit a significant drop in accuracy due to gradual and abrupt changes of the fault patterns. Fuzzy rules are useful for interpretability purposes and help to enhance model credibility for decision making.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7597	7610		10.1007/s00521-018-3789-2													
J								EEG data analysis with stacked differentiable neural computers	NEURAL COMPUTING & APPLICATIONS										Deep Learning (DL); Differentiable neural computer (DNC); Electroencephalogram (EEG); Stacked DNCs	VIGILANCE; TOPOGRAPHY; ATTENTION; NETWORK	Differentiable neural computer (DNC) has demonstrated remarkable capabilities in solving complex problems. In this paper, we propose to stack an enhanced version of differentiable neural computer together to extend its learning capabilities. Firstly, we give an intuitive interpretation of DNC to explain the architectural essence and demonstrate the stacking feasibility by contrasting it with the conventional recurrent neural network. Secondly, the architecture of stacked DNCs is proposed and modified for electroencephalogram (EEG) data analysis. We substitute the original Long Short-Term Memory network controller by a recurrent convolutional network controller and adjust the memory accessing structures for processing EEG topographic data. Thirdly, the practicability of our proposed model is verified by an open-sourced EEG dataset with the highest average accuracy achieved; then after fine-tuning the parameters, we show the minimal mean error obtained on a proprietary EEG dataset. Finally, by analyzing the behavioral characteristics of the trained stacked DNCs model, we highlight the suitableness and potential of utilizing stacked DNCs in EEG signal processing.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7611	7621		10.1007/s00521-018-3879-1													
J								Feature selection generating directed rough-spanning tree for crime pattern analysis	NEURAL COMPUTING & APPLICATIONS										Data mining; Feature selection; Rough set theory; Relative indiscernibility relation; Minimal spanning tree; Classification; Crime pattern analysis	SET-THEORY; COMMUNITY STRUCTURE; MUTUAL INFORMATION; CLASSIFICATION; NETWORK; MODEL	Nowadays, crime is a major threat to the society that affects the normal life of human beings all over the world. It is very important to make the world free from all aspects of crime activities. The main motivation of this work is to understand various crime patterns for avoiding and preventing the crime events to occur in future and save the world from such curse. Though research is going on for solving such problems, no work is noticed to handle the roughness or ambiguity that exists in the crime reports. The present work extracts all possible crime features from the crime reports and selects only the important features required for crime pattern analysis. For this purpose, it develops a purely supervised feature selection model integrating rough set theory and graph theory (spanning tree of a directed weighted graph). The crime reports are preprocessed, and crime features are extracted to represent each report as a feature vector (i.e., a set of distinct crime features). For crime pattern analysis, the main objective of our work, all extracted features are not necessarily essential, rather a minimal subset of relevant features are sufficient. Thus, feature selection is the main contribution in the paper that not only enhances the efficiency of subsequent mining process but also increases its correctness. The rough set theory-based relative indiscernibility relation is defined to measure the similarity between two features relative to the crime type. Based on the similarity score, a weighted and directed graph has been constructed that comprises the features as nodes and the inverse of the similarity score representing the similarity of featurevtouas the weight of the corresponding edge. Then, a minimal spanning tree (termed as rough-spanning tree) is generated using Edmond/Chu-Liu algorithm from the constructed directed graph and the importance of the nodes in the spanning tree is measured using the weights of the edges and the degrees (in-degrees and out-degrees) of the nodes in the spanning tree. Finally, a feature selection algorithm has been proposed that selects the most important node and remove it from the spanning tree iteratively until the modified graph (not necessarily a tree) becomes a null graph. The selected nodes are considered as the important feature subset sufficient for crime pattern analysis. The method is evaluated using various statistical measures and compared with related state-of-the-art methods to express its effectiveness in crime pattern analysis. The Wilcoxon rank-sum test, a popular nonparametric version of the two-samplettest, is done to express that the proposed supervised model is statistically significant.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7623	7639		10.1007/s00521-018-3880-8													
J								An interval-valued Pythagorean prioritized operator-based game theoretical framework with its applications in multicriteria group decision making	NEURAL COMPUTING & APPLICATIONS										Interval-valued Pythagorean fuzzy sets; Game theory; Multicriteria group decision making; Priority level	CONSENSUS; SELECTION; NETWORKS; DYNAMICS	Multicriteria decision-making process explicitly evaluates multiple conflicting criteria in decision making. The conventional decision-making approaches assumed that each agent is independent, but the reality is that each agent aims to maximize personal benefit which causes a negative influence on other agents' behaviors in a real-world competitive environment. In our study, we proposed an interval-valued Pythagorean prioritized operator-based game theoretical framework to mitigate the cross-influence problem. The proposed framework considers both prioritized levels among various criteria and decision makers within five stages. Notably, the interval-valued Pythagorean fuzzy sets are supposed to express the uncertainty of experts, and the game theories are applied to optimize the combination of strategies in interactive situations. Additionally, we also provided illustrative examples to address the application of our proposed framework. In summary, we provided a human-inspired framework to represent the behavior of group decision making in the interactive environment, which is potential to simulate the process of realistic humans thinking.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7641	7659		10.1007/s00521-019-04014-1													
J								Intelligent e-learning system based on fuzzy logic	NEURAL COMPUTING & APPLICATIONS										Fuzzy cognitive maps; Fuzzy rules; Fuzzy sets; Adaptive instruction		In this technological world demanding latest updations in the domain knowledge, it is no surprise that e-learning has become a more viable option to a range of people from beginners to get knowledged and the experts to get updated in a particular domain. Nevertheless, the evolution of e-learning systems is yet to provide full adaptability to the e-learners due to several weaknesses in the systems. Normally, e-learners have varying degrees of progress in their respective learning methodology. Over a period of time, this affects the e-learners performance while providing the same course to all e-learner. Hence, there is a need to create the adaptive e-learning environment to offer the appropriate e-learning contents to all the e-learners. This proposed work puts forth a fuzzy-based novel, intelligent and adaptive e-learning context for a programming language and offers appropriate domain contents to the e-learners which shall update the e-learners better than the previous works. The dependency relation among the concepts in the programming language is provided using fuzzy cognitive map which in turn paves the way for the development of the existing e-learning system. The fuzzy sets and the fuzzy rules represent the e-learners knowledge level and help in providing appropriate recommendations for the previous and subsequent related concepts in a fuzzy cognitive map. Evaluations of the proposed intelligent e-learning system provide promising results in the precise categorization of e-learners and to find their true knowledge.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7661	7670		10.1007/s00521-019-04087-y													
J								A framework for crime data analysis using relationship among named entities	NEURAL COMPUTING & APPLICATIONS										Crime analysis; Online news; Entity recognition; Relation extraction; Paraphrase extraction; Graph-based clustering		Many crime reports are available online in various blogs and Newswire. Though manual annotation of these massive reports is quite tedious for crime data analysis, it gives an overall crime scenario of all over the world. This motivates us to propose a framework for crime data analysis based on the online reports. Initially, the method extracts the crime reports and identifies named entities. The intermediate sequence of context words between every consecutive pair of named entities is termed as a crime vector that provides relationships between the entities. The feature vectors for each entity pair are generated from these crime vectors using the Word2Vec model. The paper considers three different types of named entity pairs to facilitate the major crime data analysis task, and for each type, similarity between every pair of entities is measured using respective feature vectors. For each type of named entity pair, a separate weighted graph is generated with entity pairs as vertices and similarity score between them as the weight of the corresponding edge. Then, Infomap, a graph-based clustering algorithm, is applied to obtain optimal set of clusters of entity pairs and a representative entity pair of each cluster. Each cluster is labelled by the relationship, represented by the crime vector, of its representative entity pair. In reality, all the entity pairs in a cluster may not reflect contextual similarity with their representative entity pair. So the clusters are further partitioned into subclusters based on WordNet-based path similarity measure which makes the entity pairs in each subcluster more contextually similar compared to their original cluster. These subclusters provide us various statistical crime information over the time period. The method is experimented only using the crime reports related to crime against women in India. The experimental results demonstrate the effectiveness and superiority of the method compared to others for analysing the crime data.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7671	7689		10.1007/s00521-019-04150-8													
J								Groundwater level forecasting using soft computing techniques	NEURAL COMPUTING & APPLICATIONS										Forecasting; Groundwater level; Artificial neural network; Support vector machine; Genetic programming; Extreme learning machine	ARTIFICIAL NEURAL-NETWORK; EXTREME LEARNING-MACHINE; WATER LEVELS; PREDICTION; FLUCTUATIONS; HYBRID; MODELS; SVM	Knowledge of groundwater level is very important in studies dealing with utilization and management of groundwater supply. Earlier studies have reported that ELM performs better than SVM for groundwater level prediction. This has been verified by comparing the prediction of groundwater levels at six locations in the district of Vizianagaram, Andhra Pradesh, using ANN, GP, SVM and ELM. Based on the comparison, it is observed that the performance of ELM is the best compared to other models. ELM is capable of predicting the nonlinear behavior of the groundwater levels. SVM performs better than GP and ANN. The performance of GP and ANN is analogous. Furthermore, an attempt has been made to enhance the performance of SVM by using SVM hybrid models such as SVM-QPSO and SVM-RBF, and the same has been compared with SVM and ELM. Results indicate that the performance of SVM-QPSO is far better compared to the performance of SVM and SVM-RBF. Moreover, performance of ELM is observed to be the best, but on some occasions, SVM-QPSO performs on par with ELM.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7691	7708		10.1007/s00521-019-04234-5													
J								A hybrid firefly algorithm with particle swarm optimization for energy efficient optimal cluster head selection in wireless sensor networks	NEURAL COMPUTING & APPLICATIONS										Wireless Sensor Networks; LEACH-C Algorithm; Firefly Algorithm (FA); Particle Swarm Optimization (PSO); Network lifetime; Energy consumption	PROTOCOL; LOCALIZATION; ARCHITECTURE; MEMORY	Wireless Sensor Networks (WSN) are operated on battery source, and the sensor nodes are used for collecting the information from the environment and transmitting the same to the base station. The sensor nodes consume more energy for the process of data communication and also affect the network lifetime. Energy efficiency is one of the important features for designing the sensor networks. Clustering technique is mainly used to perform the energy-efficient data transmission that consumes the minimum energy and also prolongs the lifetime of the network. In this paper, a Hybrid approach of Firefly Algorithm with Particle Swarm Optimization (HFAPSO) is proposed for finding the optimal cluster head selection in the LEACH-C algorithm. The hybrid algorithm improves the global search behavior of fireflies by using PSO and achieves optimal positioning of the cluster heads. The performance of the proposed methodology is evaluated by using the number of alive nodes, residual energy and throughput. The results show the improvement in network lifetime, thus increasing the alive nodes and reducing the energy utilization. While making a comparison with the firefly algorithm, it has been found that the proposed methodology has achieved better throughput and residual energy.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7709	7723		10.1007/s00521-019-04441-0													
J								Density-based semi-supervised online sequential extreme learning machine	NEURAL COMPUTING & APPLICATIONS										Semi-supervised learning; Extreme learning machine; Online sequential learning; Fast density clustering	ALGORITHM	This paper proposes a density-based semi-supervised online sequential extreme learning machine (D-SOS-ELM). The proposed method can realize online learning of unlabeled samples chunk by chunk. Local density and distance are used to measure the similarity of patterns, and the patterns with high confidence are selected by the 'follow' strategy for online learning, which can improve the accuracy of learning. Through continuous patterns selection, the proposed method ultimately achieves effective learning of unlabeled patterns. Furthermore, using local density and relative distance can effectively respond to the relationship between patterns. Compared with the traditional distance-based similarity measure, the ability to deal with complex data is improved. Empirical study on several standard benchmark data sets demonstrates that the proposed D-SOS-ELM model outperforms state-of-art methods in terms of accuracy.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7747	7758		10.1007/s00521-019-04066-3													
J								A distant supervision method based on paradigmatic relations for learning word embeddings	NEURAL COMPUTING & APPLICATIONS										Neural network; Word embedding; Text classification; Sentence matching		Word embeddings learned on external resources have succeeded in improving many NLP tasks. However, existing embedding models still face challenges in situations where fine-gained semantic information is required, e.g., distinguishing antonyms from synonyms. In this paper, a distant supervision method is proposed to guide the training process by introducing semantic knowledge in a thesaurus. Specifically, the proposed model shortens the distance between target word and its synonyms by controlling the movements of them in both unidirectional and bidirectional, yielding three different models, namelyUnidirectional Movement of Target Model(UMT),Unidirectional Movement of Synonyms Model(UMS) andBidirectional Movement of Target and Synonyms Model(BMTS). Extensive computational experiments have been conducted, and results are collected for analysis purpose. The results show that the proposed models not only efficiently capture semantic information of antonyms but also achieve significant improvements in both intrinsic and extrinsic evaluation tasks. To validate the performance of the proposed models (UMT, UMS and BMTS), results are compared against well-known models, namelySkip-gram,JointRCM,WE-TDanddict2vec. The performances of the proposed models are evaluated on four tasks (benchmarks):word analogy(intrinsic),synonym-antonym detection(intrinsic),sentence matching(extrinsic) andtext classification(extrinsic). A case study is provided to illustrate the working of the proposed models in an effective manner. Overall, a distant supervision method based on paradigmatic relations is proposed for learning word embeddings and it outperformed when compared against other existing models.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7759	7768		10.1007/s00521-019-04071-6													
J								Fault coverage-based test suite optimization method for regression testing: learning from mistakes-based approach	NEURAL COMPUTING & APPLICATIONS										Regression testing; Software maintenance; Heuristics; Greedy; Additional Greedy; HGS; Enhanced HGS	TEST-CASE PRIORITIZATION; TEST SELECTION; ALGORITHMS; SOFTWARE	This paper presents a novel method referred as fault coverage-based test suite optimization (FCBTSO) for regression test suite optimization. FCBTSO is proposed based on Harrolds-Gupta-Soffa (HGS) test suite reduction method, and it follows the phenomenon: "learning from mistakes". We conducted computational experiments on 12 versions of benchmarked programs retrieved from software artefact infrastructure repository and dummy fault matrix test. The performance of the proposed FCBTSO is measured against the traditional test suite reduction methods (Greedy method, Additional Greedy, HGS, and Enhanced HGS) by following the performance measures: fault coverage, execution time and reduced optimized test suite size. Rigorous statistical tests are conducted to determine the performance significance, which indicates that FCBTSO outperforms other approaches implemented with respect to the execution time that includes the execution time of the proposed approach to find the optimized test suite and the execution time of test cases in the optimized test suite.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7769	7784		10.1007/s00521-019-04098-9													
J								Lessons learned from longitudinal modeling of mobile-equipped visitors in a complex museum	NEURAL COMPUTING & APPLICATIONS										User behaviors; User modeling; Unsupervised classification; Data analysis; Data mining; Internet of things	SELECTION; MOVEMENT; BEHAVIOR; TRACKING	Cultural sites are evolving toward smart environments, including the notion of hyper-connected museums. In this context, stakeholders of cultural assets need more advanced and comprehensive ICT systems for monitoring and modeling visitors behaviors. In this paper, we discuss the results of a longitudinal research study embracing multiple seasons, in a complex cultural structure including outdoor and indoor attractions, multiple floors and multiple routes for visitors. Here, interactive mobile devices were used for both offering multimedial context-aware assistance to visitors and monitoring services to museum stakeholders. We deeply analyzed the data using an unsupervised classification approach, obtaining a model where the number of distinct user profiles and the number of features were considered not trivial as well as not too complex for museum stakeholders. We observed that some optimistic expectations about visitor performances were only partially met, devising possible explanations in terms of the different user profiles and features of the model. Finally, we also compared some outcomes from our interactive system with those obtained in another complex cultural structure using a noninvasive monitoring system.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7785	7801		10.1007/s00521-019-04099-8													
J								Analysis of Boolean functions based on interaction graphs and their influence in system biology	NEURAL COMPUTING & APPLICATIONS										Boolean functions; Boolean networks; Interaction graphs; Singleton attractors; Classification	GENETIC REGULATORY NETWORKS; ROBUST STABILITY; STEADY-STATES; MODELS; REDUCTION; CYCLES	Biological regulatory network can be modeled through a set of Boolean functions. These set of functions enable graph representation of the network structure, and hence, the dynamics of the network can be seen easily. In this article, the regulations of such network have been explored in terms of interaction graph. With the help of Boolean function decomposition, this work presents an approach for construction of interaction graphs. This decomposition technique is also used to reduce the network state space of the cell cycle network of fission yeast for finding the singleton attractors. Some special classes of Boolean functions with respect to the interaction graphs have been discussed. A unique recursive procedure is devised which uses the Cartesian product of sets starting from the set of one-variable Boolean function. Interaction graphs generated with these Boolean functions have only positive/negative edges, and the corresponding state spaces have periodic attractors with length one/two.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7803	7821		10.1007/s00521-019-04102-2													
J								Improved prediction of daily pan evaporation using Deep-LSTM model	NEURAL COMPUTING & APPLICATIONS										Evaporation estimation; Deep-LSTM; MLANN; Empirical methods; ACZs	NEURAL-NETWORKS; CLASSIFICATION; ALGORITHM; INFERENCE; LAKE	Precise measurement or estimation of evaporation losses is extremely important for the development of water resource management strategies and its effective implementation, particularly in drought-prone areas for increasing agricultural productivity. Evaporation can either be measured directly using evaporimeters, or it can be estimated by means of empirical models with the help of climatic factors influencing evaporation process. In general, variations in climatic factors such as temperature, humidity, wind speed, sunshine and solar radiation influence and control the evaporation process to a great extent. Due to the highly nonlinear nature of evaporation phenomenon, it is invariably very difficult to model the evaporation process through climatic factors especially in diverse agro-climatic situations. The present investigation is carried out to examine the potential of deep neural network architecture with long short-term memory cell (Deep-LSTM) to estimate daily pan evaporation with minimum input features. Depending upon the availability of climatic data Deep-LSTM models with different input combinations are proposed to model daily evaporation losses in three agro-climatic zones of Chhattisgarh state in east-central India. The performance of the proposed Deep-LSTM models are compared with commonly used multilayer artificial neural network and empirical methods (Hargreaves and Blaney-Criddle). The results of the investigations in terms of various performance evaluation criteria reveal that the proposed Deep-LSTM structure is able to successfully model the daily evaporation losses with improved accuracy as compared to other models considered in this study.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7823	7838		10.1007/s00521-019-04127-7													
J								A wrapper-filter feature selection technique based on ant colony optimization	NEURAL COMPUTING & APPLICATIONS										Wrapper-filter method; Ant colony optimization; Feature selection; NIPS2003 challenge	NATURE-INSPIRED ALGORITHM; GENE SELECTION	Ant colony optimization (ACO) is a well-explored meta-heuristic algorithm, among whose many applications feature selection (FS) is an important one. Most existing versions of ACO are either wrapper based or filter based. In this paper, we propose a wrapper-filter combination of ACO, where we introduce subset evaluation using a filter method instead of using a wrapper method to reduce computational complexity. A memory to keep the best ants and feature dimension-dependent pheromone update has also been used to perform FS in a multi-objective manner. Our proposed approach has been evaluated on various real-life datasets, taken from UCI Machine Learning repository and NIPS2003 FS challenge, using K-nearest neighbors and multi-layer perceptron classifiers. The experimental outcomes have been compared to some popular FS methods. The comparison of results clearly shows that our method outperforms most of the state-of-the-art algorithms used for FS. For measuring the robustness of the proposed model, it has been additionally evaluated on facial emotion recognition and microarray datasets.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7839	7857		10.1007/s00521-019-04171-3													
J								Hybrid intrusion detection and signature generation using Deep Recurrent Neural Networks	NEURAL COMPUTING & APPLICATIONS										Deep learning; Intrusion Detection System; LSTM; Attack detection; Signature generation; Machine learning; Web attacks; Zero-day attack	LEARNING APPROACH	Automated signature generation for Intrusion Detection Systems (IDSs) for proactive security of networks is a promising area of research. An IDS monitors a system or activities of a network for detecting any policy violations or malicious actions and produces reports to the management system. Numerous solutions have been proposed by various researchers so far for intrusion detection in networks. However, the need to efficiently identifying any intrusion in the network is on the rise as the network attacks are increasing exponentially. This research work proposes a deep learning-based system for hybrid intrusion detection and signature generation of unknown web attacks referred as D-Sign. D-Sign is capable of successfully detecting and generating attack signatures with high accuracy, sensitivity and specificity. It has been for attack detection and signature generation of web-based attacks. D-Sign has reported significantly low False Positives and False Negatives. The experimental results demonstrated that the proposed system identifies the attacks proactively than other state-of-the-art approaches and generates signatures effectively thereby causing minimum damage due to network attacks.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7859	7877		10.1007/s00521-019-04187-9													
J								Understanding NFC-Net: a deep learning approach to word-level handwrittenIndicscript recognition	NEURAL COMPUTING & APPLICATIONS										NFC-Net; Script recognition; Handwritten words; Convolutional neural network; Indicscripts	SCRIPT IDENTIFICATION; SEGMENTATION; FEATURES; SYSTEM	This paper presents a deep learning architecture modified for resource-constrained environments, calledNon-Fully-Connected Networkor NFC-Net, based on convolutional neural network architecture in order to solve the problem ofIndicscript recognition from handwritten word images. NFC-Net mainly targets resource constraint environment where there is a limited computation power or inadequate training samples or restricted training time. Previous approaches to handwritten script recognition included handcrafted features such as structure-based features and texture-based features. In contrast, here our model learns relatively different features from raw input pixels using NFC-Net. Various parameters of the NFC-Net are adjusted to present a vast and comprehensive study of the neural net in the domain of handwritten script recognition. In order to evaluate the performance of the NFC-Net with suitable parameter estimation, a dataset of 18,000 handwritten multiscript word images consisting of 1500 text words from each of the 12 officially recognizedIndicscripts has been considered and a maximum script recognition accuracy of 96.30% is noted. Our proposed model also performs better than some of the recently published script recognition methods in bi-script, tri-script, tetra-script and 12-script scenarios. It has been additionally tested on the RaFD and BHCCD datasets with improved results to prove dataset independency of our model.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7879	7895		10.1007/s00521-019-04235-4													
J								Genetic algorithm-optimized multi-channel convolutional neural network for stock market prediction	NEURAL COMPUTING & APPLICATIONS										Convolutional neural network; Genetic algorithm; Deep learning; Stock market prediction	TERM-MEMORY NETWORKS; FEATURE-SELECTION; MODEL; ARCHITECTURE; DESIGN; SYSTEM	Recently, artificial intelligence technologies have received considerable attention because of their practical applications in various fields. The key factor in this prosperity is deep learning which is inspired by the information processing in biological brains. In this study, we apply one of the representative deep learning techniques multi-channel convolutional neural networks (CNNs) to predict the fluctuation of the stock index. Furthermore, we optimize the network topology of CNN to improve the model performance. CNN has many hyper-parameters that need to be adjusted for constructing an optimal model that can learn the data patterns efficiently. In particular, we focus on the optimization of feature extraction part of CNN, because this is the most important part of the computational procedure of CNN. This study proposes a method to systematically optimize the parameters for the CNN model by using genetic algorithm (GA). To verify the effectiveness of our model, we compare the prediction result with standard artificial neural networks (ANNs) and CNN models. The experimental results show that the GA-CNN outperforms the comparative models and demonstrate the effectiveness of the hybrid approach of GA and CNN.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7897	7914		10.1007/s00521-019-04236-3													
J								Recurrent neural network with attention mechanism for language model	NEURAL COMPUTING & APPLICATIONS										Language model; Recurrent neural network; Artificial intelligence; Attention mechanism		The rapid growth of the Internet promotes the growth of textual data, and people get the information they need from the amount of textual data to solve problems. The textual data may include some potential information like the opinions of the crowd, the opinions of the product, or some market-relevant information. However, some problems that point to "How to get features from the text" must be solved. The model of extracting the text features by using the neural network method is called neural network language model. The features are based onn-gram Model concept, which are the co-occurrence relationship between the vocabularies. The word vectors are important because the sentence vectors or the document vectors still have to understand the relationship between the words, and based on this, this study discusses the word vectors. This study assumes that the words contain "the meaning in sentences" and "the position of grammar." This study uses recurrent neural network with attention mechanism to establish a language model. This study uses Penn Treebank, WikiText-2, and NLPCC2017 text datasets. According to these datasets, the proposed models provide the better performance by the perplexity.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7915	7923		10.1007/s00521-019-04301-x													
J								Hybrid optimization scheme for intrusion detection using considerable feature selection	NEURAL COMPUTING & APPLICATIONS										Intrusion detection; AABC; APSO; Support vector machine; Hybrid optimization scheme	ARTIFICIAL BEE COLONY; ALGORITHM	The intrusion detection is an essential section in network security because of its immense volume of threats which bothers the computing systems. The real-time intrusion detection dataset comprises redundant or irrelevant features. The duplicate features make it quite challenging to locate the patterns for intrusion detection. Hybrid optimization scheme (HOS) is designed for combining adaptive artificial bee colony (AABC) with adaptive particle swarm optimization (APSO) for detecting intrusive activities. The schemes are aggregated for locating improved optimization-based outcomes, and the precision during categorization is acquired using tenfold cross-validation scheme. The main objective of the proposed method is to improve the rate of precision in intrusion activities in internetwork by choosing the relevant features. Effectiveness of the hybrid categorization scheme is accessed using an NSL-KDD dataset. Single feature selection method and random feature selection method are used to assess the proposed HOS intrusion detection approaches. The effectiveness of the designed scheme is evaluated with existing machine learning schemes such as Naive Bayes, AABC, APSO, and support vector machine, which outperform the HOS.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7925	7939		10.1007/s00521-019-04477-2													
J								Deep learning-based sign language recognition system for static signs	NEURAL COMPUTING & APPLICATIONS										Sign language; Data acquisition; Convolutional neural network; Max-pooling; Softmax; Optimizer	GESTURE; HAND	Sign language for communication is efficacious for humans, and vital research is in progress in computer vision systems. The earliest work in Indian Sign Language (ISL) recognition considers the recognition of significant differentiable hand signs and therefore often selecting a few signs from the ISL for recognition. This paper deals with robust modeling of static signs in the context of sign language recognition using deep learning-based convolutional neural networks (CNN). In this research, total 35,000 sign images of 100 static signs are collected from different users. The efficiency of the proposed system is evaluated on approximately 50 CNN models. The results are also evaluated on the basis of different optimizers, and it has been observed that the proposed approach has achieved the highest training accuracy of 99.72% and 99.90% on colored and grayscale images, respectively. The performance of the proposed system has also been evaluated on the basis of precision, recall andF-score. The system also demonstrates its effectiveness over the earlier works in which only a few hand signs are considered for recognition.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7957	7968		10.1007/s00521-019-04691-y													
J								Genetic programming-assisted multi-scale optimization for multi-objective dynamic performance of laminated composites: the advantage of more elementary-level analyses	NEURAL COMPUTING & APPLICATIONS										Multi-scale optimization; Machine learning-based optimization; Genetic programming; Symbolic regression; d-Optimal design; Robust composite structures	FREE-VIBRATION ANALYSIS; STACKING-SEQUENCE OPTIMIZATIONS; STOCHASTIC NATURAL FREQUENCY; SHEAR DEFORMATION-THEORY; RESPONSE-SURFACE; SANDWICH PLATES; NEURAL-NETWORKS; BUCKLING ANALYSIS; DESIGN; UNCERTAINTY	High-fidelity multi-scale design optimization of many real-life applications in structural engineering still remains largely intractable due to the computationally intensive nature of numerical solvers like finite element method. Thus, in this paper, an alternate route of metamodel-based design optimization methodology is proposed in multi-scale framework based on a symbolic regression implemented using genetic programming (GP) coupled withd-optimal design. This approach drastically cuts the computational costs by replacing the finite element module with appropriately constructed robust and efficient metamodels. Resulting models are compact, have good interpretability and assume a free-form expression capable of capturing the non-linearly, complexity and vastness of the design space. Two robust nature-inspired optimization algorithms, viz. multi-objective genetic algorithm and multi-objective particle swarm optimization, are used to generate Pareto optimal solutions for several test problems with varying complexity. TOPSIS, a multi-criteria decision-making approach, is then applied to choose the best alternative among the Pareto optimal sets. Finally, the applicability of GP in efficiently tackling multi-scale optimization problems of composites is investigated, where a real-life scenario is explored by varying fractions of pertinent engineering materials to bring about property changes in the final composite structure across two different scales. The study reveals that a microscale optimization leads to better optimized solutions, demonstrating the advantage of carrying out a multi-scale optimization without any additional computational burden.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7969	7993		10.1007/s00521-019-04280-z													
J								Prediction of fresh and hardened properties of self-compacting concrete using support vector regression approach	NEURAL COMPUTING & APPLICATIONS										Support vector regression; Kernel functions; Self-compacting concrete; Compressive strength	ARTIFICIAL NEURAL-NETWORK; HIGH-STRENGTH CONCRETE; COMPRESSIVE STRENGTH; SILICA FUME; FLY-ASH; MECHANICAL-PROPERTIES; ELASTIC-MODULUS; MACHINE; MODELS; GEOPOLYMERS	This article presents the feasibility of using support vector regression (SVR) technique to determine the fresh and hardened properties of self-compacting concrete. Two different kernel functions, namely exponential radial basis function (ERBF) and radial basis function (RBF), were used to develop the SVR model. An experimental database of 115 data samples was collected from different literatures to develop the SVR model. The data used in SVR model have been organized in the form of six input parameters that covers dosage of binder content, fly ash, water-powder ratio, fine aggregate, coarse aggregate and superplasticiser. The above-mentioned ingredients have been taken as input variables, whereas slump flow value, L-box ratio, V-funnel time and compressive strength have been considered as output variables. The obtained results indicate that the SVR-ERBF model outperforms SVR-RBF model for learning and predicting the experimental data with the highest value of the coefficient of correlation (R) equal to 0.965, 0.954, 0.979 and 0.9773 for slump flow, L-box ratio, V-funnel and compressive strength, respectively, with small values of statistical errors. Also, the efficiency of SVR model is compared to artificial neural network (ANN) and multivariable regression analysis (MVR). In addition, a sensitivity analysis was also carried out to determine the effects of various input parameters on output. This study indicates that SVR-ERBF model can be used as an alternative approach in predicting the properties of self-compacting concrete.																	0941-0643	1433-3058				JUN	2020	32	12			SI		7995	8010		10.1007/s00521-019-04267-w													
J								Short-term solar power prediction using multi-kernel-based random vector functional link with water cycle algorithm-based parameter optimization	NEURAL COMPUTING & APPLICATIONS										Solar power forecasting; Multi-kernel random vector functional link neural network (MK-RVFLN); Evaporation-based water cycle algorithm (EVWCA)	PARTICLE SWARM OPTIMIZATION; NEURAL-NETWORK; MODEL; SELECTION; SYSTEM	A new hybrid model combining the kernel functions along with the random vector functional link neural network (RVFLN) is proposed in this paper for an effective solar power prediction. The conventional RVFLN is known for its fast learning speed, simple architecture and good generalization capabilities and allows direct connection between input and output nodes along with nonlinear enhancement nodes with random weights. However, the bottleneck of selecting the number of hidden enhancement nodes and mapping functions is still a challenging problem. To overcome these deficiencies of the conventional RVFLN, kernel functions are used for both the direct links and the hidden nodes to provide better stability, generalization and regression accuracy. Instead of using a single kernel for the enhancement nodes, this paper proposes an optimal kernel function that comprises a linear combination of weighted local kernel and a global kernel to improve the prediction accuracy of the solar power generation. This optimal kernel will be known as multi-kernel RVFLN (MK-RVFLN), and its parameters are optimized using an efficient metaheuristic evaporation-based water cycle (EVWCA-MKRVFLN) to provide accurate prediction of solar power. To validate its superior prediction accuracy, two solar power plants of 25 and 100 MW capacity in the states of New York and California are considered for 5-min- and 60-min-ahead prediction in the months of January, April, July and October. The result analysis shows that the MK-RVFLN algorithm attains better performance than many other techniques.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8011	8029		10.1007/s00521-019-04290-x													
J								Approximate empirical kernel map-based iterative extreme learning machine for clustering	NEURAL COMPUTING & APPLICATIONS										Maximum margin clustering; Extreme learning machine; Approximate empirical kernel map; Kernel learning; Compact model	NYSTROM METHOD; MATRIX	Maximum margin clustering (MMC) is a recent approach of applying margin maximization in supervised learning to unsupervised learning, aiming to partition the data into clusters with high discrimination. Recently, extreme learning machine (ELM) has been applied to MMC (called iterative ELM clustering or ELMCIter) which maximizes the data discrimination by iteratively training a weighted extreme learning machine (W-ELM). In this way, ELMC(Iter)achieves a substantial reduction in training time and provides a unified model for both binary and multi-class clusterings. However, there exist two issues in ELMCIter: (1) random feature mappings adopted in ELMC(Iter)are unable to well obtain high-quality discriminative features for clustering and (2) a large model is usually required in ELMC(Iter)because its performance is affected by the number of hidden nodes, and training such model becomes relatively slow. In this paper, the hidden layer in ELMC(Iter)is encoded by an approximate empirical kernel map (AEKM) rather than the random feature mappings, in order to solve these two issues. AEKM is generated from low-rank approximation of the kernel matrix, derived from the input data through a kernel function. Our proposed method is called iterative AEKM for clustering (AEKMC(Iter)), whose contributions are: (1) AEKM can extract discriminative and robust features from the kernel matrix so that better performance is always achieved in AEKMC(Iter)and (2) AEKMC(Iter)produces an extremely small number of hidden nodes for low memory consumption and fast training. Detailed experiments verified the effectiveness and efficiency of our approach. As an illustration, on the MNIST10 dataset, our approach AEKMC(Iter)improves the clustering accuracy over ELMC(Iter)up to 5%, while significantly reducing the training time and the memory consumption (i.e., the number of hidden nodes) up to 1/7 and 1/20, respectively.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8031	8046		10.1007/s00521-019-04295-6													
J								Detecting outliers in industrial systems using a hybrid ensemble scheme	NEURAL COMPUTING & APPLICATIONS										Outlier detection; Ensemble learning; Machine learning; Industrial system	SUPPORT	The massive growth of process data in industrial systems has promoted the development of data-driven techniques, while the presence of outliers in process data always deteriorates the effectiveness. This paper focuses on detecting outliers in industrial systems under the assumption that no labeled training data are available. Our method is on the basis of ensemble learning, and the base learners include both one-class classifiers and multi-class classifiers. The core idea is that one-class classifier ensemble model is used to address the problem of missing label, and the usage of multi-class classifier ensemble model is to further improve its performance when outlier examples are available. The essential motivation for this proposal is that results from a classifier trained using only positive data will not be as good as the results using both positive and negative data. We investigate the performance of the proposed scheme with a series of experiments. Ten benchmark data sets and two real-world industrial systems are used, and the results approve the performance of our detection scheme.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8047	8063		10.1007/s00521-019-04307-5													
J								Exploiting plaintext-related mechanism for secure color image encryption	NEURAL COMPUTING & APPLICATIONS										Image encryption; Color image; Chaotic system; Security analyses	DNA-SEQUENCE OPERATION; CHAOTIC SYSTEM; BROWNIAN-MOTION; S-BOXES; SCHEME; ALGORITHM; PERMUTATION; CRYPTOSYSTEM; EFFICIENT; CRYPTANALYSIS	Nowadays, many image cryptosystems have been cracked by chosen-plaintext attacks, for they are not highly sensitive to plain image. To solve this problem, we introduce a plaintext-related mechanism for secure color image encryption, and it is established in the generation and selection of chaotic sequences, permutation and diffusion. In the proposed image cryptosystem, the architecture of permutation and diffusion is adopted. Firstly, plaintext-related Latin-square-based block permutation is proposed to randomly shuffle pixels of the color plain image, diffusion method dependent on the plaintext and scrambled image is further given to modify pixels of permutated image, and finally cipher image is gotten. The chaotic sequence for diffusing the current pixel is dynamically generated according to the plain image and scrambled image, and diffusion operations of red, green and blue components of color plain image affect each other. Besides, chaotic sequences used in encryption are produced by new one-dimensional chaotic systems and dynamically selected, and initial values of chaotic systems are computed by plain image and external keys. Experimental results and security analyses demonstrate that our image encryption has large key space and high security level, and it can be applied for the secure communication of image information.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8065	8088		10.1007/s00521-019-04312-8													
J								Accelerating SGD using flexible variance reduction on large-scale datasets	NEURAL COMPUTING & APPLICATIONS										Optimization; Stochastic gradient descent; Variance reduction; Distributed; Neural Networks	STOCHASTIC METHODS; GRADIENT-METHOD	Stochastic gradient descent (SGD) is a popular optimization method widely used in machine learning, while the variance of gradient estimation leads to slow convergence. To accelerate the speed, many variance reduction methods have been proposed. However, most of these methods require additional memory cost or computational burden on full gradient, which results in low efficiency or even unavailable while applied to real-world applications with large-scale datasets. To handle this issue, we propose a new flexible variance reduction method for SGD, named FVR-SGD, which can reduce memory overhead and speed up the convergence using flexible subset without extra computation. We analyze the details of convergence property for our method, and linear convergence rate can be guaranteed while using flexible variance reduction. Some efficient variants for distributed environment and deep neural networks are also proposed in this paper. Several numerical experiments are conducted on a genre of real-world large-scale datasets. The experimental results demonstrated that FVR-SGD outperforms the currently popular algorithms. Specifically, the proposed method can achieve up to 40% reduction in the training time to solve the optimization problem of logistic regression, SVM and neural networks.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8089	8100		10.1007/s00521-019-04315-5													
J								A novel hybrid network of fusing rhythmic and morphological features for atrial fibrillation detection on mobile ECG signals	NEURAL COMPUTING & APPLICATIONS										Atrial fibrillation; Arrhythmia detection; Fully convolutional network; Residual network; Location of R peak position	OBSTRUCTIVE SLEEP-APNEA; P-WAVE DISPERSION; RISK	Atrial fibrillation (AF) is one of the most common arrhythmia diseases, the incidence of which is ascendant with age increase. What's more, AF is a high-risk factor for stroke, ischemia myocardial and other malignant cardiovascular diseases, which would threaten people's life significantly. Using a mobile device to screen AF segments is an effective way to reduce the mortality and morbidity of malignant cardiovascular diseases. However, most of existing AF detection methods mainly centered on clinical resting ECG signals and were incapable of processing mobile ECG signals with low signal-to-noise ratio which collected by mobile devices. In this paper, we take advantage of a fully convolutional network variant named U-Net for heart rhythmic information capturing by locating R peak positions as well as calculating RR intervals and a 34-layer residual network for waveform morphological features capturing from ECG signals. Combining both rhythmic information and waveform morphological features, two-layer fully connected networks are employed successively to discriminate AF, normal sinus rhythm , and other abnormal rhythm (other). The extensive experimental results show that our proposed AF our proposed AF screening framework named FRM-CNN can achieveF1value of 85.08 +/- 0.99% and accuracy of87.22 +/- 0.7 on identifying AF segments well without handcraft engineering. Compared with the cutting-edge AF detection methods, the FRM-CNN has more superior performance on monitoring people's health conditions with mobile devices.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8101	8113		10.1007/s00521-019-04318-2													
J								Neuro-fuzzy predictive model for surface roughness and cutting force of machined Al-20 Mg2Si-2Cu metal matrix composite using additives	NEURAL COMPUTING & APPLICATIONS										Machinability; Metal matrix composite; ANFIS; Additives	MECHANICAL-PROPERTIES; INFERENCE SYSTEM; MACHINABILITY CHARACTERISTICS; MICROSTRUCTURE; OPTIMIZATION; TEMPERATURE; ANTIMONY; BISMUTH; ALLOY	Today's metal matrix composites are widely used due to their excellent properties, which are useful for high-performance applications in the automotive and aerospace industries. Furthermore, improving the machinability of these composites is vital for improving product quality in the manufacturing process. In this research, various adaptive network-based fuzzy inference systems (ANFISs) were introduced to evaluate the effect of the feed rate, the cutting speed and the particle size on the machinability of Al-20 Mg2Si metal matrix composite. Two ANFIS models were selected as the most precise models for predicting surface roughness and cutting force. Results show that the proposed ANFIS models have an adequate accuracy in predicting the machinability of metal matrix composites.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8115	8126		10.1007/s00521-019-04314-6													
J								SRS-DNN: a deep neural network with strengthening response sparsity	NEURAL COMPUTING & APPLICATIONS										Deep neural network; Strengthening response sparsity; Sparse backpropagation algorithm; Unified residual formulae	RESTRICTED BOLTZMANN MACHINES; REPRESENTATIONS; REGULARIZATION; CONNECTIVITY	Inspired by the sparse mechanism of biological neural systems, an approach of strengthening response sparsity for deep learning is presented in this paper. Firstly, an unsupervised sparse pre-training process is implemented and a sparse deep network is begun to take shape. In order to avoid that all the connections of the network will be readjusted backward during the following fine-tuning process, for the loss function of the fine-tuning process, some regularization items which strength the sparse responsiveness are added. More importantly, the unified and concise residual formulae for network updating are deduced, which ensure the backpropagation algorithm to perform successfully. The residual formulae significantly improve the existing sparse fine-tuning methods such as which in sparse autoencoders by Andrew Ng. In this way, the sparse structure obtained in the pre-training can be maintained, and the sparse abstract features of data can be extracted effectively. Numerical experiments show that by this sparsity-strengthened learning method, the sparse deep neural network has the best classification performance among several classical classifiers; meanwhile, the sparse learning abilities and time complexity all are better than traditional deep learning methods.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8127	8142		10.1007/s00521-019-04309-3													
J								A modified discrete antlion optimizer for the ring star problem with secondary sub-depots	NEURAL COMPUTING & APPLICATIONS										Network optimization; Ring star problem; Median cycle problem; Discrete antlion optimizer	ALGORITHM	This paper introduces a new problem in the field of combinatorial optimization. This problem can be named as the ring star problem with secondary sub-depots (RSPSSD). RSPSSD has one fixed main depot, and it allows a network to be divided into three types of nodes, namely primary sub-depots (includes the main depot too), secondary sub-depots and left out nodes. The challenge of the problem is to select some primary and secondary sub-depots that minimize the total routing cost which has three components. The first one is the routing cost of the main circuit that covers all the primary sub-depots including the main depot. The second one is the total routing cost of all the secondary circuits, each of which covers a set of few secondary sub-depots and their nearest primary sub-depot. The secondary circuits also have a constraint on the number of secondary sub-depots in it. The last one is the assignment cost of the left out nodes to their nearest concentrators which is nothing but anyone from the main depot, primary or secondary sub-depots. The proposed RSPSSD problem is solved with the proposed modified discrete antlion optimizer and tested using some TSP benchmark instances. The random walk of an antlion and an ant is encoded with ternary number system. The statistical analysis and comparison of the result against some other algorithms are also presented. A real-life case study has also been shown to validate the proposed model and algorithm.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8143	8156		10.1007/s00521-019-04292-9													
J								Extreme learning machine with autoencoding receptive fields for image classification	NEURAL COMPUTING & APPLICATIONS										Local receptive field based extreme learning machine (ELM-LRF); ELM auto encoder (ELM-AE); Local receptive fields; Global receptive fields; Image classification	REGRESSION	Based on the theory of local receptive field based extreme learning machine (ELM-LRF) and ELM auto encoder (ELM-AE), a new network structure is proposed to take advantage of global attributes of image and output feature of each layer in the structure. This proposed network structure is called extreme learning machine with autoencoding receptive fields (ELM-ARF), which has two parts including convolution feature extraction and feature coding. In the convolution feature extraction part, local features are extracted using orthogonalized local receptive fields. The ELM-AE theory and local receptive fields are used to encode the global receptive fields, which is used to extract global features. The pooled global features and local features are combined and input into the next layer. In the feature coding part, the shallow layer feature can be input to any deep layer through the ELM-ARF connection structure. A series of encodings are performed on the combined features in each layer to achieve a nonlinear mapping relationship from input information to target categories. In order to verify the validity of the structure, ELM-ARF is tested on four classic databases: USPS, MNIST, NORB and CIFAR10. The experimental results show that ELM-ARF effectively improves image classification accuracy by encoding the combined features that contain global attributes.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8157	8173		10.1007/s00521-019-04303-9													
J								Memristive continuous Hopfield neural network circuit for image restoration	NEURAL COMPUTING & APPLICATIONS										Memristor; Circuit design; Hopfield neural network; Image restoration	RECOGNITION; FILTER	Image restoration (IR) methods based on neural network algorithms have shown great success. However, the hardware circuits that can perform real-time IR task with high-effective analog computation are few in the literature. To address such problem, we propose a memristor-based continuous Hopfield neural network (HNN) circuit for processing the IR task in this work. In our circuit, a single memristor crossbar array is used to represent synaptic weights and perform matrix operations. Current feedback operation amplifiers are utilized to achieve integral operation and output function. Given these designs, the proposed circuit can perform continuous recursive operations in parallel and process different optimization problems with the programmability of the memristor array. On the basis of the proposed circuit, binary and greyscale image restorations are conducted through self-organizing network operations, providing a hardware implementation platform for IR tasks. Comparative simulations show the designed HNN circuit provides effective improvements in terms of speed and accuracy compared with software simulation. Moreover, the hardware circuit shows good robustness to memristive variation and input noise.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8175	8185		10.1007/s00521-019-04305-7													
J								Graph constraint-based robust latent space low-rank and sparse subspace clustering	NEURAL COMPUTING & APPLICATIONS										Dimension reduction; Low-rank and sparse representation; Subspace clustering; Manifold clustering	SEGMENTATION; ALGORITHM	Recently, low-rank and sparse representation-based methods have achieved great success in subspace clustering, which aims to cluster data lying in a union of subspaces. However, most methods fail if the data samples are corrupted by noise and outliers. To solve this problem, we propose a novel robust method that uses the F-norm for dealing with universal noise and thel1norm or thel2,1norm for capturing outliers. The proposed method can find a low-dimensional latent space and a low-rank and sparse representation simultaneously. To preserve the local manifold structure of the data, we have adopted a graph constraint in our model to obtain a discriminative latent space. Extensive experiments on several face benchmark datasets show that our proposed method performs better than state-of-the-art subspace clustering methods.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8187	8204		10.1007/s00521-019-04317-3													
J								A novel modified whale optimization algorithm for load frequency controller design of a two-area power system composing of PV grid and thermal generator	NEURAL COMPUTING & APPLICATIONS										Automatic generation control (AGC); Multi-area multi-source power system; Modified whale optimization algorithm (MWOA); PIDF controller; PV grid	PATTERN SEARCH ALGORITHM; HYBRID GRAVITATIONAL SEARCH; TUNING DAMPING CONTROLLER; PID CONTROLLER; PARAMETERS	This paper proposes a modified approach to the original whale optimization algorithm which is a nature-inspired swarm-based optimization algorithm known as the modified whale optimization (MWOA) algorithm. The superiority of proposed modified algorithm over original algorithm in terms of implementation time and solution quality is compared by taking several benchmark test functions. Further, the real application of the said approach in the engineering field is carried out by designing a PID with derivative (PIDF) controller for frequency regulation of a the most realistic scenario of automatic generation control of a two-area interconnected power system composing of a PV grid and a thermal generator. It is observed that MWOA-based PIDF controller is more effective for the load frequency control compared to conventional PID controller.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8205	8216		10.1007/s00521-019-04321-7													
J								Solving a new cost-oriented assembly line balancing problem by classical and hybrid meta-heuristic algorithms	NEURAL COMPUTING & APPLICATIONS										Assembly line balancing problem; Meta-heuristic algorithm; Taguchi method; Hungarian method	SIMULATED ANNEALING ALGORITHM; ANT COLONY OPTIMIZATION; SEQUENCE-DEPENDENT SETUP; GENETIC ALGORITHM; SEARCH; STRAIGHT; DESIGN; TIMES	In this study, a new cost-oriented assembly line balancing problem is proposed and formulated. A single objective function consisting of minimizing the cost associated with equipment, labor wage, and station establishment is considered for the problem. This problem is more complicated comparing to the literature as worker qualification is considered for determining his/her wage. As this problem is of NP-hard optimization problems, some meta-heuristic solution approaches, e.g., simulated annealing, variable neighborhood search, genetic algorithm, tabu search, population-based simulated annealing, and their hybrid versions are proposed. In the proposed algorithms, a novel encoding-decoding scheme is applied. This scheme uses the Hungarian method to assign the workers to the station to reduce the total wage of the workers. To study the performance of the proposed meta-heuristic algorithms, ten test problems are generated randomly, and using one of them the parameters of the algorithms are tuned by the Taguchi method. The final experiments on the proposed algorithms and the test problems show that in the most of the experiments, among the proposed algorithms, the single-solution-based algorithms, except TS, perform better than the population-based algorithms, especially for the case of large size test problems.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8217	8243		10.1007/s00521-019-04293-8													
J								Multi-matrices entropy discriminant ensemble learning for imbalanced problem	NEURAL COMPUTING & APPLICATIONS										Information entropy; Multi-form matrices; Regularization method; Imbalanced learning	SMOTE	The objective of this paper is to make an improvement on ensemble learning for imbalanced problem. Multi-matrices approach and nearest entropy are introduced into model of base classifier for the sake of utilizing spatial information of data and geometric relation between instances. Our method utilizes the variety of matrix to mine the potential information in the data and constructs regularization term that measures the neighboring relationship among instances with entropy to enhance the stability of decision boundary. The different shapes of matrix contain distinct spatial information. As a result, the origin vector-oriented data are reorganized into multiple shapes of matrix to expand the different spatial information. The nearest entropy is used to measure the local certainty of instances so that the stable instances can be selected to train by the new regularization term. In order to compare the advantages of introducing the multi-matrices and entropy, several ensemble learning methods that have similar ensemble strategy and variants of linear classification models are selected to implement experiments, based on 55 binary classification datasets of KEEL benchmark.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8245	8264		10.1007/s00521-019-04306-6													
J								A Pearson-like correlation-based TOPSIS method with interval-valued Pythagorean fuzzy uncertainty and its application to multiple criteria decision analysis of stroke rehabilitation treatments	NEURAL COMPUTING & APPLICATIONS										Multiple criteria decision analysis; TOPSIS; Interval-valued Pythagorean fuzzy set; Pearson-like IVPF correlation coefficient; Correlation-based closeness coefficient; Rehabilitation treatment	AGGREGATION OPERATORS; SIMILARITY MEASURES; MEMBERSHIP GRADES; MAKING PROBLEMS; MODEL; UNIT; EXTENSION; NUMBERS; SETS	This paper extends one of the most extensively used multiple criteria decision analysis (MCDA) methods, the technique for order preference by similarity to ideal solutions (TOPSIS), to adapt to highly complicated uncertain environments based on interval-valued Pythagorean fuzzy (IVPF) sets. In contrast to classical TOPSIS methods, this paper develops a novel concept of Pearson-like IVPF correlation coefficients instead of distance measures to not only construct a useful and effective association measure between two IVPF characteristics but also depict the outranking relationship of IVPF information. Moreover, this paper proposes the (weighted) IVPF correlation-based closeness coefficients to establish a Pearson-like correlation-based TOPSIS model to manage MCDA problems within the IVPF environment. In particular, there is a definite improvement in determining the closeness coefficient required in the TOPSIS procedure. This paper considers anchored judgments with respect to the positive- and negative-ideal IVPF solutions and provides new approach- and avoidance-oriented definitions for the IVPF correlation-based closeness coefficient, which is entirely different from the traditional definition of relative closeness in TOPSIS. Furthermore, this paper proposes a comprehensive IVPF correlation-based closeness index to balance the consequences between ultra-approach orientation and ultra-avoidance orientation and acquire the ultimate compromise solution for decision support and aid. The feasibility and practicability of the developed methodology are illustrated by a practical MCDA problem of rehabilitation treatment for hospitalized patients with acute stroke. The application results, along with experimentations and comparative analyses, demonstrate that the developed methods are rational and effective.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8265	8295		10.1007/s00521-019-04304-8													
J								Ultra-low-voltage integrable electronic implementation of delayed inertial neural networks for complex dynamical behavior using multiple activation functions	NEURAL COMPUTING & APPLICATIONS										Hardware implementation of neural networks; Inertial neural network; Time delayed neural network; Low-voltage implementation of neural networks; Sinh-domain design	STABILITY SWITCHES; HOPF-BIFURCATION; MODEL; CHAOS; REALIZATION; SYSTEM; MEMORY	Ultra-low-voltage sinh-domain implementation of delayed inertial neuron is introduced in this paper. The complex dynamical behavior of the neuron has been verified using three different activation functions, namely tanh, unipolar sigmoidal and bipolar sigmoidal. The networks containing two and four neurons have been designed, and their complex dynamical behavior has also been verified. The proposed implementation vis-a-vis the already reported designs offers the benefits of: (1) low-voltage operation, (2) integrability, due to resistor-less design and the employment of only grounded components, (3) electronic tunability of performance parameters by external currents, which adds flexibility to the proposed designs even after their final fabrication, (4) absence of inductors as, in contrast to reported designs, the delay has been implemented using component substitution method where inductors have been replaced by emulated inductors and (5) low-power implementation due to the inherent class AB nature of sinh-domain technique. Besides, for the first time, the complex dynamical behavior of four-neuron delayed inertial network has been implemented and its functioning for different activations functions has been considered and verified. HSPICE simulator tool and TSMC 130 nm CMOS process were used to evaluate and verify the correct functioning of the model.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8297	8314		10.1007/s00521-019-04322-6													
J								Multi-agent learning neural network and Bayesian model for real-time IoT skin detectors: a new evaluation and benchmarking methodology	NEURAL COMPUTING & APPLICATIONS										Multi-criteria decision-making techniques; Skin detector within IoT; Evaluation and benchmarking multi-criteria analysis	HEALTH-MONITORING SYSTEMS; GROUP DECISION-MAKING; OPEN CHALLENGES; OPEN ISSUES; MULTICRITERIA ANALYSIS; TRACKING CHANNELS; COHERENT TAXONOMY; SELECTION PROBLEM; ACUTE-LEUKEMIA; HYBRID MODULE	This study aimed to develop a new methodology for evaluating and benchmarking a multi-agent learning neural network and Bayesian model for real-time skin detectors based on Internet of things (IoT) by using multi-criteria decision-making (MCDM). The novelty of this work is in the use of an evaluation matrix for the performance evaluation of real-time skin detectors that are based on IoT. Nevertheless, an issue with the performance evaluation of real-time skin detector approaches is the determination of sensible criteria for performance metrics and the trade-off amongst them on the basis of different colour spaces. An experiment was conducted on the basis of three phases. In the first phase, a real-time camera based on cloud IoT was used to gather different caption images. The second phase could be divided into two stages. In the first stage, a skin detection approach was developed by applying multi-agent learning based on different colour spaces. This stage aimed to create a decision matrix of various colour spaces and three groups of criteria (i.e. reliability, time complexity and error rate within a dataset) for testing and evaluating the developed skin detection approaches. In the second stage, Pearson rules were utilised to calculate the correlation between the criteria in order to make sure, either needs to use all of the criteria in decision matrix and the criteria facts that affect the behaviour of each criterion, in order to make sure that use all the criteria in evaluation as multidimensional measurements or not. In the third phase, the MCDM method was used by integrating between a technique in order of preference by similarity to the ideal solution and multi-layer analytic hierarchy process to benchmark numerous real-time IoT skin detection approaches based on the performed decision matrix from the second phase. Three groups of findings were obtained. Firstly, (1) statistically significant differences were found between the criteria that emphasise the need to use all of the criteria in evaluation. (2) The behaviour of the criteria in all scenarios was affected by the distribution of threshold values for each criterion based on the different colour spaces used. Therefore, the differences in the behaviour of criteria that highlight the use of the criteria in evaluation were included as multidimensional measurements. Secondly, an overall comparison of external and internal aggregation values in selecting the best colour space, namely the normalised RGB at the sixth threshold, was discussed. Thirdly, (1) the YIQ colour space had the lowest value and was the worst case, whereas the normalised RGB had the highest value and was the most recommended of all spaces. (2) The lowest threshold was obtained at 0.5, whereas the best value was 0.9.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8315	8366		10.1007/s00521-019-04325-3													
J								Combining functional near-infrared spectroscopy and EEG measurements for the diagnosis of attention-deficit hyperactivity disorder	NEURAL COMPUTING & APPLICATIONS										Attention-deficit hyperactivity disorder; Electroencephalography; Functional near-infrared spectroscopy; Multimodal neuroimaging	MEDICATION-NAIVE ADOLESCENTS; VISUAL SELECTIVE ATTENTION; LATERAL PREFRONTAL CORTEX; DEFICIT/HYPERACTIVITY DISORDER; ADHD CHILDREN; HEMODYNAMIC-RESPONSE; STROOP INTERFERENCE; COMPLEXITY ANALYSIS; INTEGRATIVE THEORY; FRACTAL DIMENSION	Recently multimodal neuroimaging which combines signals from different brain modalities has started to be considered as a potential to improve the accuracy of diagnosis. The current study aimed to explore a new method for discriminating attention-deficit hyperactivity disorder (ADHD) patients and control group by means of simultaneous measurement of electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS). Twenty-three pre-medicated combined type ADHD children and 21 healthy children were included in the study. Nonlinear brain dynamics of subjects were obtained from EEG signal using Higuchi fractal dimensions and Lempel-Ziv complexity, latency and amplitude values of P3 wave obtained from auditory evoked potentials and frontal cortex hemodynamic responses calculated from fNIRS. Lower complexity values, prolonged P3 latency and reduced P3 amplitude values were found in ADHD children. fNIRS indicated that the control subjects exhibited higher right prefrontal activation than ADHD children. Features are analyzed, looking for the best classification accuracy and finally machine learning techniques, namely Support Vector Machines, Naive Bayes and Multilayer Perception Neural Network, are introduced for EEG signals alone and for combination of fNIRS and EEG signals. Naive Bayes provided the best classification with an accuracy rate of 79.54% and 93.18%, using EEG and EEG-fNIRS systems, respectively. Our findings demonstrate that utilization of information by combining features obtained from fNIRS and EEG improves the classification accuracy. As a conclusion, our method has indicated that EEG-fNIRS multimodal neuroimaging is a promising method for ADHD objective diagnosis.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8367	8380		10.1007/s00521-019-04294-7													
J								Design of sign fractional optimization paradigms for parameter estimation of nonlinear Hammerstein systems	NEURAL COMPUTING & APPLICATIONS										Nonlinear system identification; Sign regressors; Fractional adaptive signal processing; Hammerstein models; Control structures	ADAPTIVE STRATEGY; ITERATIVE IDENTIFICATION; OPERATIONAL MATRIX; PREDICTIVE CONTROL; DYNAMIC-SYSTEMS; NEURAL-NETWORKS; GUEST EDITORIAL; ORDER CIRCUITS; ALGORITHMS; LMS	Fractional calculus plays a fundamental role in understanding the physics of nonlinear systems due to its heritage of uncertainty, nonlocality and complexity. In this study, novel sign fractional least mean square (F-LMS) algorithms are designed for ease in hardware implementation by applying sign function to input data and estimation error corresponding to first and fractional-order derivative terms in weight update mechanism of the standard F-LMS method. Theoretical expressions are derived for proposed sign F-LMS and its variants; strength of methods for different fractional orders is evaluated numerically through computer simulations for parameter estimation problem based on nonlinear Hammerstein system for low and high signal-noise variations. Comparison of the results from true parameters of the model illustrates the worth of the scheme in terms of accuracy, convergence and robustness. The stability and viability of design methodologies are examined through statistical observations on sufficiently large number of independent runs through mean square deviation and Nash-Sutcliffe efficiency performance indices.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8381	8399		10.1007/s00521-019-04328-0													
J								Multi-granularity bidirectional attention stream machine comprehension method for emotion cause extraction	NEURAL COMPUTING & APPLICATIONS										Emotion cause extraction; Bidirectional attention stream; Multi-granularity representation; Machine comprehension; Sentiment analysis; Query-aware context	CLASSIFICATION; SENTIMENT; NETWORK	Emotion cause extraction is to extract the cause information that triggers the emotion expression of described person. This task in text plays a critical role in natural language processing applications, such as sentiment analysis and semantic comprehension system. However, most existing methods for this emotion cause extraction task only focus on feature engineering and ignore the latent semantic information between emotion word and context to hinder the performance. In this paper, we propose a novel computational multi-granularity bidirectional attention stream network based on a machine comprehension frame to settle this problem. The context and query are embedded by this multistage hierarchical process based on the fine-grained levels of embeddings. Then, the bidirectional attention stream mechanism is applied to get an emotional query-aware context representation. Meanwhile, we have conducted extensive experiments on available Chinese emotion cause dataset. The experimental results demonstrate that our approach significantly outperforms the state-of-the-art methods and is able to extract the emotion cause.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8401	8413		10.1007/s00521-019-04308-4													
J								General decay anti-synchronization of multi-weighted coupled neural networks with and without reaction-diffusion terms	NEURAL COMPUTING & APPLICATIONS										General decay anti-synchronization; MWCNNs; Nonlinear control; Delayed coupling; Reaction-diffusion terms	TIME SYNCHRONIZATION; STABILITY-CRITERIA; ADAPTIVE-CONTROL; SYSTEMS; DELAYS	The network models of multi-weighted coupled neural networks (MWCNNs) and multi-weighted coupled reaction-diffusion neural networks (MWCRDNNs) with and without delayed coupling are presented in this paper, respectively. Firstly, on account of the definitions of psi-type stability and psi -type function, the concept of decay anti-synchronization is proposed. Then, we investigate the decay anti-synchronization of MWCNNs with and without delayed coupling by designing appropriate nonlinear controllers, and several criteria for ensuring decay anti-synchronization are inferred by means of Lyapunov functional method as well as inequality techniques. Similarly, some conditions for decay anti-synchronization of MWCRDNNs with and without delayed coupling are also, respectively, derived. Lastly, two numerical examples with simulations are given to validate the correctness of these derived results.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8417	8430		10.1007/s00521-019-04313-7													
J								A novel relative homogeneity thresholding method with optimization strategy	NEURAL COMPUTING & APPLICATIONS										Thresholding segmentation; Relative homogeneity; Optimization strategy; Multilevel thresholding	SEGMENTATION; OTSU; ENHANCEMENT; IMAGES	Determining thresholds by measuring class variance is highly effective for image segmentation. Otsu's method and its derivatives are common approaches that are both simple and adaptable. In spite of these methods' excellent segmentation performance, images with particular gray distributions cause a thresholding bias that limits their usefulness. We explore the limitations of Otsu's method and apply other evaluation criteria. In particular, we determine the relative homogeneity between the object and the background and then use it as a classification criterion along with a new binary thresholding method. Our method employs a histogram-smoothing method to improve valley-point selection, establishes a uniformity measure to identify the region with the best homogeneity, and identifies an optimization function for obtaining the best values for the adjustable parameters and threshold value. We also introduce a multilevel thresholding criterion based on a binary thresholding approach. Experiments using real and ground truth test images confirm the validity of our proposed method. Our method also offers a denoising ability when configured to use neighborhood information.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8431	8449		10.1007/s00521-019-04333-3													
J								Generative adversarial fusion network for class imbalance credit scoring	NEURAL COMPUTING & APPLICATIONS										Credit scoring; Class imbalance; Generative adversarial network; Feature fusion	VECTOR MACHINE; CLASSIFIERS; ENSEMBLE; DEFAULT; SYSTEM; SMOTE; MODEL	Credit scoring on class imbalance data, where the class of defaulters is insufficiently represented compared with the class of non-defaulters, is an important but challenging task. In this paper, we propose an imbalanced generative adversarial fusion network (IGAFN) to cope with the class imbalance credit scoring based on multi-source heterogeneous credit data. Concretely, we design a fusion module to integrate the heterogeneous credit data from multiple sources into a unified latent feature space. A generative adversarial network-based balance module is then designed to generate latent representations of new samples for the minority class of the imbalanced datasets. The performance of IGAFN is compared against multiple conventional machine learning and deep learning algorithms. Extensive experiments show that the proposed IGAFN exhibits significantly better performance than the compared methods on two real-life datasets.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8451	8462		10.1007/s00521-019-04335-1													
J								Optimal power flow with stochastic wind power and FACTS devices: a modified hybrid PSOGSA with chaotic maps approach	NEURAL COMPUTING & APPLICATIONS										ACOPF; Wind power; Modern power systems; Chaotic PSOGSA	SEARCH ALGORITHM; OPTIMIZATION; DISPATCH; SYSTEMS; NONCONVEX	Nowadays, the increasing usage of renewable energy sources (RES) in modern power systems introduces new challenges in power system planning and operation. Specifically, a high penetration of RESs introduces additional complexity into the optimal power flow (OPF) problem, which has a highly nonlinear complex structure. Under this environment, this paper discusses a modified hybrid particle swarm optimization and gravitational search algorithm (PSOGSA) integrated with chaotic maps (CPSOGSA) to apply the composite benchmark test functions and to solve the OPF problem with stochastic wind power and flexible alternating current transmission system (FACTS) devices. Numerical studies are used to illustrate effectiveness of the proposed CPSOGSA approach against other approaches such as moth swarm algorithm, grey wolf optimizer, and whale optimization algorithm. Additionally, to demonstrate the superiority and robustness of CPSOGSA algorithm, Wilcoxon signed-rank test is applied for all case studies. Case studies indicate the potential of CPSOGSA method in effectively solving OPF problem with stochastic wind power and FACTS devices.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8463	8492		10.1007/s00521-019-04338-y													
J								Performance of evolutionary wavelet neural networks in acrobot control tasks	NEURAL COMPUTING & APPLICATIONS										Evolutionary algorithms; Wavelet neural networks; Acrobot; Intelligent control	INTELLIGENT CONTROL	Wavelet neural networks (WNN) combine the strength of artificial neural networks and the multiresolution ability of wavelets. Determining the structure and, more specifically, the appropriate number of neurons in a WNN is a time-consuming process. We propose a type of multidimensional evolutionary WNN and, using an acrobot, evaluate this approach with two benchmark nonlinear control tasks: a height task and a hand-stand task. To facilitate direct comparison with other methods, we report on swing-up and balance times. In 50 trials, the controllers produced faster swing-up times-1.0 s for the best controller and 2.3 s on average-than any other methods reported in the literature. Moreover, the controller with the best swing-up time had a maximum balance time of 1.25 s, surpassing most other methods.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8493	8505		10.1007/s00521-019-04347-x													
J								Nonlinear CNN: improving CNNs with quadratic convolutions	NEURAL COMPUTING & APPLICATIONS										Neural network; Machine learning; Quadratic convolution		In this work, instead of designing deeper convolutional neural networks, we investigate the relationship between the nonlinearity of convolution layer and the performance of the network. We modify the normal convolution layer by inserting quadratic convolution units which can map linear features to a higher-dimensional space in a single layer so as to enhance the approximability of the network. A genetic algorithm-based training scheme is adopted to reduce the time and space complexity caused by the quadratic convolution. Our method is experimented on classical image classification architectures including VGG-16 Net and GoogLeNet and outperforms the original models on the ImageNet classification dataset. The experimental results also show that better performance of our method can be achieved with a shallower architecture. We notice that VGG-16 model is widely used in popular object detection frameworks such as faster R-CNN and SSD. We adopt our modified VGG-16 model in these frameworks and also achieve improvements on PASCAL VOC2007 and VOC2012 dataset.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8507	8516		10.1007/s00521-019-04316-4													
J								Finite-time extended dissipativity of delayed Takagi-Sugeno fuzzy neural networks using a free-matrix-based double integral inequality	NEURAL COMPUTING & APPLICATIONS										Extended dissipativity; Extended Wirtinger inequality; Finite-time bounded; Free-weighting matrix; Lyapunov-Krasovskii functional; Takagi-Sugeno fuzzy neural networks	DEPENDENT STABILITY-CRITERIA; STATE ESTIMATION; STOCHASTIC STABILITY; ROBUST STABILITY; SYSTEMS; PERFORMANCE; DISCRETE	This study focuses on the finite-time extended dissipativity of delayed Takagi-Sugeno (T-S) fuzzy neural networks (NNs). Based on the concept of extended dissipativity, this paper solves theH infinity,L2-L infinity passive, and(Q,S,R dissipativity performance in a unified framework. Using the free-matrix-based double integral inequality and an extended Wirtinger inequality in the Lyapunov-Krasovskii functional, sufficient conditions are derived to guarantee that the considered NNs are finite-time bounded, whereupon the finite-time extended dissipativity criteria for delayed T-S fuzzy NNs are constructed. The derived conditions guarantee the extended dissipativity and stability of the NNs. Three numerical examples are given to demonstrate the reduced conservatism and the effectiveness of the obtained results.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8517	8528		10.1007/s00521-019-04348-w													
J								A deep learning framework for land-use/land-cover mapping and analysis using multispectral satellite imagery	NEURAL COMPUTING & APPLICATIONS										Deep learning; Land use; Land cover; Maps; Classification; Deep neural networks; Satellite images	NEURAL-NETWORKS; CLASSIFICATION	In this article, we present an approach to land-use and land-cover (LULC) mapping from multispectral satellite images using deep learning methods. The terms satellite image classification and map production, although used interchangeably have specific meanings in the field of remote sensing. Satellite image classification describes assignment of global labels to entire scenes, whereas LULC map production involves producing maps by assigning a class to each pixel. We show that by classifying each pixel in a satellite image into a number of LULC categories we are able to successfully produce LULC maps. This process of LULC mapping is achieved using deep neural networks pre-trained on the ImageNet large-scale visual recognition competition datasets and fine-tuned on our target dataset, which consists of Landsat 5/7 multispectral satellite images taken of the Province of Manitoba in Canada. This approach resulted in 88% global accuracy. Performance was further improved by considering the state-of-the-art generative adversarial architecture and context module integrated with the original networks. The result is an automated deep learning framework that can produce highly accurate LULC maps images significantly faster than current semi-automated methods. The contribution of this article includes extensive experimentation of different FCN architectures with extensions on a unique dataset, high classification accuracy of 90.46%, and a thorough analysis and accuracy assessment of our results.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8529	8544		10.1007/s00521-019-04349-9													
J								Application of self-organizing map and fuzzy c-mean techniques for rockburst clustering in deep underground projects	NEURAL COMPUTING & APPLICATIONS										Rockburst; Self-organizing map; Fuzzy c-mean; Empirical criteria	PREDICTION; CLASSIFICATION; ENERGY; INTENSITY; ALGORITHM; AGREEMENT; HAZARD; MINE	One of the main concerns associated with deep underground constructions is the violent expulsion of rock induced by unexpected release of strain energy from surrounding rock masses that is known as rockburst. Rockburst hazard causes substantial damages to the foundation of the structure and equipment and can be a menace to the safety of workers. This study was intended to find the latent relationship between the rockburst-related parameters based on the compiled data samples from deep underground projects using two robust clustering techniques of self-organizing map (SOM) and fuzzy c-mean (FCM). The parameters of maximum tangential stress, uniaxial compressive strength, uniaxial tensile strength, and elastic energy index were considered as input parameters. SOM model could classify data samples into four distinct classes (clusters), and the rockburst intensities were identified precisely. FCM also proved its performance in clustering task with high convergence speed and acceptable accuracy. Having a comparison, the results of SOM and FCM models were compared with ones calculated from five empirical criteria of Russenes, Hoek, tangential stress, elastic energy index, and rock brittleness coefficient. At best, the empirical criteria of Hoek and tangential stress coefficient could predict rockburst intensity with the accuracy of 56.90%. By analyzing the SOM results as the best model, it was turned out that the maximum tangential stress around the openings has a crucial role in rockburst clustering and has the most influence on the occurrence of strong and moderate rockburst types. Hence, it was recommended as a possible solution to control these types of rockbursts by optimizing the diameter and shape of the underground openings.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8545	8559		10.1007/s00521-019-04353-z													
J								Development and application of an efficient optimizer for optimal coordination of directional overcurrent relays	NEURAL COMPUTING & APPLICATIONS										Directional overcurrent relays; Optimal coordination; Coordination time interval; Enhanced grey wolf optimizer	ALGORITHM	This paper proposes an enhanced version of grey wolf optimizer (EGWO) to solve the coordination problem of directional overcurrent relays (DOCRs). The EGWO is proposed to improve the convergence characteristics and computation time of the conventional grey wolf optimizer (GWO) by selecting a suitable balance between exploration and exploitation phases. This balance is achieved by exponential decreasing of the control parameter during the iterative process. The EGWO is explored in all search space during predetermined iterations, and then it fast converges to the best optimal solution by local exploitation around the optimal solutions. The proposed optimization technique is applied to solve the coordination problem of DOCRs. The main objective of optimal coordination of DOCRs is to minimize total operating time of all primary relays with sustaining the selectivity between relay pairs. The feasibility and performance of the proposed technique for solving the coordination problem of DOCRs are investigated using four different systems, compared with several well-known techniques. The obtained results prove the effectiveness and superiority of the proposed technique compared with these techniques. The proposed technique is able to find the optimal relay settings and minimize the total operating time of relays (with a reduction ratio about 19.3995% relative to the conventional GWO) without any miscoordination. In addition, DIgSILENT PowerFactory is used to validate the proposed technique.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8561	8583		10.1007/s00521-019-04361-z													
J								Human action recognition with bag of visual words using different machine learning methods and hyperparameter optimization	NEURAL COMPUTING & APPLICATIONS										Human activity recognition; Image processing; Speeded up robust features; Bag of visual words; Machine learning; k-Nearest neighbors; Decision tree; Support vector machine; Naive Bayes; Hyperparameter optimization	RECOGNIZING HUMAN ACTIONS; ROBUST APPROACH; IMAGE; FEATURES; CONTEXT; SYSTEM	Human activity recognition (HAR) has quite a wide range of applications. Due to its widespread use, new studies have been developed to improve the HAR performance. In this study, HAR is carried out using the commonly preferred KTH and Weizmann dataset, as well as a dataset which we created. Speeded up robust features (SURF) are used to extract features from these datasets. These features are reinforced with bag of visual words (BoVW). Different from the studies in the literature that use similar methods, SURF descriptors are extracted from binary images as well as grayscale images. Moreover, four different machine learning (ML) methods such as k-nearest neighbors, decision tree, support vector machine and naive Bayes are used for classification of BoVW features. Hyperparameter optimization is used to set the hyperparameters of these ML methods. As a result, ML methods are compared with each other through a comparison with the activity recognition performances of binary and grayscale image features. The results show that if the contrast of the environment decreases when a human enters the frame, the SURF of the binary image are more effective than the SURF of the gray image for HAR.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8585	8597		10.1007/s00521-019-04365-9													
J								A new optimal gene selection approach for cancer classification using enhanced Jaya-based forest optimization algorithm	NEURAL COMPUTING & APPLICATIONS										Microarray; ANOVA; Jaya; Forest optimization algorithm (FOA)	DISTRIBUTED FEATURE-SELECTION; EXPRESSION DATA; MICROARRAY; OVARIAN; CELL; ADENOCARCINOMA; IDENTIFICATION; STRATEGY; PATTERNS; FUSION	In microarray experiments, the sample size is considerably smaller than that of the feature size, thereby imposing the curse of dimensionality problem. To resolve this issue, evolutionary algorithms are often utilized. In this paper, a novel framework for feature selection and classification of the microarray data is presented. Initially, a statistical filter, namely ANOVA, is used to select the relevant genes (features) from the original set of genes. Then, an evolutionary wrapper-based approach utilizing the principles of enhanced Jaya (EJaya) algorithm and forest optimization algorithm (FOA) is proposed to find the optimal set of genes from the previously selected genes. The main objective of using EJaya is to tune the two important parameters, namely local seeding changes and global seeding changes of FOA. During the selection of the optimal set of genes, support vector machine is employed as a classifier to classify the microarray data. To perform a comprehensive experimental study, the proposed method is tested on both binary-class and multi-class microarray datasets. From the extensive result analysis, it has been observed that the proposed technique achieves better classification accuracy with considerably less number of features than that of the benchmark schemes.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8599	8616		10.1007/s00521-019-04355-x													
J								An inertia grey discrete model and its application in short-term traffic flow prediction and state determination	NEURAL COMPUTING & APPLICATIONS										Grey prediction model; Short-term traffic flow forecasting; Inertia model; Force resolution; Traffic flow state	FORECASTING-MODEL; NATURAL-GAS; CONSUMPTION; ALGORITHM; EMISSIONS	A traffic flow system is a complex dynamic system. Traffic flows data are the product of the velocity and density, and its data have dynamic and fluctuation characteristics. Therefore, three new inertia grey discrete models (IDGMs) were proposed and used to estimate short-term traffic flow based on traffic flow data mechanics and characteristics and traffic-state characteristics. The modelling process of the traditional grey DGM using the least square method may lead to a large parameter estimation deviation and a low model precision. The new model uses the mechanical characteristics of the data and applies the evolutionary process of the mechanical decomposition of the data to the modelling process. It has a more reasonable modelling process and a more stable structure and solves the shortcomings of the traditional grey DGM parameter estimation. Moreover, it uses matrix analysis to study the important characteristics of the IDGM, and it simplifies the forms of the parameter model and structural model. Then, the traffic flow of the Whitemud Drive City Expressway in Canada is analysed empirically, and the effect of the new model and the judgment of three-phase traffic flow state are analysed.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8617	8633		10.1007/s00521-019-04364-w													
J								Modeling the activity coefficient at infinite dilution of water in ionic liquids using artificial neural networks and support vector machines	NEURAL COMPUTING & APPLICATIONS										Activity coefficient; Ionic liquids; Artificial neural networks; Support vector machine; Least square support vector machine; Infinite dilution	SUPERCRITICAL CARBON-DIOXIDE; ORGANIC SOLUTES; COSMO-RS; PHYSICOCHEMICAL PROPERTIES; SOLVENT MIXTURES; BINARY-SYSTEMS; PREDICTION; SOLUBILITY; TOXICITY; QSAR	The activity coefficient at infinite dilution of water in ionic liquids is a thermodynamic property of a paramount importance in separation processes. However, accurate modeling of this parameter remains a challenging task due to the highly nonlinear behavior of the water/ionic liquid systems. Also, available models consider a large number of inputs that are usually difficult to access and require complicated use techniques. Therefore, the main objective of this paper is to use artificial intelligence techniques to propose models (based on a reduced number of inputs that are easily accessible, and to improve the accuracy of the correlative performance for activity coefficient at infinite dilution of water in ILs). The present work features the application of artificial neural networks, support vector machine and least square support vector machine, among data-driven methods, for modeling the activity coefficient at infinite dilution of water in 53 ionic liquids. Overall, the models proposed are able to accurately correlate 318 experimental data points gathered from the literature. According to the results, the ANN is more powerful and effective computational learning machine than the two remaining ones. The correlation coefficientsR(2)and deviations expressed as an average absolute relative deviation for the neural network model are estimated to be 0.99997 and 0.56%, respectively. Furthermore, the neural network model's interpolation and extrapolation capabilities are demonstrated, and its accuracy is compared to other proposed models in the literature based on multi-linear regression, least squares support vector machine and another feedforward neural network. This work also includes a graphical user interface for the proposed model, as well as an inputs' sensitivity analysis.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8635	8653		10.1007/s00521-019-04356-w													
J								A multilingual fuzzy approach for classifying Twitter data using fuzzy logic and semantic similarity	NEURAL COMPUTING & APPLICATIONS										Opinion mining; Sentiment analysis; Twitter; Fuzzy logic; Information retrieval systems; Semantic similarity; WordNet; Big data; Hadoop	NEURAL-NETWORK; SENTIMENT; CONTEXT; CLASSIFICATION	In recent years, the classification of the social networks' data has witnessed an increasing interest. It aims at extracting opinions, emotions and attitudes from social networks' data such as Facebook comments or tweets. This new scientific research area is called sentiment analysis. (It is sometimes called opinion mining.) In this article, we propose a new method to classify tweets into three classes: positive, negative or neutral. The proposed method is a new hybrid approach based on the fuzzy logic with its three important steps (fuzzification, Rule Inference/aggregation and defuzzification) and the concepts of information retrieval system (IRS) by calculating the semantic similarity between a tweet to classify and two opinion documents (one for the positive opinion words and another one for the negative opinion words) using the WordNet dictionary. To remedy the calculation time's problem-if we have a huge dataset of tweets-we decide to parallelize our work using the Hadoop framework with its distributed file system (HDFS) and the MapReduce programming model. The experimental results show that our approach outperforms some other methods from the literature as well as by using the fuzzy logic, we improve the results of the classification.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8655	8673		10.1007/s00521-019-04357-9													
J								A dynamic ensemble learning algorithm for neural networks	NEURAL COMPUTING & APPLICATIONS										Neural network ensemble; Backpropagation algorithm; Negative correlation learning; Constructive algorithms; Pruning algorithms	SELECTION; DIVERSITY; CLASSIFICATION; CLASSIFIERS; COMBINATION; DESIGN	This paper presents a novel dynamic ensemble learning (DEL) algorithm for designing ensemble of neural networks (NNs). DEL algorithm determines the size of ensemble, the number of individual NNs employing a constructive strategy, the number of hidden nodes of individual NNs employing a constructive-pruning strategy, and different training samples for individual NN's learning. For diversity, negative correlation learning has been introduced and also variation of training samples has been made for individual NNs that provide better learning from the whole training samples. The major benefits of the proposed DEL compared to existing ensemble algorithms are (1) automatic design of ensemble; (2) maintaining accuracy and diversity of NNs at the same time; and (3) minimum number of parameters to be defined by user. DEL algorithm is applied to a set of real-world classification problems such as the cancer, diabetes, heart disease, thyroid, credit card, glass, gene, horse, letter recognition, mushroom, and soybean datasets. It has been confirmed by experimental results that DEL produces dynamic NN ensembles of appropriate architecture and diversity that demonstrate good generalization ability.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8675	8690		10.1007/s00521-019-04359-7													
J								Online learning based on adaptive learning rate for a class of recurrent fuzzy neural network	NEURAL COMPUTING & APPLICATIONS										Reinforcement learning; Recurrent interval type-2 fuzzy neural networks; LM method; Lyapunov function; Adaptive learning rate	DISCRETE-TIME-SYSTEMS; PID CONTROLLER; VARYING DELAYS; IDENTIFICATION; PERFORMANCE; LEAKAGE; MOTOR	This paper proposes a novel structure of a recurrent interval type-2 TSK fuzzy neural network (RIT2-TSK-FNN) controller based on a reinforcement learning scheme for improving the performance of nonlinear systems using a less number of rules. The parameters of the proposed RIT2-TSK-FNN controller are leaned online using the reinforcement actor-critic method. The controller performance is improved over the time as a result of the online learning algorithm. The controller learns from its own mistakes and faults through the reward and punishment signal from the external environment and seeks to reinforce the RIT2-TSK-FNN controller parameters to converge. In order to obtain less number of rules, the structure learning is performed and thus the RIT2-TSK-FNN rules are obtained online based on the type-2 fuzzy clustering. The online adaptation of the proposed RIT2-TSK-FNN controller parameters is developed using the Levenberg-Marquardt method with adaptive learning rates. The stability analysis is discussed using the Lyapunov theorem. The obtained results show that the proposed RIT2-TSK-FNN controller using the reinforcement actor-critic technique is more preferable than the RIT2-TSK-FNN controller without the actor-critic method under the same conditions. The proposed controller is applied to a nonlinear mathematical system and an industrial process such as a heat exchanger to clarify the robustness of the proposed structure.																	0941-0643	1433-3058				JUN	2020	32	12			SI		8691	8710		10.1007/s00521-019-04372-w													
