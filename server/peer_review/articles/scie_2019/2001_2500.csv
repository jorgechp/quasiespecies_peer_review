PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Portfolio management with background risk under uncertain mean-variance utility	FUZZY OPTIMIZATION AND DECISION MAKING										Portfolio selection; Mean-variance utility; Background risk; Uncertain variable; Uncertain programming	SELECTION; MODEL	This paper studies comparative static effects in a portfolio selection problem when the investor has mean-variance preferences. Since the security market is complex, there exists the situation where security returns are given by experts' estimates when they cannot be reflected by historical data. This paper discusses the problem in such a situation. Based on uncertainty theory, the paper first establishes an uncertain mean-variance utility model, in which security returns and background asset returns are uncertain variables and subject to normal uncertainty distributions. Then, the effects of changes in mean and standard deviation of uncertain background asset on capital allocation are discussed. Furthermore, the influence of initial proportion in background asset on portfolio investment decisions is analyzed when investors have quadratic mean-variance utility function. Finally, the economic analysis illustration of investment strategy is presented.																	1568-4539	1573-2908															10.1007/s10700-020-09345-6		SEP 2020											
J								Event-triggered Control of Positive Switched Systems with Actuator Saturation and Time-delay	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Positive switched systems; event-triggered control; randomly occurring actuator saturation; linear programming; time-delay	COPOSITIVE LYAPUNOV FUNCTIONS; LINEAR-SYSTEMS; STABILITY; STABILIZATION	This paper investigates the event-triggered control of positive switched systems with randomly occurring actuator saturation and time-delay, where the actuator saturation and time-delay obey different Bernoulli distributions. First, an event-triggering condition is constructed based on a 1-norm inequality. Under the presented event-triggering scheme, an interval estimation method is utilized to deal with the error term of the systems. Using a co-positive Lyapunov functional, the event-triggered controller and the cone attraction domain gain matrices are designed via matrix decomposition techniques. The positivity and stability of the resulting closed-loop systems are reached by guaranteeing the positivity of the lower bound of the systems and the stability of the upper bound of the systems, respectively. The proposed approach is developed for interval and polytopic uncertain systems, respectively. Finally, two examples are provided to illustrate the effectiveness of the theoretical findings.																	1476-8186	1751-8520															10.1007/s11633-020-1245-0		SEP 2020											
J								Benchmarking the Robustness of Semantic Segmentation Models with Respect to Common Corruptions	INTERNATIONAL JOURNAL OF COMPUTER VISION										Semantic segmentation; Corruption robustness; Common image corruptions; Realistic image corruptions	CALIBRATION; CAMERA; NOISE	When designing a semantic segmentation model for a real-world application, such as autonomous driving, it is crucial to understand the robustness of the network with respect to a wide range of image corruptions. While there are recent robustness studies for full-image classification, we are the first to present an exhaustive study for semantic segmentation, based on many established neural network architectures. We utilize almost 400,000 images generated from the Cityscapes dataset, PASCAL VOC 2012, and ADE20K. Based on the benchmark study, we gain several new insights. Firstly, many networks perform well with respect to real-world image corruptions, such as a realistic PSF blur. Secondly, some architecture properties significantly affect robustness, such as a Dense Prediction Cell, designed to maximize performance on clean data only. Thirdly, the generalization capability of semantic segmentation models depends strongly on the type of image corruption. Models generalize well for image noise and image blur, however, not with respect to digitally corrupted data or weather corruptions.																	0920-5691	1573-1405															10.1007/s11263-020-01383-2		SEP 2020											
J								Fine-Grained Instance-Level Sketch-Based Image Retrieval	INTERNATIONAL JOURNAL OF COMPUTER VISION										Fine-grained; Sketch understanding; Image retrieval; Cross-modality; Deep learning		The problem of fine-grained sketch-based image retrieval (FG-SBIR) is defined and investigated in this paper. In FG-SBIR, free-hand human sketch images are used as queries to retrieve photo images containing the same object instances. It is thus a cross-domain (sketch to photo) instance-level retrieval task. It is an extremely challenging problem because (i) visual comparisons and matching need to be executed under large domain gap, i.e., from black and white line drawing sketches to colour photos; (ii) it requires to capture the fine-grained (dis)similarities of sketches and photo images while free-hand sketches drawn by different people present different levels of deformation and expressive interpretation; and (iii) annotated cross-domain fine-grained SBIR datasets are scarce, challenging many state-of-the-art machine learning techniques, particularly those based on deep learning. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based object instance retrieval application. Specifically, a new large-scale FG-SBIR database is introduced which is carefully designed to reflect the real-world application scenarios. A deep cross-domain matching model is then formulated to solve the intrinsic drawing style variability, large domain gap issues, and capture instance-level discriminative features. It distinguishes itself by a carefully designed attention module. Extensive experiments on the new dataset demonstrate the effectiveness of the proposed model and validate the need for a rigorous definition of the FG-SBIR problem and collecting suitable datasets.																	0920-5691	1573-1405															10.1007/s11263-020-01382-3		SEP 2020											
J								A parallel hybrid krill herd algorithm for feature selection	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Feature selection; Document clustering; Parallel membrane computing; Krill herd algorithm; Local search; Optimization problem	WHALE OPTIMIZATION ALGORITHM; TEXT FEATURE-SELECTION; ARTIFICIAL BEE COLONY; DIMENSION REDUCTION; COMBINATION; STRATEGY	In this paper, a novel feature selection method is introduced to tackle the problem of high-dimensional features in the text clustering application. Text clustering is a prevailing direction in big text mining; in this manner, documents are grouped into cohesive groups by using neatly selected informative features. Swarm-based optimization techniques have been widely used to select the relevant text features and shown promising results on multi-sized datasets. The performance of traditional optimization algorithms tends to fail miserably when using large-scale datasets. A novel parallel membrane-inspired framework is proposed to enhance the performance of the krill herd algorithm combined with the swap mutation strategy (MHKHA). In which the krill herd algorithm is hybridized the swap mutation strategy and incorporated within the parallel membrane framework. Finally, the k-means technique is employed based on the results of feature selection-based Krill Herd Algorithm to cluster the documents. Seven benchmark datasets of various characterizations are used. The results revealed that the proposed MHKHA produced superior results compared to other optimization methods. This paper presents an alternative method for the text mining community through cohesive and informative features.																	1868-8071	1868-808X															10.1007/s13042-020-01202-7		SEP 2020											
J								MS-NET: modular selective network Round robin based modular neural network architecture with limited redundancy	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Modular neural networks; Deep learning; Knowledge-distillation; Multi-class classification; Image classification	CLASSIFICATION; MIXTURES	We propose a modular architecture of Deep Neural Network (DNN) for multi-class classification task. The architecture consists of two parts, a router network and a set of expert networks. In this architecture, for a C-class classification problem, we have exactly C experts. The backbone network for these experts and the router are built with simple and identical DNN architecture. For each class, the modular network has a certain number rho of expert networks specializing in that particular class, where rho is called the redundancy rate in this study. We demonstrate that rho plays a vital role in the performance of the network. Although these experts are light weight and weak learners alone, together they match the performance of more complex DNNs. We train the network in two phase wherein, first the router is trained on the whole set of training data followed by training each expert network enforced by a new stochastic objective function that facilitates alternative training on a small subset of expert data and the whole set of data. This alternative training provides an additional form of regularization and avoids over-fitting the expert network on subset data. During the testing phase, the router dynamically selects a fixed number of experts for further evaluation of the input datum. The modular nature and low parameter requirement of the network makes it very suitable in distributed and low computational environments. Extensive empirical study and theoretical analysis on CIFAR-10, CIFAR-100 and F-MNIST substantiate the effectiveness and efficiency of our proposed modular network.																	1868-8071	1868-808X															10.1007/s13042-020-01201-8		SEP 2020											
J								A two-sided matching method considering the lowest value of acceptability with regret theory for probabilistic linguistic term sets	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Decision making; Regret theory; Two-sided matching; Probabilistic linguistic term sets	DECISION-MAKING; PROSPECT-THEORY; OPERATORS	In order to solve matching problems for probabilistic linguistic information, a novel two-sided matching decision method for the probabilistic linguistic term sets (PLTSs) based on the regret theory considering the lowest value of acceptability is proposed. First, we propose a new utility function to transform the PLTSs to utility values, which can be conveniently applied to two-sided matching models. Then, to reflect the bounded rationality of expert and make the decision result close to real decision process, we put forward a novel regret-based model to obtain regret-rejoice by setting the lowest value of acceptability based on the utility function. Furthermore, we presented a new type of two-sided matching method considering constraint condition based on the lowest value of acceptability. Finally, we apply our method to a real case and make comparisons with two traditional two-sided methods.																	1868-8071	1868-808X															10.1007/s13042-020-01211-6		SEP 2020											
J								Towards learning line descriptors from patches: a new paradigm and large-scale dataset	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Line feature description; Point description; Convolutional neural network; Large-scale dataset	OBJECT DETECTION; RECONSTRUCTION; FUSION; DEEP	Line feature description is important for image matching. However, its development is much slow compared to point description, and is still in the stage of manual design, which suffers from the problem of weak distinguish ability and poor robustness under complex conditions. To improve on this situation, this paper proposes to learn the line feature description based on convolutional neural network. First, a large-scale dataset consisting of about 229,000 labeled pairs of matched lines is built for training and testing. Then, a paradigm for learning the line descriptors based on the constructed line dataset is proposed. Specifically, the line is represented uniquely by the stacked mean and standard deviation patches of the support regions of those points lying on the line, which is subsequently fed into the L2Net to output the required line descriptors directly. Based on the line matching principals, the network is also trained with the triplet loss that is widely used for learning point descriptors. Experimental results for line matching and curve matching both demonstrate the superiority and effectiveness of the proposed learning-based descriptor, especially, averaged increases of 4.66 similar to 5.7% mAPs, 10.59 similar to 12.10% mAPs, 0.96 similar to 3.75% mAPs and 3.73% mAP on testing subset, Oxford dataset, line dataset and curve dataset are obtained compared to handcrafted descriptors. As an application, we apply the learned line descriptor to image stitching and also obtain good results.																	1868-8071	1868-808X															10.1007/s13042-020-01207-2		SEP 2020											
J								Research on adaptive beacon message transmission power in VANETs	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Vehicular ad hoc networks (VANETs); V2V communication; Linear combination model; Adaptive transmission power; Signal weakness; Channel contention	CONGESTION CONTROL; NETWORKS	In the future vehicular ad hoc networks (VANETs), vehicles communicate by sending beacon messages. However, fixed-period beacon messages cannot adapt to the characteristics of fast vehicle speed and variable network topology, and may contend for channel failure when there are many vehicles, resulting in the relevant information not being able to be known to surrounding vehicles, increasing the possibility of danger. In order to solve this problem, this paper proposes an adaptive beacon transmission power algorithm based on vehicle position prediction error, which increases the beacon transmission power of vehicles with large vehicle position prediction errors and reduces the transmission power of vehicles with small errors. And analyze the relevant factors that may affect the results in the experiment, and formulate relevant solutions to signal fading and channel contention. Finally, the experimental results show that, compared with the fixed transmit power, the proposed adaptive power reduces the CBT by about 16% and improves the packet transmission rate by about 4.5%, ensuring the effective transmission of security information.																	1868-5137	1868-5145															10.1007/s12652-020-02575-x		SEP 2020											
J								Visual object tracking based on residual network and cascaded correlation filters	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Object tracking; Deep learning; Residual network; Resnet features; Cascaded correlation filters	ALGORITHM	Significant progress is made in the field of object tracking recently. Especially, trackers based on deep learning and correlation filters both have achieved excellent performance. However, object tracking still faces some challenging problems such as deformation and illumination. In such kinds of situations, the accuracy and precision of tracking algorithms plunge as a result. It is imminent to find a solution to this situation. In this paper, we propose a tracking algorithm based on features extracted by residual network called Resnet features and cascaded correlation filters to improve precision and accuracy. Firstly, features extracted by a deep residual network trained on other image processing datasets, are robust enough and retain higher resolution, therefore, we exploit Resnet-101 pretrained offline to obtain features extracted by middle and high layers for target appearance model representation. Resnet-101 is deeper compared with other deep neural networks which means it contains more semantic information. Then, the method we propose to combine our correlation filters is superior. We propose cascaded correlation filters generated by handcraft, middle-level and high-level features from residual network to gain better competence. Handcraft features localize target precisely because they contain more spatial details while Resnet features are robust to the target appearance change because they retain more semantic information. Finally, we conduct extensive experiments on OTB2013 and OTB2015 benchmark. The experimental results show that our tracker achieves high performance under all kinds of challenges and performs favorably against other state-of-the-art trackers.																	1868-5137	1868-5145															10.1007/s12652-020-02572-0		SEP 2020											
J								Detection of real-time augmented reality scene light sources and construction of photorealis tic rendering framework	JOURNAL OF REAL-TIME IMAGE PROCESSING										Real-time enhancement; Realistic scene; Light source detection; Photorealistic rendering; Real-time augmented reality	PERCEPTION	In this paper, the main network of multi-channel light sources is improved, so that multi-channel pictures can be fused for joint training. Secondly, for high-resolution detection pictures, the huge memory consumption leads to a reduction in batches and then affects the model distribution. Group regularization is adopted. We can still train the model normally in small batches; then, combined with the method of the regional candidate network, the final detection accuracy and the accuracy of the candidate frame regression are improved. Finally, through in-depth analysis, based on image lighting technology and physical-based rendering theory, the requirements for lighting effects and performance limitations, combined with a variety of image enhancement technologies, such as gamma correction, HDR, and these technologies used in Java. Real-time lighting algorithms that currently run efficiently on mainstream PCs. The algorithm can be well integrated into the existing rasterization rendering pipeline, while into account better lighting effects and higher operating efficiency. Finally, the lighting effects achieved by the algorithm are tested and compared through experiments. This algorithm not only achieves a very good light and shadow effect when rendering virtual objects with a real scene as the background but also can meet the realistic rendering of picture frames in more complex scenes. Rate requirements. The experimental results show that the virtual light source automatically generated by this algorithm can approximate the lighting of the real scene, and the virtual object and the real object can produce approximately consistent lighting effects in an augmented reality environment with one or more real light sources.																	1861-8200	1861-8219															10.1007/s11554-020-01022-6		SEP 2020											
J								Learning-detailed 3D face reconstruction based on convolutional neural networks from a single image	NEURAL COMPUTING & APPLICATIONS										3D face reconstruction; Single images; Lighting; Inverse rendering; Image synthesis; Convolutional neural networks	SHAPE; MODEL	The efficiency of convolutional neural networks (CNNs) facilitates 3D face reconstruction, which takes a single image as an input and demonstrates significant performance in generating a detailed face geometry. The dependence of the extensive scale of labelled data works as a key to making CNN-based techniques significantly successful. However, no such datasets are publicly available that provide an across-the-board quantity of face images with correspondingly explained 3D face geometry. State-of-the-art learning-based 3D face reconstruction methods synthesize the training data by using a coarse morphable model of a face having non-photo-realistic synthesized face images. In this article, by using a learning-based inverse face rendering, we propose a novel data-generation technique by rendering a large number of face images that are photo-realistic and possess distinct properties. Based on the real-time fine-scale textured 3D face reconstruction comprising decently constructed datasets, we can train two cascaded CNNs in a coarse-to-fine manner. The networks are trained for actual detailed 3D face reconstruction from a single image. Experimental results demonstrate that the reconstruction of 3D face shapes with geometry details from only one input image can efficiently be performed by our method. Furthermore, the results demonstrate the efficiency of our technique to pose, expression and lighting dynamics.																	0941-0643	1433-3058															10.1007/s00521-020-05373-w		SEP 2020											
J								Global Stabilization of Memristive Neural Networks with Leakage and Time-Varying Delays Via Quantized Sliding-Mode Controller	NEURAL PROCESSING LETTERS										Memristive neural network; Time-varying delay; Leakage delay; Global stabilization; Quantized sliding-mode controller; Quantization scheme	EXPONENTIAL SYNCHRONIZATION; STABILITY; PASSIVITY	This pape investigates the global stabilization of memristive neural networks (MNNs) with leakage and time-varying delays via quantized sliding-mode controller. The leakage delay is considered in the MNNs. Sliding mode controller is imported to ensure global stabilization of delayed MNNs. We also introduce two quantization schemes with uniform quantizer and logarithmic quantizer. Our goal is to deal with errors before and after quantization. We give some simulations and comparisons between two quantizers in the end of this paper.																	1370-4621	1573-773X															10.1007/s11063-020-10356-y		SEP 2020											
J								Specialization in Hierarchical Learning Systems A Unified Information-theoretic Approach for Supervised, Unsupervised and Reinforcement Learning	NEURAL PROCESSING LETTERS										Meta-learning; Information theory; Bounded rationality	MODEL; RATIONALITY; MIXTURE; MINDS	Joining multiple decision-makers together is a powerful way to obtain more sophisticated decision-making systems, but requires to address the questions of division of labor and specialization. We investigate in how far information constraints in hierarchies of experts not only provide a principled method for regularization but also to enforce specialization. In particular, we devise an information-theoretically motivated on-line learning rule that allows partitioning of the problem space into multiple sub-problems that can be solved by the individual experts. We demonstrate two different ways to apply our method: (i) partitioning problems based on individual data samples and (ii) based on sets of data samples representing tasks. Approach (i) equips the system with the ability to solve complex decision-making problems by finding an optimal combination of local expert decision-makers. Approach (ii) leads to decision-makers specialized in solving families of tasks, which equips the system with the ability to solve meta-learning problems. We show the broad applicability of our approach on a range of problems including classification, regression, density estimation, and reinforcement learning problems, both in the standard machine learning setup and in a meta-learning setting.																	1370-4621	1573-773X															10.1007/s11063-020-10351-3		SEP 2020											
J								Application of LSTM for short term fog forecasting based on meteorological elements	NEUROCOMPUTING										Fog forecasting; Time series data; Long short-term memory(LSTM)	NEURAL-NETWORKS; PREDICTION; VISIBILITY; POLYNOMIALS; EVENTS	Fog is the main weather phenomenon that causes low visibility, which makes traffic and outdoor work extremely dangerous. In this paper, we propose a novel LSTM framework for short-term fog forecasting. The proposed network framework consists of an LSTM network and fully connected layer. In order to make the proposed LSTM framework work, the meteorological element observation data returned hourly is transferred into time series data. Based on these time series data, four datasets are created for short-term fog forecasting. In order to evaluate the proposed LSTM framework, we conduct comprehensive experiments with different machine learning algorithms. Compared with K-Nearest Neighbor (KNN), AdaBoost and convolutional neural network (CNN) algorithms, the experimental results show that the proposed LSTM framework achieves best prediction performance in four evaluation criteria. Especially in TS-Score, the proposed LSTM framework achieve 1.1%, 11%, 3%, and 11% higher performance than the best traditional machine learning algorithm. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						285	291		10.1016/j.neucom.2019.12.129													
J								A survey of CAPTCHA technologies to distinguish between human and computer	NEUROCOMPUTING										CAPTCHA; Usability; Security	HUMAN INTERACTIVE PROOFS; NEURAL-NETWORKS; IMAGE RECOGNITION; AUDIO CAPTCHA; GENERATION; ALGORITHM; MASKING; DROP; DRAG	CAPTCHA, Completely Automated Public Turing test to tell Computers and Humans Apart, is widely used as a security mechanism to classify human and computer. This security mechanism is based on the Turing Test, which has been conceived to ensure network security. Usability is another fundamental issue, which can avoid human users proceeding tedious and time-consuming operation. CAPTCHA design should consider security and usability simultaneously. This paper provides a review on the development of CAPTCHA technologies for human and computer classification, along with their applications and instantiations. Different from previous CAPTCHA survey, this review discusses the CAPTCHA mechanism from usability and security aspects, therefore attacking (anti-classification) and defending (classification) technologies towards current CAPTCHA are both reviewed. Besides, recent emerging CAPTCHA and the attacking techniques are also introduced in this paper, such as game CAPTCHA, deep learning-based attacking, and etc. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						292	307		10.1016/j.neucom.2019.08.109													
J								A survey of decomposition approaches in multiobjective evolutionary algorithms	NEUROCOMPUTING										Decomposition approach; Multiobjective optimization; Evolutionary algorithm	SCALARIZING FUNCTIONS; NSGA-II; OPTIMIZATION; MOEA/D; SELECTION; PERFORMANCE; VERSION	Since the multiobjective evolutionary algorithm based on decomposition (MOEA/D) was proposed by Zhang and Li in 2007, this interesting framework has attracted a considerable attention from researchers. In MOEA/D, a multiobjective optimization problem is decomposed into a series of aggregated subproblems, which are optimized simultaneously in a collaborative way by using the information from their neighboring subproblems. The decomposition approach has significant impact on MOEA/D as it directs the evolutionary search. Many improved MOEA/D variants proposed various kinds of decomposition approaches and have shown promising performance for different kinds of problems. In this paper, we give a survey of decomposition approaches, which are classified into five categories, i.e., the tradition decomposition, the modified Tchebycheffdecomposition, themodified penalty-based boundary intersection decomposition, the constrained decomposition, and other special cases of decomposition. Moreover, discussions are further given in this paper to analyze the performance of different decomposition approaches. One clarifies the difference between Tchebycheffdecomposition and Pareto-based domination. The other one compares the performance of various decomposition approaches on different benchmark problems. Experiments results have demonstrated that the Tchebycheffde composition and its varieties are robust on solving most problems while some specific decomposition approaches are very effective for some problems with special features. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						308	330		10.1016/j.neucom.2020.01.114													
J								Video coding and processing: A survey	NEUROCOMPUTING										Video coding; Redundant information; Intra prediction; Inter prediction; Transform; Entropy coding	MODE DECISION ALGORITHM; PROBABILISTIC NEURAL-NETWORKS; FAST INTRA PREDICTION; CU SIZE DECISION; DCT ARCHITECTURES; FUNCTION APPROXIMATION; PALMPRINT RECOGNITION; ADAPTIVE QUANTIZATION; LEARNING ALGORITHM; FEATURE-EXTRACTION	Vision is the main way for people to perceive and recognize the world. In this paper, four categories of the redundant information of video encoding, spatial redundancy, time redundancy, visual redundancy and statistical redundancy, are first introduced. Spatial redundancy is redundant information existing in static frames, time redundancy is the luminance and chrominance correlation between adjacent frames in the video sequence, visual redundancy is information that the human visual system cannot perceive, statistical redundancy is the expression redundancy of the information source symbols. Then the performance assessment of video coding are introduced. And the future development of video coding and conclusion are finally discussed in this paper. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						331	344		10.1016/j.neucom.2019.07.115													
J								Efficient integration of generative topic models into discriminative classifiers using robust probabilistic kernels	PATTERN ANALYSIS AND APPLICATIONS										Hybrid (generative-discriminative) models; Support vector machine; Conjugate priors; Beta-Liouville; Generalized Dirichlet; Probabilistic kernels; Document classification	CLASSIFICATION; SPACE	We propose an alternative to the generative classifier that usually models both the class conditionals and class priors separately, and then uses the Bayes theorem to compute the posterior distribution of classes given the training set as a decision boundary. Because SVM (support vector machine) is not a probabilistic framework, it is really difficult to implement a direct posterior distribution-based discriminative classifier. As SVM lacks in full Bayesian analysis, we propose a hybrid (generative-discriminative) technique where the generative topic features from a Bayesian learning are fed to the SVM. The standard latent Dirichlet allocation topic model with its Dirichlet (Dir) prior could be defined as Dir-Dir topic model to characterize the Dirichlet placed on the document and corpus parameters. With very flexible conjugate priors to the multinomials such as generalized Dirichlet (GD) and Beta-Liouville (BL) in our proposed approach, we define two new topic models: the BL-GD and GD-BL. We take advantage of the geometric interpretation of our generative topic (latent) models that associate aK-dimensional manifold (Kis the size of the topics) embedded into aV-dimensional feature space (word simplex) whereVis the vocabulary size. Under this structure, the low-dimensional topic simplex (the subspace) defines a document as a single point on its manifold and associates each document with a single probability. The SVM, with its kernel trick, performs on these document probabilities in classification where it utilizes the maximum margin learning approach as a decision boundary. The key note is that points or documents that are close to each other on the manifold must belong to the same class. Experimental results with text documents and images show the merits of the proposed framework.																	1433-7541	1433-755X															10.1007/s10044-020-00917-1		SEP 2020											
J								(alpha, beta, gamma)-cut set based ranking approach to solving bi-matrix games in neutrosophic environment	SOFT COMPUTING										Bi-matrix game; Triangular fuzzy number; Single-valued triangular neutrosophic number; (alpha, beta, gamma)-cut set	FUZZY; SYSTEMS	Uncertainty provides an importance in decision making problems like game theory. Several types of uncertainties occur in the literature as fuzzy, soft, rough, interval, etc., and game theory is treated by these types of uncertainties and vagueness by game theorists and others in different aspects. Neutrosophic set and logic are emerged nowadays as another type of uncertainty. Single-valued triangular neutrosophic numbers liberally assume the indeterminacy in choice of elements based upon decision makers' intuition, assumption, judgement, behaviour, evaluation and decision. Here, a new ranking approach is based on the (alpha, beta, gamma)-cut of single-valued triangular neutrosophic number and is applied on bi-matrix game theory. We compare our derived results with some previously defined score and accuracy functions and put some interesting and comparatively good results without any plausible fiasco. In this paper, our principal purpose is to validate and approve the proposed contemplations by applying it on illuminating real-life problems in neutrosophic realm through bi-matrix game theory.																	1432-7643	1433-7479															10.1007/s00500-020-05332-6		SEP 2020											
J								A novel global harmony search algorithm for solving numerical optimizations	SOFT COMPUTING										Harmony search; Improved differential harmony search; Generalized opposition-based learning with global harmony search; Novel global harmony search; Intersect mutation global harmony search	DESIGN	Harmony search (HS) is a type of population-based optimization algorithm that is introduced based on the idea of musical instruments being tuned to obtain the best harmony state. Several versions of HS have been presented, with global harmony search (GHS) considered one of the most popular. Although GHS is efficient in solving various optimization problems, a new position updating mechanism has been added to improve its efficiency and help it avoid getting stuck in local minima. The novel algorithm proposed in this paper is called the intersect mutation global harmony search algorithm (IMGHSA), which has been tested and evaluated on a set of well-known benchmark functions. The IMGHSA is compared with several improved variants of the HS algorithm, such as the basic version of harmony search (HS), improved differential harmony search, generalized opposition-based learning with global harmony search , and novel global harmony search. The experimental results show that the proposed IMGHSA performs better than the state-of-the-art HS variants and has a more robust convergence when optimizing objective functions in terms of the solution accuracy and efficiency.																	1432-7643	1433-7479															10.1007/s00500-020-05341-5		SEP 2020											
J								Multi-criteria decision-making using a complete ranking of generalized trapezoidal fuzzy numbers	SOFT COMPUTING										Multi-criteria decision-making; Fuzzy number; Generalized trapezoidal fuzzy number; Ranking function; Midpoint score; Spread	DIFFERENT LEFT HEIGHTS; MAXIMIZING SET; ALTERNATIVES	The decision-making under several uncertainties is a major concern to choose the best alternative among the several separate alternatives. This paper deals with the uncertainty of using a complete ranking classification of generalized trapezoidal fuzzy numbers (GTrFNs). In the view of that several measures such as mode, spread, midpoint the score, radius, left and right fuzziness score and linguistic expression are considered to compute the ranking order of GTrFN. Using the proposed complete ranking of GTrFN, this paper presents a method for solving fuzzy multi-criteria decision-making problems. The comparative analysis of existing methods with our proposed method is also described.																	1432-7643	1433-7479															10.1007/s00500-020-05322-8		SEP 2020											
J								A spiking neural network with probability information transmission	NEUROCOMPUTING										Spiking neural network; Probability Information Transmission; Probabilistic Spike Response Model	CLASSIFICATION; MODEL; BACKPROPAGATION; ALGORITHM	The spiking neural network provides a potential computing paradigm for simulating the complex information processing mechanism of the brain. Even though there are many theoretical and practical achievements, several crucial problems remain to be addressed for the existing spiking learning algorithm. In this paper, a Probabilistic Spike Response Model (PSRM), of which ignition mode is determined neither by the difference between the threshold and membrane voltage nor in the form of pulses, is proposed from a probabilistic perspective. The PSRM reconstructs a probability relationship between the membrane voltage and neuron ignition to transmit information in the form of probabilities and redefines pulses. The expression of the pulse sequence makes the PSRM model continuous and differentiable so as to avoid the difficulty in using supervised learning algorithms. In our study, the single-layer learning algorithm and multilayer learning algorithm based on the PSRM model are also given. As shown in our experiments, the proposed method is of theoretical and practical value. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						1	12		10.1016/j.neucom.2020.01.109													
J								Scaled consensus control of heterogeneous multi-agent systems with switching topologies	NEUROCOMPUTING										Scaled consensus; Heterogeneous multi-agent systems; Switching communication topologies; Time-varying delays	CONTAINMENT	In this contribution, we aim to examine the scaled consensus problem for heterogeneous multi-agent systems, which comprise two kinds of agents: the agents with first-order dynamics and the agents with second-order dynamics. The scaled consensus here means that the ratios between the states of the agents asymptotically approach specified constants instead of the same value. Firstly, appropriate distributed control protocols are designed for first-order and second-order networked agents, respectively. Particularly, the effects of switching communication networks and time-varying delays on model performance are investigated in this paper. Secondly, an augmented system approach based on algebraic graph theory and non-negative matrix theory is adopted to solve the proposed scaled consensus problem. Finally, a sufficient criterion is established to certify the scaled consensus performance of mixed agents. The correctness of the theoretical result is demonstrated through several simulation examples. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						13	20		10.1016/j.neucom.2019.09.017													
J								Enhanced Spiking Neural Network with forgetting phenomenon based on electronic synaptic devices	NEUROCOMPUTING										Forgetting; Spiking Neural Network; Spike-timing-dependent plasticity; Electronic synaptic devices; MNIST; Non-ideality	MEMORY	Forgetting is an essential phenomenon in human brain to help people get away from chaos. Such phenomenon could be emulated in the electronic synaptic device, which is the critical unit for hardware implementation of Spiking Neural Network (SNN). To the best of our knowledge, however, forgetting phenomenon has rarely been applied in weights update of traditional SNNs based on spike-timing-dependent plasticity (STDP). In this work, we propose a novel SNN training algorithm using forgetting phenomenon. The weights update procedures are composed of potentiation and forgetting, and implemented by single-polarity pulses and time intervals between training samples. Benchmarked with the MNIST handwriting dataset, we demonstrate the algorithm's performance by a single-layer perceptron with 784 x10 synapses. Besides, the influence of some non-ideal factors are taken into consideration to analyze the robust performance of enhanced SNN. The simulation result indicates the proposed SNN with forgetting phenomenon exhibits faster convergence speed and higher recognition rate (88.07%) than traditional SNN with similar network scale. Moreover, it shows a good tolerance to the non-linear conductance response and variation while it has less endurance requirement of electronic synaptic devices. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						21	30		10.1016/j.neucom.2019.09.030													
J								Synchronization in duplex networks of coupled Rossler oscillators with different inner-coupling matrices	NEUROCOMPUTING										Multiplex network; Inner-coupling function; Synchronized region; Synchronization	COMPLEX DYNAMICAL NETWORKS; SYSTEMS	The traditional and extended master stability framework cannot work for multiplex networks with different inner-coupling functions on different layers. In this paper, we thoroughly investigate the influence of inner-coupling functions on the synchronized regions with respect to intra- and inter-layer coupling strength in two-layer multiplex networks composed of linearly coupled Rossler oscillators with identical or nonidentical intra-layer topological structures. We focus on three typical inner-coupling matrices, representing the classical bounded, unbounded and empty synchronized regions. We numerically investigate intra-layer synchronization (synchronization of nodes within each layer), inter-layer synchronization (synchronization of node pairs across layers) and global synchronization (synchronization of all nodes) in duplex networks with identical or nonidentical intra-layer structures, for all the combinations of the three typical inner-coupling matrices. Interestingly, we find that whatever the inner-coupling matrices are, the intra-layer synchronized regions of the two layers will become the same type in most cases, which should be due to the interaction between layers. Particularly, the inner-coupling matrix that leads to an empty synchronized region in an isolated network does not necessarily result in empty synchronized regions within or across layers, though it will lead to empty global synchronized regions while working as the inter-layer inner-coupling function. Numerical results also imply that structural difference of the two intra-layer networks will weaken inter-layer as well as intra-layer synchronizability. (C) 2019 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 30	2020	408						31	41		10.1016/j.neucom.2019.10.011													
J								Convolutional neural networks with fractional order gradient method	NEUROCOMPUTING										Fractional order calculus; Gradient method; Neural networks; Backward propagation	ALGORITHM	This paper proposes a fractional order gradient method for the backward propagation of convolutional neural networks. To overcome the problem that fractional order gradient method cannot converge to real extreme point, a simplified fractional order gradient method is designed based on Caputo's definition. The parameters within layers are updated by the designed gradient method, but the propagations between layers still use integer order gradients, and thus the complicated derivatives of composite functions are avoided and the chain rule will be kept. By connecting every layers in series and adding loss functions, the proposed convolutional neural networks can be trained smoothly according to various tasks. Some practical experiments are carried out in order to demonstrate fast convergence, high accuracy and ability to escape local optimal point at last. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						42	50		10.1016/j.neucom.2019.10.017													
J								Q-Learning-based parameters adaptive algorithm for active disturbance rejection control and its application to ship course control	NEUROCOMPUTING										Q-Learning; Reinforcement learning; Adaptive control; Active disturbance rejection control (ADRC); Ship course control	NETWORK	This paper concerns with the method of parameters tuning and the capability of active disturbance rejection control (ADRC) to the nonlinear plants. Firstly, an adaptive method of ADRC parameters based on Q-learning is proposed. Besides, to verify the effectiveness of the proposed parameter tuning strategy, the novel method is applied to the ship course control which has multifarious uncertainties due to the disturbance of wind, waves and currents. And then, for better control performance, when the training of Q value-table, the states stochastic initialize of each episode is not equiprobability, different state has different weights. The simulation results of both adaptive ADRC and linear active disturbance rejection control (LADRC) show that the proposed algorithm has the advantages of robustness and higher tracking precision. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						51	63		10.1016/j.neucom.2019.10.060													
J								Adaptive forward vehicle collision warning based on driving behavior	NEUROCOMPUTING										Advanced driver assistance system (ADAS); Adaptive forward vehicle collision warning; Abnormal driver behavior; Multi-scale detection	CAMERA CALIBRATION; TRACKING	Forward Vehicle Collision Warning (FCW) is one of the most important functions for the Advanced Driver Assistance System (ADAS). In this procedure, vehicle detection and distance measurement are core components, requiring accurate localization and estimation. In this paper, we propose a simple but efficient forward vehicle collision warning framework by aggregating monocular distance measurement and precise vehicle detection. In order to obtain forward vehicle distance, a quick camera calibration method which only needs three physical points to calibrate related camera parameters is utilized. As for the forward vehicle detection, a multi-scale detection algorithm that regards the result of calibration as distance prior is proposed to improve the precision. What's more, traditional deterministic FCW approaches cannot be personalized for different drivers, which will lead to false warnings when drivers are in diverse driving status. Therefore, abnormal driver behaviors are introduced to make FCW adaptive. Specifically, the proposed adaptive FCW generates warnings by considering the different behaviors of the driver. Intensive experiments are conducted in our established real scene dataset and the results have demonstrated the effectiveness of the proposed framework. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						64	71		10.1016/j.neucom.2019.11.024													
J								Bounded consensus control for stochastic multi-agent systems with additive noises	NEUROCOMPUTING										Multi-agent systems (MASs); Bounded consensus control; System noises; Communication noises	MEAN-SQUARE; SUFFICIENT CONDITIONS; ROBUST CONSENSUS; TRACKING; SEEKING	This paper considers bounded consensus problem of continuous-time linear multi-agent systems with both additive system and communication noises under an undirected communication topology. Owning to the coexistence of the additive system and communication noises, the exact consensus cannot reach. Hence, the distributed controller is to be designed such that all the agents can reach to a collection behavior to some degree. It is supposed that each agent can obtain full state of itself and receive its neighbors' state with additive noises. For each agent, the consensus protocol is designed based on the error between the estimated state of its neighbors' and full state of itself. By means of Kalman filtering and matrix analysis, the bound of consensus is given via the solution of a Lyapunov equation. Finally, a simulation example is presented to demonstrate the effectiveness of the proposed control strategy. (C) 2019 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						72	79		10.1016/j.neucom.2019.11.027													
J								Improving deep neural network performance by integrating kernelized Min-Max objective	NEUROCOMPUTING										Kernelized Min-Max objective; Deep neural network; Convolutional neural network; Object recognition; Min-Max strategy; Kernel space	DIMENSIONALITY; CLASSIFIERS; MACHINE	Deep neural networks (DNN), such as convolutional neural networks (CNN) have been widely used for object recognition. However, they are usually unable to ensure the required intra-class compactness and inter-class separability in the kernel space. These are known to be important in pattern recognition for achieving both robustness and accuracy. In this paper, we propose to integrate a kernelized Min-Max objective in the DNN training in order to explicitly enforce both kernelized within-class compactness and between-class margin. The involved kernel space is implicitly mapped from the feature space associated with a certain upper layer of DNN by exploiting a kernel trick, while the Min-Max objective in this space is interpolated with the original DNN loss function and finally optimized in the training phase. With a very small additional computation cost, the proposed strategy can be easily integrated in different DNN models without changing any other part of the original model. The comparative recognition accuracy of the proposed method is evaluated with multiple DNN models (including shallow CNN, deep CNN and deep residual neural network models) on two benchmark datasets: CIFAR-10 and CIFAR-100. Extensive experimental results demonstrate that the integration of kernelized Min-Max objective in the training of DNN models can achieve better results compared to state-of-the-art models, without incurring additional model complexity. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						82	90		10.1016/j.neucom.2019.08.101													
J								Information-preserving feature filter for short-term EEG signals	NEUROCOMPUTING										Deep learning; EEG; Generative adversarial networks; Physiological signals; Image translation	NEURAL-NETWORKS; CLASSIFICATION; COMMUNICATION; INTERFACES; PRIVACY	The brain-computer interface (BCI) has become one of the most important biomedical research fields and has many useful applications. An important component of BCI, electroencephalography (EEG) is in general sensitive to noise and rich in all kinds of information from our brain. In this paper, we study the feature fusion problem in electroencephalography (EEG). We introduce (1) a discriminative feature extractor which can classify multi-labels from short-term EEG signals, and (2) a new strategy to filter out unwanted features from EEG signals based on our feature extractor. Filtering out signals relating to one property of the EEG signal while retaining another is similar to the way we can listen to just one voice during a party, which is known as the cocktail party problem in the machine learning area. Built based on the success of short-term EEG discriminative model, the feature filter is an end-to-end framework which is trained to map EEG signals with unwanted features directly to EEG signals without those features. Our experimental results on an alcoholism dataset show that our novel model can filter out over 90% of alcoholism information on average from EEG signals, with an average of only 4.2% useful feature accuracy lost, showing effectiveness for our proposed task. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						91	99		10.1016/j.neucom.2019.11.106													
J								Driver sleepiness detection from EEG and EOG signals using GAN and LSTM networks	NEUROCOMPUTING										EEG; EOG; Alpha blocking; Alpha wave attenuation-disappearance; GAN; LSTM; Sleepiness detection	VIGILANCE ESTIMATION; ALPHA OSCILLATIONS; DROWSINESS; WIRELESS; SYSTEM	In recent years, sleepiness during driving has become a main cause for traffic accidents. However, the fact is that we know very little yet about the electrophysiological marker for assessing diver sleepiness. Previous studies and our researches have shown that alpha blocking phenomenon and alpha wave attenuation-disappearance phenomenon represent two different sleepiness levels, the relaxed wakefulness and the sleep onset, respectively. This paper proposes a novel model for driver sleepiness detection based on electroencephalography (EEG) and electrooculography (EOG) signals. Our model aims to track the change in alpha waves and differentiate the two alpha-related phenomena. Continuous wavelet transform is adopted to extract features from physiological signals in both time and frequency domains. Meanwhile, Long-Short Term Memory (LSTM) network is introduced to deal with temporal information of EEG and EOG signals. To deal with insufficient physiological sample problem, generative adversarial network (GAN) is used to augment the training dataset. Experimental results indicate that the F1 score for detecting start and end points of alpha waves reaches to around 95%. And Conditional Wasserstein GAN (CWGAN) we adopted was effective in augmenting dataset and boost classifier performance. Meanwhile, our LSTM classifier achieved a mean accuracy of 98% for classifying end points of alpha waves under leave-one-subject-out cross validation. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						100	111		10.1016/j.neucom.2019.05.108													
J								A learning-based approach for surface defect detection using small image datasets	NEUROCOMPUTING										Defect detection; Convolutional neural network; Transfer learning; Multi-model ensemble; Generative adversarial nets(GANs)	RECOGNITION	Quality management is a fundamental component of a manufacturing process. In this paper, we propose a promising learning-based approach for automatic defect detection based on small image datasets. With the help of Wasserstein generative adversarial nets (WGANs), feature-extraction-based transfer learning techniques, and multi-model ensemble framework, our approach is able to deal with imbalanced and severely rare images with defects successfully, which is practically useful to the manufacturing industry. In addition, we reduce the false negative rate (FNR) as much as possible. Extensive experiments of defect detection on decorative sheets and welding joints achieve FNR accuracy results as 0.47% and 1.9% respectively, while traditional vision methods using in the production line can only achieve FNR results at about 20% under the similar circumstance, thus substantiating the proposed approach is quite effective for surface defect detection. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						112	120		10.1016/j.neucom.2019.09.107													
J								A cascade adaboost and CNN algorithm for drogue detection in UAV autonomous aerial refueling	NEUROCOMPUTING										Autonomous aerial refueling; Cascade adaboost; Tiny convolutional neural networks; Improved focal loss	NAVIGATION; PROBE; CLASSIFICATION; SIMULATION; SYSTEM; SHAPE	To promote the combat capability of unmanned aerial vehicles (UAVs) in the future battlefield, the autonomous aerial refueling (AAR) technology becomes a challenging research issue. An accurate position relationship between the tanker and the receiver is significant for AAR. A novel drogue detection method is presented in this paper. The Adaptive boosting (Adaboost) and the convolutional neural networks (CNN) classifier with the improved focal loss (IFL) function are utilized to detect the drogue in complex environments. The sample imbalance during the training stage of the CNN classifier is solved by the IFL function. The PyTorch deep learning framework is employed to implement the software system with the graphics processing units (GPUs). Real scenario images with a mimetic drogue on the tanker are captured for training and testing dataset by the airborne camera on the receiver. The experimental results indicate that the presented algorithm can accelerate the detection speed and improve the detection accuracy. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 30	2020	408						121	134		10.1016/j.neucom.2019.10.115													
J								Reconstructing multi-echo magnetic resonance images via structured deep dictionary learning	NEUROCOMPUTING										Deep learning; Dictionary learning; Medical imaging	MRI RECONSTRUCTION; NETWORKS	Multi-echo magnetic resonance (MR) images are acquired by changing the echo times (for T2 weighted) or relaxation times (for T1 weighted) of scans. The resulting (multi-echo) images are usually used for quantitative MR imaging. Acquiring MR images is a slow process and acquiring multi scans of the same cross section for multi-echo imaging is even slower. In order to accelerate the scan, compressed sensing (CS) based techniques have been advocating partial K-space (Fourier domain) scans; the resulting images are reconstructed via structured CS algorithms. In recent times, it has been shown that instead of using off-the-shelf CS, better results can be obtained by adaptive reconstruction algorithms based on structured dictionary learning. In this work, we show that the reconstruction results can be further improved by using structured deep dictionaries. Experimental results on real datasets show that by using our proposed technique the scan-time can be cut by half compared to the state-of-the-art. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						135	143		10.1016/j.neucom.2019.11.107													
J								Robust nuclei segmentation in histopathology using ASPPU-Net and boundary refinement	NEUROCOMPUTING										Nuclei segmentation; Histopathology; Atrous spatial pyramid pooling U-Net; Concave point detection	ACTIVE CONTOUR; CANCER; SCHEME; CLASSIFICATION; RESOLUTION; NETWORKS; PROSTATE	Automated nuclear segmentation in histopathological images is a prerequisite for a computer-aided diagnosis framework. However, it remains a challenging problem due to the nucleus occlusion or overlapping, shape variation, and image background complexity. Recently, deep learning techniques are widely used in analyzing digital histopathology. We present a computerized image-based method for automatically segmenting nuclei using an integration of a deep learning model and an improved concave point detection algorithm. A modified atrous spatial pyramid pooling U-Net (ASPPU-Net) is derived to capture multi-scale nuclei features and obtain nuclei context information without reducing the spatial resolution of feature map. A weighted binary cross entropy loss function with Dice loss function is used to better handle the data unbalance problem. An accelerated concave point detection method allows to effectively and accurately segmenting highly overlapping nuclei. Our ASPPU-Net based method was tested on four independent data cohorts and achieved the highest Dice similarity coefficient of 0.83, and pixel wise accuracy of 0.95. The experimental results suggested that the combination of ASPPU-Net model and concave point detection method was able to gain improved performance in separating both isolated and touching clustered nuclei in histopathology. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						144	156		10.1016/j.neucom.2019.08.103													
J								Accelerating deep reinforcement learning model for game strategy	NEUROCOMPUTING										Deep reinforcement learning; Convolutional neural network; Depthwise separable convolution; Binary weight network	GO	In recent years, deep reinforcement learning has achieved impressing accuracies in games compared with traditional methods. Prior schemes utilized Convolutional Neural Networks (CNNs) or Long Short-Term Memory networks (LSTMs) to improve the performances of the agents. In this paper, we consider the issue from a different perspective when the training and inference of deep reinforcement learning are required to be performed with limited computing resources. Mainly, we propose two efficient neural network architectures of deep reinforcement learning: Light-Q-Network (LQN) and Binary-Q-Network (BQN). In LQN, The depth-wise separable CNNs are utilized in memory and computation saving. While, in BQN, the weights of convolutional layers are binary that help in shortening the training time and reduce memory consumption. We evaluate our approach on Atari 2600 domain and StarCraft II mini-games. The results demonstratethe efficiency of the proposed architectures. Though performances of agents in most games are still super-human, the proposed methods advance the agent from sub to super-human performance in particular games. Also, we empirically find that non-standard convolution and non-full-precision networks do not affect agent learning game strategy. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						157	168		10.1016/j.neucom.2019.06.110													
J								Online sequential extreme learning machine based adaptive control for wastewater treatment plant	NEUROCOMPUTING										Wastewater treatment plant; Benchmark simulation model no.1 (BSM1); OS-ELM algorithm; Adaptive control	DISSOLVED-OXYGEN CONTROL; NEURAL-NETWORK; PREDICTIVE CONTROL; FUZZY CONTROL; MODEL	Wastewater Treatment Plant (WWTP) is challenging to regulate for its complex chemical and biological characteristics, and its precise mathematical model is usually not accessible due to the limitation of available measurement. Traditional methods highly rely on human intervention and cannot adapt to the varying environment. Meanwhile, adaptive neural network based control strategies are encountered with dilemmas of local minima, slow convergence, huge time consumption, and low efficiency. To overcome such challenges, in this paper, a novel Online Sequential Extreme Learning Machine (OS-ELM) based adaptive control is discussed. In contrast, no a prior human experience or off-line training phase is required. It also has fast training speed thanks to randomly generated parameters of the hidden layer and Moore-Penrose pseudo-inverse. Moreover, the performance of the system is guaranteed even in the presence of time-varying dynamics and uncertainties through a learning mechanism in an online manner. The stability of the closed-loop system is shown strictly and extensive comparison case studies substantiate the feasibility of the scheme. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						169	175		10.1016/j.neucom.2019.05.109													
J								Neural networks-based adaptive dynamic surface control for vehicle active suspension systems with time-varying displacement constraints	NEUROCOMPUTING										Neural networks; Dynamic surface control; Active suspension systems; Barrier Lyapunov functions	UNCERTAIN NONLINEAR-SYSTEMS; BACKSTEPPING CONTROL; FUZZY CONTROL; TRACKING CONTROL; STATE; STABILITY; DESIGN	This paper addresses controlling of displacements of vehicle active suspension systems with an active seat suspension and a human-body model. A neural networks-based dynamic surface control strategy is constructed for the active suspension systems. Specifically, asymmetric time-varying barrier Lyapunov functions are applied to ensure that the displacements of vehicle active suspensions do not violate their time-varying constraint bounds. Neural networks are used to approximate unknown functions in the active suspension systems and their basis function properties are employed to deal with functions with non-strict form. Dynamic surface control technique is used to reduce the complexity of the controller. Advantages of the control strategy are substantiated by two simulation examples. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						176	187		10.1016/j.neucom.2019.08.102													
J								A comprehensive survey on support vector machine classification: Applications, challenges and trends	NEUROCOMPUTING										SVM; Classification; Machine learning	SEMI-SUPERVISED SVM; NEAREST-NEIGHBOR; NEURAL-NETWORKS; FEATURE-SELECTION; DECISION TREE; TEXT CATEGORIZATION; PARAMETER SELECTION; HOMOLOGY DETECTION; FACE DETECTION; RBF KERNEL	In recent years, an enormous amount of research has been carried out on support vector machines (SVMs) and their application in several fields of science. SVMs are one of the most powerful and robust classification and regression algorithms in multiple fields of application. The SVM has been playing a significant role in pattern recognition which is an extensively popular and active research area among the researchers. Research in some fields where SVMs do not perform well has spurred development of other applications such as SVM for large data sets, SVM for multi classification and SVM for unbalanced data sets. Further, SVM has been integrated with other advanced methods such as evolve algorithms, to enhance the ability of classification and optimize parameters. SVM algorithms have gained recognition in research and applications in several scientific and engineering areas. This paper provides a brief introduction of SVMs, describes many applications and summarizes challenges and trends. Furthermore, limitations of SVMs will be identified. The future of SVMs will be discussed in conjunction with further applications. The applications of SVMs will be reviewed as well, especially in the some fields. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						189	215		10.1016/j.neucom.2019.10.118													
J								Recent development in face recognition	NEUROCOMPUTING										Biometrics; Face recognition; Digital face; Scanned face; Face features; Deep learning; Indexing schemes	PROBABILISTIC NEURAL-NETWORKS; EXPRESSION VARIANT FACES; FEATURE-EXTRACTION; COMPONENT ANALYSIS; FUNCTION APPROXIMATION; PALMPRINT RECOGNITION; SPARSE REPRESENTATION; LEARNING ALGORITHM; EFFICIENT METHOD; IMAGE	Face stands out as a preferable biometric trait for automatic human authentication as it is intuitive and non-intrusive. This paper investigates various feature-based automatic face recognition approaches in detail. High degree of freedom in head movement and human emotion leads a face recognition system to face critical challenges in terms of pose, illumination and expression. Human face also undergoes irreversible changes due to aging. These factors makes the process of face recognition non trivial and hard. This paper also provides a review of the facial recognition approaches individually dealing with these issues. Applications of face recognition in the forensic domain sometimes needs identification using a scanned facial image. The scenario is quite useful to get investigative leads. Important approaches for the same are also been discussed in the manuscript. Recent developments in the low-cost image capturing devices has flooded the facial image databases with a lot of images, at the same time availability of GPU based compute power has helped develop deep learning approaches to handle the face recognition at a very accurate and massive level. The same has also been surveyed and analyzed in the manuscript. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						231	245		10.1016/j.neucom.2019.08.110													
J								Plant species recognition methods using leaf image: Overview	NEUROCOMPUTING										Plant species recognition; Subspace learning; Sparse representation; Deep learning	ORTHOGONAL DISCRIMINANT PROJECTION; WEIGHTED SPARSE REPRESENTATION; PROBABILISTIC NEURAL-NETWORKS; FEATURE-SELECTION; FEATURE-EXTRACTION; FUNCTION APPROXIMATION; LEARNING ALGORITHM; FACE RECOGNITION; SHAPE-FEATURES; FEATURE FUSION	Plant plays an important role in agricultural, industrial, medicine, environmental and ecological protection. Recently, with global warming, biodiversity loss, rapid urban development and environmental damage, people have been seriously destroying the natural environments, which results in that a large number of plant species constantly dying and even dying out every year. It is essential to protect plant species. The first step of protecting plants is to recognize them and understand what they are and where they come from. But there are a large number of plant species that have been named on Earth, and many are still unknown yet, it is difficult to identifiy each species. To handle such huge information, develop a quick and efficient classification method has become a significant research. Plant species can be recognized by its leaf, flower, skin, fruit and seed, etc. Relatively speaking, using leaf to recognize plant species is very simple and convenient, and many leaf based plant species recognition methods have been proposed. In this paper, we mainly summarize the existing leaf based plant species identification methods, including plant leaf characteristic, public databases, feature extraction based methods, subspace learning based methods, sparse representation based methods, and deep learning based methods. The aim is to emphasize the importance of plant species identification, train people to know about plant species, and provide guidance and comprehensive study for the beginners in this field, in turn, to treasure and protect plant species. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						246	272		10.1016/j.neucom.2019.09.113													
J								Unconstrained and constrained face recognition using dense local descriptor with ensemble framework	NEUROCOMPUTING										Ensemble face recognition; Local binary pattern (LBP); Symmetric local graph structure (SLGS); Classifiers; Fusion rules	PRINCIPAL COMPONENT ANALYSIS; LINEAR DISCRIMINANT; CLASSIFICATION; FEATURES; PATTERN; SCALE; PCA	This paper presents an ensemble face recognition system which makes use of the novel local descriptor called Dense Local Graph Structure (D-LGS) which is exploited from symmetric LGS that and it uses additional graph structure in addition to its own local graph structure. This additional local graph structure is generated by finding additional corner pixel points through bilinear interpolation of neighborhood pixels. These corner pixels lead to most stable features and information related to local deformation of the image. In this proposed ensemble system, three classifiers, namely K-nearest neighbor, Chi-square and correlation coefficient are used. Further the proposed approach fuses the decisions obtained from individual classifiers through OR rule, majority voting and AND rule. To evaluate the performance of proposed ensemble system, the experiment is conducted with three face databases viz. AT&T (formerly The ORL Database of Faces), UFI and LFW face database. The ensemble face recognition system on the use of novel dense local graph structure has reached the accuracy of 100% on AT&T, 99.3488% on UFI and 87.3372% on LFW face database. Further, the templates of D-LGS are optimized using Genetic algorithm (GA) as part of 'curse-of-dimensionality' and the reduced number of templates give accuracies of 100% on AT&T and 99.2165% on LFW face database. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 30	2020	408						273	284		10.1016/j.neucom.2019.10.117													
J								A Custom EOG-Based HMI Using Neural Network Modeling to Real-Time for the Trajectory Tracking of a Manipulator Robot	FRONTIERS IN NEUROROBOTICS										EOG; HMI; customization calibration; MNN; optimization; robots trajectories	STROKE	Although different physiological signals, such as electrooculography (EOG) have been widely used in the control of assistance systems for people with disabilities, customizing the signal classification system remains a challenge. In most interfaces, the user must adapt to the classification parameters, although ideally the systems must adapt to the user parameters. Therefore, in this work the use of a multilayer neural network (MNN) to model the EOG signal as a mathematical function is presented, which is optimized using genetic algorithms, in order to obtain the maximum and minimum amplitude threshold of the EOG signal of each person to calibrate the designed interface. The problem of the variation of the voltage threshold of the physiological signals is addressed by means of an intelligent calibration performed every 3 min; if an assistance system is not calibrated, it loses functionality. Artificial intelligence techniques, such as machine learning and fuzzy logic are used for classification of the EOG signal, but they need calibration parameters that are obtained through databases generated through prior user training, depending on the effectiveness of the algorithm, the learning curve, and the response time of the system. In this work, by optimizing the parameters of the EOG signal, the classification is customized and the domain time of the system is reduced without the need for a database and the training time of the user is minimized, significantly reducing the time of the learning curve. The results are implemented in an HMI for the generation of points in a Cartesian space (X, Y, Z) in order to control a manipulator robot that follows a desired trajectory by means of the movement of the user's eyeball.																	1662-5218					SEP 29	2020	14								578834	10.3389/fnbot.2020.578834													
J								Novel competitive-cooperative learning models (cclms) based on higher order information sets	APPLIED INTELLIGENCE										Hanman transform; Hesitancy; CCLM; HEFAG; Entropification; Competition and cooperation phases; Entropy function and hesitancy degree; PIS	ALGORITHM	This paper presents two novel competitive-cooperative learning models (CCLM) for achieving goals by human contenders. These models have two phases, viz., Competition phase and Cooperation phase. CCLM based on Hanman Transform (HT) is called HT-CCLM and that using a new concept termed Pervasive Information set is called PIS-CCLM. In the competition phase of HT-CCLM, each contender emulates the effort of best achiever by taking the difference of Hanman Transform values associated with the efforts of an individual and the best achiever whereas in the cooperation phase the differential of HT values of efforts of two random contenders is considered. In PIS-CCLM pervasive information value obtained from hesitancy values are used in the competition phase only. We have also carried out Wilcoxon test to establish the superiority of the proposed HT-CCLM and PIS-CCLM.																	0924-669X	1573-7497															10.1007/s10489-020-01881-3		SEP 2020											
J								Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems	APPLIED INTELLIGENCE										Archimedes' principle; Buoyant force; Optimization; Metaheuristic; Exploration and exploitation	ENGINEERING OPTIMIZATION; EXPLOITATION; EXPLORATION	The difficulty and complexity of the real-world numerical optimization problems has grown manifold, which demands efficient optimization methods. To date, various metaheuristic approaches have been introduced, but only a few have earned recognition in research community. In this paper, a new metaheuristic algorithm called Archimedes optimization algorithm (AOA) is introduced to solve the optimization problems. AOA is devised with inspirations from an interesting law of physics Archimedes' Principle. It imitates the principle of buoyant force exerted upward on an object, partially or fully immersed in fluid, is proportional to weight of the displaced fluid. To evaluate performance, the proposed AOA algorithm is tested on CEC'17 test suite and four engineering design problems. The solutions obtained with AOA have outperformed well-known state-of-the-art and recently introduced metaheuristic algorithms such genetic algorithms (GA), particle swarm optimization (PSO), differential evolution variants L-SHADE and LSHADE-EpSin, whale optimization algorithm (WOA), sine-cosine algorithm (SCA), Harris' hawk optimization (HHO), and equilibrium optimizer (EO). The experimental results suggest that AOA is a high-performance optimization tool with respect to convergence speed and exploration-exploitation balance, as it is effectively applicable for solving complex problems. The source code is currently available for public from: https://www.mathworks.com/matlabcentral/fileexchange/79822-archimedes-optimization-algorithm																	0924-669X	1573-7497															10.1007/s10489-020-01893-z		SEP 2020											
J								Beyond missing: weakly-supervised multi-label learning with incomplete and noisy labels	APPLIED INTELLIGENCE										Multi-label learning; Incomplete and noisy labels; Cost-sensitive; Low-rank and sparse; Label correlations		Weakly-supervised multi-label learning has received much attention more recently, and most of the existing methods focus on such problem with either missing or noisy labels, while the issue with both missing and noisy labels has not been well investigated. In this paper, we propose a novel COst-sensitive label Ranking Approach with Low-rank and Sparse constraints (CORALS) to enrich the missing labels and remove the noisy labels simultaneously. Unlike most existing studies that an indicator matrix needs to be given in advance which may not be available in reality, a label confidence matrix is constructed to reflect the relevance between the labels and the corresponding instances, and then the relevance ordering of all possible labels including both missing and noisy labels on each instance is optimized by minimizing a cost-sensitive ranking loss. By considering the dependencies in both feature space and label space, we exploit the dual low-rank regularization terms to capture the corresponding correlations. Afterwards, noticing the fact that both missing and noisy labels are rare, the sparse regularization term is encoded to constrain such noisy information to be sparse. Comprehensive experimental results demonstrate the effectiveness of the proposed method.																	0924-669X	1573-7497															10.1007/s10489-020-01878-y		SEP 2020											
J								Modelling daily soil temperature by hydro-meteorological data at different depths using a novel data-intelligence model: deep echo state network model	ARTIFICIAL INTELLIGENCE REVIEW										Soil temperature; Deep echo state network; Multilayer perceptron neural network; Random forest; M5Prime tree	ARTIFICIAL NEURAL-NETWORK; EXTREME LEARNING-MACHINE; REGRESSION; PREDICTION; CLIMATE; GROUNDWATER; TRANSPORT; BROMIDE; REGIONS	Soil temperature (T-s) is an essential regulator of a plant's root growth, evapotranspiration rates, and hence soil water content. Over the last few years, in response to the climatic change, significant amount of research has been conducted worldwide to understand the quantitative link between soil temperature and the climatic factors, and it was highlighted that the hydrothermal conditions in the soil are continuously changing in response to the change of the hydro-meteorological factors. A large amount of the models have been developed and used in the past for the analysis and modelling of soil temperature, however, none of them has investigated the robustness and feasibilities of the deep echo state network (Deep ESN) model. A more accurate model for forecastingT(s)presents many worldwide opportunities in improving irrigation efficiency in arid climates and help attain sustainable water resources management. This research compares the application of the novel Deep ESN model versus three conventional machine learning models for soil temperature forecasting at 10 and 20 cm depths. We combined several critical daily hydro-meteorological data into six different input combinations for constructing the Deep ESN model. The accuracy of the developed soil temperature models is evaluated using three deterministic indices. The results of the evaluation indicate that the Deep ESN model outperformed conventional machine learning methods and can reduce the root mean square error (RMSE) accuracy of the traditional models between 30 and 60% in both stations. In the test phase, the most accurate estimation was obtained by Deep ESN at depths of 10 cm by RMSE = 2.41 degrees C and 20 cm by RMSE = 1.28 degrees C in Champaign station and RMSE = 2.17 degrees C (10 cm) and RMSE = 1.52 degrees C (20 cm) in Springfield station. The superior performance of the Deep ESN model confirmed that this model can be successfully applied for modellingT(s)based on meteorological paarameters.																	0269-2821	1573-7462															10.1007/s10462-020-09915-5		SEP 2020											
J								Genetic programming in civil engineering: advent, applications and future trends	ARTIFICIAL INTELLIGENCE REVIEW										Civil engineering; Prediction; Classification; Genetic programming; Machine learning; Deep learning	ARTIFICIAL NEURAL-NETWORK; SHEAR-STRENGTH; COMPRESSIVE STRENGTH; CONCRETE STRENGTH; TENSILE-STRENGTH; FORMULATION; BEAMS; PREDICTION; REGRESSION; DESIGN	Over the past two decades, machine learning has been gaining significant attention for solving complex engineering problems. Genetic programing (GP) is an advanced framework that can be used for a variety of machine learning tasks. GP searches a program space instead of a data space without a need to pre-defined models. This method generates transparent solutions that can be easily deployed for practical civil engineering applications. GP is establishing itself as a robust intelligent technique to solve complicated civil engineering problems. This paper provides a review of the GP technique and its applications in the civil engineering arena over the last decade. We discuss the features of GP and its variants followed by their potential for solving various civil engineering problems. We finally envision the potential research avenues and emerging trends for the application of GP in civil engineering.																	0269-2821	1573-7462															10.1007/s10462-020-09894-7		SEP 2020											
J								The Orbiting Dubins Traveling Salesman Problem: planning inspection tours for a minehunting AUV	AUTONOMOUS ROBOTS										Autonomous underwater vehicles; Data collection planning; Nonholonomic motion planning; Subsea inspection; Traveling salesman problem	SALESPERSON PROBLEMS; SURVEILLANCE; CURVATURE; TRANSFORMATION; ALGORITHMS; VEHICLES; PATHS	The Orbiting Dubins Traveling Salesman Problem (ODTSP) is to plan a minimum-time tour for a Dubins vehicle model to inspect a set of targets in the plane by orbiting each target along a circular arc. This problem arises in underwater minehunting, where targets are mine-like objects on the sea bottom that are inspected by a sonar-equipped underwater vehicle. Each orbit subtends a prescribed angle so that the target's acoustic response is measured from a variety of target-sensor relative geometries to aid in classifying it. ODTSP tours consist of circular-arc orbits joined by Dubins paths, and the optimization problem is to partition the set of targets into orbits and determine the position, radius, direction, and vehicle entry angle of each. Algorithms are presented for the restricted case, where each orbit inspects a single target (only), and the general case, where orbits inspect multiple targets. The approach is facilitated by analytical conditions that identify admissible clusters of targets as cliques of a disk graph. The ODTSP is extended to consider path planning in the presence of a steady uniform current.																	0929-5593	1573-7527															10.1007/s10514-020-09946-5		SEP 2020											
J								Real-time application of swarm and evolutionary algorithms for line follower automated guided vehicles: a comprehensive study	EVOLUTIONARY INTELLIGENCE										Swarm intelligence; Evolutionary algorithm; Line follower; Machine vision; Automated guided vehicle		One of the most economical forms of automated guided vehicles (AGV) is a vision-based line follower. A line follower uses machine vision to extract the path shape from the captured image and follows it. Among many methods for path detection, some studies suggested using the real-time application of meta-heuristic population-based algorithms for visual line follower AGV. Generally, Swarm Intelligence and Evolutionary Algorithms are not well suited for real-time applications as they need generations to evolve. For this reason, a comprehensive study is presented to find the best solutions to this particular application. Artificial Bee Colony, Genetic Algorithm, Harmony Search, Imperialist Competitive Algorithm, and Particle Swarm Optimization were studied with three proposed objective functions that could assist path shape detection. The fastest and most reliable solution is optimized and tested on a real AGV platform. The AGV designed for this research has an independent onboard Raspberry Pi 3 with an ARM processor and it is capable of traversing the track fast and reliably. Furthermore, the proposed system does not require edge detection or down-sampling on captured images. Additionally, our newly developed direction inferring technique, the Triangle Closest Midpoint, enables the AGV to find its path even with faulty or incomplete input. As a result, a novel real-time meta-heuristic line follower AGV is presented in this research.																	1864-5909	1864-5917															10.1007/s12065-020-00496-4		SEP 2020											
J								LaSOT: A High-quality Large-scale Single Object Tracking Benchmark	INTERNATIONAL JOURNAL OF COMPUTER VISION										Visual tracking; Large-scale benchmark; High-quality dense annotation; Tracking evaluation	VISUAL TRACKING	Despite great recent advances in visual tracking, its further development, including both algorithm design and evaluation, is limited due to lack of dedicated large-scale benchmarks. To address this problem, we presentLaSOT, a high-qualityLarge-scaleSingleObjectTracking benchmark. LaSOT contains a diverse selection of 85 object classes, and offers 1550 totaling more than 3.87 million frames. Each video frame is carefully and manually annotated with a bounding box. This makes LaSOT, to our knowledge, the largest densely annotated tracking benchmark. Our goal in releasing LaSOT is to provide a dedicated high quality platform for both training and evaluation of trackers. The average video length of LaSOT is around 2500 frames, where each video contains various challenge factors that exist in real world video footage,such as the targets disappearing and re-appearing. These longer video lengths allow for the assessment of long-term trackers. To take advantage of the close connection between visual appearance and natural language, we provide language specification for each video in LaSOT. We believe such additions will allow for future research to use linguistic features to improve tracking. Two protocols,full-overlapandone-shot, are designated for flexible assessment of trackers. We extensively evaluate 48 baseline trackers on LaSOT with in-depth analysis, and results reveal that there still exists significant room for improvement. The complete benchmark, tracking results as well as analysis are available at.																	0920-5691	1573-1405															10.1007/s11263-020-01387-y		SEP 2020											
J								Dense crowd counting based on adaptive scene division	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Crowd counting; Granular computing; Density map; Feature extraction; Dilated convolution		With the rapid development of computer vision and artificial intelligence, crowd counting has attracted significant attention from researchers and many well-known methods were proposed. However, due to interocclusions, perspective distortion, and uneven crowd distribution, crowd counting is still a highly challenging task in crowd analysis. Motivated by granular computing, a novel end-to-end crowd counting network (GrCNet) is proposed to enable the problem of crowd counting to be conceptualized at different levels of granularity, and to map problem into computationally tractable subproblems. It shows that by adaptively dividing the image into granules and then feeding the granules into different counting subnetworks separately, the scale variation range of image is narrowed and the the adaptability of counting algorithm to different scenarios is improved. Experiments on four well-known crowd counting benchmark datasets indicate that GrCNet achieves state-of-the-art counting performance and high robustness in dense crowd counting.																	1868-8071	1868-808X															10.1007/s13042-020-01212-5		SEP 2020											
J								An improved lightweight anonymous user authenticated session key exchange scheme for Internet of Things	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet of Things; User authentication; Session key agreement; Security; Smart card loss attack; Stolen verifier attack	AGREEMENT SCHEME; MUTUAL AUTHENTICATION; PROVABLY SECURE; 3-FACTOR AUTHENTICATION; ACCESS-CONTROL; PROTOCOL; PRIVACY; DEVICES	Due to the myriad applications of the Internet of Things (IoT) in various sectors like healthcare, military, industry, safety, etc., there is also a need to secure these systems efficiently. The devices in such networks need to provide services to users in a secure manner. User authentication is a mechanism through which we can provide secure communication between IoT devices. Recently Banerjee et al. outlined a lightweight anonymous user authenticated session key exchange scheme for Internet of Things deployment, which uses three-factor authentication of a user such as smart card, password and biometric. In this paper, we cryptanalyze their scheme and find that it is not secure against smart card loss attack and stolen verifier attack. Then we have proposed an improved scheme to overcome the weaknesses of their scheme. We present the formal security analysis of our scheme using the random oracle model and informal security analysis to show that our scheme is secure against many known attacks. Its formal security verification is carried out using ProVerif tool. Its performance analysis is carried out with the related schemes which shows that our scheme is more secure than other schemes. Also, our scheme does not contain any storage table at the gateway side for authentication.																	1868-5137	1868-5145															10.1007/s12652-020-02532-8		SEP 2020											
J								Multi-attribute decision making using q-rung orthopair fuzzy weighted fairly aggregation operators	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										q-rung orthopair fuzzy numbers; Fairly operations; q-rung orthopair fuzzy weighted fairly aggregation operator; q-rung orthopair fuzzy ordered weighted fairly aggregation operator; MADM; Supplier selection	PYTHAGOREAN MEMBERSHIP GRADES; BONFERRONI OPERATORS; SIMILARITY MEASURE; OPERATIONAL LAWS; MEAN OPERATORS; SETS; TOPSIS; DISTANCES; SELECTION	In this study, in view of expressing the uncertain information more elegantly, we shall enlighten theq-rung orthopair fuzzy sets (q-ROFSs) and theq-rung orthopair fuzzy numbers (q-ROFNs) which are considered to be superior of the intuitionistic fuzzy sets and the Pythagorean fuzzy sets, respectively. Here our aim is towards the development of some new operational laws and their corresponding weighted aggregation operators under theq-rung orthopair fuzzy environment. In this regard, at the very beginning, we define some new neutral or fair operational laws that include the concept of proportional distribution to achieve a neutral or fair treatment to the membership and non-membership functions ofq-ROFN. Subsequently, with these operations, we developq-rung orthopair fuzzy weighted fairly aggregation operator (qROFWFA) andq-rung orthopair fuzzy ordered weighted fairly aggregation operator (qROFOWFA) which can neutrally or fairly serve the membership and non-membership degrees. We observe the noteworthy features of these proposed aggregation operators. Furthermore, we exercise also an MADM (multi-attribute decision-making) approach with multiple decision makers and partial weight information in the framework ofq-rung orthopair fuzzy sets. At the end of this study, we provide an illustrative example to highlight the feasibility and a practical look of the approach proposed herein.																	1868-5137	1868-5145															10.1007/s12652-020-02551-5		SEP 2020											
J								Improved ant colony optimization for achieving self-balancing and position control for balancer systems	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Self-balancing control; Ball balancer setup; Proportional integral derivative control; Ant colony optimization	SLIDING-MODE CONTROL; TRAJECTORY-TRACKING; PID CONTROLLER; PLATE SYSTEM; BALL; DESIGN; IMPLEMENTATION; STABILIZATION; OBSERVER; SCHEME	The balancer systems represent feedback in loop-based underactuated system which is electromechanical, multivariate, and nonlinear. This paper develops a self-balancing controller using an improved ant colony optimization (ACO) to optimize the proportional integral derivative controller (PID) controller. The proposed controller achieves self-balancing control for a ball on the plate by controlling the plate inclination angle. Initially, the modelling of the ball balancer system is achieved with the help of a two degree of freedom (2DoF) ball balancer system controlled by a PID controller. Further, ACO is employed to autonomously evaluate the condition of a process and find the optimal tuning parameters for the PID controller. The transition probability of the ACO is revised to improve the response and convergence speed of the algorithm resulting in an improved ACO. The developed control schemes were applied with the 2DoF ball balancer model both in simulation as well as for the real-time operation. The results depicted the performance of the proposed control scheme by analysing the characteristics such as transient response and steady-state error. Further, stability analysis has been done for the developed control schemes using describing function method for multiple frequencies. The results depicted the superiority of the improved ACO based PID controller over the conventional PID controller.																	1868-5137	1868-5145															10.1007/s12652-020-02566-y		SEP 2020											
J								A novel scheme for employee churn problem using multi-attribute decision making approach and machine learning	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Employee churn; Employee importance model; Retention policy; CatBoost algorithm; MADM method; TOPSIS	TURNOVER; SATISFACTION; SELECTION	Employee churn (ECn) is a crucial problem for any organization that adversely affects its overall revenue and brand image. Many machine learning (ML) based systems have been developed to solve the ECn problem. However, they miss out on some essential issues such as employee categorization, category-wise churn prediction, and retention policy for effectively addressing the ECn problem. By considering all these issues, we propose, in this paper, a multi-attribute decision making (MADM) based scheme coupled with ML algorithms. The proposed scheme is referred as employee churn prediction and retention (ECPR). We first design an accomplishment-based employee importance model (AEIM) that utilizes a two-stage MADM approach for grouping the employees in various categories. Preliminarily, we formulate an improved version of the entropy weight method (IEWM) for assigning relative weights to the employee accomplishments. Then, we utilize the technique for order preference by similarity to ideal solution (TOPSIS) for quantifying the importance of the employees to perform their class-based categorization. The CatBoost algorithm is then applied for predicting class-wise employee churn. Finally, we propose a retention policy based on the prediction results and ranking of the features. The proposed ECPR scheme is tested on a benchmark dataset of the human resource information system (HRIS), and the results are compared with other ML algorithms using various performance metrics. We show that the system using the CatBoost algorithm outperforms other ML algorithms.																	0925-9902	1573-7675															10.1007/s10844-020-00614-9		SEP 2020											
J								Stabilization and Tracking Control Algorithms for VTOL Aircraft: Theoretical and Practical Overview	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Multirotor aerial systems; Classical approach; Virtual appraoch; Nonlinear; Linear backstepping; Nested saturation; Hyperbolic bounded control	SLIDING-MODE CONTROL; TRAJECTORY TRACKING; QUADROTOR UAV; CONTROL STRATEGIES; INPUT; INTEGRATORS; SATURATION; FLATNESS	Control theory applied to multirotor aerial systems (MAS) has gained attention with the recent increase on the power computation for embedded systems. These systems are now able to perform the calculations needed for a variety of control techniques, with lower cost of sensors and actuators. These types of control algorithms are applied to the position and the attitude of MAS. In this paper, a brief overview evaluation of popular control algorithms for multirotor aerial systems, especially for VTOL - Vertical Take-Off and Landing aircraft, is presented. The main objective is to provide a unified and accessible analysis, placing the classical model of the VTOL vehicle and the studied control methods into a proper context. In addition, to provide the basis for beginner users working in aerial vehicles. In addition, this work contributes in presenting a comprehensive analysis of the implementation for the Nonlinear and Linear Backstepping, Nested Saturation and the Hyperbolic Bounded Controllers. These techniques are selected and compared to evaluate the performance of the aircraft, by simulations and experimental studies.																	0921-0296	1573-0409															10.1007/s10846-020-01252-7		SEP 2020											
J								A Common Optimization Framework for Multi-Robot Exploration and Coverage in 3D Environments	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Multi-Robot systems; Cooperative exploration; Optimal coverage	CENTROIDAL VORONOI TESSELLATIONS	This paper studies the problems of static coverage and autonomous exploration of unknown three-dimensional environments with a team of cooperating aerial vehicles. Although these tasks are usually considered separately in the literature, we propose a common framework where both problems are formulated as the maximization of online acquired information via the definition of single-robot optimization functions, which differs only slightly in the two cases to take into account the static and dynamic nature of coverage and exploration respectively. A common derivative-free approach based on a stochastic approximation of these functions and their successive optimization is proposed, resulting in a fast and decentralized solution. The locality of this methodology limits however this solution to have local optimality guarantees and specific additional layers are proposed for the two problems to improve the final performance. Specifically, a Voronoi-based initialization step is added for the coverage problem and a combination with a frontier-based approach is proposed for the exploration case. The resulting algorithms are finally tested in simulations and compared with possible alternatives.																	0921-0296	1573-0409															10.1007/s10846-020-01255-4		SEP 2020											
J								Adaptive neural network output feedback control of incommensurate fractional-order PMSMs with input saturation via command filtering and state observer	NEURAL COMPUTING & APPLICATIONS										Permanent magnet synchronous motors (PMSMs); Incommensurate fractional-order; Command filtering; Observer; Input saturation	MAGNET SYNCHRONOUS MOTORS; DYNAMIC SURFACE CONTROL; NONLINEAR-SYSTEMS; BACKSTEPPING CONTROL; TRACKING CONTROL; DESIGN	In this paper, an adaptive neural network (NN) output feedback control is investigated for incommensurate fractional-order permanent magnet synchronous motors under the condition of input saturation. First, a NN state observer is presented to obtain the 'virtual estimate' of angle speed, where the unknown function is approximated by the NN. Then, in order to solve the input saturation problem, an auxiliary system is developed under fractional-order framework. Next, the command filtered technology with an error compensation mechanism is used to handle the 'explosion of complexity' in backstepping and remove the filtering errors. In addition, the frequency distributed model is utilized such that the Lyapunov theory is available in the backstepping design and the system stability is demonstrated. Finally, numerical simulations confirm the availability of the proposed design.																	0941-0643	1433-3058															10.1007/s00521-020-05344-1		SEP 2020											
J								An Application of Generalized Fuzzy Hyperbolic Model for Solving Fractional Optimal Control Problems with Caputo-Fabrizio Derivative	NEURAL PROCESSING LETTERS										Fractional optimal control problems; Caputo-Fabrizio derivative; Optimality conditions; Fuzzy system; Generalized fuzzy hyperbolic model; Optimization	NUMERICAL-SOLUTION; COLLOCATION METHOD; RITZ METHOD; SYSTEMS; FORMULATION; DESIGN; IDENTIFICATION; POLYNOMIALS	In this paper we present a new approach for solving a class of fractional optimal control problems based on generalized fuzzy hyperbolic model. The fractional derivatives are described in the Caputo-Fabrizio sense. In order to solve this problem, the necessary optimality conditions associated to the fractional optimal control problem is first derived. The solution of these conditions is then approximated by fuzzy solution based on generalized fuzzy hyperbolic model. A learning algorithm is used to achieve the adjustable parameters of the obtained fuzzy solution. In order to confirm the efficiency and accuracy of the proposed approach, some illustrative examples are implemented.																	1370-4621	1573-773X															10.1007/s11063-020-10334-4		SEP 2020											
J								Discrete imperialist competitive algorithm for the resource-constrained hybrid flowshop problem with energy consumption	COMPLEX & INTELLIGENT SYSTEMS										Hybrid flowshop; Imperialist competitive algorithm; Resource-constrained	SHOP SCHEDULING PROBLEM; BOUND ALGORITHM; ROBOTIC CELLS; TIME; OPTIMIZATION; MINIMIZE; MODEL; GA	The resource-constrained hybrid flowshop problem (RCHFS) has been investigated thoroughly in recent years. However, the practical case that considers both resource-constrained and energy consumption still has rare research. To address this issue, a discrete imperialist competitive algorithm (DICA) was proposed to minimize the makespan and energy consumption. In the proposed algorithm, first, each solution was represented by a two-dimensional vector, where one vector represented the scheduling sequence and another one showed the machine assignment. Then, a decoding method considering the resource allocation was designed. Finally, we combined DICA and the simulated annealing algorithm (SA) to improve the performance of the proposed approach. Furthermore, we tested the proposed algorithm based on a randomly generated set of real shop scheduling system instances and compared with the existing heuristic algorithms. The results confirmed that the proposed algorithm can solve the RCHFS with high efficiency.																	2199-4536	2198-6053															10.1007/s40747-020-00193-w		SEP 2020											
J								Design of online intelligent English teaching platform based on artificial intelligence techniques	COMPUTATIONAL INTELLIGENCE										artificial intelligence education; deep learning; online English teaching platform	DECISION-MAKING; MODEL	Artificial intelligence education (AIEd) is defined in the field of education as the utilization of artificial intelligence. There are currently many AIEd-driven applications in schools and universities. This paper applies an artificial intelligence module combined with the knowledge recommendation to the system and develops an online English teaching system in comparison with the common teaching auxiliary system. The method of English teaching is useful in investigating the potential internal connections between evaluation outcomes and various factors. This article develops deep learning-assisted online intelligent English teaching system that utilizes to create a modern tool platform to help students improve their English language teaching efficiency in line with their mastery of knowledge and personality. The decision tree algorithm and neural networks have been used and to generate an English teaching assessment implementation model based on decision tree technologies. It provides valuable data from extensive information, summarizes rules and data, and helps teachers to improve their education and the English scores of students. This system reflects the thinking of the artificial intelligence expert system. Test application demonstrates that the system can help students improve their learning efficiency and will make learning content more relevant. Besides, the system provides an example model with similar methods and has a referential definition.																	0824-7935	1467-8640															10.1111/coin.12351		SEP 2020											
J								Research on group behavior model based on neural network computing	COMPUTATIONAL INTELLIGENCE										artificial neural network; deep neural network; group behavior model; neural network; perceptron		Compute is a term coined from the etymology of French and Latin wordscomputerandcomputarerespectively, so is computing. This field of computing has grown enormously over the years. From the simple, traditional Turing machine invented in 1936 by Alan Turing to the current neural network (NN) computing. NNs, a field of artificial intelligence (AI) was exhilarated from the structure and inner workings of the brain. Just as the brain is, that is, an interconnection of neurons, so is the NN which is an interconnection of basic structures known as the perceptron. They do not differ much in structure. Their only difference is that one is artificial while the other is entirely biological. The hierarchical intricacies of the NN can be represented in three layers: the perceptron, artificial NN (ANN), and deep NN (DNN). With the influx of mental and behavioral disorders, basic surveillance, and the urgency to improve the mental health of people, studying the behavioral dynamics of people is requisite. CCTV and street cameras can only do so much, thus the need to employ the field of NN which makes use of supervised learning in training the models to perfect and automate surveillance. The results of this retrospective research indicate that the use of the NN model surpasses those of traditional methods in terms of efficiency and reliability.																	0824-7935	1467-8640															10.1111/coin.12403		SEP 2020											
J								Executing native Java code in R: an approach based on a local server	PEERJ COMPUTER SCIENCE										Interoperability; Java local server; TCP/IP connection; R vectorization; Java Native Interface		The R language is widely used for data analysis. However, it does not allow for complex object-oriented implementation and it tends to be slower than other languages such as Java, C and C++. Consequently, it can be more computationally efficient to run native Java code in R. To do this, there exist at least two approaches. One is based on the Java Native Interface (JNI) and it has been successfully implemented in the rJava package. An alternative approach consists of running a local server in Java and linking it to an R environment through a socket connection. This alternative approach has been implemented in an R package called J4R. This article shows how this approach makes it possible to simplify the calls to Java methods and to integrate the R vectorization. The downside is a loss of performance. However, if the vectorization is used in conjunction with multithreading, this loss of performance can be compensated for.																	2376-5992					SEP 28	2020									e300	10.7717/peerj-cs.300													
J								A survey of accepted authors in computer systems conferences	PEERJ COMPUTER SCIENCE										Computer Systems; Author survey; Researcher Diversity; Peer Review	PUBLICATION; ENGLISH; BIAS	Computer Science researchers rely on peer-reviewed conferences to publish their work and to receive feedback. The impact of these peer-reviewed papers on researchers' careers can hardly be overstated. Yet conference organizers can make inconsistent choices for their review process, even in the same subfield. These choices are rarely reviewed critically, and when they are, the emphasis centers on the effects on the technical program, not the authors. In particular, the effects of conference policies on author experience and diversity are still not well understood. To help address this knowledge gap, this paper presents a cross-sectional study of 56 conferences from one large subfield of computer science, namely computer systems. We introduce a large author survey (n = 918), representing 809 unique papers. The goal of this paper is to expose this data and present an initial analysis of its findings. We primarily focus on quantitative comparisons between different survey questions and comparisons to external information we collected on author demographics, conference policies, and paper statistics. Another focal point of this study is author diversity. We found poor balance in the gender and geographical distributions of authors, but a more balanced spread across sector, experience, and English proficiency. For the most part, women and nonnative English speakers exhibit no differences in their experience of the peer-review process, suggesting no specific evidence of bias against these accepted authors. We also found strong support for author rebuttal to reviewers' comments, especially among students and less experienced researchers.																	2376-5992					SEP 28	2020									e299	10.7717/peerj-cs.299													
J								Mining frequent weighted closed itemsets using the WN-list structure and an early pruning strategy	APPLIED INTELLIGENCE										Data mining; Frequent weighted closed itemsets; Weighted support; WN-list structure	BIT-VECTOR APPROACH; EFFICIENT ALGORITHMS; PATTERN	The problem of miningfrequent weighted itemsets(FWIs) is an extension of the miningfrequent itemsets(FIs), which considers not only the frequent occurrence of items but also their relative importance in a dataset. However, like mining FIs, mining FWIs usually produces a large result set, which makes it difficult to extract rules and creates redundancy. The problem of miningfrequent weighted closed itemsets(FWCIs) has been proposed as a solution to this issue, which produces a smaller result set while preserving sufficient information to extract rules. Theweighted node-list(WN-list) structure is currently considered the state-of-the-art structure for mining FWIs. In this study, we first propose the definition of WN-list ancestral operation and a theorem as the theoretical basis for eliminating unsatisfactory candidates, then propose an efficient algorithm, namely NFWCI, for mining FWCIs using the WN-list and an early pruning strategy. The experimental results on many sparse and dense datasets show that the proposed algorithm outperforms the-state-of-the-art algorithm for mining FWCIs.																	0924-669X	1573-7497															10.1007/s10489-020-01899-7		SEP 2020											
J								Enhanced Gaussian process regression-based forecasting model for COVID-19 outbreak and significance of IoT for its detection	APPLIED INTELLIGENCE										IoT; Machine learning; Novel coronavirus (COVID-19); HealthCare; Virus	CORONAVIRUS 2019-NCOV	Virus based epidemic is one of the speedy and widely spread infectious disease which can affect the economy of the country as well as it is life-threatening too. So, there is a need to forecast the epidemic lifespan, which can help us in taking preventive measures and remedial action on time. These preventive measures and corrective action may consist of closing schools, closing malls, closing theaters, sealing of borders, suspension of public services, and suspension of traveling. Resuming such restrictions is depends upon the outbreak momentum and its decay rate. The accurate forecasting of the epidemic lifespan is one of the enormously essential and challenging tasks. It is a challenging task because the lack of knowledge about the novel virus-based diseases and its consequences with complicated societal-governmental factors can influence the widespread of this newly born disease. At this stage, any forecasting can play a vital role, and it will be reliable too. As we know, the novel virus-based diseases are in a growing phase, and we also do not have real-time data samples. Thus, the biggest challenge is to find out the machine learning-based best forecasting model, which could offer better forecasting with the limited training samples. In this paper, the Multi-Task Gaussian Process (MTGP) regression model with enhanced predictions of novel coronavirus (COVID-19) outbreak is proposed. The purpose of the proposed MTGP regression model is to predict the COVID-19 outbreak worldwide. It will help the countries in planning their preventive measures to reduce the overall impact of the speedy and widely spread infectious disease. The result of the proposed model has been compared with the other prediction model to find out its suitability and correctness. In subsequent analysis, the significance of IoT based devices in COVID-19 detection and prevention has been discussed.																	0924-669X	1573-7497															10.1007/s10489-020-01889-9		SEP 2020											
J								A divide-and-unite deep network for person re-identification	APPLIED INTELLIGENCE										Person re-identification; Siamese network; Global feature; Part feature		Person re-identification (person re-ID) is one of the most challenging tasks in the field of computer vision as it involves large variations in human appearances, human poses, background illuminations, camera views, etc. In recent literature, using part-level features for the person re-ID task provides fine-grained information, and has been proven to be effective. Instead of relying on additional skeleton key points or pose estimation models, this paper proposes a Divide-and-Unite Network to obtain feature embedding end-to-end. We design a deep network guided by image contents, which divides pedestrians into parts and obtains the part features with different contributions. These part features and the global feature are united to obtain the pedestrian descriptor for person re-ID. To summarize, the contributions of this work are two-fold. Firstly, a novel architecture of discriminative descriptor learning is proposed, which is based on the global feature and supplemented by part features. Secondly, a Feature Division Network is constructed to generate the part features with different contributions, where the divided parts maintain the consistency of content between different images. Extensive experiments are conducted on three widely-used benchmarks including Market1501, CUHK03, and DukeMTMC-reID. The results have demonstrated that the proposed model can achieve remarkable performance against numerous state-of-the-arts.																	0924-669X	1573-7497															10.1007/s10489-020-01880-4		SEP 2020											
J								LipschitzLR: Using theoretically computed adaptive learning rates for fast convergence	APPLIED INTELLIGENCE										Lipschitz constant; Adaptive learning; Machine learning; Deep learning		We present a novel theoretical framework for computing large, adaptive learning rates. Our framework makes minimal assumptions on the activations used and exploits the functional properties of the loss function. Specifically, we show that the inverse of the Lipschitz constant of the loss function is an ideal learning rate. We analytically compute formulas for the Lipschitz constant of several loss functions, and through extensive experimentation, demonstrate the strength of our approach using several architectures and datasets. In addition, we detail the computation of learning rates when other optimizers, namely, SGD with momentum, RMSprop, and Adam, are used. Compared to standard choices of learning rates, our approach converges faster, and yields better results.																	0924-669X	1573-7497															10.1007/s10489-020-01892-0		SEP 2020											
J								Saving bandwidth and energy of mobile and IoT devices with link predictions	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobile clouds; Internet of Things; Context awareness; Context forecast	GENERIC CONTEXT ADAPTATION; CLOUD; EDGE	Use cases in the Internet of Things (IoT) and in mobile clouds often require the interaction of one or more mobile devices with their infrastructure to provide users with services. Ideally, this interaction is based on a reliable connection between the communicating devices, which is often not the case. Since most use cases do not adequately address this issue, service quality is often compromised. Aimed to address this issue, this paper proposes a novel approach to forecast the connectivity and bandwidth of mobile devices by applying machine learning to the context data recorded by the various sensors of the mobile device. This concept, designed as a microservice, has been implemented in the mobile middlewareCloudAware, a system software infrastructure for mobile cloud computing that integrates easily with mobile operating systems, such as Android. We evaluated our approach with real sensor data and showed how to enable mobile devices in the IoT to make assumptions about their future connectivity, allowing for intelligent and distributed decision making on the mobile edge of the network.																	1868-5137	1868-5145															10.1007/s12652-020-02557-z		SEP 2020											
J								Enhanced optimal placements of multi-controllers in SDN	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Software-defined network; Controller plane; Controller placements; Migration; Link failures; Latency		Software-Defined Networks (SDN) is a promising network technology that delivers the programable networks by separating control and data plane from the traditional architecture. The key issue in the SDN is to identify the number of controllers needed and its optimal location in the network. There are three major objectives of this paper. The primary objective is identifying the number of controllers needed. To identify it, a graph theory approach is adapted. The second objective is to identify optimal location of controllers in the network and what are all the nodes to be connected to the controller to enhance the performance of the network. For that, Pareto Integrated Tabu Search (PITS) algorithm is proposed. The final objective is to perform controller migration to handle dynamic situations like link failure and imbalance load of controller. A heuristic approach is proposed to perform migration. Real time topologies from Internet Topology Zoo are considered for experiment and the experimental results shows that the proposed methodology outperforms well in all situations considered for experiment.																	1868-5137	1868-5145															10.1007/s12652-020-02554-2		SEP 2020											
J								An improved Taguchi multi-criteria decision-making method based on the hesitant fuzzy correlation coefficient and its application in quality evaluation	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Multi-criteria decision-making (MCDM); Hesitant fuzzy set (HFS); Correlation coefficient; Hesitant fuzzy Taguchi signal-to-noise ratio (SNR) measure; Tourism quality evaluation	SIMILARITY MEASURES; SUPPLIER SELECTION; DISTANCE MEASURES; TOPSIS APPROACH; HYBRID TAGUCHI; SETS; INFORMATION; AGGREGATION; DESIGN; MCDM	This article is aimed at exploring an improved Taguchi SNR technique to settle the problem of multi-criteria decision-making (MCDM) in a hesitant fuzzy situation. Firstly, a novel correlation coefficient is defined under message from hesitant fuzzy sets and a weighted correlation coefficient proposed to deal with uncertainty. On that basis, several hesitant fuzzy correlation SNR measures are proposed in terms of the use of the weighted correlation coefficient. These measures cannot only avoid information distortion and omission, but are more sensitive when small datasets are used to reduce computational burden and reflect the correlation conflict in the process of information processing. Then, a hesitant fuzzy Taguchi method is proposed based on a novel weighted correlation coefficient which follows the principle of compromise such that the difference between the selected alternatives and the average solution is minimised to determine the optimal alternatives under the framework of the Taguchi method. The established method considers association conflict and provides a flexible and effective method for solving MCDM problems in a hesitant fuzzy environment. The implementation and the rationality process of the proposed method are demonstrated by an example pertinent to quality evaluation of tourism city development and compared outputs therefrom with four similar methods.																	1868-5137	1868-5145															10.1007/s12652-020-02558-y		SEP 2020											
J								Semantic segmentation of microscopic neuroanatomical data by combining topological priors with encoder-decoder deep networks	NATURE MACHINE INTELLIGENCE											MRI	Advances in large-scale connectivity mapping of the brain require efficient computational tools to detect fine structures across large volumes of images, which poses challenges. The authors introduce a hybrid architecture that incorporates topological priors of neuronal structures with deep learning models to improve semantic segmentation of neuroanatomical image data. Understanding of neuronal circuitry at cellular resolution within the brain has relied on neuron tracing methods that involve careful observation and interpretation by experienced neuroscientists. With recent developments in imaging and digitization, this approach is no longer feasible with the large-scale (terabyte to petabyte range) images. Machine-learning-based techniques, using deep networks, provide an efficient alternative to the problem. However, these methods rely on very large volumes of annotated images for training and have error rates that are too high for scientific data analysis, and thus requires a substantial volume of human-in-the-loop proofreading. Here we introduce a hybrid architecture combining prior structure in the form of topological data analysis methods, based on discrete Morse theory, with the best-in-class deep-net architectures for the neuronal connectivity analysis. We show significant performance gains using our hybrid architecture on detection of topological structure (for example, connectivity of neuronal processes and local intensity maxima on axons corresponding to synaptic swellings) with precision and recall close to 90% compared with human observers. We have adapted our architecture to a high-performance pipeline capable of semantic segmentation of light-microscopic whole-brain image data into a hierarchy of neuronal compartments. We expect that the hybrid architecture incorporating discrete Morse techniques into deep nets will generalize to other data domains.																		2522-5839															10.1038/s42256-020-0227-9		SEP 2020											
J								Cognition and Neurocomputation	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE																													1012-2443	1573-7470				DEC	2020	88	11-12					1119	1123		10.1007/s10472-020-09713-3		SEP 2020											
J								A comprehensive survey of Crow Search Algorithm and its applications	ARTIFICIAL INTELLIGENCE REVIEW										Crow Search Algorithm; Optimization; Nature-inspired algorithm; Swarm intelligence; Meta-heuristics	CENTRAL FORCE OPTIMIZATION; HEURISTIC OPTIMIZATION; DESIGN; PERFORMANCE; MODEL; COST	Crow Search Algorithm (CSA) is a recent swarm intelligence optimization algorithm inspired by the social intelligent behavior of crows for hiding food. It has been widely used to solve a large variety of optimization problems in several fields and areas of research and has proved its efficiency compared to several state-of-the-art optimization algorithms available in the literature. This paper presents a comprehensive overview of Crow Search Algorithm and its new variants categorized into modified and hybridized versions. It also describes the several applications of CSA in various domains such as feature selection, image processing, scheduling, economic dispatch, distributed generation, and other engineering problems. In addition, the paper suggests some interesting research areas related to CSA enhancement, CSA hybridization, and possible new applications.																	0269-2821	1573-7462															10.1007/s10462-020-09911-9		SEP 2020											
J								Optimized execution of morphological reconstruction in large medical images on embedded devices	JOURNAL OF REAL-TIME IMAGE PROCESSING										Morphological reconstruction; FPGA; System-on-Programmable-Chip; Image processing	ALGORITHMS	This work presents a hardware/software co-design implementation of the morphological reconstruction targeting a Systemon-Chip (SoC) FPGA-based embedded system. Our approach processes large images with fast algorithms. This was achieved by the proposal and use of an execution scheme that partitions the input image into sub- images that are independently processed before a second phase is executed to enable propagation of information among sub-images. The SoC is efficiently used by processing sub-images on hardware (the costly phase), while the software takes care of computations due to discontinuities that are irregular and inefficient for the hardware execution. Several optimizations were proposed, including parallel software and hardware execution and the use of borders to minimize computations in the discontinuities correction. This enables the processing of large images from our use-case brain cancer tissue image analysis application. For an image of 8192 x 8192 pixels, our co-design solution attains a speedup of 12.7 x vs. the software execution (Dual core ARM A9 Cortex).																	1861-8200	1861-8219															10.1007/s11554-020-01011-9		SEP 2020											
J								SD-Net: Understanding overcrowded scenes in real-time via an efficient dilated convolutional neural network	JOURNAL OF REAL-TIME IMAGE PROCESSING										Crowd counting; Crowded scenes; Deep learning; Dilated convolutional neural network; Real-time; Surveillance	TRACKING; CNN	The advancements in computer vision-related technologies attract many researchers for surveillance applications, particularly involving the automated crowded scenes analysis such as crowd counting in a very congested scene. In crowd counting, the main goal is to count or estimate the number of people in a particular scene. Understanding overcrowded scenes in real-time is important for instant responsive actions. However, it is a very difficult task due to some of the key challenges including clutter background, occlusion, variations in human pose and scale, and limited surveillance training data, that are inadequately covered in the employed literature. To tackle these challenges, we introduce "SD-Net" an end-to-end CNN architecture, which produces real-time high quality density maps and effectively counts people in extremely overcrowded scenes. The proposed architecture consists of depthwise separable, standard, and dilated 2D convolutional layers. Depthwise separable and standard 2D convolutional layers are used to extract 2D features. Instead of using pooling layers, dilated 2D convolutional layers are employed that results in huge receptive fields and reduces the number of parameters. Our CNN architecture is evaluated using four publicly available crowd analysis datasets, demonstrating superiority over state-of-the-art in terms of accuracy and model size.																	1861-8200	1861-8219															10.1007/s11554-020-01020-8		SEP 2020											
J								Toward soft real-time stress detection using wrist-worn devices for human workspaces	SOFT COMPUTING										Stress detection; Classification; HRV; GSR; Wearable sensors; Soft real-time system	HEART-RATE-VARIABILITY; DRIVING STRESS; RECOGNITION; RESPONSES; EMOTION; INTERFERENCE; POPULATION; CLASSIFIER; FRAMEWORK; SENSORS	Continuous exposure to stress leads to many health problems and substantial economic loss in companies. A lot of attention has been given to the development of wearable systems for stress monitoring to tackle its long-term effects such as confusion, high blood pressure, insomnia, depression, headache and inability to take decisions. Accurate detection of stress from physiological measurements embedded in wearable devices has been the primary goal in the healthcare industry. Advanced sensor devices with a high sampling rate have been proven to achieve high accuracy in many earlier works. However, there has been a little attempt to employ consumer-based devices with a low sampling rate, which potentially degrades the performance of detection systems. In this paper, we propose a set of new features, local maxima and minima (LMM), from heart rate variability and galvanic skin response sensors along with the voting and similarity-based fusion (VSBF) method, to improve the detection performance. The proposed feature set and fusion method are first tested on the acquired dataset which is collected using the wrist-worn devices with a low sampling rate in workplace environments and validated on a publicly available dataset, driveDB from PhysioNet. The experimental results from both datasets prove that the LMM features can improve the detection accuracy for different classifiers in general. The proposed VSBF method further boosts the recognition accuracy by 5.69% and 2.90% in comparison with the AdaBoost, which achieves the highest accuracy as a single classifier on the acquired, and the DriveDB dataset, respectively. Our analyses show that the stress detection system using the acquired dataset yields an accuracy of 92.05% and anF(1)score of 0.9041. Based on the analyses, a soft real-time system is implemented and validated to prove the applicability of the proposed work for stress detection in a real environment.																	1432-7643	1433-7479															10.1007/s00500-020-05338-0		SEP 2020											
J								Convolutional neural network for preprocessing-free bacterial Spectra identification	JOURNAL OF CHEMOMETRICS										class activation map; convolutional neural network; deep learning; fatty acid methyl esters; gas chromatography-vacuum ultraviolet spectroscopy; global average pooling	CLASSIFICATION; SPECTROSCOPY; DISCRIMINATION	Identifying bacterial species is essential to epidemiological surveillance. However, the determination of bacterial species is a tedious and labor-intensive process. Various machine learning methods have been used for identifying bacterial species with mass spectral fingerprints. Although machine learning methods achieve real-time identification without human experts, it still requires data preprocessing. To address this issue, we proposed a unified solution for the identification of bacterial species with a convolutional neural network. The neural network automatically determined species according to their mass spectra without the preprocessing steps. The convolutional and pooling layers in the neural network could replace the binning, baseline correction, and scaling procedures. Moreover, because of the explainable structure, the model could identify important regions of spectra to discriminate each bacterial species. We used spectral samples obtained from the fatty acid methyl esters of 10 samples from 16 bacterial species (a total of 16) to demonstrate the usefulness of the proposed method by comparing it with existing classification methods preceded by preprocessing. The comparison results confirmed that the proposed method outperformed the alternatives in terms of classification accuracy and robustness. Moreover, the classification results of the proposed method are interpretable.																	0886-9383	1099-128X														e3304	10.1002/cem.3304		SEP 2020											
J								An experimental study of modified physical performance test of low-temperature epoxy grouting material for grouting joints with tenon and mortise	JOURNAL OF INTELLIGENT MANUFACTURING										Joint with tenon and mortise; Low-temperature epoxy; Physical performance modification; Silica powder	CONSTRUCTION METHODS; PRECAST; EMISSIONS	With the grouting material as focus, this study aims to guarantee that the joint with tenon and mortise constructing a metro station has the necessary waterproof performance, which shall not be poorer than the mechanical properties of the concrete with joints itself, and fine structural integrity. With groutability at low-temperature and available operational time as basis, low-temperature epoxy was selected as the grouting material for the joints. The silica powder of particular particle size and mass was added for modifying the physical performance of grouting material. A series of physical and mechanical tests were conducted in an attempt to achieve the optimal particle size and mix ratio provided that costs were reduced as practically as possible. Also, the flexural capacity of the joint filled with the above grouting material was demonstrated via the combined equal-proportion joint axial bend test.																	0956-5515	1572-8145															10.1007/s10845-020-01664-0		SEP 2020											
J								Knee joint vibration signal classification algorithm based on machine learning	NEURAL COMPUTING & APPLICATIONS										Machine learning; Knee joint vibration signal (VAG signal); Classification algorithm	ASSOCIATION; ADULTS; GAIT	The knee joint is the largest and most complex flexion and extension joint of the human body. It supports most of the weight of the human body during the whole body during standing or exercise. Because the knee joint has the characteristics of complex structure and large load, it is also vulnerable to damage. An effective diagnosis in the early stage of injury or lesion of the knee joint is of great help to the later treatment. At present, the commonly used knee joint examination methods have the problems of large trauma and high cost. Therefore, this paper uses machine learning technology to study the classification algorithm of knee joint vibration signal. The research results of this paper were verified by selecting the subjects to form a healthy group and a disease injury group. The experimental results show that the proposed signal denoising algorithm is superior to the traditional denoising algorithm. After analyzing several classification algorithms, the multi-classifier fusion algorithm has excellent performance in signal classification. The experimental results show that the research results can be applied to the classification of knee joint vibration signals, and then applied to the clinical diagnosis of knee joint diseases.																	0941-0643	1433-3058															10.1007/s00521-020-05370-z		SEP 2020											
J								A new recommendation system using map-reduce-based tournament empowered Whale optimization algorithm	COMPLEX & INTELLIGENT SYSTEMS										Recommendation system; Big data; Map-reduce; Clustering; Whale optimization algorithm	TWITTER SENTIMENT ANALYSIS; WOLF OPTIMIZER	In the era of Web 2.0, the data are growing immensely and is assisting E-commerce websites for better decision-making. Collaborative filtering, one of the prominent recommendation approaches, performs recommendation by finding similarity. However, this approach fails in managing large-scale datasets. To mitigate the same, an efficient map-reduce-based clustering recommendation system is presented. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. The clustering efficiency of the proposed method is measured on four large-scale datasets in terms of F-measure and computation time. The experimental results are compared with state-of-the-art map-reduce-based clustering methods, namely map-reduce-based K-means, map-reduce-based bat algorithm, map-reduce-based Kmeans particle swarm optimization, map-reduce-based artificial bee colony, and map-reduce-based whale optimization algorithm. Furthermore, the proposed method is tested as a recommendation system on the publicly available movie-lens dataset. The performance validation is measured in terms of mean absolute error, precision and recall, over a different number of clusters. The experimental results assert that the proposed method is a permissive approach for the recommendation over large-scale datasets.																	2199-4536	2198-6053															10.1007/s40747-020-00200-0		SEP 2020											
J								AI Ethics: how can information ethics provide a framework to avoid usual conceptual pitfalls? An Overview	AI & SOCIETY										Ethics; Artificial intelligence; Transhumanism; Liberalism; Information		Artificial intelligence (AI) plays an important role in current discussions on information and communication technologies (ICT) and new modes of algorithmic governance. It is an unavoidable dimension of what social mediations and modes of reproduction of our information societies will be in the future. While several works in artificial intelligence ethics (AIE) address ethical issues specific to certain areas of expertise, these ethical reflections often remain confined to narrow areas of application, without considering the global ethical issues in which they are embedded. We, therefore, propose to clarify the main approaches to AIE, their philosophical assumptions and the specific characteristics of each one of them, to identify the most promising approach to develop an ethical reflection on the deployment of AI in our societies, which is the one based on information ethics as proposed by Luciano Floridi. We will identify the most important features of that approach to highlight areas that need further investigation.																	0951-5666	1435-5655															10.1007/s00146-020-01077-w		SEP 2020											
J								Virtual machine placement in cloud data centers using a hybrid multi-verse optimization algorithm	ARTIFICIAL INTELLIGENCE REVIEW										Cloud computing; Virtualization technology; Whale optimization algorithm; Multi-verse optimizer; Chaotic functions; Power consumption; Resource management	ANT COLONY OPTIMIZATION; ENERGY; ALLOCATION; MIGRATION; TAXONOMY; SYSTEM	Cloud computing is a computing paradigm, where a large pool of systems is connected in private or public networks to provide dynamically scalable infrastructure for application, data, and file storage. With the advent of this technology, the cost of power computation, application hosting, content storage, resource wastage, and delivery is reduced significantly. Cloud computing provides the possibility of merely concentrating on business goals instead of expanding hardware resources for users. Challenging work in virtualization technology is the placement of virtual machines under optimal conditions on physical machines in cloud data centers. Optimal placement of virtual machines over physical ones in cloud data centers can lead to the management of resources and prevention of the resources waste. Hereby, a new approach is proposed based on the combination of the hybrid discrete multi-object whale optimization algorithm, multi-verse optimizer with chaotic functions for optimal placement in the cloud data center. The first object of the proposed algorithm is to decrease power consumption, which is consumed in cloud data centers by reducing active physical machines. The second goal is to cut the resource wastage and managing resources using the optimal placement of virtual machines over physical machines in cloud data centers. With this method, the increasing rate of virtual migration to physical machines is prevented. Finally, the results obtained from the proposed algorithm were compared to some algorithms such as first fit, VMPACS, MBFD.																	0269-2821	1573-7462															10.1007/s10462-020-09903-9		SEP 2020											
J								Interval-valued Pythagorean fuzzy linguistic TODIM based on PCA and its application for emergency decision	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										emergency decision; interval-valued Pythagorean fuzzy linguistic information; IVPFL principal component analysis; TODIM	MEMBERSHIP GRADES; PROSPECT-THEORY; VARIABLES; COMPLEX	Nowadays the emergency decision has become a hot topic in the field of decision-making with interval-valued Pythagorean fuzzy linguistic (IVPFL) information. Moreover, with the increase of attributes and decision makers, the complexity of the operation is a great challenge for making decision. How to overcome multicollinearity is a crucial link in the emergency decision modeling process. In this paper, we treat the attributes and DMs as IVPFL variables and construct the IVPFL principal component analysis (IVPFL-PCA) model to overcome the multicollinearity. Then, a novel TODIM (abbreviation for interactive and multicriterial decision-making in Portuguese) method is proposed to tackle the IVPFL information under several new variables that are independent of each other (i.e., the PCs) and the reasonable weights of PCs obtained based on the IVPFL-PCA model. Finally, a case study on earthquake emergency decision is presented to show the applicability of the proposed approach and some comparisons are presented to illustrate its superiorities.																	0884-8173	1098-111X				DEC	2020	35	12					2049	2086		10.1002/int.22284		SEP 2020											
J								Interactive task learning via embodied corrective feedback	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS										Human robot interaction; Interactive learning; Knowledge representation and reasoning	FF PLANNING SYSTEM; COMPLEXITY	This paper addresses a task in Interactive Task Learning (Laird et al. IEEE Intell Syst 32:6-21, 2017). The agent must learn to build towers which are constrained by rules, and whenever the agent performs an action which violates a rule the teacher provides verbal corrective feedback: e.g. "No, red blocks should be on blue blocks". The agent must learn to build rule compliant towers from these corrections and the context in which they were given. The agent is not only ignorant of the rules at the start of the learning process, but it also has a deficient domain model, which lacks the concepts in which the rules are expressed. Therefore an agent that takes advantage of the linguistic evidence must learn the denotations of neologisms and adapt its conceptualisation of the planning domain to incorporate those denotations. We show that by incorporating constraints on interpretation that are imposed bydiscourse coherenceinto the models for learning (Hobbs in On the coherence and structure of discourse, Stanford University, Stanford, 1985; Asher et al. in Logics of conversation, Cambridge University Press, Cambridge, 2003), an agent which utilizes linguistic evidence outperforms a strong baseline which does not.																	1387-2532	1573-7454				SEP 27	2020	34	2							54	10.1007/s10458-020-09481-8													
J								Learning to detect community smells in open source software projects	KNOWLEDGE-BASED SYSTEMS										Community smells detection; Social debt; Socio-technical metrics; Machine learning	QUALITY	Community smells are symptoms of organizational and social issues within the software development community that often lead to additional project costs. Recent studies identified a variety of community smells and defined them as sub-optimal patterns connected to organizational-social structures in the software development community. To early detect and discover existence of potential community smells in a software project, we introduce, in this paper, a novel machine learning-based detection approach, named CSDETECTOR, that learns from various existing bad community development practices to provide automated support in detecting such community smells. In particular, our approach learns from a set of organizational-social symptoms that characterize the existence of potential instances of community smells in a software project. We built a detection model using Decision Tree by adopting the C4.5 classifier to identify eight commonly occurring community smells in software projects. To evaluate the performance of our approach, we conduct an empirical study on a benchmark of 74 open source projects from Github. Our statistical results show a high performance of CSDETECTOR, achieving an average accuracy of 96% and AUC of 0.94. Moreover, our results indicate that the CSDETECTOR outperforms two recent state-of-the-art techniques in terms of detection accuracy. Finally, we investigate the most influential community-related metrics to identify each community smell type. We found that the number of commits and developers per time zone, the number of developers per community, and the social network betweenness and closeness centrality are the most influential community characteristics. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106201	10.1016/j.knosys.2020.106201													
J								NexT: A framework for next-place prediction on location based social networks	KNOWLEDGE-BASED SYSTEMS										Next-place prediction; Trajectory pattern mining; LBSN		The extensive use of location-based social networks (LBSNs) allows for the collection of huge amount of geo-tagged data about people activities and costumes within urban context, including human mobility regularities. In this context, predicting the future position of a mobile object is the key for the implementations of several applications aiming at improving mobility within urban areas (e.g., traffic congestion, location-based advertisements). The paper proposes NexT, a next-place prediction framework, which exploits LBSNs data to forecast the next location of an individual based on the observations of her mobility behavior over some period of time and the recent locations that she has visited (individuals typical mobility routines) and on global mobility in the considered geographic area (e.g., mobility routines of all the Twitter users). The approach integrates frequent pattern mining and feature-based supervised classification, exploiting a set of spatio-temporal features characterizing locations and movements among them. The features are combined into a decision tree prediction model. The experimental evaluation, performed on real-world tweets shows the effectiveness and efficiency of the approach in predicting users next places, achieving a remarkable accuracy and prediction rate, outperforming state-of-the art approaches. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106205	10.1016/j.knosys.2020.106205													
J								Identification of Drug-Target Interactions via Dual Laplacian Regularized Least Squares with Multiple Kernel Fusion	KNOWLEDGE-BASED SYSTEMS										Drug-Target Interactions; Bipartite network; Multiple Kernel Learning; Dual Laplacian Regularized Least Squares; Graph regularized model	INTERACTION PREDICTION; INFORMATION; INTEGRATION	Detection of Drug-Target Interactions (DTIs) is the time-consuming and laborious experiment via biochemical approaches. Machine learning based methods have been widely used to mine meaningful information of drug research. In this study, we establish a novel computational method to predict DTIs via Dual Laplacian Regularized Least Squares model (DLapRLS) with Hilbert-Schmidt Independence Criterion-based Multiple Kernel Learning (HSIC-MKL). Multiple kernels are built from different information sources (drug and target spaces). Then, above corresponding kernels are integrated by HSIC-MKL. At last, DLapRLS model is trained by Alternating Least Squares Algorithm (ALSA) and employed to predict new DTIs. On four benchmark datasets, the results of our method are comparable and even better than existing models. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106254	10.1016/j.knosys.2020.106254													
J								Automatic segmentation of left ventricle using parallel end-end deep convolutional neural networks framework	KNOWLEDGE-BASED SYSTEMS										Automatic segmentation; Left ventricle; Deep learning	REGION; IMAGES; GRADIENT; HEART	Under the background of high incidence and mortality of cardiovascular diseases, the accurate and automatic left ventricle (LV) segmentation method is of essential importance for the diagnosis of the cardiovascular system. However, fully automatic LV segmentation remains challenging due to the complex structure of cardiac magnetic resonance image (MRI) and the morphological changes of LV caused by various cardiovascular diseases. In this paper, we propose a novel parallel end-to-end convolutional neural network (CNN) for LV segmentation. Our network consists of two interactive subnetworks which utilize essentially identical but formally different labels in the hope that they can learn segmentation from different perspectives. The two subnetworks take the same cardiac MRI as input and output a pair of segmentation maps in different forms. After averaging the two segmentation maps obtained from the two subnetworks, we get the final contours of the endocardium (endo) and epicardium (epi) simultaneously. The proposed method is evaluated on the dataset provided by the Left Ventricle Full Quantification Challenge of MICCAI 2019. The average Dice scores on epi, endo, and myocardium (myo) reach 0.961, 0.949, and 0.867 respectively which outperform the other methods. The experimental results show that our method has the potential for clinical application. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106210	10.1016/j.knosys.2020.106210													
J								Wasserstein based transfer network for cross-domain sentiment classification	KNOWLEDGE-BASED SYSTEMS										Cross-domain sentiment classification; Wasserstein distance; Attention mechanism; Word embedding		Automatic sentiment analysis of social media texts is of great significance for identifying people's opinions that can help people make better decisions. Annotating data is time consuming and laborious, and effective sentiment analysis on domains lacking of labeled data has become a problem. Crossdomain sentiment classification is a promising task, which leverages the source domain data with rich sentiment labels to analyze the sentiment polarity of the target domain lacking supervised information. Most of the existing researches usually explore algorithms that select common features manually to bridge different domains. In this paper, we propose a Wasserstein based Transfer Network (WTN) to share the domain-invariant information of source and target domains. We benefit from BERT to achieve rich knowledge and obtain deep level semantic information of text. The recurrent neural network with attention is used to capture features automatically, and Wasserstein distance is applied to estimate feature representations of source and target domains, which could help to capture significant domain-invariant features by adversarial training. Extensive experiments on Amazon datasets demonstrate that WTN outperforms other state-of-the-art methods significantly. Especially, the model behaves more stable across different domains. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106162	10.1016/j.knosys.2020.106162													
J								Extensible and displaceable hyperdisk based classifier for gear fault intelligent diagnosis	KNOWLEDGE-BASED SYSTEMS										Gear fault; Intelligent diagnosis; Extensible and displaceable hyperdisk; Multiscale fuzzy distribution entropy	CONVOLUTIONAL NEURAL-NETWORK; MULTISCALE FUZZY ENTROPY; DECOMPOSITION	The support vector machine (SVM) method has been widely used in gear fault diagnosis. SVM is essentially a convex hull (CH) based classifier. However, using the CH to approximate the class region underestimates the true region, which leads to unsatisfactory classification performance of SVM. The use of hyperdisk (HD) based classifiers for classification can effectively avoid the above problem. But the compactness or looseness of the HD model is not adjustable and the HD based classifier has poor robustness to outliers. Therefore, to achieve better classification results in gear fault diagnosis, a classifier based on extensible and displaceable hyperdisk (EDHD) is proposed. By introducing the extensibility factor, the EDHD based classifier allows the compactness or looseness of the HD model to be adjusted to better approximate the class region. Besides, by introducing the displaceability factor, the EDHD based classifier can achieve higher robustness to outliers. Meanwhile, to extract features from unstable and nonlinear signals, a new entropy called multiscale fuzzy distribution entropy (MFDE) is proposed. Moreover, empirical mode decomposition (EMD) is used to preprocess the original signal before feature extraction, and Laplacian Score (LS) is used for feature selection after feature extraction. Finally, the EDHD and MFDE based gear fault diagnosis method is proposed. The results of gear fault diagnosis experiments fully prove the effectiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106250	10.1016/j.knosys.2020.106250													
J								A reinforcement learning approach for optimizing multiple traveling salesman problems over graphs	KNOWLEDGE-BASED SYSTEMS										Multi-agent reinforcement learning; Combinatorial optimization problems; Multiple traveling salesman problems; Graph neural networks; Policy networks		This paper proposes a learning-based approach to optimize the multiple traveling salesman problem (MTSP), which is one classic representative of cooperative combinatorial optimization problems. The MTSP is interesting to study, because the problem arises from numerous practical applications and efficient approaches to optimize the MTSP can potentially be adapted for other cooperative optimization problems. However, the MTSP is rarely researched in the deep learning domain because of certain difficulties, including the huge search space, the lack of training data that is labeled with optimal solutions and the lack of architectures that extract interactive behaviors among agents. This paper constructs an architecture consisting of a shared graph neural network and distributed policy networks to learn a common policy representation to produce near-optimal solutions for the MTSP. We use a reinforcement learning approach to train the model, overcoming the requirement data labeled with ground truth. We use a two-stage approach, where reinforcement learning is used to learn an allocation of agents to vertices, and a regular optimization method is used to solve the single-agent traveling salesman problems associated with each agent. We introduce a S-samples batch training method to reduce the variance of the gradient, improving the performance significantly. Experiments demonstrate our approach successfully learns a strong policy representation that outperforms integer linear programming and heuristic algorithms, especially on large scale problems. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106244	10.1016/j.knosys.2020.106244													
J								Deep Transfer Convolutional Neural Network and Extreme Learning Machine for lung nodule diagnosis on CT images	KNOWLEDGE-BASED SYSTEMS										Lung nodule diagnosis; Computed Tomography; Convolutional Neural Network; Extreme Learning Machine; Transfer learning	CLASSIFICATION; TEXTURE; ARCHITECTURES; INFORMATION; SHAPE	Diagnosis of benign-malignant nodules in the lung on Computed Tomography (CT) images is critical for determining tumor level and reducing patient mortality. Deep learning-based diagnosis of nodules in lung CT images, however, is time-consuming and less accurate due to redundant structure and the lack of adequate training data. In this paper, a novel diagnosis method based on Deep Transfer Convolutional Neural Network (DTCNN) and Extreme Learning Machine (ELM) is explored, which merges the synergy of two algorithms to deal with benign-malignant nodules classification. An optimal DTCNN is first adopted to extract high-level features of lung nodules, which has been trained with the ImageNet dataset beforehand. After that, an ELM classifier is further developed to classify benign and malignant lung nodules. Two datasets, including the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) public dataset and a private dataset from the First Affiliated Hospital of Guangzhou Medical University in China (FAH-GMU), have been conducted to verify the efficiency and effectiveness of the proposed approach. For LIDC-IDRI dataset, the experimental results show that our novel DTCNN-ELM model achieved the performance with an accuracy of 94.57%, a sensitivity of 93.69%, a specificity of 95.15%, an area under the receiver operator curve (AUC) of 94.94%, and testing time per nodule of 0.5 ms, which has the most reliable results compared with current state-of-the-art methods. Codes are available(1). (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106230	10.1016/j.knosys.2020.106230													
J								Supervised feature selection through Deep Neural Networks with pairwise connected structure	KNOWLEDGE-BASED SYSTEMS										Feature selection; Sparse learning-based; DNN; Fully-connected network; Pairwise connected structure	REGRESSION; ALGORITHM; REGULARIZATION; OPTIMIZATION	Feature selection is an important data preprocessing strategy, has been proven empirically that it contributes to reducing the dimensionality of feature and enhancing the performance of learning algorithms in practice. Typical sparse learning-based models select the features by removing ones that the feature scores are zero. However, linear models puzzle to build the non-linear relations between features and responses. The Deep Neural Network (DNN) has a strong capability to mode the non-linear relations and has been employed to select features. In this paper, we introduce a novel deep Neural network-based Feature Selection (NeuralFS) method to identify features. The new model comprises of a fully-connection network, a decision network, and connect them through a pairwise connected structure. In NeuralFS, the fully-connected network is the crucial structure in NeuralFS that transforms the features into their corresponding scores, and the decision network is the final structure that performs classification or regression. The pairwise connected can be regarded as a "bridge" to connect the two networks, and its weights are fixed as the normalized input as well as it is un-trainable during model training. After optimizing, the feature scores can be obtained by calculating the output of the fully-connected network. NeuralFS takes advantage of the deep network to model the non-linearity, and also make features scores sparse without the sparse regularization technology. We apply the proposed method to both synthetic datasets and benchmark datasets to prove its effectiveness. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106202	10.1016/j.knosys.2020.106202													
J								Multi-objective optimization based on decomposition for flexible job shop scheduling under time-of-use electricity prices	KNOWLEDGE-BASED SYSTEMS										Flexible job shop scheduling; Time-of-use electricity prices; Multi-objective optimization; Cooperative search; Local intensification; Adaptive selection; Adjustment strategy	PERMUTATION FLOW-SHOP; SINGLE-MACHINE; ALGORITHM; SEQUENCE; SEARCH; COST	To decrease the load of electricity grid during the peak period, time-of-use electricity price has been implemented in industries to shift the production activities from the peak to the off-peak period. This paper addresses the flexible job shop scheduling under time-of-use electricity prices (FJSPTOUEP) to minimize both makespan and total electricity cost (TEC) simultaneously. We present the mixed integer programming model and propose a hybrid multi-objective evolutionary algorithm based on decomposition (HMOEA/D) to solve the problem. To generate an initial population with certain quality and diversity, several rules are used together. In the framework of MOEA/D, a cooperative search operator is designed to generate new solutions by exchanging information of neighbours. To improve the quality of solutions, two local intensification operators are designed by analysing the critical path of the schedule. An adaptive selection strategy is designed based on the reference point for well using the local search operators to enhance exploitation ability. Moreover, according to the characteristics of time-of-use electricity prices, an adjustment strategy is proposed to reduce electricity cost for further improving solutions. Computational results and statistical comparisons show that both the local intensification and adjustment strategy are effective. It also shows that the proposed HMOEND is more effective than other optimization algorithms in solving the FJSPTOUEP. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106177	10.1016/j.knosys.2020.106177													
J								Combined Cleaning and Resampling algorithm for multi-class imbalanced data with label noise	KNOWLEDGE-BASED SYSTEMS										Machine learning; Imbalanced data; Multi-class imbalance; Oversampling; Noisy data; Class label noise	CLASSIFICATION; SMOTE	The imbalanced data classification is one of the most crucial tasks facing modern data analysis. Especially when combined with other difficulty factors, such as the presence of noise, overlapping class distributions, and small disjuncts, data imbalance can significantly impact the classification performance. Furthermore, some of the data difficulty factors are known to affect the performance of the existing oversampling strategies, in particular SMOTE and its derivatives. This effect is especially pronounced in the multi-class setting, in which the mutual imbalance relationships between the classes complicate even further. Despite that, most of the contemporary research in the area of data imbalance focuses on the binary classification problems, while their more difficult multi-class counterparts are relatively unexplored. In this paper, we propose a novel oversampling technique, a Multi-Class Combined Cleaning and Resampling (MC-CCR) algorithm. The proposed method utilizes an energy-based approach to modeling the regions suitable for oversampling, less affected by small disjuncts and outliers than SMOTE. It combines it with a simultaneous cleaning operation, the aim of which is to reduce the effect of overlapping class distributions on the performance of the learning algorithms. Finally, by incorporating a dedicated strategy of handling the multi-class problems, MC-CCR is less affected by the loss of information about the inter-class relationships than the traditional multi-class decomposition strategies. Based on the results of experimental research carried out for many multi-class imbalanced benchmark datasets, the high robust of the proposed approach to noise was shown, as well as its high quality compared to the state-of-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106223	10.1016/j.knosys.2020.106223													
J								Relational completion based non-negative matrix factorization for predicting metabolite-disease associations	KNOWLEDGE-BASED SYSTEMS										Metabolite-disease associations; Non-negative matrix factorization; Molecular fingerprint similarity of metabolite	CHRONIC KIDNEY-DISEASE; SIMILARITY; ALGORITHMS; RISK	Metabolite, also known as intermediate metabolite, refers to substances produced or consumed in the metabolic processes. There are growing evidences that metabolites play an important role in the study of diseases. Due to the traditional experiments, it is time-consuming and luxurious to find the associations between metabolite and disease, we proposed a computational method, called RCNMF, to predict metabolite-disease associations. Firstly, we calculate the disease semantic similarity and the molecular fingerprint similarity of metabolite. The molecular fingerprint similarity of metabolite makes full use of the molecular structure internal information of metabolites. Then, we modify the original metabolite-disease associations matrix to replace some values of 0 with numbers between 0 and 1. Finally, we use the non-negative matrix factorization algorithm to predict potential metabolite-disease associations. We adopt the cross-validation mechanism to verify the performance of our proposed method. The AUC values of based the Leave-one-out cross validation measurement and the Five-fold cross validation measurement reach 0.9566 and 0.9430, respectively. What is more, case studies of common diseases also illustrate the effectiveness of our method. Thus, the superior experimental results show that our method can effectively predict the potential disease-metabolites associations. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106238	10.1016/j.knosys.2020.106238													
J								Deep reinforcement learning for robust emotional classification in facial expression recognition	KNOWLEDGE-BASED SYSTEMS										Emotion classification; Reinforcement learning; Image selector; Deep neural network	NEURAL-NETWORKS	For emotion classification in facial expression recognition (FER), the performance of both traditional statistical methods and state-of-the-art deep learning methods are highly dependent on the quality of data. Traditional methods use image preprocessing (such as smoothing and segmentation) to improve image quality. However, the results still fail to meet the quality requirements of the emotion classifiers in FER. To address the above issues, this paper proposed a novel framework based on reinforcement learning for pre-selecting useful images(RLPS) for emotion classification in FER, which is made up of two modules: image selector and rough emotion classifier. Image selector is used to select useful images for emotion classification through reinforcement strategy and rough emotion classifier acts as a teacher to train image selector. Our framework improves classification performance by improving the quality of the dataset and can be applied to any classifier. Experiment results on RAF-DB, ExpW, and FER2013 datasets show that the proposed strategy achieves consistent improvements compared with the state-of-the-art emotion classification methods in FER.(1) (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106172	10.1016/j.knosys.2020.106172													
J								Fast infrared and visible image fusion with structural decomposition	KNOWLEDGE-BASED SYSTEMS										Image fusion; Multi-scale; Fast fusion; Structural decomposition; Infrared	MULTISCALE TRANSFORM; PERFORMANCE; FRAMEWORK; NETWORK	Infrared and visible image fusion aims to generate a composite image with salient thermal targets and texture information from infrared image and visible image. Existing advanced methods tend to consume high computational cost for a high-quality fusion result. In this paper, a simple yet effective method is proposed based on structural patch decomposition. A modified gamma function is proposed to weight the mean intensity component to keep the thermal target. An enhanced power function is used to weight the mean-removed component to preserve the texture information. Different from general patch level fusion implemented via a sliding window, we convert the explicit structural patch decomposition and fusion into an image level mean filtering via a detailed analysis on input images. By this means, the computational cost of the proposed method can be largely reduced, which is independent of the patch size. Furthermore, we analyze the relationship of our method with classic filtering based image decomposition methods. Finally, a multi-scale implementation of the proposed method is developed to avoid the evident halo and spatial inconsistency artifacts. Extensive experimental results on the public dataset demonstrate that the proposed method can obtain more texture information and outperform the state-of-the-art fusion method qualitatively and quantitatively. The code can be downloaded from: https: //github.com/xiaohuiben/MSID-KBS. (C) 2020 Published by Elsevier B.V.																	0950-7051	1872-7409				SEP 27	2020	204								106182	10.1016/j.knosys.2020.106182													
J								Deep learning-based unsupervised representation clustering methodology for automatic nuclear reactor operating transient identification	KNOWLEDGE-BASED SYSTEMS										Deep learning; Nuclear reactor; Clustering; Transient identification; Unsupervised learning	CONVOLUTIONAL NEURAL-NETWORK; FAULT-DIAGNOSIS METHOD; SCENARIOS; SYSTEM	Transient identification of condition monitoring data in nuclear reactor is important for system health assessment. Conventionally, the operating transients are correlated with the pre-designed ones by human operators during operations. However, due to necessary conservatism and significant differences between the operating and pre-designed transients, it has been less effective to manually identify transients, that usually contribute to different system degradation modes. This paper proposes a deep learning-based unsupervised representation clustering method for automatic transient pattern recognition based on the on-site condition monitoring data. Sample entropy is used as indicator for transient extraction, and a pre-training stage is implemented using an auto-encoder architecture for learning high-level features. An iterative representation clustering algorithm is further proposed to enhance the clustering effects, where a novel distance metric learning strategy is integrated. Experiments on a real-world nuclear reactor condition monitoring dataset validate the effectiveness and superiority of the proposed method, which provides a promising tool for transient identification in the real industrial scenarios. This study offers a new perspective in exploring unlabeled data with deep learning, and the end-to-end implementation scheme facilitates applications in the real nuclear industry. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106178	10.1016/j.knosys.2020.106178													
J								Scalable KDE-based top-n local outlier detection over large-scale data streams	KNOWLEDGE-BASED SYSTEMS										Local outlier detection; Data streams; Kernel Density Estimation; Upper-bound based pruning	DISTANCE-BASED OUTLIERS; ALGORITHMS; EFFICIENT	The detection of local outliers over high-volume data streams is critical for diverse real-time applications in the real world, where the distributions in different subsets of the data tend to be skewed. However, existing methods are not scalable to large-scale high-volume data streams owing to the high complexity of the re-detection of data updates. In this work, we propose a top-n local outlier detection method based on Kernel Density Estimation (KDE) over large-scale high-volume data streams. First, we define a KDE-based Outlier Factor (KOF) to measure the local outlierness score for the data points. Then, we propose the upper bounds of the KOF and an upper-bound-based pruning strategy to quickly eliminate the majority of the inlier points by leveraging the upper bounds without computing the expensive KOF scores. Moreover, we design an Upper-bound pruning-based top-n KOF detection method (UKOF) over data streams to efficiently address the data updates in a sliding window environment. Furthermore, we propose a Lazy update method of UKOF (LUKOF) for bulk updates in high-speed large-scale data streams to further minimize the computation cost. Our comprehensive experimental study demonstrates that the proposed method outperforms the state-of-the-art methods by up to 3,600 times in speed, while achieving the best performance in detecting local outliers over data streams. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106186	10.1016/j.knosys.2020.106186													
J								RDBN: Visual relationship detection with inaccurate RGB-D images	KNOWLEDGE-BASED SYSTEMS										Visual relationship detection; Visual scene understanding; RGB-D image; Zero-shot learning; Deep neural network		Traditional visual relationship detection methods only use RGB information to train the semantic network, which do not match human habits that we combine RGB information with Depth information to perceive the world, thus, there is not enough generalization ability (zero-shot performance) to extract the visual relationships in practical scenes. To solve this problem, a novel visual relationship detection framework based on RGB-D images is proposed in this paper. Since it is difficult to get accurate depth maps from complex scenes, we propose a fuzzy strategy based method to represent Depth features of inaccurate depth maps which are independent of manual depth annotations. In particular, we formulate the RGB-Depth-Balanced-Network (RDBN) which can simultaneously process RGB features and the corresponding estimated depth maps to counter the inaccuracy of depth maps and extract semantic information by the only input of monocular RGB images. In experiments, we conduct ablation experiments to analyze functions of different visual components to demonstrate the effectiveness of our RDBN. Furthermore, we show that RDBN outperforms state-of-the-art visual relationship detection methods on Visual Relationship Dataset (VRD) and UnRel Dataset when tackling the visual relationship detection task of zero-shot learning in specific depth conditions, and the task of image retrieval among unusual relationships. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106142	10.1016/j.knosys.2020.106142													
J								Safe sample screening for regularized multi-task learning	KNOWLEDGE-BASED SYSTEMS										Multi-task learning; Support vector machine; Safe screening rules; Pattern recognition; Image classification	SUPPORT VECTOR MACHINES	As a machine learning paradigm, multi-task learning (MTL) attracts increasing attention recently. It can improve the overall performance by exploiting the correlation among different tasks. It is especially helpful in dealing with small sample learning problems. As a classic multi-task learner, regularized multi-task learning (RMTL) inspired lots of multi-task learning researches in the past. Massive researches have shown the performance of RMTL when compared to single-task learners, i.e., support vector machine. However, the training complexity will be considerably large when training large datasets. To tackle such a problem, we propose safe screening rules for an improved regularized multi-task support vector machine (IRMTL). By statically detecting and removing inactive samples from multiple tasks simultaneously before solving the reduced optimization problem, both rules reduce the training time significantly without incurring performance degradation of the proposed method. The experimental results on 13 benchmark datasets and an image dataset also clearly demonstrate the effectiveness of safe screening rules for IRMTL. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106248	10.1016/j.knosys.2020.106248													
J								A framework for building closed-domain chat dialogue systems	KNOWLEDGE-BASED SYSTEMS										Closed-domain chatbot; Dialogue system development framework; Non-task-oriented dialogue system		This paper presents HRIChat, a framework for developing closed-domain chat dialogue systems. Being able to engage in chat dialogues has been found effective for improving communication between humans and dialogue systems. This paper focuses on closed-domain systems because they would be useful when combined with task-oriented dialogue systems in the same domain. HRIChat enables domain-dependent language understanding so that it can deal well with domain-specific utterances. In addition, HRIChat makes it possible to integrate state transition network-based dialogue management and reaction-based dialogue management. FoodChatbot, which is an application in the food and restaurant domain, has been developed and evaluated through a user study. Its results suggest that reasonably good systems can be developed with HRIChat. This paper also reports lessons learned from the development and evaluation of FoodChatbot. (C) 2020 The Authors. Published by Elsevier B.V.																	0950-7051	1872-7409				SEP 27	2020	204								106212	10.1016/j.knosys.2020.106212													
J								AutoEmbedder: A semi-supervised DNN embedding system for clustering	KNOWLEDGE-BASED SYSTEMS										Deep Neural Network; Unsupervised learning; Semi-supervised learning; Transfer learning; Embedding; Clustering; Dimensionality reduction; Pairwise constraint		Clustering is widely used in unsupervised learning method that deals with unlabeled data. Deep clustering has become a popular study area that relates clustering with Deep Neural Network (DNN) architecture. Deep clustering method downsamples high dimensional data, which may also relate clustering loss. Deep clustering is also introduced in semi-supervised learning (SSL). Most SSL methods depend on pairwise constraint information, which is a matrix containing knowledge if data pairs can be in the same cluster or not. This paper introduces a novel embedding system named AutoEmbedder, that downsamples higher dimensional data to clusterable embedding points. To the best of our knowledge, this is the first research endeavor that relates to traditional classifier DNN architecture with a pairwise loss reduction technique. The training process is semi-supervised and uses Siamese network architecture to compute pairwise constraint loss in the feature learning phase. The AutoEmbedder outperforms most of the existing DNN based semi-supervised methods tested on famous datasets. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106190	10.1016/j.knosys.2020.106190													
J								A new locally adaptive k-nearest neighbor algorithm based on discrimination class	KNOWLEDGE-BASED SYSTEMS										Classification algorithm; k-nearest neighbor rule; Majority class; Second majority class; Discrimination class; Adaptive k value		The k-nearest neighbor (kNN) rule is a classical non-parametric classification algorithm in pattern recognition, and has been widely used in many fields due to its simplicity, effectiveness and intuitiveness. However, the classification performance of the kNN algorithm suffers from the choice of a fixed and single value of k for all queries in the search stage and the use of simple majority voting rule in the decision stage. In this paper, we propose a new kNN-based algorithm, called locally adaptive k-nearest neighbor algorithm based on discrimination class (DC-LAKNN). In our method, the role of the second majority class in classification is for the first time considered. Firstly, the discrimination classes at different values of k are selected from the majority class and the second majority class in the k-neighborhood of the query. Then, the adaptive k value and the final classification result are obtained according to the quantity and distribution information on the neighbors in the discrimination classes at each value of k. Extensive experiments on eighteen real-world datasets from UCI (University of California, Irvine) Machine Learning Repository and KEEL (Knowledge Extraction based on Evolutionary Learning) Repository show that the DC-LAKNN algorithm achieves better classification performance compared to standard kNN algorithm and nine other state-of-the-art kNN-based algorithms. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106185	10.1016/j.knosys.2020.106185													
J								Semi-supervised neighborhood discrimination index for feature selection	KNOWLEDGE-BASED SYSTEMS										Semi-supervised; Feature selection; Neighborhood discriminant index	MUTUAL INFORMATION; REGRESSION	Neighborhood discriminant index (NDI) is an effective feature selection method for supervised learning. In reality, it is easy to obtain unlabeled data and is costly to tag them all. Thus, the given dataset commonly has only a small amount of tagged samples and a large amount of unlabeled ones, which cannot be handled by supervised learning methods. For this situation, we propose a semi-supervised feature selection method called semi-supervised neighborhood discriminant index (SSNDI) that combines NDI and the Laplacian score method to effectively deal with both labeled and unlabeled samples. The goal of SSNDI is to find an optimal feature subset that has a good ability to keep local geometrical structure and to distinguish samples belonging to different classes. In SSNDI, the classical Laplacian score method is modified to cooperate the iterative form of NDI. In each iteration, SSNDI picks up an important feature according to the new criterion that is a mixture of NDI and the modified Laplacian score. Extensive experiments are conducted on UCI and microarray gene datasets. Experimental results confirm that SSNDI can achieve a better performance than NDI and the other state-of-the-art semi-supervised methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106224	10.1016/j.knosys.2020.106224													
J								HASVRec: A modularized Hierarchical Attention-based Scholarly Venue Recommender system	KNOWLEDGE-BASED SYSTEMS										Recommender system; Bidirectional LSTM; Attentive pooling; Deep learning; Hierarchical Attention Network (HAN)	JOURNALS; INFORMATION	Manually selecting appropriate scholarly venues is becoming a tedious and time-consuming task for researchers due to many reasons that include relevance, scientific impact, and research visibility. Sometimes, high-quality papers get rejected due to mismatch between the area of the paper and the scope of the journal. Recommending appropriate academic venues can, therefore, enable researchers to identify and take part in relevant conferences and publish in journals that matter the most. A researcher may certainly know of a few leading venues for her specific field of interest. However, a venue recommendation system becomes particularly helpful when exploring a new domain or when more options are needed. Due to high dimensionality and sparsity of text data, and complex semantics of the natural language, journal identification presents difficult challenges. We propose a novel and unified architecture that contains a Bi-directional LSTM (Bi-LSTM) and a Hierarchical Attention Network (HAN) to address the above problems. We call the proposed architecture modularized Hierarchical Attention-based Scholarly Venue Recommender system (HASVRec), which only requires the abstract, title, keywords, field of study, and author of a new paper along with its past publication record to recommend scholarly venues. Experiments on the DBLP-Citation-Network V11 dataset exhibit that our proposed approach outperforms several state-of-the-art methods in terms of accuracy, F1, nDCG, MRR, average venue quality, and stability. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106181	10.1016/j.knosys.2020.106181													
J								Discriminative deep asymmetric supervised hashing for cross-modal retrieval	KNOWLEDGE-BASED SYSTEMS										Asymmetric hashing learning; Discrete optimization; Discriminative; Cross-modal retrieval	NETWORK	Due to the advantages of low storage cost and high retrieval efficiency, cross-modal hashing has received considerate attention. Most existing deep cross-modal hashing adopt a symmetric strategy to learn same deep hash functions for both query instances and database instances. However, the training of these symmetric deep cross-modal hashing methods is time-consuming, which makes them hard to effectively utilize the supervised information for cases with large-scale datasets. Inspired by the latest advance in the asymmetric hashing scheme, in this paper, we propose a discriminative deep asymmetric supervised hashing (DDASH) for cross-modal retrieval. Specifically, asymmetric hashing only learns hash codes of query instances by deep hash functions while learning the hash codes of the database instances by hand-crafted matrices. It cannot only make full use of the information in large-scale datasets, but also reduce the training time. Besides, we introduce discrete optimization to reduce the binary quantization error. Furthermore, a mapping matrix which maps generated hash codes into the corresponding labels is introduced to ensure that the hash codes are discriminative. We also calculate the level of similarity between instances as supervised information. Experiments on three common datasets for cross-modal retrieval show that DDASH outperforms state-of-the-art cross-modal hashing methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106188	10.1016/j.knosys.2020.106188													
J								KdMutual: A novel clustering algorithm combining mutual neighboring and hierarchical approaches using a new selection criterion	KNOWLEDGE-BASED SYSTEMS										Clustering; Mutual neighbors; Agglomerative; Dissimilarity; Density	DENSITY PEAKS; FAST SEARCH; FIND	New clustering algorithms are expected to manage complex data, meaning various shapes and densities while being user friendly. This work addresses this challenge. A new clustering algorithm KdMutual(1) driven by the number of clusters is proposed. The idea behind the algorithm is based on the assumption that working with cluster cores rather than considering frontiers makes the clustering process easier. KdMutual is based on three steps: The first one aims at identifying the potential core clusters. It relies on mutual neighborhood and includes specific mechanisms to identify and preserve potential core clusters. The second step is based on a constrained hierarchical process that deals with noise. In the last step the potential clusters are selected using a specific ranking criterion and the final partition is built. KdMutual combines the best characteristics of density peaks and connectivity-based approaches. It is capable of detecting the non-presence of natural clusters. Tests were carried out to compare the proposal with 14 other clustering algorithms. Using 2-dimensional benchmark datasets of various shapes and densities they showed that KdMutual was highly effective in matching a ground truth target. It also proved efficient in high dimensions when clusters are well separated. Moreover, it is able to identify clusters of various densities, partially overlapping and including a large amount of noise within spaces of moderate dimension. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106220	10.1016/j.knosys.2020.106220													
J								Self-adaptive feature learning based on a priori knowledge for facial expression recognition	KNOWLEDGE-BASED SYSTEMS										Facial expression recognition; Self-adaptive feature learning; A priori knowledge; Active feature dictionary	ROBUST FACE RECOGNITION; DISCRIMINATIVE DICTIONARY; LOW-RANK; REPRESENTATION	Conventional feature extraction methods generally focus on extracting global and local features from the original data or converting a high dimensional space to a lower dimensional one. However, they tend to overlook the discriminative information of pixel values hidden in the original data. Pixel values in some local parts of a face, such as the mouth, eyebrows and eyes, provide extremely useful information for expression recognition, as they reveal the correlation between these local parts. While this information can be learned manually, being able to automatically identify important location information in this context is highly desirable. Given this, we propose a self-adaptive feature learning approach based on a priori knowledge for facial expression recognition in this paper. The proposed approach aims to adaptively select active features. It first generates an intra-class, low-rank dictionary that can decouple the original space from the expression subspace and mitigate the dependence on individual facial identities. Next, the active feature dictionary is formed, taking both global and local importance into account simultaneously. After that, the principal component of the active feature dictionary is extracted to address the influence of redundant features and reduce the dimension. We also introduce an active feature learning model as the final classification framework to make the features more discriminative and reduce the computation time. Results of comprehensive experiments on public facial expression datasets confirm the efficacy of the proposed approach, in terms of accuracy and computation time, compared to some state-of-the-art feature extraction and dictionary learning methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106124	10.1016/j.knosys.2020.106124													
J								Addressing the train-test gap on traffic classification combined subflow model with ensemble learning	KNOWLEDGE-BASED SYSTEMS										Network traffic classification; train-test gap; Subflow; Ensemble learning		Previous machine learning-based network traffic classification approaches hold the assumption that training and testing network environment are of the same. This assumption is invalid in most real cases due to the changes in traffic features and leads to the train-test gap issue: the model trained in the training environment performs poorly in the testing environment. In this paper, to address the gap, we propose CSA: a traffic classification approach based on packet-wise segmentation and aggregation. Firstly, we observe that some specific fragments of network flows - subflows - are robust against the gap. Therefore, we are motivated to segment the traffic flows into different subflows. Afterward, with the justification of our feature selection, 26 statistical features are extracted from each subflow and input into its corresponding sub-classifier. Secondly, with the results from sub-classifiers, we develop an aggregation method based on their classification accuracy to increase the overall classification performance. We experiment on five real datasets, including three collected from the Northwest Center of CERNET (China Education and Research Network) and two from public traces. By comparing with state-of-the-art baselines, the experiment results demonstrate the effectiveness of our CSA against the gap. (C) 2020 Published by Elsevier B.V.																	0950-7051	1872-7409				SEP 27	2020	204								106192	10.1016/j.knosys.2020.106192													
J								Diversified service recommendation with high accuracy and efficiency	KNOWLEDGE-BASED SYSTEMS										Recommender system; Collaborative Filtering; Accuracy; Diversity; Efficiency	USER; ALGORITHM	Collaborative filtering-based recommender systems are regarded as an important tool to predict the items that users will appreciate based on the historical usage of users. However, traditional recommendation solutions often pay more attentions to the accuracy of the recommended items while neglect the diversity of the final recommended list, which may produce partial redundant items in the recommended list and as a result, decrease the satisfaction degree of users. Moreover, historical usage data for recommendation decision-making often update frequently, which may lead to low recommendation efficiency as well as scalability especially in the big data environment. Considering these drawbacks, a novel method called DivRec_LSH is proposed in this paper to achieve diversified and efficient recommendations, which is based on the historical usage records and the Locality-Sensitive Hashing (LSH) technique. Finally, we compare our method with existing methods on the MovieLens dataset. Experiment results indicate that our proposal is feasible in addressing the triple dilemmas of recommender systems simultaneously, i.e., high efficiency, accuracy and diversity. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106196	10.1016/j.knosys.2020.106196													
J								Adversarial transfer learning for cross-domain visual recognition	KNOWLEDGE-BASED SYSTEMS										Transfer learning; Adversarial learning; Image classification	ADAPTATION	In many practical visual recognition scenarios, feature distributions between source domain and the target domain are quite different, which results in the emergence of general cross-domain visual recognition problems. To address the problems of visual domain mismatch, we propose a novel shallow semi-supervised adversarial transfer learning network, which is called Coupled adversarial transfer Domain Adaptation (CatDA), for distribution alignment between two domains. The proposed CatDA approach is inspired by cycleGAN, but leveraging multiple shallow multilayer perceptrons (MLPs) instead of deep networks. Specifically, our CatDA comprises of two symmetric and slim sub-networks, such that the coupled adversarial learning framework is formulated. With such symmetry of two generators, the input data from source/target domain can be fed into the MLP network for target/source domain generation, supervised by two confrontation oriented coupled discriminators. Notably, in order to avoid the critical flaw of high-capacity of the feature extraction function during domain adversarial training, domain specific loss and domain knowledge fidelity loss are proposed in each generator, such that the effectiveness of the proposed transfer network is guaranteed. Additionally, the essential difference from cycleGAN is that our method aims to generate domain-agnostic and aligned features for domain adaptation and transfer learning rather than synthesize realistic images. We show experimentally on a number of benchmark datasets and the proposed approach achieves competitive performance over state-of-the-art domain adaptation and transfer learning approaches. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106258	10.1016/j.knosys.2020.106258													
J								Home service robot task planning using semantic knowledge and probabilistic inference	KNOWLEDGE-BASED SYSTEMS										Task planning; Home environment; Semantic knowledge; Probabilistic inference; Hierarchical task network; Task execution diagnosis		In the face of unstructured home environment, home service robots are inevitably confronted with uncertainty and incompleteness of environment information. How to make the home service robot obtain enough environment information and plan a discrete sequence of actions through task planning is the key problem of robot intelligence. In this paper, a hierarchical task network based on semantic knowledge and probabilistic inference method is proposed. We use the object location ontology, the location relation between dynamic and static objects to build semantic knowledge of home environment, and build the probability model between dynamic and static objects, as well as between static objects and home scenes. The location of the object is determined by the semantic knowledge and the probability model. Hierarchical task network is selected as an engine of task planner, which can be provided with the location information to improve the autonomy and effectiveness of robot task planning. In order to prevent task execution failure and enhance the adaptability of robot to unstructured home environment, a mechanism of task execution diagnosis and replanning is designed. Experimental results in simulation and real home environment demonstrate that our method can effectively improve the performance of service robot task planning and generate better task execution sequence. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106174	10.1016/j.knosys.2020.106174													
J								Optimal business model for the monopolistic ride-hailing platform: Pooling, premier, or hybrid?	KNOWLEDGE-BASED SYSTEMS										Ride-hailing platform; Business model; Time-sensitive cost; Pricing strategy; Sharing economy	TAXI SERVICES; DEMAND; MARKET; STRATEGIES; NETWORK; EQUILIBRIUM; COMPETITION	Pooling, premier, and hybrid are three business models employed by ride-hailing platforms. We establish an analytical framework to examine these three models for addressing the platform's optimal business decision. Our results reveal that both the time-sensitive cost of heterogeneous passengers and the operating cost of the platform's self-operating vehicles play critical roles in the platform's choice of optimal model. If the operating cost of the platform's self-operating vehicles is relatively high, the platform should choose the pooling service model when passengers have a low ratio of time-sensitive cost between using the pooling service and using the premier service. The premier service model should be implemented if this ratio is in the middle range and the operating cost is sufficiently low. Otherwise, the hybrid service model is optimal. We characterize the conditions under which the pooling service model and the premier service model can achieve Pareto improvement for the platform and passengers. Furthermore, if the ratio is in the middle range, the pooling service model is more beneficial for passengers, while the premier service model is more profitable for the platform. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106093	10.1016/j.knosys.2020.106093													
J								A novel feature separation model exchange-GAN for facial expression recognition	KNOWLEDGE-BASED SYSTEMS										Generative adversarial network; Facial expression recognition; Encoder and decoder; Feature separation; Partial feature exchange	POSE	Currently, with the rapid development of deep learning, many breakthroughs have been made in the field of facial expression recognition (FER). However, according to our prior knowledge, facial images contain not only expression-related features but also some identity-related features, and the identity-related features vary from person to person which often have a negative influence on the FER process. It is one of the most important challenges in the field of FER. In this paper, a novel feature separation model exchange-GAN is proposed for the FER task, which can realize the separation of expression-related features and expression-independent features with high purity. And the FER method based on the exchange-GAN can overcome the interference of identity-related features to a large extent. First, the feature separation is achieved by the exchange-GAN through partial feature exchange and various constraints. Then we ignore the expression-independent features, and conduct FER only according to the expression-related features to alleviate the adverse effect of identity-related features. Finally, some experiments are conducted on three famous databases with the FER methods proposed in this paper. The experimental results show that the proposed FER method can alleviate the interference of identity-related information through feature separation by the exchange-GAN and achieve excellent performance for the objects that have not appeared in the training set. What's more, our method can obtain very competitive FER accuracy on the three experimental databases. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106217	10.1016/j.knosys.2020.106217													
J								HAGERec: Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation	KNOWLEDGE-BASED SYSTEMS										Recommender system; Graph convolutional network; Hierarchical attention; Knowledge graph		Knowledge graph (KG) can provide auxiliary information for recommender system to alleviate the sparsity and cold start problems, while graph convolutional networks (GCN) has recently been established as the state-of-the-art representation learning method. The combination of them is a promising perspective to improve the performance of graph-structured recommendation. However, most of GCN-based recommendations focus on homogeneous graph or user/item-similarity graph, fail to fully make use of the complex and rich semantics between entities in heterogeneous knowledge graph. In this paper, we develop Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation (HAGERec) to explore users' potential preferences from the high-order connectivity structure of heterogeneous knowledge graph. To exploit semantic information, HAGERec simultaneously learn the representations of users and items via a bi-directional information propagation strategy. Specifically, the entity's representation can be aggregated through messages passing from its local proximity structure, and a hierarchical attention mechanism is developed to adaptively characterize and adjust collaborative signals. With the help of the attention mechanism, an attentive entity sampling strategy is proposed to select relevant neighbor entities, and the explainability is endowed to the model by building knowledge-aware connectivity. Experiments conducted on four real-world public datasets demonstrate the state-of-the-art performance and the strong explainability of HAGERec. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106194	10.1016/j.knosys.2020.106194													
J								A constrained differential evolution algorithm to solve UAV path planning in disaster scenarios	KNOWLEDGE-BASED SYSTEMS										UAV path planning; Disaster emergency management; Differential evolution algorithm; Constrained optimization	OPTIMIZATION	Disasters have caused significant losses to humans in the past decades. It is essential to learn about the disaster situation so that rescue works can be conducted as soon as possible. Unmanned aerial vehicle (UAV) is a very useful and effective tool to improve the capacity of disaster situational awareness for responders. In the paper, UAV path planning is modelled as the optimization problem, in which fitness functions include travelling distance and risk of UAV, three constraints involve the height of UAV, angle of UAV, and limited UAV slope. An adaptive selection mutation constrained differential evolution algorithm is put forward to solve the problem. In the proposed algorithm, individuals are selected depending on their fitness values and constraint violations. The better the individual is, the higher the chosen probability it has. These selected individuals are used to make mutation, and the algorithm searches around the best individual among the selected individuals. The well-designed mechanism improves the exploitation and maintains the exploration. The experimental results have indicated that the proposed algorithm is competitive compared with the state-of-art algorithms, which makes it more suitable in the disaster scenario. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106209	10.1016/j.knosys.2020.106209													
J								A parallel and constraint induced approach to modeling user preference from rating data	KNOWLEDGE-BASED SYSTEMS										Rating data; User preference; Latent variable; Bayesian network; Expectation maximization; Spark	BAYESIAN NETWORK	Observed rating data in Web2.0 applications concerns user attributes and rating scores, which explicitly reflects users' overall evaluation on events, products and various informative items. However, the unobservable user preference is critical for personalized services, precise marketing, accurate advertising, etc. In this paper, by adopting Bayesian network (BN) with a latent variable as the knowledge framework to describe user preference using the latent variable, we propose user preference Bayesian network (UPBN) to represent dependence relations among the latent and observed variables. By incorporating the classic expectation maximization (EM) algorithm and scoring & search idea for learning a BN, we focus on UPBN construction from rating data, i.e., the learning of probability parameters and graphical structure. To make UPBN fit the rating data, we first give the constraints of structure and parameters in terms of inherence dependencies among user preference, latent variable and characteristics of EM. Consequently, we present a parallel and constraint induced algorithm for UPBN construction based on EM, structural EM (SEM) and Bayesian information criterion. To deal with the large amount of iterations of probability computations and guarantee the efficiency of model construction, we implement our algorithms upon Spark for the massive intermediate results and large scale rating datasets. Experimental results show the expressiveness of UPBN for preference modeling and the efficiency of model construction, and also demonstrate that UPBN outperforms some state-of-the-art models for user preference estimation and rating prediction. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106206	10.1016/j.knosys.2020.106206													
J								Consensus reaching for social network group decision making by considering leadership and bounded confidence	KNOWLEDGE-BASED SYSTEMS										Group decision making; Consensus reaching; Interval fuzzy preference relations; Social network analysis; Bounded confidence	MINIMUM ADJUSTMENT; OPINION DYNAMICS; FEEDBACK MECHANISM; MODEL; FRAMEWORK; WEIGHTS; COST	With the rapid development of information, communication and techniques, social network group decision making problems which allow information exchange and communication among experts are more and more common in recent years. How to use social relationships generated by social networks to promote consensus among experts has been becoming a hot topic in the field of group decision making. In this paper, we consider a new type of group decision making problems in which experts will provide his/her interval fuzzy preference relations over alternatives under social network environment and propose a new model to help experts reach consensus. In the proposed model, we first define the individual consensus measure and the group consensus measure, and then use a network partition algorithm to detect sub-networks of experts, based on which the leadership of experts can be identified. Afterwards, by considering the leadership and the bounded confidence levels of experts, a new feedback mechanism which can provide acceptable advice to experts who need to modify their opinions is devised and a consensus reaching algorithm is further developed. To demonstrate the performance of the proposed consensus model and algorithm, a hypothetical application and some simulation analysis are provided eventually. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106240	10.1016/j.knosys.2020.106240													
J								HetNERec: Heterogeneous network embedding based recommendation	KNOWLEDGE-BASED SYSTEMS										Heterogeneous network; Network embedding; Recommender system; Heterogeneous network embedding	FACTORIZATION; COMMUNITY	Traditional recommendation techniques are hindered by the simplicity and sparsity of user-item interaction data and can be improved by introducing auxiliary information related to users and/or items. However, most studies have focused on a single typed external relationship and not fully utilized the latent relationships among users and items. In this paper, we propose a heterogeneous network embedding-based recommendation method called HetNERec. Specifically, we first construct the co-occurrence networks by extracting multiple co-occurrence relationships from a recommendation-oriented heterogeneous network. We then propose an integration function to integrate multiple network embedded representations into a single representation to enhance the recommendation performance. Finally, the matrix factorization is extended by integrating the embedded representations and considering the latent relationships among users and items. The experimental results on real-world datasets demonstrate that the proposed HetNERec outperforms several state-of-the-art recommendation methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106218	10.1016/j.knosys.2020.106218													
J								Conversational semantic parsing over tables by decoupling and grouping actions	KNOWLEDGE-BASED SYSTEMS										Conversation; Semantic parsing; Table; Neural network; Action space		In this article, we present a new approach for answering a series of simple but inter-related questions over a table by mapping them to the corresponding SQLs. We follow the sequence-to-action paradigm and contribute two innovations: (1) an improved action space. We decouple some actions from existing work because they were jointly deciding unrelated query components, and group some actions with one neural network feature extractor as they were seeking the same aspect of information from the question and table. We also extend the equal action to match multiple cells under a column with a key word or phrase. (2) a simplified scoring model. For question-table encoder, we incorporate BERT to enhance the detection of reference and ellipsis, thus better resolve conversations. For action decoder, we adopt simple feed-forward neural networks to avoid heuristically designed features. We achieve competitive performance on the SequentialQA dataset. Further studies show the effectiveness of each part proposed in our approach. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106237	10.1016/j.knosys.2020.106237													
J								Sparse and low-rank regularized deep subspace clustering	KNOWLEDGE-BASED SYSTEMS										Subspace clustering; Self-expressive matrix; Low-rank; Deep neural network	REPRESENTATION; REGRESSION; IMAGE	Subspace clustering aims at discovering the intrinsic structure of data in unsupervised fashion. As ever in most of approaches, an affinity matrix is constructed by learning from original data or the corresponding hand-crafted feature with some constraints on the self-expressive matrix (SEM), which is then followed by spectral clustering algorithm. Based on successful applications of deep technologies, it has become popular to simultaneously accomplish deep feature and self-representation learning for subspace clustering. However, deep feature and SEM in previous deep methods are lack of precise constraints, which is sub-optimal to conform with the linear subspace model. To address this, we propose an approach, namely sparse and low-rank regularized deep subspace clustering (SLR-DSC). In the proposed SLR-DSC, an end-to-end framework is proposed by introducing sparse and low-rank constraints on deep feature and SEM respectively. The sparse deep feature and low-rank regularized SEM implemented via fully-connected layers are encouraged to facilitate a more informative affinity matrix. In order to solve the nuclear norm minimization problem, a sub-gradient computation strategy is utilized to cater to the chain rule. Experiments on the data sets demonstrate that our method significantly outperforms the competitive unsupervised subspace clustering approaches. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				SEP 27	2020	204								106199	10.1016/j.knosys.2020.106199													
J								Stochastic local search for Partial Max-SAT: an experimental evaluation	ARTIFICIAL INTELLIGENCE REVIEW										Boolean satisfiability; Partial Max-SAT; Max-SAT; Stochastic local search; Incomplete solver; Max-SAT evaluation	CONFIGURATION CHECKING; ALGORITHMS; SATISFIABILITY	Stochastic local search (SLS) methods are heuristic-based algorithms that have gained in popularity for their efficiency and robustness when solving very large and complex problems from various areas of artificial intelligence. This study aims to gain insights into SLS methods for solving the Partial Max-SAT (PMSAT) problem. The PMSAT is an NP-Hard problem, an optimization variant of the Propositional Boolean Satisfiability (SAT) problem, that has importance in theory and practice. Many real-world problems including timetabling, scheduling, planning, routing, and software debugging can be reduced to the PMSAT problem. Modern PMSAT solvers are able to solve practical instances with hundreds of thousands to millions of variables and clauses. However, performance of PMSAT solvers are still limited for solving some benchmark instances. In this paper, we present, investigate, and analyze state-of-the-art SLS methods for solving the PMSAT problem. An experimental evaluation is presented based on the MAX-SAT evaluations from 2014 to 2019. The results of this evaluation study show that the currently best performing SLS methods for the PMSAT problem fall into three categories: distinction-based, configuration checking-based, and dynamic local search methods. Very good performance was reported for the dynamic local search based method. The paper gives a detailed picture of the performance of SLS solvers for the PMSAT problem, aims to improve our understanding of their capabilities and limitations, and identifies future research directions.																	0269-2821	1573-7462															10.1007/s10462-020-09908-4		SEP 2020											
J								Computation offloading model for smart factory	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Smart factory; Fog computing; Cloud computing; Internet of Things (IoT); Non-cooperative game; Offloading	RESOURCE-ALLOCATION; FOG; IOT; INTERNET; THINGS; CLOUD; EDGE; SIMULATION; FRAMEWORK; TASKS	Internet of Things (IoT) is coming up in a rapid pace in various application domains. In smart factories, IoT can be deployed using sensors and actuators for taking smart manufacturing decisions. To maintain the smartness, huge computational power is required to handle the generated data by the IoT sensors. Local servers, in smart factories, usually organize the sensors/actuators and takes decisions at the local level. However, they are not equipped with enough computational power to handle all types of computational tasks and therefore some tasks need to be offloaded to the upper layer such as Cloud. Hybrid cloud i.e. public cloud along with some local servers can better handle this requirement. Recently, an additional layer called fog computing is introduced in the cloud architecture to complement it with added power. Offloading of tasks, generated by the industrial applications of IoT devices, should be done only when existing computational power of local server is not able to meet the quality requirements of the tasks. An ultimate objective of the smart factory owner is to earn revenue and for that, IoT devices need to meet their quality of service expectation. For offloading, tasks can be categorized as delay sensitive and delay tolerant and making decision on offloading by the local server is non-trivial. This work proposes an offloading decision model using game theory in a non-cooperative environment considering the categorization of tasks and it is shown that dominant strategy exists for the local server. For the performance study of the proposed model, simulation is done using iFogSim simulator. A comparative study with state-of-art exhibits that the proposed offloading scheme outperforms.																	1868-5137	1868-5145															10.1007/s12652-020-02564-0		SEP 2020											
J								Hyperparameters tuning of ensemble model for software effort estimation	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Software estimation; Ensemble model; Stacking; Hyperparameters tuning; Evolutionary algorithms	FEATURE-SELECTION; OPTIMIZATION; DURATION	This article presents an effective method to improve estimation accuracy of software projects to a significant level by tuning the hyperparameters of the stacking ensemble model using evolutionary methods. Traditional and parametric methods for software effort estimation are mostly inaccurate due to bias and subjectivity. Machine Learning methods are found to be effective in dealing with bias and subjectivity issues, if the data is subjected to appropriate data pre-processing and feature extraction methods. Instead of employing a single machine learning model to estimate the software project effort, ensemble of learning models is deployed to improve the estimate. Accurate hyperparameters need to be determined to operate the ensemble model at optimised level and to reduce the errors. Hyperparameters setting is traditionally done manually according to the problem and dataset by trial and error, which is a cumbersome process. In this paper, two evolutionary approaches namely Particle Swarm Optimization (PSO) and Genetic Algorithms (GA) have been employed to tune the hyperparameters. ISBSG dataset has been used for constructing the stacking ensemble model, which is a heterogeneous dataset consisting of software project data from different countries and organizations. Experimental outcomes reveal that the accuracy of estimation is higher when the hyperparameters are tuned using PSO.																	1868-5137	1868-5145															10.1007/s12652-020-02277-4		SEP 2020											
J								Ubiquitous healthcare: a systematic mapping study	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Ubiquitous healthcare; Mapping study; Systematic literature review; EServices; MHealth; Mobile health; EHealth; Ambient assisted living; Body area networks; Telecare; Telehealth; Telemedicine and wellness; Digital health; Emerging healthcare technologies	LITERATURE-REVIEWS; MOBILE; INTERNET; THINGS	Ubiquitous healthcare is an emerging area that employs ubiquitous technologies to enable technology oriented environment for healthcare professionals for provision of efficient and effective healthcare services. In past years, research community has proposed various technological solutions in different healthcare areas such as chronic disease monitoring, gait analysis, mood and fall detection, neuropathic monitoring, physiological and vital signs monitoring, pulmonogical monitoring, etc. However, in-depth analysis of these proposed solutions is required to analyze the form of proposed ubiquitous healthcare solutions; the extent ubiquitous technologies are integrated in these solutions; the type of real problem addressed; and how far these solutions are evaluated in real world settings? The addressal of these questions is critical to understand and evaluate the progress made in the area of ubiquitous healthcare and identify the challenges that are hindering the progress in this area. Therefore, in this research, a systematic research technique in the form of mapping study (also known as scoping study) is employed for in-depth analysis of evidences available on ubiquitous healthcare. The mapping study adopts a systematic approach to construct chain of evidences related to a particular topic and is a well-defined research technique in evidence based software engineering. This study identified a total of 103 primary studies, published between 2007 and 2018, for analysis of area under investigation. The study findings reveal that research trend in ubiquitous healthcare is horizontally spread by involving broad range of healthcare areas. The proposed solutions largely fall under the category of validation studies where experiments are conducted in laboratory settings rather real world environment. Another interesting finding is the lack of involvement of relevant healthcare community in proposed solution design. The challenges such as context awareness, data ownership, privacy and security, usability and trust are limiting the adoption of proposed solutions. Therefore, more extensive studies are required to first evaluate the applicability of proposed solutions in their respective environment, second, engagement and ownership of relevant community in solution design need to be considered. Third, the broad coverage of healthcare areas does not provide significant clusters of similar research in any particular area therefore future research should focus on strengthening these areas by conducting evaluation based longitudinal studies. In this way, the effects of proposed solutions can only be measured objectively and can be added to the body of knowledge. Finally, this research provides a thorough insight into the research on ubiquitous healthcare and offers an opportunity to conduct further research in this area.																	1868-5137	1868-5145															10.1007/s12652-020-02513-x		SEP 2020											
J								Nonlinear Model Predictive Control with Enhanced Actuator Model for Multi-Rotor Aerial Vehicles with Generic Designs	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Model predictive control; Multi-rotor aerial vehicles; Multi-directional thrust; Actuator constraints	STABILITY; TRACKING; MPC; ROBOTS	In this paper, we propose, discuss, and validate an online Nonlinear Model Predictive Control (NMPC) method for multi-rotor aerial systems with arbitrarily positioned and oriented rotors which simultaneously addresses the local reference trajectory planning and tracking problems. This work brings into question some common modeling and control design choices that are typically adopted to guarantee robustness and reliability but which may severely limit the attainable performance. Unlike most of state of the art works, the proposed method takes advantages of a unified nonlinear model which aims to describe the whole robot dynamics by explicitly including a realistic physical description of the actuator dynamics and limitations. As a matter of fact, our solution does not resort to common simplifications such as: (1) linear model approximation, (2) cascaded control paradigm used to decouple the translational and the rotational dynamics of the rigid body, (3) use of low-level reactive trackers for the stabilization of the internal loop, and (4) unconstrained optimization resolution or use of fictitious constraints. More in detail, we consider as control inputs the derivatives of the propeller forces and propose a novel method to suitably identify the actuator limitations by leveraging experimental data. Differently from previous approaches, the constraints of the optimization problem are defined only by the real physics of the actuators, avoiding conservative - and often not physical - input/state saturations which are present, e.g., in cascaded approaches. The control algorithm is implemented using a state-of-the-art Real Time Iteration (RTI) scheme with partial sensitivity update method. The performances of the control system are finally validated by means of real-time simulations and in real experiments, with a large spectrum of heterogeneous multi-rotor systems: anunder-actuatedquadrotor, afully-actuatedhexarotor, a multi-rotor withorientablepropellers, and a multi-rotor with an unexpectedrotor failure. To the best of our knowledge, this is the first time that a predictive controller framework with all the valuable aforementioned features is presented and extensively validated in real-time experiments and simulations.																	0921-0296	1573-0409															10.1007/s10846-020-01250-9		SEP 2020											
J								All-Instances Restricted Chase Termination for Linear TGDs	KUNSTLICHE INTELLIGENZ											QUERY; RULES	The chase procedure is a fundamental algorithmic tool in database theory with a variety of applications. A key problem concerning the chase procedure is all-instances chase termination: for a given set of tuple-generating dependencies (TGDs), is it the case that the chase terminates for every input database? In view of the fact that this problem is, in general, undecidable, it is natural to ask whether well-behaved classes of TGDs, introduced in different contexts, ensure decidability. It has been recently shown that the problem is decidable for the restricted (a.k.a. standard) version of the chase, and linear TGDs, a prominent class of TGDs that has been introduced in the context of ontological query answering, under the assumption that only one atom appears in TGD-heads. We provide an alternative proof for this result based on Monadic Second-Order Logic, which we believe is simpler that the ones obtained from the literature.																	0933-1875	1610-1987															10.1007/s13218-020-00690-7		SEP 2020											
J								Assess deep learning models for Egyptian exchange prediction using nonlinear artificial neural networks	NEURAL COMPUTING & APPLICATIONS										Artificial neural networks; Autoregressive; Bayesian regularization; Deep learning; Egyptian stock market; Levenberg-Marquardt; Stock price prediction	STOCK-MARKET PREDICTION; INDEXES; ALGORITHM	Financial analysis of the stock market using the historical data is the exigent demand in business and academia. This work explores the efficiency of three deep learning (Dl) techniques, namely Bayesian regularization (BE), Levenberg-Marquardt (lM), and scaled conjugate gradient (SCG), for training nonlinear autoregressive artificial neural networks (NARX) for predicting specifically the closing price of the Egyptian Stock Exchange indices (EGX-30, EGX-30-Capped, EGX-50-EWI, EGX-70, EGX-100, and NIlE). An empirical comparison is established among the experimented prediction models considering all techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. For performance evaluation, statistical measures such as mean squared error (MSE) and correlationRare used. From the simulation result, it can be clearly suggested that BR outperforms other models for short-term prediction especially for 3 days ahead. On the other hand, lM generates better prediction accuracy than BR- and SCG-based models for long-term prediction, especially for 7-day prediction.																	0941-0643	1433-3058															10.1007/s00521-020-05374-9		SEP 2020											
J								Safety diagnosis of TBM for tunnel excavation and its effect on engineering	NEURAL COMPUTING & APPLICATIONS										Tunnel mechanical engineering; Mining law; Risk management; Construction safety risk		Since the development of tunnel construction technology, different tunnel excavation technologies have also been derived for different conditions. The safety diagnosis before the TBM mining method is particularly important. With the technology of safety diagnosis, the excavation process has the following effects on the tunnel engineering work. Great guarantee. The purpose of this paper is to study the excavation process of tunnel machinery for safety diagnosis before mining by TBM. It mainly includes step excavation method, full-section excavation method, guide pit excavation method and other technologies. This article uses a city subway construction project as an example to discuss in-depth the study of tunnel machinery excavation technology before the safety diagnosis of the mining method. The specific project is a city subway line with a total length of about 25.464 km and a total of 22 stations, including 9 transfer station. Based on field engineering experiments, the problems encountered in tunnel mechanical excavation are studied. The experimental data show that the results obtained through engineering tests can guarantee the safe and stable construction of the tunnel project, and the safety rate can reach 90%. The experimental results show that the obtained results can ensure the safety of tunnel mechanical excavation.																	0941-0643	1433-3058															10.1007/s00521-020-05371-y		SEP 2020											
J								A complete ranking method for interval-valued intuitionistic fuzzy numbers and its applications to multicriteria decision making	SOFT COMPUTING										Interval-valued intuitionistic fuzzy numbers; Entropy function; Score function	IMPROVED ACCURACY FUNCTION	In this study, a complete ranking method for interval-valued intuitionistic fuzzy numbers (IVIFNs) is introduced by using a score function and three types of entropy functions. This work is motivated by the work of Lakshmana Gomathi Nayagam et al. (Soft Comput 21, 7077-7082, 2017) in which a novel non-hesitant score function for the theory of interval-valued intuitionistic fuzzy sets was introduced. The authors claimed that the proposed non-hesitant score function could overcome the shortcomings of some familiar methods. By using some examples, they pointed out that the non-hesitant score function is better compared with Sahin's and Zhang et al.'s approaches. It is pointed out that although in some specific cases, the cited method overcomes the shortcomings of several of the existing methods mentioned, it also created new defects that can be solved by other methods. The main aim of this study is to give a complete ranking method for IVIFNs which can rank any two arbitrary IVIFNs. At last, two examples to demonstrate the effectiveness of the proposed method are provided.																	1432-7643	1433-7479															10.1007/s00500-020-05324-6		SEP 2020											
J								Penalty term based suitable fuzzy intuitionistic possibilistic clustering: analyzing high dimensional gene expression cancer database	SOFT COMPUTING										Fuzzy clustering; Big data; Neighboring objects; Cancer database; Penalty term	C-MEANS; ALGORITHM; PREDICTION	The aim of this paper is to identify the co-expressed potential genes that may serve for the development of the portions of normal or tumor. This paper differentiates the co-expressed genes into normal samples and tumor samples from gene expression dataset GSE25066. Since the dataset has vague boundaries and having common characteristics between the clusters, identifying the subgroups contain similar gene expression is really a tricky task one. Therefore, this paper introduces an effective fuzzy iterative clustering algorithm by incorporating kernel function, possibilistic c-means, fuzzy memberships, neighborhood information, median of neighboring objects and penalty term. The performances of the proposed clustering techniques have been shown through the succession experimental works on GSE25066. The effects of clustering results have been proved through comparing the resulted classes with ground truth.																	1432-7643	1433-7479															10.1007/s00500-020-05321-9		SEP 2020											
J								Crossroads of seeing: about layers in painting and superimposition in Augmented Reality	AI & SOCIETY										Augmented Reality; (Digital) layering; Stack; Superimposition; Transparency; Trompe-l'oe il; Velo (veil)		Augmented Reality (AR) is itself a technology in which two ways of seeing are crossed. Our field of vision is thereby superimposed with digital information and images. But before this, the real environment is already perceived by machine seeing, it is redoubled by a 3D-model, scanned, located and linked. In this brief investigation, I will face the way of seeing in AR with traditional procedures, like 'trompe-l'oe il' and the so-called 'velo', to distinguish between what remains classic and what has changed. It is important to examine this as layering, because it is a very thin stack of techniques, technology, materials and media, we seek to watch through. Subsequently, I shall analyze a painting of the contemporary artist Laura Owens in which both ways are crossed, the traditional one and the one concerning AR.																	0951-5666	1435-5655															10.1007/s00146-020-01060-5		SEP 2020											
J								Parameter Transfer Deep Neural Network for Single-Modal B-Mode Ultrasound-Based Computer-Aided Diagnosis	COGNITIVE COMPUTATION										B-mode ultrasound; Elastography ultrasound; Transfer learning; Projective model; Parameter transfer deep neural network	EXTREME LEARNING-MACHINE; BREAST-TUMORS; CLASSIFICATION; REPRESENTATION; DISEASE; LIVER	Elastography ultrasound (EUS) imaging has shown its effectiveness for diagnosis of tumors by providing additional information about tissue stiffness to the conventional B-mode ultrasound (BUS). However, due to the lack of EUS devices and experienced sonologists, EUS is not widely used, especially in rural areas. It is still a challenging task to improve the performance of the single-modal BUS-based computer-aided diagnosis (CAD) for tumors. In this work, we propose a novel transfer learning (TL)-based deep neural network (DNN) algorithm, named CW-PM-DNN, for the BUS-based CAD by transferring diagnosis knowledge from EUS during model training. CW-PM-DNN integrates both the feature-level and classifier-level knowledge transfer into a unified framework. In the feature-level TL, a bichannel DNN is learned by the cross-weight-based multimodal DL (MDL-CW) algorithm to transfer informative features from EUS to BUS. In the classifier-level TL, a projective model (PM)-based classifier is then embedded to the pretrained bichannel DNN to implement the parameter transfer in the classifier model at the second stage. The back-propagation procedure is then applied to optimize the whole CW-PM-DNN to further improve its performance. Experimental results on two bimodal ultrasound tumor datasets demonstrate that the proposed CW-PM-DNN achieves the best classification accuracy, sensitivity, and specificity of 89.02 +/- 1.54%, 88.37 +/- 4.72%, and 89.63 +/- 4.06%, respectively, for the breast ultrasound dataset, and the corresponding values of 80.57 +/- 3.41%, 76.67 +/- 3.85%, and 83.94 +/- 3.95%, respectively, for the prostate ultrasound dataset. The proposed two-stage TL-based CW-PM-DNN algorithm outperforms all the compared algorithms. It is also proved that the performance of the BUS-based CAD can be significantly improved by transferring the knowledge of EUS. It suggests that CW-PM-DNN has the potential for more applications in the field of medical image-based CAD.																	1866-9956	1866-9964															10.1007/s12559-020-09761-1		SEP 2020											
J								Application of morphological wavelet and permutation entropy in gear fault recognition	EVOLUTIONARY INTELLIGENCE										Permutation entropy; Morphological wavelet; Fault recognition; Gear	SIGNAL DECOMPOSITION SCHEMES	In this paper, a new gear fault recognition method was proposed by using morphological wavelet and permutation entropy. Firstly, the morphological Haar wavelet was proposed based on morphological wavelet, and it was used to pre-process the measured gear vibration signal. Then, the permutation entropy was used as the eigenvalue of gear fault to be extracted from the vibration signal, which included four working conditions: normal, mild wear, moderate wear, and broken teeth. Finally, according to different faults corresponding to different permutation entropy distributions, the various fault states were classified, and the permutation entropy distributions of non-denoised signals were compared. It could be seen that the morphological Haar wavelet had good de-noising effectiveness, and permutation entropy could express the feature of different gear conditions. The example of gear fault recognition proved that the combination of morphological wavelet and permutation entropy could effectively improve the ability of gear fault classification.																	1864-5909	1864-5917															10.1007/s12065-020-00492-8		SEP 2020											
J								Deep Hashing with Hash-Consistent Large Margin Proxy Embeddings	INTERNATIONAL JOURNAL OF COMPUTER VISION										Proxy embeddings; Metric learning; Image retrieval; Hashing; Transfer learning	IMAGE RETRIEVAL; QUANTIZATION; QUERY	Image hash codes are produced by binarizing the embeddings of convolutional neural networks (CNN) trained for either classification or retrieval. While proxy embeddings achieve good performance on both tasks, they are non-trivial to binarize, due to a rotational ambiguity that encourages non-binary embeddings. The use of a fixed set of proxies (weights of the CNN classification layer) is proposed to eliminate this ambiguity, and a procedure to design proxy sets that are nearly optimal for both classification and hashing is introduced. The resultinghash-consistent large margin(HCLM) proxies are shown to encourage saturation of hashing units, thus guaranteeing a small binarization error, while producing highly discriminative hash-codes. A semantic extension (sHCLM), aimed to improve hashing performance in a transfer scenario, is also proposed. Extensive experiments show that sHCLM embeddings achieve significant improvements over state-of-the-art hashing procedures on several small and large datasets, both within and beyond the set of training classes.																	0920-5691	1573-1405															10.1007/s11263-020-01362-7		SEP 2020											
J								Misdirection steganography	SOFT COMPUTING										Steganography; Data hiding; Misdirection; Entanglement; Quantum code	QUANTUM STEGANOGRAPHY; IMAGE STEGANOGRAPHY	Information is one of the most important resources in this world. Therefore, we must protect it from third parties. A typical method for protecting information contents is cryptography. We use cryptography to prevent secret information from leaking to third parties. However, we will use steganography to conceal the existence of information because cryptography cannot achieve this function. Many steganographic techniques have been also proposed as well as cryptography. In this paper, we propose a different type of steganography called misdirection steganography. Our steganography transfers two kinds of secret data, true secret data and decoy secret data, as data embedding into cover data, and the process embedding the true secret data depends on how to embed the decoy secret data, i.e., the information about embedding the decoy secret data is also required to extract the true secret data. Our aim is to transfer true secret data in secret by letting third parties pay attention to decoy secret data. In other words, misdirection in the proposed steganography techniques is caused by the fact that the decoy secret data protect the true secret data against third parties.																	1432-7643	1433-7479				NOV	2020	24	21					16005	16010		10.1007/s00500-020-05345-1		SEP 2020											
J								AFDL: a new adaptive fuzzy dictionary learning for medical image classification	PATTERN ANALYSIS AND APPLICATIONS										Sparse coding; Adaptive fuzzy dictionary learning; Medical image classification; Sparse representation	SPARSE REPRESENTATION; DISCRIMINATIVE DICTIONARY; BRAIN-TUMORS; K-SVD; SEGMENTATION; MACHINE; UNCERTAINTY; EXTRACTION; MODEL; MRI	Sparse coding allows the representation of complex data as a linear combination of basis sparse vectors (alternatively called atoms or codewords), a collection of which constitutes a dictionary. Dictionary learning is a learning process aimed at finding a small number of optimal basis vectors for a more accurate representation of the original data. The existing dictionary learning methods do not address the inherent uncertainty of the input data in their learning processes. To compensate for the uncertainty, and to obtain a flexible and effective learning system, we introduce a new adaptive fuzzy dictionary learning (AFDL) method for image classification purposes. The new method iteratively alternates between sparse coding based on a given dictionary and an adaptive fuzzy dictionary learning approach to learn (improve) dictionary atoms. The adjustability of the dictionary and coefficients vectors, in this method, provide us a more accurate and straight representation of input data. AFDL was applied on magnetic resonance images from the cancer image archive datasets, for medical image classification of cancer tumors. Finally, the overall experimental results clearly show that our approach outperforms its rival techniques in terms of accuracy, sensitivity, and specificity. Convergence speed in the experimental results shows that AFDL can achieve its acceptable precision in a reasonable time.																	1433-7541	1433-755X															10.1007/s10044-020-00909-1		SEP 2020											
J								Robustness Improvement of Visual Templates Matching Based on Frequency-Tuned Model in RatSLAM	FRONTIERS IN NEUROROBOTICS										simultaneous localization and mapping; RatSLAM; frequency-tuned model; visual templates; salient map	LOCALIZATION; MEMORY	This paper describes an improved brain-inspired simultaneous localization and mapping (RatSLAM) that extracts visual features from saliency maps using a frequency-tuned (FT) model. In the traditional RatSLAM algorithm, the visual template feature is organized as a one-dimensional vector whose values only depend on pixel intensity; therefore, this feature is susceptible to changes in illumination intensity. In contrast to this approach, which directly generates visual templates from raw RGB images, we propose an FT model that converts RGB images into saliency maps to obtain visual templates. The visual templates extracted from the saliency maps contain more of the feature information contained within the original images. Our experimental results demonstrate that the accuracy of loop closure detection was improved, as measured by the number of loop closures detected by our method compared with the traditional RatSLAM system. We additionally verified that the proposed FT model-based visual templates improve the robustness of familiar visual scene identification by RatSLAM.																	1662-5218					SEP 25	2020	14								568091	10.3389/fnbot.2020.568091													
J								Autonomous computation offloading and auto-scaling the in the mobile fog computing: a deep reinforcement learning-based approach	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobile fog computing; Offloading; Deep reinforcement learning; Power efficiency; Delay	EDGE; CLOUD; FRAMEWORK	The Fog Computing (FC) paradigm is rapidly becoming an appropriate framework for the infrastructure related to the Internet of Things (IoT). FC can be a good framework for mobile applications in the IoT. This architecture is referred to as the Mobile Fog Computing (MFC). Modules in the applications can be sent to the Fog or Cloud layer in the event of the lack of resources or increased runtime on the mobile. This increases the efficiency of the whole system. As data is entered sequentially, and the input is given to the modules, the number of executable modules increases. So, this research was conducted to find the best place in order to run the modules that can be on the mobile, Fog, or Cloud. According to the proposed method, first, the Fog Devices (FDs) were locally evaluated using a greedy technique; namely, the sibling nodes followed by the parent and in the second step, a Deep Reinforcement Learning (DRL) algorithm found the best destination to execute the module so as to create a compromise between the power consumption and execution time of the modules. The evaluation results obtained regarding the parameters of the power consumption, execution cost, delay, and network resource usage showed that the proposed method on average is better than the local execution, First-Fit (FF), and standard DRL by 18, 6, and 2%, respectively.																	1868-5137	1868-5145															10.1007/s12652-020-02561-3		SEP 2020											
J								Applying composite physiological characteristics to assess the severity of obstructive sleep apnea	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Sleep apnea; Electroencephalography; Physiological characteristics; Prediction; Fuzzy c-means clustering	POSITIVE AIRWAY PRESSURE; HEART-RATE-VARIABILITY; SYMPTOMS; PREDICTORS; DEPRESSION; DIAGNOSIS; IMPACT	Obstructive Sleep Apnea (OSA) is a common sleep disorder which causes poor sleep quality, daytime drowsiness, memory loss, and lack of attention, and can contribute to accidents. Long-term OSA is associated with cardiovascular disease, high blood pressure, arrhythmia and diabetes. Early discovery and treatment of OSA can significantly reduce the difficulty and cost of treatment. OSA detection uses a scale method which is prone to subjective errors. Polysomnography (PSG) requires long detection times, entails equipment which can be difficult to obtain and high cost, and does not provide immediate diagnosis or the establishment of preventative treatment. Human biosignals have been found to provide a faster and more objective means of sleep apnea diagnosis, allowing for the early treatment of OSA. By identifying key physiological characteristics and observing their change over time, one can assess the severity of the patient's condition, and appropriate treatment can reduce the likelihood of disease onset or slow its progression. This study applies machine learning techniques to electroencephalography (EEG), electrocardiography (ECG), oxygen saturation (SpO(2)) and other complex physiological characteristics to establish a model for OSA severity and evaluate the effectiveness of various machine learning methods to detect sleep apnea. In addition, the fuzzy C-mean (FCM) algorithm is used to construct a predictive model for OSA to assist physicians in the early clinical detection of symptoms. The study found that patients with severe sleep apnea have a self-rescue condition which causes wakening due to respiratory arrest. Only relying on SpO(2)and the Apnea Hypopnea Index (AHI) will cause severe OSA cases to be misidentified as mild, and this study found that the A5 band brain wave can help detect sleep apnea, reducing the possibility of miscategorization and assisting physicians in accurate clinical diagnosis.																	1868-5137	1868-5145															10.1007/s12652-020-02493-y		SEP 2020											
J								Optimal trade-off between sample size, precision of supervision, and selection probabilities for the unbalanced fixed effects panel data model	SOFT COMPUTING										Unbalanced fixed effects panel data model; Noise variance control; Generalization error; Large-sample approximation; Optimal sample size and selection probabilities		This paper is focused on the unbalanced fixed effects panel data model. This is a linear regression model able to represent unobserved heterogeneity in the data, by allowing each two distinct observational units to have possibly different numbers of associated observations. We specifically address the case in which the model includes the additional possibility of controlling the conditional variance of the output given the input and the selection probabilities of the different units per unit time. This is achieved by varying the cost associated with the supervision of each training example. Assuming an upper bound on the expected total supervision cost and fixing the expected number of observed units for each instant, we analyze and optimize the trade-off between sample size, precision of supervision (the reciprocal of the conditional variance of the output) and selection probabilities. This is obtained by formulating and solving a suitable optimization problem. The formulation of such a problem is based on a large-sample upper bound on the generalization error associated with the estimates of the parameters of the unbalanced fixed effects panel data model, conditioned on the training input dataset. We prove that, under appropriate assumptions, in some cases "many but bad" examples provide a smaller large-sample upper bound on the conditional generalization error than "few but good" ones, whereas in other cases the opposite occurs. We conclude discussing possible applications of the presented results, and extensions of the proposed optimization framework to other panel data models.																	1432-7643	1433-7479				NOV	2020	24	21					15937	15949		10.1007/s00500-020-05317-5		SEP 2020											
J								QNBP NN-basedI cos phi algorithm for PV systems integrated with LV/MV grid	SOFT COMPUTING										Solar PV systems; Inverter; Maximum power point tracking (MPPT); Synchronization; Power quality	POWER QUALITY IMPROVEMENT; POINT TRACKING TECHNIQUES; PERFORMANCE ANALYSIS; DSTATCOM; NETWORK; PENETRATION; VOLTAGE; BACKPROPAGATION; GENERATION	In this paper, a robust control technique is designed presented for a grid-integrated solar photovoltaic system. The proposed system consists of a solar photovoltaic array, converter along with linear/nonlinear loads. The main aim of this controller is to obtain maximum power from solar photovoltaic array and control the DC link voltage and injected grid current under different scenarios. The performance analysis of the proposed controller is demonstrated under different scenarios and meteorological conditions. The proposed system performs very well under transient conditions and gives very fast response. Moreover, various power quality indices were monitored and analyzed at unity power factor using hybrid control technique based onI cos phi approach with quasi-newton backpropagation learning. The grid current distortion is kept within the prescribed limits given by IEEE-519 and the IEEE-1547 standard. Experimental results illustrate the capabilities of proposed system under abnormal and unbalanced conditions.																	1432-7643	1433-7479															10.1007/s00500-020-05295-8		SEP 2020											
J								Numerical simulations of Newtonian fluid flow through a suddenly contracted rectangular channel with two different types of baffle plates	SOFT COMPUTING										Turbulent flow; Plane channel; Rectangular & trapezoidal baffle plate; Standard k - epsilon model	SIDE HEAT-TRANSFER; SHELL-SIDE; TRANSFER COEFFICIENTS; GEOMETRICAL FACTORS; EXCHANGERS; DOWNSTREAM; DUCTS	Numerical analysis of turbulent air flow structure through a rectangular channel along with multiple and different types of baffle plates has been performed, which is an important issue for heat exchangers and for that the flow characteristics and pressure drop are need to be identified. Finite Volume Method are employed to solve the governing equations using FLUENT with the Standard k - epsilon turbulence model. The present study has been validated at Re = 87,300 with the studies of Dermitini et al. The aim of this study is to investigate the dynamic behavior of turbulent air flow, baffle height, baffle thickness and arrangement of baffle in different locations for high values of Re = 88,000. Moreover, flow structure and pressure drop characteristics are discussed in the presence of trapezoidal and plane shape baffles. Normalized velocity profiles and skin friction coefficients have been studied at different locations for trapezoidal and plane baffle plates. Finally, it has been concluded that pressure drop attains its maximum value at the upstream of the channel and minimum value at the downstream of the channel for both the plane and trapezoidal shape baffles. It is ensured that in trapezoidal case axial velocity is higher than plane baffle when four baffles are alternately placed at lower and upper walls. Furthermore, it has also been revealed that the separation of boundary layer is influenced by baffle height (h) and baffle thickness (b). At x = 0.170 m, normalized velocity profiles (u/u0) are presented for wide range of Reynolds number, Re is an element of [44,000 - 176,000] to reveal that increase of Re causes the increase in vortexes.																	1432-7643	1433-7479															10.1007/s00500-020-05326-4		SEP 2020											
J								Handwritten Digit Classification in Bangla and Hindi Using Deep Learning	APPLIED ARTIFICIAL INTELLIGENCE											CONVOLUTIONAL NEURAL-NETWORK; RECOGNITION	Handwritten digit classification is a well-known and important problem in the field of optical character recognition (OCR). The primary challenge is correctly classifying digits which are highly varied in their visual characteristics primarily due to the writing styles of different individuals. In this paper, we propose the use of Convolutional Neural Networks (CNN) for the purpose of classifying handwritten Bangla and Hindi numerals. The major advantage that we face by using a CNN-based classifier is that no prior hand-crafted feature needs to be extracted from the images for efficient and accurate classification. An added benefit of a CNN classifier is that it provides translational invariance and a certain extent of rotational invariance during recognition. Applications can be found in real-time OCR systems where input images are often not perfectly oriented along a vertical axis. In this work, we use modified versions of the well-known LeNet CNN architecture. Extensive experiments have revealed a best-case classification accuracy of 98.2% for Bangla and 98.8% for Hindi numerals outperforming competitive models in the literature.																	0883-9514	1087-6545															10.1080/08839514.2020.1804228		SEP 2020											
J								hPSO-SA: hybrid particle swarm optimization-simulated annealing algorithm for relay node selection in wireless body area networks	APPLIED INTELLIGENCE										Wireless body area networks; Particle swarm optimization; Simulated annealing; Energy efficiency; Relay sensor node	EFFICIENT ROUTING PROTOCOL; ANT COLONY OPTIMIZATION; ENERGY-EFFICIENT; OPTIMAL-DESIGN; INTEGER; SEARCH	In the modern world, wireless body area networks (WBANs) play an essential role in psychological and biomedical applications. The use of WBANs in medical applications is limited due to various issues related to the sensors, viz., irregularity in data production, replacement and recharging of their batteries and the energy consumed by the networks. This manuscript addresses how these problems can be solved along with optimization of the energy consumption through efficient design of the system by applying routing protocols and heuristic-based optimization algorithms. In this paper, the particle swarm optimization (PSO) algorithm is a heuristic search algorithm that relies on an upgrade mechanism of the velocity and position of swarms. Although PSO has excellent exploration capability in global search, it becomes quickly stuck in local minima. To enhance the local search function of the current PSO algorithm, a simulated annealing (SA) algorithm has been incorporated in the exploitation phase. The newly developed hybrid PSO-SA (hPSO-SA) algorithm is validated with other state-of-the-art nature-inspired algorithms on eighteen benchmarks and five real engineering design problems. The statistical results of the proposed hPSO-SA algorithm are promising and indicate very good efficiency. The paper also aims at the application of the proposed algorithm to the WBAN design problem for minimization of the energy consumption through better selection of the relay node. The proposed hPSO-SA algorithm outperforms twelve other metaheuristic algorithms, taking hybrid variants for comparison.																	0924-669X	1573-7497															10.1007/s10489-020-01834-w		SEP 2020											
J								SMOTE-WENN: Solving class imbalance and small sample problems by oversampling and distance scaling	APPLIED INTELLIGENCE										Imbalanced data classification; Small sample datasets; Oversampling; Data cleaning	CLASSIFICATION; TRENDS; NOISY; TREE	Many practical applications suffer from imbalanced data classification, in which case the minority class has degraded recognition rate. The primary causes are the sample scarcity of the minority class and the intrinsic complex distribution characteristics of imbalanced datasets. The imbalanced classification problem is more serious on small sample datasets. To solve the problems of small sample and class imbalance, a hybrid resampling method is proposed. The proposed method combines an oversampling approach (synthetic minority oversampling technique, SMOTE) and a novel data cleaning approach (weighted edited nearest neighbor rule, WENN). First, SMOTE generates synthetic minority class examples using linear interpolation. Then, WENN detects and deletes unsafe majority and minority class examples using weighted distance function and k-nearest neighbor (kNN) rule. The weighted distance function scales up a commonly used distance by considering local imbalance and spacial sparsity. Extensive experiments over synthetic and real datasets validate the superiority of the proposed SMOTE-WENN compared with three state-of-the-art resampling methods.																	0924-669X	1573-7497															10.1007/s10489-020-01852-8		SEP 2020											
J								A survey on video-based Human Action Recognition: recent updates, datasets, challenges, and applications	ARTIFICIAL INTELLIGENCE REVIEW										Human Action Recognition (HAR); Machine Learning (ML); Deep Learning (DL); Challenges in HAR; Public Datasets for HAR; Future directions	EXTREME LEARNING-MACHINE; HUMAN FALL DETECTION; BEHAVIOR RECOGNITION; GESTURE RECOGNITION; GAIT RECOGNITION; EVENT DETECTION; HUMAN MOVEMENT; SYSTEM; MOTION; CLASSIFIER	Human Action Recognition (HAR) involves human activity monitoring task in different areas of medical, education, entertainment, visual surveillance, video retrieval, as well as abnormal activity identification, to name a few. Due to an increase in the usage of cameras, automated systems are in demand for the classification of such activities using computationally intelligent techniques such as Machine Learning (ML) and Deep Learning (DL). In this survey, we have discussed various ML and DL techniques for HAR for the years 2011-2019. The paper discusses the characteristics of public datasets used for HAR. It also presents a survey of various action recognition techniques along with the HAR applications namely, content-based video summarization, human-computer interaction, education, healthcare, video surveillance, abnormal activity detection, sports, and entertainment. The advantages and disadvantages of action representation, dimensionality reduction, and action analysis methods are also provided. The paper discusses challenges and future directions for HAR.																	0269-2821	1573-7462															10.1007/s10462-020-09904-8		SEP 2020											
J								A clustering approach for modularizing service-oriented systems	JOURNAL OF INTELLIGENT MANUFACTURING										Product modularity; Service modularity; Service-oriented system; Clustering; Variety management	PRODUCT MODULARITY	Companies are seeking more and more to offer customized goods and services to customers to be able to satisfy their needs. Several methods emerged to fulfill the needs of customization without affecting the performance of the company. Modularity has been considered as an effective method to address the challenges regarding variety management in the product and service domain. It has been addressed in the product domain but rarely in the service domain. This paper aims to provide a method to modularize a service-oriented system that consists of products and services. The method uses a set of modularization criteria and clustering techniques to form service-oriented system modules (product and/or service modules). The output of the clustering process is evaluated using indicators to provide decision-makers with insights into potentially preferred clustering alternatives. A test case is presented in order to show the applicability of the method.																	0956-5515	1572-8145															10.1007/s10845-020-01668-w		SEP 2020											
J								Optimization of the integrated fleet-level imperfect selective maintenance and repairpersons assignment problem	JOURNAL OF INTELLIGENT MANUFACTURING										Fleet selective maintenance; Reliability; Preventive maintenance; Repairperson assignment; Optimization	MULTISTATE SYSTEMS; GAME APPROACH; STRATEGY; BREAKS	Industrial environments such as manufacturing and transportation industries usually involve fleets of identical systems that must carry out several missions interspersed with scheduled finite breaks. Given the limited amount of maintenance resources and time available, only a restricted number of maintenance actions can be performed on selected components to ensure a pre-specified performance level of the fleet for the next mission. Such a maintenance strategy is known as fleet-level selective maintenance (FSM). The FSM is more complex than the selective maintenance problem as it adds the total number of systems in the fleet as another level of combinations to be explored during the optimization process. Most FSM models consider the replacement or perfect repair of system components as the only maintenance option. Furthermore, they consider a single repair channel and disregard the assignment of repairpersons and the impact of their variable skillsets on the maintenance costs and duration. In this paper, an approach is proposed to help in more realistic decision making for FSM where several imperfect maintenance levels and multiple repair channels are available. A novel integrated non-linear programming formulation of the FSM problem where maintenance and repairpersons assignment decisions are made jointly is proposed. All relevant parameters and terms of this non-linear optimization problem are developed and discussed. A two-phase modeling approach is then used to transform the original nonlinear problem into a binary integer optimization model. To demonstrate the validity and the added value of the proposed approach, multiple sets of numerical experiments are investigated and managerial implications are provided.																	0956-5515	1572-8145															10.1007/s10845-020-01672-0		SEP 2020											
J								Structural health monitoring of railway tracks using IoT-based multi-robot system	NEURAL COMPUTING & APPLICATIONS										Multi-robot system; Convolutional neural network (CNN); Artificial Neural Network (ANN); Random forest; Support Vector Machine (SVM); LEACH protocol	SURFACE-DEFECTS; INSPECTION	A multi-robot-based fault detection system for railway tracks is proposed to eliminate manual human visual inspection. A hardware prototype is designed to implement a master-slave robot mechanism capable of detecting rail surface defects, which include cracks, squats, corrugations, and rust. The system incorporates ultrasonic sensor inputs coupled with image processing using OpenCV and deep learning algorithms to classify the surface faults detected. The proposed Convolutional Neural Network (CNN) model fared better compared to the Artificial Neural Network (ANN), random forest, and Support Vector Machine (SVM) algorithms based on accuracy, R-squared value, F1 score, and Mean-Squared Error (MSE). To eliminate manual inspection, the location and status of the fault can be conveyed to a central location enabling immediate attention by utilizing GSM, GPS, and cloud storage-based technologies. The system is extended to a multi-robot framework designed to optimize energy utilization, increase the lifetime of individual robots, and improve the overall network throughput. Thus, the Low Energy Adaptive Clustering Hierarchy (LEACH) protocol is simulated using 100 robot nodes, and the corresponding performance metrics are obtained.																	0941-0643	1433-3058															10.1007/s00521-020-05366-9		SEP 2020											
J								Deep autoencoder for false positive reduction in handgun detection	NEURAL COMPUTING & APPLICATIONS										Handgun detection; False positive reduction; Autoencoder; One-class classification		In an object detection system, the main objective during training is to maintain the detection and false positive rates under acceptable levels when the model is run over the test set. However, this typically translates into an unacceptable rate of false alarms when the system is deployed in a real surveillance scenario. To deal with this situation, which often leads to system shutdown, we propose to add a filter step to discard part of the new false positive detections that are typical of the new scenario. This step consists of a deep autoencoder trained with the false alarm detections generated after running the detector over a period of time in the new scenario. Therefore, this step will be in charge of determining whether the detection is a typical false alarm of that scenario or whether it is something anomalous for the autoencoder and, therefore, a true detection. In order to decide whether a detection must be filtered, three different approaches have been tested. The first one uses the autoencoder reconstruction error measured with the mean squared error to make the decision. The other two use thek-NN (k-nearest neighbors) and one-class SVMs (support vector machines) classifiers trained with the autoencoder vector representation. In addition, a synthetic scenario has been generated with Unreal Engine 4 to test the proposed methods in addition to a dataset with real images. The results obtained show a reduction in the number of false positives between 22.5% and 87.2% and an increase in the system's precision of 1.2%-47% when the autoencoder is applied.																	0941-0643	1433-3058															10.1007/s00521-020-05365-w		SEP 2020											
J								Cost-sensitive Dictionary Learning for Software Defect Prediction	NEURAL PROCESSING LETTERS										Software defect prediction; Cost-sensitive; Dictionary learning; Discrimination	LABEL PROPAGATION; NEURAL-NETWORKS; RECOGNITION; INFORMATION; MACHINE; QUALITY	In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments ontwenty-fivesoftware projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison withtenstate-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.																	1370-4621	1573-773X															10.1007/s11063-020-10355-z		SEP 2020											
J								Linguistic Interval-Valued Pythagorean Fuzzy Sets and Their Application to Multiple Attribute Group Decision-making Process	COGNITIVE COMPUTATION										Linguistic interval-valued Pythagorean fuzzy set; Multiple attribute group decision-making; Aggregation operators; Linguistic variables; Interval numbers; Pythagorean fuzzy set	AGGREGATION OPERATORS; NORM	The paper's aims are to present a novel concept of linguistic interval-valued Pythagorean fuzzy set (LIVPFS) or called a linguistic interval-valued intuitionistic type-2 fuzzy set, which is a robust and trustworthy tool, and to accomplish the imprecise information while solving the decision-making problems. The presented LIVPFS is a generalization of the linguistic Pythagorean fuzzy set, by characterizing the membership and non-membership degrees as the interval-valued linguistic terms to represent the uncertain information. To explore the study, we firstly define some basic operational rules, score and accuracy functions, and the ordering relations of LIVPFS with a brief study of the desirable properties. Based on the stated operational laws, we proposed several weighted averages and geometric aggregating operators to aggregate the linguistic interval-valued Pythagorean fuzzy information. The fundamental inequalities between the proposed operators and their properties are discussed in detail. Finally, a multiple attribute group decision-making (MAGDM) algorithm is promoted to solve the group decision-making problems with uncertain information using linguistic features and the proposed operators. The fundamental inequalities between the proposed operators and their properties are discussed in detail. Also, the illustration of the stated algorithm is given through several numerical examples and compared their performance with the results of the existing algorithms. Based on the stated MAGDM algorithm and the suitable operators, the decision-makers' can be selected their best alternatives with their own attitude character towards optimism or pessimism choice. The presented LIVPFS is an extension of the several existing sets and is more generalized to utilize the uncertain and imprecise information with a wider range of information. Based on the presented aggregation operators, a decision-maker can select the desired one as per their choices to access the finest alternatives.																	1866-9956	1866-9964															10.1007/s12559-020-09750-4		SEP 2020											
J								A Novel Approach for Detecting Anomalous Energy Consumption Based on Micro-Moments and Deep Neural Networks	COGNITIVE COMPUTATION										Energy consumption; Micro-moments; Deep neural network; Anomalies detection; Visualization; Energy efficiency	BEHAVIOR-CHANGE; EFFICIENCY; PERFORMANCE; MANAGEMENT; FEATURES; IMPACT	Nowadays, analyzing, detecting, and visualizing abnormal power consumption behavior of householders are among the principal challenges in identifying ways to reduce power consumption. This paper introduces a new solution to detect energy consumption anomalies based on extracting micro-moment features using a rule-based model. The latter is used to draw out load characteristics using daily intent-driven moments of user consumption actions. Besides micro-moment features extraction, we also experiment with a deep neural network architecture for efficient abnormality detection and classification. In the following, a novel anomaly visualization technique is introduced that is based on a scatter representation of the micro-moment classes, and hence providing consumers an easy solution to understand their abnormal behavior. Moreover, in order to validate the proposed system, a new energy consumption dataset at appliance level is also designed through a measurement campaign carried out at Qatar University Energy Lab, namely, Qatar University dataset. Experimental results on simulated and real datasets collected at two regions, which have extremely different climate conditions, confirm that the proposed deep micro-moment architecture outperforms other machine learning algorithms and can effectively detect anomalous patterns. For example, 99.58% accuracy and 97.85% F1 score have been achieved under Qatar University dataset. These promising results establish the efficacy of the proposed deep micro-moment solution for detecting abnormal energy consumption, promoting energy efficiency behaviors, and reducing wasted energy.																	1866-9956	1866-9964															10.1007/s12559-020-09764-y		SEP 2020											
J								Neural Network-Based Event-Triggered Adaptive Control Algorithms for Uncertain Nonlinear Systems with Actuator Failures	COGNITIVE COMPUTATION										Neural network; Event-triggered; Fault-tolerant control; Observer	MULTIAGENT SYSTEMS; CONSENSUS; STABILITY; TRACKING	The adaptive control for strict-feedback nonlinear systems has drawn a lot of attention in various communities. Since neural network is a useful universal-approximator to approximate unknown plant model, the neural network-based adaptive control for nonlinear systems has attracted substantial interest over decades. Furthermore, to reduce the controller updating and save the control resource, the event-triggered mechanism has been widely applied. In this paper, the RBF neural network is applied to construct the state and composite disturbance observers and the back-stepping and Lyapunov-like method are applied to design the event-triggered adaptive controller. The theoretical framework of adaptive fault-tolerant control issue for strict-feedback nonlinear system that suffer from both unknown mismatched disturbance and actuator failures is formulated. This paper comes up with a novel event-triggered control strategy to guarantee that the tracking issue is resolved with better desired performance. In this study, a unified theoretical mechanism is developed to tackle the case where some factors consisting of unknown state variables, unknown mismatched disturbance, and actuator failures as well as event-triggered effects are merged together. We expect to extend the proposed method for the self-triggered case.																	1866-9956	1866-9964															10.1007/s12559-020-09767-9		SEP 2020											
J								Road obstacles positional and dynamic features extraction combining object detection, stereo disparity maps and optical flow data	MACHINE VISION AND APPLICATIONS										Features extraction; Disparity map; Optical flow		One of the most relevant tasks in an intelligent vehicle navigation system is the detection of obstacles. It is important that a visual perception system for navigation purposes identifies obstacles, and it is also important that this system can extract essential information that may influence the vehicle's behavior, whether it will be generating an alert for a human driver or guide an autonomous vehicle in order to be able to make its driving decisions. In this paper we present an approach for the identification of obstacles and extraction of class, position, depth and motion information from these objects that employs data gained exclusively from passive vision. We use a convolutional neural network for the obstacles detection, optical flow for the analysis of movement of the detected obstacles, both in relation to the direction and in relation to the intensity of the movement, and also stereo vision for the analysis of distance of obstacles in relation to the vehicle. We performed our experiments on two different datasets, and the results obtained showed a good efficacy from the use of depth and motion patterns to assess the obstacles' potential threat status.																	0932-8092	1432-1769				SEP 25	2020	31	7-8							73	10.1007/s00138-020-01126-w													
J								A new feature extraction process based on SFTA and DWT to enhance classification of ceramic tiles quality	MACHINE VISION AND APPLICATIONS										Image processing; Pattern recognition; Manufacturing systems; Hyper-parameter tuning	ALGORITHM	We propose a combination of image processing methods to detect ceramic tiles defects automatically. The primary goal is to identify faults in ceramic tiles, with or without texture. The process consists of four steps: preprocessing, feature extraction, optimization, and classification. In the second step, gray-level co-occurrence matrix, segmentation-based fractal texture analysis, discrete wavelet transform, local binary pattern, and a novel method composed of segmentation-based fractal texture analysis and discrete wavelet transform are applied. The genetic algorithm was used to optimize the parameters. In the classification step,k-nearest neighbor, support vector machine, multilayer perceptron, probabilistic neural network, and radial basis function network were assessed. Two datasets were used to validate the proposed process, totaling 782 ceramic tiles. In comparison with the other feature extraction methods commonly used, we demonstrate that the use of SFTA with DWT had a remarkable increase in the overall accuracy, without compromising computational time. The proposed method can be executed in real time on actual production lines and reaches a defect detection accuracy of 99.01% for smooth tiles and 97.89% for textured ones.																	0932-8092	1432-1769				SEP 24	2020	31	7-8							71	10.1007/s00138-020-01121-1													
J								Real-time and accurate abnormal behavior detection in videos	MACHINE VISION AND APPLICATIONS										Abnormal behavior detection; Real-time; Spatiotemporal autoencoder; Spatiotemporal convolutional neural network	UNUSUAL EVENT DETECTION; ANOMALY DETECTION; CROWDED SCENES; NEURAL-NETWORKS; LOCALIZATION	Abnormal crowd behavior detection is a hot research topic in the field of computer vision. In order to solve the problems of high computational cost and the imbalance between positive and negative samples, we propose an efficient algorithm that can detect and locate anomalies in videos. In order to solve the problem of less negative samples, the algorithm uses the spatiotemporal autoencoder to identify and extract the negative samples (contain abnormal behaviors) in the dataset in an unsupervised learning method. On this basis, a spatiotemporal convolutional neural network (CNN) is constructed with simple structure and low computational complexity. The supervised training method is used to train the spatiotemporal CNN with positive and negative samples to generate the detection model. Experiments are conducted on the UCSD and UMN datasets. The experiment results show that the proposed algorithm can detect and locate abnormal behaviors in real time (using only CPU), and the accuracy of the algorithm exceeds those of the existing algorithms at both the pixel level and frame level.																	0932-8092	1432-1769				SEP 24	2020	31	7-8							72	10.1007/s00138-020-01111-3													
J								Enhancing feature fusion for human pose estimation	MACHINE VISION AND APPLICATIONS										Human pose estimation; Convolutional neural networks; Feature fusion; Global convolutional network (GCN )		Current human pose estimation methods mainly rely on designing efficient Convolutional Neural Networks (CNN) frameworks. These CNN architectures typically consist of high-to-low resolution sub-networks to learn semantic information, and then followed by low-to-high sub-networks to raise the resolution to locate the keypoints. Because low-level features have high resolution but less semantic information, while high-level features have rich semantic information but less high resolution details, so it is important to fuse different level features to improve the final performance. However, most existing models implement feature fusion by simply concatenate low-level and high-level features without considering the gap between spatial resolution and semantic levels. In this paper, we propose a new feature fusion method for human pose estimation. We introduce high level semantic information into low-level features to enhance feature fusion. Further, to keep both the high-level semantic information and high-resolution location details, we use Global Convolutional Network blocks to bridge the gap between low-level and high-level features. Experiments on MPII and LSP human pose estimation datasets demonstrate that efficient feature fusion can significantly improve the performance. The code is available at: https://github.com/tongjiangwei/FeatureFusion.																	0932-8092	1432-1769				SEP 24	2020	31	7-8							70	10.1007/s00138-020-01104-2													
J								ClothGAN: generation of fashionable Dunhuang clothes using generative adversarial networks	CONNECTION SCIENCE										Dunhuang clothes; designing clothes; GAN; style transfer; Dunhuang element	NEURAL-NETWORKS; DEEP	Clothing is one of the symbols of human civilisation. Clothing design is an art form that combines practicality and artistry. The Dunhuang clothes culture has a long history which represents ancient Chinese aesthetics. Artificial intelligence (AI) technology has been recently applied to multiple areas, which is also drawing increasing attention in fashion. However, little research has been done on the usage of AI for the creation of clothing, especially in traditional culture. It is challenging that the exploration of computer science and Dunhuang clothing design, which is a cross-history interaction between AI and Chinese classical culture. In this paper, we propose ClothGAN, which is an innovative framework for "designing" new patterns and styles of clothes based on generative adversarial network (GAN) and style transfer algorithm. Besides, we built the Dunhuang clothes dataset and conducted experiments to generate new patterns and styles of clothes with Dunhuang elements. We evaluated these clothing works generated from different models by computing inception score (IS), human prefer score (HPS) and generated score (IS and HPS). The results show that our framework outperformed others in these designing works.																	0954-0091	1360-0494															10.1080/09540091.2020.1822780		SEP 2020											
J								Transferring trading strategy knowledge to deep learning models	KNOWLEDGE AND INFORMATION SYSTEMS										Trading strategy; LSTM; RNN; Deep learning	TECHNICAL ANALYSIS; NEURAL-NETWORKS; MARKET	Trading strategies are constantly being employed in the financial markets in order to increase consistency, reduce human errors of judgment and boost the probability of taking profitable market positions. In this work, we attempt to transfer the knowledge of several different types of trading strategies to deep learning models. The trading strategies are applied on price data of foreign exchange trading pairs and are actual strategies used in production trading environments. Along with our approach to transfer the strategy knowledge, we introduce a preprocessing method of the original price candles making it suitable for use with Neural Networks. Our results suggest that the deep models that are tested perform better than simpler models and they can accurately learn a variety of trading strategies.																	0219-1377	0219-3116															10.1007/s10115-020-01510-y		SEP 2020											
J								Benchmarking performance of machine and deep learning-based methodologies for Urdu text document classification	NEURAL COMPUTING & APPLICATIONS										Urdu text document classification; Urdu news classification; Urdu news genre categorization; Multi-class Urdu text categorization computational methodologies; Deep neural networks; BERT	FEATURE-SELECTION; NEURAL-NETWORKS; GLOBAL OPTIMIZATION	In order to provide benchmark performance for Urdu text document classification, the contribution of this paper is manifold. First, it provides a publicly available benchmark dataset manually tagged against 6 classes. Second, it investigates the performance impact of traditional machine learning-based Urdu text document classification methodologies by embedding 10 filter-based feature selection algorithms which have been widely used for other languages. Third, for the very first time, it assesses the performance of various deep learning-based methodologies for Urdu text document classification. In this regard, for experimentation, we adapt 10 deep learning classification methodologies which have produced best performance figures for English text classification. Fourth, it also investigates the performance impact of transfer learning by utilizing Bidirectional Encoder Representations from Transformers approach for Urdu language. Fifth, it evaluates the integrity of a hybrid approach which combines traditional machine learning-based feature engineering and deep learning-based automated feature engineering. Experimental results show that feature selection approach named as normalized difference measure along with support vector machine outshines state-of-the-art performance on two closed source benchmark datasets CLE Urdu Digest 1000k, and CLE Urdu Digest 1Million with a significant margin of 32% and 13%, respectively. Across all three datasets, normalized difference measure outperforms other filter-based feature selection algorithms as it significantly uplifts the performance of all adopted machine learning, deep learning, and hybrid approaches. The source code and presented dataset are available at Github repository https://github.com/minixain/Urdu-Text-Classification.																	0941-0643	1433-3058															10.1007/s00521-020-05321-8		SEP 2020											
J								A heuristic technique to detect phishing websites using TWSVM classifier	NEURAL COMPUTING & APPLICATIONS										Phishing; Anti-phishing; Compromised server; Heuristic; SVM; TWSVM	SUPPORT; FEATURES; WEBPAGES	Phishing websites are on the rise and are hosted on compromised domains such that legitimate behavior is embedded into the designed phishing site to overcome the detection. The traditional heuristic techniques using HTTPS, search engine, Page Ranking and WHOIS information may fail in detecting phishing sites hosted on the compromised domain. Moreover, list-based techniques fail to detect phishing sites when the target website is not in the whitelisted data. In this paper, we propose a novel heuristic technique using TWSVM to detect malicious registered phishing sites and also sites which are hosted on compromised servers, to overcome the aforementioned limitations. Our technique detects the phishing websites hosted on compromised domains by comparing the log-in page and home page of the visiting website. The hyperlink and URL-based features are used to detect phishing sites which are maliciously registered. We have used different versions of support vector machines (SVMs) for the classification of phishing websites. We found that twin support vector machine classifier (TWSVM) outperformed the other versions with a significant accuracy of 98.05% and recall of 98.33%.																	0941-0643	1433-3058															10.1007/s00521-020-05354-z		SEP 2020											
J								Stochastic One-Step Training for Feedforward Artificial Neural Networks	NEURAL PROCESSING LETTERS										Feedforward neural network; Constructive networks; Training; Cross-validation; Single-hidden layer feedforward network; Multiple responses	EXTREME LEARNING-MACHINE; CATALYST; OPTIMIZATION; ADSORPTION; WEIGHTS; DESIGN; MODEL	This paper studies the use and application of a fast method (non-iterative and instantaneous) for Feedforward Neural Networks training in which the weights of the hidden layer are assigned randomly, and the weights of the output layer are trained through a linear regression adjustment. The method solves two of the problems that are present in traditional training: training time and optimal structure. While traditional iterative training methods require long periods to train a single structure, the proposed method allows training a structure in a single step (not iterative). In this way, by scanning the number of neurons in the hidden layer, many structures are trained in a short time, and it is possible to obtain an optimal topology. A quality control criterion of the predictions is proposed based on the coefficient of determination that guarantees short times and an optimal number of hidden neurons to characterize a specific problem. The feasibility of the proposed method is tested by comparing its performance against building functions of the artificial neural networks toolbox in Matlab(R), resulting superior in both approximation quality and training time. A rigorous study and analysis are performed for the regression of simulated data on two different surfaces with a specific noise and different topologies of the neural network. The resulting process time is at least 150 times shorter for proposed training than with the iterative training that Matlab uses, thus obtaining well-founded learning rules. A novel way of an amputated matrix is proposed that breaks the paradigm of the way multiple-output systems are trained and improves the quality of predictions with no detriment to training times.																	1370-4621	1573-773X															10.1007/s11063-020-10335-3		SEP 2020											
J								Bipartite Synchronization Analysis of Fractional Order Coupled Neural Networks with Hybrid Control	NEURAL PROCESSING LETTERS										Hybrid control; Bipartite synchronization; Fractional order	FINITE-TIME SYNCHRONIZATION; COMPLEX NETWORKS; STABILITY; GRAPH	The bipartite synchronization problem for fractional order antagonistic coupled neural networks (FACNNs) is investigated in this paper. Using the properties of gamma function and special matrix, some criteria for bipartite Mittag-Leffler (M-L) synchronization and bipartite finite time synchronization of FACNNs have been obtained. To achieve bipartite finite time pinning synchronization, hybrid control strategy is designed. That is, finite time control combined with pinning control, pinning partial nodes, which can access the information of the leader. The upper bound of synchronization setting time is obtained.																	1370-4621	1573-773X															10.1007/s11063-020-10332-6		SEP 2020											
J								Methodological aspects for cognitive architectures construction: a study and proposal	ARTIFICIAL INTELLIGENCE REVIEW										Methodology; Bio-inspired cognitive architectures; Cognition; Cognitive sciences; Neurosciences	VENTRAL VISUAL PATHWAY; OBJECT RECOGNITION; ARTIFICIAL-INTELLIGENCE; INFEROTEMPORAL CORTEX; WORKING-MEMORY; MODEL; REPRESENTATION; SYSTEMS; FRAMEWORK; NEURONS	In the field of Artificial Intelligence (AI), efforts to achieve human-like behavior have taken very different paths through time. Cognitive Architectures (CAs) differentiate from traditional AI approaches, due to their intention to model cognitive and behavioral processes by understanding the brain's structure and their functionalities in a natural way. However, the development of distinct CAs has not been easy, mainly because there is no consensus on the theoretical basis, assumptions or even purposes for their creation nor how well they reflect human function. In consequence, there is limited information about the methodological aspects to construct this type of models. To address this issue, some initial statements are established to contextualize about the origins and directions of cognitive architectures and their development, which help to outline perspectives, approaches and objectives of this work, supported by a brief study of methodological strategies and historical aspects taken by some of the most relevant architectures to propose a methodology which covers general perspectives for the construction of CAs. This proposal is intended to be flexible, focused on use-case tasks, but also directed by theoretic paradigms or manifestos. A case study between cognitive functions is then detailed, using visual perception and working memory to exemplify the proposal's assumptions, postulates and binding tools, from their meta-architectural conceptions to validation. Finally, the discussion addresses the challenges found at this stage of development and future work directions.																	0269-2821	1573-7462															10.1007/s10462-020-09901-x		SEP 2020											
J								m-polar neutrosophic soft mapping with application to multiple personality disorder and its associated mental disorders	ARTIFICIAL INTELLIGENCE REVIEW										m-polar neutrosophic soft set; m-polar neutrosophic soft mapping and its properties; Multiple personality disorder (MPD; DID) and its associated mental disorders; Decision-making	PYTHAGOREAN MEMBERSHIP GRADES; DECISION-MAKING; SET-THEORY; FUZZY; LOGIC; DIAGNOSIS; VIEW	Multiple personality disorder (MPD) or dissociative identity disorder is the mental disease in which one can observe the existence of two or more than two personalities in a single person. We define the controversies nearby the diagnosis of MPD with its associated mental disorders. We discuss the various symptoms of MPD, dissociative amnesia, depersonalization or derealization disorder, and major depression disorder. After this exploration, we perceive that these disorders enclose parallel symptoms and it is difficult to identify the accurate type of disorder with its severeness. Since in experimental diagnosis the indeterminacy and falsity parts are often neglected. Due to this problem, we cannot see the accuracy in the patient's improvement record and cannot predict the duration of treatment. To eradicate these boundaries, we present the m-polar neutrosophic soft set (MPNSS) and m-polar neutrosophic soft mapping (MPNS-mapping) with its inverse mapping. These notions are proficient and valuable to diagnose the disorder appropriately by connecting it with the mathematical modeling. The connection of m-polar neutrosophic set (MPNS) with the soft set characterizes a relation among patients, symptoms, and treatments which decreases the complexity of the case study. We build a chart based on a fuzzy interval [0, 1] to range the types of disorders. We establish an algorithm based on MPNS-mapping to identify the disease appropriately and to select the finest treatment for the corresponding disease of every patient. At last, we introduce the generalized MPNS-mapping which will helps a doctor to save the patient's improvement record and to predict the period of treatment until the disease is cured.																	0269-2821	1573-7462															10.1007/s10462-020-09912-8		SEP 2020											
J								Understanding Violin Players' Skill Level Based on Motion Capture: a Data-Driven Perspective	COGNITIVE COMPUTATION										Movement technology; Music education; Music learning technology; Multimodal interactive systems; Machine learning; Feature engineering; Feature ranking; Model selection; Error estimation	ENSEMBLE; RECOGNITION; MUSICIANS; KNOWLEDGE; FEATURES	Learning to play and perform a music instrument is a complex cognitive task, requiring high conscious control and coordination of an impressive number of cognitive and sensorimotor skills. For professional violinists, there exists a physical connection with the instrument allowing the player to continuously manage the sound through sophisticated bowing techniques and fine hand movements. Hence, it is not surprising that great importance in violin training is given to right hand techniques, responsible for most of the sound produced. In this paper, our aim is to understand which motion features can be used to efficiently and effectively distinguish a professional performance from that of a student without exploiting sound-based features. We collected and made freely available a dataset consisting of motion capture recordings of different violinists with different skills performing different exercises covering different pedagogical and technical aspects. We then engineered peculiar features and trained a data-driven classifier to distinguish among two different levels of violinist experience, namely beginners and experts. In accordance with the hierarchy present in the dataset, we study two different scenarios: extrapolation with respect to different exercises and violinists. Furthermore, we study which features are the most predictive ones of the quality of a violinist to corroborate the significance of the results. The results, both in terms of accuracy and insight on the cognitive problem, support the proposal and support the use of the proposed technique as a support tool for students to monitor and enhance their home study and practice.																	1866-9956	1866-9964															10.1007/s12559-020-09768-8		SEP 2020											
J								Uncertain SEIAR model for COVID-19 cases in China	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Uncertain differential equation; Uncertain SEIAR model; COVID-19; Parameter estimation	SIS EPIDEMIC MODEL; DIFFERENTIAL-EQUATION	The Susceptible-Exposed-Infectious-Asymptomatic-Removed (SEIAR) epidemic model is one of most frequently used epidemic models. As an application of uncertain differential equations to epidemiology, an uncertain SEIAR model is derived which considers the human uncertainty factors during the spread of an epidemic. The parameters in the uncertain epidemic model are estimated with the numbers of COVID-19 cases in China, and a prediction to the possible numbers of active cases is made based on the estimates.																	1568-4539	1573-2908															10.1007/s10700-020-09341-w		SEP 2020											
J								Hip-hop action image recognition based on symmetric algorithm and iterative weighting of dense sampling	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Symmetric algorithm; Dense sampling; Iterative weighting; Hip-hop; Action; Image; Recognition	3D	With the rapid increase of hip-hop video data, facing a large number of rapidly updated data, automatic, accurate and fast analysis and recognition of relevant information in hip-hop video has become an urgent problem to be solved. An image recognition method of hip-hop action based on symmetric algorithm and iterative weighting of dense sampling is proposed. Firstly, the symmetric action feature of human hip-hop action image is extracted by the feature extraction method based on symmetric algorithm. Then, the symmetric action feature is obtained by fusion of the hip-hop action recognition algorithm based on iterative weighting of dense sampling. Finally, the action feature is obtained based on the fused action feature. The K-nearest neighbor classification learning method is used to recognize the hip-hop action image. The experimental results show that, under the same sample number, the number of omissions of children is 3, the extraction rate is 92.5%; the number of omissions of adults is 0, the extraction rate is 100%. This method can extract the human hip-hop image well, which lays a good foundation for the subsequent image recognition.																	1868-5137	1868-5145															10.1007/s12652-020-02547-1		SEP 2020											
J								Multi-channel spectrograms for speech processing applications using deep learning methods	PATTERN ANALYSIS AND APPLICATIONS										Speech processing; Multi-channel spectrograms; Cochlear implants; Phoneme recognition		Time-frequency representations of the speech signals provide dynamic information about how the frequency component changes with time. In order to process this information, deep learning models with convolution layers can be used to obtain feature maps. In many speech processing applications, the time-frequency representations are obtained by applying the short-time Fourier transform and using single-channel input tensors to feed the models. However, this may limit the potential of convolutional networks to learn different representations of the audio signal. In this paper, we propose a methodology to combine three different time-frequency representations of the signals by computing continuous wavelet transform, Mel-spectrograms, and Gammatone spectrograms and combining then into 3D-channel spectrograms to analyze speech in two different applications: (1) automatic detection of speech deficits in cochlear implant users and (2) phoneme class recognition to extract phone-attribute features. For this, two different deep learning-based models are considered: convolutional neural networks and recurrent neural networks with convolution layers.																	1433-7541	1433-755X															10.1007/s10044-020-00921-5		SEP 2020											
J								Deep learning-based data augmentation method and signature verification system for offline handwritten signature	PATTERN ANALYSIS AND APPLICATIONS										Deep learning; Data augmentation; Signature verification; Convolutional neural networks	GRAPH EDIT DISTANCE; COMPETITION; CNN	Offline handwritten signature verification is a challenging pattern recognition task. One of the most significant limitations of the handwritten signature verification problem is inadequate data for training phases. Due to this limitation, deep learning methods that have obtained the state-of-the-art results in many areas achieve quite unsuccessful results when applied to signature verification. In this study, a new use of Cycle-GAN is proposed as a data augmentation method to address the inadequate data problem on signature verification. We also propose a novel signature verification system based on Caps-Net. The proposed data augmentation method is tested on four different convolutional neural network (CNN) methods, VGG16, VGG19, ResNet50, and DenseNet121, which are widely used in the literature. The method has provided a significant contribution to all mentioned CNN methods' success. The proposed data augmentation method has the best effect on the DenseNet121. We also tested our data augmentation method with the proposed signature verification system on two widely used databases: GPDS and MCYT. Compared to other studies, our verification system achieved the state-of-the-art results on MCYT database, while it reached the second-best verification result on GPDS.																	1433-7541	1433-755X															10.1007/s10044-020-00912-6		SEP 2020											
J								LMIs conditions to robust pinning synchronization of uncertain fractional-order neural networks with discontinuous activations	SOFT COMPUTING										Fractional-order neural networks; Discontinuous activations; Robust pinning synchronization; Lyapunov function; Linear matrix inequality (LMI)	MITTAG-LEFFLER SYNCHRONIZATION; TIME-VARYING DELAYS; GLOBAL CONVERGENCE; FINITE-TIME	This paper deals with the robust pinning synchronization issue of uncertain fractional-order neural networks with discontinuous activations (FNNDAs) by means of the linear matrix inequalities (LMIs). In this paper, a class of FNNDAs model is presented. Moreover, an appropriate pinning controller is designed to ensure the error dynamical system gets robust Mittag-Leffler stability via Lyapunov function approach, non-smooth analysis theory and inequality analysis technique. In addition, the robust pinning synchronization conditions of FNNDAs drive system and FNNDAs response system are obtained in terms of the LMIs. Finally, a typical numerical simulation is provided to show the effectiveness of the obtained results.																	1432-7643	1433-7479				NOV	2020	24	21					15927	15935		10.1007/s00500-020-05315-7		SEP 2020											
J								Towards a general class of parametric probability weighting functions	SOFT COMPUTING										Probability weighting functions; Modifier operator; Continuous-valued logic; Prospect theory	OPERATORS; UTILITY; CHOICE; RISK	In this study, we present a novel methodology that can be used to generate parametric probability weighting functions, which play an important role in behavioral economics, by making use of the Dombi modifier operator of continuous-valued logic. Namely, we will show that the modifier operator satisfies the requirements for a probability weighting function. Next, we will demonstrate that the application of the modifier operator can be treated as a general approach to create parametric probability weighting functions including the most important ones such as the Prelec and the Ostaszewski, Green and Myerson (Lattimore, Baker and Witte) probability weighting function families. Also, we will show that the asymptotic probability weighting function induced by the inverse of the so-called epsilon function is none other than the Prelec probability weighting function. Furthermore, we will prove that, by using the modifier operator, other probability weighting functions can be generated from the dual generator functions and from transformed generator functions. Finally, we will show how the modifier operator can be used to generate strictly convex (or concave) probability weighting functions and introduce a method for fitting a generated probability weighting function to empirical data.																	1432-7643	1433-7479				NOV	2020	24	21					15967	15977		10.1007/s00500-020-05335-3		SEP 2020											
J								On the dynamics: existence of chaos and symmetry in Krause and Robert (KR) flow	SOFT COMPUTING										Symmetry; Chaos; Image attractor; Hamilton energy; Boundedness	EQUATION	A detailed analytical and numerical investigation of Krause and Robert (KR) flow is done in this article. KR flow is directly derived from magnetohydrodynamics (MHD) equations by using dynamo theory that describes the process through which a rotating, convecting and electrically conducting fluid acts to maintain a magnetic field. The present work focuses on describing complex behavior and symmetry in KR flow. The existence of symmetry has a profound and far-reaching impact on the properties of solution of chaotic dynamical systems. The relation between the KR chaotic attractor with twofold symmetry and its projected image without symmetry is shown in this article. Chaotic behavior of KR flow is studied through Lyapunov spectrum and boundedness to specify the chaotic region. Moreover, the computation of the Hamilton energy shows that KR flow depends on all its variables and, therefore, enough energy is critical to generate wings of KR flow.																	1432-7643	1433-7479															10.1007/s00500-020-05325-5		SEP 2020											
J								NSLPCD: Topic based tweets clustering using Node significance based label propagation community detection algorithm	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Tweet clustering; Supervised and Unsupervised technique; Label propagation; Keyword co-occurrence; Topic modeling	EVENT DETECTION	Social networks like Twitter, Facebook have recently become the most widely used communication platforms for people to propagate information rapidly. Fast diffusion of information creates accuracy and scalability issues towards topic detection. Most of the existing approaches can detect the most popular topics on a large scale. However, these approaches are not effective for faster detection. This article proposes a novel topic detection approach - Node Significance based Label Propagation Community Detection (NSLPCD) algorithm, which detects the topic faster without compromising accuracy. The proposed algorithm analyzes the frequency distribution of keywords in the collection of tweets and finds two types of keywords: topic-identifying and topic-describing keywords, which play an important role in topic detection. Based on these defined keywords, the keyword co-occurrence graph is built, and subsequently, the NSLPCD algorithm is applied to get topic clusters in the form of communities. The experimental results using the real data of Twitter, show that the proposed method is effective in quality as well as run-time performance as compared to other existing methods.																	1012-2443	1573-7470															10.1007/s10472-020-09709-z		SEP 2020											
J								Discrete-valued belief structures combination and normalization using evidential reasoning rule	APPLIED INTELLIGENCE										Discrete-valued belief structure; Dempster-Shafer theory; Evidential reasoning; Group decision-making; Uncertain preference ordinals	LIFE-CYCLE MANAGEMENT; DECISION-MAKING; REGRESSION-ANALYSIS; AGGREGATION; UNCERTAIN; AHP	Discrete-valued belief structures (DBSs) (known as discrete belief structures) are universal in real life, differ from precise-valued belief structures, and interval-valued belief structures (IBSs). However, the combination of different discrete belief structures presents a problem that has yet to be solved. Therefore, this study investigated the respective counter-intuitive types of behavior associated with the combination of discrete belief structures within the frameworks of the Dempster-Shafer theory. (DST) evidential reasoning (ER) for the purpose of constructing a more general method for the combination and normalization of discrete evidence. Finally, an experimental application is provided to indicate that the proposed method is suitable for combining and normalizing conflict-free/conflicting discrete evidence, and can effectively solve problems involving group decision-making (GDM) with uncertain preference ordinals, such as in a software selection problem.																	0924-669X	1573-7497															10.1007/s10489-020-01897-9		SEP 2020											
J								Improved fuzzy-assisted hierarchical neural network system for design of computer-aided English teaching system	COMPUTATIONAL INTELLIGENCE										computer-aided learning; English learning system; fuzzy logic; neural network system		The world has enhanced the development of education with the rapid development of information technology in modern society to facilitate the information process. Educational technology has gained experience through the advancement of digital information network technology, from modern teaching technology to computer technology and communication technology. In this paper, an English learning system has been developed based on an improved fuzzy-assisted hierarchical neural network system (IF-HNNS). Improving the standard of English education is particularly important in improving intelligent education, especially the efficiency of classroom teaching. The development of an interactive educational system has changed the conventional way of teaching and facilitated individual independent learning. This English teaching system is a network updating computer-aided learning platform. The computer-aided system has the following advantages: (i) Easy-to-actualize computer-aided learning media will provide more teaching content and teach satisfaction. (ii) The interaction of computer-aided learning will raise interest in learning. (iii) Computer helped learners are rich in educational resources and are easy to set teaching goals. (iv) It will improve the monitoring of the education and teaching cycle using a computer-aided learning with human-computer interaction method.																	0824-7935	1467-8640															10.1111/coin.12362		SEP 2020											
J								Automatic Controller Code Generation for Swarm Robotics Using Probabilistic Timed Supervisory Control Theory (ptSCT)	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Swarm robotics; Foraging; Probabilistic timed supervisory control theory; ptSCT	TASK ALLOCATION; DISCRETE; MODEL	The development of flexible swarm robotics systems capable of adapting to the task and environmental changes is a serious challenge. The main motivations of Swarm robotics are decentralized control, stability, adaptivity, and flexibility. Usually, ad-hoc approaches are employed to design a controller capable of meeting the problem specifications. However, these methods cannot be easily verified, and in some cases, it is not even shown that they meet the specifications. Moreover, the controller source code has to be developed separately, primarily when formal methods are employed; As a result, it cannot be guaranteed that the implementation matches the design. This paper proposes a new method - probabilistic timed supervisory control (ptSCT) - to formally design a controller from systems specifications. The proposed ptSCT has several advantages: 1) the automatic generation of the controller source code utilizable in ARGoS platform, 2) formal designing capability using the implemented software tool, 3) set of powerful design components like probabilistic decisions and time constraints, and 4) the reusability of formally designed modules among different scenarios and multiple robotic platforms. Two case studies are considered to investigate various aspects of the proposed system. Firstly, the synchronization case study is implemented for a comparison between SCT and ptSCT in terms of design capabilities and memory consumption. Secondly, the foraging case study as a complex and medium-sized problem is modeled using ptSCT step by step. More than 2400 experiments with a varying number of obstacles, targets, and robots are executed in ARGoS platform in order to show the performance of the automatically generated source code.																	0921-0296	1573-0409				NOV	2020	100	2					729	750		10.1007/s10846-020-01201-4		SEP 2020											
J								Calibration of Low Cost IMU's Inertial Sensors for Improved Attitude Estimation	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Inertial measurement unit; Twelve positions calibration; Ellipsoid fitting; Eight positions calibration; Attitude solution	OF-THE-ART; KALMAN FILTER	To better solve the attitude of robots with high precision using low cost inertial measurement unit (IMU), we design novel calibration methods, namely twelve positions calibration method, method based on ellipsoid fitting and eight positions calibration method, to effectively calibrate accelerometer, magnetometer and gyroscope, respectively. An attitude estimator using data from the multi-sensors calibrated by our proposed methods was designed based on Kalman Filter, with its estimated value of the attitude prediction deviation fed back to the predicted value as the prediction deviation at the end of each filtering period. Finally, relevant experiments are designed to verify the validity of the proposed attitude solution method as well as the proposed calibration methods, with results showing that the roll and pitch angle measured by the attitude measurement unit have an effective resolution of 0.1 degrees and the yaw angle has an effective resolution of 1 degrees. The innovation of this paper is that the proposed calibration methods can be carried out with simple tools, eliminating the need for expensive and complicated multi-axis turntables, and the designed attitude measurement unit based on calibrated low cost IMU's inertial sensors has smaller size, higher resolution in roll and pitch, and much lower cost compared with the commercial MTi-G-710. The accuracy of the attitude solution for such IMU is high enough for the application on robots.																	0921-0296	1573-0409															10.1007/s10846-020-01259-0		SEP 2020											
J								Path Following Control of Quadrotor UAV With Continuous Fractional-Order Super Twisting Sliding Mode	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Fractional-order controller; Quadrotor; SMC; FO; Super twisting; Nonlinear systems; Varying load; Uncertainty and disturbance	TRACKING CONTROL; ATTITUDE-CONTROL; DISTURBANCE; DESIGN; POSITION	Quadrotors are highly maneuverable drones, which are susceptible to the parameter uncertainties such as the mass, drag coefficients, and moment of inertia. Whose nonlinearities, aerodynamic disturbances, and higher coupling between the rotational and the translational dynamics stand for a problem that demands a robust controller. In the present paper, a fractional order (FO) improved super twisting proportional-integral-derivative sliding-mode control (STPIDSMC) is proposed for the quadrotor system. To improve the speed tracking performance, a FOPIDSM surface is designed. Moreover, the proposed FO control approach ensures fast convergence, high precision, good robustness against stochastic perturbations and uncertainties. Finally, the performance of the FOSTPIDSMC is investigated under different scenarios. The simulation results clearly show the high control performance, efficiency and high disturbance rejection capacity of the controller strategy proposed in this work in comparison with the nonlinear internal model control (NLIMC) and FO backstepping sliding mode control (FOBSMC) strategies.																	0921-0296	1573-0409															10.1007/s10846-020-01256-3		SEP 2020											
J								A relative position attention network for aspect-based sentiment analysis	KNOWLEDGE AND INFORMATION SYSTEMS										Aspect-based; CNN; Relative position; Aspect attention		Aspect-based sentiment analysis can predict the sentiment polarity of specific aspect terms in the text. Compared to general sentiment analysis, it extracts more useful information and analyzes the sentiment more accurately in the comment text. Many previous approaches use long short-term memory networks with attention mechanisms to directly learn aspect-specific representations and model comment text. However, these methods always ignore the importance of the aspect terms position and interactive information between the aspect terms and other words. To address these issues, we propose an improved model based on convolutional neural networks. First, a novel relative position encode layer can integrate the relative position information of specific aspect terms validly in a text. Second, by using the aspect attention mechanism, the semantic relationship between aspect terms and words in the text is fully considered. To verify the effectiveness of the proposed models, we conduct a large number of experiments and comparisons on seven public datasets. The experimental results show that this model outperforms to other state-of-the-art methods.																	0219-1377	0219-3116															10.1007/s10115-020-01512-w		SEP 2020											
J								Group discriminative least square regression for multicategory classification	NEUROCOMPUTING										Multicategory classification; Least square regression; Group discrimination; Class-induced structure constraint	FACE RECOGNITION; ILLUMINATION; PROJECTION	The least square regression (LSR) is a popular framework for multicategory classification because it has simple mathematical formulation and efficient solution. The classification performance of LSR based methods depends heavily on the discriminative capability of the label transformation. In this work, we aim to enhance the discriminative capability of the label transformation by imposing a new class -induced structure constraint. Specifically, we propose to regularize the label transformation matrix by the difference of l(2,1) norm and l(2,2) norm of the predicted labels of each class. The major advantage of the new regularity is that, it can guarantee the ideal discrimination of the label transformation matrix and make the classification more stable. For better generalization capability, we adopt the existing e -dragging technique to relax the binary label. Leveraging the new regularity term and the label relaxation, we give a group discriminative least square regression (GDLSR) training model to learn the label trans-formation for multicategory classification. To solve the proposed model, we present an ADMM-like iter-ation algorithm, which we can guarantee a weak convergency. Experiments on several commonly used datasets show that our method outperforms both related LSR-based methods and some traditional methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						175	184		10.1016/j.neucom.2020.05.016													
J								Deterministic convergence of complex mini-batch gradient learning algorithm for fully complex-valued neural networks	NEUROCOMPUTING										Fully complex-valued neural networks; Mini-batch gradient algorithm; Convergence; Wirtinger calculus	BACKPROPAGATION ALGORITHM; PERFORMANCE BOUNDS; MOMENTUM; BOUNDEDNESS; ESTIMATORS; LMS	This paper investigates the fully complex mini-batch gradient algorithm for training complex-valued neural networks. Mini-batch gradient method has been widely used in neural network training, however, its convergence analysis is usually restricted to real-valued neural networks and of probability nature. By introducing a new Taylor mean value theorem for analytic functions, in this paper we establish determin-istic convergence results for the fully complex mini-batch gradient algorithm under mild conditions. The deterministic convergence here means that the algorithm will deterministically converge, and both the weak convergence and strong convergence will be proved. Benefited from the newly introduced mean value theorem, our results are of global nature in that they are valid for arbitrarily given initial values of the weights. The theoretical findings are validated with a simulation example. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						185	193		10.1016/j.neucom.2020.04.114													
J								Calibration of deep probabilistic models with decoupled bayesian neural networks	NEUROCOMPUTING										Calibration; Bayesian modelling; Bayesian neural networks; Image classification		Deep Neural Networks (DNNs) have achieved state-of-the-art accuracy performance in many tasks. However, recent works have pointed out that the outputs provided by these models are not well -calibrated, seriously limiting their use in critical decision scenarios. In this work, we propose to use a decoupled Bayesian stage, implemented with a Bayesian Neural Network (BNN), to map the uncalibrated probabilities provided by a DNN to calibrated ones, consistently improving calibration. Our results evi-dence that incorporating uncertainty provides more reliable probabilistic models, a critical condition for achieving good calibration. We report a generous collection of experimental results using high -accuracy DNNs in standardized image classification benchmarks, showing the good performance, flexibil-ity and robust behaviour of our approach with respect to several state-of-the-art calibration methods. Code for reproducibility is provided. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						194	205		10.1016/j.neucom.2020.04.103													
J								Log-sum enhanced sparse deep neural network	NEUROCOMPUTING										Deep neural network; Log-sum enhanced sparsity; Back propagation algorithm; Concise gradient formula; Magnetic resonance imaging.	RESTRICTED BOLTZMANN MACHINES; REGULARIZATION; REPRESENTATIONS; CONNECTIVITY; DROPOUT; KERNEL	How to design deep neural networks (DNNs) for the representation and analysis of high dimensional but small sample size data is still a big challenge. One solution is to construct a sparse network. At present, there exist many approaches to achieve sparsity for DNNs by regularization, but most of them are carried out only in the pre-training process due to the difficulty in the derivation of explicit formulae in the fine-tuning process. In this paper, a log-sum function is used as the regularization terms for both the responses of hidden neurons and the network connections in the loss function of the fine-tuning process. It provides a better approximation to the L-0-norm than several often used norms. Based on the gradient formula of the loss function, the fine-tuning process can be executed more efficiently. Specifically, the commonly used gradient calculation in many deep learning research platforms, such as PyTorch or TensorFlow, can be accelerated. Given the analytic formula for calculating gradients used in any layer of DNN, the error accumulated from successive numerical approximations in the differentiation process can be avoided. With the proposed log-sum enhanced sparse deep neural network (LSES-DNN), the spar-sity of the responses and the connections can be well controlled to improve the adaptivity of DNNs. The proposed model is applied to MRI data for both the diagnosis of schizophrenia and the study of brain developments. Numerical experiments demonstrate its superior performance among several classical classifiers tested. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						206	220		10.1016/j.neucom.2020.04.118													
J								Event-triggering H-infinity synchronization for discrete time switched complex networks via the quasi-time asynchronous controller	NEUROCOMPUTING										Event-triggering synchronization; Quasi-time dependent asynchronous controller; Switched complex networks; Coupled nodes	AVERAGE DWELL TIME; NEURAL-NETWORKS; LINEAR-SYSTEMS; NONLINEAR-SYSTEMS; STABILITY; STABILIZATION	This paper is concerned with the problem of event triggering H-infinity synchronization control for discrete -time switched complex networks via quasi-time asynchronous controllers. One event triggering mecha-nism is introduced with the triggering parameters depending on triggering states. Applying quasi-time dependent multiple Lyapunov functions and the mode-dependent average dwell time technique, quasi-time dependent synchronization conditions are obtained with a lower weighted performance index. And then, a quasi-time dependent asynchronous controller is designed with quasi-time dependent control gains in each triggering interval. In addition, not only no more than one switching, but also mul-tiple switchings are taken into account in each triggering interval, by which the assumption in some existing results is relaxed. Finally, the proposed result is applied to the PWM-driven boost converter. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 24	2020	407						221	231		10.1016/j.neucom.2020.05.003													
J								Cost sensitive active learning using bidirectional gated recurrent neural networks for imbalanced fault diagnosis	NEUROCOMPUTING										Fault diagnosis; Deep learning; Bidirectional GRU; Active learning; Class imbalance; Cost sensitive learning	FISHER DISCRIMINANT-ANALYSIS; CLASSIFICATION; MODEL	Most existing fault diagnosis methods may fail in the following three scenarios: (1) serial correlations exist in the process data; (2) fault data are much less than normal data; and (3) it is impractical to obtain enough labeled data. In this paper, a novel form of the bidirectional gated recurrent unit (BGRU) is developed to underpin effective and efficient fault diagnosis using cost sensitive active learning. Specifically, BGRU is devised to consider the dynamic behavior of a complex process. In the training phase of BGRU, the idea of weighting each training example is proposed to reduce the effect of class imbalance. Besides, in order to explore the unlabeled data, cost sensitive active learning is utilized to select the candidate instances. The effectiveness of the proposed method is evaluated on the Tennessee Eastman (TE) dataset and a real plasma etching process dataset. The experiment results show that the proposed cost senstive active learning bidirectional gated recurrent unit (CSALBGRU) method achieves better performance in both binary fault diagnosis and multi-class fault diagnosis. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						232	245		10.1016/j.neucom.2020.04.075													
J								Neuromorphic approach to tactile edge orientation estimation using spatiotemporal similarity	NEUROCOMPUTING										Tactile sensing; Neuromorphic; Biomimetic; Spatiotemporal; Edge orientation estimation; Mechanoreceptors	HUMAN HAND; FINGERTIP; MODEL	Moving a finger around the boundary edge is one of the important strategies followed by humans for ascertaining the shape and size of an object by touch. Tactile response from thousands of mechanorecep-tors in the human hand offers a high spatiotemporal resolution to perceive the edge orientation quickly (< 50 ms) and accurately (acuity of < 3 degrees). Inspired by the computational efficiency of biological tactile system, we present a neuromorphic approach to artificial tactile sensing that mimics the spike-based spa-tiotemporal tactile response of Fast Adapting type I (FA-I) mechanoreceptors. We propose a novel, model -based spatiotemporal correlation matching method to estimate the orientation of the boundary edge while a piezoresistive tactile sensor array attached to robotic arm palpates over the object. Results high-light the ability of the proposed method to efficiently leverage spatial and temporal information, by obtaining very precise orientation estimates (+/- 1.67 degrees error for edges oriented from 10 degrees to 90 degrees, with a step of 5 degrees) in spite of a low-resolution sensor (169 mm(2), 4 x 4 resolution). A comparison with both spatial and spatiotemporal based classifiers indicates that the proposed method achieves 20% lower mean absolute error (MAE) than its closest counterparts, all of which required supervised training. Furthermore, we show that even with a ten-fold loss of spike time precision (1 ms-10 ms), MAE is maintained at 2 degrees. This work highlights that even with a modest sensor size and resolution, spatiotemporal similarity met-rics can be used to obtain very precise estimates of orientation. Such an approach has potential applica-tions towards improving the tactile sensing capability in robotic/prosthetic hands where knowledge of spatial edge orientation information is paramount for object manipulation, and sensor contact area is often sparse and small. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						246	258		10.1016/j.neucom.2020.04.131													
J								Learning from discrete Gaussian label distribution and spatial channel-aware residual attention for head pose estimation	NEUROCOMPUTING										Head pose estimation; Label distribution; Attention; Deep convolutional neural network	SUPPORT VECTOR MACHINES; FACE; RECONSTRUCTION	Recent head pose estimation techniques are advanced by performing bin classification, where the pre-dicted result is compared against a one-hot classification vector. We argue that the head poses may better be modelled by discrete distribution sampled from a smooth continuous curve rather than one-hot cod-ing or some other kinds of binned classification vector, since pose angles in practice are arbitrary. In this paper, we propose a deep head pose estimation scheme by regressing between predicted probabilistic labels and discrete Gaussian distribution. Such Gaussian distribution aims at modelling the arbitrary state of true head poses and supervises the deep network through maximum mean discrepancy loss. Besides, we also propose a spatial channel-aware residual attention structure for enhancing intrinsic pose features to further improve the prediction accuracy and speed up training convergence. Experiments on two pub-lic datasets AFLW2000 and BIWI show the proposed method outperforms all previous methods, and its individual components yield substantial improvements. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						259	269		10.1016/j.neucom.2020.05.010													
J								SSM: a high-performance scheme for in situ training of imprecise memristor neural networks	NEUROCOMPUTING										Memristors; Neural networks; Crossbar; Momentum; Neuromorphic		Memristor based neural networks have great potentials in on-chip neuromorphic computing systems due to their properties of fast computation and low-energy consumption. However, the imprecise features of synaptic weight encoding by memristor devices generally result in catastrophic failures of the network in situ training. Learning schemes that consider all of the imprecise memristor network properties were rarely reported, such as variations from device-to-device (D2D) and pulse-to-pulse (P2P), weight pro-gramming without reading, pulse number rounding, etc. In this work, we have considered all major imprecise proprieties and designed a learning scheme that integrates stochastic sparse updating with momentum adaption (SSM) to efficiently train the imprecise memristor networks with high classification accuracy. With the SSM scheme, experiments show that the classification accuracy on multilayer percep-tron (MLP) and convolutional neural network (CNN) improves from 26.12% to 90.07% and from 65.98% to 92.38%, respectively. Meanwhile, the total numbers of weight updating pulses decrease 90% and 40% in MLP and CNN, respectively, and the convergence rates are both 3 x faster. The SSM scheme provides a high-accuracy, low-power, and fast-convergence solution for the in situ training of imprecise memristor networks, which is crucial to future neuromorphic intelligence systems. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						270	280		10.1016/j.neucom.2020.04.130													
J								Inequalities and stability of stochastic Hopfield neural networks with discrete and distributed delays	NEUROCOMPUTING										Integral inequalities; Differential inequalities; Exponential stability; Stochastic Hopfield neural networks	SQUARE EXPONENTIAL STABILITY; DIFFERENTIAL-EQUATIONS; FIXED-POINTS; MODELS	In this paper, the pth moment exponential stability and almost surely exponential stability of stochastic Hopfield neural networks with discrete and distributed delays are investigated. Some previous works are improved and extended. Our approach is based on constructing a class of integral inequalities and differ-ential inequalities, as well as stochastic analysis techniques. Our results neither require to construct a complicated Lyapunov function nor the differentiability of the delay function. In addition, two examples with their simulations are given to illustrate the effectiveness of the main results. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						281	291		10.1016/j.neucom.2020.05.005													
J								MobileCount: An efficient encoder-decoder framework for real-time crowd counting	NEUROCOMPUTING										Crowd counting; Light-weight Neural Networks; Fully convolutional networks; Knowledge distillation		In this work, we propose a computation-efficient encoder-decoder architecture, named MobileCount, which is specifically designed for high-accuracy real-time crowd counting on mobile or embedded devices with limited computation resources. For the encoder part, MobileNetV2 is tailored in order to sig-nificantly reduce FLOPs at a little cost of performance drop, which has 4 bottleneck blocks preceded by a max pooling layer of stride 2. The design of decoder is motivated by Light-weight RefineNet, which fur-ther boosts counting performance with only a 10% increase of FLOPs. In comparison with state-of-the-arts, our proposed network is able to achieve comparable counting performance with 1/10 FLOPs on a number of benchmarks. At last, we propose a multi-layer knowledge distillation method to further boost the performance of MobileCount without increasing its FLOPs. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						292	299		10.1016/j.neucom.2020.05.056													
J								Rank order coding based spiking convolutional neural network architecture with energy-efficient membrane voltage updates	NEUROCOMPUTING										Spiking neural network; Rank order coding; Unsupervised learning; MNIST; Neuromorphic; Spike-timing dependent plasticity	TIMING-DEPENDENT PLASTICITY	Spiking neural network (SNN) system that uses rank order coding (ROC) as input spike encoding, gener-ally suffers from low recognition accuracy and unnecessary computations that increase complexities. In this paper, we present a Spiking convolutional neural network (Spiking CNN) architecture that signifi-cantly improves recognition accuracy as well as computation efficiencies based on a novel ROC and mod-ified kernel sizes. The proposed ROC generates spike trains based on maximum input value without sorting operations. In addition, as the recognition accuracy is affected by the reduced number of spikes as layers become deeper, the proposed ROC is inserted just before the final layer to increase the number of input spikes. The 2 x 2 pooling kernels are also replaced with 4 x 4 to reduce the network size. The hardware architecture of the proposed Spiking CNN has been implemented using 65 nm CMOS process. Neuron-centric membrane voltage update approach is also efficiently exploited in convolutional and fully connected layers to improve the hardware energy efficiencies. The Spiking CNN processor is seamlessly processing 2.85 K classifications per second with 6.79 uJ/classification. It also achieves 90.2% of recogni-tion accuracy for MNIST dataset using unsupervised learning with STDP. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						300	312		10.1016/j.neucom.2020.05.031													
J								Complex-valued encoding metaheuristic optimization algorithm: A comprehensive survey	NEUROCOMPUTING										Complex-valued encoding; Complex-valued encoding Metaheuristic algorithm; Combination optimization; Engineering optimization design; Function optimization	PARTICLE SWARM OPTIMIZATION; PROBABILISTIC NEURAL-NETWORKS; SYMBIOTIC ORGANISMS SEARCH; CUCKOO SEARCH; ENGINEERING OPTIMIZATION; STRUCTURAL OPTIMIZATION; DIFFERENTIAL EVOLUTION; FUNCTION APPROXIMATION; PALMPRINT RECOGNITION; LEARNING ALGORITHM	The number of publications related to complex-valued encoding metaheuristic optimization research is increasing the area of metaheuristic optimization is gaining in popularity. In this paper, we aim to pro-vide researchers with a comprehensive and extensive overview of complex-valued encoding metaheuristic algorithms and applications for function optimization, engineering optimization design, and combination optimization. Compared with the basic metaheuristic algorithm, which are based on real-valued encod-ing or binary encoding, the complex-valued encoding metaheuristic algorithm expands the dimension of the search region and efficiently avoids the problem of falling into the local minimum. Finally, eight complex-valued encoding metaheuristic algorithms were used for 29 benchmark test functions and five engineering optimization design problems. Through the analysis and comparison of the results with sta-tistical significance, the superiority of complex-value encoding was proved, and the complex-value en-coding metaheuristic algorithm with the best performance was obtained. The purpose of this review is to present a relatively comprehensive list of all the complex-value encoding metaheuristic algorithms in the literature to inspire further research. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						313	342		10.1016/j.neucom.2019.06.112													
J								SemiText: Scene text detection with semi-supervised learning	NEUROCOMPUTING										Scene text detection; Semi-supervised learning; Mask R-CNN; Context information		Scene text detection is an important step of scene text recognition and has achieved significant progress. However, the requirement of large amounts of annotated training data, which is used for training text detection model, has become a great challenge for existing methods. In this paper, we propose a semi -supervised scene text detection framework (SemiText), which trains robust and accurate scene text detectors using a pre-trained supervised model and the unannotated data. With a pre-trained model that is pre-trained on the fully annotated synthetic dataset, i.e., SynthText, we investigate the inductive and transductive semi-supervised learning on the unannotated dataset respectively. For inductive learning, the pre-trained model is applied to the unannotated training dataset to search for more training exam-ples, which are further combined with SynthText to fine-tune the pre-trained model and achieve a supe-rior detection model. For transductive learning, the unannotated training dataset is replaced with the unannotated test dataset. Meanwhile, for the aim of real-world applications, we adopt Mask R-CNN to detect text with arbitrary shapes and exploit context information to suppress false positives. Extensive experiments on different datasets show that the performance of our text detection method can be clearly improved under both inductive and transductive semi-supervision. Additionally, we also achieve state-of-the-art performance under full supervision. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						343	353		10.1016/j.neucom.2020.05.059													
J								Analog circuit fault diagnosis based on density peaks clustering and dynamic weight probabilistic neural network	NEUROCOMPUTING										Dynamic weight; Probabilistic neural networks; Analog circuit; Fault diagnosis; Density peaks clustering	CLASSIFICATION; PROGNOSTICS; ALGORITHM	Fault diagnosis methods based on probabilistic neural networks (PNNs) have been widely used in various products, owing to their simplicity and efficiency. However, in some multi-condition circuit fault diag-noses, the presence of numerous faults and heterogeneity of the training data make the computational efficiency, classification accuracy, and selection of the pattern neuron samples of the PNN challenging. To overcome these difficulties, this study proposes a novel analog circuit fault diagnosis method based on density peaks clustering and a dynamic weight PNN. In this method, density peaks clustering is per-formed to determine the number of pattern neuron classes. Based on the results of clustering, a priority function is defined, and a novel two-step pattern neuron optimization algorithm incorporating local den-sity and gravity is proposed. Accordingly, the representative boundary data are selected as the pattern neuron samples and numerous redundant samples are reduced. Moreover, a dynamic grey correlation weight determination (GCWD) algorithm between the input and pattern layers is proposed, to determine which classes of the pattern neurons need to be activated and involved in the diagnostic calculation. In addition, a dynamic proportion-amplified weight determination (PAWD) algorithm between the pattern and summation layers is suggested to reduce the adverse effect of the heterogeneity. This not only reduces the number of calculations in the diagnostic process, but also improves the accuracy of the diag-nostic model. Case study on a filter circuit clearly demonstrates that the proposed method can achieve high classification accuracy with only a few pattern neurons. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						354	365		10.1016/j.neucom.2020.04.113													
J								Optimal feasible step-size based working set selection for large scale SVMs training	NEUROCOMPUTING										Support vector machines; Decomposition algorithm; Working set selection; Sequential minimal optimization; Feasible step-size	SUPPORT VECTOR MACHINES; DESCENT	Efficient training of support vector machines (SVMs) with large-scale samples is of crucial importance in the era of big data. Sequential minimal optimization (SMO) is considered as an effective solution to this challenging task, and the working set selection is one of the key steps in SMO. Various strategies have been developed and implemented for working set selection in LibSVM and Shark. In this work we point out that the algorithm used in LibSVM does not maintain the box-constraints which, nevertheless, are very important for evaluating the final gain of the selection operation. Here, we propose a new algorithm to address this challenge. The proposed algorithm maintains the box-constraints within a selection procedure using a feasible optional step-size. We systematically study and compare several related algorithms, and derive new theoretical results. Experiments on benchmark data sets show that our algorithm effectively improves the training speed without loss of accuracy. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						366	375		10.1016/j.neucom.2020.05.054													
J								A neural model for joint event detection and prediction	NEUROCOMPUTING										Event prediction; Joint event detection and prediction; Hierarchical attention		Event prediction aims to predict the future possible event given a sequence of previously happened events. Event prediction is important since it can benefit the government, agencies and companies for avoiding damages by taking proactive actions. A further related task is event detection, which is to classify each event to predefined types, helping users quickly find relevant information. Event prediction is related to event detection, since salient information of events is universal between the tasks. In this paper, we propose a novel neural model for joint event detection and prediction, which classifies the events to predefined types as well as predicts the next probable event by generating a sequence of words describing it. In addition, we propose a hierarchical attention mechanism to enable the model to capture important information at both word level and event level for next event prediction. Empirical experiments on a real-world dataset reveal that our joint model with hierarchical attention achieves substantial improvements on event prediction, advancing state-of-the-art models. With joint learning, our model also improves the performance on event detection. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						376	384		10.1016/j.neucom.2020.05.023													
J								Adaptive median feature baseline correction for improving of epileptic seizures in ICU EEG recognition	NEUROCOMPUTING										Adaptive median feature baseline correction; Epileptic seizures; Matrix determinant; Post-processing; Successive decomposition index; Support vector machine	SIGNAL CLASSIFICATION; APPROXIMATE ENTROPY; WAVELET TRANSFORM; SVM; REPRESENTATION; NORMALIZATION; LOCALIZATION	Automated classification of epileptic seizures surrogates the manual interventions required for analyzing long-term electroencephalographic (EEG) signals and helps to speed up the treatment in epilepsy patients. Developing a patient independent algorithm is a great challenge due to the differences in EEG characteristics. Feature distribution among many subjects results in inter-subject variability, which leads to poor classification performance. Therefore, in order to overcome this limitation, we have proposed a novel adaptive median feature baseline correction (AM-FBC) method to update the feature distribution. Two recently proposed features referred to as successive decomposition index (SDI) and matrix determi-nant (MD) were extracted from 40 intensive care unit patients EEG at a segmentation length of 4 s with 50% overlap. We have investigated the influence of outliers removal and correction, AM-FBC, and post -processing of classifier output to improve the seizure detection results. The classification was performed using a support vector machine classifier with leave-one-subject-out cross-validation. With the applica-tion of above-mentioned methods, the highest area under the curve (AUC) of 0.9663 (sensitivity S+ = 0.9661, specificity (S- = 0.8446) and 0.9812 S+ = 0.9822, S- = 0.8705) was achieved using SDI and MD fea-tures respectively. Further, the AUC of 0.9593 (S+ = 0.9069, S- = 0.8695) was achieved when both SDI and MD features were used with the application of the outliers correction method. The findings of the study suggest (1) Outliers correction method does not improve results (2) AM-FBC enhances the results (3) Post-processing method improved the classification results at least 2 to 5% and reduced false detections (4) Lowering the outlier removal factor showed good AUC at the cost of loss of feature samples. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						385	398		10.1016/j.neucom.2020.04.144													
J								Relevant region prediction for crowd counting	NEUROCOMPUTING										Crowd counting; Count map; Graph convolutional network		Crowd counting is a concerned and challenging task in computer vision. Existing density map based methods excessively focus on the individuals' localization which harms the crowd counting performance in highly congested scenes. In addition, the dependency between the regions of different density is also ignored. In this paper, we propose Relevant Region Prediction (RRP) for crowd counting, which consists of the Count Map and the Region Relation-Aware Module (RRAM). Each pixel in the count map represents the number of heads falling into the corresponding local area in the input image, which discards the detailed spatial information and forces the network pay more attention to counting rather than localizing individuals. Based on the Graph Convolutional Network (GCN), Region Relation-Aware Module is pro-posed to capture and exploit the important region dependency. The module builds a fully connected directed graph between the regions of different density where each node (region) is represented by weighted global pooled feature, and GCN is learned to map this region graph to a set of relation-aware regions representations. Experimental results on three datasets show that our method obviously outper-forms other existing state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						399	408		10.1016/j.neucom.2020.04.117													
J								A novel method to compute the weights of neural networks	NEUROCOMPUTING										Neural networks; Gradient free; Closed-form solution; White box models		Neural networks are the main strength of modern artificial intelligence; they have demonstrated revolu-tionary performance in a wide range of applications. In practice, the weights of neural networks are gen-erally obtained indirectly using iterative training methods. Such methods are inefficient and problematic in many respects. Besides, neural networks trained end-to-end by such methods are typical black box models that are hard to interpret. Thus, it would be significantly better if the weights of a neural network could be calculated directly. In this paper, we located the key for calculating the weights of a neural net-work directly: assigning proper targets to the hidden units. Furthermore, if such targets are assigned, the neural network becomes a white box model that is easy to interpret. Thus, we propose a framework for solving the weights of a neural network and provide a sample implementation of the framework. The implementation was tested in various classification and regression experiments. Compared with neural networks trained using traditional methods, the constructed ones using solved weights had similar or better performance on many tasks, while remaining interpretable. Given the early stage of the proposed approach, many improvements are expectable in future developments. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						409	427		10.1016/j.neucom.2020.03.114													
J								Deep historical long short-term memory network for action recognition	NEUROCOMPUTING										Action recognition; Deep learning; Long short-term memory (LSTM); Convolutional neural networks (CNN); Tennis game		Human action recognition technology has received increasing interest recently. The technology is very useful in sports video analysis. Most of the action recognition methods in sports mainly focus on recog-nizing which sport is being performed. However, recognizing of the specific action in videos is important for the analysis of some sports video such as tennis matches. Hence, in this paper, we proposed a deep historical long short-term memory network for video-based tennis action recognition and general action recognition. First, the spatial representations are extracted from each frame using a pre-trained convolu-tional neural network (CNN). To describe the temporal information, a stacked multi-layer long short-term memory network (LSTM) was used. The historical information of the past frames is important for model-ing the action. So we propose a historical information layer that is added to the top of the multi-layered LSTM network. A historical feature of each video is generated for classification by hybridizing the hidden state of LSTM at time t and the historical updated feature at time t-1 with an updating scheme and utilized for classification. Experiments on the benchmark datasets demonstrate that our method that using only simple raw RGB video can outperform the state-of-the-art baselines for both general action recognition and tennis action recognition. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						428	438		10.1016/j.neucom.2020.03.111													
J								Residue Number System-Based Solution for Reducing the Hardware Cost of a Convolutional Neural Network	NEUROCOMPUTING										Image recognition; Convolutional neural networks; Residue number system; Quantization noise; FPGA		Convolutional neural networks (CNNs) represent deep learning architectures that are currently used in a wide range of applications, including computer vision, speech recognition, time series analysis in fi-nance, and many others. At the same time, CNNs are very demanding in terms of the hardware and time cost of a computing system, which considerably restricts their practical use, e.g., in embedded systems, real-time systems, and mobile volatile devices. The goal of this paper is to reduce the resources required to build and operate CNNs. To achieve this goal, a CNN architecture based on Residue Number System (RNS) and the new Chinese Remainder Theorem with fractions is proposed. The new architecture gives an efficient solution to the main problem of RNSs associated with restoring the number from its residues, which determines the main contribution to the CNN structure. In accordance with the results of hardware simulation on Kintex7 xc7k70tfbg484-2 FPGA, the use of RNS in the convolutional layer of a neural net-work reduces hardware cost by 32.6% compared to the traditional approach based on the binary number system. In addition, the use of the proposed hardware-software architecture reduces the average image recognition time by 37.06% compared to the software implementation. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						439	453		10.1016/j.neucom.2020.04.018													
J								Weighted bilinear coding over salient body parts for person re-identification	NEUROCOMPUTING										Person re-identification; Feature aggregation; Bilinear coding		Deep convolutional neural networks (CNNs) have demonstrated dominant performance in person re -identification (Re-ID). Existing CNN based methods utilize global average pooling (GAP) to aggregate intermediate convolutional features for Re-ID. However, this strategy only considers the first-order statis-tics of local features and treats local features at different locations equally important, leading to sub-optimal feature representation. To deal with these issues, we propose a novel weighted bilinear coding (WBC) framework for local feature aggregation in CNN networks to pursue more representative and dis-criminative feature representations, which can adapt to other advanced methods and improve their per-formance. In specific, bilinear coding is used to encode the channel-wise feature correlations to capture richer feature interactions. Meanwhile, a weighting scheme is applied on the bilinear coding to adaptively adjust the weights of local features at different locations based on their importance in recognition, further improving the discriminability of feature aggregation. To handle the spatial misalignment issue, we use a salient part net to derive salient body parts, and apply the WBC model on each part. The final represen-tation, formed by concatenating the WBC encoded features of each part, is both discriminative and resis-tant to spatial misalignment. Experiments on three benchmarks including Market-1501, DukeMTMC-reID and CUHK03 evidence the favorable performance of our method against other outstanding methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						454	464		10.1016/j.neucom.2020.05.009													
J								Time-varying generalized tensor eigenanalysis via Zhang neural networks	NEUROCOMPUTING										Time-varying tensor; Eigenvalue and eigenvector; Z-eigenvalue; H-eigenvalue; Time-varying matrix; Generalized eigenvalues; Zhang neural network; Zhang dynamics model	SOLVING MULTILINEAR SYSTEMS; SHIFTED POWER METHOD; MULTIPLE-EIGENVALUES; MATRICES; EIGENVECTORS; DECOMPOSITION; COMPUTATION	Eigenanalysis of matrices with parameters has a long history. When the parameter is time, or the matrix is time-dependent, the Zhang neural networks for the time-varying matrix problem have been developed in recent years. Motivated by tensor generalized eigenvalues and the Zhang dynamics method, we inves-tigate the time-varying eigenpair of symmetric tensors. A continuous Zhang dynamics model is given to compute the tensor eigenpairs, such as the H-and Z-eigenpairs. In order to accelerate the convergence, a modified Zhang dynamics model is also presented. Moreover, the generalized tensor/matrix eigenpairs could also be computed by the two proposed models. Theoretical analysis of the convergence and robust-ness are provided. We also test some numerical examples which illustrate that the two proposed models are effective. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						465	479		10.1016/j.neucom.2020.04.115													
J								IT2-GSETSK: An evolving interval Type-II TSK fuzzy neural system for online modeling of noisy data	NEUROCOMPUTING										Type-II; Self-evolving; GSETSK; Neuro-fuzzy; Noisy data; Non-stationary	INFERENCE SYSTEM; NETWORK	As a core part of a fuzzy neural system, the rule base antecedents and consequents may carry uncer-tainties because they are trained using noisy data. So, handling the uncertain rule base is an important need in some specific problems such as noisy non-dynamic problems which leads a better data model-ing. As a solution, Interval Type-II (IT2) version of GSETSK (Generic Self-Evolving Takagi-Sugeno-Kang), namely IT2-GSETSK, is presented in this paper. This solution uses IT2 membership functions for handling uncertainties, plus having Type-I (GSETSK) capabilities. In this way IT2-GSETSK is a fully-online model able to handle data streams and cope with time-variant data. It also provides up-to-date, relevant and compact rule base that is easily interpretable by human. The IT2-GSETSK is tested over several applica-tions including medical, environmental and financial predictions, which show satisfactory performance of IT2-GSETSK. Moreover, it is observed that while GSETSK performs well enough for dynamic problems with less noise, noisy non-dynamic problems benefit significantly from IT2-GSETSK. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						1	11		10.1016/j.neucom.2020.03.065													
J								Hyperspectral image classification based on sparse modeling of spectral blocks	NEUROCOMPUTING										Sparse modeling; Dictionary learning; Hyperspectral image; Classification	SOURCE SEPARATION; DICTIONARY	Hyperspectral images provide abundant spatial and spectral information that is very valuable for mate-rial detection in diverse areas of practical science. The high-dimensions of data lead to many processing challenges that can be addressed via existent spatial and spectral redundancies. In this paper, a sparse modeling framework is proposed for hyperspectral image classification. Spectral blocks are introduced to be used along with spatial groups to jointly exploit spectral and spatial redundancies. To reduce the computational complexity of sparse modeling, spectral blocks are used to break the high-dimensional optimization problems into small-size sub-problems that are faster to solve. Furthermore, the proposed sparse structure enables to extract the most discriminative spectral blocks and further reduce the com-putational burden. Experiments on three benchmark datasets, i.e., Pavia University, Indian Pines and Salinas images verify that the proposed method leads to a robust sparse modeling of hyperspectral images and improves the classification accuracy compared to several state-of-the-art methods. Moreover, the experiments demonstrate that the proposed method requires less processing time. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						12	23		10.1016/j.neucom.2020.04.138													
J								Deep multi-scale convolutional transfer learning network: A novel method for intelligent fault diagnosis of rolling bearings under variable working conditions and domains	NEUROCOMPUTING										Rolling bearing; Fault diagnosis; Transfer learning; Multi-scale convolutional neural network; Global average pooling	NEURAL-NETWORK; FUSION	Intelligent fault detection and diagnosis, as an important approach, play a crucial role in ensuring the stable, reliable and safe operation of rolling bearings, which is one of the most main components in the rotating machinery. However, the data distribution shift is inevitable in the practical scene due to changes in internal and external environments, it is still challenging to establish an effective fault di-agnosis model that can eliminate the same distribution assumption. In light of the above demands, a novel transfer learning framework based on deep multi-scale convolutional neural network (MSCNN) is presented in this paper. First, a novel multi-scale module is ingenious established based on dilated convolution, which is used as the key part to obtain differential features through different perceptual fields. Then, in order to further reduce the complexity of the proposed model, a global average pooling technol-ogy is adopted to replace the traditional fully-connected layer. Finally, the architecture and weights of the MSCNN pre-trained on source domain are transferred to the other different but similar tasks with proper fine-tuning instead of training a network from scratch. The proposed MSCNN is evaluated by different transfer scenarios constructed on two famous rolling bearing test-bed. Three case studies show that the proposed framework not only has excellent performance on the source domain, but also has superior transferability on variable working conditions and domains. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 24	2020	407						24	38		10.1016/j.neucom.2020.04.073													
J								An anomaly detection framework for time-evolving attributed networks	NEUROCOMPUTING										Anomaly detection; Dynamic attributed network; Residual analysis		Real-world information systems are naturally dynamic, and they are usually represented as a time -evolving attributed network (i.e., a sequence of static attributed networks). Recently, there is a surge of research interests in finding anomalous nodes upon attributed networks due to its significant implications in many high-impact applications, such as financial fraud detection, network intrusion detection, and opinion spam detection, to name a few. Despite the importance of anomaly detection in time-evolving attributed network, a vast majority of existing methods fail to capture the evolution of the underlying networks properly, as they regard the whole system as static and neglect the evolution process. Mean-while, they treat all the attributes and the instances equally, ignoring the existence of noisy which may lead to the adverse effects to the detection results. To tackle these problems, in this paper, we propose a novel dynamic anomaly detection framework on time-evolving attributed networks on the basis of resid-ual analysis, namely AMAD. Under the assumption of temporal smoothness property, AMAD leverages the small smooth disturbance between two consecutive time stamps to characterize the evolution of net-works for incrementally update. Experiments conducted on both synthetic and real-world time-evolving attributed networks show the superiority of our proposed method in detecting anomalies. Moreover, our method is competitive in terms of efficiency compared to the existing work. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						39	49		10.1016/j.neucom.2020.04.047													
J								Optimizing Weighted Extreme Learning Machines for imbalanced classification and application to credit card fraud detection	NEUROCOMPUTING										Imbalanced classification; Weighted Extreme Learning Machine; Dandelion algorithm with probability-based mutation; Credit card fraud detection	FACE RECOGNITION; DANDELION ALGORITHM; OPTIMIZATION; SCHEME	The classification problems with imbalanced datasets widely exist in real word. An Extreme Learning Ma-chine is found unsuitable for imbalanced classification problems. This work applies a Weighted Extreme Learning Machine (WELM) to handle them. Its two parameters are found to affect its performance greatly. The aim of this work is to apply various intelligent optimization methods to optimize a WELM and com-pare their performance in imbalanced classification. Experimental results show that WELM with a dan-delion algorithm with probability-based mutation can perform better than WELM with improved particle swarm optimization, bat algorithm, genetic algorithm, dandelion algorithm and self-learning dandelion algorithm. In addition, the proposed algorithm is applied to credit card fraud detection. The results show that it can achieve high detection performance. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						50	62		10.1016/j.neucom.2020.04.078													
J								Gated forward refinement network for action segmentation	NEUROCOMPUTING										Action segmentation; Video analysis; Refinement network; Policy gradient		Action segmentation aims at temporally locating and classifying video segments in long untrimmed videos, which is of particular interest to many applications like surveillance and robotics. While most existing methods tackle this task by predicting frame-wise probabilities and adjusting them via highlevel temporal models, recent approaches classify every video frame directly with temporal convolutions. However, there are limits to generate high quality predictions due to ambiguous information in the video frames. In this paper, in order to address the limitations of existing methods in temporal action segmentation task, we propose an end-to-end multi-stage architecture, Gated Forward Refinement Network (G-FRNet). In G-FRNet, each stage makes a prediction that is refined progressively by next stage. Specifically, we propose a new gated forward refinement network to adaptively correct the errors in the prediction from previous stage, where an effective gate unit is used to control the refinement process. Moreover, to efficiently optimize the proposed G-FRNet, we design an objective function that consists of a classification loss and a multi-stage sequence-level refinement loss that incorporates segmental edit score via policy gradient. Extensive evaluation on three challenging datasets (50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset) shows our method achieves state-of-the-art results. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 24	2020	407						63	71		10.1016/j.neucom.2020.03.066													
J								SA-NLI: A Supervised Attention based framework for Natural Language Inference	NEUROCOMPUTING										Natural language inference; Supervised attention; Syntactic information; Alignment		Natural Language Inference (NLI) aims to determine the relationship of a pair of sentences. As a critical component of NLI models, attention mechanism has been proven to be effective in the representation and interaction of sentences. However, the attention methods adopted in the existing NLI models are nonparametric or trained inside the model without explicit supervision, and the attention results are poorly explained. In this paper, we propose a Supervised Attention based Natural Language Inference (SA-NLI) framework to solve this problem. In our framework, the intra attention module is trained to focus on syntactically related tokens, while the inter attention module is constrained to capture alignment between sentences. Moreover, the supervised training of intra attention module and inter attention module are unified with the training of the NLI model by multi-task learning and transfer learning, respectively. We conduct extensive experiments on multiple NLI datasets, and the results demonstrate the effectiveness of our supervised attention based method. Further visual analysis validates the interpretability of attention results, and the extended experimental results indicate the generalization of our SA-NLI framework. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				SEP 24	2020	407						72	82		10.1016/j.neucom.2020.03.092													
J								Tree decomposition based anomalous connected subgraph scanning for detecting and forecasting events in attributed social media networks	NEUROCOMPUTING										Anomalous subgraph detection; Approximation algorithm; Social media networks; Nonparametric statistics; Tree decomposition; Event detection and forecasting	STATISTICS; TWITTER	Event detection and forecasting in social media networks, such as disease outbreak and air pollution event detection, have been formulated as an anomalous connected subgraph detection problem. How-ever, the huge search space and the sparsity of anomaly events make it difficult to solve this problem effectively and efficiently. This paper presents a general framework, namely anomalous connected sub -graph scanning (GraphScan) which optimizes a large class of sophisticated nonlinear nonparametric scan statistic functions, to solve this problem in attributed social media networks. We first transform the so-phisticated nonlinear nonparametric scan statistics functions into the Price-Collecting Steiner Tree (PCST) problem with provable guarantees for evaluating the significance of connected subgraphs to indicate the ongoing or forthcoming events. Then, we use tree decomposition technique to divide the whole graph into a set of smaller subgraph bags, and arrange them into a tree structure, through which we can re-duce the search space dramatically. Finally, we propose an efficient approximation algorithm to solve the problem of anomalous subgraph detection using the tree of bags. With two real-world datasets from different domains, we conduct extensive experimental evaluations to demonstrate the effectiveness and efficiency of the proposed approach. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						83	93		10.1016/j.neucom.2020.04.064													
J								Context-aware colorization of gray-scale images utilizing a cycle-consistent generative adversarial network architecture	NEUROCOMPUTING										Context-aware specialist network; Generative adversarial network; Image colorization; Two-stage architecture		Converting gray-scale images to colorful ones is one of the challenging tasks in the Computer Vision area, and various approaches based on neural network architectures have been proposed to generate colorful images. However, most of the suggested colorization frameworks use a single model for colorization regardless of the diversity of colors in images of various datasets. We claim that since such a structure is responsible for generating all types of images, it results in producing either faint-colored images or some artifacts in the images. We addressed this issue by proposing parallel colorization models, each of which is customized for generating images with similar contexts or color themes. Our proposed architecture consists of two stages as follows. The first stage includes a single colorization network that generates an initial colored image and simultaneously selects one of the specialist networks of the second stage for each image. The second stage consists of several specialist networks, whose tasks are improving the quality of the initial colored image and produce real-looking, plausible images. Our goal is to assign images to specialist networks in a way that each one of the specialist networks deals with contextually similar images so that the networks become more confident in generating vibrant colors and high-quality images. Cycle-Consistent Generative Adversarial Network structure is utilized in our architecture since it has demonstrated great potential in creating plausible images in the literature. The proposed model is evaluated on the ImageNet dataset, and the results stand for the effectiveness of employing context-aware specialists for colorization. (c) 2020ElsevierB.V. Allrightsreserved.																	0925-2312	1872-8286				SEP 24	2020	407						94	104		10.1016/j.neucom.2020.04.042													
J								An adversarial denoising convolutional neural network for fault diagnosis of rotating machinery under noisy environment and limited sample size case	NEUROCOMPUTING										Adversarial training; Denoising; Convolutional neural network; Rotating machinery; Fault diagnosis	WIND TURBINE; INTELLIGENT DIAGNOSIS; MODEL	The rapid development of deep learning raises a new research area for condition monitoring and fault diagnosis of mechanical equipment recently. However, the amount of labeled fault samples is limited in industrial field, also the samples are filled with complex environmental noise. Thus, a model with strong generalization and robustness is required. To tackle these challenges, an adversarial denoising convo-lutional neural network (ADCNN) is proposed in this paper. Moving maximum is firstly applied to the frequency spectrum of the vibration signal to enhance the anti-noise performance of the training sam-ples. Then the enhanced training samples are erased with dynamic probability to simulate noise inter-ference. Meanwhile, adversarial training is utilized to expand the labeled samples until Nash equilibrium is reached. These processes improve the robustness and generalization of ADCNN, and avoid over-fitting with limited amount of labeled samples. In our two experiments, when signal to noise ratio(SNR) is -12dB, the ADCNN achieves a diagnosis accuracy of 94.05% and 94.47%, respectively. Besides, ADCNN can maintain a high diagnosis accuracy under limited sample size case, and has the best adaptation perfor-mance across different load domains. The comparison studies with respect to other models demonstrate the applicability and superiority of ADCNN. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						105	120		10.1016/j.neucom.2020.04.074													
J								A Dual Recurrent Neural Network-based Hybrid Approach for Solving Convex Quadratic Bi-Level Programming Problem	NEUROCOMPUTING										Quadratic Bi-Level Programming Problem (BLPP); Recurrent Neural Networks (RNN); Genetic Algorithm (GA); Hybrid Strategy	GLOBAL OPTIMIZATION METHOD; BILEVEL; CONVERGENCE; ALGORITHMS; SYSTEMS	The current paper presents a neural network-based hybrid strategy that combines a Genetic Algorithm (GA) and a Dual Recurrent Neural Network (DRNN) for efficiently and accurately solving the quadratic -Bi-level Programming Problem (BLPP). In this model, the GA is used to handle the upper-level decision problem by choosing desirable solution candidates and passing them to the lower-level problem. Sub-sequently, in the lower-level, the parameterized-DRNN is used to determine possible optimal solutions. This combination offers several benefits such as being a parallel computing structure, the RNN offers faster convergence to the optimum for the lower-level decision problem and it also helps to quickly and accurately determining the global optimal. Moreover, the GA can quickly reach the global optima and can search without becoming stuck to the local optimal. Additionally, by choosing desirable initialization of parameters, the proposed algorithm reaches the optimum with higher accuracy. Apart from that, there are still a few utilizations of hybrid NN-based methods for solving BLPPs. Hence, we believe the proposed algorithm will contribute to solving quadratic-BLPPs involved in various engineering, management, and finance applications. The accuracy and efficiency of the proposed method have been found better than the existing and widely used approaches, while doing experimental verification using four well-known examples used in prior works. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						136	154		10.1016/j.neucom.2020.04.013													
J								Distributed initialization-free algorithms for multi-agent optimization problems with coupled inequality constraints	NEUROCOMPUTING										Distributed algorithm; Multi-agent optimization; Nonsmooth function; Coupled inequality constraint; Projection operator	RESOURCE-ALLOCATION; ECONOMIC-DISPATCH; GRADIENT ALGORITHM; NONSMOOTH ANALYSIS; TIME ALGORITHM; NETWORK; COORDINATION; CONVERGENCE; SYSTEMS; SET	This paper studies a resource optimization problem for a multi-agent network where all agents have local objective functions and local constraint sets. Meanwhile, the decision variables of all the agents need to satisfy a set of globally coupled inequality constraints. Then, a distributed continuous-time algorithm is designed with the help of the nonsmooth analysis theory and projection operator method. The proposed algorithm does not require each agent to send the gradient information of the cost function to its neighbors, which prevents the gradient information of agents leaking out. Moreover, the convergence analysis shows that the proposed algorithm can converge to the optimal solution starting from any initial allocation. Finally, a case study is presented for a resource allocation problem of a hybrid water-power network. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						155	162		10.1016/j.neucom.2020.05.006													
J								Dictionary learning with low mutual coherence constraint	NEUROCOMPUTING										Sparse approximation; Dictionary learning; Mutual coherence; Proximal mapping; Penalty method	INCOHERENT DICTIONARIES; FRAMES; CONVERGENCE; PROJECTIONS; ALGORITHMS; NONCONVEX	This paper presents efficient algorithms for learning low-coherence dictionaries. First, a new algorithm based on proximal methods is proposed to solve the dictionary learning (DL) problem regularized with the mutual coherence of dictionary. This is unlike the previous approaches that solve a regularized prob-lem where an approximate incoherence promoting term, instead of the mutual coherence, is used to encourage low-coherency. Then, a new solver is proposed for constrained low-coherence DL problem, i.e., a DL problem with an explicit constraint on the mutual coherence of the dictionary. As opposed to current methods, which follow a suboptimal two-step approach, the new algorithm directly solves the associated DL problem. Using previous studies, convergence of the new schemes to critical points of the associated cost functions is also provided. Furthermore, it is shown that the proposed algorithms have lower iteration complexity than existing algorithms. Our simulation results on learning low-coherence dictionaries for natural image patches as well as image classification based on discriminative over -complete dictionary learning demonstrate the superiority of the proposed algorithms compared with the state-of-the-art method. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 24	2020	407						163	174		10.1016/j.neucom.2020.04.135													
J								A bi-objective supplier location, supplier selection and order allocation problem with green constraints: scenario-based approach	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Supplier location; Supplier selection; Order allocation; Scenario-based approach; Green supply chain	FACILITY LOCATION; CHAIN NETWORK; ROBUST OPTIMIZATION; PROGRAMMING-MODEL; INVENTORY PROBLEM; CONFIGURATION; METHODOLOGY; PROCUREMENT; ALGORITHM; DESIGN	In this study, There is a mixed-integer nonlinear program (MINLP) for a two-echelon supply chain that focuses on supplier location, supplier selection and order allocation with green constraints. This bi-objective model is designed and modeled with the aim of coordinating inventory and transportation among suppliers and warehouses and tries to simultaneously meet the targets of minimizing total costs and carbon dioxide emissions of polluting gas in transportation. Since some of the important parameters in this model are considered uncertain, the scenario-based analysis is proposed to deal with uncertainty. Thirty numerical examples with different values and various sizes are solved by applying two methods of MODM, LP metrics, and Multi-choice goal programming with utility functions (MCGP-U) and their results are compared with one of the soft computing methods, Genetic algorithm. TOPSIS, Coefficient of Variation (CV) and One-way analysis of variance (ANOVA) methods are employed for the comprehensive comparison of these numerical examples. Finally, the sensitivity analysis method and Tornado diagram are applied to analyze the effect of variations of the model's inputs on the results of the model.																	1868-5137	1868-5145															10.1007/s12652-020-02555-1		SEP 2020											
J								A comparative study of social group optimization with a few recent optimization algorithms	COMPLEX & INTELLIGENT SYSTEMS										Meta-heuristic; Benchmark functions; Optimization algorithms; Fitness evaluations	SALP SWARM ALGORITHM; META-HEURISTIC OPTIMIZATION; MANY-OBJECTIVE OPTIMIZATION; FEATURE-SELECTION; INSPIRED ALGORITHM; SEARCH ALGORITHM; EVOLUTION; DYNAMICS	From the past few decades, the popularity of meta-heuristic optimization algorithms is growing compared to deterministic search optimization algorithms in solving global optimization problems. This has led to the development of several optimization algorithms to solve complex optimization problems. But none of the algorithms can solve all optimization problems equally well. As a result, the researchers focus on either improving exiting meta-heuristic optimization algorithms or introducing new algorithms. The social group optimization (SGO) Algorithm is a meta-heuristic optimization algorithm that was proposed in the year 2016 for solving global optimization problems. In the literature, SGO is shown to perform well as compared to other optimization algorithms. This paper attempts to compare the performance of the SGO algorithm with other optimization algorithms proposed between 2017 and 2019. These algorithms are tested through several experiments, including multiple classical benchmark functions, CEC special session functions, and six classical engineering problems etc. Optimization results prove that the SGO algorithm is extremely competitive as compared to other algorithms.																	2199-4536	2198-6053															10.1007/s40747-020-00189-6		SEP 2020											
J								Fast greedy C-bound minimization with guarantees	MACHINE LEARNING										PAC-Bayes; Boosting; Ensemble methods; C-bound; Greedy optimization		The C-bound is a tight bound on the true risk of a majority vote classifier that relies on the individual quality and pairwise disagreement of the voters and provides PAC-Bayesian generalization guarantees. Based on this bound, MinCq is a classification algorithm that returns a dense distribution on a finite set of voters by minimizing it. Introduced later and inspired by boosting, CqBoost uses a column generation approach to build a sparse C-bound optimal distribution on a possibly infinite set of voters. However, both approaches have a high computational learning time because they minimize the C-bound by solving a quadratic program. Yet, one advantage of CqBoost is its experimental ability to provide sparse solutions. In this work, we address the problem of accelerating the C-bound minimization process while keeping the sparsity of the solution and without losing accuracy. We present CB-Boost, a computationally efficient classification algorithm relying on a greedy-boosting-based-C-bound optimization. An in-depth analysis proves the optimality of the greedy minimization process and quantifies the decrease of the C-bound operated by the algorithm. Generalization guarantees are then drawn based on already existing PAC-Bayesian theorems. In addition, we experimentally evaluate the relevance of CB-Boost in terms of the three main properties we expect about it: accuracy, sparsity, and computational efficiency compared to MinCq, CqBoost, Adaboost and other ensemble methods. As observed in these experiments, CB-Boost not only achieves results comparable to the state of the art, but also provides C-bound sub-optimal weights with very few computational demand while keeping the sparsity property of CqBoost.																	0885-6125	1573-0565				SEP	2020	109	9-10			SI		1945	1986		10.1007/s10994-020-05902-7		SEP 2020											
J								Risk evaluation in failure modes and effects analysis: hybrid TOPSIS and ELECTRE I solutions with Pythagorean fuzzy information	NEURAL COMPUTING & APPLICATIONS										Pythagorean fuzzy sets; FMEA; Modified operators; Hybrid TOPSIS approach; Hybrid ELECTRE I approach; Implementations; Discussions and comparative analysis	GROUP DECISION-MAKING; MEMBERSHIP GRADES; OWA; METHODOLOGY	This article proposes two novel modified techniques, namely Pythagorean fuzzy hybrid Order of Preference by Similarity to an Ideal Solution (PFH-TOPSIS) method and Pythagorean fuzzy hybrid ELimination and Choice Translating REality I (PFH-ELECTRE I) method, in order to measure risk rankings in failure modes and effects analysis (FMEA). These methods are designed to overcome the flaws and shortcomings of traditional crisp risk priority numbers and fuzzy FMEA techniques in risk rankings. The proposed methods consider subjective as well as objective weight values of all factors in risk rankings of identified failures. The FMEA experts team are allowed to submit their information by linguistic terms using Pythagorean fuzzy numbers. Both techniques use a Pythagorean fuzzy weighted averaging operator to aggregate their independent evaluations into group assessments. Subsequent steps are different. The PFH-TOPSIS approach computes the distances of failure modes from the Pythagorean fuzzy positive ideal solution and Pythagorean fuzzy negative ideal solution. To evaluate failure modes, the PFH-ELECTRE I approach produces Pythagorean fuzzy concordance and Pythagorean fuzzy discordance matrices. We illustrate the structure of both techniques with the help of flowcharts. The effectiveness of the methods that we develop is described by a numerical example, namely a case study of 1.8-in. color super-twisted nematic (CSTN). To validate their effectiveness and accuracy, we provide a comprehensive comparative analysis with existing techniques of risk evaluation, including intuitionistic fuzzy hybrid TOPSIS, intuitionistic fuzzy TOPSIS, IWF-TOPSIS, and fuzzy TOPSIS methods.																	0941-0643	1433-3058															10.1007/s00521-020-05350-3		SEP 2020											
J								AutoRWN: automatic construction and training of random weight networks using competitive swarm of agents	NEURAL COMPUTING & APPLICATIONS										Classification; Random weight networks; Activation functions; Competitive swarm optimizer	EXTREME LEARNING-MACHINE; NEURAL-NETWORKS; OPTIMIZATION; PARAMETERS; REGRESSION; ALGORITHM; FEATURES	Random Weight Networks have been extensively used in many applications in the last decade because it has many strong features such as fast learning and good generalization performance. Most of the traditional training techniques for Random Weight Networks randomly select the connection weights and hidden biases and thus suffer from local optima stagnation and degraded convergence. The literature shows that stochastic population-based optimization techniques are well regarded and reliable alternative for Random Weight Networks optimization because of high local optima avoidance and flexibility. In addition, many practitioners and non-expert users find it difficult to set the other parameters of the network like the number of hidden neurons, the activation function, and the regularization factor. In this paper, an approach for training Random Weight Networks is proposed based on a recent variant of particle swarm optimization called competitive swarm optimization. Unlike most of Random Weight Networks training techniques, which are used to optimize only the input weights and hidden biases, the proposed approach will automatically tune the weights, biases, the number of hidden neurons, and regularization factor as well as the embedded activation function in the network, simultaneously. The goal is to help users to effectively identify a proper structure and hyperparameter values to their applications while obtaining reasonable prediction results. Twenty benchmark classification datasets are used to compare the proposed approach with different types of basic and hybrid Random Weight Network-based models. The experimental results on the benchmark datasets show that the reasonable classification results can be obtained by automatically tuning the hyperparameters using the proposed approach.																	0941-0643	1433-3058															10.1007/s00521-020-05329-0		SEP 2020											
J								A Robust Least Squares Support Vector Machine Based on L-infinity-norm	NEURAL PROCESSING LETTERS										LSSVMs; Structural risk; Empirical risk; L-infinity-norm; L-2-norm		A family of norm-based least squares support vector machines (LSSVMs) is the effective statistical learning tool and has attracted considerable attentions. However, there are two critical problems: (1) LSSVM is ill-conditioned or singular when the sample size is much less than feature number and thus causes over-fitting for small sample size (SSS) problem, while other norm-based LSSVMs own slower training speed and cannot deal with large scale data. (2) Norm-based LSSVMs pay less attention to the edge points that are important for learning the final classifier. To overcome the above drawbacks, by replacing L-2-norm with L-infinity-norm in empirical loss, we construct a robust classifier, named L-infinity- LSSVM in short. After adjustment, L-infinity-LSSVM can detect edge points effectively and enhances the capability of the robustness and the generalization. Also, inspired by the idea of sequential minimal optimization (SMO), we design a novel SMO-typed iterative algorithm. The new algorithm not only guarantees the convergence of optimum solution in theory, but also owns the lower computational time and storage space when data size is large. Finally, extensive numerical experiments validate the above opinions again on four groups of artificial data, Non-i.i.d data: fault detection of railway turnout, four SSS datasets, two types of massive datasets and six benchmark datasets.																	1370-4621	1573-773X															10.1007/s11063-020-10353-1		SEP 2020											
J								Memo Akten's Learning to See: from machine vision to the machinic unconscious	AI & SOCIETY										Machine vision; Machine bias; Bernard Stiegler; Algorithmic art; Black box		This article uses Memo Akten's art installationLearning to See(Akten,2017) to challenge the belief that machine learning and machine vision are neutral and objective technologies. Furthermore, this article follows Bernard Stiegler to contend that not only machine vision but also human vision is the result of constant training processes that rely directly on technology (understood as a technical surface of inscription). From this perspective, human vision is always already technical. Likewise, in an age dominated growingly by machine learning technologies, it is possible to speak not only of machine vision but also of a machinic imagination and a machinic unconscious, two notions that can be illustrated through Akten's art installation.																	0951-5666	1435-5655															10.1007/s00146-020-01071-2		SEP 2020											
J								Multiple Attribute Decision Making Based on Power Muirhead Mean Operators Under 2-Tuple Linguistic Pythagorean Fuzzy Environment	COGNITIVE COMPUTATION										Multiple attribute decision making (MADM); Pythagorean fuzzy numbers; Two-tuple linguistic Pythagorean fuzzy set (2TLPFSs); 2TLPFPMM operator; 2TLPFPDMM operator; Green supplier selection	AGGREGATION OPERATORS; REPRESENTATION MODEL; PROGRAMMING METHOD; TODIM METHOD; SETS	Due to the uncertainty and complexity of socioeconomic environments and cognitive diversity of decision makers, the cognitive information over alternatives provided by decision makers is usually uncertain and fuzzy. Two-tuple linguistic Pythagorean fuzzy sets (2TLPFSs) provide useful tools to depict the uncertain and fuzzy cognitions of the decision makers over attributes. To effectively handle such common cases, in this paper, some power Muirhead mean (PMM) operator and power dual MM (PDMM) operator operators under 2TLPFS environment are proposed and investigated the methods for multiple attribute decision making(MADM) problems based on the PMM and PDMM operators with 2-tuple linguistic Pythagorean fuzzy numbers (2TLPFNs) are investigated. Firstly, some new PMM and PDMM operators to aggregate 2-tuple linguistic Pythagorean fuzzy cognitive information is developed, such as 2-tuple linguistic Pythagorean fuzzy MM (2TLPFPMM) operator, 2-tuple linguistic Pythagorean fuzzy weighted PMM (2TLPFWPMM) operator, 2-tuple linguistic Pythagorean fuzzy PDMM (2TLPFPDMM) operator, and 2-tuple linguistic Pythagorean fuzzy weighted PDMM (2TLPFNWPDMM) operator, which consider the interrelationship of 2TLPFNs, and can generate more accurate results than the existing aggregation operators. After that, the developed aggregation operator are applied to MADM with 2TLPFNs and two MADM methods are designed, which can be applied to different decision making situations. Based on the proposed operators and built models, two methods are developed to solve the MADM problems with 2TLPFNs and the validity and advantages of the proposed method are analyzed by comparison with some existing approaches. The method proposed in this paper can effectively handle the MADM problems in which the attribute information is expressed by 2TLPFNs, the attributes' weights are completely known, and the attributes are interactive. Finally, an example for green supplier selection is used to show the proposed methods.																	1866-9956	1866-9964															10.1007/s12559-020-09756-y		SEP 2020											
J								Optimal sizing and placement of multiple renewable distribution generation andDSTATCOMin radial distribution systems using hybrid lightning search algorithm-simplex method optimization algorithm	COMPUTATIONAL INTELLIGENCE										hybrid lightning search algorithm-simplex method; loss sensitivity factor; power loss minimization; voltage stability index	PARTICLE SWARM OPTIMIZATION; OPTIMAL LOCATION; RECONFIGURATION; ALLOCATION; DSTATCOM	In this literature, the simultaneous placement of both the Renewable Distribution Generation (DG) and Distribution STATCOM (DSTATCOM) in the Radial Distribution System (RDS) for Power Loss Minimization (PLM) is discussed. Loss Sensitivity Factor (LSF) is initially applied to discover the candidate location of DG and DSTATCOM in RDS. The effective Hybrid Lightning Search Algorithm-Simplex Method (LSA-SM) is used to compute the optimal sizing of DG and D-STATCOM. The performance of the proposed method is tested separately on both IEEE33 and IEEE69 RDS test systems. The improvement in system Voltage Profile and operational stability before and after the allocation of DG and DSTATCOM is discussed. The improved system Voltage Stability Index values for different cases are plotted. The performance of the proposed method is compared with similar existing methods.																	0824-7935	1467-8640															10.1111/coin.12402		SEP 2020											
J								Cross lingual speech emotion recognition via triple attentive asymmetric convolutional neural network	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										center loss; cross-lingual; domain adaptation; speech emotion recognition; triple attentive asymmetric	DOMAIN ADAPTATION; FEATURES	The application of cross-corpus for speech emotion recognition (SER) via domain adaptation methods have gain high acknowledgment for developing good robust emotion recognition systems using different corpora or datasets. However, the issue of cross-lingual still remains a challenge in SER and needs more attention to resolve the scenario of applying different language types in both training and testing. In this paper, we propose a triple attentive asymmetric convolutional neural network to address the recognition of emotions for cross-lingual and cross-corpus speech in an unsupervised approach. The proposed method adopts the joint supervision of softmax loss and center loss to learn high power discriminative feature representations for target domain via the use of high quality pseudo-labels. The proposed model uses three attentive convolutional neural networks asymmetrically, where two of the networks are used to artificially label unlabeled target samples as a result of their predictions from training on source labeled samples and the other network is used to obtain salient target discriminative features from the pseudo-labeled target samples. We evaluate our proposed method on three different language types (i.e., English, German, and Italian) data sets. The experimental results indicate that, our proposed method achieves higher prediction accuracy over other state-of-the-art methods.																	0884-8173	1098-111X															10.1002/int.22291		SEP 2020											
J								Combining Boundary Detector and SND-SVM for Fast Learning	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										SND-SVM; Critical samples; Boundary detection; Subset selection	SUPPORT; SAMPLES; POINT	As a state-of-the-art multi-class supervised novelty detection method, supervised novelty detection-support vector machine (SND-SVM) is extended from one-class support vector machine (OC-SVM). It still requires to slove a more time-consuming quadratic programming (QP) whose scale is the number of training samples multiplied by the number of normal classes. In order to speed up SND-SVM learning, we propose a down sampling framework for SND-SVM. First, the learning result of SND-SVM is only decided by minor samples that have non-zero Lagrange multipliers. We point out that the potential samples with non-zero Lagrange multipliers are located in the boundary regions of each class. Second, the samples located in boundary regions can be found by a boundary detector. Therefore, any boundary detector can be incorporated into the proposed down sampling framework for SND-SVM. In this paper, we use a classical boundary detector, local outlier factor (LOF), to illustrate the effective of our down sampling framework for SND-SVM. The experiments, conducted on several benchmark datasets and synthetic datasets, show that it becomes much faster to train SND-SVM after down sampling.																	1868-8071	1868-808X															10.1007/s13042-020-01196-2		SEP 2020											
J								Nonnegative representation based discriminant projection for face recognition	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Discriminant projection; Face recognition; Nonnegative representation; Unsupervised dimensionality reduction	REGRESSION-BASED PROJECTIONS; PRESERVING PROJECTIONS; ILLUMINATION	Dimensionality reduction (DR) has been widely used to deal with high-dimensional data, and plays an important role in alleviating the so-called "curse of dimensionality". In this paper, we propose a novel unsupervised DR method with applications to face recognition, i.e., Nonnegative Representation based Discriminant Projection (NRDP). Different with other locality or globality preserving DR methods, NRDP focuses on both locality and nonlocality of data points and learns a discriminant projection by maximizing the nonlocal scatter and minimizing the local scatter simultaneously. A nonnegative representation model is designed in NRDP to discover the local structure and nonlocal structure of data. Thel l(1)-norm is used as metric in nonnegative representation to enhance the robustness against noises, and an iterative algorithm is presented to solve the optimization model. NRDP is able to learn features with large inter-class or subspace scatter and small intra-class scatter in the case that label information is unavailable, which significantly improves the representation power and discrimination. Experimental results on several popular face datasets demonstrate the effectiveness of our proposed method.																	1868-8071	1868-808X															10.1007/s13042-020-01199-z		SEP 2020											
J								A scalable semantic data fusion framework for heterogeneous sensors data	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Data fusion; Semantic conflicts; IoT; Scalability; Measurement units; Heterogeneous sensors data	INTERNET; WEB; THINGS; INFORMATION; MANAGEMENT; PLATFORM	Data fusion is a fundamental research topic especially in the Internet of Things (IoT). A massive quantity of data is increasingly being generated by heterogeneous sensors which make data integration more difficult. A noticeable body of research has attempted to mitigate the incompatibility between the collected data to facilitate meaningful data integration between machines by using the semantic web technologies. However, there are still some critical issues including scalability and measurement unit conflicts. Therefore, this paper proposes a scalable semantic data fusion framework that aims at improving the scalability of data fusion and detecting and reconciling measurement unit conflicts. This framework is fully implemented to demonstrate its scalability during the process of data fusion, and its ability to handle measurement unit conflicts. Two experiments were conducted to evaluate the scalability and effectiveness of the proposed framework using real dataset that was collected from different sensors. To evaluate the scalability of the proposed framework, a set of queries was adapted and the average response time was calculated from the execution of every query. Whereas, the total number of the conflicts detected and resolved by the proposed framework were used to evaluate the effectiveness. Experimental results show that the proposed framework improves the scalability of data fusion among heterogeneous sensors' data, and effective in detecting and resolving data unit conflicts.																	1868-5137	1868-5145															10.1007/s12652-020-02527-5		SEP 2020											
J								Adapting smartwatch interfaces to hand gestures during movements: offset models and the C-shaped pattern of tapping	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Smartwatch; Movement; Gait; Tapping; Target size	FINGERTIP; WALKING; DEVICES; MOTION	Interacting with smartwatches is fairly common when users are moving. Although novel interaction gestures like flick of the wrist are implemented, basic touch gestures such as tapping and swiping still dominate. Using these gestures during a variety of movements could be challenging, and it is still not clear how the interface of smartwatches should tailor to users' gestures during movements and how the usage of smartwatches influences the pattern of users' movements. Therefore, this study investigates the interrelationship among users' interaction gestures, movements, and gait features. An experiment was conducted among 47 participants, who used smartwatches through tapping, swiping, and wrist flicking to complete daily tasks in stand, strolling, normal walking, rushing, and jogging. They were tracked through built-in accelerometer and angle sensors. Four findings were derived from the experiment. First, rushing and jogging significantly decrease the effectiveness and efficiency of tapping. To reduce the tapping deviation, offset models were proposed and tested. Second, there is a C-shaped pattern on the round screen where tapping targets achieves higher accuracy than other areas. Third, the tapping performance could be improved by setting target sizes. Target sizes at 0.7 cm in stand, 1.1 cm in strolling, and 1.1 cm in walking achieve a high level of accuracy (95%), while target sizes at 1.5 cm in rushing and jogging achieve a middle level of accuracy (90%). Finally, tapping, swiping, and wrist flicking when users are moving significantly reduce their gait symmetry and step length. They do not imply significant influence on gait intensity, regularity, and overall stability.																	1868-5137	1868-5145															10.1007/s12652-020-02545-3		SEP 2020											
J								A machine learning approach for performance-oriented decision support in service-oriented architectures	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Web service; Service related knowledge; Service ontology; Quality of service; Service reuse; Data mining; Inference rules	MODEL; QOS; SOA	Enterprise IT performance can be improved by providing reactive and predictive monitoring tools that anticipate problem detection. It requires advanced approaches for creating more agile, adaptable, sustainable and intelligent information systems. Service-oriented architecture (SOA) has been used in significant performance-based approaches by information system practitioners. Organizations are interested in performance-based decision support along the layers of SOA to maintain their sustainability for service reuse. Reusability is a very important aspect of Service-based systems (SBS) to analyze service or process reuse. This helps in achieving business agility to meet changing marketplace needs. However currently, there are many challenges pertaining tothe complexities of service reuse evolution along SBS. These challenges are related to the sustainability of service behavior during its lifecycle and the limitations of existing monitoring tools. There is a need for a consolidated classified knowledge-based performance profile, analytical assessment, prediction and recommendation. Therefore, this paper provides a semantic performance-oriented decision support system (SPODSS) for SOA. SPODSS provides recommendations for suggesting service reuse during its evolution. SPODSS is supported by five building blocks. These blocks are data, semantic, traces, machine learning, and decision. SPODSS classify data, validate (analytical assessment, traces, semantic enrichment) at different time intervals and increased consumption and prediction based on consolidated results. It handles the dynamic evolution of SBS and new or changed user requirements by ontology development. Finally, SPODSS generates recommendations for atomic service, composite service, and resourceallocation provisioning. To motivate this approach, we illustrate the implementation of the proposed algorithms for all the five blocks by a business process use case and public data set repositories of shared services. Sustainability and adaptability of service-based systems areensured by handling new business requirements, dynamicity issues and ensuring performance. Performance criterion includes functional suitability, time behavior, resource utilization, and reliability in terms of availability, maturity, and risk.																	0925-9902	1573-7675															10.1007/s10844-020-00617-6		SEP 2020											
J								A prediction approach of SLM based on the ensemble of metamodels considering material efficiency, energy consumption, and tensile strength	JOURNAL OF INTELLIGENT MANUFACTURING										Powder utilization rate; Energy consumption; Tensile strength; Process parameters; Metamodel	PROCESSING PARAMETERS; MECHANICAL-PROPERTIES; OPTIMIZATION; DEPOSITION; POROSITY	As a rapid developing additive manufacturing (AM) technology, selective laser melting (SLM) provides a promising way for intelligent manufacturing. The SLM part quality depends largely on the process parameters in the manufacturing process. Therefore, understanding the relationships between the input process parameters and the output part performances is critical to improve the part quality. In this work, the ensemble of metamodels (EM) is adopted and an adaptive hybrid leave-one-out error-based EM (EM-AHL) is developed to predict the powder utilization rate, the energy consumption, and the tensile strength of the as-built parts. First, the Taguchi experiment design is applied to obtain the sample points and the corresponding SLM experiments are conducted to get the experimental results. Second, the correlations between the process parameters (i.e., laser power, layer thickness, scanning speed) and the three responses are fitted using the proposed EM-AHL, which is constructed by aggregating three metamodels, Kriging, Radial basis fuction (RBF), and Support vector regression (SVR), according to the local measures. Finally, K-fold cross-validation and additional experiments validation methods are adopted to evaluate the prediction accuracy of the proposed EM-AHL. Results illustrate that the proposed EM-AHL not only outperforms the stand-alone metamodels but also provides more accurate results than the EM constructed by global measures (EM-G). Among the three prediction objectives, the prediction accuracy of the proposed EM-AHL has improved by up to 20% compared to the stand-alone metamodels. Besides, the main effects and contribution rates of process parameters on the responses are analyzed. Overall, the proposed EM-AHL method exhibits the excellent capability of guiding the actual SLM manufacturing.																	0956-5515	1572-8145															10.1007/s10845-020-01665-z		SEP 2020											
J								On-line prediction of ultrasonic elliptical vibration cutting surface roughness of tungsten heavy alloy based on deep learning	JOURNAL OF INTELLIGENT MANUFACTURING										Tungsten heavy alloy; Ultrasonic elliptical vibration cutting; Surface roughness; Deep learning; Vibration signal	INTELLIGENT FAULT-DIAGNOSIS; NEURAL-NETWORKS; MODEL	The surface quality of tungsten heavy alloy parts has an important influence on its service performance. The accurate on-line prediction of surface roughness in ultra-precision cutting of tungsten heavy alloy has always been the difficulty of research. In this paper, the ultrasonic elliptical vibration cutting technology is used for ultra-precision machining of tungsten heavy alloy. Based on the idea of deep learning, the surface roughness is discretized, and the fitting problem in surface roughness is transformed into a classification problem. The generalization ability of the prediction model is improved by introducing batch standardization and Dropout. The relationship between the vibration signal and the surface roughness is established. Experimental results show that the model can achieve on-line prediction of cutting surface roughness. The prediction accuracy rate can be improved by more than 10% compared with the direct fitting method.																	0956-5515	1572-8145															10.1007/s10845-020-01669-9		SEP 2020											
J								Model Reference Adaptive Control of Switched Dynamical Systems with Applications to Aerial Robotics	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Model reference adaptive control; Switched dynamical systems; Caratheodory solutions; Filippov solutions; Aerial robots	SET-POINT CONTROLLERS; SUPERVISORY CONTROL; STABILIZATION; FAMILIES; FEEDBACK	This paper presents an adaptive control law for unknown nonlinear switched plants that must follow the trajectory of user-defined linear switched reference models. The effectiveness of the proposed control architecture is proven in two alternative frameworks, that is, analyzing Caratheodory and Filippov solutions of discontinuous differential equations. Numerical and experimental data verify the applicability of the theoretical results to problems of practical interest. The proposed numerical simulation involves the design of a model reference adaptive control law to regulate the roll dynamics of a reconfigurable delta-wing aircraft. The proposed flight tests involve an aerial robot tasked with autonomously mounting a camera of unknown inertial properties to a vertical surface.																	0921-0296	1573-0409															10.1007/s10846-020-01260-7		SEP 2020											
J								A fuzzy production inventory control model using granular differentiability approach	SOFT COMPUTING										Production inventory control model; Fuzzy exponential demand function; Fuzzy product innovation; Nonlinear fuzzy dynamical system; Granular differentiability	HORIZONTAL MEMBERSHIP FUNCTION; DYNAMICAL-SYSTEMS; EQUATIONS; TIME	In this paper, we have created a single-period fuzzy production inventory control model on the finite time horizon. A new nonlinear demand function has been introduced, which depends on the stock, selling price and product quality. The realistic reasons come from logistical function and entry into the initial demand for the product and the reliance on uncertain advertising rates, uncertain stock rates, uncertain selling prices and uncertain product quality. In order to control and test the stability, the model needs to be defuzzified. The concept of granular differentiability has been applied to defuzzification. Granular differentiability is the new definition of fuzzy derivatives based on the function of horizontal membership. For the first time in this paper, we have used the granular differentiation method in production inventory systems. We analyzed vaguely optimized controls in terms of granular differentiation analytically and numerically.																	1432-7643	1433-7479															10.1007/s00500-020-05329-1		SEP 2020											
J								Short-term photovoltaic power generation predicting by input/output structure of weather forecast using deep learning	SOFT COMPUTING										Photovoltaic; Meteorological factors; Power generation predicting; Artificial neural network; Adaptive neuro-fuzzy inference system		In Korea, weather forecasts for fundamental weather factors, such as temperature, precipitation, wind direction and speed, humidity, and cloudiness, are provided for a three-day period in each region. This can facilitate predicting photovoltaic power generation based on weather forecasting. For this purpose, in the present paper, we aim to propose corresponding model. However, the Korea Meteorological Administration does not forecast the amount of solar radiation and sunshine that mostly influence the results of photovoltaic power generation prediction. In this study, we predict these parameters considering various input/output (I/O) variables and learning algorithms applied to weather forecasts on hourly weather data. Finally, we predict photovoltaic power generation based on the best sunshine and solar radiation prediction results. The data structure underlying all predictions relies on four models applied to fundamental weather factors on sunshine and solar radiation data two hours ago. Then, the photovoltaic power generation prediction is implemented using four models depending on whether to add the predicted sunshine and solar radiation data obtained at the previous step. The prediction algorithm relies on an adaptive neuro-fuzzy inference system and artificial neural network (ANN) techniques, including dynamic neural network (DNN), recurrent neural network (RNN), and long short-term memory (LSTM). The results of the conducted experiment indicate that ANN perform better than the neuro-fuzzy approach. Moreover, we demonstrate that RNN and LSTM are more suitable for the time series data structures compared with DNN. Furthermore, we report that the weather forecast structure and the model 4 structure, which includes sunshine and solar radiation data two hours ago, achieve the best prediction results.																	1432-7643	1433-7479															10.1007/s00500-020-05199-7		SEP 2020											
J								Predicting Calorific Value of Thar Lignite Deposit: A Comparison between Back-propagation Neural Networks (BPNN), Gradient Boosting Trees (GBT), and Multiple Linear Regression (MLR)	APPLIED ARTIFICIAL INTELLIGENCE											HIGHER HEATING VALUE; RANDOM FOREST; VALUE GCV; MODELS; COALS	Calorific value provides a strong measure of useful energy during coal utilization. Previously, different AI techniques have been used for the prediction of calorific value; however, one model is not valid for all geographic locations. In this research, Lower Calorific Value (LCV) of the Thar coal region in Pakistan is predicted from proximate analysis of 693 drill holes extending to 9,000 sq. km. Researchers have applied different techniques to produce the best model for prediction of calorific value; however, Gradient Boosting Trees (GBT) has not been used for this purpose. A comparison of GBT, Back-propagation Neural Networks (BPNN), and Multiple Linear Regression (MLR) is presented to predict the calorific value from a total of 8,039 samples with 1 m support interval. The samples were split randomly into 70:15:15 for training, testing, and validation of GBT, BPNN, and MLR models, reporting correlations of 0.90, 0.89, and 0.80, respectively. The features' importance was reported by the intuitive and best-performing GBT model in decreasing order of importance as: Volatile Matter, Fixed Carbon, Moisture, and Ash with corresponding feature importance values of 0.50, 0.30, 0.12, and 0.08.																	0883-9514	1087-6545															10.1080/08839514.2020.1824091		SEP 2020											
J								Simulation research on safety detection of pattern rope jumping motion based on large data background	CONNECTION SCIENCE										Tibial trabecula; aerobic metabolism; pattern skipping; rope jumping; joint morphology and structure	BIG DATA; ADOLESCENTS; RESPONSES; PROGRAM	With the continuous progress of society and the improvement of economic level, more and more people devote their spare time to physical exercise. With the development of the times, figure rope skipping is a new sport which integrates fitness, entertainment, competition and performance. Nowadays, figure rope skipping, as a new fashionable sport, has become a popular fitness sport. In order to give full play to the fitness function of figure rope skipping on the basis of full consideration of safety, a large-data joint prediction model was proposed based on inverse dynamics is proposed to explore the influence of rope skipping on joint position. Introducing the pattern skipping rope into the school physical education curriculum not only makes the students feel the sports side. At the same time, it can also develop the wisdom and potential of students, entertain the body and mind, and cultivate the spirit of unity and cooperation and disappointment. In the future physical education work, we should vigorously develop the national fitness cause, and make the pattern skipping movement become a campus special project to promote its development and promotion on campus.																	0954-0091	1360-0494															10.1080/09540091.2020.1820449		SEP 2020											
J								Designing our future bio-materiality	AI & SOCIETY										Biodesign; Biofabrication; Bio-materiality; Sustainability		A new road map for design is emerging out of interdisciplinary research across biology and design. Whilst in the second part of the twentieth century, the emergence of the digital realm altered and radically challenged conventional design and manufacturing processes, the beginning of the twenty-first century marks a strong shift towards the amalgamation of the binary code (1s and 0s) with biological systems. With advances in synthetic biology, we can now 'biofabricate' like Nature does. By tinkering and altering the DNA code or the environment of growth of living organisms, we can effectively 'design' and grow new biomaterials. The role of design is shifting from working with inanimate matter such as plastic and metals to making with animate living entities such as mycelium, yeast and bacteria. This paradigm shift promises to open up new possibilities for biofabricating future intelligent materials as well as for engaging with new sustainable processes. This paper examines strategies and tools for designing with living systems and proposes a framework for design to engage with our future bio-materiality. From biofabrication experiments to synthetic biology propositions, the paper will investigate a series of design artifacts that explores strategies such as co-designing with natural organisms or actuating a new synthetic nature and develop a critique of how biodesign can help shifting towards the crafting of a future sustainable intelligent bio-materiality.																	0951-5666	1435-5655															10.1007/s00146-020-01013-y		SEP 2020											
J								Cascaded deep learning classifiers for computer-aided diagnosis of COVID-19 and pneumonia diseases in X-ray scans	COMPLEX & INTELLIGENT SYSTEMS										Coronavirus outbreak; COVID-19; Biomedical image processing; Deep learning; Cascaded classifiers	PULMONARY NODULES; CHEST CT; CORONAVIRUS	Computer-aided diagnosis (CAD) systems are considered a powerful tool for physicians to support identification of the novel Coronavirus Disease 2019 (COVID-19) using medical imaging modalities. Therefore, this article proposes a new framework of cascaded deep learning classifiers to enhance the performance of these CAD systems for highly suspected COVID-19 and pneumonia diseases in X-ray images. Our proposed deep learning framework constitutes two major advancements as follows. First, complicated multi-label classification of X-ray images have been simplified using a series of binary classifiers for each tested case of the health status. That mimics the clinical situation to diagnose potential diseases for a patient. Second, the cascaded architecture of COVID-19 and pneumonia classifiers is flexible to use different fine-tuned deep learning models simultaneously, achieving the best performance of confirming infected cases. This study includes eleven pre-trained convolutional neural network models, such as Visual Geometry Group Network (VGG) and Residual Neural Network (ResNet). They have been successfully tested and evaluated on public X-ray image dataset for normal and three diseased cases. The results of proposed cascaded classifiers showed that VGG16, ResNet50V2, and Dense Neural Network (DenseNet169) models achieved the best detection accuracy of COVID-19, viral (Non-COVID-19) pneumonia, and bacterial pneumonia images, respectively. Furthermore, the performance of our cascaded deep learning classifiers is superior to other multi-label classification methods of COVID-19 and pneumonia diseases in previous studies. Therefore, the proposed deep learning framework presents a good option to be applied in the clinical routine to assist the diagnostic procedures of COVID-19 infection.																	2199-4536	2198-6053															10.1007/s40747-020-00199-4		SEP 2020											
J								Evaluation of cloud computing resource scheduling based on improved optimization algorithm	COMPLEX & INTELLIGENT SYSTEMS										Cloud computing; Improved particle swarm algorithm; CloudSim; Resource scheduling	PARTICLE SWARM OPTIMIZATION	Cloud computing, as a new computing mode in recent years, has been pursued by many users who have computational requirements, and the service quality of cloud computing depends largely on the efficiency of resource scheduling. In this study, an improved particle swarm optimization (IPSO) algorithm was proposed to improve the efficiency of resource scheduling, and simulation experiments were carried out on the IPSO algorithm and the traditional particle swarm optimization using CloudSim simulation platform. The phenomenon of premature appeared with the increase of the number of iterations, and the globally optimal solution was not found. The IPSO algorithm was more efficient in exploring the globally optimal solution, and the phenomenon of premature did not appear. As the number of tasks increased, the operation time of both algorithms increased, but the IPSO algorithm increased more slowly. The IPSO algorithm had more advantages when there were a large amount of tasks. Virtual machines in the two algorithms had different loads, and the load of the virtual machine in the IPSO algorithm was more balanced.																	2199-4536	2198-6053															10.1007/s40747-020-00163-2		SEP 2020											
J								FAB classification of acute leukemia using an ensemble of neural networks	EVOLUTIONARY INTELLIGENCE										Acute leukemia; Leukemia classification; Feature extraction; Ensemble neural network	ACUTE LYMPHOBLASTIC-LEUKEMIA; WATERSHED ALGORITHM; IMAGE SEGMENTATION; DIAGNOSIS; FRAMEWORK; SYSTEM; CELLS; PREDICTION; FEATURES; DISEASES	Acute leukemia is the most frequently occurring malignancy present in human blood and a kind of liquid cancer. This hematological disorder can impinge on bone marrow and lymphatic system. Accordingly, a computer-aided classification system is proposed for French-American-British classification of Acute Leukemia using an ensemble of neural networks which is validated on 180 microscopic blood images taken from online benchmark dataset. As per the requirement of pathologists in real-life examination scenario various objectives are formulated as (i) correct nucleus segmentation in blood cell image, (ii) correct classification of FAB classes of acute leukemia (L1, L2, L3, M2, M3, and M5). To accomplish these research objectives the proposed method consist of segmentation section, feature extraction section, feature pruning section and classification section. The classification of the proposed method consists of two subsections as subsection1 is comprised of single six class PCA based neural network as PCA-NN0 (L1/L2/L3/M2/M3/M5) and subsection 2 contains an ensemble of 15 binary PCA based neural network classifiers as PCA-NN1 (L1/L2), PCA-NN2(L1/L3), PCA-NN3(L1/M2), PCA-NN4(L1/M3), PCA-NN5(L1/M5), PCA-NN6(L2/L3), PCA-NN7(L2/M2), PCA-NN8(L2/M3), PCA-NN9(L2/M5), PCA-NN10(L3/M2), PCA-NN11(L3/M3), PCA-NN12(L3/M5), PCA-NN13(M2/M3), PCA-NN14(M2/M5), PCA-NN15(M3/M5). The achieved accuracy for experiment 1 is 86.4% using PCA-NN0. The output of two most plausible classes predicted by PCA-NN0 is passed to other binary PCA based neural network i.e. PCA-NN1 to PCA-NN15. After passing all the test images to subsection 2, the achieved accuracy is 94.2% from the exhaustive experiment 2. The outcome of the work verifies the capabilities of computer-aided classification system to substitute the conventional diagnostic systems.																	1864-5909	1864-5917															10.1007/s12065-020-00491-9		SEP 2020											
J								Hybridizing salp swarm algorithm with particle swarm optimization algorithm for recent optimization functions	EVOLUTIONARY INTELLIGENCE										Standard functions; Heuristic hybridization; Salp swarm algorithm; Particle swarm optimization algorithm; Exploration and exploitation	OPTIMAL POWER-FLOW; DIFFERENTIAL EVOLUTION; SEARCH; DESIGN; DISPATCH; BEHAVIOR; PSO	The salp swarm algorithm (SSA) has shown its fast search speed in several challenging problems. Research shows that not every nature-inspired approach is suitable for all applications and functions. Additionally, it does not provide the best exploration and exploitation for each function during the search process. Therefore, there were several researches attempts to improve the exploration and exploitation of the meta-heuristics by developing the newly hybrid approaches. This inspired our current research and therefore, we developed a newly hybrid approach called hybrid salp swarm algorithm with particle swarm optimization for searching the superior quality of optimal solutions of the standard and engineering functions. The hybrid variant integrates the advantages of SSA and PSO to eliminate many disadvantages such as the trapping in local optima and the unbalanced exploitation. We have used the velocity phase of the PSO approach in salp swarm approach in order to avoid the premature convergence of the optimal solutions in the search space, escape from ignoring in local minima and improve the exploitation tendencies. The new approach has been verified on different dimensions of the given functions. Additionally, the proposed technique has been compared with a wide range of algorithms in order to confirm its efficiency in solving standard CEC 2005, CEC 2017 test suits and engineering problems. The simulation results show that the proposed hybrid approach provides competitive, often superior results as compared to other existing algorithms in the research community.																	1864-5909	1864-5917															10.1007/s12065-020-00486-6		SEP 2020											
J								Observer-Based Adaptive Fuzzy Tracking Control for a Class of Strict-Feedback Systems with Event-Triggered Strategy and Tan-type Barrier Lyapunov Function	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Strict-feedback nonlinear systems; Fuzzy observer; Event-triggered control; Prescribed performance; Tan-type barrier Lyapunov function	NONLINEAR-SYSTEMS; CONTROL DESIGN	In this paper, an observer-based adaptive fuzzy tracking control is considered for a class of strict-feedback nonlinear systems. The nonlinear functions and unmeasured states in the system are estimated by means of fuzzy logic systems and fuzzy state observers, respectively. In addition, the tan-type barrier Lyapunov specifies that the tracking error is limited to a given area. An improved event-triggered technique is introduced in the controller design to save the network resources and avoid the Zeno-behavior. It is proven that the proposed controller can ensure that all the signals of the closed-loop system are uniformly and ultimately bounded. Finally, the simulation results verify the feasibility of the design scheme.																	1562-2479	2199-3211															10.1007/s40815-020-00948-0		SEP 2020											
J								Detecting and Recognizing Outliers in Datasets via Linguistic Information and Type-2 Fuzzy Logic	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Outliers in datasets; Detecting outliers; Recognizing outliers; Outliers defined via linguistic information; Type-2 linguistic quantification; Type-2 fuzzy logic	ACUTE MYOCARDIAL-INFARCTION; MEDICAL THERAPY; SUMMARIES; ALGORITHMS	Uncertainty appearing in datasets (stochastic, linguistic, of measurements, etc.), if not handled properly, may negatively affect information analysis or retrieval procedures. One of possible methods of dealing with uncertain (rare, strange, unexampled) data is to treat them as "outliers" or "exceptions". Among different definitions and algorithms for detecting outliers, we are especially interested in those based on linguistic information represented with type-2 fuzzy logic. We introduce new definitions of outliers in datasets in terms fuzzy properties and linguistically expressed quantities of objects possessing them. Next, new algorithms for detecting outlying objects are presented, to answer whether outliers appear in a dataset or not. Finally, recognition algorithms are presented and exemplified to enumerate particular objects being outliers (e.g., to eliminate them for further considerations). The novelty of this contribution is that we define, detect and recognize outliers using linguistic information represented mostly by type-2 fuzzy sets and logic (if any other information like measures or distances is not accessible), and we supersede this way some earlier approaches based on similar but relatively limited assumptions.																	1562-2479	2199-3211															10.1007/s40815-020-00919-5		SEP 2020											
J								Path-Following-Based Design for Guaranteed Cost Control of Polynomial Fuzzy Systems	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Guaranteed cost control; Hamilton-JacobiBellman inequality; Lower upper-bound estimation; Path-following-based design; Polynomial Lyapunov function; S-procedure; Sum-of-squares	LYAPUNOV-FUNCTIONS; STABILITY ANALYSIS; STABILIZATION CRITERION; NONLINEAR-SYSTEMS; SUM; OPTIMIZATION	This paper presents a path-following-based design for guaranteed cost control of a class of nonlinear systems represented by polynomial fuzzy systems. First, this paper proposes a polynomial Lyapunov function approach to guaranteed cost control for the feedback system consisting of a polynomial fuzzy system and a polynomial fuzzy controller. In particular, we introduce a new type of polynomial fuzzy controllers based on an approximate solution for the Hamilton-Jacobi-Bellman inequality. To design a guaranteed cost polynomial fuzzy controller effectively, a path-following-based design algorithm is newly developed by formulating as a sum-ofsquares (SOS) stabilization problem. Two new relaxations are provided by bringing a peculiar benefit of the SOS framework. One is an S-procedure relaxation for the considered outmost Lyapunov function level set that is contractively invariant set. The other is an S-procedure relaxation for design conditions obtained for polynomial membership functions redefined by variable replacements in considered ranges. Furthermore, this paper provides a practical and reasonable way for estimating lower upperbounds of a given performance function by increasing the order of a considered polynomial function. Finally, a complicated nonlinear system design example is employed to illustrate the validity of the proposed design algorithm and the lower upper-bound estimation.																	1562-2479	2199-3211															10.1007/s40815-020-00931-9		SEP 2020											
J								A novel binarization technique based on Whale Optimization Algorithm for better restoration of palm leaf manuscript	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Binarization; Palm leaf manuscript; Niblack; Sauvola; Adaptive thresholding; Whale Optimization Algorithm; Text retrieval; Image restoration		Palm leaf manuscript is a rich source of information pertaining to culture and heritage from the ancient period which is written on Palm leaves. They share surplus knowledge base in the field of art, medicine, culture, science, astronomy, astrology, crafts, literature, etc. Due to environmental effects and various other factors like handling, storage methods, etc. these manuscripts undergoes degradation. Hence for preservation of the information contained in the palm leaves, digitization of the manuscript is needed. The manuscript is either scanned or photographed for digitization and stored for preserving the content. For storage, enormous storage space is required and in addition, the degradation due to the noise should be removed for restoration of the text in the Palm leaf manuscript. Textual retrieval is done by using binarization method. Many binarization techniques such as Local threshold methods, Global thresholding, Otsu histogram thresholding, Adaptive thresholding techniques are available in the literature. Even then lots of challenges are present due to the degradation of the Palm-leaf manuscript. Swarm intelligence techniques are gaining importance in almost all domains for the optimization of parameters. In this present work, an attempt is made to use Whale Optimization Algorithm for optimization of Adaptive thresholding and the results are compared with the existing techniques. It proves the ascendance of the proposed technique over the prevailing techniques.																	1868-5137	1868-5145															10.1007/s12652-020-02546-2		SEP 2020											
J								Fuzzy Markovian modeling of machining system with imperfect coverage, spare provisioning and reboot	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Availability; Fault tolerance; Mean time to failure (MTTF); Imperfect coverage; Reboot; P-NLP	REPAIRABLE SYSTEM; SWITCHING FAILURE; GENERAL REPAIR; RELIABILITY; AVAILABILITY; POLICY; QUEUE; DELAY	Reliability prediction of fault-tolerant system (FTS) supported by a backup unit and operating in a fuzzy environment has been investigated by developing Markov models. The FTS is supported by redundancy, reboot provisioning, and a facility of a single server for repairing the failed components. The failures in the FTS are not covered successfully due to a lack of fault detection of the failed unit and recovered automatically by the reboot process. The parametric non-linear programming (P-NLP) method is used for the assessment of the reliability, availability, and maintainability (RAM) in a fuzzified environment. The failure and repair rates having the lack of exactness are fuzzified using fuzzy triangular numbers. The alpha-cut is used to analyze the fuzzy Markov model. P-NLP approach is proposed in order to facilitate the required defuzzified system performance indices. The performance indices obtained analytically are examined by computing numerical results.																	1868-5137	1868-5145															10.1007/s12652-020-02523-9		SEP 2020											
J								Modified interval EDAS approach for the multi-criteria ranking problem in banking sector of Iran	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Banks ranking problem; Multi-criteria optimization; EDAS approach; Interval number	PERFORMANCE EVALUATION; FINANCIAL STABILITY; MCDM APPROACH; TOPSIS; SUSTAINABILITY; DISTRESS	In this study an important real-world multi-criteria problem in banking sector is focused. The aim of this problem is to rank some branches of a bank in Iran subject to some economic criteria under interval type uncertainty. The problem is complex because of its multi-criteria nature and also its interval type data. A new solution procedure is proposed for this problem. In the proposed procedure first the criteria are weighted as interval values according to an effective method which combines experts' opinions and the Shannon's entropy approach. Then, as a novelty, the classical EDAS multi-criteria solution approach is newly modified for interval type data in order to overcome the shortcomings of the interval EDAS approaches of the literature. Finally, using the data obtained from the case study, an extensive computational study is performed by the proposed solution procedure. The sensitivity of the proposed approach also is analyzed by changing its parameters and a comparative study was done by some other approaches.																	1868-5137	1868-5145															10.1007/s12652-020-02550-6		SEP 2020											
J								Tool wear condition monitoring based on a two-layer angle kernel extreme learning machine using sound sensor for milling process	JOURNAL OF INTELLIGENT MANUFACTURING										Tool wear monitoring; Milling process; Sound sensor; Kernel extreme learning	SUPPORT VECTOR MACHINE; BREAKAGE DETECTION; NEURAL-NETWORK; ACOUSTIC-EMISSION; FAULT-DIAGNOSIS; SYSTEM; PREDICTION; FAILURE; MODEL	Tool condition monitoring (TCM) in numerical control machines plays an essential role in ensuring high manufacturing quality. The TCM process is conducted according to the data obtained from one or more of a variety of sensors, among which acoustic sensors offer numerous practical advantages. However, acoustic sensor data suffer from strong noise, which can severely limit the accuracy of predictions regarding tool condition. The present work addresses this issue by proposing a novel TCM method that employs only a few appropriate feature parameters of acoustic sensor signals in conjunction with a two-layer angle kernel extreme learning machine. The two-layer network structure is applied to enhance the learning of features associated with complex nonlinear data, and two angle kernel functions without hyperparameters are employed to avoid the complications associated with the use of preset hyperparameters in conventional kernel functions. The proposed TCM method is experimentally demonstrated to achieve superior TCM performance relative to other state-of-the-art methods based on sound sensor data.																	0956-5515	1572-8145															10.1007/s10845-020-01663-1		SEP 2020											
J								Autonomous UAV Trail Navigation with Obstacle Avoidance Using Deep Neural Networks	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Autonomous navigation; Obstacle avoidance; Deep learning; Trail following; Unmanned aerial vehicle	VISION; ROBOT; FLIGHT	This paper proposes a vision-based bike trail following approach with obstacle avoidance using CNN (Convolutional Neural Network) for the UAV (Unmanned Aerial Vehicle). The UAV is controlled to follow a given trail while keeping its position near the center of the trail using the CNN. Also, to return to the original path when the UAV goes out of the path or the camera misses the trail due to disturbances such as wind, the control commands from the CNN are stored for a certain duration of time and used for recovering from such disturbances. To avoid obstacles during the trail navigation, the optical flow computed with another CNN is used to determine the safe maneuver. By combining these methods of i) trail following, ii) disturbance recovery, and iii) obstacle avoidance, the UAV deals with various situations encountered when traveling on the trail. The feasibility and performance of the proposed approach are verified through realistic simulations and flight experiments in real-world environments.																	0921-0296	1573-0409															10.1007/s10846-020-01254-5		SEP 2020											
J								HipaccVX: wedding of OpenVX and DSL-based code generation	JOURNAL OF REAL-TIME IMAGE PROCESSING										OpenVX; Domain-specific language; Image processing; GPU; FPGA	LANGUAGE; COMPILER	Writing programs for heterogeneous platforms optimized for high performance is hard since this requires the code to be tuned at a low level with architecture-specific optimizations that are most times based on fundamentally differing programming paradigms and languages. OpenVX promises to solve this issue for computer vision applications with a royalty-free industry standard that is based on a graph-execution model. Yet, the OpenVX ' algorithm space is constrained to a small set of vision functions. This hinders accelerating computations that are not included in the standard. In this paper, we analyze OpenVX vision functions to find an orthogonal set of computational abstractions. Based on these abstractions, we couple an existing domain-specific language (DSL) back end to the OpenVX environment and provide language constructs to the programmer for the definition of user-defined nodes. In this way, we enable optimizations that are not possible to detect with OpenVX graph implementations using the standard computer vision functions. These optimizations can double the throughput on an Nvidia GTX GPU and decrease the resource usage of a Xilinx Zynq FPGA by 50% for our benchmarks. Finally, we show that our proposed compiler framework, called HipaccVX, can achieve better results than the state-of-the-art approaches Nvidia VisionWorks and Halide-HLS.																	1861-8200	1861-8219															10.1007/s11554-020-01015-5		SEP 2020											
J								R-CNN and wavelet feature extraction for hand gesture recognition with EMG signals	NEURAL COMPUTING & APPLICATIONS										R-CNN; EMG signal; Wavelet power spectrum; Discrete wavelet transform; Gesture recognition; Validation	NETWORK	This paper demonstrates the implementation of R-CNN in terms of electromyography-related signals to recognize hand gestures. The signal acquisition is implemented using electrodes situated on the forearm, and the biomedical signals are generated to perform the signals preprocessing using wavelet packet transform to perform the feature extraction. The R-CNN methodology is used to map the specific features that are acquired from the wavelet power spectrum to validate and train how the architecture is framed. Additionally, the real-time test is completed to reach the accuracy of 96.48% compared to the related methods. This kind of result proves that the proposed work has the highest amount of accuracy in recognizing the gestures.																	0941-0643	1433-3058				NOV	2020	32	21			SI		16723	16736		10.1007/s00521-020-05349-w		SEP 2020											
J								Iris presentation attack detection based on best-kfeature selection from YOLO inspired RoI	NEURAL COMPUTING & APPLICATIONS										DarkNet-19; Feature selection; Image enhancement; Iris presentation attack detection; RoI localization; Score-level fusion	TEXTURED CONTACT-LENSES; RECOGNITION; ENSEMBLE; CLASSIFICATION; CLASSIFIERS; FRAMEWORK; FEATURES	Obfuscating an iris recognition system through forged iris samples has been a major security threat in iris-based authentication. Therefore, a detection mechanism is essential that may explicitly discriminate between the live iris and forged (attack) patterns. The majority of existing methods analyze the eye image as a whole to find discriminatory features for fake and real iris. However, many attacks do not alter the entire eye image, instead merely the iris region is affected. It infers that the iris embodies the region of interest (RoI) for an exhaustive search towards identifying forged iris patterns. This paper introduces a novel framework that locates RoI using the YOLO approach and performs selective image enhancement to enrich the core textural details. The YOLO approach tightly bounds the iris region without any pattern loss, where the textural analysis through local and global descriptors is expected to be efficacious. Afterward, various handcrafted and CNN based methods are employed to extract the discriminative textural features from the RoI. Later, the best-kfeatures are identified through the Friedman test as the optimal feature set and combined using score-level fusion. Further, the proposed approach is assessed on six different iris databases using predefined intra-dataset, cross-dataset, and combined-dataset validation protocols. The experimental outcomes exhibit that the proposed method results in significant error reduction with the state of the arts.																	0941-0643	1433-3058															10.1007/s00521-020-05342-3		SEP 2020											
J								Rice-net: an efficient artificial fish swarm optimization applied deep convolutional neural network model for identifying the Oryza sativa diseases	NEURAL COMPUTING & APPLICATIONS										Artificial intelligence (AI); Rice diseases; Deep convolution neural network (DCNN); Long short-term memory (LSTM); Efficient artificial fish swarm optimization (EAFSO)		This research aims to identify rice diseases, namely Leaf blast, Brown spot, Healthy and Hispa. The purpose of this research is to utilize deep convolutional neural network (DCNN) with support vector machine (SVM), DCNN with artificial neural network (ANN) and DCNN with long short-term memory (LSTM). To enhance the performance of LSTM further, the research includes particle swarm optimization, artificial fish swarm optimization (AFSO) and efficient artificial fish swarm optimization (EAFSO) to identify optimal weights. This research also compares the proposed technique results with a conventional feature extraction approaches like texture, discrete wavelet transforms and color histogram with SVM, ANN and LSTM. The results exhibit the superiority of proposed DCNN-LSTM (EAFSO) technique over other techniques. The proposed technique EAFSO associates DCNN-LSTM identifies the rice diseases with 97.5% accuracy, which is better than DCNN-SVM and DCNN-ANN.																	0941-0643	1433-3058															10.1007/s00521-020-05364-x		SEP 2020											
J								Machine learning-based QOT prediction for self-driven optical networks	NEURAL COMPUTING & APPLICATIONS										Machine learning; Self-driven networking; Quality of transmission; Optical signal-to-noise ratio; Neural networks	AUTOMATIC MICROSTRUCTURAL CHARACTERIZATION; QUALITY; MODEL	Nowadays, digital businesses with diverse deployment models such as cloud, mobile and edge devices for the internet of things will impact traffic, in both volume and dynamicity, at unprecedented rates. Moreover, due to the recent advances in optical networks and systems, the complexity of provisioning lightpaths is growing dramatically. Hence, optical network operators are forced to change their insight and move toward intent-based and self-driven networking, to cost-efficiently accommodate these challenging requirements. In this regard, knowledge-defined networking (KDN) promises to play a paramount role in realizing flexible and self-driven optical networks. In this work, we focus on one of the key aspects in this environment, i.e., prediction of quality of service for unestablished lightpaths. KDN is a solution that introduces machine learning techniques into the control plane of the network, to cope with inevitable complexities that arise in enabling network to operate autonomously and faster. For this, five machine learning models are evaluated for the classification and regression approaches. Multilayer perceptron, radial basis function and generalized regression neural network (GRNN) models are used for both of the regression and classification approaches, while support-vector machine and probabilistic neural network (PNN) models are used only for the classification scenario. Also, to discard the redundant features (among the considered experimental features) in the classification approach, input features are selected using the analysis of variance (ANOVA) test. The proposed models can accelerate and handle a significant part of operations in the closed-loop architecture of knowledge-defined optical networks, as a paradigm for designing self-driven optical networks. The best accuracies of quality of transmission prediction (classification approach) and optical signal-to-noise ratio estimation (regression approach) are achieved using PNN (with average accuracy of 99.6 +/- 0.5%) and GRNN (withR-squared value of 0.957), respectively.																	0941-0643	1433-3058															10.1007/s00521-020-05123-y		SEP 2020											
J								EW-Fisher: A Novel Loss Function for Deep Learning-Based Image Co-Segmentation	NEURAL PROCESSING LETTERS										Loss function; Deep learning; Image co-segmentation; Edge weighting strategy; Fisher criterion		The loss function is an important factor for the success of machine learning. This paper proposes a new loss function for deep learning-based image co-segmentation. It aims to maximize the inter-class difference between the foreground and the background and at the same time minimize the two intra-class variances. This idea has some similarity to the Fisher criterion in pattern recognition. We further embed an edge weighting strategy into this form of Fisher-like criterion to let the pixels near the foreground edges be paid more attentions in the training process for achieving the finer segmentation. The resultant loss function is called EW-Fisher (Edge-Weighted Fisher). We apply the proposed EW-Fisher loss to image co-segmentation and evaluate it on commonly used datasets. In the experiments, the EW-Fisher stably outperforms the most-widely used cross-entropy loss and Dice loss as well as the recently presented edge agreement loss and Hausdorff distance loss. The comparison results and the ablation studies prove the values of our Fisher-like learning criterion and edge weighting strategy.																	1370-4621	1573-773X															10.1007/s11063-020-10354-0		SEP 2020											
J								Infrared and visible image fusion using modified spatial frequency-based clustered dictionary	PATTERN ANALYSIS AND APPLICATIONS										Image fusion; Sparse representation; Dictionary learning; Spatial frequency; Online dictionary learning	CONTOURLET TRANSFORM; PERFORMANCE; VIDEO; ALGORITHM; COLOR	Infrared and visible image fusion is an active area of research as it provides fused image with better scene information and sharp features. An efficient fusion of images from multisensory sources is always a challenge for researchers. In this paper, an efficient image fusion method based on sparse representation with clustered dictionary is proposed for infrared and visible images. Firstly, the edge information of visible image is enhanced by using a guided filter. To extract more edge information from the source images, modified spatial frequency is used to generate a clustered dictionary from the source images. Then, non-subsampled contourlet transform (NSCT) is used to obtain low-frequency and high-frequency sub-bands of the source images. The low-frequency sub-bands are fused using sparse coding, and the high-frequency sub-bands are fused using max-absolute rule. The final fused image is obtained by using inverse NSCT. The subjective and objective evaluations show that the proposed method is able to outperform other conventional image fusion methods.																	1433-7541	1433-755X															10.1007/s10044-020-00919-z		SEP 2020											
J								Wavelet domain majority coupled binary pattern: a new descriptor for texture classification	PATTERN ANALYSIS AND APPLICATIONS										Texture classification; Local binary pattern; Texture feature extraction	GRAY-SCALE; TRANSFORM	In this paper, a new approach for texture classification called wavelet domain majority coupled binary pattern is proposed. Here, the single-level wavelet transform is applied which decomposes the image, resulting in wavelet coefficients. The wavelet coefficients present in all the four sub-bands are taken for further processing. The relationship of wavelet coefficients present at distances one, two and three is utilized. The average wavelet coefficients present at various distances are compared with the center wavelet coefficient of the local region, resulting in binary value. For each distance, eight bit binary pattern is generated. Altogether, three distances yield three eight bit binary pattern. Then, the rule of majority is applied to the three eight bit binary pattern and results in generation of proposed label. The proposed labels together contribute for the construction of histogram. Finally, the distance measure is used to identify the similarity between query and database images. Experimental results show that the proposed method achieves the average retrieval rate of 88.92% on Brodatz, 93.95% on Outex and 90.53% on Virus databases. This shows that the proposed method achieves good performance and outperforms other existing methods.																	1433-7541	1433-755X															10.1007/s10044-020-00907-3		SEP 2020											
J								Classification among healthy, mild cognitive impairment and Alzheimer's disease subjects based on wavelet entropy and relative beta and theta power	PATTERN ANALYSIS AND APPLICATIONS										EEG; Wavelet; Entropy; Mild cognitive impairment; Alzheimer's disease	EEG BACKGROUND ACTIVITY; PERMUTATION ENTROPY; ELECTROENCEPHALOGRAM	Diagnosis of Alzheimer's disease (AD), mild cognitive impairment (MCI), and healthy subjects (Healthy) is currently lacking an automated tool. It requires experience of neuropsychologists and has sensibilities of 80% when separating between Healthy and MCI. The aim of this work is to evaluate the performance of a method for classification among the three groups using a database of 17 Healthy, 9 MCI and 15 AD. The method uses wavelet decomposition of the EEG signal (Haar mother wavelet and 5 decomposition levels) to calculate the wavelet entropy and theta and beta relative power of the EEG signal. These features are used as inputs to a three-way classifier consisting in a support vector machine with polynomial kernel and a two-layer neural network. The last implements a vote procedure. Wavelet entropy was evaluated together with the sample entropy and approximated entropy to choose the one that best detected changes in the complexity of the EEG signal. The results show that it is possible to automatically classify a subject of a particular group with an overall accuracy of 92.6%, close to the best result found in the literature that is 97.9%. The method could be the basis for the implementation of a diagnosis-support quantitative tool oriented to aid in clinical diagnosis, especially when the classification between the three groups is not one of the more represented researches in the consulted literature.																	1433-7541	1433-755X															10.1007/s10044-020-00910-8		SEP 2020											
J								Seismicity analysis using space-time density peak clustering method	PATTERN ANALYSIS AND APPLICATIONS										Space-time density peak clustering; Earthquake catalogs; Inverse TM metric; Coefficient of variation	CALIFORNIA	This paper presents two-stage clustering approach for accurate analysis of earthquake catalogs where aim is to categorize events in terms of aftershock (AF) clusters or independent backgrounds (BGs). In stage I, the Gaussian kernel-based temporal density estimation is used for grouping of events based on their occurrence time. From the graph, local peak (maxima), local minima and their timing information are utilized to group the events into significant time zones. In stage II, on events of each time zone, coordinate and magnitude information is combined together (weighted mechanism) to determine effective local weighted spatial density (rho(w)). Based on rho(w) and event distance (delta), a decision graph is drawn to find out the spatial cluster centroids for each time zone. Event's assignment to the centroid is carried out based on its nearest neighbor of higher density. Outliers (non-clustered) are also detected in stage II which is considered as independent backgrounds. The experimental analysis is carried out on historical seismicity of California, Himalaya, Japan and Sumatra-Andaman region. The results indicate that obtained AFs and total number of events follow a similar cumulative and lambda rate, whereas BGs have linear cumulative and consistent lambda rate. It is also observed that AFs and total events have similar ergodic behavior, quantified from the inverse TM metric plot. The competitive performance of the proposed approach is obtained over state-of-the-art declustering methods.																	1433-7541	1433-755X															10.1007/s10044-020-00913-5		SEP 2020											
J								An optimization drone routing model for inspecting wind farms	SOFT COMPUTING										Unmanned aircraft system; Drone; Wind turbine inspection routing; Integer linear programming; Traveling salesman problem (TSP); Equality generalized traveling salesman problem (E-GTSP)	TRAVELING SALESMAN PROBLEM; MULTIPLE DEPOT; TRUCK-DRONE; VEHICLE; DELIVERY; ALGORITHMS	The use of wind turbines to generate electricity is growing worldwide. They comprise an extended area of hundreds of square miles, making the inspection process difficult and time-consuming. Recently, there has been an increasing interest in using a drone, or also known as unmanned aircraft systems, for inspecting wind turbines. Motivated by leveraging drone technology, this paper provides a routing optimization model to reduce the total operation time for inspecting a wind farm. We assume that one drone and one ground vehicle which carries the drone and extra batteries and charging equipment are available. The optimization model is solved in two steps. The first step clusters the wind turbines and optimizes the drone routing in each cluster by solving the classical traveling salesman problem using an integer linear programming model. The second step optimizes the ground vehicle routing by solving the equality generalized traveling salesman problem using an integer linear programming model. We test our proposed model using three case studies created by using actual wind farm locations. We compare the results with two models. One model assumes no clustering of the wind turbines, and the other model uses a greedy approach for determining the ground vehicle route. The results show that the proposed model is more efficient at different flight speeds and endurances. Also, we confirm that the efficiency increases as the drone flies faster or it has longer flight endurance.																	1432-7643	1433-7479															10.1007/s00500-020-05316-6		SEP 2020											
J								A novel mathematical model for predicting landslide displacement	SOFT COMPUTING										Kernel grey model with fractional operators; Mathematical model; Prediction; Engineering application; Landslide displacement	GREY; CONSUMPTION; SYSTEM; OPERATOR; MACHINE	Landslide displacement evolution is important for predicting landslide geological disasters. Because landslide displacement monitoring data are limited, in this paper we propose a novel model for predicting landslide displacement, namely the kernel grey model with fractional operators (FKGM). By combining the advantages of fractional modeling, kernel function methods and grey models, we derived the theoretical framework of FKGM. The parameters of FKGM were obtained using particle swarm optimization algorithm. Then, FKGM was applied in a case study of a landslide in Hubei, China. The engineering geological characteristics of the landslide were analyzed, and seven factors including rainfall and the rate of the reservoir water-level change were selected as inputs. The results show that the mean absolute percentage error and mean square error of FKGM are smaller than those of the least square support vector machine (LSSVM) and the classical grey prediction model-GM(1,1). The influence of the FKGM parameters was investigated. Our results indicate that FKGM can be applied to reliably predict large deformation of landslides.																	1432-7643	1433-7479															10.1007/s00500-020-05313-9		SEP 2020											
J								Solving technician routing and scheduling problem using improved particle swarm optimization	SOFT COMPUTING										Neighborhood operator; Particle swarm optimization; Technician routing and scheduling		In this paper, an improved particle swarm optimization (IPSO) algorithm is proposed to solve the technician routing and scheduling problem (TRSP). The TRSP consists of the assignment of technicians into teams, the assignment of teams to tasks, the construction of routes, and the selection of the day on which a service is provided by considering the proficiency level of workers and the proficiency requirement of the task. The paper considers the planning horizon as a multi-period covering 5 days, which further increases the complexity of the problem. Then a task can be fulfilled in any one of 5 days. The IPSO algorithm includes a particle swarm optimization (PSO) algorithm and one neighborhood operator. One neighborhood operator is used to avoid the local solution trap since the global best solution found by PSO is falling into a local solution trap. Further, the proposed algorithm's performance is experimentally compared with the branch-and-cut algorithm for the solution of the TRSP, on the benchmark instances generated from the literature. The computational results show that IPSO provides better solutions considering the branch-and-cut algorithm within reasonable computing time.																	1432-7643	1433-7479															10.1007/s00500-020-05333-5		SEP 2020											
J								Determining the price and refund of products in a supply chain with quality and advertising costs in a fuzzy environment	SOFT COMPUTING										Supply chain; Pricing and refund; Quality; Cooperative advertising; Game theory; Fuzzy sets	EXPECTED VALUE; DECISIONS; COORDINATION; RETAILER; STRATEGIES; COLLECTION; POLICIES	In online direct selling, three effective elements, namely price, refund and quality, affect the increment (or decrement) of demand and product return. This paper considers forward and backward (i.e., return) pricing decisions under uncertainty and develops a fuzzy mathematical model based on the Stackelberg game approach utilizing the proper action and reaction between a manufacturer and a retailer. Moreover, media advertising and manufacturer's desire for accepting massive payments made us take into account the advertising as another factor influencing the demand. By an agreement between the manufacturer and the retailer, the costs of advertising and raising the level of the product quality are shared by two agreed rates. Two numerical examples are considered and the associated results are analyzed under fuzzy and crisp conditions when customers are sensitive or insensitive to the quality of the product. It is found that incorporation of the quality factor under a fuzzy environment has a better performance compared with the case of ignoring the quality and uncertainty in the parameters.																	1432-7643	1433-7479															10.1007/s00500-020-05307-7		SEP 2020											
J								A novel TODIM-VIKOR approach based on entropy and Jensen-Tsalli divergence measure for picture fuzzy sets in a decision-making problem	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										divergence; entropy; picture fuzzy number; picture fuzzy set; TODIM; VIKOR	INTUITIONISTIC FUZZY; AGGREGATION OPERATORS; COMPROMISE SOLUTION; CROSS-ENTROPY; INFORMATION; RANKING; MODEL	The picture fuzzy set (PFS) has grown huge attention in the research area of uncertain information from the last few years. Information measures have been widely studied in various fuzzy environments. Therefore, in this paper, we study the entropy and divergence measures under the picture fuzzy environment. First, the paper introduced a new entropy measure to measure the fuzziness degree associated with a PFS. An example is established to show the capabilities of the proposed entropy measure. Second, the paper defines a new Jensen-Tsalli divergence measure for PFS to evaluate the information of discrimination between two PFS. We also discuss several properties of entropy and divergence measures in detail. Then we present a new method, based on proposed entropy and divergence measure, to determine the objective weights of experts for multicriteria group decision making with picture fuzzy information. The final criteria weights are obtained by combining subjective and objective weights for more reliable weightage of evaluation criteria. By using this comprehensive weight-determination technique, the proposed method can effectively reduce the unreasonable impact of the extreme evaluation data on the evaluation results. Further, a new multi-criteria decision-making approach is developed based on the combining concepts of the TODIM and VIKOR method under the picture fuzzy environment. We used TODIM to obtain the overall dominance degree which considers the bounded rationality of decision makers and VIKOR is used to obtain the compromise ranking of alternatives. Lastly, an application of the proposed integrated model is demonstrated to verify the feasibility and usefulness and the outcomes of the proposed model are compared with the outcomes of the existing approaches to indicate its validity. This integrated method can effectively reduce the distortion of decision information and provide extraordinary evaluation results. The proposed approach is used in detecting the major issues due to which a company is facing such breakdowns.																	0884-8173	1098-111X				DEC	2020	35	12					2140	2180		10.1002/int.22289		SEP 2020											
J								Fuzzy-Based Impulsive Synchronization of Different Complex Networks with Switching Topology and Time-Varying Dynamic	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Synchronization; Complex network; Switching topology; Impulsive control; Fuzzy logic	EXPONENTIAL SYNCHRONIZATION; SYSTEM	In this paper, the synchronization problem of complex networks using fuzzy-based impulsive control is discussed. Synchronization problem is considered for networks with switching topologies. Also, each node of the networks has a time-varying chaotic dynamic. Based on the Takagi-Sugeno fuzzy model, a new representation of a complex network is presented. Using impulsive control theory, a new controller for the synchronization of time-varying networks is designed. The synchronization problem has been extended for two different networks. Simulation examples show the effectiveness of the proposed method.																	1562-2479	2199-3211															10.1007/s40815-020-00950-6		SEP 2020											
J								Fuzzy Rule-Based Signal Restoration for Wireless Optical Communication of Multi-autonomous Underwater Vehicles	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Underwater wireless optical communication; Autonomous underwater vehicles; Fuzzy control		As a complex process, wireless optical communication of autonomous underwater vehicles (AUVs) is particularly challenging in the complex communication environment. Therefore, the existing control or denoise systems show some limitations for communication system of multi-AUV. It is still difficult to balance between the complexity of underwater environment and the performance of reality or estimation. This paper is about to investigate the possibility of combining this realistic communication environment for AUVs with existing strategies in fuzzy control framework. More specifically, first, a model for underwater wireless optical communication (UWOC) is proposed, then, signal restore model for UWOC based on fuzzy control is developed for simulation and analysis purposes. To illustrate the superiority of the proposed methods, several common denoising methods are experimented and compared together. It is also shown that the fuzzy control for signal restore model can well adapt to the real communication environment, and ensure more efficiency and stabilization.																	1562-2479	2199-3211															10.1007/s40815-020-00935-5		SEP 2020											
J								An Underwater Human-Robot Interaction Using Hand Gestures for Fuzzy Control	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy control; Gesture recognition; Human-robot communication; AUV		Autonomous underwater vehicle (AUV) plays an important role in ocean research and exploration. The underwater environment has a great influence on AUV control and human-robot interaction, since underwater environment is highly dynamic with unpredictable fluctuation of water flow, high pressure and light attenuation. The traditional control model contains a large number of parameters, which is not effective and produces errors frequently. The proposal of fuzzy control addressed this issue to a certain extent. It applies fuzzy variables to the controller, which replace the values in an interval. In addition to the controller, underwater human-robot interaction is also difficult. Divers cannot speak or show any facial expressions underwater. The buttons on the AUV also need to overcome the huge water pressure. In this paper, we proposed a method to recognize the gesture instructions and apply it to the fuzzy control of AUV. Our contribution is the gesture recognition framework for the human-robot interaction, including the gesture detection network and the algorithm for the control of AUV. The experiment result shows the efficiency of the proposed method.																	1562-2479	2199-3211															10.1007/s40815-020-00946-2		SEP 2020											
J								For real: a thorough look at numeric attributes in subgroup discovery	DATA MINING AND KNOWLEDGE DISCOVERY										Subgroup discovery; Supervised local pattern mining; Numeric attributes; Discretisation	EFFICIENT ALGORITHMS; SD	Subgroup discovery (SD) is an exploratory pattern mining paradigm that comes into its own when dealing with large real-world data, which typically involves many attributes, of a mixture of data types. Essential is the ability to deal with numeric attributes, whether they concern the target (a regression setting) or the description attributes (by which subgroups are identified). Various specific algorithms have been proposed in the literature for both cases, but a systematic review of the available options is missing. This paper presents a generic framework that can be instantiated in various ways in order to create different strategies for dealing with numeric data. The bulk of the work in this paper describes an experimental comparison of a considerable range of numeric strategies in SD, where these strategies are organised according to four central dimensions. These experiments are furthermore repeated for both the classification task (target is nominal) and regression task (target is numeric), and the strategies are compared based on the quality of the top subgroup, and the quality and redundancy of the top-kresult set. Results of three search strategies are compared: traditional beam search, complete search, and a variant of diverse subgroup set discovery called cover-based subgroup selection. Although there are various subtleties in the outcome of the experiments, the following general conclusions can be drawn: it is often best to determine numeric thresholds dynamically (locally), in a fine-grained manner, with binary splits, while considering multiple candidate thresholds per attribute.																	1384-5810	1573-756X															10.1007/s10618-020-00703-x		SEP 2020											
J								Unsupervised Deep Representation Learning for Real-Time Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION										Visual tracking; Unsupervised learning; Correlation filter; Siamese network		The advancement of visual tracking has continuously been brought by deep learning models. Typically, supervised learning is employed to train these models with expensive labeled data. In order to reduce the workload of manual annotation and learn to track arbitrary objects, we propose an unsupervised learning method for visual tracking. The motivation of our unsupervised learning is that a robust tracker should be effective in bidirectional tracking. Specifically, the tracker is able to forward localize a target object in successive frames and backtrace to its initial position in the first frame. Based on such a motivation, in the training process, we measure the consistency between forward and backward trajectories to learn a robust tracker from scratch merely using unlabeled videos. We build our framework on a Siamese correlation filter network, and propose a multi-frame validation scheme and a cost-sensitive loss to facilitate unsupervised learning. Without bells and whistles, the proposed unsupervised tracker achieves the baseline accuracy of classic fully supervised trackers while achieving a real-time speed. Furthermore, our unsupervised framework exhibits a potential in leveraging more unlabeled or weakly labeled data to further improve the tracking accuracy.																	0920-5691	1573-1405															10.1007/s11263-020-01357-4		SEP 2020											
J								UAV Model-based Flight Control with Artificial Neural Networks: A Survey	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Model-based control (MBC); Artificial neural network (ANN); Flight control; Hybridization; Unmanned aerial vehicle (UAV)	CONTROL-SYSTEMS; ALGORITHM; ONLINE	Model-Based Control (MBC) techniques have dominated flight controller designs for Unmanned Aerial Vehicles (UAVs). Despite their success, MBC-based designs rely heavily on the accuracy of the mathematical model of the real plant and they suffer from the explosion of complexity problem. These two challenges may be mitigated by Artificial Neural Networks (ANNs) that have been widely studied due to their unique features and advantages in system identification and controller design. Viewed from this perspective, this survey provides a comprehensive literature review on combined MBC-ANN techniques that are suitable for UAV flight control, i.e., low-level control. The objective is to pave the way and establish a foundation for efficient controller designs with performance guarantees. A reference template is used throughout the survey as a common basis for comparative studies to fairly determine capabilities and limitations of existing research. The end-result offers supported information for advantages, disadvantages and applicability of a family of relevant controllers to UAV prototypes.																	0921-0296	1573-0409															10.1007/s10846-020-01227-8		SEP 2020											
J								A 3D Computer Vision-Guided Robotic Companion for Non-Contact Human Assistance and Rehabilitation	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Assistive robot; Mobile robot; Computer vision	OLDER-ADULTS; WALKING; EXOSKELETON; DEMANDS; BALANCE; PEOPLE; BODY	With the rapid aging of the U.S. population, the mobility impairment is becoming a more and more challenging issue that affects a large number of individuals. The research presented in this paper aims at helping the mobility-challenged individuals with a novel robotic companion, which is a walker-type mobile robot capable of accompanying the human user and keeping user at the center for protection and possible power assistance. The robotic companion is equipped with a 3D computer vision system, which provides a unique capability of sensing the human-robot relative position/orientation without physical contact or the need for wearable sensors. As such, the robotic companion enables the user to walk freely with minimum disturbance to his/her normal gait, relieving the user from the physical and cognitive loads associated with the use of traditional assistive devices. For the development of the robotic companion, the authors designed and fabricated a low-cost, differentially steered mobile robotic platform, and also developed a unique image processing system to extract the position/orientation information from the 3D camera-captured images. Furthermore, an advanced motion control system was developed for the robotic companion, which provides novel solutions to the unique challenges such as sway reduction and noise reduction in digital differentiation. To quantify the performance, component and system-level experimentation was conducted, and the results demonstrated that robotic companion and its key components function as desired and the system is expected to reduce the user load and improve the user mobility in real-world scenarios.																	0921-0296	1573-0409															10.1007/s10846-020-01258-1		SEP 2020											
J								Low-complexity CNN with 1D and 2D filters for super-resolution	JOURNAL OF REAL-TIME IMAGE PROCESSING										Super-resolution; CNN; VDSR; Deep learning	IMAGE SUPERRESOLUTION; INVERSE PROBLEMS; NEURAL-NETWORKS; RESOLUTION	This paper proposes a low-complexity convolutional neural network (CNN) for super-resolution (SR). The proposed deep-learning model for SR has two layers to deal with horizontal, vertical, and diagonal visual information. The front-end layer extracts the horizontal and vertical high-frequency signals using a CNN with one-dimensional (1D) filters. In the high-resolution image-restoration layer, the high-frequency signals in the diagonal directions are processed by additional two-dimensional (2D) filters. The proposed model consists of 1D and 2D filters, and as a result, we can reduce the computational complexity of the existing SR algorithms, with negligible visual loss. The computational complexity of the proposed algorithm is 71.37%, 61.82%, and 50.78% lower in CPU, TPU, and GPU than the very-deep SR (VDSR) algorithm, with a peak signal-to-noise ratio loss of 0.49 dB.																	1861-8200	1861-8219															10.1007/s11554-020-01019-1		SEP 2020											
J								A frame-level MLP-based bit-rate controller for real-time video transmission using VVC standard	JOURNAL OF REAL-TIME IMAGE PROCESSING										Versatile video coding (VVC); Bit-rate; Buffer; Control; Quantization parameter (QP); Multi-layer perceptron (MLP)	RATE CONTROL ALGORITHM; GAME-THEORY; HEVC; ALLOCATION; QUALITY; OPTIMIZATION	Real-time video transmission is one of the most popular applications that are included in the versatile video coding (VVC) standard. However, real-time applications are encountered with practical limitations, including the buffer size and available bandwidth. In these applications, the buffer overflow and underflow should be strictly prevented and also the bit-rate fluctuation should be suppressed. In this paper, a video bit-rate controller is proposed that completely conforms with the constraints of real-time applications. The proposed controller is based on a multi-layer perceptron (MLP) neural network which estimates the proper quantization parameter (QP) modification at the frame level. The buffer occupancy is directly included in the QP derivation process for robust buffer control. Experimental results show that the proposed bit-rate controller fulfils the buffering constraints and controls the bit-rate accurately. The average bit-rate error of the proposed method is 0.29% while providing a low initial buffering delay of about 0.21 s. Also, the rate-distortion analysis shows that the performance of the proposed method is close to those of the conventional algorithms.																	1861-8200	1861-8219															10.1007/s11554-020-01018-2		SEP 2020											
J								High-dimensional Bayesian optimization using low-dimensional feature spaces	MACHINE LEARNING											ALGORITHM	Bayesian optimization (BO) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for fine tuning hyper-parameters of machine learning models. However, BO is practically limited to optimizing 10-20 parameters. To scale BO to high dimensions, we usually make structural assumptions on the decomposition of the objective and/or exploit the intrinsic lower dimensionality of the problem, e.g. by using linear projections. We could achieve a higher compression rate with nonlinear projections, but learning these nonlinear embeddings typically requires much data. This contradicts the BO objective of a relatively small evaluation budget. To address this challenge, we propose to learn a low-dimensional feature space jointly with (a) the response surface and (b) a reconstruction mapping. Our approach allows for optimization of BO's acquisition function in the lower-dimensional subspace, which significantly simplifies the optimization problem. We reconstruct the original parameter space from the lower-dimensional subspace for evaluating the black-box function. For meaningful exploration, we solve a constrained optimization problem.																	0885-6125	1573-0565				SEP	2020	109	9-10			SI		1925	1943		10.1007/s10994-020-05899-z		SEP 2020											
J								Modeling human thinking about similarities by neuromatrices in the perspective of fuzzy logic	NEURAL COMPUTING & APPLICATIONS										Similarity perception; Fuzzy logic; Similarity matrix decomposition; Neuromatrices; Linguistic ordinal scales (LOS); Reconstructing similarity matrix	PAIRWISE LIKELIHOOD ESTIMATION; BOOLEAN FACTOR-ANALYSIS; LONG-TERM-MEMORY; ELECTROENCEPHALOGRAM EEG; HIERARCHICAL CLASSES; MATRICES; BRAIN; FACTORIZATION; ARCHITECTURE; PERFORMANCE	In this work, we propose a new method for modeling human reasoning about objects' similarities. We assume that similarity depends on perceived intensities of objects' attributes expressed by natural language expressions such as low, medium, and high. We show how to find the underlying structure of the matrix with intensities of objects' similarities in the factor-analysis-like manner. The demonstrated approach is based on fuzzy logic and set theory principles, and it uses only maximum and minimum operators. Similarly to classic eigenvector decomposition, we aim at representing the initial linguistic ordinal-scale (LOS) matrix as a max-min product of other LOS matrix and its transpose. We call this reconstructing matrix a neuromatrix because we assume that such a process takes place at the neural level in our brain. We show and discuss on simple, illustrative examples, how the presented way of modeling grasps natural way of reasoning about similarities. The unique characteristics of our approach are treating smaller attribute intensities as less important in making decisions about similarities. This feature is consistent with how the human brain is functioning at a biological level. A neuron fires and passes information further only if input signals are strong enough. The proposal of the heuristic algorithm for finding the decomposition in practice is also introduced and applied to exemplary data from classic psychological studies on perceived similarities between colors and between nations. Finally, we perform a series of simulation experiments showing the effectiveness of the proposed heuristic.																	0941-0643	1433-3058															10.1007/s00521-020-05363-y		SEP 2020											
J								SESF-Fuse: an unsupervised deep model for multi-focus image fusion	NEURAL COMPUTING & APPLICATIONS										Multi-focus image fusion; Unsupervised deep learning; Spatial frequency	QUALITY ASSESSMENT	Muti-focus image fusion is the extraction of focused regions from different images to create one all-in-focus fused image. The key point is that only objects within the depth-of-field have a sharp appearance in the photograph, while other objects are likely to be blurred. We propose an unsupervised deep learning model for multi-focus image fusion. We train an encoder-decoder network in an unsupervised manner to acquire deep features of input images. Then, we utilize spatial frequency, a gradient-based method to measure sharp variation from these deep features, to reflect activity levels. We apply some consistency verification methods to adjust the decision map and draw out the fused result. Our method analyzes sharp appearances in deep features instead of original images, which can be seen as another success story of unsupervised learning in image processing. Experimental results demonstrate that the proposed method achieves state-of-the-art fusion performance compared to 16 fusion methods in objective and subjective assessments, especially in gradient-based fusion metrics.																	0941-0643	1433-3058															10.1007/s00521-020-05358-9		SEP 2020											
J								Parameter estimation of PEMFC model based on Harris Hawks' optimization and atom search optimization algorithms	NEURAL COMPUTING & APPLICATIONS										Fuel cell modeling; Parameter estimation; Meta-heuristic algorithms	FUEL-CELL; IDENTIFICATION; STATE	Proton exchange membrane fuel cell (PEMFC) is considered as propitious solution for an environmentally friendly energy source. A precise model of PEMFC for accurate identification of its polarization curve and in-depth understanding of all its operating characteristics attracted the interest of many researchers. In this paper, novel meta-heuristic optimization methods have been successfully applied to evaluate the unknown parameters of PEMFC models, particularly Harris Hawks' optimization (HHO) and atom search optimization (ASO) techniques. The proposed optimization algorithms have been tested on three different commercial PEMFC stacks, namely BCS 500-W PEM, 500W SR-12PEM and 250W stack, under various operating conditions. The sum of square errors (SSE) between the results obtained by the application of the estimated parameters and the experimentally measured results of the fuel cell stacks was considered as the objective function of the optimization problem. In order to validate the effectiveness of the proposed methods, the results are compared with that obtained in studies. Moreover, theI/Vcurves obtained by the application of HHO and ASO showed a clear matching with data sheet curves for all the studied cases. Finally, PEMFC model based on HHO technique surpasses all compared algorithms in terms of the solution accuracy and the convergence speed.																	0941-0643	1433-3058															10.1007/s00521-020-05333-4		SEP 2020											
J								Event-triggered neural intelligent control for uncertain nonlinear systems with specified-time guaranteed behaviors	NEURAL COMPUTING & APPLICATIONS										Event-triggered mechanism; MLP-based state observer; Modified barrier Lyapunov function; Uncertain nonlinear systems	DYNAMIC SURFACE CONTROL; FUZZY BACKSTEPPING CONTROL; SLIDING MODE CONTROL; PRESCRIBED PERFORMANCE; FEEDBACK SYSTEMS; NETWORK CONTROL; VARYING OUTPUT; PARAMETERS; DESIGN	In this paper, an event-triggered neural intelligent control for uncertain nonlinear systems with specified-time guaranteed behaviors is proposed. To cope with constrained communication resources, an event-triggered mechanism using switched thresholds is devised without involving input-to-state stability assumption, such that a better design flexibility and freedom can be provided. In addition, a minimum-learning-parameter-based state observer is developed to online estimate the unavailable states and uncertainties at the same time, which effectively eliminates the issue of learning explosion without sacrificing the identification precision. Furthermore, in pursuit of making a compromise between sampling cost and tracking performance, a modified barrier Lyapunov function based on a time-varying finite-time behavior boundary is constructed in the controller design, which can guarantee that the tracking error converges to a predetermined region within a specified time. Then by introducing the Nussbaum gain technique to handle the unknown control direction, an event-triggered neural output feedback control strategy is synthesized within the framework of dynamic surface control. Meanwhile, with the aid of Lyapunov synthesis, all the signals involved in the closed-loop system are proved to be bounded while Zeno phenomena is circumvented, and system outputs are well within the predefined region. Finally, an application on control design for a micro-electro-mechanical system gyroscope is given to validate the efficiency and superiority of proposed intelligent control scheme.																	0941-0643	1433-3058															10.1007/s00521-020-05357-w		SEP 2020											
J								Efficiency in uncertain variational control problems	NEURAL COMPUTING & APPLICATIONS										LU-optimal solution; Uncertain variational control problem; Interval-valued variational problem; (rho, b)-Quasiinvexity; Genetic algorithms	OPTIMIZATION; DUALITY	In this paper, considering the applications of interval analysis in various fields (such as artificial intelligence, neural computation, genetic algorithms, information theory or fuzzy logic), a new class of interval-valued variational control problems governed by multiple integral functionals, first-order PDE and inequality constraints is studied. More precisely, efficiency conditions for the considered uncertain variational control problem are formulated and proved. The sufficiency of Karush-Kuhn-Tucker conditions is established under some invexity and (rho,b)-quasiinvexity assumptions of the involved functionals. In addition, the paper is completed with illustrative applications (describing the controlled behavior of an artificial neural system) and the corresponding algorithm.																	0941-0643	1433-3058															10.1007/s00521-020-05353-0		SEP 2020											
J								Non-deterministic and emotional chatting machine: learning emotional conversation generation using conditional variational autoencoders	NEURAL COMPUTING & APPLICATIONS										Chatting machine; Conditional variational autoencoders; Non-deterministic; Neural dialog		Conversational responses are non-trivial for artificial conversational agents. Artificial responses should not only be meaningful and plausible, but should also (1) have an emotional context and (2) should be non-deterministic (i.e., vary given the same input). The two factors enumerated, respectively, above are involved and this is demonstrated such that previous studies have tackled them individually. This paper is the first to tackle them together. Specifically, we present two models both based upon conditional variational autoencoders. The first model learns disentangled latent representations to generate conversational responses given a specific emotion. The other model explicitly learns different emotions using a mixture of multivariate Gaussian distributions. Experiments show that our proposed models can generate more plausible and diverse conversation responses in accordance with designated emotions compared to baseline approaches.																	0941-0643	1433-3058															10.1007/s00521-020-05338-z		SEP 2020											
J								Ensemble pruning of ELM via migratory binary glowworm swarm optimization and margin distance minimization	NEURAL PROCESSING LETTERS										Glowworm swarm optimization; Margin distance minimization; Ensemble pruning; Diversity; Extreme learning machine	EXTREME LEARNING-MACHINE; ORDERED AGGREGATION; NEURAL-NETWORKS; ALGORITHM; DIVERSITY; CLASSIFIERS; SYSTEMS; DESIGN	Ensemble pruning aims at attaining an ensemble composed of less size of leaners for improving classification ability. Extreme Learning Machine (ELM) is employed as a base learner in this work, in light of its salient features, an initial pool is constructed using ELM. An ensemble composed of ELMs with better performance and diversity can make it perform the best, but the average accuracy of the whole ELMs must be decreased as the increase of diversity among them. Hence there exists a balance between the diversity and the precision of ELMs. Existing works find it via diversity measures or heuristic algorithms, which cannot find the exact tradeoff. To solve the issue, ensemble pruning of ELM via migratory binary glowworm swarm optimization and margin distance minimization (EPEMBM) is proposed utilizing the integration of the proposed migratory binary glowworm swarm optimization (MBGSO) and margin distance minimization (MDM). First, the created ELMs in a pool can be pre-pruned by MDM, and it can markedly downsize the ELMs in the pool, and significantly alleviates its computation overhead. Second, the retaining ELMs are further pruned utilizing MBGSO, and the final ensemble is attained with a high efficiency. Experimental results on 21 UCI classification tasks indicate that EPEMBM outperforms techniques, and that its effectiveness and efficiency. It is a very useful tool for solving the selection problem of ELMs.																	1370-4621	1573-773X															10.1007/s11063-020-10336-2		SEP 2020											
J								A new feature selection using dynamic interaction	PATTERN ANALYSIS AND APPLICATIONS										Feature selection; Feature interaction; Feature relevance; Feature redundancy; Filter method	MUTUAL INFORMATION; RELEVANCE; CLASSIFICATION	With the continuous development of Internet technology, data gradually present a complicated and high-dimensional trend. These high-dimensional data have a large number of redundant features and irrelevant features, which bring great challenges to the existing machine learning algorithms. Feature selection is one of the important research topics in the fields of machine learning, pattern recognition and data mining, and it is also an important means in the data preprocessing stage. Feature selection is to look for the optimal feature subset from the original feature set, which would improve the classification accuracy and reduce the machine learning time. The traditional feature selection algorithm tends to ignore the kind of feature which has a weak distinguishing capacity as a monomer, whereas the feature group's distinguishing capacity is strong. Therefore, a new dynamic interaction feature selection (DIFS) algorithm is proposed in this paper. Initially, under the theoretical framework of interactive information, it redefines the relevance, irrelevance and redundancy of the features. Secondly, it offers the computational formulas for calculating interactive information. Finally, under the eleven data sets of UCI and three different classifiers, namely, KNN, SVM and C4.5, the DIFS algorithm increases the classification accuracy of the FullSet by 3.2848% and averagely decreases the number of features selected by 15.137. Hence, the DIFS algorithm can not only identify the relevance feature effectively, but also identify the irrelevant and redundant features. Moreover, it can effectively improve the classification accuracy of the data sets and reduce the feature dimensions of the data sets.																	1433-7541	1433-755X															10.1007/s10044-020-00916-2		SEP 2020											
J								Representing and analyzing relief patterns using LBP variants on mesh manifold	PATTERN ANALYSIS AND APPLICATIONS										Relief patterns representation and classification; Mesh-LBP variants; Ordered ring facets; Mesh regularization	LOCAL BINARY PATTERNS; SHAPE; CLASSIFICATION; RECOGNITION; FEATURES	Extending the concept of texture to the geometry of a mesh manifold surface is an emerging topic in computer vision. This concept is different from gluing images to the surface, but rather indicates the presence of relief patterns that locally change the surface geometry, showing some regular and repetitive patterns. The representation and the analysis of such relief patterns have several potential applications. In this paper, we propose an original and comprehensive framework to address this novel task, which redefines a large variety of local binary patterns on the mesh manifold domain. We also propose an efficient mesh re-sampling technique that enables uniform surface tessellation. We assess the different descriptive variants derived with this framework in terms of uniformity, repeatability and discriminative power. Afterward, we conduct an extensive experimentation on different datasets showcasing the competitiveness of our framework in classification and retrieval tasks, in terms of both accuracy and computational complexity, with respect to state-of-the-art methods.																	1433-7541	1433-755X															10.1007/s10044-020-00920-6		SEP 2020											
J								Development of a valid and reliable software customization model for SaaS quality through iterative method: perspectives from academia	PEERJ COMPUTER SCIENCE										Customization approaches; Content validity; Iterative method; Model development; Reliability study; SaaS quality; Software as a service	DELPHI METHOD; SERVICE; IMPACT; ENTERPRISE; FRAMEWORK; PLATFORM; SYSTEM	Despite the benefits of standardization, the customization of Software as a Service (SaaS) application is also essential because of the many unique requirements of customers. This study, therefore, focuses on the development of a valid and reliable software customization model for SaaS quality that consists of (1) generic software customization types and a list of common practices for each customization type in the SaaS multi-tenant context, and (2) key quality attributes of SaaS applications associated with customization. The study was divided into three phases: the conceptualization of the model, analysis of its validity using SaaS academic-derived expertise, and evaluation of its reliability by submitting it to an internal consistency reliability test conducted by software-engineer researchers. The model was initially devised based on six customization approaches, 46 customization practices, and 13 quality attributes in the SaaS multi-tenant context. Subsequently, its content was validated over two rounds of testing after which one approach and 14 practices were removed and 20 practices were reformulated. The internal consistency reliability study was thereafter conducted by 34 software engineer researchers. All constructs of the content-validated model were found to be reliable in this study. The final version of the model consists of 6 constructs and 44 items. These six constructs and their associated items are as follows: (1) Configuration (eight items), (2) Composition (four items), (3) Extension (six items), 4) Integration (eight items), (5) Modification (five items), and (6) SaaS quality (13 items). The results of the study may contribute to enhancing the capability of empirically analyzing the impact of software customization on SaaS quality by benefiting from all resultant constructs and items.																	2376-5992					SEP 21	2020									e294	10.7717/peerj-cs.294													
J								Towards FAIR protocols and workflows: the OpenPREDICT use case	PEERJ COMPUTER SCIENCE										Ontology-driven healthcare; FAIR workflows; Drug repurposing; Scientific workflows and protocols; Reproducibility; Semantic web; Research Object; FAIR data principles	ONTOLOGIES; RESOURCES	It is essential for the advancement of science that researchers share, reuse and reproduce each other's workflows and protocols. The FAIR principles are a set of guidelines that aim to maximize the value and usefulness of research data, and emphasize the importance of making digital objects findable and reusable by others. The question of how to apply these principles not just to data but also to the workflows and protocols that consume and produce them is still under debate and poses a number of challenges. In this paper we describe a two-fold approach of simultaneously applying the FAIR principles to scientific workflows as well as the involved data. We apply and evaluate our approach on the case of the PREDICT workflow, a highly cited drug repurposing workflow. This includes FAIRification of the involved datasets, as well as applying semantic technologies to represent and store data about the detailed versions of the general protocol, of the concrete workflow instructions, and of their execution traces. We propose a semantic model to address these specific requirements and was evaluated by answering competency questions. This semantic model consists of classes and relations from a number of existing ontologies, including Workflow4ever, PROV, EDAM, and BPMN. This allowed us then to formulate and answer new kinds of competency questions. Our evaluation shows the high degree to which our FAIRified OpenPREDICT workflow now adheres to the FAIR principles and the practicality and usefulness of being able to answer our new competency questions.																	2376-5992					SEP 21	2020									e281	10.7717/peerj-cs.281													
J								Categorical study for algebras of Fitting's lattice-valued logic and lattice-valued modal logic	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Lattice-valued Boolean systems; Lattice-valued relational systems; Algebras of Fitting's lattice-valued modal logic; Adjoint; Co-adjoint; Duality	TOPOLOGY	The paper explores categorical interconnections between lattice-valued relational systems and algebras of Fitting's lattice-valued modal logic. We define lattice-valued Boolean systems, and then we study adjointness and co-adjointness of functors defined on them. As a result, we get a duality for algebras of lattice-valued logic. Following this duality result, we establish a duality for algebras of lattice-valued modal logic.																	1012-2443	1573-7470															10.1007/s10472-020-09707-1		SEP 2020											
J								OptCoNet: an optimized convolutional neural network for an automatic diagnosis of COVID-19	APPLIED INTELLIGENCE										Automatic diagnosis; Coronavirus; COVID-19; Convolutional neural network; Grey wolf optimizer; Stochastic gradient descent		The quick spread of coronavirus disease (COVID-19) has become a global concern and affected more than 15 million confirmed patients as of July 2020. To combat this spread, clinical imaging, for example, X-ray images, can be utilized for diagnosis. Automatic identification software tools are essential to facilitate the screening of COVID-19 using X-ray images. This paper aims to classify COVID-19, normal, and pneumonia patients from chest X-ray images. As such, an Optimized Convolutional Neural network (OptCoNet) is proposed in this work for the automatic diagnosis of COVID-19. The proposed OptCoNet architecture is composed of optimized feature extraction and classification components. The Grey Wolf Optimizer (GWO) algorithm is used to optimize the hyperparameters for training the CNN layers. The proposed model is tested and compared with different classification strategies utilizing an openly accessible dataset of COVID-19, normal, and pneumonia images. The presented optimized CNN model provides accuracy, sensitivity, specificity, precision, and F1 score values of 97.78%, 97.75%, 96.25%, 92.88%, and 95.25%, respectively, which are better than those of state-of-the-art models. This proposed CNN model can help in the automatic screening of COVID-19 patients and decrease the burden on medicinal services frameworks.																	0924-669X	1573-7497															10.1007/s10489-020-01904-z		SEP 2020											
J								A novel active multi-source transfer learning algorithm for time series forecasting	APPLIED INTELLIGENCE										Time series forecasting (TSF); Transfer learning (TL); Multi-source transfer learning (MSTL); Active multi-source transfer learning (AMSTL)	MACHINE; PREDICTION	In Time Series Forecasting (TSF), researchers usually assume that there is enough training data can be obtained, with the old a`nd new data satisfying the same distribution. However, time series data always produces some time-varying characteristics over time, which will lead to relatively large differences between old and new data. As we all know, single-source TSF Transfer Learning (TL) faces the problem of negative transfer. Addressing this issue, this paper proposes a new Multi-Source TL algorithm, abbreviated as the MultiSrcTL algorithm, and a novel Active Multi-Source Transfer Learning, abbreviated as the AcMultiSrcTL algorithm, with the latter one integrating Multi-Source TL with Active Learning (AL), and taking the former one as its sub-algorithm. We introduce domain adaptation theory into this work, and analyze the expected target risk of TSF under the multi-source setting, accordingly. For the development of MultiSrcTL, we make full use of source similarity and domain dependability, using the Maximum Mean Discrepancy statistical indicator to measure the similarity between domains, so as to promote better transfer. A domain relation matrix is constructed to describe the relationship between source domains, so that the source-source and source-target relations are adequately considered. In the design of AcMultiSrcTL, Kullback-Leibler divergence is used to measure the similarity of related indicators to select the appropriate source domain. The uncertainty sampling method and the distribution match weighting technique are integrated, obtaining a new sample selection scheme. The empirical results on six benchmark datasets demonstrate the applicability and effectiveness of the two proposed algorithms for multi-source TSF TL.																	0924-669X	1573-7497															10.1007/s10489-020-01871-5		SEP 2020											
J								A jumping mining attack and solution	APPLIED INTELLIGENCE										Proof of work; Difficulty adjustment algorithm; Hashrate simulation; Jumping mining attack		Mining is the important part of the blockchain used the proof of work (PoW) on its consensus, looking for the matching block through testing a number of hash calculations. In order to attract more hash computing power, the miner who finds the proper block can obtain some rewards. Actually, these hash calculations ensure that the data of the blockchain is not easily tampered. Thus, the incentive mechanism for mining affects the security of the blockchain directly. This paper presents an approach to attack against the difficulty adjustment algorithm (abbreviated as DAA) used in blockchain mining, which has a direct impact on miners' earnings. In this method, the attack miner jumps between different blockchains to get more benefits than the honest miner who keep mining on only one blockchain. We build a probabilistic model to simulate the time to obtain the next block at different hash computing power called hashrate. Based on this model, we analyze the DAAs of the major cryptocurrencies, including Bitcoin, Bitcoin Cash, Zcash, and Bitcoin Gold. We further verify the effectiveness of this attack called jumping mining through simulation experiments, and also get the characters for the attack in the public block data of Bitcoin Gold. Finally, we give an improved DAA scheme against this attack. Extensive experiments are provided to support the efficiency of our designed scheme.																	0924-669X	1573-7497															10.1007/s10489-020-01866-2		SEP 2020											
J								COVID-19 open source data sets: a comprehensive survey	APPLIED INTELLIGENCE										COVID-19; Coronavirus; Pandemic; Machine learning; Artificial intelligence; Open source; Data sets	MACHINE; DISCRIMINATION	In December 2019, a novel virus named COVID-19 emerged in the city of Wuhan, China. In early 2020, the COVID-19 virus spread in all continents of the world except Antarctica, causing widespread infections and deaths due to its contagious characteristics and no medically proven treatment. The COVID-19 pandemic has been termed as the most consequential global crisis since the World Wars. The first line of defense against the COVID-19 spread are the non-pharmaceutical measures like social distancing and personal hygiene. The great pandemic affecting billions of lives economically and socially has motivated the scientific community to come up with solutions based on computer-aided digital technologies for diagnosis, prevention, and estimation of COVID-19. Some of these efforts focus on statistical and Artificial Intelligence-based analysis of the available data concerning COVID-19. All of these scientific efforts necessitate that the data brought to service for the analysis should be open source to promote the extension, validation, and collaboration of the work in the fight against the global pandemic. Our survey is motivated by the open source efforts that can be mainly categorized as(a)COVID-19 diagnosis from CT scans, X-ray images, and cough sounds,(b)COVID-19 case reporting, transmission estimation, and prognosis from epidemiological, demographic, and mobility data,(c)COVID-19 emotional and sentiment analysis from social media, and(d)knowledge-based discovery and semantic analysis from the collection of scholarly articles covering COVID-19. We survey and compare research works in these directions that are accompanied by open source data and code. Future research directions for data-driven COVID-19 research are also debated. We hope that the article will provide the scientific community with an initiative to start open source extensible and transparent research in the collective fight against the COVID-19 pandemic.																	0924-669X	1573-7497															10.1007/s10489-020-01862-6		SEP 2020											
J								Automatically running experiments on checking multi-party contracts	ARTIFICIAL INTELLIGENCE AND LAW										Conflict detection; Multi-party contracts; Relativized contract language; Experiments	LOGIC	Contracts play an important role in business management where relationships among different parties are dictated by legal rules. Electronic contracts have emerged mostly due to technological advances and electronic trading between companies and customers. New challenges have then arisen to guarantee reliability among the stakeholders in electronic negotiations. In this scenario, automatic verification of electronic contracts appeared as an imperative support, specially the conflict detection task of multi-party contracts. The problem of checking contracts has been largely addressed in the literature, but there are few, if any, methods and practical tools that can deal with multi-party contracts using a contract language with deontic and dynamic aspects as well as relativizations, over the same formalism. In this work we present an automatic checker for finding conflicts on multi-party contracts modeled by an extended contract language with deontic operators and relativizations. Moreover a well-known case study of sales contract is modeled and automatically verified by our tool. Further, we performed practical experiments in order to evaluate the efficiency of our method and the practical tool.																	0924-8463	1572-8382															10.1007/s10506-020-09276-y		SEP 2020											
J								DISCERN: diversity-based selection of centroids for k-estimation and rapid non-stochastic clustering	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Clustering; K-means initialization; Estimating the number of clusters; Unsupervised learning; Deterministic K-means		One of the applications of center-based clustering algorithms such as K-means is partitioning data points intoKclusters. In some examples, the feature space relates to the underlying problem we are trying to solve, and sometimes we can obtain a suitable feature space. Nevertheless, while K-means is one of the most efficient offline clustering algorithms, it is not equipped to estimate the number of clusters, which is useful in some practical cases. Other practical methods which do are simply too complex, as they require at least one run of K-means for each possibleK. In order to address this issue, we propose a K-means initialization similar to K-means++, which would be able to estimateKbased on the feature space while finding suitable initial centroids for K-means in a deterministic manner. Then we compare the proposed method, DISCERN, with a few of the most practicalKestimation methods, while also comparing clustering results of K-means when initialized randomly, using K-means++ and using DISCERN. The results show improvement in both the estimation and final clustering performance.																	1868-8071	1868-808X															10.1007/s13042-020-01193-5		SEP 2020											
J								Optimized radial basis neural network for classification of breast cancer images	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Breast cancer; Radial basis function; Optimization; Cuckoo search; F1-score; Classification; Cancer imaging net	SEGMENTATION; FRAMEWORK	Breast cancer is a curable disease if the diagnosed at an early stage. The chances of having breast cancer are the lowest in the married woman after the breast-feeding phase because the cancer is formed from the blocked milk ducts. Nowadays, cancer is considered the leading cause of death globally. Breast cancer is the most common cancer among females. It is possible to develop breast cancer while breast-feeding a baby, but it is rare. Mammography is one of the most effective methods used in hospitals and clinics for early detection of breast cancer. Various researchers are used in artificial intelligence-based mammogram techniques. This process of mammography will reduce the death rate of the patients affected by breast cancer. This process is improved by image analysing, detection, screening, diagnosing, and other performance measures. The radial basis neural network will be used for classification purposes. The radial basis neural network is designed with the help of the optimization algorithm. The optimization is to tune the classifier to reduce the error rate with the minimum time for the training process. The cuckoo search algorithm will be used for this purpose. Thus, the proposed optimum RBNN is determined to classify breast cancer images. In this, the three sets of properties were classified by performing the feature extraction and feature reduction. In this breast cancer MRI image, the normal, benign, and malignant is taken to perform the classification. The minimum fitness value is determined to evaluate the optimum value of possible locations. The radial basis function is evaluated with the cuckoo search algorithm to optimize the feature reduction process. The proposed methodology is compared with the traditional radial basis neural network using the evaluation parameter like accuracy, precision, recall and f1-score. The whole system model is done by using Matrix Laboratory (MATLAB) with the adaptation of 2018a since the proposed system is most efficient than most recent related literature. Thus, it concluded with the efficient classification process of RBNN using a cuckoo search algorithm for breast cancer images. The mammogram images are taken into recent research because breast cancer is a major issue for women. This process is carried to classify the various features for three sets of properties. The optimized classifier improves performance and provides a better result. In this proposed research work, the input image is filtered using a wiener filter and the classifier extracts the feature based on the breast image.																	1868-5137	1868-5145															10.1007/s12652-020-02534-6		SEP 2020											
J								Multithreaded scheduling for program segments based on chemical reaction optimizer	SOFT COMPUTING										Chemical reaction optimization; Metaheuristic algorithm; Scheduling; Multithreading technique; Program segments	HEURISTIC-SEARCH; ALGORITHM DESIGN; CODE	Multicore processors that support multithreading techniques have many advantages, including processors' utilization, responsiveness, resource sharing, and economical usage of threads. Thus, to have these advantages, programming languages must support multithreading programming. Unfortunately, this technique is not compatible with old programs since most of the old program codes have been prepared sequentially. Inevitably, this posed a challenge when attempts were made to convert old sequential codes into multithreading codes. Despite the existence of several approaches of multithreading, differences do exist in their overhead, efficiency, and speedup, thereby underpinning the need for further optimization. Thus, a chemical reaction optimizer demonstrates the efficacy of its optimization in several problems. Against this backdrop, this paper presents a chemical reaction optimizer for the multithreading scheduling (CROTS) technique that generates multithreaded code while considering a sequential one. CROTS technique has been evaluated using several performance metrics, such as the number of steps, execution time, speedup, efficiency, cost, and percentage of error. Experimental results show that the maximum speedup achieved by CROTS is 11.98 upon the usage of 32 threads, with an average percentage of error being 14.56% in regard to the comparison between experimental and analytical cost results. Furthermore, after comparing CROTS with intermediate representation based on diKernel (KIR), it has been established that it can accommodate more threads and attain greater speedup. For example, the experiments show that when applying both approaches CROTS and KIR using 32 threads on dataset M7000, CROTS attains a speedup of 11.71, that is, about tripled the speedup achieved by KIR, which is 3.77.																	1432-7643	1433-7479															10.1007/s00500-020-05334-4		SEP 2020											
J								Modified flower pollination algorithm for optimizing FOPID controller and its application with the programmablen-level inverter using fuzzy logic	SOFT COMPUTING										Multilevel inverter; Converter; Buck-boost converter; Optimization problem; Bio-inspired algorithm; Harmonics	MULTILEVEL INVERTER; REDUCED NUMBER; DESIGN; TOPOLOGIES; CONVERTER	Ann-level multilevel inverter for PV connected systems is proposed in this paper. The proposed inverter is the combination of a buck-boost converter and an H-bridge inverter ((BH)-H-2 multilevel inverter). This system produces a constant AC output voltage with multilevels for a PV connected system with few number of switches. With the proposed inverter, the constant output voltage level is obtained from the PV system irrespective of the variable irradiance. Any number of levels is achieved by varying the duty cycle of the buck-boost converter over a wide range using an n-level generation algorithm. Thus, many numbers of levels can be attained in the output voltage which reduces the THD significantly. The voltage regulation process is performed by designing an optimized fractional-order proportional integral and derivative (FOPID) controller. The FOPID controller provides improved voltage regulation characteristics through the optimization of parameters of controller with the use of modified flower pollination algorithm. The proposed configuration is designed and implemented in MATLAB Simulink. The quality of output, their harmonics and the output resolution time are evaluated for various input voltages and for various numbers of output levels.																	1432-7643	1433-7479															10.1007/s00500-020-05305-9		SEP 2020											
J								A semantic-enabled and context-aware monitoring system for the internet of medical things	EXPERT SYSTEMS										context-awareness; medical connected objects; ontology; patient monitoring	HEALTH-CARE; ONTOLOGY; IOT; DEVICES; REVOLUTION; SENSORS; OQUARE	The emergence of the Internet of Things (IoT) in the medical field has led to the massive deployment of a myriad of medical connected objects (MCOs). These MCOs are being developed and implemented for remote healthcare monitoring purposes including elderly patients with chronic diseases, pregnant women, and patients with disabilities. Accordingly, different associated challenges are emerging and include the heterogeneity of the gathered health data from these MCOs with ever-changing contexts. These contexts are relative to the continuous change of constraints and requirements of the MCOs deployment (time, location, state). Other contexts are related to the patient (medical record, state, age, sex, etc.) that should be taken into account to ensure a more precise and appropriate treatment of the patient. These challenges are difficult to address due to the absence of a reference model for describing the health data and their sources and linking these data with their contexts. This article addresses this problem and introduces a semantic-based context-aware system (IoT Medicare system) for patient monitoring with MCOs. This system is based on a core domain ontology (HealthIoT-O), that is, designed to describe the semantic of heterogeneous MCOs and their data. Moreover, an efficient interpretation and management of this knowledge in diverse contexts are ensured through SWRL rules such as the verification of the proper functioning of the MCOs and the analysis of the health data for diagnosis and treatment purposes. A case study of gestational diabetes disease management is proposed to evaluate the effectiveness of the implemented IoT Medicare system. An evaluation phase is provided and focuses on the quality of the elaborated semantic model and the performance of the system.																	0266-4720	1468-0394														e12629	10.1111/exsy.12629		SEP 2020											
J								Short-text feature expansion and classification based on nonnegative matrix factorization	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										correlation; feature extension; nonnegative matrix factorization; short text classification		In this paper, a non-negative matrix factorization feature expansion (NMFFE) approach was proposed to overcome the feature-sparsity issue when expanding features of short-text. First, we took the internal relationships of short texts and words into account when segmenting words from texts and constructing their relationship matrix. Second, we utilized the Dual regularization non-negative matrix tri-factorization (DNMTF) algorithm to obtain the words clustering indicator matrix, which was used to get the feature space by dimensionality reduction methods. Thirdly, words with close relationship were selected out from the feature space and added into the short-text to solve the sparsity issue. The experimental results showed that the accuracy of short text classification of our NMFFE algorithm increased 25.77%, 10.89%, and 1.79% on three data sets: Web snippets, Twitter sports, and AGnews, respectively compared with the Word2Vec algorithm and Char-CNN algorithm. It indicated that the NMFFE algorithm was better than the BOW algorithm and the Char-CNN algorithm in terms of classification accuracy and algorithm robustness.																	0884-8173	1098-111X															10.1002/int.22290		SEP 2020											
J								Rapid quantification of constituents in tobacco by NIR fiber-optic probe	JOURNAL OF CHEMOMETRICS										chemometrics; fiber-optic probe; NIR autosampler; tobacco	NEAR-INFRARED-SPECTROSCOPY; GREEN; LEAVES; SUGAR	This study aims to develop, evaluate, and optimize the application of near-infrared spectroscopy (NIR) autosampler device equipped with a fiber-optic probe associated with chemometric methods for the fast quantification of routine chemical constituents such as total alkaloids, reducing sugars, nitrate, and ammonia in tobacco. For this purpose, an NIR autosampler device with capacity for 40 samples was used. The spectra were collected in the range of 950 to 2,500 nm, with three spins on the sample, a 3.0-cm(2)sample scanning area, and 2.0 +/- 0.2 mm distance between the fiber-optic probe and the sample. Four partial least-squares (PLS) models were developed, and different preprocessing methods were investigated. The predicted results were compared with those obtained from the reference method (continuous-flow analysis), and root mean square error of prediction values of 0.31%, 1.27%, 0.47%, and 0.026% were obtained for total alkaloids, reducing sugars, nitrate, and ammonia, respectively. The proposed method performed well for the analysis of total alkaloids and reducing sugars with an appropriate goodness-of-fit and fair precision. In conclusion, considering the performance of the regression models and the associated environmental and economic advantages, the application of NIR spectrometer autosampler device equipped with a fiber-optic probe associated with a PLS and synergy interval PLS algorithms cannot replace the reference method, but it is a promising tool for tobacco monitoring.																	0886-9383	1099-128X														e3303	10.1002/cem.3303		SEP 2020											
J								A smartly designed automated map based clustering algorithm for the enhanced diagnosis of pathologies in brain MR images	EXPERT SYSTEMS										medical image analysis; modified fuzzy entropy clustering; self-organizing map; tissue segmentation; tumours and lesion identification	MULTIPLE-SCLEROSIS LESIONS; SEGMENTATION; ENTROPY; TISSUE; TUMOR; IDENTIFICATION; INFORMATION; FLAIR	The competitive segmentation of fuzzy clustering is utilized in a greater manner to deal with the local spatial information of input medical images. Fuzzy clustering favours lesions and tumour identification through the segmentation process where less accuracy attainment and time complexity might be instigated for the identification of oddities. To rectify the above-said problems, a novel methodology that encapsulates the combination of unsupervised neural network and fuzzy clustering processes, which effortlessly distinguishes the lesion and tumour region in MR brain images is developed through this study. The initial process of the proposed algorithm employs the histogram-based feature extraction of the input images; whereof, a feature vector selection is made for the operation of self-organizing map (SOM), which is a neural network functionary that progresses through the mapping process. Modification regarding the membership function of fuzzy entropy clustering (MFEC) is done based on the entropy value of the input image that results in quicker convergence. Finally, the updated objective function of MFEC algorithm augments the SOM result. It is found that the proposed SOM based MFEC algorithm is superior to other traditional segmentation algorithms, which have rendered the better visible understanding of the image. Further, the end-results of the algorithm are verified through the evaluation of quantity metrics using ground truth of the brain MR images. The proposed SOM based MFEC algorithm precisely provides 82.26% of Jaccard value and 90.05% of Dice Overlap Index value, and these values prove better brain slices segmentation and provide enormous help to radiologists during patient diagnosis.																	0266-4720	1468-0394														e12625	10.1111/exsy.12625		SEP 2020											
J								An intelligent nonintrusive load monitoring scheme based on 2D phase encoding of power signals	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										appliance identification; classification; feature extraction; nonintrusive load monitoring; phase encoding	MICRO-MOMENTS; CLASSIFICATION; TRANSFORM	Nonintrusive load monitoring (NILM) is the de facto technique for extracting device-level power consumption fingerprints at (almost) no cost from only aggregated mains readings. Specifically, there is no need to install an individual meter for each appliance. However, a robust NILM system should incorporate a precise appliance identification module that can effectively discriminate between various devices. In this context, this paper proposes a powerful method to extract accurate power fingerprints for electrical appliance identification. Rather than relying solely on time-domain (TD) analysis, this framework abstracts the phase encoding of the TD description of power signals using a two-dimensional (2D) representation. This allows mapping power trajectories to a novel 2D binary representation space, and then performing a histogramming process after converting binary codes to new decimal representations. This yields the final histogram of 2D phase encoding of power signals, namely, 2D-PEP. An empirical performance evaluation conducted with three realistic power consumption databases collected at distinct resolutions indicates that the proposed 2D-PEP descriptor achieves outperformance for appliance identification in comparison with other recent techniques. Accordingly, high identification accuracies are attained on the GREEND, UK-DALE, and WHITED data sets, where 99.54%, 98.78%, and 100% rates have been achieved, respectively, using the proposed 2D-PEP descriptor.																	0884-8173	1098-111X															10.1002/int.22292		SEP 2020											
J								Recency-based sequential pattern mining in multiple event sequences	DATA MINING AND KNOWLEDGE DISCOVERY										Data mining; Sequential pattern mining; Web clickstream analysis		The standard sequential pattern mining scheme hardly considers the positions of events in a sequence, and therefore it is difficult to focus on more interesting patterns that represent better the causal relationships between events. Without quantifying how close two events are in a sequence, we may fail to evaluate how likely an event is caused by the others from the pattern, which is a severe drawback for some applications like prediction. Motivated by this, we propose therecency-based sequential pattern miningscheme together with a novel measure of pattern interestingness to effectively capture recency as well asfrequency. To efficiently extract all the recency-based sequential patterns, we devise a mining algorithm, calledRecency-basedFrequent patternMiner(RF-Miner), together with an effective prediction method to evaluate the quality of recency-based patterns in terms of their prediction power. The experimental results show that ourRF-Mineralgorithm can extract more diverse and important patterns that can be used to make prediction of the next event, and can be more efficiently performed by using the upper bounds of our measure than baseline algorithms.																	1384-5810	1573-756X															10.1007/s10618-020-00715-7		SEP 2020											
J								A transductive transfer learning approach for image classification	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Machine learning; Unsupervised transfer learning; Cross-domain problems; Discriminative learning; Respective subspaces	DOMAIN ADAPTATION	Among machine learning paradigms, unsupervised transductive transfer learning is useful when no labeled data from the target domain are available at training time, but there is accessible unlabeled target data during training phase instead. The current paper proposes a novel unsupervised transductive transfer learning method to find the specific and shared features across the source and the target domains. The proposed learning method then maps both domains into the respective subspaces with minimum marginal and conditional distribution divergences. It is shown that the discriminative learning across domains leads to boost the model performance. Hence, the proposed method discriminates the classes of both domains via maximizing the distance between each sample-pairs with different labels and via minimizing the distance between each instance-pairs of the same classes. We verified our approach using standard visual benchmarks, with the average accuracy of 46 experiments as 76.5%, which rates rather high in comparison with other state-of-the-art transfer learning methods through various cross-domain tasks.																	1868-8071	1868-808X															10.1007/s13042-020-01200-9		SEP 2020											
J								GDPC: generalized density peaks clustering algorithm based on order similarity	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Clustering; Order similarity; Density; Density peak; Graph	K-NEAREST NEIGHBORS; FAST SEARCH; FIND	Clustering is a fundamental approach to discover the valuable information in data mining and machine learning. Density peaks clustering is a typical density based clustering and has received increasing attention in recent years. However DPC and most of its improvements still suffer from some drawbacks. For example, it is difficult to find peaks in the sparse cluster regions; assignment for the remaining points tends to cause Domino effect, especially for complicated data. To address the above two problems, we propose generalized density peaks clustering algorithm (GDPC) based on a new order similarity, which is calculated by the order rank of Euclidean distance between two samples. The order similarity can help us to find peaks in the sparse regions. In addition, a two-step assignment is used to weaken Domino effect. In general, GDPC can not only discover clusters in datasets regardless of different sizes, dimensions and shapes, but also address the above two issues. Several experiments on datasets, including Lung, COIL20, ORL, USPS, Mnist, breast and Vote, show that our algorithm is effective in most cases.																	1868-8071	1868-808X															10.1007/s13042-020-01198-0		SEP 2020											
J								Brain epilepsy seizure detection using bio-inspired krill herd and artificial alga optimized neural network approaches	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Brain informatics; Epilepsy; Electroencephalogram (EEG); Krill herd algorithm; Artificial alga optimized general adversarial networks	ALGORITHM	Nowadays, Epilepsy is one of the chronic severe neurological diseases; it has been identified with the help of brain signal analysis. The brain signals are recorded with the help of electrocorticography (ECoG), Electroencephalogram (EEG). From the brain signal, the abnormal brain functions are a more challenging task. The traditional systems are consuming more time to predict unusual brain patterns. Therefore, in this paper, effective bio-inspired machine learning techniques are utilized to predict the epilepsy seizure from the EEG signal with maximum recognition accuracy. Initially, patient brain images are collected by placing the electrodes on their scalp. From the brain signal, different features are extracted that are analyzed with the help of the Krill Herd algorithm for selecting the best features. The selected features are processed using an artificial alga optimized general Adversarial Networks. The network recognizes the intricate and abnormal seizure patterns. Then the discussed state-of-art methods are examined simulation results.																	1868-5137	1868-5145															10.1007/s12652-020-02520-y		SEP 2020											
J								A non-dominated sorting based customized random-key genetic algorithm for the bi-objective traveling thief problem	JOURNAL OF HEURISTICS										Combinatorial optimization; Multi-objective optimization; Real-world optimization problem; Traveling thief problem; NSGA-II	MEMETIC ALGORITHMS; OPTIMIZATION	In this paper, we propose a method to solve a bi-objective variant of the well-studied traveling thief problem (TTP). The TTP is a multi-component problem that combines two classic combinatorial problems: traveling salesman problem and knapsack problem. We address the BI-TTP, a bi-objective version of the TTP, where the goal is to minimize the overall traveling time and to maximize the profit of the collected items. Our proposed method is based on a biased-random key genetic algorithm with customizations addressing problem-specific characteristics. We incorporate domain knowledge through a combination of near-optimal solutions of each subproblem in the initial population and use a custom repair operator to avoid the evaluation of infeasible solutions. The bi-objective aspect of the problem is addressed through an elite population extracted based on the non-dominated rank and crowding distance. Furthermore, we provide a comprehensive study showing the influence of each parameter on the performance. Finally, we discuss the results of the BI-TTP competitions atEMO-2019andGECCO-2019conferences where our method has won first and second places, respectively, thus proving its ability to find high-quality solutions consistently.																	1381-1231	1572-9397															10.1007/s10732-020-09457-7		SEP 2020											
J								A steel surface defect inspection approach towards smart industrial monitoring	JOURNAL OF INTELLIGENT MANUFACTURING										Defect inspection; Object detection; Smart industrial monitoring; Steel surface; Deep learning	LOCAL BINARY PATTERNS; ARTIFICIAL-INTELLIGENCE; PREDICTION; CRACKS; WEAR	With the advance in Industry 4.0, smart industrial monitoring has been proposed to timely discover faults and defects in industrial processes. Steel is widely used in manufacturing equipment, and steel surface defect inspection is of great significance to the normal operation of steel equipment in manufacturing workshops. In steel defect inspection systems, industrial inspection robots generate images via scanning steel surface, and processors perform surface defect inspection algorithms on images. We focus on applying advanced object detection techniques to surface defect inspection algorithm for sheet steel. In the proposed steel surface defect inspection model, a deformable convolution enhanced backbone network firstly extracts complex features from multi-shape steel surface defects. Then the feature fusion network with balanced feature pyramid generates high-quality multi-resolution feature maps for the inspection of multi-size defects. Finally, detector network achieves the localization and classification of steel surface defects. The proposed model is evaluated on a typical steel surface defect dataset. Our model achieves 0.805 mAP, 0.144 higher than baseline models, and our model shows high efficiency in inference. Experiments are performed to reveal the effect of employed approaches, and results also show our model achieves a balance between inspection performance and inference efficiency.																	0956-5515	1572-8145															10.1007/s10845-020-01670-2		SEP 2020											
J								A bisector Line Field Approach to Interpolation of Orientation Fields	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Orientation fields; bisector line fields; polynomial interpolation; fingerprint analysis; singularities	FINGERPRINT ENHANCEMENT; IMAGE-RECONSTRUCTION; MODEL; COMPUTATION; DIFFUSION	We propose an approach to the problem of global reconstruction of an orientation field. The method is based on a geometric model calledbisector line fields, which maps a pair of vector fields to an orientation field, effectively generalizing the notion of doubling phase vector fields. Endowed with a well-chosen energy minimization problem, we provide a polynomial interpolation of a target orientation field while bypassing the doubling phase step. The procedure is then illustrated with examples from fingerprint analysis.																	0924-9907	1573-7683															10.1007/s10851-020-00990-5		SEP 2020											
J								Vertex covering problems of fuzzy graphs and their application in CCTV installation	NEURAL COMPUTING & APPLICATIONS										Graph theory; Fuzzy graph; Fuzzy number; Covering problem; Fuzzy optimization	OPERATIONS	In graph theory, a vertex covering set V-C is a set of vertices such that each edge of the graph is incident to at least one of the vertices of the set V-C. The problems related to vertex covering are called vertex covering problems. Many real-life problems contain a lot of uncertainties. To handle such uncertainties, concept of fuzzy set/graph is used. Here, we consider the covering problems of fuzzy graph to model some real-life problems. In this paper, a vertex covering problem is modeled as a series of linear and nonlinear programming problems with the help of basic graph-theoretic concept. In this model, the following objectives are considered: (1) the total number of facilities, the coverage area and total efficiency of all facilities are maximized, whereas (2) the total cost for the covering problem is minimized. Some new sets are defined and determined to make best decision on the basis of the features of facilities of the fuzzy system. An illustration is given to describe the whole model. Application of the said vertex covering problem to make a suitable decision for the placement of CCTVs in a city with the help of the developed formulations is given in a systematic way. To find the solutions, some algorithms are designed and the mathematical software 'LINGO' is used to keep the fuzziness of the parameters involved in the problems.																	0941-0643	1433-3058															10.1007/s00521-020-05324-5		SEP 2020											
J								A deep Q-learning portfolio management framework for the cryptocurrency market	NEURAL COMPUTING & APPLICATIONS										Deep reinforcement learning; Q-learning; Portfolio management; Dueling double deep Q-networks		Deep reinforcement learning is gaining popularity in many different fields. An interesting sector is related to the definition of dynamic decision-making systems. A possible example is dynamic portfolio optimization, where an agent has to continuously reallocate an amount of fund into a number of different financial assets with the final goal of maximizing return and minimizing risk. In this work, a novel deep Q-learning portfolio management framework is proposed. The framework is composed by two elements: a set of local agents that learn assets behaviours and a global agent that describes the global reward function. The framework is tested on a crypto portfolio composed by four cryptocurrencies. Based on our results, the deep reinforcement portfolio management framework has proven to be a promising approach for dynamic portfolio optimization.																	0941-0643	1433-3058															10.1007/s00521-020-05359-8		SEP 2020											
J								A New Robust Fuzzy Clustering Approach: DBKIFCM	NEURAL PROCESSING LETTERS										Fuzzy clustering; Outlier identification; Kernel function; FCM; IFCM; KIFCM; DOFCM	FAULT-DIAGNOSIS; SEGMENTATION; ALGORITHM	A clustering algorithm-Distance Based Gaussian Kernelized Intuitionistic Fuzzy C Means (DBKIFCM) is proposed. This algorithm is based on Gaussian kernel, outlier identification, and intuitionist fuzzy sets. It is intended to resolve the issue of presence of outliers, problem of sensitivity to initialization (STI) and is motivated by good performance of Radial Based Kernelized Intuitionistic Fuzzy C Means (KIFCM-RBF). Experiments are performed on standard 2D data sets such as Diamond (D12 and D15), and Dunn and real-world high dimension data sets such as Fisheriris, Wisconsin breast cancer, and Wine. DBKIFCM outcomes are studied in relation to Fuzzy C Means (FCM), Intuitionistic Fuzzy C Means (IFCM), KIFCM-RBF, Density Oriented Fuzzy C Means (DOFCM). It is observed that proposed approach significantly outperforms the earlier proposed algorithms with respect to outlier identification, effect of noise, issue of STI, and clustering error.																	1370-4621	1573-773X															10.1007/s11063-020-10345-1		SEP 2020											
J								Solar Radiation Estimation in Mediterranean Climate by Weather Variables Using a Novel Bayesian Model Averaging and Machine Learning Methods	NEURAL PROCESSING LETTERS										Bayesian model averaging; Ensemble method; Solar radiation; Wavelet; Artificial neural networks; Extreme learning machines; Radial basis function	SUPPORT VECTOR MACHINE; EMPIRICAL-MODELS; NEURAL-NETWORKS; TEMPERATURE; PREDICTION; PRECIPITATION	The present study investigated the potential of new ensemble method, Bayesian model averaging (BMA), in modeling monthly solar radiation based on climatic data. Data records covered monthly maximum temperature (T-max), minimum temperature (T-min), sunshine hours (H-s), wind speed (W-s), relative humidity (RH), and solar radiation values obtained from two weather stations of Turkey. The BMA estimates were compared with the artificial neural networks (ANN), extreme learning machines (ELM), radial basis function (RBF), and their hybrid versions with wavelet transform technique (wavelet-ANN or WANN, wavelet-ELM or WELM, and wavelet-RBF or WRBF). Three evaluation criteria e.g., root mean square error (RMSE), Nash-Sutcliffe efficiency, and determination coefficient (R-2), were applied to measure the accuracy of the employed methods. The results indicated the superior accuracy of the BMA4 models over six machine learning models for estimating monthly solar radiation; improvements in accuracy of ANN4, ELM4, RBF4, WANN4, WELM4, and WRBF4 models comprising T-max, T-min, H-s, W(s)and RH input variables were about 56-41%, 44-31%, 57-46%, 35-26%, 27-16%, and 43-28% in terms of RMSE reduction in both stations. While the hybrid models (i.e., WANN4, WELM4, and WRBF4) increased the accuracy of the single models about 31-21%, 23-18%, and 26-25% for ANN4, ELM4, and RBF4, respectively.																	1370-4621	1573-773X															10.1007/s11063-020-10350-4		SEP 2020											
J								Hybrid convolutional bidirectional recurrent neural network based sentiment analysis on movie reviews	COMPUTATIONAL INTELLIGENCE										bidirectional gated recurrent unit (BGRU); convolutional bidirectional recurrent neural network (CBRNN); sentiment analysis (SA)	SUPPORT VECTOR MACHINES; TEXT CLASSIFICATION; PREDICTION	Sentiment analysis is the process of extracting the opinions of customers from online reviews. In general, customers express their reviews in natural language. It becomes a complex task when applying sentiment analysis on those reviews. In earlier stages, word-level features with various feature weighting methods such as Bag of Words, TF-IDF, and Word2Vec were applied for sentiment analysis and deep learning networks are not explored much. We considered phrase level and sentence level features instead of applying word-level features for sentiment analysis and also enhanced by applying various deep learning techniques. In this article, we have proposed a hybrid convolutional bidirectional recurrent neural network model (CBRNN) by combining two-layer convolutional neural network (CNN) with a bidirectional gated recurrent unit (BGRU). In the proposed CBRNN model, the CNN layer extracts the rich set of phrase-level features and BGRU captures the chronological features through long term dependency in a multi-layered sentence. The proposed approach was evaluated on two benchmark datasets and compared with various baselines. The experimental results show that the proposed hybrid model provides better results than any other models with an F(1)score of 87.62% and 77.4% on IMDB and Polarity datasets,respectively. Our CBRNN model outperforms the state of the art by 2%-4% on these two datasets. It is also observed that, the time taken for training is slightly higher than the existing approaches with the substantial improvement in the performance.																	0824-7935	1467-8640															10.1111/coin.12400		SEP 2020											
J								TIRNet: Object detection in thermal infrared images for autonomous driving	APPLIED INTELLIGENCE										Thermal infrared images; Object detection; CNN		In the present study, towards reliable and efficient object detection in thermal infrared (TIR) images, we put forward a novel object detection approach, termed TIRNet, which is built upon convolutional neural network (CNN). Instead of using the deep CNN backbone (ResNet, ResNeXt) which suffers low speed and high computational cost, the lightweight feature extractor (VGG) is adopted. To get the robust and discriminating features for accurate box regression and classification, the Residual Branch is introduced. More uniquely, it only exists in the training phase, so no any additional time is increased when inference. All the computation is encapsulated in a single network, so our TIRNet can be optimized and tested in the manner of end-to-end. Furthermore, the continuous information fusion strategy is proposed for improving detection performance, which can effectively solve the problems such as complex background, occlusion, and get more accurate and smoother detection results. To get the real-world dataset and effectively evaluate the effectiveness, a China Thermal Infrared (CTIR) dataset is collected. Besides, we also evaluate our proposed approach on the public KAIST Multispectral dataset. As demonstrated in the comparative experiments, our approach gets the state-of-the-art detection accuracy while maintains high detection efficiency.																	0924-669X	1573-7497															10.1007/s10489-020-01882-2		SEP 2020											
J								A deep learning-based approach for the automated surface inspection of copper clad laminate images	APPLIED INTELLIGENCE										Machine vision; Defect detection; Deep learning; Convolutional neural network; Efficient network		Surface quality inspection and control are extremely important for electronic manufacturing. The use of machine vision technology to automatically detect the defects of products has become an indispensable means for better quality control. A machine vision-based surface quality inspection system is usually composed of two processes: image acquisition and automatic defect detection. In this paper, we propose a deep learning-based approach for the defect detection of Copper Clad Laminate (CCL) images acquired from an industrial CCL production line. In the proposed approach, a new convolutional neural network (CNN) that realizes fast defect detection while maintaining high accuracy is designed. Our proposed approach makes four contributions. First, we introduce the depthwise separable convolution to reduce the calculation time. Second, we improve the squeeze-and-excitation block to improve network performance. Third, we introduce the squeeze-and-expand mechanism to reduce the computation cost. Fourth, we employ a smoother activation function (Mish) to allow improved information flow. The proposed network is compared with the benchmark CNNs (including Inception, ResNet and MobileNet). The experimental results show that compared with the benchmark networks, our proposed network has achieved the best results regarding the accuracy and suboptimal results in terms of the speed compared with the benchmark networks. Therefore, our proposed method has been integrated into an industrial CCL production line as a guideline for online defective product rejection.																	0924-669X	1573-7497															10.1007/s10489-020-01877-z		SEP 2020											
J								Uncertain growth model for the cumulative number of COVID-19 infections in China	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Uncertain statistics; Uncertain regression analysis; Uncertain hypothesis test; COVID-19		As a type of coronavirus, COVID-19 has quickly spread around the majority of countries worldwide, and seriously threatens human health and security. This paper aims to depict cumulative numbers of COVID-19 infections in China using the growth model chosen by cross validation. The residual plot does not look like a null plot, so we can not find a distribution function for the disturbance term that is close enough to the true frequency. Therefore, the disturbance term can not be characterized as random variables, and stochastic regression analysis is invalid in this case. To better describe this pandemic automatically, this paper first employs uncertain growth models with the help of uncertain hypothesis tests to detect and modify outliers in data. The forecast value and confidence interval for the cumulative number of COVID-19 infections in China are provided.																	1568-4539	1573-2908															10.1007/s10700-020-09340-x		SEP 2020											
J								Adaptively Converting Auxiliary Attributes and Textual Embedding for Video Captioning Based on BiLSTM	NEURAL PROCESSING LETTERS										Video captioning; Bi-directional long short-term memory; Multiple-instance learning; Semantic fine-grained attributes; Attention mechanism; Conversion gate		Automatically generating captions for videos faces a huge challenge since it is a cross-modal cross task that involves vision and texts. Most of the existing models generate the captioning words merely based on the video visual content features, ignoring the important underlying semantic information. The relationship between explicit semantics and hidden visual content is not holistically exploited, thus hardly describing fine-grained caption accurately from a global view. To better extract and integrate the semantic information, we propose a novel encoder-decoder framework of bi-directional long short-term memory with attention model and conversion gate (BiLSTM-CG), which transfers auxiliary attributes and then generates detailed captioning. Specifically, we extract semantic attributes from sliced frames in a multiple-instance learning (MIL) manner. MIL algorithms attempt to learn a classification function that can predict the labels of bags and/or instances in the visual content. In the encoding stage, we adopt 2D and 3D convolutional neural networks to encode video clips, and then feed the concatenate features into a BiLSTM. In decoding stage, we design a CG to adaptively fuse semantic attributes into hidden features at word level, and a CG can convert auxiliary attributes and textual embedding for video captioning. Furthermore, the CG has an ability to automatically decide the optimal time stamp to capture the explicit semantic or rely on the hidden states of the language model to generate the next word. Extensive experiments conducted on the MSR-VTT and MSVD video captioning datasets demonstrate the effectiveness of our method compared with state-of-the-art approaches.																	1370-4621	1573-773X															10.1007/s11063-020-10352-2		SEP 2020											
J								A multi-scale and rotation-invariant phase pattern (MRIPP) and a stack of restricted Boltzmann machine (RBM) with preprocessing for facial expression classification	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Emotion; Pattern; Classification; Feature; Texton	EXTREME LEARNING-MACHINE; TEXTURE CLASSIFICATION; FACE; RECOGNITION; REPRESENTATION; QUANTIZATION; DATABASES; HISTOGRAM; KERNEL; SCHEME	In facial expression recognition applications, the classification accuracy decreases because of the blur, illumination and localization problems in images. Therefore, a robust emotion recognition technique is needed. In this work, a Multi-scale and Rotation-Invariant Phase Pattern (MRIPP) is proposed. The MRIPP extracts the features from facial images, and the extracted patterns are blur-insensitive, rotation-invariant and robust. The performance of classification algorithms like Fisher faces, Support Vector Machine (SVM), Extreme Learning Machine (ELM), Convolutional Neural Network (CNN) and Deep Neural Network (DNN) are analyzed. In order to reduce the time for classification, an OPTICS-based pre-processing of the features is proposed that creates a non-redundant and compressed training set to classify the test set. Ten-fold cross validation is used in experimental analysis and the performance metric classification accuracy is used. The proposed approach has been evaluated with six datasets Japanese Female Facial Expression (JAFFE), Cohn Kanade (CK +), Multi- media Understanding Group (MUG), Static Facial Expressions in the Wild (SFEW), Oulu-Chinese Academy of Science, Institute of Automation (Oulu-CASIA) and Man-Machine Interaction (MMI) datasets to meet a classification accuracy of 98.2%, 97.5%, 95.6%, 35.5%, 87.7% and 82.4% for seven class emotion detection using a stack of Restricted Boltzmann Machines(RBM), which is high when compared to other latest methods.																	1868-5137	1868-5145															10.1007/s12652-020-02517-7		SEP 2020											
J								Language identification from multi-lingual scene text images: a CNN based classifier ensemble approach	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Multi-lingual; Language identification; Scene text; CNN; Classifier combination	SCRIPT IDENTIFICATION; LOCALIZATION; VIDEO	Since the past two decades, detecting text regions in complex natural images has emerged as a problem of great interest for the research fraternity. This is because these regions of interest serve as source of information that can be utilized for various purposes. However, these regions may contain texts in multiple languages. Hence, identifying the corresponding language of a detected scene text becomes important for further information processing. Language identification of the text, captured in a wild, is an extremely challenging research field in the domain of scene text recognition. In this paper, a deep learning-based classifier combination approach is proposed to solve the problem of language identification from multi-lingual scene text images. In this work, a minimalist Convolutional Neural Network architecture is used as the base model. Five variants of an input image-three different channels of RGB color model (i.e. R for red, G for green and B for blue) along with RGB itself, and grayscale image are passed through the base model separately. The outcomes of these five models are combined using the classifier combination approaches based on sum rule and product rule. Performances of the proposed model have been evaluated on some standard datasets like KAIST and MLe2e as well as in-house multi-lingual scent text dataset. From the experimental results, it has been observed that the proposed model outperforms some state-of-the-art methods considered here for comparison.																	1868-5137	1868-5145															10.1007/s12652-020-02528-4		SEP 2020											
J								A unified generative model using generative adversarial network for activity recognition	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Activity recognition; Data generation; Generative adversarial network; Data augmentation		The recent advancement of deep learning methods has seen a significant increase in recognition accuracy in many important applications such as human activity recognition. However, deep learning methods require a vast amount of sensor data to automatically extract the most salient features for activity classification. Therefore, in this paper, a unified generative model is proposed to generate verisimilar data of different activities for activity recognition. The proposed generative model not only able to generate data that have a similar pattern, but also data with diverse characteristics. This allows for data augmentation in activity classification to improve the overall recognition accuracy. Three similarity measures are proposed to assess the quality of the synthetic data in addition to two visual evaluation methods. The proposed generative model was evaluated on a public dataset. The training data was prepared by systematically varying the combination of original and synthetic data. Results have shown that classification using the hybrid training data achieved a comparable recognition accuracy with the classification using the original training data. The performance of the classifiers maintained at the recognition accuracy of 85%.																	1868-5137	1868-5145															10.1007/s12652-020-02548-0		SEP 2020											
J								Flexible multipoint relay selection for suitable route in mobile ad hoc networks	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Ad hoc network; Suitable multipoint relay; Routing protocol; Tactical network; MANET	OLSR PROTOCOL	The dynamic formations of the mobile ad hoc networks require routing protocols to handle the routing requirements in run-time. The purpose of this work is to improve the endurance, quality, and trust of the path chosen by the link state routing in mobile ad hoc networks. The multipoint relay concept has been fascinating in link sate routing optimization to reduce duplicate retransmissions in the same region. In this paper, we present the notion of flexibility and suitability in choosing the multipoint relays. A suitable multipoint relay selection algorithm has been proposed to choose the appropriate multipoint relays which are trustworthy, restrain appropriate residual battery and possess a good quality link for interconnections. The algorithm also takes care of the willingness, reachability, degree, and the relative mobility of the nodes in the selection process. The results illustrate that the selection of the appropriate relay nodes offers substantial improvements.																	1868-5137	1868-5145															10.1007/s12652-020-02552-4		SEP 2020											
J								Live MPEG-DASH video streaming cache management with cognitive mobile edge computing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Live video streaming; Cognitive mobile edge computing; Forward error correction; Quality of experience; Convex optimization; Device-to-device		Video streaming is expected to account for up to 82% of network traffic by 2021 according to the forecast of CISCO's Visual Networking Index. Dynamic Adaptive Streaming over HTTP (DASH) is the de facto protocol for delivering video streaming services over the Internet. As the cellular network entering the 5G era, more and more video streaming will be live video streaming delivered to mobile phones. However, due to a large amount of video traffic, several techniques are required to improve the user Quality of Experience (QoE). In this work, we first propose a network architecture design for delivering live video streaming over the cellular core network with cognitive Mobile Edge Computing (MEC) servers. We then focused on the optimal cache management by considering several issues, include QoE, cache size, backhaul bandwidth, pre-cache mechanism, and user mobility. Finally, we show a prototype of the proposed MEC-assisted live video streaming system. Our simulation results show the performance improvement of the proposed cache management schemes in terms of QoE-based system utility. Our prototype shows the significant latency reduction in receiving video streams with MEC pre-cache mechanism.																	1868-5137	1868-5145															10.1007/s12652-020-02549-z		SEP 2020											
J								A comparison of combat genetic and big bang-big crunch algorithms for solving the buffer allocation problem	JOURNAL OF INTELLIGENT MANUFACTURING										Buffer allocation problem; Throughput maximization; Production lines; Combat genetic algorithm; Big bang-big crunch algorithm	TABU SEARCH APPROACH; EVOLUTIONARY ALGORITHM; PRODUCTION LINES; STORAGE SPACE; OPTIMIZATION; SYSTEMS; MACHINES; DESIGN; MAINTENANCE	The buffer allocation problem (BAP) aims to determine the optimal buffer configuration for a production line under the predefined constraints. The BAP is an NP-hard combinatorial optimization problem and the solution space exponentially grows as the problem size increases. Therefore, problem specific heuristic or meta-heuristic search algorithms are widely used to solve the BAP. In this study two population-based search algorithms; i.e. Combat Genetic Algorithm (CGA) and Big Bang-Big Crunch (BB-BC) algorithm, are proposed in solving the BAP to maximize the throughput of the line under the total buffer size constraint for unreliable production lines. Performances of the proposed algorithms are tested on existing benchmark problems taken from the literature. The experimental results showed that the proposed BB-BC algorithm yielded better results than the proposed CGA as well as other algorithms reported in the literature.																	0956-5515	1572-8145															10.1007/s10845-020-01647-1		SEP 2020											
J								A multilayer shallow learning approach to variation prediction and variation source identification in multistage machining processes	JOURNAL OF INTELLIGENT MANUFACTURING										Variation propagation; Skin Model Shapes; Virtual machining	SKIN MODEL SHAPES; ERRORS	Variation propagation modelling in multistage machining processes through use of analytical approaches has been widely investigated for the purposes of dimension prediction and variation source identification. Yet the variation prediction of complex features is non-trivial task to model mathematically. Moreover, the application of the variation propagation approaches and associated variation source identification techniques using Skin Model Shapes is unclear. This paper proposes a multilayer shallow neural network regression approach to predict geometrical deviations of parts given manufacturing errors. The neural network is trained on a simulated data, generated from machining simulation of a point cloud of a part. Further, given a point cloud data of a machined feature, the source of variation can be identified by optimally matching the deviation patterns of the actual surface with that of shallow neural network generated surface. To demonstrate the method, a two-stage machining process and a virtual part that has planar, cylindrical and torus features was considered. The geometric characteristics of machined features and the sources variation could be predicted at an error of 1% and 4.25%, respectively. This work extends the application of Skin Model Shapes in variation propagation analysis in multistage manufacturing.																	0956-5515	1572-8145															10.1007/s10845-020-01649-z		SEP 2020											
J								The Translator's Extended Mind	MINDS AND MACHINES										Extended mind; Computer-assisted translation; Machine translation; Translation memory	USER	The rapid development of natural language processing in the last three decades has drastically changed the way professional translators do their work. Nowadays most of them usecomputer-assisted translation(CAT) ortranslation memory(TM) tools whose evolution has been overshadowed by the much more sensational development ofmachine translation(MT) systems, with which TM tools are sometimes confused. These two language technologies now interact in mutually enhancing ways, and their increasing role in human translation has become a subject of behavioral studies. Philosophers and linguists, however, have been slow in coming to grips with these important developments. The present paper seeks to fill in this lacuna. I focus on the semantic aspects of the highly distributed human-computer interaction in the CAT process which presents an interesting case of anextended cognitive systeminvolving a human translator, a TM tool, an MT engine, and sometimes other human translators or editors. Considered as a whole, such a system is engaged in representing the linguistic meaning of the source document in the target language. But the roles played by its various components, natural as well as artificial, are far from trivial, and the division of linguistic labor between them throws new light on the familiar notions that were initially inspired by rather different phenomena in the philosophy of language, mind, and cognitive science.																	0924-6495	1572-8641															10.1007/s11023-020-09536-5		SEP 2020											
J								A hybridized intelligence model to improve the predictability level of strength index parameters of rocks	NEURAL COMPUTING & APPLICATIONS										Hybrid model; Sensitivity analysis; Metaheuristic algorithm; Strength index parameters; Predictability level	UNIAXIAL COMPRESSIVE STRENGTH; IMPERIALIST COMPETITIVE ALGORITHM; ELASTIC-MODULUS; OPTIMIZATION; PREDICTION; ASMARI	In the current paper, the uniaxial compressive strength (UCS) and Young modulus (E) of rocks were predicted using a hybridized intelligence method. The model was developed using an optimum multi-objective generalized feedforward neural network (GFFN) incorporated with an imperialist competitive metaheuristic algorithm (ICA) and managed using 208 datasets of different physical and mechanical quarries from almost all over of Iran. Rock class, density, porosity,P-wave velocity, point load index and water absorption were datacenter components. The predictability and accuracy performance of the hybridICA-GFFNmodel were discussed using different error criteria and confusion matrixes. The observed 5.4% and at least 32% improvement in hybridICA-GFFNthanGFFNand multivariate regression (MVR) demonstrated feasible and accurate enough tools that can effectively be applied for multi-objective prediction purposes. The influence of inputs on predicted outputs was also identified using two different sensitivity analyses.																	0941-0643	1433-3058															10.1007/s00521-020-05223-9		SEP 2020											
J								Effect of number of neurons and layers in an artificial neural network for generalized concrete mix design	NEURAL COMPUTING & APPLICATIONS										Artificial neural network; Performance; Decision making; Concrete; Mix design; Back-propagation		Selection of the number of neurons in different layers of an artificial neural network (ANN) is a key decision-making step involved in its successful training. Although the number of neurons in the input layer is decided by the number of input parameters, and similarly, in the output layer the number of neurons is fixed by the output parameters, however, the number of neurons in the hidden layer is not fixed, whereby the overall efficiency of the ANN depends upon the correct modeling of the realistic scenario in the form of a neural network. Concrete can be mixed in a huge variety of methods and compositions to achieve a specific or a combination of specific results. These results have been observed to repeat and follow patterns. Furthermore, for several types of concrete mixes, only actual physical trial data are available with no mix design method; this makes achieving different required results very complex and expensive task. Having an ANN to be able to predict a concrete mix to handle such variations will save a lot of time and money and will prove to be a universal mix design tool. A thorough analysis for deciding the number of neurons for mix design of concrete has been carried out in this research. The results of neural networks for a varying number of neurons and layers have been correlated. The data for a number of concrete mixes were sorted and normalized. Properties of concrete constituents like specific gravity of cement, coarse and fine aggregates, dry density of coarse and fine aggregates, cement type, type of mineral admixture, water-to-cement ratio, type and temperature of curing and hardened properties like compressive strength, modulus of elasticity and tensile strength were taken as input parameters. The contents of constituents of concrete such as water content, cement content, coarse aggregates content, fine aggregates content and content of mineral admixtures are regarded as output parameters. For 17 inputs and 5 outputs, it has been discovered that simple neural network with single or double hidden layers performed better that 3 or more such layers.																	0941-0643	1433-3058															10.1007/s00521-020-05305-8		SEP 2020											
J								Exploring the best sequence LSTM modeling architecture for flood prediction	NEURAL COMPUTING & APPLICATIONS										Recurrent neural network; Hydrologic analysis; Sequence modeling; Long short-term memory network	RUNOFF; NETWORKS	Accurate and efficient models for rainfall-runoff (RR) simulations are crucial for flood risk management. Recently, the success of the recurrent neural network (RNN) applied to sequential models has motivated groups to pursue RR modeling using RNN. Existing RNN based methods generally use either sequence input single output or unsynced sequence input and output architectures. In this paper, we propose a synced sequence input and output long short-term memory (LSTM) network architecture for hydrologic analysis and compare it to existing methods (sequence input single output LSTM). We expect the model will improve RR prediction in terms of accuracy, calibration training time, and computational cost. The key idea is to efficiently learn the long term dependency of runoff on past rainfall history. To be more specific, we use the indigenous ability of the LSTM network to preserve long term memory instead of artificially setting a time window for input data. In this way, we can avoid losing long term memory of the input, the calibration of the time window length, and excessive computation. The whole procedure mimics the traditional process-driven methods and is closer to the physics interpretation of the RR process. We conducted experiments on real-world hydrologic data from the Brays Bayou in Houston, Texas. Extensive experimental results clearly validate the effectiveness of our proposed method in terms of various statistical and hydrological related evaluation metrics. Notably, our experiment shows that some rainfall events could affect the runoff process in the test watershed for at least a week. For fine temporal resolution prediction, this long term effect needs to be carefully handled, and our proposed method is superior in this case.																	0941-0643	1433-3058															10.1007/s00521-020-05334-3		SEP 2020											
J								A universal closed-loop brain-machine interface framework design and its application to a joint prosthesis	NEURAL COMPUTING & APPLICATIONS										Brain-machine interface; Closed-loop framework; Artificial sensory feedback; Auxiliary controller; Application experiment	PREDICTIVE CONTROL; MODELS; CORTEX	Brain-machine interface (BMI) system offers the possibility for the brain communicating with external devices (such as prostheses) according to the electroencephalograms, but there are few BMI frameworks available for flexible design systems. In this paper, first of all, inspired by the single-joint information transmission (SJIT) model, a Wiener-filter-based decoder and an auxiliary controller based on model predictive control strategy are designed to rebuild the information pathways between the brain and prosthesis. Specifically, the decoder is used to decode the neuron activities from cerebral cortex, and the auxiliary controller is used to calculate control inputs, which injected to the SJIT model as feedback information. Then, a universal closed-loop BMI framework available for designing flexible systems is proposed and formulated on the basis of the brain model, decoder, auxiliary controller and prosthesis, and it can well recovery the motor function of prosthesis. Finally, a simulation and another experiment are designed to show that the presented closed-loop BMI framework is feasible and can track the target trajectory accurately, and the presented framework with actual prosthesis can successfully achieve the target position along the target trajectory.																	0941-0643	1433-3058															10.1007/s00521-020-05323-6		SEP 2020											
J								Hybrid bio-inspired algorithm and convolutional neural network for automatic lung tumor detection	NEURAL COMPUTING & APPLICATIONS										Medical imaging; Artificial intelligence; Feature extraction; Hybrid WOA_APSO; Convolutional neural network	ORIENTED GENETIC ALGORITHM; CANCER; SEGMENTATION; CLASSIFICATION; OPTIMIZATION; FEATURES; FUSION	In this paper, we have proposed a hybrid bio-inspired algorithm which takes the merits of whale optimization algorithm (WOA) and adaptive particle swarm optimization (APSO). The proposed algorithm is referred as the hybrid WOA_APSO algorithm. We utilize a convolutional neural network (CNN) for classification purposes. Extensive experiments are performed to evaluate the performance of the proposed model. Here, pre-processing and segmentation are performed on 120 lung CT images for obtaining the segmented tumored and non-tumored region nodule. The statistical, texture, geometrical and structural features are extracted from the processed image using different techniques. The optimized feature selection plays a crucial role in determining the accuracy of the classification algorithm. The novel variant of whale optimization algorithm and adaptive particle swarm optimization, hybrid bio-inspired WOA_APSO, is proposed for selecting optimized features. The feature selection grouping is applied by embedding linear discriminant analysis which helps in determining the reduced dimensions of subsets. Twofold performance comparisons are done. First, we compare the performance against the different classification techniques such as support vector machine, artificial neural network (ANN) and CNN. Second, the computational cost of the hybrid WOA_APSO is compared with the standard WOA and APSO algorithms. The experimental result reveals that the proposed algorithm is capable of automatic lung tumor detection and it outperforms the other state-of-the-art methods on standard quality measures such as accuracy (97.18%), sensitivity (97%) and specificity (98.66%). The results reported in this paper are encouraging; hence, these results will motivate other researchers to explore more in this direction.																	0941-0643	1433-3058															10.1007/s00521-020-05362-z		SEP 2020											
J								Black-box combinatorial optimization using models with integer-valued minima	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										Surrogate models; Bayesian optimization; Black-box optimization	DISCRETE OPTIMIZATION	When a black-box optimization objective can only be evaluated with costly or noisy measurements, most standard optimization algorithms are unsuited to find the optimal solution. Specialized algorithms that deal with exactly this situation make use of surrogate models. These models are usually continuous and smooth, which is beneficial for continuous optimization problems, but not necessarily for combinatorial problems. However, by choosing the basis functions of the surrogate model in a certain way, we show that it can be guaranteed that the optimal solution of the surrogate model is integer. This approach outperforms random search, simulated annealing and a Bayesian optimization algorithm on the problem of finding robust routes for a noise-perturbed traveling salesman benchmark problem, with similar performance as another Bayesian optimization algorithm, and outperforms all compared algorithms on a convex binary optimization problem with a large number of variables.																	1012-2443	1573-7470															10.1007/s10472-020-09712-4		SEP 2020											
J								Batch Bayesian optimization via adaptive local search	APPLIED INTELLIGENCE										Batch Bayesian optimization; Adaptive local search; Parallel search; Hyperparameter tuning	GLOBAL OPTIMIZATION; GAUSSIAN PROCESS; NEURAL-NETWORKS; ROBUST; DESIGNS	Bayesianoptimization (BO) provides an efficient tool for solving the black-box global optimization problems. Under situations where multiple points can be evaluated simultaneously, batch Bayesian optimization has been a popular extension by taking full use of the computational and experimental resources. In this paper, an adaptive local search strategy is investigated to select batch points for Bayesian optimization. First, multi-start strategy and gradient-based optimization method are combined to maximize the acquisition function. Then, an automatic cluster approach (e.g., X-means) is applied to adaptively identify the acquisition function's local maxima from the gradient-based optimization results. Third, the Bayesian stopping criterion is utilized to guarantee all the local maxima can be obtained theoretically. Moreover, the lower bound confidence criterion and frontend truncation operation are employed to select the most promising local maxima as batch points. Extensive evaluations on various synthetic functions and two hyperparameter tuning problems for deep learning models are utilized to verify the proposed method.																	0924-669X	1573-7497															10.1007/s10489-020-01790-5		SEP 2020											
J								An archetype for evolving dynamics of primitive human culture	EVOLVING SYSTEMS										Dynamical processes; Inter-cultural interaction; Inheritance; Cultural diversity; Global polarisation; Colonization	EVOLUTION	From the very beginning, human civilizations have evolved and spread across the surface of the planet Earth through various dynamical processes such as growth, assimilation, invasion, aggression, and annihilation. Such processes being responsible for expansion, integration, destruction, and reconstruction of civilizations, used to play key roles in the tides of time and fabric today's multicultural societies. A culture, being an inherent entity of human civilization, also evolves in conformity with civilizations. As such, the evolution of cultures can be understood as an artifact of such dynamical processes. How such dynamical processes initiate the diversification of cultures from small-scale simple societies? Why most of the cultures go extinct and why some survive for a comparatively longer period even after facing several wars and attacks? What plays a key role in creating a multicultural society? In order to partially answer all such highly stimulating questions, here we are interested in tackling the problem by giving importance to the nature of governing dynamical processes. Hence we perform a set of computer simulations on an archetypal model where a large number of independent and isolated primitive human cultures, being distributed randomly in a two-dimensional domain, are allowed to evolve following some historically-inspired rules for expansion, interaction, and merging processes among the cultures. As they evolve through inter-cultural interactions, the surviving cultures dynamically inherit the characteristics of their ancestors, leading to a well-mixed globally-polarise culture that emerges depending on the frequency and casualties of wars, consequences of coalescence, and similarity factors. From the ensuing simulation results, we find in accord with the historical fact that the rich diversity in a surviving culture is a consequence of all the dynamical processes that act repeatedly during its entire evolutionary track. We also visualize through our model how a global monocultural state and colonization among multicultural societies emerge separately in the modern period. We highlight a number of possible avenues for future research along these lines.																	1868-6478	1868-6486															10.1007/s12530-020-09355-0		SEP 2020											
J								Low-light enhancement based on an improved simplified Retinex model via fast illumination map refinement	PATTERN ANALYSIS AND APPLICATIONS										Image contrast enhancement; Illumination map refinement; Simplified retinex model	EXPOSURE IMAGE FUSION; CONTRAST ENHANCEMENT	Low-light enhancement is an important post-image-processing technique, as it helps to reveal hidden details from dark image regions. In this paper, we propose a fast low-light enhancement model, which is robust to various lighting conditions and imaging noise, and is computationally efficient. By using a fusion-based simplified Retinex model, our model caters to different lighting conditions. In the model, we propose an edge-preserving filter to efficiently refine the estimated illumination map. We also extend our model by equipping it with a very simple denoising step, which effectively prevents the over-boosting of imaging noise in the dark regions. We conduct the experiments on public available images as well as the ones collected by ourselves. Visual and quantitative results validate the effectiveness of our model.																	1433-7541	1433-755X															10.1007/s10044-020-00908-2		SEP 2020											
J								A dynamic approach for updating the lower approximation in adjustable multi-granulation rough sets	SOFT COMPUTING										Granular computing; Multi-granulation; Rough set; Lower approximation	ATTRIBUTE REDUCTION; RULE ACQUISITION; MULTIGRANULATION; MAINTENANCE	Granular computing (GrC) is one of the key issues in the field of information sciences. Research on the theory and algorithms of granular computing has very important practical significance in huge amounts of information. In multi-granulation rough set theory, two subsets are calculated to approximate the target concept, which are extremely time-consuming for large-scale data. In this paper, to address the issue above, we propose efficient algorithms for updating the lower approximation when a single object is added into or deleted from the target concept in an incomplete information system. Firstly, adjustable multi-granulation rough sets (AMGRSs) are introduced in an incomplete information system, and the related properties and theorems are explored. Secondly, it is proved that local-AMGRSs and AMGRSs are equivalent in an incomplete information system. Finally, dynamic algorithms for updating the lower approximation are proposed, and the efficiency of these algorithms is verified by an experiment.																	1432-7643	1433-7479				NOV	2020	24	21					15951	15966		10.1007/s00500-020-05323-7		SEP 2020											
J								Link prediction based on node weighting in complex networks	SOFT COMPUTING										Complex networks; Link prediction; Node-weighted networks; Social networks; Multi-criteria decision analysis (MCDA)	CENTRALITY	Link prediction is used to predict future links in complex networks. Traditional methods proposed for link prediction make estimates based on similarity measurements, taking into account only the instant topological structure of the network. However, especially in dynamic networks, the activity of nodes varies over time, so it is not enough to measure similarity from topological properties for a good prediction process. Accordingly, the success rate is low in prediction processes where the power of the nodes in the network is not sufficiently reflected. In this study, a novel link prediction model called "Link Prediction Based on Node Weighting in Complex Networks" is proposed to overcome the mentioned problems. Unlike using weights between nodes, the proposed model is based on calculating the own weights of the nodes and making the link prediction. The weighting process includes factors such as eigenvector centrality, experience, continuity that can reveal the power of nodes over time. The model consists of two parts. The first part is node weighting, which calculates the strength of nodes in the network. The second part is the node-weighted link prediction process, where node weights are used to predict future links. Scientific collaboration data at IEEE Xplore and Australian Open Tennis Tournaments data were used to test the success of the proposed model. In experimental studies conducted in networks created from different time periods, it has been determined that the proposed method gives more successful results than the latest technology methods according to the AUC metric.																	1432-7643	1433-7479															10.1007/s00500-020-05314-8		SEP 2020											
J								Comparison of synchronous and asynchronous parallelization of extreme surrogate-assisted multi-objective evolutionary algorithm	NATURAL COMPUTING										Evolutionary computation; Extreme learning machine; Multi-objective optimization; Parallelization; Surrogate model	GLOBAL OPTIMIZATION; GENETIC ALGORITHM; DIFFERENTIAL EVOLUTION; MOEA/D	This paper investigates the integration of a surrogate-assisted multi-objective evolutionary algorithm (MOEA) and a parallel computation scheme to reduce the computing time until obtaining the optimal solutions in evolutionary algorithms (EAs). A surrogate-assisted MOEA solves multi-objective optimization problems while estimating the evaluation of solutions with a surrogate function. A surrogate function is produced by a machine learning model. This paper uses an extreme learning surrogate-assisted MOEA/D (ELMOEA/D), which utilizes one of the well-known MOEA algorithms, MOEA/D, and a machine learning technique, extreme learning machine (ELM). A parallelization of MOEA, on the other hand, evaluates solutions in parallel on multiple computing nodes to accelerate the optimization process. We consider a synchronous and an asynchronous parallel MOEA as a master-slave parallelization scheme for ELMOEA/D. We carry out an experiment with multi-objective optimization problems to compare the synchronous parallel ELMOEA/D with the asynchronous parallel ELMOEA/D. In the experiment, we simulate two settings of the evaluation time of solutions. One determines the evaluation time of solutions by the normal distribution with different variances. On the other hand, another evaluation time correlates to the objective function value. We compare the quality of solutions obtained by the parallel ELMOEA/D variants within a particular computing time. The experimental results show that the parallelization of ELMOEA/D significantly reduces the computational time. In addition, the integration of ELMOEA/D with the asynchronous parallelization scheme obtains higher quality of solutions quicker than the synchronous parallel ELMOEA/D.																	1567-7818	1572-9796															10.1007/s11047-020-09806-2		SEP 2020											
J								The representational entity in physical computing	NATURAL COMPUTING										Unconventional computing; Bacterial computing; Representation		We have developed abstraction/representation (AR) theory to answer the question "When does a physical system compute?" AR theory requires the existence of arepresentational entity(RE), but the vanilla theory does not explicitly include the RE in its definition of physical computing. Here we extend the theory by showing how the RE forms a linked complementary model to the physical computing model. We show that the RE does not need to be a human brain, by demonstrating its use in the case of intrinsic computing in a non-human RE: a bacterium.																	1567-7818	1572-9796															10.1007/s11047-020-09805-3		SEP 2020											
J								Symbol positions-based Slepian-Wolf coding with application to distributed video coding	IET IMAGE PROCESSING										rate distortion theory; video coding; channel coding; source coding; decoding; encoder; channel coding operations; symbol positions-based Slepian-Wolf coding; efficient Slepian-Wolf coding; practical distributed video coding system; probable symbols; position-based SW coding; bitplane-based DVC system; fast parallel decoding	SIDE INFORMATION; BINARY SOURCES; COMPRESSION; MOTION; CODES	In this study, the authors will show that coding the positions of the symbols, instead of their values, can be a good way to implement efficient Slepian-Wolf (SW) coding and can reduce the complexity of both the encoder and the decoder. The authors will also propose a practical distributed video coding (DVC) system that exploits this idea. This system will use binary maps to indicate the positions of the most probable symbols, instead of separating them into bitplanes. Simulations show that this position-based SW coding allows a simple and more efficient DVC system with improved rate-distortion performance, compared to the bitplane-based DVC system that uses the same side information. The memory requirements at the encoder are reduced by about 50% and the number of channel coding operations is also reduced. This DVC system also allows to use an easy way to control quantisation, reduces the decoding latency, and allows fast parallel decoding.																	1751-9659	1751-9667				SEP 18	2020	14	11					2301	2309		10.1049/iet-ipr.2018.5942													
J								Novel image encryption by combining dynamic DNA sequence encryption and the improved 2D logistic sine map	IET IMAGE PROCESSING										cryptography; image processing; image coding; DNA; chaos; novel image encryption; improved 2D logistic sine map; one-dimensional chaotic encryption algorithm; good encryption performance; chaotic sequence; improved 2D logistic sine chaotic map; image encryption scheme; dynamic DNA sequences encryption; logistic map; 2D-LSMM chaotic sequences; implementing dynamic DNA sequence encryption; encryption process; authors; proper encryption	SCHEME; ALGORITHM; NETWORKS; SYSTEM	The one-dimensional (2D) chaotic encryption algorithm has good encryption performance. For its properties, such as the excellent complexity, pseudo-randomness, and sensitivity to the initial value of the chaotic sequence. However, compared with other methods, its biggest drawback is that the key space is too small. To address these problems, in this study, the authors introduce an improved 2D logistic sine chaotic map (2D-LSMM). A novel image encryption scheme based on dynamic DNA sequences encryption and improved 2D-LSMM is presented. The logistic map is used to control the input of the sine map. And the encoding and operation rules of DNA sequences are determined by 2D-LSMM chaotic sequences. By implementing dynamic DNA sequence encryption, the encryption process becomes more complicated and harder to be attacked. Simulation experimental results and security analysis show that the authors' encryption scheme not only achieves proper encryption but can also resist different attacks.																	1751-9659	1751-9667				SEP 18	2020	14	11					2310	2320		10.1049/iet-ipr.2019.1340													
J								Background subtraction using infinite asymmetric Gaussian mixture models with simultaneous feature selection	IET IMAGE PROCESSING										feature selection; inference mechanisms; mixture models; Bayes methods; learning (artificial intelligence); Gaussian processes; Gaussian distribution; variational inference methods; uninformative features; background subtraction task; infinite asymmetric Gaussian mixture models; simultaneous feature selection; image processing domains; related existing challenges; approximate exact data shapes; irrelevant features; statistical self-refinement framework; Dirichlet Process-based asymmetric Gaussian mixture model	VARIATIONAL INFERENCE	Mixture models are broadly applied in image processing domains. Related existing challenges include failure to approximate exact data shapes, estimate correct number of components, and ignore irrelevant features. In this study, the authors develop a statistical self-refinement framework for the background subtraction task by using Dirichlet Process-based asymmetric Gaussian mixture model. The parameters of this model are learned using variational inference methods. They also incorporate feature selection simultaneously within the framework to avoid noisy influence from uninformative features. To validate the proposed framework, they report their results on background subtraction tasks on 8 different datasets for infrared and visible videos.																	1751-9659	1751-9667				SEP 18	2020	14	11					2321	2332		10.1049/iet-ipr.2019.1029													
J								Robust palmprint identification using efficient enhancement and two-stage matching technique	IET IMAGE PROCESSING										image matching; feature extraction; palmprint recognition; fingerprint identification; image enhancement; graph theory; robust palmprint identification; efficient enhancement; two-stage matching technique; palmprint-based human authentication; civil security applications; forensic security applications; corporate security applications; palmprint recognition systems; palmprint sizes; matching phases; enhancement approach; minutia features; high-quality regions; local ridge characteristics; global minutiae neighbour; identification technique; palmprint enhancement; global minutiae neighbour-based matching technique; two-stage local minutiae neighbour-based matching technique; open-source algorithms; equal error rate; detection error trade-off graph	FINGERPRINT; ALGORITHM	Palmprint-based human authentication has shown great potential for civil, forensic, and corporate security applications in recent years. Palmprint recognition systems suffer because of large palmprint sizes and the presence of a large number of creases and erroneous minutiae that make the enhancement and matching phases a challenge. In this study, a novel approach is presented based on efficient enhancement and a two-stage matching technique that demonstrates highly accurate identification results. The enhancement approach extracts minutia features from high-quality regions based on local ridge characteristics. The selected minutiae are then matched using a two-stage local and global minutiae neighbour-based matching technique. To demonstrate the performance of the proposed technique, comparisons with open-source algorithms are made based on equal error rate and detection error trade-off graph. The results confirm the efficacy of proposed palmprint enhancement and identification technique.																	1751-9659	1751-9667				SEP 18	2020	14	11					2333	2342		10.1049/iet-ipr.2018.5736													
J								Conditional semi-fuzzyc-means clustering for imbalanced dataset	IET IMAGE PROCESSING										pattern classification; data mining; pattern clustering; fuzzy set theory; edge objects; image segmentation; pattern recognition; data mining; maximum fuzzy boundary; fuzzy partition results; hard partition; soft partition; conditional semifuzzy c-means clustering	IMAGE SEGMENTATION; RECOGNITION	Fuzzy c-means algorithms have been widely utilised in several areas such as image segmentation, pattern recognition and data mining. However, the related studies showed the limitations in facing imbalanced datasets. The maximum fuzzy boundary tends to be located on the largest cluster which is not desirable. The overall fuzzy partition results in false grouping of edge objects and weakens the compactness of cluster. It is important the clusters are delineated by the maximum fuzzy boundary. In this study, a semi-fuzzy c-means algorithm is proposed by combining hard partition and soft partition. This study aims to provide an effective partition for the edge objects, such that the compactness of cluster can be improved. The proposed algorithm integrates the semi-fuzzy c-means method with the size-insensitive integrity-based fuzzy c-means algorithm. In particular, the latter algorithm has the ability to deal with imbalanced data. With the experiment validation, the proposed algorithm is robust and outperforms the two component algorithms by using synthetic and widely known benchmark datasets.																	1751-9659	1751-9667				SEP 18	2020	14	11					2343	2355		10.1049/iet-ipr.2019.0253													
J								Physics-based dynamic texture analysis and synthesis model using GPU	IET IMAGE PROCESSING										video signal processing; computational complexity; image texture; graphics processing units; image-based approach; physics-based approach; different dynamic textures; dynamic texture videos; physics-based dynamic texture analysis; static texture		The texture is a repetition of a particular structure. Textures classified into static texture and dynamic texture. There are two approaches for synthesising dynamic textures: image-based approach and physics-based approach. In the proposed work, the synthesis of different dynamic textures is shown. The physics-based approach is used to synthesise dynamic texture videos. Different mathematical models are proposed which are suitable to give appropriate motion to the dynamic textures. The raw frames are created, and these frames are further used to synthesise the dynamic textures using physics laws and mathematical formulae. The flexibility of each model is demonstrated. The proposed model has less specificity and less computational complexity. The proposed algorithms are implemented on the graphics processing unit to reduce the overall execution time and time complexity. High-quality videos are produced, and the evaluation of every frame assures the quality.																	1751-9659	1751-9667				SEP 18	2020	14	11					2356	2364		10.1049/iet-ipr.2019.0984													
J								Sparse representation based computed tomography images reconstruction by coupled dictionary learning algorithm	IET IMAGE PROCESSING										medical image processing; image representation; diseases; image reconstruction; singular value decomposition; dictionaries; image resolution; brain; image denoising; computerised tomography; learning (artificial intelligence); sparse coupled dictionaries; sparse coefficients; image patches; HR image patch; LR image; conventional algorithms; different dictionary sizes; high-resolution image; HR images; computed tomography images reconstruction; coupled dictionary; high-resolution reconstruction-based methods; high-resolution images; image processing applications; image analysis; medical imaging; high-resolution computed tomography medical images; super-resolution method; CT medical images; sparse representation domain; K-singular value decomposition algorithm; dictionary learning purposes; low-resolution images; KSVD algorithm	SUPERRESOLUTION RECONSTRUCTION; QUALITY ASSESSMENT	It is very interesting to reconstruct high-resolution computed tomography (CT) medical images that are very useful for clinicians to analyse the diseases. This study proposes an improved super-resolution method for CT medical images in the sparse representation domain with dictionary learning. The sparse coupled K-singular value decomposition (KSVD) algorithm is employed for dictionary learning purposes. Images are divided into two sets of low resolution (LR) and high resolution (HR), to improve the quality of low-resolution images, the authors prepare dictionaries over LR and HR image patches using the KSVD algorithm. The main idea behind the proposed method is that sparse coupled dictionaries learn about each patch and establish the relationship between sparse coefficients of LR and HR image patches to recover the HR image patch for LR image. The proposed method is compared to conventional algorithms in terms of mean peak signal-to-noise ratio and structural similarity index measurements by using three different data set images, including CT chest, CT dental and CT brain images. The authors also analysed the proposed improved method for different dictionary sizes and patch size to obtain a similar high-resolution image. These parameters play an essential role in the reconstruction of the HR images.																	1751-9659	1751-9667				SEP 18	2020	14	11					2365	2375		10.1049/iet-ipr.2019.1312													
J								Feature channel enhancement for crowd counting	IET IMAGE PROCESSING										fuzzy set theory; feature extraction; feature channel enhancement; crowded visual space; crowd counting system; stable model; accurate robust model; feature channels; counting network; featured channel enhancement block; FCE; feature extraction unit; encoded channel information; positive characteristic channel; weak channel information; negative channel information		Crowd counting, i.e. count the number of people in a crowded visual space, is emerging as an essential research problem with public security. A key in the design of the crowd counting system is to create a stable and accurate robust model, which requires to process on the feature channels of the counting network. In this study, the authors present a featured channel enhancement (FCE) block for crowd counting. First, they use a feature extraction unit to obtain the information of each channel and encodes the information of each channel. Then use a non-linear variation unit to deal with the encoded channel information, finally, normalise the data and affixed to each channel separately. With the use of the FCE, the positive characteristic channel can be enhanced and weak or negative channel information can be suppressed. The authors successfully incorporate the FCE with two compact networks on the standard benchmarks and prove that the proposed FCE achieves promising results.																	1751-9659	1751-9667				SEP 18	2020	14	11					2376	2382		10.1049/iet-ipr.2019.1308													
J								Approach to model human appearance based on sparse representation for human tracking in surveillance	IET IMAGE PROCESSING										object detection; learning (artificial intelligence); image reconstruction; gradient methods; image colour analysis; face recognition; image sequences; image motion analysis; feature extraction; object tracking; video signal processing; image representation; minimal reconstruction error; target template; local appearance; varying illumination environment; robust tracking algorithm; fine representation; sparse code; image gradient orientation; local human appearance; human tracking algorithm; sparse representation-based human appearance model	ROBUST VISUAL TRACKING; OBJECT TRACKING; SELECTION; FILTER	In human tracking, sparse representation successfully localises the human in a video with minimal reconstruction error using target templates. However, the state-of-the-art approaches use colour and local appearance of a human to discriminate the human from the background regions, and hence fail when the human is occluded and appears in the varying illumination environment. In this study, a robust tracking algorithm is proposed that utilises gradient orientation and fine and coarse sparse representation of the target template. Sparse representation-based human appearance model utilises weighted gradient orientation that is insensitive to illumination variation. Coarse and fine representation of sparse code facilitates tracking under varying scales. Subspace learning from image gradient orientation is enforced with occlusion detection during the dictionary updation stage to capture the visual characteristics of the local human appearance that supports tracking under partial occlusion with lesser tracking error. The proposed human tracking algorithm is evaluated on various datasets and shows efficient human tracking performance when compared to the other state-of-the-art approaches. Furthermore, the proposed human tracking algorithm is suitable for surveillance applications.																	1751-9659	1751-9667				SEP 18	2020	14	11					2383	2394		10.1049/iet-ipr.2018.5961													
J								Multi-head mutual-attention CycleGAN for unpaired image-to-image translation	IET IMAGE PROCESSING										learning (artificial intelligence); realistic images; virtual reality; language translation; image processing; unpaired image-to-image translation; source image domain; multihead mutual-attention CycleGAN model; image size; multihead mutual-attention mechanism; photorealistic images; translation quality; long-range dependency modelling; MMA-CycleGAN architecture		The image-to-image translation, i.e. from source image domain to target image domain, has made significant progress in recent years. The most popular method for unpaired image-to-image translation is CycleGAN. However, it always cannot accurately and rapidly learn the key features in target domains. So, the CycleGAN model learns slowly and the translation quality needs to be improved. In this study, a multi-head mutual-attention CycleGAN (MMA-CycleGAN) model is proposed for unpaired image-to-image translation. In MMA-CycleGAN, the cycle-consistency loss and adversarial loss in CycleGAN are still used, but a mutual-attention (MA) mechanism is introduced, which allows attention-driven, long-range dependency modelling between the two image domains. Moreover, to efficiently deal with the large image size, the MA is further improved to the multi-head mutual-attention (MMA) mechanism. On the other hand, domain labels are adopted to simplify the MMA-CycleGAN architecture, so only one generator is required to perform bidirectional translation tasks. Experiments on multiple datasets demonstrate MMA-CycleGAN is able to learn rapidly and obtain photo-realistic images in a shorter time than CycleGAN.																	1751-9659	1751-9667				SEP 18	2020	14	11					2395	2402		10.1049/iet-ipr.2019.1153													
J								New flexible directional filter bank by tuning Hermite transform parameters for content based medical image retrieval	IET IMAGE PROCESSING										polynomials; filtering theory; content-based retrieval; visual databases; transforms; medical image processing; image retrieval; feature extraction; biomedical MRI; channel bank filters; new flexible directional filter bank; content based medical image retrieval; content-based medical image retrieval; imperative Hermite transform parameters; Hermite polynomial; flexible Hermite orthogonal basis; retrieval performance; 2D diamond shape filter; McClellan transformation; directional decomposition; directionally decomposed images; mean retrieval precision; medical image databases; magnetic resonance imaging	MCCLELLAN TRANSFORMATIONS; FEATURE DESCRIPTOR; EXTREMA PATTERN; CLASSIFICATION; DECOMPOSITION; EXTRACTION; TEXTURE; SYSTEMS; DESIGN	This study presents a flexible directional filter bank (DFB) by tuning Hermite transform parameters for content-based medical image retrieval (CBMIR). Two imperative Hermite transform parameters such as the scale of Gaussian kernel and the order of Hermite polynomial are tuned to adapt the flexible Hermite orthogonal basis to improve the retrieval performance of the CBMIR system. First, the tuned 1D Hermite filter transformed into 2D diamond shape filter by McClellan transformation and made it adequate for the directional decomposition of images using DFB structure. The dominant features of these directionally decomposed images are extracted by the rotation-invariant local neighbourhood frequency pattern. The mean retrieval precision is used as a high-level criterion to measure retrieval performance. The proposed method is assessed on three medical image databases: two for computed tomography and one for magnetic resonance imaging and achieved 99.41, 89.07, and 88.71% mean precision, respectively, when ten images are returned by the system.																	1751-9659	1751-9667				SEP 18	2020	14	11					2403	2416		10.1049/iet-ipr.2019.0252													
J								E2-capsule neural networks for facial expression recognition using AU-aware attention	IET IMAGE PROCESSING										learning (artificial intelligence); feature extraction; neural nets; emotion recognition; face recognition; AU-aware attention; traditional capsule neural network; dynamic routing; double enhanced capsule neural network; facial expression recognition; enhancement module; convolutional neural network; E2-capsule neural networks	SEQUENCES; FEATURES	Capsule neural network is a new and popular technique in deep learning. However, the traditional capsule neural network does not extract features sufficiently before the dynamic routing between capsules. In this study, one double enhanced capsule neural network (E2-Capsnet) that uses AU-aware attention for facial expression recognition (FER) is proposed. The E2-Capsnet takes advantage of dynamic routing between capsules and has two enhancement modules which are beneficial to FER. The first enhancement module is the convolutional neural network with AU-aware attention, which can focus on the active areas of the expression. The second enhancement module is the capsule neural network with multiple convolutional layers, which enhances the ability of the feature representation. Finally, the squashing function is used to classify the facial expression. The authors demonstrate the effectiveness of E2-Capsnet on the two public benchmark datasets, RAF-DB and EmotioNet. The experimental results show that their E2-Capsnet is superior to the state-of-the-art methods. The code is available athttps://github.com/ShanCao18/E2-Capsnet.																	1751-9659	1751-9667				SEP 18	2020	14	11					2417	2424		10.1049/iet-ipr.2020.0063													
J								ResDNN: deep residual learning for natural image denoising	IET IMAGE PROCESSING										Gaussian noise; convolution; image denoising; learning (artificial intelligence); neural nets; computer vision; deep residual learning; natural image denoising; thoroughly studied research problem; image processing; computer vision; deep convolution neural network; added benefits; convolution layers; ResNet blocks; rectified linear unit; end-to-end mappings; noise distorted images; deeper networks; learned abstractions	SPARSE REPRESENTATION; FILTER; DICTIONARIES; ALGORITHM	Image denoising is a thoroughly studied research problem in the areas of image processing and computer vision. In this work, a deep convolution neural network with added benefits of residual learning for image denoising is proposed. The network is composed of convolution layers and ResNet blocks along with rectified linear unit activation functions. The network is capable of learning end-to-end mappings from noise distorted images to restored cleaner versions. The deeper networks tend to be challenging to train and often are posed with the problem of vanishing gradients. The residual learning and orthogonal kernel initialisation keep the gradients in check. The skip connections in the ResNet blocks pass on the learned abstractions further down the network in the forward pass, thus achieving better results. With a single model, one can tackle different levels of Gaussian noise efficiently. The experiments conducted on the benchmark datasets prove that the proposed model obtains a significant improvement in structural similarity index than the previously existing state-of-the-art techniques.																	1751-9659	1751-9667				SEP 18	2020	14	11					2425	2434		10.1049/iet-ipr.2019.0623													
J								Acceleration of multi-task cascaded convolutional networks	IET IMAGE PROCESSING										face recognition; learning (artificial intelligence); object detection; probability; convolutional neural nets; convolutional neural network; human face detection architecture; cascaded structure; P-Net; computation time; weight pruning; channel pruning; self-fine-tuning method; NMS process; human face probabilities; NMS input boxes; face boxes; self-fine-tuned MTCNN; multitask cascaded convolutional networks		Multi-task cascaded convolutional neural network (MTCNN) is a human face detection architecture which uses a cascaded structure with three stages (P-Net, R-Net and O-Net). The authors intend to reduce the computation time of the whole process of the MTCNN. They find that the non-maximum suppression (NMS) processes after the P-Net occupy over half of the computation time. Therefore, the authors propose a self-fine-tuning method which makes the control of computation time for the NMS process easier. Self-fine-tuning is a training trick which uses hard samples generated by P-Net to retrain P-Net. After self-fine-tuning, the distribution of human face probabilities generated by P-Net is changed, and the tail of distribution becomes thinner. The control of the number of NMS input boxes can be made easier when the distribution has a thinner tail, and choosing a suitable threshold to filter the face boxes will generate less boxes. So the computation time can be reduced. In order to keep the performance of MTCNN, the authors still propose a landmark data set augmentation, which can enhance the performance of the self-fine-tuned MTCNN. From the experiments, it is found that the proposed scheme can significantly reduce the computation time of MTCNN.																	1751-9659	1751-9667				SEP 18	2020	14	11					2435	2441		10.1049/iet-ipr.2019.0141													
J								Detection, quantification and classification of ripened tomatoes: a comparative analysis of image processing and machine learning	IET IMAGE PROCESSING										learning (artificial intelligence); object detection; mobile robots; Hough transforms; image segmentation; image colour analysis; crops; feature extraction; image classification; robot vision; cameras; microcontrollers; industrial robots; ripened tomatoes; image processing; crop field; Cascaded Object Detector; Colour Transformation; Circular Hough Transformation; ripeness checking; colour thresholding; RGB colour; machine learning techniques; tomato field; machine learning method; Colour Segmentation Method	HOUGH TRANSFORM; COMPUTER VISION; FRUIT; RECOGNITION	In this study, specifically for the detection of ripe/unripe tomatoes with/without defects in the crop field, two distinct methods are described and compared from captured images by a camera mounted on a mobile robot. One is a machine learning approach, known as 'Cascaded Object Detector' (COD) and the other is a composition of traditional customised methods, individually known as 'Colour Transformation': 'Colour Segmentation' and 'Circular Hough Transformation'. The (Viola-Jones) COD generates 'histogram of oriented gradient' (HOG) features to detect tomatoes. For ripeness checking, the RGB mean is calculated with a set of rules. However, for traditional methods, colour thresholding is applied to detect tomatoes either from natural or solid background and RGB colour is adjusted to identify ripened tomatoes. This algorithm is shown to be optimally feasible for any micro-controller based miniature electronic devices in terms of its run time complexity ofO(n(3)) for a traditional method in best and average cases. Comparisons show that the accuracy of the machine learning method is 95%, better than that of the Colour Segmentation Method using MATLAB.																	1751-9659	1751-9667				SEP 18	2020	14	11					2442	2456		10.1049/iet-ipr.2019.0738													
J								Perceptual accessible image encryption scheme conjugating multiple chaotic maps	IET IMAGE PROCESSING										image colour analysis; image coding; chaos; cryptography; image processing; random permutation; 1D logistic map; tent maps; binary image; cover grey image; bit-plane decomposition methods; random initial conditions; key space high; colour space images; perceptual accessible image encryption scheme; multiple chaotic maps; recent decade; chaos-based image encryption algorithms; different colour space; feed forward initial condition	BINARY IMAGE	In the recent decade, chaos-based image encryption algorithms gained attention due to their pros and cons. The authors suggest one such algorithm of image encryption for different colour space using feed forward initial condition to pursue random permutation by combining 1D logistic map with a series of tent maps. The algorithm adds one more novel step to protect and encrypt binary image by concealing it within a cover grey image using bit-plane decomposition methods. Sensitivity towards initial condition is shown using block division of image by applying a stream of random initial conditions to each block for encryption along with XOR operation which leads the key space high (similar or equal to 2(484)). For better performance analysis, the proposed scheme has been tested with many colour space images including a binary image. The proposed technique is more efficient with respect to time complexity and resistance to vulnerability aspects.																	1751-9659	1751-9667				SEP 18	2020	14	11					2457	2468		10.1049/iet-ipr.2019.0527													
J								Automatic food recognition system for middle-eastern cuisines	IET IMAGE PROCESSING										feature extraction; genetic algorithms; diseases; image fusion; sugar; blood; particle swarm optimisation; image classification; medical image processing; object tracking; automatic tools; diabetics; intelligent food recognition; tracking system; mobile application; blood glucose level; glucose measuring sensors; feature extraction; classification techniques; early fusion techniques; genetic algorithm-based fusion; local middle-eastern food; automatic food recognition system; middle-eastern cuisines; healthier diet; daily food intake; particle swarm optimisation; large-scale dataset collection	CLASSIFICATION; SCALE	The concerns for a healthier diet are increasing day by day, especially in diabetics wherein the aim of healthier diet can only be achieved by keeping a track of daily food intake and glucose-level. As a consequence, there is an ever-increasing need for automatic tools able to help diabetics to manage their diet and also help physicians to better analyse the effects of various types of food on the glucose-level of diabetics. In this paper, we propose an intelligent food recognition and tracking system for diabetics, which is potentially an essential part of a mobile application that we propose to couple food intake with the blood glucose-level using glucose measuring sensors. For food recognition, we rely on several feature extraction and classification techniques individually and jointly using an early and three different late fusion techniques, namely (i) Particle Swarm Optimisation (PSO), (ii) Genetic Algorithms (GA) based fusion and (iii) simple averaging. Moreover, we also evaluate the performance of several handcrafted and deep features and compare the results against state-of-the-art. In addition, we collect a large-scale dataset containing images from several types of local Middle-Eastern food, which is intended to become a powerful support tool for future research in the domain.																	1751-9659	1751-9667				SEP 18	2020	14	11					2469	2479		10.1049/iet-ipr.2019.1051													
J								Dynamic gesture recognition based on feature fusion network and variant ConvLSTM	IET IMAGE PROCESSING										learning (artificial intelligence); video signal processing; feature extraction; gesture recognition; image classification; image fusion; recurrent neural nets; convolutional neural nets; image sequences; spatiotemporal phenomena; human computer interaction; variant ConvLSTM; human communication; human-computer interaction; dynamic gesture recognition method; deep learning; spatiotemporal feature extraction; gesture recognition architecture; feature fusion network; local aspects; global aspects; deep aspects; local spatiotemporal feature information; 3D residual network; channel feature fusion; global spatiotemporal information; multifeature fusion depthwise separable network; higher-level features; depth feature information; SKIG dataset; Sheffifield Kinect Gesture dataset; video sequence; gesture feature information; variant convolutional long short-term memory; Jester dataset; classification accuracies	CONVOLUTIONAL NEURAL-NETWORKS	Gesture is a natural form of human communication, and it is of great significance in human-computer interaction. In the dynamic gesture recognition method based on deep learning, the key is to obtain comprehensive gesture feature information. Aiming at the problem of inadequate extraction of spatiotemporal features or loss of feature information in current dynamic gesture recognition, a new gesture recognition architecture is proposed, which combines feature fusion network with variant convolutional long short-term memory (ConvLSTM). The architecture extracts spatiotemporal feature information from local, global and deep aspects, and combines feature fusion to alleviate the loss of feature information. Firstly, local spatiotemporal feature information is extracted from video sequence by 3D residual network based on channel feature fusion. Then the authors use the variant ConvLSTM to learn the global spatiotemporal information of dynamic gesture, and introduce the attention mechanism to change the gate structure of ConvLSTM. Finally, a multi-feature fusion depthwise separable network is used to learn higher-level features including depth feature information. The proposed approach obtains very competitive performance on the Jester dataset with the classification accuracies of 95.59%, achieving state-of-the-art performance with 99.65% accuracy on the SKIG (Sheffifield Kinect Gesture) dataset.																	1751-9659	1751-9667				SEP 18	2020	14	11					2480	2486		10.1049/iet-ipr.2019.1248													
J								Vanishing point detection using the teaching learning-based optimisation algorithm	IET IMAGE PROCESSING										image segmentation; pattern clustering; search problems; optimisation; computer vision; edge detection; TLBO algorithm; line segment detection; optimal vanishing point; nonorthogonal vanishing points; vanishing point detection; teaching learning-based optimisation algorithm; computer vision; image vanishing points; heuristic approach; metaheuristic search; population-based method; metaheuristic technique; teaching-learning process; computational cost	SCENES	Within the computer vision field, estimating image vanishing points has many applications regarding robotic navigation, camera calibration, image understanding, visual measurement, 3D reconstruction, among others. Different methods for detecting vanishing points relies on accumulator space techniques, while others employ a heuristic approach such as RANSAC. Nevertheless, these types of methods suffer from low accuracy or high computational cost. To explore a different technique, this paper focuses on improving the efficiency of the metaheuristic search for vanishing points by using a recently proposed population-based method: The Teaching Learning Based Optimisation algorithm (TLBO). The TLBO algorithm is a metaheuristic technique inspired by the teaching-learning process. In our method, the TLBO algorithm is used after a line segment detection, to cluster line segments according to their more optimal vanishing point. Thus, our algorithm detects both orthogonal and nonorthogonal vanishing points in real images. To corroborate the performance of our proposed algorithm, different comparison and tests with other approaches were carried out. The results validate the accuracy and efficiency of our proposed method. Our approach had an average computational time of1.42 seconds and obtained a cumulative focal length error of 1 pixel, and cumulative angular error of 0.1 degrees.																	1751-9659	1751-9667				SEP 18	2020	14	11					2487	2494		10.1049/iet-ipr.2019.0516													
J								Extreme learning machine with feature mapping of kernel function	IET IMAGE PROCESSING										pattern classification; learning (artificial intelligence); kernel function mapping space; ELM; feature mapping; FM-KELM; random FM; introduced kernel function; kernel-based extreme learning machine; faster learning speed; higher learning accuracy	ALGORITHM	Kernel-based extreme learning machine (KELM) solves the problem of random initialisation of extreme learning machine (ELM), and it has a faster learning speed and higher learning accuracy. However, when it comes to a scenario in which the dimensionality of kernel function mapping space is less than the number of samples, the kernel function theoretically cannot be introduced into ELM. To solve this problem, ELM with feature mapping (FM) of kernel function (FM-KELM) is proposed in this study, in which the random FM between the input layer and hidden layer of ELM is replaced with the FM of the kernel function. Moreover, the authors prove that when the regularised parameter C is close to zero, the solution of introduced kernel function is approximately equal to the correct solution. The proposed algorithm is more robust than KELM for the parameter C. Several experimental results show that the proposed algorithm in this study achieves higher classification accuracy without excessive parameter tuning, and the duration of the training and testing process is significantly reduced.																	1751-9659	1751-9667				SEP 18	2020	14	11					2495	2502		10.1049/iet-ipr.2019.1016													
J								Seed picking crossover optimisation algorithm for semantic segmentation from images	IET IMAGE PROCESSING										learning (artificial intelligence); image segmentation; pattern clustering; iterative methods; object recognition; image representation; image classification; optimisation; semantic image segmentation; object recognition; visually uniform regions; partitioned regions; pixel classification; segmented regions; semantic labels; low-level features; high-level contextual cues; minimum classification accuracy; nature-inspired meta-heuristic optimisation algorithm; semisegmentation process; simple linear iterative clustering algorithm; pixel transformation; pixel association; optimised CRFs; parametric optimisation; SPCO algorithm; seed picking crossover optimisation algorithm; conditional random field; CRF; linear iterative clustering algorithm; MSRC-21 dataset; Dirichlet process mixture model		Semantic image segmentation treats the issues involved in the object recognition and image segmentation as a combined task. The chief notion of semantic segmentation is to partition the image into visually uniform regions and to discriminate the class of the partitioned regions. Pixel classification is done over the segmented regions by assigning semantic labels. In general, inference frameworks are fed with the combination of low-level features and high-level contextual cues to segment an image. Since these combinations are rarely object consistent, result with minimum classification accuracy because of choosing non-influencing features and cues to track specific objects. To overcome this problem, a nature-inspired meta-heuristic optimization algorithm called Seed Picking Crossover Optimization (SPCO) is proposed to optimize i.e. train the CRF (Conditional Random Field) for choosing relevant feature to segment the object with high accuracy. To meritoriously recognize the objects, a semi-segmentation process is initially performed using Simple Linear Iterative Clustering (SLIC) algorithm. For pixel transformation and pixel association, Dirichlet process mixture model and CRF are employed. Optimized CRFs are used where the parametric optimization is done using the proposed SPCO algorithm. The proposed work results with 84% on classification accuracy and the performance evaluations are done using MSRC-21 dataset.																	1751-9659	1751-9667				SEP 18	2020	14	11					2503	2511		10.1049/iet-ipr.2019.1189													
J								A bi-directional fractional-order derivative mask for image processing applications	IET IMAGE PROCESSING										edge detection; differentiation; image denoising; image texture; gradient methods; de-noising problems; fractional useful operators; fractional edge images; image processing applications; fractional computation; two-dimensional fractional differentiation; one-dimensional Charef fractional differentiation extension; multidirectional mask; adaptive fractional-order computation; gradient computation properties; edge detection; bi-directional fractional-order derivative mask		Fractional computation has been recently designed as a major mathematical tool in image and signal processing fields. This study presents a novel operator established for two-dimensional fractional differentiation. It is developed based on the one-dimensional Charef fractional differentiation extension. A new multi-directional mask is proposed and a new adaptive fractional-order computation is introduced. The proposed method uses the gradient computation properties. It has been applied in edge detection and de-noising problems using real and synthetic images. Obtained results have been compared to those given by integer and fractional useful operators. Results demonstrate that the fractional edge images obtained using the proposed operator has more complete and clear contour information and more abundant texture detail information. The performances have been improved by the proposed method.																	1751-9659	1751-9667				SEP 18	2020	14	11					2512	2524		10.1049/iet-ipr.2019.0467													
J								Structure-texture image decomposition using a new non-local TV-Hilbert model	IET IMAGE PROCESSING										variational techniques; image texture; convex programming; minimisation; image denoising; proximal-based primal-dual algorithm; Chambolle-Pock's first-order primal-dual algorithm; convex-concave saddle-point problem; nonlocal TV-Hilbert minimisation problem; texture components; Gabor function; nonlocal total variation; nonlocal TV-Hilbert model; structure-texture image decomposition	TOTAL VARIATION MINIMIZATION	Combining the advantages of the non-local total variation (TV) and the Gabor function, a new Gabor function based non-local TV-Hilbert model is presented to separate the structure and texture components of the image. Computationally, by introducing the dual form of the non-local TV, the authors reformulate the non-local TV-Hilbert minimisation problem into a convex-concave saddle-point problem. In the aspect of solving algorithm, by transforming the Chambolle-Pock's first-order primal-dual algorithm into a different equivalent form. The authors propose a proximal-based primal-dual algorithm to solve the convex-concave saddle-point problem. At last, experimental results demonstrate that the proposed new model outperforms several existing state-of-the-art variational models.																	1751-9659	1751-9667				SEP 18	2020	14	11					2525	2531		10.1049/iet-ipr.2019.0392													
J								Comparative analysis of texture feature extraction techniques for rice grain classification	IET IMAGE PROCESSING										image texture; feature extraction; image classification; backpropagation; naive Bayes methods; neural nets; comparative analysis; texture feature extraction techniques; rice grain classification; various texture models; local texture feature extraction techniques; run length matrix; co-occurrence matrix; size zone matrix; neighbourhood grey tone difference matrix; wavelet decomposition; back propagation neural network; Brodatz texture data; BPNN classifier; linear discriminant classifier; Naive Bayes classifier; classification accuracy	MACHINE VISION SYSTEM; CEREAL-GRAINS; AUTOMATIC CLASSIFICATION; COMPUTER VISION; NEURAL-NETWORK; COLOR; QUALITY; IDENTIFICATION; CULTIVARS; WHEAT	Classifications of eight different varieties of rice grain are discussed in this study based on various texture models. Four local texture feature extraction techniques are proposed and three sets of texture features (SET-A, SET-B and SET-C) are formed, for the classification task. Performances of the proposed feature sets are compared with the existing techniques based on, run length matrix, co-occurrence matrix, size zone matrix, neighbourhood grey tone difference matrix and wavelet decomposition, towards classification of rice grain using a back propagation neural network (BPNN). The proposed techniques are also tested against publicly available data from Brodatz's texture data set and their results are compared with other techniques. The classification accuracy by the BPNN classifier is also compared with other statistical classifiers namely, K-nearest neighbour, linear discriminant classifier and Naive Bayes classifier. It is found that, the proposed feature sets yield better classification results on both rice data and Brodatz's data. Results show that, feature SET-B, is able to classify rice grain with an average classification accuracy of 99.63% with a minimum of six features.																	1751-9659	1751-9667				SEP 18	2020	14	11					2532	2540		10.1049/iet-ipr.2019.1055													
J								DeepJoint segmentation for the classification of severity-levels of glioma tumour using multimodal MRI images	IET IMAGE PROCESSING										image classification; biomedical MRI; tumours; neurophysiology; medical image processing; feature extraction; brain; image segmentation; convolutional neural nets; optimisation; cancer; oedema tumours; glioma tumour; multimodal MRI images; surgical planning; magnetic resonance imaging; brain tumour segmentation; normal brain tissues; treatment planning; multiclassifier; brain images; DeepJoint segmentation; fractional Jaya whale optimiser; deep convolutional neural network; glial cells	BRAIN MRI; TEXTURE; MACHINE	Brain tumour segmentation is the process of separating the tumour from normal brain tissues. A glioma is a kind of tumour, which fires up in the glial cells of the spine or the brain. This study introduces a technique for classifying the severity levels of glioma tumour using a novel segmentation algorithm, named DeepJoint segmentation and the multi-classifier. Initially, the brain images are subjected to pre-processing and the region of interest is extracted. Then, the segmentation of the pre-processed image is done using the proposed DeepJoint segmentation, which is developed through the iterative procedure of joining the grid segments. After the segmentation, feature extraction is carried out from core and oedema tumours using information-theoretic measures. Finally, the classification is done by the deep convolutional neural network (DCNN), which is trained by an optimisation algorithm, named fractional Jaya whale optimiser (FJWO). FJWO is developed by integrating the whale optimisation algorithm in fractional Jaya optimiser. The performance of the proposed FJWO-DCNN with the DeepJoint segmentation method is analysed using accuracy, true positive rate, specificity, and sensitivity. The results depicted that the proposed method produces a maximum accuracy of 96%, which indicates its superiority.																	1751-9659	1751-9667				SEP 18	2020	14	11					2541	2552		10.1049/iet-ipr.2018.6682													
J								Robust landmark-free head pose estimation by learning to crop and background augmentation	IET IMAGE PROCESSING										computer vision; learning (artificial intelligence); face recognition; image representation; neural nets; approximation theory; pose estimation; regression analysis; sufficient information; minimising background noise; box margin changes; convolutional cropping module; input image; attentional area; Background augmentation; face landmarking; convolutional neural network; landmark detection results; robust landmark-free head; crop; suitable bounding box margin		It is well known that the performance of head pose estimation is greatly affected by the bounding box margin of the face and its background. Traditionally, researchers will manually choose a suitable bounding box margin to strike a balance between ensuring sufficient information and minimising background noise. However, head pose estimation is still worse when the background is complex in reality or when the box margin changes slightly. To make estimation results more robust, the authors propose two methods to improve it: (i) a convolutional cropping module that can learn to crop the input image to an attentional area for head pose regression. (ii) Background augmentation that can make the network more robust to the background noise. Rather than using the face landmarking to calculate head pose angles, they use another convolutional neural network to regress the head pose angles, which is independent of the landmark detection results. They evaluate the method on BIWI and AFLW2000 dataset and experimental results show that their approach outperforms many other methods. Besides, they evaluate the method on Pointing'04 dataset using head pose accuracy. Furthermore, the approach is more robust and has a lower variance in realistic scenarios.																	1751-9659	1751-9667				SEP 18	2020	14	11					2553	2560		10.1049/iet-ipr.2019.1369													
J								Self-guided filter for image denoising	IET IMAGE PROCESSING										image denoising; filtering theory; image texture; exceptional edge-preserving filter; traditional guided filter; desired result; performing image denoising; clear guidance image; effective guided filter variant; single image noise; denoising strategy; weak textured patches based image noise estimation; clear intermediate image; local noise level; state-of-the-art local denoising methods		The guided filter has been acknowledged as an exceptional edge-preserving filter whose output is a locally linear transform of the guidance image. However, the traditional guided filter heavily relies on the guidance image and fails to achieve the desired result when performing image denoising without a clear guidance image. In this study, to address this limitation, the authors propose a simple yet effective guided filter variant for the single image noise removing. They further show that the proposed denoising strategy can be easily realised by using the iterative framework. Moreover, the weak textured patches based image noise estimation is utilised to generate a clear intermediate image which makes the proposed method highly adaptable to the local noise level. Experimental results demonstrate that their proposed algorithm can compete with the state-of-the-art local denoising methods in edge-preserving.																	1751-9659	1751-9667				SEP 18	2020	14	11					2561	2566		10.1049/iet-ipr.2019.1471													
J								SAR multi-target interactive motion recognition based on convolutional neural networks	IET IMAGE PROCESSING										target tracking; radar target recognition; image denoising; object detection; object recognition; synthetic aperture radar; signal denoising; feature extraction; radar imaging; wavelet transforms; neural nets; multitarget interactive motion type recognition method; target type recognition; SAR multitarget interactive motion recognition; synthetic aperture radar multitarget; multitarget motions; interactive motion feature extraction; SAR target images; target recognition	AUTOMATIC TARGET RECOGNITION	Synthetic aperture radar (SAR) multi-target interactive motion recognition classifies the type of interactive motion and generates descriptions of the interactive motions at the semantic level by considering the relevance of multi-target motions. A method for SAR multi-target interactive motion recognition is proposed, which includes moving target detection, target type recognition, interactive motion feature extraction, and multi-target interactive motion type recognition. Wavelet thresholding denoising combined with a convolutional neural network (CNN) is proposed for target type recognition. The method performs wavelet thresholding denoising on SAR target images and then uses an eight-layer CNN named EilNet to achieve target recognition. After target type recognition, a multi-target interactive motion type recognition method is proposed. A motion feature matrix is constructed for recognition and a four-layer CNN named FolNet is designed to perform interactive motion type recognition. A motion simulation dataset based on the MSTAR dataset is built, which includes four kinds of interactive motions by two moving targets. The experimental results show that the recognition performance of the authors' Wavelet + EilNet method for target type recognition and FolNet for multi-target interactive motion type recognition are both better than other methods. Thus, the proposed method is an effective method for SAR multi-target interactive motion recognition.																	1751-9659	1751-9667				SEP 18	2020	14	11					2567	2578		10.1049/iet-ipr.2019.0861													
J								Hybrid deep emperor penguin classifier algorithm-based image quality assessment for visualisation application in HDR environments	IET IMAGE PROCESSING										image processing; image colour analysis; computer displays; cathode-ray tubes; organic light emitting diodes; television displays; lighting; brightness; liquid crystal displays; neural nets; visualisation application; different visualisation applications; tone-mapped image; LCD display; OLED display; state-of-the-art image quality assessment methods; hybrid deep emperor penguin classifier algorithm-based image quality assessment; HDR environments; cathode ray tube monitor; liquid-crystal display; organic light-emitting diode; high dynamic range environs; different tone mapping operators; visualising HDR images; standard displays; different dynamic ranges; quality tone mapped image	NATURAL SCENE STATISTICS; REPRODUCTION; COMPRESSION	One of the main open challenges in visualisation applications such as cathode ray tube (CRT) monitor, liquid-crystal display (LCD), and organic light-emitting diode (OLED) display is the robustness for high dynamic range (HDR) environs. This is due to the imperfections in the sensor and the incapability to track interest points successfully because of the brightness constancy in visualisation applications. To address this problem, different tone mapping operators are required for visualising HDR images on standard displays. However, these standard displays have different dynamic ranges. Thus, there is a need for a new model to find the best quality tone mapped image for specific kinds of visualisation applications. The authors propose a hybrid deep emperor penguin classifier to accurately classify the tone mapped images for different visualisation applications. Here, a selective deep neural network is trained to predict the quality of a tone-mapped image. Based on this quality, a decision is made as to the suitability of the image for CRT monitor, LCD display or OLED display. Also, they evaluate the proposed model on the TMIQD database and the simulation results prove that the proposed model outperforms the state-of-the-art image quality assessment methods.																	1751-9659	1751-9667				SEP 18	2020	14	11					2579	2587		10.1049/iet-ipr.2019.1371													
J								Non-uniform image blind deblurring by two-stage fully convolution network	IET IMAGE PROCESSING										neural nets; parameter estimation; image restoration; nonuniform image blind deblurring; two-stage fully convolution network; deep neural networks; fully convolutional network; blur restored image; feed-forward pass; parameter estimation subnet P-net; pixel-wise parameters; multiple blur types; blur removal subnet G-net; high quality latent sharp image; PG-net; parameter estimation method; deblurring method	QUALITY ASSESSMENT; INFORMATION	Deep neural networks have recently demonstrated high performance for deblurring. However, few methods are designed for both non-uniform image blur estimation and removal with highly efficient. In this study, the authors proposed a fully convolutional network that outputs estimated blur and restored image in one feed-forward pass for the non-uniformly blurred image of any input-size. The proposed network contains two subnets. The parameter estimation subnet P-net predicts pixel-wise parameters of multiple blur types with high accuracy. The output of P-net is used as a condition, which guides the blur removal subnet G-net to restore a high quality latent sharp image. P-net and G-net are ultimately integrated into a single framework called PG-net, which guarantees the consistency of parameter estimation and blur removal, thereby improves algorithm efficiency. Experiment results show that the authors blur parameter estimation method as well as their deblurring method outperforms the comparison methods both quantitatively and qualitatively.																	1751-9659	1751-9667				SEP 18	2020	14	11					2588	2596		10.1049/iet-ipr.2018.5716													
J								Higher order PDE based model for segmenting noisy image	IET IMAGE PROCESSING										partial differential equations; image segmentation; image denoising; image colour analysis; unsupervised learning; Fourier spectral method; nonlinear PDE model; fourth-order non-linear partial differential equation; noisy greyscale image segmentation; unsupervised segmentation	ACTIVE CONTOURS; SEGMENTATION; CLASSIFICATION; MUMFORD; GRAPHS	In this study, a fourth-order non-linear partial differential equation (PDE) model together with multi-well potential has been proposed for greyscale image segmentation. The multi-well potential is constructed from the histogram of the given image to make the segmentation process fully automatic and unsupervised. Further, the model is refined for effective segmentation of noisy greyscale image. The fourth-order anisotropic term with the multi-well potential is shown to properly segment noisy images. Fourier spectral method in space with semi-implicit convexity splitting in time is used to derive an unconditionally stable scheme. Numerical studies on some standard test images and comparison of results with those in literature clearly depict the superiority of the anisotropic variant of the non-linear PDE model.																	1751-9659	1751-9667				SEP 18	2020	14	11					2597	2609		10.1049/iet-ipr.2019.0885													
J								Support vector machine classification combined with multimodal magnetic resonance imaging in detection of patients with schizophrenia	IET IMAGE PROCESSING										support vector machines; biomedical MRI; brain; medical image processing; multimodal magnetic resonance imaging; schizophrenia; schizophrenic patients; normal human brain avatar; complex environmental effects; traditional magnetic resonance imaging; brain information; support vector machine classification algorithm; multimodal MRI detection method; detection model; existing test cases; algorithm model; brain detection	QUALITATIVE RESEARCH; BODY-IMAGE; HEALTH; WOMEN	The brain avatar of schizophrenic patients is different from the normal human brain avatar, and it is difficult to overcome the complex environmental effects of the brain through traditional magnetic resonance imaging (MRI). In order to improve the accuracy of MRI in detecting brain information in patients with schizophrenia, this study is based on the support vector machine classification algorithm and combined with multimodal MRI detection method to construct a detection model suitable for patients with schizophrenia. In addition, this study combines the existing test cases to divide the brain into regions and design a comparative experiment to study the accuracy of the model proposed in this study. Finally, the study draws the results by sub-regional comparison. Studies have shown that the algorithm model of this study has certain effects on brain detection in patients with schizophrenia, and can be applied to practice, and can provide theoretical reference for subsequent related research.																	1751-9659	1751-9667				SEP 18	2020	14	11					2610	2615		10.1049/iet-ipr.2019.1108													
J								Unsupervised multiscale retinal blood vessel segmentation using fundus images	IET IMAGE PROCESSING										blood vessels; curvelet transforms; medical image processing; eye; image segmentation; image enhancement; wavelet transforms; biomedical optical imaging; diseases; unsupervised multiscale retinal blood vessel segmentation; retinal disease; structural changes; rule-based retinal blood vessel segmentation algorithm; directional-wavelet transform; vessel enhancement; retinal image analysis; morphological thickness-correction; curvelet transform	MATCHED-FILTER; GRAY-LEVEL; EXTRACTION; MODEL	Blood vessel segmentation is a vital step in automated diagnosis of retinal diseases. Some retinal diseases progress with structural changes in the vessels whereas in others, vessels may remain unaffected. Segmentation of vessels is inevitable in both the cases. The extracted vessel map can be studied for these structural changes or can be removed to highlight other abnormalities of the retina. This study presents a rule-based retinal blood vessel segmentation algorithm. It implements two multi-scale approaches, local directional-wavelet transform and global curvelet transform, together in a novel manner for vessel enhancement and thereby segmentation. The authors have proposed a generic field-of-view mask for extraction of region-of-interest. Further, a morphological thickness-correction step, to recover vessel-boundary pixels, is also proposed. The significant contribution of this work is, segmentation of fine vessels while preserving the thickness of major vessels. Moreover, the algorithm is robust, as it performs consistently well, on four public databases, DRIVE, STARE, CHASE_DB-1 and HRF. Performance of the proposed algorithm is evaluated in terms of eight measures : accuracy, sensitivity, specificity, precision, F-1 score, G-mean, MCC and AUC, where it has outperformed many other existing methods. Zero data dependency gives the suggested algorithm, an edge over other state-of-the-art supervised methods.																	1751-9659	1751-9667				SEP 18	2020	14	11					2616	2625		10.1049/iet-ipr.2019.0969													
J								Solving matrix games based on Ambika method with hesitant fuzzy information and its application in the counter-terrorism issue	APPLIED INTELLIGENCE										Hesitant fuzzy sets; Ambika method; Hesitant fuzzy matrix games; Counter-terrorism issue	ATTRIBUTE DECISION-MAKING; CROSS-ENTROPY MEASURES; PROGRAMMING APPROACH; LINGUISTIC ENTROPY; PAYOFFS; SETS; TOPSIS; AGGREGATION	The hesitant fuzzy set has been studied as a powerful tool to describe the decision makers' judgements under uncertain environment and applied to many domains. For solving the matrix games whose payoffs are expressed by the hesitant fuzzy information, the paper proposes the Ambika method of hesitant fuzzy matrix games (HFMGs). In this paper, firstly, the formal representation of HFMGs is established to meet the conditions of two-person finite zero-sum games. Secondly, after a new method of adding elements to the shorter hesitant fuzzy elements (HFEs), i.e. the hesitant fuzzy elements with possibility, is developed to keep the same length of HFEs, a weighting method based on the position of element in the HFEs is proposed. Then the hesitant fuzzy bi-objective nonlinear programming models for both players are established for HFMGs. Thirdly, according to the proposed value and ambiguity indexes, the Ambika method of HFMGs is developed to find the optimal solutions of mixed strategies by solving the converted linear programming models. Finally, as the illustration of the proposed method, a numerical example about how to choose the optimal solutions for a state security department is given in the counter-terrorism issue.																	0924-669X	1573-7497															10.1007/s10489-020-01759-4		SEP 2020											
J								Generic model for automated player selection for cricket teams using recurrent neural networks	EVOLUTIONARY INTELLIGENCE										Cricket; Data mining; Sports prediction; Genetic algorithm; RNN	SPORTS	In this paper, an optimized model has been proposed exclusively for the game of cricket whereby a team of fifteen members can be chosen in an unbiased strategy. The proposed method involves a hybrid technique that uses the concept of genetic algorithm (GA) and recurrent neural networks (RNN) for selecting efficient players. Suitable preprocessing is applied to the individual players historical statistics and an initial feature matrix is generated for a player. This feature matrix is fed to the proposed mathematical function used in GA. The GA utilizes a novel fitness function for the minimization of loss-factor. This results in a refined feature matrix. This refined feature matrix is further subjected to RNN to assess a final score for the individual player. Finally, the proposed model comes up with a concurrent rank table that can be referred by the team selectors for an easy and efficient player selection for the upcoming match. It may be essentially considered that the proposed model provides results for the upcoming match or tournament only. Three different authentic datasets have been referred for the purpose of experimental evaluation of the proposed model. The results are compared with the recent match performances of each players. Surprisingly, almost equivalent results are obtained which supports the robustness of the scheme. In cases, the proposed scheme outperforms the manual team selection in terms of performance, that indicates that a slight better team could have been created in certain cases. The overall rate of accuracy in terms of predicted list of players for each match vis-a-vis the manually selected players comes out to be satisfactorily 98.5%.																	1864-5909	1864-5917															10.1007/s12065-020-00488-4		SEP 2020											
J								Multi-classification decision-making method for interval-valued intuitionistic fuzzy three-way decisions and its application in the group decision-making	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Three-way decisions; Multi-classification; Constructive covering algorithm; Interval-valued intuitionistic fuzzy sets; Group decision-making	OPERATORS; SET	With the introduction of the interval-valued intuitionistic fuzzy sets, the interval-valued intuitionistic fuzzy numbers are used instead of precise numbers to provide fuzzy characterization of feature attribute values and misclassification loss function values, which is more in line with the realistic fuzzy decision-making environment. Also, the constructive covering algorithm is introduced into the three-way decisions model, which effectively solves the shortcomings of the traditional decision-theoretic rough sets model in dealing with multi-classification problems, such as too many artificial parameters, complicated computation, redundant decisions, decisional conflicts and excessively large boundary domains. At the same time, in order to avoid the one-sidedness of individual decisions, the group decision-making method is introduced into the preliminarily constructed multi-classification model in this paper to build a multi-classification group decision-making model for interval-valued intuitionistic fuzzy three-way decisions based on the constructive covering algorithm. This model determines the initial weights of feature attributes by the precise weighting method, and determines the expert weights by the grey relational precise weighting method, which effectively achieves the consistency of group decision-making. The decision-making process and rules are also deduced, which expand the model of three-way decisions as well as its practical application value and scope.																	1868-8071	1868-808X															10.1007/s13042-020-01195-3		SEP 2020											
J								A Novel Strategy for Automatic Error Classification and Error Recovery for Robotic Assembly in Flexible Production	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Automatic error classification; Automatic error recovery; Robotic assembly; Flexible production; Semi-structured environment; Active vision		In this article, we develop a novel strategy for automatic error classification and recovery in robotic assembly tasks. The strategy does not require error diagnosis. It allows for effective reduction of an undetermined number of error states to 4, without the need for further operator updates of error space. The strategy integrates existing methods for computer vision, active vision and active manipulation. Our solution is implemented in a generic software framework, which is independent from software and hardware for implementing error detection and allows for application in other assembly types and components. The value of our strategy was experimentally validated on a simple case, where we inserted a battery into a cell phone. The experiment was performed on 1500 assembly attempts and included 500 detected errors. The whole experiment ran for 42 hours, with no need for operator assistance or supervision. The resulting classification rate is 99.6% and the resulting recovery rate is 98.8%. The 6 unrecovered errors were successfully resolved in a successive assembly attempt.																	0921-0296	1573-0409															10.1007/s10846-020-01248-3		SEP 2020											
J								Online Reconfiguration of Distributed Robot Control Systems for Modular Robot Behavior Implementation	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Robot programming; Robot control architectures; Robot autonomy; Model-based development; Model-driven engineering; Robot control	SPECIFICATION	The use of autonomous robots in areas that require executing a broad range of different tasks is currently hampered by the high complexity of the software that adapts the robot controller to different situations the robot would face. Current robot software frameworks facilitate implementing controllers for individual tasks with some variability, however, their possibilities for adapting the controllers at runtime are very limited and don't scale with the requirements of a highly versatile autonomous robot. With the software presented in this paper, the behavior of robots is implemented modularly by composing individual controllers, between which it is possible to switch freely at runtime, since the required transitions are calculated automatically. Thereby the software developer is relieved of the task to manually implement and maintain the transitions between different operational modes of the robot, what largely reduces software complexity for larger amounts of different robot behaviors. The software is realized by a model-based development approach. We will present the metamodels enabling the modeling of the controllers as well as the runtime architecture for the management of the controllers on distributed computation hardware. Furthermore, this paper introduces an algorithm that calculates the transitions between two controllers. A series of technical experiments verifies the choice of the underlying middleware and the performance of online controller reconfiguration. A further experiment demonstrates the applicability of the approach to real robotics applications.																	0921-0296	1573-0409															10.1007/s10846-020-01234-9		SEP 2020											
J								A Deep-Learning-based Strategy for Kidnapped Robot Problem in Similar Indoor Environment	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Relocalization; 2D LiDAR sensor; CNN; Robot pose; Kidnapped robot problem	MOBILE ROBOT; PARTICLE FILTERS; LOCALIZATION; SLAM	We present a deep-learning-based strategy that only uses a 2D LiDAR sensor to solve the kidnapped robot problem in similar indoor environments. First, we converted a set of 2D laser data into an RGB-image and an occupancy grid map and stacked them into a multi-channel image. Then, a neural network structure with five convolutional layers and four fully connected layers was designed to regress the 3-DOF robot pose. Finally, the network was trained using multi-channel images as input. We also improved the network structure to identify the scene where the robot is localized. Extensive experiments have been conducted in practice with a real mobile robot, verifying the effectiveness of the proposed strategy. Our network can obtain approximately 2m and 5(circle)accuracy indoors, and the scene classification accuracy of our network reaches up to 98%.																	0921-0296	1573-0409															10.1007/s10846-020-01216-x		SEP 2020											
J								Temporal Huber Regularization for DCE-MRI	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Dce-mri; Compressed sensing; Huber penalty; Total variation; Radial mri	CONTRAST-ENHANCED MRI; BLOOD-BRAIN-BARRIER; IMAGE-RECONSTRUCTION; VARIATION PENALTY; INPUT FUNCTION; BREAST-CANCER; NOISE; PARAMETERS	Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is used to study microvascular structure and tissue perfusion. In DCE-MRI, a bolus of gadolinium-based contrast agent is injected into the blood stream and spatiotemporal changes induced by the contrast agent flow are estimated from a time series of MRI data. Sufficient time resolution can often only be obtained by using an imaging protocol which produces undersampled data for each image in the time series. This has lead to the popularity of compressed sensing-based image reconstruction approaches, where all the images in the time series are reconstructed simultaneously, and temporal coupling between the images is introduced into the problem by a sparsity promoting regularization functional. We propose the use of Huber penalty for temporal regularization in DCE-MRI, and compare it to total variation, total generalized variation and smoothness-based temporal regularization models. We also study the effect of spatial regularization to the reconstruction and compare the reconstruction accuracy with different temporal resolutions due to varying undersampling. The approaches are tested using simulated and experimental radial golden angle DCE-MRI data from a rat brain specimen. The results indicate that Huber regularization produces similar reconstruction accuracy with the total variation-based models, but the computation times are significantly faster.																	0924-9907	1573-7683				NOV	2020	62	9					1334	1346		10.1007/s10851-020-00985-2		SEP 2020											
J								Total Variation and Mean Curvature PDEs on the Homogeneous Space of Positions and Orientations	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Total variation; Mean curvature; Sub-Riemannian geometry; Roto-translations; Denoising; Fiber enhancement	ENHANCEMENT; TRACTOGRAPHY; SCORES	Two key ideas have greatly improved techniques for image enhancement and denoising: the lifting of image data to multi-orientation distributions and the application of nonlinear PDEs such as total variation flow (TVF) and mean curvature flow (MCF). These two ideas were recently combined by Chambolle and Pock (for TVF) and Citti et al. (for MCF) for two-dimensional images. In this work, we extend their approach to enhance and denoise images of arbitrary dimension, creating a unified geometric and algorithmic PDE framework, relying on (sub-)Riemannian geometry. In particular, we follow a different numerical approach, for which we prove convergence in the case of TVF by an application of Brezis-Komura gradient flow theory. Our framework also allows for additional data adaptation through the use of locally adaptive frames and coherence enhancement techniques. We apply TVF and MCF to the enhancement and denoising of elongated structures in 2D images via orientation scores and compare the results to Perona-Malik diffusion and BM3D. We also demonstrate our techniques in 3D in the denoising and enhancement of crossing fiber bundles in DW-MRI. In comparison with data-driven diffusions, we see a better preservation of bundle boundaries and angular sharpness in fiber orientation densities at crossings.																	0924-9907	1573-7683															10.1007/s10851-020-00991-4		SEP 2020											
J								Autocalibration method for scanning electron microscope using affine camera model	MACHINE VISION AND APPLICATIONS										Autocalibration; SEM; Affine camera; Global optimization	SELF-CALIBRATION; MOTION; FACTORIZATION; SHAPE	This paper deals with the task of autocalibration of scanning electron microscope (SEM), which is a technique allowing to compute camera motion and intrinsic parameters. In contrast to classical calibration, which implies the use of a calibration object and is known to be a tedious and rigid operation, auto- or selfcalibration is performed directly on the images acquired for the visual task. As autocalibration represents an optimization problem, all the steps contributing to the success of the algorithm are presented: formulation of the cost function incorporating metric constraints, definition of bounds, regularization, and optimization algorithm. The presented method allows full estimation of camera matrices for all views in the sequence. It was validated on virtual images as well as on real SEM images (pollen grains, cutting tools, etc.). The results show a good convergence range and low execution time, notably compared to classical methods, and even more in the context of the calibration of SEM.																	0932-8092	1432-1769				SEP 18	2020	31	7-8							69	10.1007/s00138-020-01109-x													
J								Semi-supervised deep learning based named entity recognition model to parse education section of resumes	NEURAL COMPUTING & APPLICATIONS										Named entity recognition (NER); Semi-supervised learning; Deep learning models; Natural language processing; Resume information extraction		A job seeker's resume contains several sections, including educational qualifications. Educational qualifications capture the knowledge and skills relevant to the job. Machine processing of the education sections of resumes has been a difficult task. In this paper, we attempt to identify educational institutions' names and degrees from a resume's education section. Usually, a significant amount of annotated data is required for neural network-based named entity recognition techniques. A semi-supervised approach is used to overcome the lack of large annotated data. We trained a deep neural network model on an initial (seed) set of resume education sections. This model is used to predict entities of unlabeled education sections and is rectified using a correction module. The education sections containing the rectified entities are augmented to the seed set. The updated seed set is used for retraining, leading to better accuracy than the previously trained model. This way, it can provide a high overall accuracy without the need of large annotated data. Our model has achieved an accuracy of 92.06% on the named entity recognition task.																	0941-0643	1433-3058															10.1007/s00521-020-05351-2		SEP 2020											
J								Robust evaluation method of communication network based on the combination of complex network and big data	NEURAL COMPUTING & APPLICATIONS										Complex network; Cloud edge computer; Single-layer network; Multi-layer network		The essence of big data may be the science of complex network, which should be one of the basic theories of big data, and the direct object of mobile communication network is big data. The purpose of this paper is to study the evaluation method of communication network robustness based on the combination of cloud edge computer and big data. Firstly, the technical system of big data technology and the basic concept and model of complex network are studied. Secondly, it analyzes the robustness of single-layer network and multi-layer network to lay a solid foundation for the following experiments. Set up the experiment code, and test each experiment several times to get the final data. The experimental results show that the change ofR(LCC) from 0 to non-0 occurs at the reciprocal of the average for different network averages, that is, the critical value of network robustness P is equal to the reciprocal of the average. Random networks are not robust to regular networks. Even if the average order of the random network is the same as that of the regular network, the random network is not robust to the regular network. There are 5 x 10(4)nodes in each of the random networks ER1 and ER2. ER1 and ER2 are one to one connected. The average value of ER1 is set to be the same as the average value of ER2. The multi-layer random network is not stable without single-layer random network.																	0941-0643	1433-3058															10.1007/s00521-020-05264-0		SEP 2020											
J								In-depth analysis of financial market based on iris recognition algorithm of MATLAB GUI	NEURAL COMPUTING & APPLICATIONS										MatalabGUI; Iris recognition; Financial market; Security analysis; In-depth analysis	ECONOMIC-MODEL; STOCK	When analyzing financial markets, it needs to mine effective information from massive data. However, it is difficult to obtain information from image information. In order to improve the efficiency of financial market analysis, this paper applies the iris recognition algorithm to financial image data analysis and proposes a feature extraction and recognition algorithm based on morphological skeleton and Gabor filter. The algorithm uses a multi-frequency, multi-directional 2D Gabor filter to extract local features and combines the extracted feature codes with the iris recognition method to complete the identification of intra-class irises and inter-class irises. In addition, in order to verify the effect of the algorithm, this study uses MatalabGUI as a platform to build an experimental model. In summary, in this study, financial images are used as research images for identification and analysis. The research results show that the algorithm proposed in this paper has a certain effect.																	0941-0643	1433-3058															10.1007/s00521-020-05348-x		SEP 2020											
J								Multiscale-based multimodal image classification of brain tumor using deep learning method	NEURAL COMPUTING & APPLICATIONS										MSMCNN; LSTM; Semantic segmentation; U-NET; BRATS'15	NEURAL-NETWORKS; SEGMENTATION	MRI is a broadly used imaging method to determine glioma-based tumors. During image processing, MRI provides large image information, and therefore, an accurate image processing must be carried out in clinical practices. Therefore, automatic and consistent methods are requisite for knowing the precise details of the image. The automated segmentation method inheres obstacles like inconsistency in tracing out the large spatial and structural inconsistency of brain tumors. In this work, a semantic-based U-NET-convolutional neural networks exploring a 3*3 kernel's size is proposed. Small kernels have an effect against overfitting in the deeper architecture and provide only a smaller number of weights in this network. Multiscale multimodal convolutional neural network (MSMCNN) with long short-term memory (LSTM)-based deep learning semantic segmentation technique is used for multimodalities of magnetic resonance images (MRI). The proposed methodology aims to identify and segregate the classes of tumors by analyzing every pixel in the image. Further, the performance of semantic segmentation is enhanced by applying a patch-wise classification technique. In this work, multiscale U-NET-based deep convolution network is used for classifying the multimodal convolutions into three different scale patches based on a pixel level. In order to identify the tumor classes, all three pathways are combined in the LSTM network. The proposed methodology is validated by a fivefold cross-validation scheme from MRI BRATS'15 dataset. The experiment outcomes show that the MSMCNN model outperforms the CNN-based models over the Dice coefficient and positive predictive value and obtains 0.9214 sensitivity and 0.9636 accuracy.																	0941-0643	1433-3058															10.1007/s00521-020-05332-5		SEP 2020											
J								A novel binary chaotic genetic algorithm for feature selection and its utility in affective computing and healthcare	NEURAL COMPUTING & APPLICATIONS										Affective computing; Genetic algorithms; Emotion identification; Feature selection; Optimization tasks; Healthcare computing	SEARCH ALGORITHM; HYBRID; OPTIMIZATION; EVOLUTION	Genetic algorithm (GA) is a nature-inspired algorithm to produce best possible solution by selecting the fittest individual from a pool of possible solutions. Like most of the optimization techniques, the GA can also stuck in the local optima, producing a suboptimal solution. This work presents a novel metaheuristic optimizer named as the binary chaotic genetic algorithm (BCGA) to improve the GA performance. The chaotic maps are applied to the initial population, and the reproduction operations follow. To demonstrate its utility, the proposed BCGA is applied to a feature selection task from an affective database, namely AMIGOS (A Dataset for Affect, Personality and Mood Research on Individuals and Groups) and two healthcare datasets having large feature space. Performance of the BCGA is compared with the traditional GA and two state-of-the-art feature selection methods. The comparison is made based on classification accuracy and the number of selected features. Experimental results suggest promising capability of BCGA to find the optimal subset of features that achieves better fitness values. The obtained results also suggest that the chaotic maps, especially sinusoidal chaotic map, perform better as compared to other maps in enhancing the performance of raw GA. The proposed approach obtains, on average, a fitness value twice as better than the one achieved through the raw GA in the identification of the seven classes of emotions.																	0941-0643	1433-3058															10.1007/s00521-020-05347-y		SEP 2020											
J								A novel time-varying modeling and signal processing approach for epileptic seizure detection and classification	NEURAL COMPUTING & APPLICATIONS										Electroencephalogram (EEG); Epileptic seizure detection; Time-varying process; Ultra-regularized orthogonal forward regression (UROFR); Time-frequency analysis; Bayesian optimization	WAVELET TRANSFORM; FREQUENCY ANALYSIS; EEG; IDENTIFICATION; SELECTION; NETWORKS; TERM	Electroencephalogram (EEG) signal analysis plays an essential role in detecting and understanding epileptic seizures. It is known that seizure processes are nonlinear and non-stationary, discriminating between rhythmic discharges and dynamic change is a challenging task in EEG-based seizure detection. In this paper, a new time-varying (TV) modeling framework, based on an autoregressive (AR) model structure, is proposed to characterize and analyze EEG signals. The TV parameters of the AR model are approximated through a multi-wavelet basis function expansion (MWBF) approach. An effective ultra-regularized orthogonal forward regression (UROFR) algorithm is employed to significantly reduce and refine the resulting expanded model. Given a time-varying process, the proposed TVAR-MWBF-UROFR method can generate a parsimonious TVAR model, based on which a high-resolution power spectrum density (PSD) estimation can be obtained. Informative features are then defined and extracted from the PSD estimation. The TVAR-MWBF-UROFR method is applied to a number of real EEG datasets; features obtained from these datasets are then used for seizure detection and classification. To make the results more accurate and reliable, a PCA algorithm is adopted to select the optimal feature subset, and a Bayesian optimization technique based on the Gaussian process is performed to determine the coefficients associated with each of the classifiers. The performance of the proposed method is tested on two benchmark datasets, and the experimental results indicate that TVAR-MWBF-UROFR outperforms the compared state-of-the-art classifiers in terms of accuracy, specificity, sensitivity and robustness.																	0941-0643	1433-3058															10.1007/s00521-020-05330-7		SEP 2020											
J								An efficient generic approach for automatic taxonomy generation using HMMs	PATTERN ANALYSIS AND APPLICATIONS										Automatic taxonomy generation; Hidden Markov models; Hierarchical classification	SIMILARITY; CLASSIFICATION; MODELS; TREES	Taxonomies are essential tools for fast information retrieval and classification of knowledge. Many existing techniques for automatic taxonomy generation strongly depend on the specific properties of a particular domain and are consequently hard to apply to other domains. Some attempts have been made to design taxonomies for multiple domains. Unfortunately, they induce high hierarchical classification error rates for some datasets. The automatic design of a taxonomy requires the capability of measuring the similarity between classes. More precisely, the fact that two classes are near intuitively implies that some elements of one class are scattered in the neighborhood of some elements of the other class. This observation is used in this paper to propose a new generic technique for automatic taxonomy generation. A topological analysis of the neighborhood of each instance is first performed. The results of this analysis are used to initialize and train a hidden Markov model for each class. The model of a given classccaptures the frequencies of the classes found in the neighborhood of the instances ofc, from the most dominant class to the least dominant. The similarities between these models are finally used to derive a taxonomy. Hierarchical classification experiments realized on 20 datasets from various domains showed an average accuracy of 97.22% and a standard deviation of 4.11%. Comparison results revealed that the proposed approach outperforms existing work with accuracy gains reaching 38.62% for one dataset.																	1433-7541	1433-755X															10.1007/s10044-020-00918-0		SEP 2020											
J								Analysis of MAP, PH2OA/PH1I, PH2O/1 retrial queue with vacation, feedback, two-way communication and impatient customers	SOFT COMPUTING										PH distribution; MAP; Vacation; Feedback; Impatient customers; Two way communication	SINGLE-SERVER QUEUE; ARRIVALS; MODEL	This article concentrates on the steady-state analysis of a constant retrial queueing system with impatient customers, vacation, feedback, and two types of arrivals, namely the incoming calls which are made by the customers and the outgoing calls which are made by the server during the idle period. The incoming calls arrive at the system by following the Markovian Arrival Process(MAP) and service times of incoming/outgoing calls follow phase-type (PH) distribution, and the rest of the random variables are exponentially distributed. We have framed our model for analyzing some of the basic situations/problems in telecommunication systems. With the support of matrix analytic method, the invariant analysis of our system has been carried out. We have also discussed the busy period and have performed the cost analysis for our model. At last, we have validated our model through numerical and graphical exemplifications.																	1432-7643	1433-7479															10.1007/s00500-020-05318-4		SEP 2020											
J								Estimating the parameters of fuzzy linear regression model with crisp inputs and Gaussian fuzzy outputs: A goal programming approach	SOFT COMPUTING										Goal programming; Fuzzy linear regression; Gaussian fuzzy number		In this paper, we offered a new method to fit a fuzzy linear regression model to a set of crisp inputs and Gaussian fuzzy outputs, by considering its parameters as Gaussian fuzzy numbers. To calculate the regression coefficients, a nonlinear programming model is formulated based on a new distance between Gaussian fuzzy numbers. The nonlinear programming model is converted to a goal programming model by choosing appropriate deviation variables and then to a linear programming which can be solved simply by simplex method. To show the efficiency of proposed model, some applicative examples are solved and three simulation studies are performed. The computational results are compared with some earlier methods.																	1432-7643	1433-7479															10.1007/s00500-020-05331-7		SEP 2020											
J								A novel hybrid dynamic fireworks algorithm with particle swarm optimization	SOFT COMPUTING										Fireworks algorithm; Dynamic explosion amplitude; Global best firework; Updating process; Particle swarm optimization	DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION	In recent years, the fireworks algorithm (FWA) has attracted more and more attention due to its strong ability to solve optimization problems. However, the global performance of FWA is significantly affected by the explosion amplitude. In this paper, a dynamic fireworks algorithm with particle swarm optimization (DFWPSO) is developed to improve the global performance of FWA. In DFWPSO, a dynamic explosion amplitude mechanism based on the evolution speed of population, which is dynamically adjusted by evaluating the evolution speed of fitness in each iteration process, is designed to control the global and local searching information. Moreover, a new nonlinear minimal amplitude check strategy based on function decreasing is designed to obtain appropriate amplitude. Furthermore, a new firework updating mechanism based on particle swarm optimization (PSO) is implemented to accelerate the convergence of algorithm and cut down on computing resources. In addition, the selection operator of FWA is abandoned and all fireworks are updated by velocity and current location in each iteration process. To verify the performance of the proposed DFWPSO algorithm, three groups of the benchmark functions are used and tested for experiments. Compared with other variants of FWA and PSO variants, results show that the proposed algorithm performs competitively and effectively.																	1432-7643	1433-7479															10.1007/s00500-020-05308-6		SEP 2020											
J								Spatial distribution and content determination of Ganoderic acid F in tablets using confocal Raman microspectroscopy	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Ganoderic acid F; Spatial distribution; Content detection; Confocal micro-Raman spectroscopy mapping	SPECTROSCOPY; QUANTIFICATION; ELECTROSPUN; IMAGES; NIR	This study determines the spatial distribution and content of Ganoderic acid F in tablets without destroying the tablet. Confocal Raman microspectroscopy was conducted on the raw materials for Ganoderic acid F, starch, hydrated magnesium silicate, and magnesium stearate using live video imaging. Five different concentrations of Ganoderic acid F tablets (18.0-54.0%) were scanned at a spectral resolution of 1000 x 1000 mu m. After surface scanning imaging of the tablets at five different concentrations, the characteristic Raman spectra were obtained, which were used for the rapid and accurate identification of the tablets. The spatial distribution of the drug in the tablet was determined, and the uniformity of drug mixture was confirmed. The content of each component in the tablet was successfully calculated according to the single-peak spectra of the raw and auxiliary materials. In conclusion, the characteristic Raman scanning spectra of the tablets were obtained, and the authenticity of the tablets was determined rapidly. In the tablets of different concentrations, Ganoderic acid F was evenly distributed in the low-concentration tablets. Without destroying the drug, the confocal microscopic Raman spectrometer and function calculation can be used to understand the spatial distribution and content of each component in the drug, which can be used for the validation of drug preparation process, the detection of drug content, and the identification of drug authenticity.																	1868-5137	1868-5145															10.1007/s12652-020-02516-8		SEP 2020											
J								COVIDetectioNet: COVID-19 diagnosis system based on X-ray images using features selected from pre-learned deep features ensemble	APPLIED INTELLIGENCE										COVID-19 diagnosis; Relief algorithm; SVM; Pre-learned features; CNN	SUPPORT; NETWORKS	The recent novel coronavirus (also known as COVID-19) has rapidly spread worldwide, causing an infectious respiratory disease that has killed hundreds of thousands and infected millions. While test kits are used for diagnosis of the disease, the process takes time and the test kits are limited in their availability. However, the COVID-19 disease is also diagnosable using radiological images taken through lung X-rays. This process is known to be both faster and more reliable as a form of identification and diagnosis. In this regard, the current study proposes an expert-designed system called COVIDetectioNet model, which utilizes features selected from combination of deep features for diagnosis of COVID-19. For this purpose, a pretrained Convolutional Neural Network (CNN)-based AlexNet architecture that employed the transfer learning approach, was used. The effective features that were selected using the Relief feature selection algorithm from all layers of the architecture were then classified using the Support Vector Machine (SVM) method. To verify the validity of the model proposed, a total of 6092 X-ray images, classified as Normal (healthy), COVID-19, and Pneumonia, were obtained from a combination of public datasets. In the experimental results, an accuracy of 99.18% was achieved using the model proposed. The results demonstrate that the proposed COVIDetectioNet model achieved a superior level of success when compared to previous studies.																	0924-669X	1573-7497															10.1007/s10489-020-01888-w		SEP 2020											
J								A Lyapunov-Stable Adaptive Method to Approximate Sensorimotor Models for Sensor-Based Control	FRONTIERS IN NEUROROBOTICS										robotics; sensorimotor models; adaptive systems; sensor-based control; servomechanisms; visual servoing	ROBOT; MANIPULATION; FEATURES; OBJECTS; EYES	In this article, we present a new scheme that approximates unknown sensorimotor models of robots by using feedback signals only. The formulation of the uncalibrated sensor-based regulation problem is first formulated, then, we develop a computational method that distributes the model estimation problem amongst multiple adaptive units that specialize in a local sensorimotor map. Different from traditional estimation algorithms, the proposed method requires little data to train and constrain it (the number of required data points can be analytically determined) and has rigorous stability properties (the conditions to satisfy Lyapunov stability are derived). Numerical simulations and experimental results are presented to validate the proposed method.																	1662-5218					SEP 17	2020	14								59	10.3389/fnbot.2020.00059													
J								Pruning filters with L1-norm and capped L1-norm for CNN compression	APPLIED INTELLIGENCE										Filter pruning; Capped L1-norm; VGGnet; CIFAR; Convolutional neural network; FLOPs		The blistering progress of convolutional neural networks (CNNs) in numerous applications of the real-world usually obstruct by a surge in network volume and computational cost. Recently, researchers concentrate on eliminating these issues by compressing the CNN models, such as pruning filters and weights. In comparison with the technique of pruning weights, the technique of pruning filters doesn't effect in sparse connectivity patterns. In this article, we have proposed a fresh new technique to estimate the significance of filters. More precisely, we combined L1-norm with capped L1-norm to represent the amount of information extracted by the filter and control regularization. In the process of pruning, the insignificant filters remove directly without any loss in the test accuracy, providing much slimmer and compact models with comparable accuracy and this process is iterated a few times. To validate the effectiveness of our algorithm. We experimentally determine the usefulness of our approach with several advanced CNN models on numerous standard data sets. Particularly, data sets CIFAR-10 is used on VGG-16 and prunes 92.7% parameters with float-point-operations (FLOPs) reduction of 75.8% without loss of accuracy and has achieved advancement in state-of-art.																	0924-669X	1573-7497															10.1007/s10489-020-01894-y		SEP 2020											
J								Multi-view clustering via adversarial view embedding and adaptive view fusion	APPLIED INTELLIGENCE										Multi-view clustering; Adversarial view embedding; Adaptive view fusion; Clustering friendly representation learning		Multi-view clustering, which explores complementarity and consistency among multiple distinct feature sets to boost clustering performance, is becoming more and more useful in many real-world applications. Traditional approaches usually map multiple views to a unified embedding, in which some weighted mechanisms are utilized to measure the importance of each view. The embedding, serving as a clustering friendly representation, is then sent to extra clustering algorithms. However, a unified embedding cannot cover both complementarity and consistency among views and the weighted scheme measuring the importance of each view as a whole ignores the differences of features in each view. Moreover, because of lacking in proper grouping structure constraint imposed on the unified embedding, it will lead to just multi-view representation learned, which is not clustering friendly. In this paper, we propose a novel multi-view clustering method to alleviate the above problems. By dividing the embedding of a view into unified and view-specific vectors explicitly, complementarity and consistency can be reflected. Besides, an adversarial learning process is developed to force the above embeddings to be non-trivial. Then a fusion strategy is automatically learned, which will adaptively adjust weights for all the features in each view. Finally, a Kullback-Liebler (KL) divergence based objective is developed to constrain the fused embedding for clustering friendly representation learning and to conduct clustering. Extensive experiments have been conducted on various datasets, performing better than the state-of-the-art clustering approaches.																	0924-669X	1573-7497															10.1007/s10489-020-01864-4		SEP 2020											
J								Segmentation mask-guided person image generation	APPLIED INTELLIGENCE										Pose transferrable; Segmentation mask; Generative adversarial networks; Person re-identification	ADVERSARIAL NETWORKS; REIDENTIFICATION	Background clutters and pose variation are the key factors which prevents the network from learning a robust Person re-identification (Re-ID) model. To address the problem above, we first introduce the binary segmentation mask to construct the body region served as the input of the generator, then design a segmentation mask-guided person image generation network for the pose transfer. The binary segmentation mask has the capability of removing the background clutters in pixel-level, and contains more details about the edge information, where better shape consistency can be achieved for the generated image with the input image. Compared with the previous methods, the proposed method can dramatically improve the model adaptive ability and deal with the diversity of postures. In addition, we design a lightweight attention mechanism module as a guider module, which can assist the generator to focus on the discriminative features of pedestrians. The experiment results are introduced to demonstrate the effectiveness of the proposed method and the superiority performance over most state-of-the-art methods without over-computing in the design process of the Re-ID model. It is worth mentioning that our ideas can be easily combined with other fields to solve the phenomenon of the current situation with insufficient pose variations in the datasets.																	0924-669X	1573-7497															10.1007/s10489-020-01907-w		SEP 2020											
J								Efficient multiple constraint acquisition	CONSTRAINTS										Constraint acquisition; Learning; Modeling	ANSWERS; ERRORS; DNF	Constraint acquisition systems such as QuAcq and MultiAcq can assist non-expert users to model their problems as constraint networks by classifying (partial) examples as positive or negative. For each negative example, the former focuses on one constraint of the target network, while the latter can learn a maximum number of constraints. Two bottlenecks of the acquisition process where both these algorithms encounter problems are the large number of queries required to reach convergence, and the high cpu times needed to generate queries, especially near convergence. In this paper we propose algorithmic and heuristic methods to deal with both these issues. We first describe an algorithm, called MQuAcq, that blends the main idea of MultiAcq into QuAcq resulting in a method that learns as many constraints as MultiAcq does after a negative example, but with a lower complexity. A detailed theoretical analysis of the proposed algorithm is also presented. Then we turn our attention to query generation which is a significant but rather overlooked part of the acquisition process. We describe how query generation in a typical constraint acquisition system operates, and we propose heuristics for improving its efficiency. Experiments from various domains demonstrate that our resulting algorithm that integrates all the new techniques does not only generate considerably fewer queries than QuAcq and MultiAcq, but it is also by far faster than both of them, in average query generation time as well as in total run time, and also largely alleviates the premature convergence problem.																	1383-7133	1572-9354															10.1007/s10601-020-09311-4		SEP 2020											
J								Intuitionistic fuzzy multi-stage multi-objective fixed-charge solid transportation problem in a green supply chain	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Fixed-charge solid transportation problem; Supply chain network; Green supply chain; Multi-objective decision making; Intuitionistic fuzzy number; Pareto-optimal solution	OPTIMIZATION; ENVIRONMENT; NETWORK	This research mainly focuses on presenting an innovative study of a multi-stage multi-objective fixed-charge solid transportation problem (MMFSTP) with a green supply chain network system under an intuitionistic fuzzy environment. The most controversial issue in recent years is that greenhouse gas emissions such as carbon dioxide, methane, etc. induce air pollution and global warming, thus motivating us to formulate the proposed research. In real-world situations the parameters of MMFSTP via a green supply chain network system usually have unknown quantities, and thus we assume trapezoidal intuitionistic fuzzy numbers to accommodate them and then employ the expected value operator to convert intuitionistic fuzzy MMFSTP into deterministic MMFSTP. Next, the methodologies are constructed to solve the deterministic MMFSTP by weighted Tchebycheff metrics programming and min-max goal programming, which provide Pareto-optimal solutions. A comparison is then drawn between the Pareto-optimal solutions that are extracted from the programming, and thereafter a procedure is performed to analyze the sensitivity analysis of the target values in the min-max goal programming. Finally, we incorporate an application example connected with a real-life industrial problem to display the feasibility and potentiality of the proposed model. Conclusions about the findings and future study directions are also offered.																	1868-8071	1868-808X															10.1007/s13042-020-01197-1		SEP 2020											
J								A non-smooth non-local variational approach to saliency detection in real time	JOURNAL OF REAL-TIME IMAGE PROCESSING										Variational methods; Convex; Primal-dual; Non-local image processing; Saliency segmentation; GPU; Superpixels	IMAGE; SUPERPIXELS; ATTENTION	In this paper, we propose and solve numerically a general non-smooth, non-local variational model to tackle the saliency detection problem in natural images. In order to overcome the typical drawback of the non-local methods in image processing, which mainly is the inherent computational complexity of non-local calculus, as the non-local derivatives are computed w.r.t every point of the domain, we propose a different scenario. We present a novel convex energy minimization problem in the feature space, which is efficiently solved by means of a non-local primal-dual method. Several implementations and discussions are presented taking care of the computing platforms, CPU and GPU, achieving up to 33 fps and 62 fps respectively for 300x400 image resolution, making the method eligible for real time applications.																	1861-8200	1861-8219															10.1007/s11554-020-01016-4		SEP 2020											
J								Integrated neuro-evolution-based computing solver for dynamics of nonlinear corneal shape model numerically	NEURAL COMPUTING & APPLICATIONS										Stochastic numerical computing; Neural networks; Genetic algorithms; Corneal shape models; Optimization techniques	INTERIOR-POINT ALGORITHM; OPTIMIZATION; NETWORK; DESIGN; HEURISTICS; PARADIGM; ANALYZE; FLUID; FLOW	In this study, bio-inspired computational techniques have been exploited to get the numerical solution of a nonlinear two-point boundary value problem arising in the modelling of the corneal shape. The computational process of modelling and optimization makes enormously straightforward to obtain accurate approximate solutions of the corneal shape models through artificial neural networks, pattern search (PS), genetic algorithms (GAs), simulated annealing (SA), active-set technique (AST), interior-point technique, sequential quadratic programming and their hybrid forms based on GA-AST, PS-AST and SA-AST. Numerical results show that the designed solvers provide a reasonable precision and efficiency with minimal computational cost. The efficacy of the proposed computing strategies is also investigated through a descriptive statistical analysis by means of histogram illustrations, probability plots and one-way analysis of variance.																	0941-0643	1433-3058															10.1007/s00521-020-05355-y		SEP 2020											
J								Identifying crop water stress using deep learning models	NEURAL COMPUTING & APPLICATIONS										Crop phenotyping; Confusion matrix; DCNN; Digital agriculture; Machine learning	NEURAL-NETWORK; CLASSIFICATION; FUSION; IDENTIFICATION; TOLERANCE; IMAGES	The identification of water stress is a major challenge for timely and effective irrigation to ensure global food security and sustainable agriculture. Several direct and indirect methods exist for identification of crop water stress, but they are time consuming, tedious and require highly sophisticated sensors or equipment. Image processing is one of the techniques which can help in the assessment of water stress directly. Machine learning techniques combined with image processing can aid in identifying water stress beyond the limitations of traditional image processing. Deep learning (DL) techniques have gained momentum recently for image classification and the convolutional neural network based on DL is being applied widely. In present study, comparative assessment of three DL models: AlexNet, GoogLeNet and Inception V3 are applied for identification of water stress in maize (Zea mays), okra (Abelmoschus esculentus) and soybean (Glycine max) crops. A total of 1200 digital images were acquired for each crop to form the input dataset for the deep learning models. Among the three models, performance of GoogLeNet was found to be superior with an accuracy of 98.3, 97.5 and 94.1% for maize, okra and soybean, respectively. The onset of convergence in GoogLeNet models commenced after 8 epochs with 22 (maize), 31 (okra) and 15 (soybean) iterations per epoch with error rate of less than 7.5%.																	0941-0643	1433-3058															10.1007/s00521-020-05325-4		SEP 2020											
J								Visual localization under appearance change: filtering approaches	NEURAL COMPUTING & APPLICATIONS										Visual localization; Place recognition; Autonomous driving; Robotics		A major focus of current research on place recognition is visual localization for autonomous driving. In this scenario, as cameras will be operating continuously, it is realistic to expect videos as an input to visual localization algorithms, as opposed to the single-image querying approach used in other visual localization works. In this paper, we show that exploiting temporal continuity in the testing sequence significantly improves visual localization-qualitatively and quantitatively. Although intuitive, this idea has not been fully explored in recent works. To this end, we propose two filtering approaches to exploit the temporal smoothness of image sequences: (i) filtering on discrete domain with hidden Markov model, and (ii) filtering on continuous domain with Monte Carlo-based visual localization. Our approaches rely on local features with an encoding technique to represent an image as a single vector. The experimental results on synthetic and real datasets show that our proposed methods achieve better results than state of the art (i. e., deep learning-based pose regression approaches) for the task on visual localization under significant appearance change. Our synthetic dataset and source code are made publicly available (https://sites.google.com/view/g2d-software/home; https://github.com/dadung/ Visual-Localization-Filtering).																	0941-0643	1433-3058															10.1007/s00521-020-05339-y		SEP 2020											
J								A precise and stable machine learning algorithm: eigenvalue classification (EigenClass)	NEURAL COMPUTING & APPLICATIONS										Data classification; Eigenvalues; Learning algorithm; Machine learning; Supervised learning	MULTI-LABEL CLASSIFICATION	In this study, a precise and efficient eigenvalue-based machine learning algorithm, particularly denoted as Eigenvalue Classification (EigenClass) algorithm, has been presented to deal with classification problems. The EigenClass algorithm is constructed by exploiting an eigenvalue-based proximity evaluation. To appreciate the classification performance of EigenClass, it is compared with the well-known algorithms, such as k-nearest neighbours, fuzzy k-nearest neighbours, random forest (RF) and multi-support vector machines. Number of 20 different datasets with various attributes and classes are used for the comparison. Every algorithm is trained and tested for 30 runs through 5-fold cross-validation. The results are then compared among each other in terms of the most used measures, such as accuracy, precision, recall, micro-F-measure, and macro-F-measure. It is demonstrated that EigenClass exhibits the best classification performance for 15 datasets in terms of every metric and, in a pairwise comparison, outperforms the other algorithms for at least 16 datasets in consideration of each metric. Moreover, the algorithms are also compared through statistical analysis and computational complexity. Therefore, the achieved results show that EigenClass is a precise and stable algorithm as well as the most successful algorithm considering the overall classification performances.																	0941-0643	1433-3058															10.1007/s00521-020-05343-2		SEP 2020											
J								DeTrAs: deep learning-based healthcare framework for IoT-based assistance of Alzheimer patients	NEURAL COMPUTING & APPLICATIONS										Alzheimer disease; Convolution neural network; Internet of Health; Naive Bayes; Recurrent neural network		Healthcare 4.0 paradigm aims at realization of data-driven and patient-centric health systems wherein advanced sensors can be deployed to provide personalized assistance. Hence, extreme mentally affected patients from diseases like Alzheimer can be assisted using sophisticated algorithms and enabling technologies. Motivated from this fact, in this paper, DeTrAs: Deep Learning-based Internet of Health Framework for the Assistance of Alzheimer Patients is proposed. DeTrAs works in three phases: (1) A recurrent neural network-based Alzheimer prediction scheme is proposed which uses sensory movement data, (2) an ensemble approach for abnormality tracking for Alzheimer patients is designed which comprises two parts: (a) convolutional neural network-based emotion detection scheme and (b) timestamp window-based natural language processing scheme, and (3) an IoT-based assistance mechanism for the Alzheimer patients is also presented. The evaluation of DeTrAs depicts almost 10-20% improvement in terms of accuracy in contrast to the different existing machine learning algorithms.																	0941-0643	1433-3058															10.1007/s00521-020-05327-2		SEP 2020											
J								Deep reinforcement learning for permanent magnet synchronous motor speed control systems	NEURAL COMPUTING & APPLICATIONS										Permanent magnet synchronous motor (PMSM); Speed control; Markov decision process (MDP); Deep reinforcement learning (DRL); Deep Q-networks (DQN)	PMSM; IMPLEMENTATION; REGULATOR; DESIGN	The permanent magnet synchronous motor (PMSM) servo system is widely applied in many industrial fields due to its unique advantages. In this paper, we study the deep reinforcement learning (DRL) speed control strategy for PMSM servo system, in which exist many disturbances, i.e., load torque and rotational inertia variations. The speed control problem is formulated as a Markov decision process problem, which is computed optimal regulation scheme corresponding to each speed and error state using the deep Q-networks. Simulation results are provided to demonstrate that compared with conventional proportion integral control, the proposed DRL control can improve the robustness against load disturbances and high performance of the PMSM speed control system.																	0941-0643	1433-3058															10.1007/s00521-020-05352-1		SEP 2020											
J								Efficient locality-sensitive hashing over high-dimensional streaming data	NEURAL COMPUTING & APPLICATIONS										Approximate nearest neighbor search; Locality-sensitive hashing; LSM-tree; Streaming data		Approximate nearest neighbor (ANN) search in high-dimensional spaces is fundamental in many applications. Locality-sensitive hashing (LSH) is a well-known methodology to solve the ANN problem. Existing LSH-based ANN solutions typically employ a large number of individual indexes optimized for searching efficiency. Updating such indexes might be impractical when processing high-dimensional streaming data. In this paper, we present a novel disk-based LSH index that offers efficient support for both searches and updates. The contributions of our work are threefold. First, we use the write-friendly LSM-trees to store the LSH projections to facilitate efficient updates. Second, we develop a novel estimation scheme to estimate the number of required LSH functions, with which the disk storage and access costs are effectively reduced. Third, we exploit both the collision number and the projection distance to improve the efficiency of candidate selection, improving the search performance with theoretical guarantees on the result quality. Experiments on four real-world datasets show that our proposal outperforms the state-of-the-art schemes.																	0941-0643	1433-3058															10.1007/s00521-020-05336-1		SEP 2020											
J								Small vehicle classification in the wild using generative adversarial network	NEURAL COMPUTING & APPLICATIONS										Vehicle classification; GAN; Image reconstruction; Convolutional neural networks	SUPERRESOLUTION	With the popularization of intelligent transportation system, the demand for vision-based algorithms and performance becomes more and severe. Vehicle detection techniques have made great strides in the past decades; however, there are still some challenges, such as the classification of tiny vehicles. The images of distant vehicles are generally blurred and lack detailed information due to their low resolutions. To solve this problem, we propose a novel method to generate high-resolution (HR) images from fuzzy images by employing a generative adversarial network (GAN). In addition, the dataset used for training standard GAN is generally constructed by down-sampling from the neutral HR images. Unfortunately, the effect of reconstruction is more modest. To cope with this trouble, we first construct our dataset by using three fuzzy kernels. Then, the exposure of the low-resolution (LR) image is adjusted randomly. Furthermore, a hybrid objective function is designed to guide the model to restore image details. The experimental results on the KITTI data set verify the effectiveness of our method for tiny vehicle classification.																	0941-0643	1433-3058															10.1007/s00521-020-05331-6		SEP 2020											
J								Multi-label fault diagnosis of rolling bearing based on meta-learning	NEURAL COMPUTING & APPLICATIONS										Fault diagnosis; Multi-label learning; Meta-learning; Rolling bearing	CONVOLUTIONAL NEURAL-NETWORK; ROTATING MACHINERY; OBJECT DETECTION	In practical applications, it is difficult to acquire sufficient fault samples for training deep learning fault diagnosis model of rolling bearing. Aiming at the few-shot issue and multi-label attributes of single-point faults, a novel fault diagnosis method of rolling bearing based on time-frequency signature matrix (T-FSM) feature and multi-label convolutional neural network with meta-learning (MLCML) is proposed in this paper. At the beginning, the T-FSM features sensitive to few-shot fault diagnosis of measured vibration signal are extracted. Subsequently, a designed multi-label convolutional neural network (MLCNN) with a specific architecture is employed to identify faults. Crucially, the meta-learning strategy of learning initial network parameters susceptive to task changes is incorporated to MLCNN for addressing the few-shot problem. Ultimately, the publicly available rolling bearing dataset is utilized to demonstrate the effectiveness of the proposed method. The experimental results exhibit that the trained MLCML has the capability of learning to learn few-shot fault attributes with outstanding diagnosis accuracy and generalization. More concretely, the model can adapt to new fault categories rapidly owing to that only a few samples and update steps are required to fine-tune the network.																	0941-0643	1433-3058															10.1007/s00521-020-05345-0		SEP 2020											
J								Getting into the engine room: a blueprint to investigate the shadowy steps of AI ethics	AI & SOCIETY										Applied ethics; AI ethics; Data ethics; Data science; Responsible innovation	BIG DATA	Enacting an AI system typically requires three iterative phases where AI engineers are in command: selection and preparation of the data, selection and configuration of algorithmic tools, and fine-tuning of the different parameters on the basis of intermediate results. Our main hypothesis is that these phases involve practices with ethical questions. This paper maps these ethical questions and proposes a way to address them in light of a neo-republican understanding of freedom, defined as absence of domination. We thereby identify different types of responsibility held by AI engineers and link them to concrete suggestions on how to improve professional practices. This paper contributes to the literature on AI and ethics by focusing on the work necessary to configure AI systems, thereby offering an input to better practices and an input for societal debates.																	0951-5666	1435-5655															10.1007/s00146-020-01069-w		SEP 2020											
J								Dynamic multi-objective evolutionary algorithm for IoT services	APPLIED INTELLIGENCE										Agriculture; Differential evolution; Dynamic multi-objective optimization; Internet of things; Multi-objective evolutionary algorithm	GREY WOLF OPTIMIZER; RESOURCE-ALLOCATION; INDUSTRIAL INTERNET; FRAMEWORK; ENSEMBLE; SYSTEM	The primary goal of the Internet of things(IoT) is to provide people with anywhere services in real life. But intelligent IoT shouldn't only provide services, but also consider how to allocate heterogeneous resources reasonably, which has become a very challenging problem. To obtain the best resource allocation scheme, it is crucial to minimize the service cost and service time. Since the two objectives are contradictory, we have modelled IoT services as a dynamic multi-objective optimization problem. Then a dynamic multi-objective evolutionary algorithm for dynamic IoT services(dMOEA/DI) is proposed. In dMOEA/DI, we have designed operators such as the appropriate encoding method, dynamic detection operator, filtering strategy, differential evolution, and polynomial mutation. Based on the single service strategy and collaborative service strategy, experimental research is performed on the agricultural IoT services with dynamic requests under different distributions. The simulation experimental results prove that dMOEA/DI performs better than the contrasted algorithms on the IoT service optimization problems.																	0924-669X	1573-7497															10.1007/s10489-020-01861-7		SEP 2020											
J								Numerical solution and parameter estimation for uncertain SIR model with application to COVID-19	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Uncertain differential equation; SIR model; COVID-19	EPIDEMIC MODEL	Developing algorithms for solving high-dimensional uncertain differential equations has been an exceedingly difficult task. This paper presents an a-path-based approach that can handle the proposed high-dimensional uncertain SIR model. We apply the alpha-path-based approach to calculating the uncertainty distributions and related expected values of the solutions. Furthermore, we employ the method of moments to estimate parameters and design a numerical algorithm to solve them. This model is applied to describing the development trend of COVID-19 using infected and recovered data of Hubei province. The results indicate that lockdown policy achieves almost 100% efficiency after February 13, 2020, which is consistent with the existing literatures. The high-dimensional a-path-based approach opens up new possibilities in solving high-dimensional uncertain differential equations and new applications.																	1568-4539	1573-2908															10.1007/s10700-020-09342-9		SEP 2020											
J								ILAS-IoT: An improved and lightweight authentication scheme for IoT deployment	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										IoT; Key establishment; Device access control; Lightweight cryptography	KEY AGREEMENT SCHEME; WIRELESS SENSOR NETWORKS; USER AUTHENTICATION; PROVABLY-SECURE; INTERNET; THINGS; EXCHANGE; PROTOCOL	In 2019, Banerjee et al. (IEEE Int Things J 6(5):8739-8752, 2019; 10.1109/JIOT.2019.2931372) proposed an authenticated key agreement scheme to facilitate the session establishment resulting into a session key between a user and a smart device for IoT based networks. As per their claim, the scheme of Banerjee et al. provides known security features and resist all known attacks using only lightweight symmetric key primitives. The analysis in this paper; however, shows that the scheme of Banerjee et al. cannot complete normally. The user in their scheme, after sending a request message may never receive the response from smart device. This incorrectness results into total in applicability of Banerjee et al.'s scheme. Moreover, it is also shown that their scheme has weaknesses against stolen verifier attack. Then an improved lightweight authentication scheme for IoT deployments (ILAS-IoT) is proposed in this article. ILAS-IoT performs the process correctly by increasing very little computation and communication overheads. The proposed ILAS-IoT also resists stolen verifier and all known attacks, which is evident from the formal and informal security analysis.																	1868-5137	1868-5145															10.1007/s12652-020-02349-5		SEP 2020											
J								A new methodology for analyzing vehicle network topologies for critical hacking	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Vehicle network topology; Cybersecurity; Network vulnerability; Hierarchical clustering; Ordinal logistic regression		This study aims to provide a new approach for describing and measuring the vulnerability of in-vehicle networks regarding cyberattacks. Cyberattacks targeting in-vehicle networks can result in a reasonable threat considering passenger safety. Unlike previous literature, the methodology focuses on a comparatively large sample of vehicle networks (114 objects) by proposing a new framework of statistical techniques for measuring, classifying, and modelling in-vehicle networks concerning the changed vulnerability, instead of dealing with each vehicle network individually. To facilitate understanding of the vulnerability patterns of in-vehicle networks, the dataset has been evaluated through three analytic stages: vulnerability identification, classification, and modeling. The result has helped in ranking vehicles based on their network vulnerability level. The result of the modeling has shown that every additional remote endpoint installation causes a relevant weakening in security. Higher cost vehicles have also appeared to be more vulnerable to cyberattacks, while the increase in the number of segmented network domains has had a positive effect on network security.																	1868-5137	1868-5145															10.1007/s12652-020-02522-w		SEP 2020											
J								E-commerce payment model using blockchain	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Blockchain; e-commerce; Payment gateway; Digital signature	AUTHENTICATION; EFFICIENT; PROTOCOL; SYSTEM; TIME	The current e-commerce payment systems for credit or check cards require a payment gateway (PG). This incurs PG fees, which in turn increases the cost of engaging in e-commerce. This paper proposes a simple payment model that uses basic cryptocurrency features, such as public key, private key, and digital signature, to eliminate the need for transaction intermediaries such as public key certificate and PG. This model can process e-commerce payments without registering additional public key certificate, public key, or private key. The use of a digital signature guarantees the integrity and nonrepudiation of electronic payments, besides eliminating the fees for intermediary services such as PG, thereby reducing the overall cost of operating e-commerce services. This proposal is crucial as it is the first attempt to apply blockchain technology to e-commerce payment services. In addition, our model is important because it not only supports the evolution of e-commerce payment technology but also enhances the competitive advantage of using e-commerce.																	1868-5137	1868-5145															10.1007/s12652-020-02519-5		SEP 2020											
J								Improved local fisher discriminant analysis based dimensionality reduction for cancer disease prediction	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Dimensionality reduction; Local fisher discriminant analysis; Locality-preserving projection; Cancer; Type2fuzzy neural network	PARTICLE SWARM OPTIMIZATION; CLASSIFICATION	A good dimensional reduction technique is needed to apply and improve the effectiveness of dimensionality reduction for medical data. High-dimensional data brings great challenges in terms of computational complexity and classification efficiency. It is necessary to compress effectively from high dimensional space to low dimensional space to design a learning curve with good performance. Therefore, dimensional reduction is necessary to study and understand the mechanism of the practical problems of medical data. In this paper, a hybrid local fisher discriminant analysis (HLFDA) method is proposed for the dimension reduction of the medical data. LFDA is a localized variant of Fisher discriminant analysis and it is popular for supervised dimensionality reduction method. The proposed HLFDA is a combination of Locality-preserving projection and LFDA. After the dimensionality reduction process, the data are given to the Type2fuzzy neural network classifier to classify a given data as normal or abnormal. The paper focused on improving performance in terms of prediction accuracy. Three types of UCI cancer dataset is used for analyzing the performance of the proposed method.																	1868-5137	1868-5145															10.1007/s12652-020-02542-6		SEP 2020											
J								Case studies on using natural language processing techniques in customer relationship management software	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Customer relationship management; Word embeddings; Machine learning; Natural language processing; Recurrent neural networks		How can we use a text corpus stored in a customer relationship management (CRM) database for data mining and segmentation? To answer this question, we inherited the state of the art methods commonly used in natural language processing (NLP) literature, such as word embeddings, and deep learning literature, such as recurrent neural networks (RNN). We used the text notes from a CRM system taken by customer representatives of an internet ads consultancy agency between 2009 and 2020. We trained word embeddings by using the corresponding text corpus and showed that these word embeddings could be used directly for data mining and used in RNN architectures, which are deep learning frameworks built with long short-term memory (LSTM) units, for more comprehensive segmentation objectives. The obtained results prove that we can use structured text data populated in a CRM to mine valuable information. Hence, any CRM can be equipped with useful NLP features once we correctly built the problem definitions and conveniently implement the solution methods.																	0925-9902	1573-7675															10.1007/s10844-020-00619-4		SEP 2020											
J								Improving the accuracy of machine-learning models with data from machine test repetitions	JOURNAL OF INTELLIGENT MANUFACTURING										Machine learning; Artificial intelligence; Ensembles; Brandsma facing tests; Tool geometry; Turning	ARTIFICIAL NEURAL-NETWORKS; TOOL RAKE ANGLE; SURFACE-ROUGHNESS; CUTTING CONDITIONS; PREDICTION; WEAR; INTELLIGENCE; GEOMETRY; TRENDS; FORCE	The modelling of machining processes by means of machine-learning algorithms is still based on principles that are especially adapted to mechanical approaches, in which very few inputs are varied with little repetition of experimental conditions. These principles might not be ideal to achieve accurate machine-learning models and they are certainly not aligned with the practicalities of industrial machining in factories. In this research the effect of a new strategy to improve machine-learning model accuracy is studied: experimental repetition. Tool-life prediction in the face-turning operations of AISI 1045 steel discs, depending on different cooling systems and tool geometries, is selected as a case study. Both the side rake and the relief angles of HSS tools are optimized using the Brandsma facing test under dry, MQL, and flooding conditions. Different machine-learning algorithms, such as regression trees, kNNs, artificial neural networks, and ensembles (bagging and Random Forest) are tested. On the one hand, the results of the study showed that artificial neural networks of Radial Basis Functions presented the highest model accuracy (11.4 mm RMSE), but required a very sensitive and complex tuning process. On the other hand, they demonstrated that ensembles, especially Random Forest, provided models with accuracy in the same range, but with no tuning procedure (12.8 mm RMSE). Secondly, the effect of an increased dataset size, by means of experimental repetition, is evaluated and compared with traditional experimental modelling that used average values. The results showed that some machine-learning techniques, including both ensemble types, significantly improved their accuracy with this strategy, by up to 23%. The results therefore suggested that the use of raw experimental data, rather than their averaged values, can achieve machine-learning models of higher accuracy for tool-wear processes.																	0956-5515	1572-8145															10.1007/s10845-020-01661-3		SEP 2020											
J								Hierarchical multistrategy genetic algorithm for integrated process planning and scheduling	JOURNAL OF INTELLIGENT MANUFACTURING										Process planning; Jopshop scheduling; Multistrategy; Genetic algorithm	SIMULATED ANNEALING APPROACH; EVOLUTIONARY ALGORITHM; OPTIMIZATION APPROACH	To adapt to the flexibility characteristics of modern manufacturing enterprises and the dynamics of manufacturing subsystems, promote collaboration in manufacturing functions, and allocate production resources in a reasonable manner, a mathematical model of integrated process planning and scheduling (IPPS) problems was developed to optimize the global performance of manufacturing systems. To solve IPPS problems, a hierarchical multistrategy genetic algorithm was developed. To address the multidimensional flexibility of IPPS problems, a chromosome coding method was designed to include a scheduling layer, a process layer, a machine layer, and a logic layer. Multiple crossover operators and mutation operators with polytypic global or local optimization strategies were used during the genetic operation stage to expand the algorithm's search dimension and maintain the population's diversity, thereby addressing the problems of population evolution stagnation and premature convergence. The effectiveness of the algorithm was verified by benchmark testing in the example simulation process. The test data show that if the makespan is taken as the optimization target, the proposed genetic algorithm performs better in solving IPPS problems with high complexity. The use of multistrategy genetic operators and logic layer coding makes a significant contribution to the improved performance of the algorithm reported in this paper.																	0956-5515	1572-8145															10.1007/s10845-020-01659-x		SEP 2020											
J								Incremental one-class collaborative filtering with co-evolving side networks	KNOWLEDGE AND INFORMATION SYSTEMS										Incremental algorithms; One-class collaborative filtering; Evolving networks	RECOMMENDATION	One-class collaborative filtering (OCCF) is a fundamental research problem in a myriad of applications where the preferences of users can only be implicitly inferred from their one-class feedback (e.g., click an ad or purchase a product). The main challenges of OCCF lie in the sparsity of user feedback and the ambiguity of unobserved preferences. To effectively address the above two challenges, side networks from users and items are extensively exploited by state-of-the-art methods, which are predominantly focused on static settings. However, as real-world recommender systems evolve over time (where both the user-item ratings and user-user/item-item side networks will change), it is necessary to update OCCF results (e.g., the latent features of users and items) accordingly. The main obstacle for OCCF online update with co-evolving side networks lies in the fact that the coupled system is highly sensitive to local changes, which may cause massive perturbation on the latent features of a large number of users and items. In this paper, we propose a novel incremental one-class collaborative filtering (OCCF) method that can cope with co-evolving side networks efficiently. In particular, we model the evolution of latent features as a linear transformation process, which enables fast update of the latent features on the fly. Empirical experiments demonstrate that our method can provide high-quality recommendation results on real-world datasets.																	0219-1377	0219-3116															10.1007/s10115-020-01511-x		SEP 2020											
J								Complementary Boundary Estimation Network for Temporal Action Proposal Generation	NEURAL PROCESSING LETTERS										Temporal action proposal generation; Temporal boundary evaluation; Proposal evaluation; Network fusion		Temporal Action Detection is an important yet challenging task, in which temporal action proposal generation plays an important part. Since the temporal boundaries of action instances in videos are often ambiguous, it's difficult to locate them precisely. Boundary Sensitive Network (BSN) (Lin et al. in ECCV, 2018) is a state-of-the-art corner-based method that can generate high-quality proposals with high recall rate. It contains a temporal evaluation network and a proposal evaluation network to generate and evaluate proposals separately, which can find the temporal boundaries of action instances directly to produce proposals with flexible temporal intervals and evaluate the quality of proposals. But BSN still has some issues: (1) Due to the small reception field of temporal evaluation network, it often generates many false temporal boundaries. (2) Evaluating the quality of proposals is a difficult task and not well solved in the paper. To address these issues, we propose Complementary Boundary Estimation Network (CBEN), an improved approach to temporal action proposal generation based on the framework of BSN. Specifically, we improve BSN in two aspects: Firstly, considering the temporal evaluation network of BSN can only capture local information and tends to have high response at background segments, we combine it with a new network with larger reception field to better identify false temporal action boundaries. Secondly, to evaluate the quality of temporal action proposals more accurately, we propose a class-based proposal evaluation network and combine it with a tIoU-based proposal evaluation network to filter out low-quality proposals. Extensive experiments on THUMOS14 and ActivityNet-1.3 datasets indicate that CBEN can achieve better performance than current mainstream methods on temporal action proposal generation. We further combine CBEN with an off-the-shelf action classifier, and show consistent performance improvements on THUMOS14 dataset.																	1370-4621	1573-773X															10.1007/s11063-020-10349-x		SEP 2020											
J								Semantic -related image style transfer with dual -consistency loss.	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						135	149		10.1016/j.neucom.2020.04.027													
J								Learning to find reliable correspondences with local neighborhood consensus	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						150	158		10.1016/j.neucom.2020.04.016													
J								Stable recovery of approximately k -sparse signals in noisy cases via t p minimization ?	NEUROCOMPUTING											L(Q) MINIMIZATION; REPRESENTATION																		0925-2312	1872-8286				SEP 17	2020	406						159	168		10.1016/j.neucom.2020.04.014													
J								LSHR-Net: A hardware -friendly solution for high -resolution computational imaging using a mixed -weights neural network	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						169	181		10.1016/j.neucom.2020.04.010													
J								Adaptive neural optimal control of uncertain nonlinear systems with output constraints	NEUROCOMPUTING											DYNAMIC SURFACE CONTROL; CONTINUOUS-TIME SYSTEMS; FUZZY CONTROL; TRACKING CONTROL; BACKSTEPPING CONTROL; DESIGN; ALGORITHM																		0925-2312	1872-8286				SEP 17	2020	406						182	195		10.1016/j.neucom.2020.04.007													
J								Dynamic state estimation for islanded microgrids with multiple fading measurements	NEUROCOMPUTING											POWER-SYSTEMS; MISSING MEASUREMENTS; FUSION ESTIMATION; ATTENUATION; INVERTERS; SUBJECT																		0925-2312	1872-8286				SEP 17	2020	406						196	203		10.1016/j.neucom.2020.03.104													
J								A Koopman operator approach for machinery health monitoring and prediction with noisy and low -dimensional industrial time series	NEUROCOMPUTING											DYNAMIC-MODE DECOMPOSITION; SPECTRAL-ANALYSIS; SYSTEMS																		0925-2312	1872-8286				SEP 17	2020	406						204	214		10.1016/j.neucom.2020.04.005													
J								Xnet: Task -specific attentional domain adaptation for satellite -to -aerial scene	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						215	223		10.1016/j.neucom.2020.04.036													
J								Synchronization of multi -links impulsive fractional -order complex networks via feedback control based on discrete -time state observations	NEUROCOMPUTING											MITTAG-LEFFLER SYNCHRONIZATION; STOCHASTIC COUPLED SYSTEMS; NEURAL-NETWORKS; GLOBAL SYNCHRONIZATION; INTERMITTENT CONTROL; FINITE-TIME; STABILIZATION; STABILITY; MODEL																		0925-2312	1872-8286				SEP 17	2020	406						224	233		10.1016/j.neucom.2020.04.024													
J								Deep network compression based on partial least squares	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						234	243		10.1016/j.neucom.2020.03.108													
J								Extended dissipative state estimation of delayed stochastic neural networks ?	NEUROCOMPUTING											TIME-VARYING DELAY; LEAKAGE DELAY; STABILITY; SYSTEMS; SYNCHRONIZATION; SUBJECT																		0925-2312	1872-8286				SEP 17	2020	406						244	252		10.1016/j.neucom.2020.03.106													
J								Elastic exponential linear units for convolutional neural networks	NEUROCOMPUTING											NOISE																		0925-2312	1872-8286				SEP 17	2020	406						253	266		10.1016/j.neucom.2020.03.051													
J								StainCNNs: An efficient stain feature learning method	NEUROCOMPUTING											COLOR NORMALIZATION; IMAGE																		0925-2312	1872-8286				SEP 17	2020	406						267	273		10.1016/j.neucom.2020.04.008													
J								Bipartite output consensus for heterogeneous multi -agent systems via re duce d-order observer-base d protocols	NEUROCOMPUTING											TRACKING; NETWORKS																		0925-2312	1872-8286				SEP 17	2020	406						274	281		10.1016/j.neucom.2020.04.006													
J								NEW: A generic learning model for tie strength prediction in networks	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						282	292		10.1016/j.neucom.2020.03.053													
J								Unsupervised urban scene segmentation via domain adaptation	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						295	301		10.1016/j.neucom.2020.01.117													
J								Knowledge attention sandwich neural network for text classification	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						1	11		10.1016/j.neucom.2020.03.093													
J								Surrogate -Assisted Evolutionary Search of Spiking Neural Architectures in Liquid State Machines	NEUROCOMPUTING											NETWORKS; OPTIMIZATION; FRAMEWORK																		0925-2312	1872-8286				SEP 17	2020	406						12	23		10.1016/j.neucom.2020.04.079													
J								Attention -guided dual spatial -temporal non -local network for video super -resolution	NEUROCOMPUTING											SINGLE IMAGE SUPERRESOLUTION																		0925-2312	1872-8286				SEP 17	2020	406						24	33		10.1016/j.neucom.2020.03.068													
J								Local and nonlocal constraints for compressed sensing video and multi -view image recovery	NEUROCOMPUTING											SIGNAL RECOVERY; RECONSTRUCTION; NETWORKS																		0925-2312	1872-8286				SEP 17	2020	406						34	48		10.1016/j.neucom.2020.04.072													
J								Revisiting metric learning for few -shot image classification	NEUROCOMPUTING											FACE																		0925-2312	1872-8286				SEP 17	2020	406						49	58		10.1016/j.neucom.2020.04.040													
J								A Cross -Modal Multi -granularity Attention Network for RGB-IR Person Re -identification	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						59	67		10.1016/j.neucom.2020.03.109													
J								MRCDRL: Multi -robot coordination with deep reinforcement learning	NEUROCOMPUTING											GAME; GO																		0925-2312	1872-8286				SEP 17	2020	406						68	76		10.1016/j.neucom.2020.04.028													
J								Mean -removed product quantization for large-scale image retrieval	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						77	88		10.1016/j.neucom.2020.04.026													
J								Deep 3D Facial Landmark Localization on position maps	NEUROCOMPUTING											FACE RECOGNITION; REGRESSION																		0925-2312	1872-8286				SEP 17	2020	406						89	98		10.1016/j.neucom.2020.04.025													
J								An inertial projection neural network for solving inverse variational inequalities	NEUROCOMPUTING											GLOBAL EXPONENTIAL STABILITY; OPTIMIZATION PROBLEMS; DESIGN																		0925-2312	1872-8286				SEP 17	2020	406						99	105		10.1016/j.neucom.2020.04.023													
J								Refinedbox: Refining for fewer and high -quality object proposals	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						106	116		10.1016/j.neucom.2020.04.017													
J								Chimeras in an adaptive neuronal network with burst -timing -dependent plasticity	NEUROCOMPUTING											TERM SYNAPTIC PLASTICITY; SYNCHRONIZATION; STATES; CIRCUIT; MEMORY																		0925-2312	1872-8286				SEP 17	2020	406						117	126		10.1016/j.neucom.2020.03.083													
J								DTMMN: Deep transfer multi -metric network for RGB-D action recognition	NEUROCOMPUTING											MULTIMODALITY; DESCRIPTORS																		0925-2312	1872-8286				SEP 17	2020	406						127	134															
J								A Brief Survey on Semantic Segmentation with Deep Learning	NEUROCOMPUTING											NETWORK; MODEL; REGRESSION; IMAGES; VIDEO																		0925-2312	1872-8286				SEP 17	2020	406						302	321		10.1016/j.neucom.2019.11.118													
J								Rapido: Scaling blockchain with multi -path payment channels	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						322	332		10.1016/j.neucom.2019.09.114													
J								Similarity preserving feature generating networks for zero -shot learning	NEUROCOMPUTING											CODES																		0925-2312	1872-8286				SEP 17	2020	406						333	342		10.1016/j.neucom.2019.08.111													
J								Destination prediction using deep echo state network	NEUROCOMPUTING											CLASSIFICATION																		0925-2312	1872-8286				SEP 17	2020	406						343	353		10.1016/j.neucom.2019.09.115													
J								Detecting thoracic diseases via representation learning with adaptive sampling *	NEUROCOMPUTING											PNEUMONIA; CLASSIFICATION																		0925-2312	1872-8286				SEP 17	2020	406						354	360		10.1016/j.neucom.2019.06.113													
J								Spectral representation learning for one-step spectral rotation clustering	NEUROCOMPUTING											UNSUPERVISED FEATURE-SELECTION; HYPERGRAPH																		0925-2312	1872-8286				SEP 17	2020	406						361	370		10.1016/j.neucom.2019.09.108													
J								Privacy preserving online matching on ridesharing platforms	NEUROCOMPUTING																													0925-2312	1872-8286				SEP 17	2020	406						371	377		10.1016/j.neucom.2019.09.116													
J								Evaluating facial recognition web services with adversarial and synthetic samples	NEUROCOMPUTING											FACE RECOGNITION																		0925-2312	1872-8286				SEP 17	2020	406						378	385		10.1016/j.neucom.2019.11.117													
J								TDHPPIR: An Efficient Deep Hashing Based Privacy-Preserving Image Retrieval Method	NEUROCOMPUTING										Privacy-preserving; Image retrieval; Deep hashing; CNN	NETWORKS; MODEL	With the rapid development of multimedia techniques, mobile Internet and cloud computing, large-scale image retrieval service has become a necessity in our daily life. To overcome the challenges of privacy-preserving and data security during the image retrieval, we propose a novel deep hashing based privacy-preserving image retrieval method named TDHPPIR that can generate high quality hash codes of image and provide an efficient index structure for fast image retrieval in a security manner in cloud. A triplet Deep CNN structure model is introduced to learn deep visual representations and hash codes of images simultaneously, which can generate higher quality hash codes than the traditional way that mainly utilizes hand-crafted features. Besides, A novel hierachical bit-scalable hash codes based S-Tree, named H2S-Tree, is developed to increase the search efficiency. Comprehensive experiments on four benchmarks show that our method can combat the state-of-the-arts in both aspects of accuracy and efficiency. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				SEP 17	2020	406						386	398		10.1016/j.neucom.2019.11.119													
J								Meta-heuristic approach for solving multi-objective path planning for autonomous guided robot using PSO-GWO optimization algorithm with evolutionary programming	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Path planning; PSO; GWO	LOCALIZATION; NAVIGATION; CONTROLLER	As path planning is an NP-hard problem it can be solved by multi-objective algorithms. In this article, we propose a multi-objective path planning algorithm which consists of three steps: (1) the first step consists of optimizing a path by the hybridization of the Grey Wolf optimizer-particle swarm optimization algorithm, it minimizes the path distance and smooths the path. (2) the second step, all optimal and feasible points generated by PSO-GWO algorithm are integrated with Local Search technique to convert any infeasible point into feasible point solution, the last step (3) depends on collision avoidance and detection algorithm, where mobile robot detects the presence of an obstacle in its sensing circle and then avoid them using collision avoidance algorithm. The proposed method is further improved by adding the mutation operators by evolutionary, it further solves path safety, length, and smooths it further for a mobile robot. Different simulations have been performed under numerous environments to test the feasibility of the proposed algorithm and it is shown the algorithm produces a more feasible path with a short distance and thus proves that it overcomes the shortcomings of other conventional techniques.																	1868-5137	1868-5145															10.1007/s12652-020-02514-w		SEP 2020											
J								An intrusion detection algorithm based on data streams mining and cognitive computing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cognitive computing; Closed frequent item mining; Intrusion detection; Data streams	EFFICIENT; ENCRYPTION; ITEMSETS; SYSTEMS	With the emergence of large-volume and high-speed streaming data, traditional techniques for mining closed frequent itemsets has become inefficient. Online mining of closed frequent itemsets over streaming data is one of the most important issues in data streams minging. In view of the low efficiency of traditional closed frequent item data mining, a combined data structure based on the principle of cognitive computing is proposed, that is, combining the effective bit first with the extended dictionary frequent item list to form a mixed data structure that can identify the closed frequent information in data streams. At the same time, a variety of pruning strategies based on cognitive computing are proposed to avoid the generation of a large number of intermediate itemsets and to remove the non closed frequent term sets from the Hash Table of Closed Itemsets (CIHT). Closed Frequent Itemset Deletion and Search Strategy (CFIDWSS) is used to effectively add or remove the closed frequent itemsets, so as to greatly reduce the search space and improve the user response speed. The proposed algorithm solves the problem of low efficiency of data streams mining of closed frequent items. On the basis of the above algorithms, this paper proposes a new intrusion detection model. Through the mining of normal or abnormal patterns of data stream information, the corresponding database of network access pattern is established. Then the database is used to detect the intrusion online in real time and improve the detection accuracy of the system. Theoretical and experimental results show that the proposed algorithm and intrusion detection system have good performance.																	1868-5137	1868-5145															10.1007/s12652-020-02543-5		SEP 2020											
J								Deep learning based an automated skin lesion segmentation and intelligent classification model	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										IoMT; Skin lesion; Deep learning; Artifact removal; Feature extraction	IMAGES; MELANOMA; INTERNET	Internet of Medical Things (IoMT) includes interconnected sensors, wearable devices, medical devices, and clinical systems. At the same time, skin cancer is a commonly available type of cancer that exists all over the globe. This study projects a new segmentation based classification model for skin lesion diagnosis by combining a GrabCut algorithm and Adaptive Neuro-Fuzzy classifier (ANFC) model. The proposed method involves four main steps: preprocessing, segmentation, feature extraction, and classification. Initially, the preprocessing step is carried out using a Top hat filter and inpainting technique. Then, the Grabcut algorithm is used to segment the preprocessed images. Next, the feature extraction process takes place by the use of a deep learning based Inception model. Finally, an adaptive neuro-fuzzy classifier (ANFC) system gets executed to classify the dermoscopic images into different classes. The proposed model is simulated using a benchmark International Skin Imaging Collaboration (ISIC) dataset and the results are examined interms of accuracy, sensitivity and specificity. The proposed model exhibits better identification and classification of skin cancer. For examining the effective outcome of the projected technique, an extensive comparison of the presented method with earlier models takes place. The experimental values indicated that the proposed method has offered a maximum sensitivity of 93.40%, specificity of 98.70% and accuracy of 97.91%.																	1868-5137	1868-5145															10.1007/s12652-020-02537-3		SEP 2020											
J								I-SiamIDS: an improved Siam-IDS for handling class imbalance in network-based intrusion detection systems	APPLIED INTELLIGENCE										Network-based intrusion detection system (NIDS); Class imbalance; Siamese neural network (Siamese-NN); eXtreme gradient boosting (XGBoost); Deep neural network (DNN); NSL-KDD dataset; CIDDS-001 dataset	SMOTE	Network-based Intrusion Detection Systems (NIDSs) identify malicious activities by analyzing network traffic. NIDSs are trained with the samples of benign and intrusive network traffic. Training samples belong to either majority or minority classes depending upon the number of available instances. Majority classes consist of abundant samples for the normal traffic as well as for recurrent intrusions. Whereas, minority classes include fewer samples for unknown events or infrequent intrusions. NIDSs trained on such imbalanced data tend to give biased predictions against minority attack classes, causing undetected or misclassified intrusions. Past research works handled this class imbalance problem using data-level approaches that either increase minority class samples or decrease majority class samples in the training data set. Although these data-level balancing approaches indirectly improve the performance of NIDSs, they do not address the underlying issue in NIDSs i.e. they are unable to identify attacks having limited training data only. This paper proposes an algorithm-level approach called Improved Siam-IDS (I-SiamIDS), which is a two-layer ensemble for handling class imbalance problem. I-SiamIDS identifies both majority and minority classes at the algorithm-level without using any data-level balancing techniques. The first layer of I-SiamIDS uses an ensemble of binary eXtreme Gradient Boosting (b-XGBoost), Siamese Neural Network (Siamese-NN) and Deep Neural Network (DNN) for hierarchical filtration of input samples to identify attacks. These attacks are then sent to the second layer of I-SiamIDS for classification into different attack classes using multi-class eXtreme Gradient Boosting classifier (m-XGBoost). As compared to its counterparts, I-SiamIDS showed significant improvement in terms of Accuracy, Recall, Precision, F1-score and values of Area Under the Curve (AUC) for both NSL-KDD and CIDDS-001 datasets. To further strengthen the results, computational cost analysis was also performed to study the acceptability of the proposed I-SiamIDS.																	0924-669X	1573-7497															10.1007/s10489-020-01886-y		SEP 2020											
J								Analysis of coordinated behavior structures with multi-agent deep reinforcement learning	APPLIED INTELLIGENCE										Multi-agent deep reinforcement learning; Cooperation; Coordination; Norm; Divisional cooperation	DYNAMICS	Cooperation and coordination are major issues in studies on multi-agent systems because the entire performance of such systems is greatly affected by these activities. The issues are challenging however, because appropriate coordinated behaviors depend on not only environmental characteristics but also other agents' strategies. On the other hand, advances in multi-agent deep reinforcement learning (MADRL) have recently attracted attention, because MADRL can considerably improve the entire performance of multi-agent systems in certain domains. The characteristics of learned coordination structures and agent's resulting behaviors, however, have not been clarified sufficiently. Therefore, we focus here on MADRL in which agents have their own deep Q-networks (DQNs), and we analyze their coordinated behaviors and structures for thepickup and floor laying problem, which is an abstraction of our target application. In particular, we analyze the behaviors around scarce resources and long narrow passages in which conflicts such as collisions are likely to occur. We then indicated that different types of inputs to the networks exhibit similar performance but generate various coordination structures with associated behaviors, such as division of labor and a shared social norm, with no direct communication.																	0924-669X	1573-7497															10.1007/s10489-020-01832-y		SEP 2020											
J								Consensus-based robust decision making methods under a novel study of probabilistic uncertain linguistic information and their application in Forex investment	ARTIFICIAL INTELLIGENCE REVIEW										Multi-attribute group decision making; Probabilistic uncertain linguistic term set; Consensus measure; Consensus-based PUL-GLDS method; Consensus-based-PUL-aggregation method	TERM SETS; PREFERENCE RELATIONS; MODEL; DEAL	The probabilistic uncertain linguistic terms set (PULTS) is an effective tool to depict uncertain linguistic opinions of individuals or groups in the procedure of decision making. Motivated by the power of PULTS and the linguistic scale function, this study aims to propose robust techniques to solve multi-attribute group decision making problems with uncertain linguistic evaluations. To enrich calculation and enhance the flexibility of PULTS, we first generalize the aggregation formula to fuse opinions of decision makers represented as PULTSs and secondly derive adjusting rule of probability to adjust the probability distribution of two or more than two probabilistic uncertain elements (PULEs) into the same probability distribution. Novel operations of PULTSs are designed based on the adjusting rule of probability distribution and linguistic scale function for the semantics of linguistic terms. Many related properties of these operations are also discussed. New score function and deviation degree of PULEs are also developed to compare PULEs. Two aggregation operators i.e., probabilistic uncertain linguistic averaging (PULWA) operator and probabilistic uncertain linguistic geometric (PULWG) operator are also redefined in terms of novel operations. In addition, a series of distance measure is defined to overcome the shortcomings of existing ones. After defining a correlation measure, the probabilistic uncertain linguistic (PUL)-consensus reaching method (in which two specific consensus approaches are described separately) is put forward to refine the consensus level of a group. To suit the needs of different semantics, two robust decision making methods named as consensus-based PUL-gained and lost dominance score method and consensus-based PUL-aggregation method are proposed. Finally, a case study concerning the selection of the best commodity for investment in Forex is conducted to illustrate the practicality of the proposed methods. Lastly, a detailed comparative analysis is done with the existing technique to highlight the improvements and advantages of proposed work.																	0269-2821	1573-7462															10.1007/s10462-020-09900-y		SEP 2020											
J								Electrocardiogram signals-based user authentication systems using soft computing techniques	ARTIFICIAL INTELLIGENCE REVIEW										ECG; Authentication; Security; Feature selection; SVM; CNN; Deep learning	BIOMETRIC AUTHENTICATION; ECG AUTHENTICATION; EXISTING AUTHENTICATION; NEURAL-NETWORK; MOBILE; FUSION; FINGERPRINT; SECURITY; INTERNET; SCHEMES	With the advent of various security attacks, biometric authentication methods are gaining momentum in the security literature. Electrocardiogram or ECG signals are one of the essential biometric features generated by the human heart's electrical activities. Many authentication schemes apply these signals due to their uniqueness, resistance to fabrication attacks, and support for continuous authentication. This survey article focuses on the ECG-based authentication approaches and provides the required background knowledge about the ECG signals and authentication methods. Then, it presents a taxonomy of the ECG-based authentication approaches first based on the authentication factors and then according to the applied algorithms for conducting authentication. It then describes their key contributions, applied algorithms, and possible drawbacks. Furthermore, their employed evaluation factors, ECG datasets, and simulators are illuminated and compared. Finally, the concluding remarks and future studies directions in this context are provided.																	0269-2821	1573-7462															10.1007/s10462-020-09863-0		SEP 2020											
J								A modified teaching learning metaheuristic algorithm with opposite-based learning for permutation flow-shop scheduling problem	EVOLUTIONARY INTELLIGENCE										Evolutionary algorithms; Opposite-based learning; Permutation flow-shop scheduling problem; Teaching-learning-based optimization	DIFFERENTIAL EVOLUTION ALGORITHM; TABU SEARCH ALGORITHM; OPTIMIZATION ALGORITHM; CUCKOO SEARCH; SHOP; MAKESPAN	Teaching-Learning-Based Optimization is one of the well-known metaheuristic algorithm in the research industry. Recently, various population-based algorithms have been developed for solving optimization problems. In this paper, a random scale factor approach is proposed to modify the simple TLBO algorithm. Modified Teaching-Learning-Based Optimization with Opposite-Based-Learning algorithm is applied to solve the Permutation Flow-Shop-Scheduling Problem with the purpose of minimizing the makespan. The OBL approach is used to enhance the quality of the initial population and convergence speed. PFSSP is used extensively for solving scheduling problem, which belongs to the category of NP-hard optimization problems. First, MTLBO is developed to effectively determine the PFSSP using the Largest Order Value rule-based random key, so that individual job schedules are converted into discrete schedules. Second, new initial populations are generated in MTLBO using the Nawaz-Enscore-Ham heuristic mechanism. Finally, the local exploitation ability is enhanced in the MTLBO using effective swap, insert and inverse structures. The performance of proposed algorithm is validated using ten benchmark functions and the Wilcoxon rank test. The computational results and comparisons indicate that the proposed algorithm outperformed over five well-known datasets such as Carlier, Reeves, Heller, Taillards and VRF benchmark test functions, compared to other metaheuristic algorithms. Thep-value indicated the significance and superiority of the proposed algorithm over other metaheuristic algorithms.																	1864-5909	1864-5917															10.1007/s12065-020-00487-5		SEP 2020											
J								Fusion model based on entropy by using optimized DCNN and iterative seed for multilane detection	EVOLUTIONARY INTELLIGENCE										Driver assistance systems; Lane detection; Entropy; Deep convolutional neural network; Region based segmentation; Earth worm-crow search algorithm; Fusion model	LANE DETECTION	The recent progress in the DSAs led to the progress of advanced lane detection systems for preventing accidents. The information about the lane is detected, which is used for the vehicle control and provide warning to the drivers. This paper proposes the multi-lanes detection based on an entropy-based fusion approach. The main use of the proposed model for combining the results obtained by the EW-CSA based DCNN and iterative seed based on region for providing efficient multilane detection. Initially, the lanes are detected using a deep learning technique that is trained using an optimization algorithm, EW-CSA. Similarly, the approach namely segmentation based on region is used for the detection of multi-lane. Depends on the results of the two approaches, an fusion model based on entropy is proposed for making the best results, based on a pre-defined threshold. The proposed method performance is evaluated based on the metrics, such as specificity, accuracy, and sensitivity, which outperforms with values 0.887, 0.991, and 0.992, respectively.																	1864-5909	1864-5917															10.1007/s12065-020-00480-y		SEP 2020											
J								Fuzzy Adaptive Fault-Tolerant Control for Non-identifiable Multi-agent Systems under Switching Topology	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy logic system; Fault-tolerant control; Adaptive control; Actuator faults	COMPLEX DYNAMICAL NETWORKS; TRACKING CONTROL; SYNCHRONIZATION; CONSENSUS; LEADER	This paper considers the leader-following consensus problem for linear multi-agent systems (MASs) with actuator faults, matched unknown nonlinearity and non-identifiable uncertainty under switching network topology for studying. A novel distributed switching fault-tolerant controller is established by approximating the nonlinear dynamics using a fuzzy logic system and by developing adaptive update laws with switching mechanisms. Besides, by introducing an adaptive mechanism to estimate the norm of weight vectors in the FLS, the developed controller can not only reduce the number of adaptive parameters but also is effective to compensate for unknown nonlinearity under the influence of actuator faults. Furthermore, it can be shown that the consensus errors are uniformly ultimately bounded by utilizing the proposed method. Compared with the existing MASs' results with switching network topology, the nonlinearity considered is completely unknown and fewer adaptive parameters are used to counteract the influence of nonlinearity. Finally, the efficiency and effectiveness of the developed approach are demonstrated by an illustrative example.																	1562-2479	2199-3211				OCT	2020	22	7					2246	2257		10.1007/s40815-020-00926-6		SEP 2020											
J								TermInformer: unsupervised term mining and analysis in biomedical literature	NEURAL COMPUTING & APPLICATIONS										Term mining; Unsupervised learning; Term embeddings; Sequence labelling; GloVe; Biomedical literature	ANOMALY DETECTION; DEEP; HEALTH	Terminology is the most basic information that researchers and literature analysis systems need to understand. Mining terms and revealing the semantic relationships between terms can help biomedical researchers find solutions to some major health problems and motivate researchers to explore innovative biomedical research issues. However, how to mine terms from biomedical literature remains a challenge. At present, the research on text segmentation in natural language processing (NLP) technology has not been well applied in the biomedical field. Named entity recognition models usually require a large amount of training corpus, and the types of entities that the model can recognize are limited. Besides, dictionary-based methods mainly use pre-established vocabularies to match the text. However, this method can only match terms in a specific field, and the process of collecting terms is time-consuming and labour-intensive. Many scenarios faced in the field of biomedical research are unsupervised, i.e. unlabelled corpora, and the system may not have much prior knowledge. This paper proposes the TermInformer project, which aims to mine the meaning of terms in an open fashion by calculating terms and find solutions to some of the significant problems in our society. We propose an unsupervised method that can automatically mine terms in the text without relying on external resources. Our method can generally be applied to any document data. Combined with the word vector training algorithm, we can obtain reusable term embeddings, which can be used in any NLP downstream application. This paper compares term embeddings with existing word embeddings. The results show that our method can better reflect the semantic relationship between terms. Finally, we use the proposed method to find potential factors and treatments for lung cancer, breast cancer, and coronavirus.																	0941-0643	1433-3058															10.1007/s00521-020-05335-2		SEP 2020											
J								Seeing like an algorithm: operative images and emergent subjects	AI & SOCIETY										Algorithmic vision; Big data; Operational image; Machine learning; Algorithms		Algorithmic vision, the computational process of making meaning from digital images or visual information, has changed the relationship between the image and the human subject. In this paper, I explicate on the role of algorithmic vision as a technique of algorithmic governance, the organization of a population by algorithmic means. With its roots in the United States post-war cybernetic sciences, the ontological status of the computational image undergoes a shift, giving way to the hegemonic use of automated facial recognition technologies towards predatory policing and profiling practices. By way of example, I argue that algorithmic vision reconfigures the philosophical links between vision, image, and truth, paradigmatically changing the way a human subject is represented through imagistic data. With algorithmic vision, the relationship between subject and representation challenges the humanistic discourse around images, calling for a critical displacement of the human subject from the center of an analysis of how computational images make meaning. I will explore the relationship between theoperative image, the image that acts but is not seen by human eyes, and what Louise Amoore calls an "emergent subject," a subject that is made visible through algorithmic techniques (2013). Algorithmic vision reveals subjects to power in a mode that requires a new approach towards analyzing the entanglement and invisiblization of the human in automated decision-making systems.																	0951-5666	1435-5655															10.1007/s00146-020-01067-y		SEP 2020											
J								Fast and slow curiosity for high-level exploration in reinforcement learning	APPLIED INTELLIGENCE										Reinforcement learning; Exploration; Autonomous exploration; Curiosity in reinforcement learning		Deep reinforcement learning (DRL) algorithms rely on carefully designed environment rewards that are extrinsic to the agent. However, in many real-world scenarios rewards are sparse or delayed, motivating the need for discovering efficient exploration strategies. While intrinsically motivated agents hold promise of better local exploration, solving problems that require coordinated decisions over long-time horizons remains an open problem. We postulate that to discover such strategies, a DRL agent should be able to combine local and high-level exploration behaviors. To this end, we introduce the concept of fast and slow curiosity that aims to incentivize long-time horizon exploration. Our method decomposes the curiosity bonus into a fast reward that deals with local exploration and a slow reward that encourages global exploration. We formulate this bonus as the error in an agent's ability to reconstruct the observations given their contexts. We further propose to dynamically weight local and high-level strategies by measuring state diversity. We evaluate our method on a variety of benchmark environments, including Minigrid, Super Mario Bros, and Atari games. Experimental results show that our agent outperforms prior approaches in most tasks in terms of exploration efficiency and mean scores.																	0924-669X	1573-7497															10.1007/s10489-020-01849-3		SEP 2020											
J								HFADE-FMD: a hybrid approach of fireworks algorithm and differential evolution strategies for functional module detection in protein-protein interaction networks	APPLIED INTELLIGENCE										Protein-protein interaction network; Functional module detection; Fireworks algorithm; Explosion operation; Differential evolution strategies	BACTERIAL FORAGING OPTIMIZATION; KRILL HERD ALGORITHM; PARTICLE SWARM; COMPLEXES	Functional module detection in protein-protein interaction (PPI) network is one important content of the proteomics research in the post-genomic era. Nowadays the swarm intelligence and evolutionary based approaches have become effective ways for detecting functional modules. This paper proposes a novel hybrid approach of fireworks algorithm and differential evolution strategies for functional module detection in PPI networks (called HFADE-FMD). HFADE-FMD first initializes each firework individual into a candidate functional module partition based on label propagation according to the topological and functional information between protein nodes. Then HFADE-FMD uses the explosion operator of firework algorithm, and mutation, crossover and selection strategies of differential evolution algorithm to iteratively search for better functional module partitions. To verify the performance of HFADE-FMD, this paper compared it with ten competitive methods on four public PPI datasets. The experimental results show that HFADE-FMD achieves prominent performance with respective to Recall, Sn, PPV, and ACC metrics while performing well in terms of Precision and F-measure metrics. Thus, it is able to more accurately detect functional modules and help biologists to find some novel biological insights.																	0924-669X	1573-7497															10.1007/s10489-020-01791-4		SEP 2020											
J								Image robust recognition based on feature-entropy-oriented differential fusion capsule network	APPLIED INTELLIGENCE										Robust recognition; Capsule network; Differential fusion; Feature-entropy-oriented	CNN	In solving the black box attribute problem of neural networks, how to extract feature information in data and generalize inherent features of data are the focus of artificial intelligence research. Aiming at the problem of the weak generalization ability of large image transformation under deep convolutional networks, a new method for image robust recognition based on a feature-entropy-oriented differential fusion capsule network (DFC) is proposed, the core of which is feature entropy approximation. First, convolution feature entropy is introduced as the transformation metric at the feature extraction level, and a convolution difference scale space is constructed using a residual network to approximate the similar entropy. Then, based on this scale feature, convolution feature extraction in a lower scale space is carried out and fused with the last scale feature to form a convolution differential fusion feature. Finally, a capsule network is used to autonomously cluster using dynamic routing to complete the semantic learning of various high-dimensional features, thereby further enhancing the recognition robustness. Experimental results show that feature entropy can effectively evaluate the transformation image recognition effect, and the DFC is effective for robust recognition with large image transformations such as image translation, rotation, and scale transformation.																	0924-669X	1573-7497															10.1007/s10489-020-01873-3		SEP 2020											
J								A relation between moments of Liu process and Bernoulli numbers	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Liu process; Bernoulli numbers; Inverse uncertainty distribution	STABILITY	This paper finds a relation between moments of Liu process and Bernoulli numbers. Firstly, by an exponential generating function of Bernoulli numbers, a useful integral formula is obtained. Secondly, based on this integral formula, the moments of a normal uncertain variable and Liu process are expressed via Bernoulli numbers.																	1568-4539	1573-2908															10.1007/s10700-020-09338-5		SEP 2020											
J								Analysis and prediction of confirmed COVID-19 cases in China with uncertain time series	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Uncertain time series; Uncertain hypothesis test; COVID-19		This paper presents an uncertain time series model to analyse and predict the evolution of confirmed COVID-19 cases in China, excluding imported cases. Compared with the results of the classical time series model, the uncertain time series model could better describe the COVID-19 epidemic by using an uncertain hypothesis test to filter out outliers. This improvement is reflected in the two observations. One is that the estimated variance of the disturbance term in the uncertain time series model is more appropriate and acceptable than that in the classical time series model, and the other is that the disturbance term of the classical time series model cannot be regarded as a random variable but as an uncertain variable.																	1568-4539	1573-2908															10.1007/s10700-020-09339-4		SEP 2020											
J								Impurities detection in edible bird's nest using optical segmentation and image fusion	MACHINE VISION AND APPLICATIONS										Edible bird's nest; Impurity inspection; Optical segmentation; Image analysis; LED lightings; Image fusion	QUALITY; FOOD	The cleanliness of edible bird's nest (EBN) is among the determinative factors for market acceptance. As it is meant for human consumption, EBN should be free of any impurities or matter which are foreign to it, such as bird feathers, egg fragments and droppings. However, natural variations in composition, density and thickness impose inconsistency to the level of translucency and colour of EBN, resulting in intensity inhomogeneity in EBN images that substantially reduce the accuracy of the segmentation and detection of impurities. Consequently, the segmentation and detection of impurities, which are essential to visual automation in the cleaning and inspection processes, remain unsolved. This work proposes a novel optical segmentation method to segment impurities from the EBN, in order to facilitate the detection of impurities. EBN images captured under two different lighting scenarios, namely, low-angle blue-diffused lighting and red-diffused backlighting, were used to prepare the fused image for background-EBN-impurities segmentation. The applicability of the method was demonstrated by comparing the detection results with those of human inspectors. With a simple thresholding operation performed on fused images, the impurities detection algorithm recorded a true positive/recall rate of 93.39%, a precision of 71.17% and a false-negative detection rate of 4.8%. Despite the high misclassification rate of 32.25%, the algorithm was able to detect more than 93% of the impurities, compared to human inspectors, who required a second examination on the EBNs.																	0932-8092	1432-1769				SEP 16	2020	31	7-8							68	10.1007/s00138-020-01124-y													
J								Decision making based on linguistic interval-valued intuitionistic neutrosophic Dombi fuzzy hybrid weighted geometric operator	SOFT COMPUTING										Linguistic term; LIVINDFWG operator; LIVINDFOWG operator; LIVINDFHWG operator; MCDM	ROUTING ALGORITHM; OPTIMIZATION ALGORITHM; AGGREGATION OPERATORS; SYSTEM; MODEL; SETS	In this paper, we proposed the notion of a linguistic interval-valued intuitionistic neutrosophic fuzzy number. We define some score and accuracy functions of LIVINFNs are defined with a brief study of related properties. Moreover, we propose the geometric forms of LIVINDFWG, LIVINDFOWG, and LIVINDFHWG operator, which is called the geometric operators. Then, we present its characteristics and some special cases. Moreover, we put forward two new MADM approaches founded on the developed LIVINDFWG and LIVINDFOWG operators. Finally, a representative example is provided to verify the effectiveness and superiority of the proposed method by comparing it with other several existing representative MAGDM methods.																	1432-7643	1433-7479				NOV	2020	24	21					15907	15925		10.1007/s00500-020-05282-z		SEP 2020											
J								The DIAMOND Model: Deep Recurrent Neural Networks for Self-Organizing Robot Control	FRONTIERS IN NEUROROBOTICS										deep neural networks; autonomous learning; homeokinesis; self-organizing control; robot control	ORGANIZATION	The proposed architecture applies the principle of predictive coding and deep learning in a brain-inspired approach to robotic sensorimotor control. It is composed of many layers each of which is a recurrent network. The component networks can be spontaneously active due to the homeokinetic learning rule, a principle that has been studied previously for the purpose of self-organized generation of behavior. We present robotic simulations that illustrate the function of the network and show evidence that deeper networks enable more complex exploratory behavior.																	1662-5218					SEP 15	2020	14								62	10.3389/fnbot.2020.00062													
J								Synchronous intercept strategies for a robotic defense-intrusion game with two defenders	AUTONOMOUS ROBOTS										Pursuit-evasion; Defense-intrusion; Synchronous intercept; Multi-robot systems	PURSUIT-EVASION GAMES; YELLOWSTONE-NATIONAL-PARK; COOPERATIVE PURSUIT; DIFFERENTIAL GAME; CAPTURE; TEAM	We study the defense-intrusion game, in which a single attacker robot tries to reach a stationary target that is protected by two defender robots. We focus on the "synchronous intercept problem", where both robots have to reach the attacker robotsynchronouslyto intercept it. Assume that the attacker robot has the control policy which is based on attraction to the target and repulsion from the defenders, two kinds of synchronous intercept strategies are proposed for the defense-intrusion game, introduced here asAttacker-orientedandNeutral-position-oriented. Theoretical analysis and simulation results show that: (1) the two strategies are able to generate different synchronous intercept patterns: contact intercept pattern and stable non-contact intercept pattern, respectively. (2) The contact intercept pattern allows the defender robots to intercept the attacker robot in finite time, while the stable non-contact intercept pattern generates a periodic attractor that prevents the attack robot from reaching the target for infinite time. There is potential to apply the insights obtained into defense-intrusion in real systems, including aircraft escort and the defense of military targets or territorial boundaries.																	0929-5593	1573-7527															10.1007/s10514-020-09945-6		SEP 2020											
J								Bio-inspired motivational architecture for autonomous robots using glucose and insulin theories	EVOLUTIONARY INTELLIGENCE										Motivational architecture; Cognitive robots; Intelligent robots; Glucose-insulin theory; Drives; Emotions	MINIMAL MODEL; SENSITIVITY	Motivation and emotions have been area of interest for philosophers, psychologists and neuroscientist. Researchers and scientists want to have human like intelligent robots which are self-aware and self-motivated. Motivational robots are autonomous and intelligent which can set goals and then take actions to achieve their goals independently. Moreover, intelligence in robots is not possible without autonomy and autonomy is incorporated in robots through motivation. Nowadays, attention is being paid to build robots which have computational and energy autonomy. In Literature, various motivational architectures have been presented but none seems to focus on the development of human inspired motivation in robots comprehensively. These architectures try to achieve mere functional motivation in limited way, some considered only time for the regulation of drives, others failed to incorporate physiological and psychological aspects of human motivation. To the best of our knowledge, no architecture is truly based on the physiology and psychology of humans has been considered in the literature. To solve this problem, this paper proposes a motivational architecture for autonomous robots to make them independent in deciding the goals and taking actions. The proposed architecture is primarily based on physiology and psychology of human motivation through basic human drives (hunger, thirst and sleep), emotions and glucose-insulin theories. The whole process of drives regulation is based on stimulation and satiation. The intensity of the drives and the emotional states help in setting the goal and accordingly a suitable action is taken to meet the particular goal. Empirical results show that glucose and insulin have direct relationship with basic drives and emotions in the process of intrinsic motivation generation. The proposed architecture has applications in industry, education and autonomous robots. The proposed motivational architecture has significant advantages over several state-of-the-art architectures in terms of autonomy through intrinsic motivation.																	1864-5909	1864-5917															10.1007/s12065-020-00489-3		SEP 2020											
J								Ambient assisted living predictive model for cardiovascular disease prediction using supervised learning	EVOLUTIONARY INTELLIGENCE										Internet of Things; Healthcare; Real-time monitoring; Wireless sensor networks; ML (machine learning); K-nearest neighbors (KNN); Naive Bayes (NB); Support vector machine (SVM); Evolutionary intelligence technique	WIRELESS SENSOR NETWORKS; ARTIFICIAL-INTELLIGENCE; HEALTH; PLATFORM; SYSTEMS	The rapid increase of the aged population and challenges towards taking health care and social care become the key point for the industry and researchers nowadays. Heart diseases are typical chronic illnesses with a high recurrence rate. In some of the cases, a heart attack occurs suddenly without any omens. Patients typically live in their homes rather than in hospitals and are often unable to access medical care in an emergency. Cardiovascular disease leads to a significant difficulty for the doctors to know the patient's status in time, and it becomes one of the significant reasons for death. To overcome these problems, a solution needs to design, implement, and validate adequately through an appropriate base knowledge. To overcome these challenges, remotely real-time patient's health data can be identified. Today Internet of Things is playing a key role in solving the problem of heart disease. The patients can avail of the medical resource much. This research work aims to propose a framework for prediction of heart disease using major risk factors based on various classifier arrangements; K-nearest neighbors, Naive Bayes, support vector machine, Lasso and ridge regression algorithms. Apart from these data classification, linear discriminant analysis and principal component analysis were done. The support vector machine provides 92% accuracy, and F1 accuracy is 85%. The performance of the proposed research work is evaluated using precision, accuracy, and sensitivity.																	1864-5909	1864-5917															10.1007/s12065-020-00484-8		SEP 2020											
J								Numerical solution of Bagley-Torvik equations using Legendre artificial neural network method	EVOLUTIONARY INTELLIGENCE										Fractional differential equation; Caputo fractional derivative; Legendre polynomial; Simulated annealing optimization technique	MODEL	In this article, we have used the Legendre artificial neural network to find the solution of the Bagley-Torvik equation, which is a fractional-order ordinary differential equation. Caputo fractional derivative has been considered throughout the presented work to handle the fractional order differential equation. The training of optimal weights of the network has been carried out using a simulated annealing optimization technique. Here we have presented three examples to exhibit the precision and relevance of the proposed technique with comparison to the other numerical methods with error analysis. The proposed technique is an easy, highly efficient, and robust technique for finding the approximate solution of fractional-order ordinary differential equations.																	1864-5909	1864-5917															10.1007/s12065-020-00481-x		SEP 2020											
J								Initial value estimation of uncertain differential equations and zero-day of COVID-19 spread in China	FUZZY OPTIMIZATION AND DECISION MAKING										Uncertainty theory; Uncertain statistics; Uncertain differential equation; COVID-19		Assume an uncertain process follows an uncertain differential equation, and some realizations of this process are observed. Parameter estimation for the uncertain differential equation that fits the observed data as much as possible is a core problem in practice. This paper first presents a problem of initial value estimation for uncertain differential equations and proposes an estimation method. In addition, the method of moments is recast for estimating the time-varying parameters in uncertain differential equations. Using those techniques, a COVID-19 spread model based on uncertain differential equation is derived, and the zero-day of COVID-19 spread in China is inferred.																	1568-4539	1573-2908															10.1007/s10700-020-09337-6		SEP 2020											
J								A Clustering Algorithm for Triangular Fuzzy Normal Random Variables	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy-probability binary measure space; Triangular fuzzy normal random variables; Euclidean random synthesis absolute distance; TFNRV-k-means clustering algorithm	AGREEMENT	In view of the fact that most clustering algorithms cannot solve the clustering problem about samples with uncertain information, according to the theory of fuzzy sets and probability, we define the fuzzy-probability binary measure space and triangular fuzzy normal random variables firstly, and then combine the advantages ofk-means algorithm, such as simple principle, few parameters, fast convergence rate, good clustering effect and good scalability, etc., a clustering algorithm is proposed for samples containing multiple triangular fuzzy normal random variables, which we call TFNRV-k-means algorithm. The algorithm uses our proposed Euclidean random comprehensive absolute distance (ERCAD for short) as a measurement, under the fuzzy measure, the lower bound, the principal value and the upper bound of the triangular fuzzy normal random variables are iterated, respectively, by means, and then the cluster center is updated until it becomes stable and unchanged. Then we analyze the time complexity of the proposed algorithm, and test the algorithm under different sample sets by random simulation experiments. We get the highest clustering accuracy of 99.00% and the maximum Kappa coefficient of 0.9850, and draw the conclusion that TFNRV-k-means clustering algorithm has good clustering effect. Finally, we summarize the content of the article, list the advantages and disadvantages of TFNRV-k-means clustering algorithm, and propose corresponding improvement methods, which provide ideas for further research on TFNRV-k-means in the future.																	1562-2479	2199-3211				OCT	2020	22	7					2083	2100		10.1007/s40815-020-00933-7		SEP 2020											
J								Closed Forms of the Interval Type 2 Fuzzy Sets Additions Based on Archimedean T-norms with Application in Decision Making Aggregation	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Triangular norm (t-norm); Generalized fuzzy number; Interval type 2 fuzzy number; Fuzzy addition; Multiple criteria decision making aggregration	OPERATIONS; NUMBERS	Fuzzy addition is one of the operations widely used in the application of fuzzy systems. The analytical and closed form expressions of the fuzzy additions of the generalized fuzzy numbers and the interval type 2 fuzzy numbers (IT2FS) are developed. The generalized fuzzy numbers is a non-flat and subnormal fuzzy number with different left and right shape functions. Classical fuzzy operations based on the minimum t-norm could lead to uncontrollable fuzziness. Fuzzy addition based on generalized t-norm can better control ambiguity. In order to control the ambiguity of fuzzy addition, this paper is to develop a general type 1 fuzzy set and interval type 2 fuzzy set (IT2FS) additions based on t-norm. The closed forms of the generalized IT2FS additions based on some popular t-norms are formulated. The specific analytical and closed form expressions based on Archimedean t-norms: e.g. drastic, Lukasiewicz, product and the families of Schweizer-Sklar and Yager t-norms are derived. The IT2FS are widely used to characterize the natural words, e.g. the decision making linguistic judgments, the fuzzy real time control systems with linguistic rules. Furthermore, based on the analytical T1FS additions results, the application to the linguistic multiple criteria decision making aggregation of the IT2FS additions based on t-norms is introduced. A comparative MCDM numerical example is demonstrated for the verification of the developed closed form expressions.																	1562-2479	2199-3211				OCT	2020	22	7					2300	2318		10.1007/s40815-020-00932-8		SEP 2020											
J								An Agent-Based System for the Design of New Products Using a Fuzzy Multicriteria Approach	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Marketing; Decision support systems; Agent technology; New product design; Multiobjective evolutionary algorithms; Multicriteria decision analysis	DECISION-SUPPORT-SYSTEM	The intense competition of global markets stimulates a significant change in the way products are designed, manufactured, and delivered. Such a situation is forcing companies to consider the use of new tools to support this decision process. This paper describes an agent-based system implementing a novel consumer-based fuzzy multicriteria methodology to support the design of new products. It argues that a combination of marketing decision support systems, multicriteria and multiobjective methodologies, fuzzy models, and agent technologies could be a valuable tool to assist marketing managers in new product design applications. In the multi-agent system architecture, software agents were classified into types and organized in teams. The first includes interface, task, and information agents. The second reflects Simon's decision-making process, including intelligence, design, and choice teams. The communication between agents is carried out using an ontology. An example of system operation attempting to get the design of new corn oil is presented using sequence diagrams.																	1562-2479	2199-3211															10.1007/s40815-020-00934-6		SEP 2020											
J								On integer closure in a system of unit two variable per inequality constraints	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										UTVPI constraints; Relaxation; Integer closure; Dijkstra's algorithm; Shortest paths	CERTIFYING ALGORITHM; FEASIBILITY	In this paper, we study the problem of computing the lattice point closure of a conjunction of Unit Two Variable Per Inequality (UTVPI) constraints. We accomplish this by adapting Johnson's all pairs shortest path algorithm to UTVPI constraint systems (UCSs). Thus, we obtain a closure algorithm that is efficient for sparse constraint systems. This problem has been extremely well-studied in the literature, since it arises in a number of applications, including but not limited to, program verification and operations research. In UTVPI constraints, linear feasibility does not always imply integer feasibility. Thus, there is a difference between the linear closure of a UCS and the integer closure of that same system. Finding the linear closure requires only a single inference rule called thetransitive inference rule.This inference rule corresponds to the addition of constraints and preserves both linear and integer solutions. The problem of finding the integer closure requires the use of the tightening inference rule. Unlike the transitive inference rule, the tightening inference rule does not preserve linear solutions. However, it does preserve integer solutions. The complexity of solving the integer closure problem has steadily improved over the past several decades with the fastest algorithm for this problem running in time O(n(3)) on a UCS withnvariables andmconstraints. For the same input parameters, we detail an algorithm that runs in time O(mn+n(2) log n). It is clear that our algorithm is superior to the state of the art when the UCS is sparse (m is an element of o(n(2))), and no worse than the state of the art when the UCS is dense (m is an element of Theta(n(2))). The best known running time for computing the closure of a conjunction of difference constraints (mconstraints, n variables) is O(mn+n(2)log n), and UTVPI constraints subsume difference constraints.																	1012-2443	1573-7470				OCT	2020	88	10					1101	1118		10.1007/s10472-020-09703-5		SEP 2020											
J								A new base basic probability assignment approach for conflict data fusion in the evidence theory	APPLIED INTELLIGENCE										Dempster-Shafer evidencve theory; Basic probability assignment; Conflict management; Conflicting data fusion	BELIEF FUNCTIONS; REASONING RULE; RELIABILITY; ALGORITHM	Dempster-Shafer evidence theory (D-S theory) is applied to process uncertain information in different scenarios. However, traditional Dempster combination rule may produce counterintuitive results while dealing with highly conflicting data. Inspired by a perspective of constructing base belief function for conflicting data processing in D-S theory, a new base basic probability assignment (bBPA) method is proposed to process the potential conflict before data fusion. Instead of assigning initial belief on the whole power set space, the new method assigns the base belief to basic events in the frame of discernment. Consequently, the bBPA is consistent with the classical probability theory. Several numerical examples are adopted to verify the reliability and accuracy of the method in processing highly conflicting data. The data sets in the University of California Irvine (UCI) Machine Learning Repository are used to verity the availability of the new method in classification problem. Experimental result shows that the new method has some superiority in dealing with highly conflicting data.																	0924-669X	1573-7497															10.1007/s10489-020-01876-0		SEP 2020											
J								Natural object manipulation using anthropomorphic robotic hand through deep reinforcement learning and deep grasping probability network	APPLIED INTELLIGENCE										Anthropomorphic robotic hand; Natural object grasping and relocation; Deep reinforcement learning; Human grasping hand poses; Deep grasping probability network; Natural policy gradient		Human hands can perform complex manipulation of various objects. It is beneficial if anthropomorphic robotic hands can manipulate objects like human hands. However, it is still a challenge due to the high dimensionality and a lack of machine intelligence. In this work, we propose a novel framework based on Deep Reinforcement Learning (DRL) with Deep Grasping Probability Network (DGPN) to grasp and relocate various objects with an anthropomorphic robotic hand much like a human hand. DGPN is used to predict the probability of successful human-like natural grasping based on the priors of human grasping hand poses and object touch areas. Thus, our DRL with DGPN rewards natural grasping hand poses according to object geometry for successful human-like manipulation of objects. The proposed DRL with DGPN is evaluated by grasping and relocating five objects including apple, light bulb, cup, bottle, and can. The performance of our DRL with DGPN is compared with the standard DRL without DGPN. The results show that the standard DRL only achieves an average success rate of 22.60%, whereas our DRL with DGPN achieves 89.40% for the grasping and relocation tasks of the objects.																	0924-669X	1573-7497															10.1007/s10489-020-01870-6		SEP 2020											
J								A new partial robust adaptive modified maximum likelihood estimator	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Partial least squares; Robust adaptive modified likelihood; Outliers; Robust estimation	PARTIAL LEAST-SQUARES; REGRESSION; PARAMETERS	Partial least squares (PLS) regression is a widely-used regression method for high-dimensional data. However, PLS is not robust to outlying observations since it uses partial information of the variables in a least squares (LS) setting, which is known to be very sensitive to outliers. Several proposals are available which robustify PLS. In this study, our aim is to propose a new partial robust estimator using robust adaptive modified maximum likelihood (RAMML) estimators [1, 2]. The resulting estimators are therefore called partial robust adaptive modified maximum likelihood estimators (PRAMMLs). The distinguished advantage of the PRAMMLs is that they are computationally straightforward. This is because of the fact that they are constructed based on explicitly formulated estimators. The simulation study shows that the PRAMMLs are preferable to PLS and other existing robust alternatives of PLS in terms of the mean squared error (MSE) criterion under different nonnormal error distributions, as well as in the presence of leverage points. The PRAMMLs also give satisfactory results in terms of the empirical influence function and breakdown robustness criteria.																	0169-7439	1873-3239				SEP 15	2020	204								104068	10.1016/j.chemolab.2020.104068													
