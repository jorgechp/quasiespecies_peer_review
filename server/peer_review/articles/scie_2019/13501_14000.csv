PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Achieving the best defuzzifier in terminology of Persian sentences through classified fuzzy method	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Fuzzy role; defuzzifier; terminology	CORPUS	Fuzzy logic is a multi-valued concept, whose emergence in software sciences has eliminated 0 and 1 computations, putting them within an infinite space of [0,1]. This characteristic of fuzzy logic has resolved ambiguity in numerous previous problems. The sentence roles in Persian language were specified based on the fuzzy logic's capability to resolve ambiguity. For that purpose, we first obtained the best classification for each defuzzifier, based on which a classified fuzzy was implemented. Nonetheless, the fuzzy system used in this research was classified based on statistical computations. To achieve the best classification, five defuzzification methods (Mean Of Max, Max Of Membership, Largest Of Max, Smallest Of Max, and Central Average) competed in 16 roles each in five classes (different matrices). Finally, Mean of Max with a success rate of 64% proved to be a defuzzifier delivering the best output among 5 different defuzzification methods.																	1064-1246	1875-8967					2020	39	3					2921	2934		10.3233/JIFS-191447													
J								An intelligent approach framework for decision-making risk analysis of Chinese hydropower corporations	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Chinese hydropower corporations; decision makers; decision-making risks; Bayesian network; triangular fuzzy; numbers	SUPPORT; SUSTAINABILITY; OPTIMIZATION; UNCERTAINTY; CLIMATE; PLANTS; MODEL; GHANA; DAM	An intelligent decision analytic framework for dealing with complex decision-making risk system is presented and Bayesian network (BN) approach is utilized to evaluate the influence of multilevel uncertainty in various risks (e.g., social, natural, economic, intracompany risks) on decision-making deviation of Chinese hydropower corporations. The technique of fuzzy probability is approached to calculate intricate parameters to the question of inference learning through the sensitivity and influence power analysis, the results of back inference show that there exists the risk transformation mechanism from external uncertain risks (e.g., social risks, ecological environment factors) to hydropower corporations' internal uncertainties closely relating to economic uncertainties through strategic planning. The study concerning identification and intelligent analysis of uncertain risks in decision-making process illustrates the feasibility and validity of applying BN and its pragmatic implications on hydropower corporations strategic planning and guidance in operational management.																	1064-1246	1875-8967					2020	39	3					2935	2945		10.3233/JIFS-191469													
J								Impact of government regulation of RPS on China's power market under carbon abatement constraints	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Renewable portfolio standards (RPS); China's power market; Carbon abatement; Government regulation; evolu-tionary strategy stability; system dynamics	RENEWABLE PORTFOLIO STANDARDS; FEED-IN TARIFF; TRADABLE GREEN CERTIFICATE; SYSTEM DYNAMICS; CO2 EMISSIONS; GENERATION EXPANSION; ELECTRICITY MARKET; UNITED-STATES; ENERGY; POLICY	In a significant period of Chinese energy reformation to the point of expediting revolution in energy production and consumption, and promoting green low-carbon upgrading transformation of energy electricity, Chinese government has to implement the obligatory policy of renewable portfolio standards (RPS) with specific institutional provisions sternly. The renewable energy quotas in thermal power industry with carbon emission abatement constraints particularly have a latent impact on the behavior of thermal electricity producers, which is ineluctably involved in electricity connection of grid companies. To make clear the positive role in boosting investment in renewable energy generation in thermal power industry under mandatory quotas requirements, we will utilize evolutionary game based on system dynamics (SD) to tackle with the sophisticated nexus among the government, thermal power producers and grid companies. We begin analysis of general evolutionary strategy stability in scenario ll by dynamically adjusting values of external variables of SD model to uncover pivotal variables affecting evolutionary strategy stability. Then in scenario I, the dynamic punishment structure consisting of cost elements to spark off the emulation of optimal manoeuvre selections of tripartite game agents is amended based on the simulation of vital variables affecting evolutionary strategy stability in scenario II. The significant conclusions provide decision-making support and management enlightenment for Chinese government to edge renewable energy generation capacity of thermal power producers and constrained degree of dynamic penalty for grid companies.																	1064-1246	1875-8967					2020	39	3					2947	2975		10.3233/JIFS-191470													
J								Reversible data hiding method based on pixel expansion and homomorphic encryption	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Reversible data hiding; pixel expansion; reversible data hiding in encrypted image; imperceptibility; homomorphic encryption	DIFFERENCE EXPANSION; SCHEME; PVO	Digital image steganography algorithms usually suffer from a lossy restoration of the cover content after extraction of a secret message. When a cover object and confidential information are both utilised, the reversible property of the cover is inevitable. With this objective, several reversible data hiding (RDH) algorithms are available in the literature. Conversely, because both are diametrically related parameters, existing RDH algorithms focus on either a good embedding capacity (EC) or better stego-image quality. In this paper, a pixel expansion reversible data hiding (PE-RDH) method with a high EC and good stego-image quality are proposed. The proposed PE-RDH method was based on three typical RDH schemes, namely difference expansion, histogram shifting, and pixel value ordering. The PE-RDH method has an average EC of 0.75 bpp, with an average peak signal-to-noise ratio (PSNR) of 30.89 dB. It offers 100% recovery of the original image and confidential hidden messages. To protect secret as well as cover the proposed PE-RDH is also implemented on the encrypted image by using homomorphic encryption. The strength of the proposed method on the encrypted image was verified based on a comparison with several existing methods, and the approach achieved better results than these methods in terms of its EC, location size and of																	1064-1246	1875-8967					2020	39	3					2977	2990		10.3233/JIFS-191478													
J								Cross-Modality Person Re-Identification via Modality-Aware Collaborative Ensemble Learning	IEEE TRANSACTIONS ON IMAGE PROCESSING										Cameras; Task analysis; Collaboration; Learning systems; Visualization; Face recognition; Collaborative work; Cross-modality; person re-identification; collaborative ensemble learning	RANKING	Visible thermal person re-identification (VT-ReID) is a challenging cross-modality pedestrian retrieval problem due to the large intra-class variations and modality discrepancy across different cameras. Existing VT-ReID methods mainly focus on learning cross-modality sharable feature representations by handling the modality-discrepancy in feature level. However, the modality difference in classifier level has received much less attention, resulting in limited discriminability. In this paper, we propose a novel modality-aware collaborative ensemble (MACE) learning method with middle-level sharable two-stream network (MSTN) for VT-ReID, which handles the modality-discrepancy in both feature level and classifier level. In feature level, MSTN achieves much better performance than existing methods by capturing sharable discriminative middle-level features in convolutional layers. In classifier level, we introduce both modality-specific and modality-sharable identity classifiers for two modalities to handle the modality discrepancy. To utilize the complementary information among different classifiers, we propose an ensemble learning scheme to incorporate the modality sharable classifier and the modality specific classifiers. In addition, we introduce a collaborative learning strategy, which regularizes modality-specific identity predictions and the ensemble outputs. Extensive experiments on two cross-modality datasets demonstrate that the proposed method outperforms current state-of-the-art by a large margin, achieving rank-1/mAP accuracy 51.64%/50.11% on the SYSU-MM01 dataset, and 72.37%/69.09% on the RegDB dataset.																	1057-7149	1941-0042					2020	29						9387	9399		10.1109/TIP.2020.2998275													
J								PrivacyNet: Semi-Adversarial Networks for Multi-Attribute Face Privacy	IEEE TRANSACTIONS ON IMAGE PROCESSING										Faces; Privacy; Face recognition; Biomedical imaging; Perturbation methods; Biological system modeling; Image recognition; Privacy; semi-adversarial; neural networks; autoencoder; face image; perturbation; soft biometrics; deep learning	RECOGNITION	Recent research has established the possibility of deducing soft-biometric attributes such as age, gender, and race from an individual's face image with high accuracy. However, this raises privacy concerns, especially when face images collected for biometric recognition purposes are used for attribute analysis without the person's consent. To address this problem, we develop a technique for imparting soft biometric privacy to face images via an image perturbation methodology. The image perturbation is undertaken using a GAN-based Semi-Adversarial Network (SAN) - referred to as PrivacyNet - that modifies an input face image such that it can be used by a face matcher for matching purposes but cannot be reliably used by an attribute classifier. Further, PrivacyNet allows a person to choose specific attributes that have to be obfuscated in the input face images (e.g., age and race), while allowing for other types of attributes to be extracted (e.g., gender). Extensive experiments using multiple face matchers, multiple age/gender/race classifiers, and multiple face datasets demonstrate the generalizability of the proposed multi-attribute privacy enhancing method across multiple face and attribute classifiers.																	1057-7149	1941-0042					2020	29						9400	9412		10.1109/TIP.2020.3024026													
J								Image Interpolation Using Multi-Scale Attention-Aware Inception Network	IEEE TRANSACTIONS ON IMAGE PROCESSING										Interpolation; Task analysis; Machine learning; Image edge detection; Training; Image resolution; Image interpolation; image super-resolution; deep learning; multi-scale; convolutional neural network; attention-aware; inception network; image pyramid; pyramid cut		A new multi-scale deep learning (MDL) framework is proposed and exploited for conducting image interpolation in this paper. The core of the framework is a seeding network that needs to be designed for the targeted task. For image interpolation, a novel attention-aware inception network (AIN) is developed as the seeding network; it has two key stages: 1) feature extraction based on the low-resolution input image; and 2) feature-to-image mapping to enlarge image's size or resolution. Note that the designed seeding network, AIN, needs to be trained with a matched training dataset at each scale. For that, multi-scale image patches are generated using our proposed pyramid cut, which outperforms the conventional image pyramid method by completely avoiding aliasing issue. After training, the trained AINs are then combined for processing the input image in the testing stage. Extensive experimental simulation results obtained from seven image datasets (comprising 359 images in total) have clearly shown that the proposed MAIN consistently delivers highly accurate interpolated images.																	1057-7149	1941-0042					2020	29						9413	9428		10.1109/TIP.2020.3026632													
J								Sparse BSS From Poisson Measurements	IEEE TRANSACTIONS ON IMAGE PROCESSING										Approximation algorithms; Extraterrestrial measurements; Additives; Noise measurement; Robustness; Mixture models; Blind source separation; Blind source separation (BSS); sparsity; Poisson measurements	COORDINATE DESCENT METHOD; BLIND SOURCE SEPARATION; DECOMPOSITION; FACTORIZATION; MINIMIZATION; ALGORITHMS	The problem of sparse Blind Source Separation (BSS) has been extensively studied when the noise is additive and Gaussian. This is however not the case when the measurements follow Poisson or shot noise statistics, which is customary with counting-based measurements. To that purpose, we introduce a novel sparse BSS algorithm coined pGMCA (poisson-Generalized Morphological Component Analysis) that specifically tackles the blind separation of sparse sources from measurements following Poisson statistics. The proposed algorithm builds upon Nesterov's smoothing technique to define a smooth approximation of sparse BSS, with a data fidelity term derived from the Poisson likelihood. This allows to design a block coordinate descent-based minimization procedure with a simple choice of the regularization parameter. Numerical experiments have been carried out that illustrate the robustness of the proposed method with respect to Poisson noise. The pGMCA algorithm has been further evaluated in a realistic astrophysical X-ray imaging setting.																	1057-7149	1941-0042					2020	29						9429	9444		10.1109/TIP.2020.3027986													
J								SAFNet: A Semi-Anchor-Free Network With Enhanced Feature Pyramid for Object Detection	IEEE TRANSACTIONS ON IMAGE PROCESSING										Feature extraction; Detectors; Object detection; Generators; Semantics; Task analysis; Training; Object detection; feature pyramid; semi-anchor-free; computer vision; deep learning		In recent years, the field of object detection has made significant progress. The success of most state-of-the-art object detectors is derived from the use of feature pyramid and the carefully designed anchor boxes. However, the existing methods for constructing feature pyramid blindly integrate multi-scale representations on each feature hierarchy. Furthermore, these detectors also suffer from some drawbacks brought by the hand-designed anchors. To mitigate the adverse effects caused thereby, we propose a semi-anchor-free network with enhanced feature pyramid for object detection, named SAFNet. Specifically, to better construct feature pyramid, we propose a novel enhanced feature pyramid generation paradigm, which consists of two modules, i.e., adaptive feature fusion module (AFFM) and self-enhanced module (SEM). The paradigm adaptively integrates multi-scale representations in a non-linear way meanwhile suppresses the redundant semantic information for each pyramid level. Thus, a clean and enhanced feature pyramid could be obtained. In addition, an adaptive anchor generator (AAG) is designed to yield fewer but more suitable anchor boxes for each input image. Benefiting from the enhanced feature pyramid, AAG is capable of generating more accurate anchor boxes by introducing few priors. With this semi-anchor-free method, our detector has the ability to alleviate the drawbacks of hand-designed anchors meanwhile retain the merits of anchor-based methods. Extensive experiments demonstrate the effectiveness of our approach. Profited from the proposed modules, SAFNet significantly boosts the detection performance, i.e., achieving 2 points and 2.1 points higher Average Precision (AP) than RetinaNet on PASCAL VOC and MS COCO respectively.																	1057-7149	1941-0042					2020	29						9445	9457		10.1109/TIP.2020.3028196													
J								Rate Distortion Optimization: A Joint Framework and Algorithms for Random Access Hierarchical Video Coding	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image coding; Encoding; Rate-distortion; Standards; Video coding; Quantization (signal); Distortion; Rate distortion optimization; video coding; HEVC	LAGRANGE MULTIPLIER; BIT ALLOCATION; QUANTIZATION; HEVC; H.264; IMAGE	This paper revisits the problem of rate distortion optimization (RDO) with focus on inter-picture dependence. A joint RDO framework which incorporates the Lagrange multiplier as one of parameters to be optimized is proposed. Simplification strategies are demonstrated for practical applications. To make the problem tractable, we consider an approach where prediction residuals of pictures in a video sequence are assumed to be emitted from a finite set of sources. Consequently the RDO problem is formulated as finding optimal coding parameters for a finite number of sources, regardless of the length of the video sequence. Specifically, in cases where a hierarchical prediction structure is used, prediction residuals of pictures at the same prediction layer are assumed to be emitted from a common source. Following this approach, we propose an iterative algorithm to alternatively optimize the selections of quantization parameters (QPs) and the corresponding Lagrange multipliers. Based on the results of the iterative algorithm, we further propose two practical algorithms to compute QPs and the Lagrange multipliers for the RA(random access) hierarchical video coding: the first practical algorithm uses a fixed formula to compute QPs and the Lagrange multipliers, and the second practical algorithm adaptively adjusts both QPs and the Lagrange multipliers. Experimental results show that these three algorithms, integrated into the HM 16.20 reference software of HEVC, can achieve considerable RD improvements over the standard HM 16.20 encoder, in the common RA test configuration.																	1057-7149	1941-0042					2020	29						9458	9469		10.1109/TIP.2020.3028280													
J								Sketch-a-Segmenter: Sketch-Based Photo Segmenter Generation	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image segmentation; Training; Feature extraction; Semantics; Task analysis; Data models; Training data; Sketch-based photo segmentation; category-level segmentation; fine-grained segmentation; dataset	OBJECT CLASSES; DETECT	Given pixel-level annotated data, traditional photo segmentation techniques have achieved promising results. However, these photo segmentation models can only identify objects in categories for which data annotation and training have been carried out. This limitation has inspired recent work on few-shot and zero-shot learning for image segmentation. In this article, we show the value of sketch for photo segmentation, in particular as a transferable representation to describe a concept to be segmented. We show, for the first time, that it is possible to generate a photo-segmentation model of a novel category using just a single sketch and furthermore exploit the unique fine-grained characteristics of sketch to produce more detailed segmentation. More specifically, we propose a sketch-based photo segmentation method that takes sketch as input and synthesizes the weights required for a neural network to segment the corresponding region of a given photo. Our framework can be applied at both the category-level and the instance-level, and fine-grained input sketches provide more accurate segmentation in the latter. This framework generalizes across categories via sketch and thus provides an alternative to zero-shot learning when segmenting a photo from a category without annotated training data. To investigate the instance-level relationship across sketch and photo, we create the SketchySeg dataset which contains segmentation annotations for photos corresponding to paired sketches in the Sketchy Dataset.																	1057-7149	1941-0042					2020	29						9470	9481		10.1109/TIP.2020.3028292													
S								Introduction to Fuzzy Collaborative Forecasting Systems	FUZZY COLLABORATIVE FORECASTING AND CLUSTERING: METHODOLOGY, SYSTEM ARCHITECTURE, AND APPLICATIONS	Springerbriefs in Applied Sciences and Technology										INTELLIGENCE APPROACH; NEURAL SYSTEM; PRICE																		2191-530X	2191-5318	978-3-030-22574-2; 978-3-030-22573-5				2020							1	8		10.1007/978-3-030-22574-2_1	10.1007/978-3-030-22574-2												
J								Modelling sensor ontology with the SOSA/SSN frameworks: a case study for laboratory parameters	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Semantic sensor network; ontology modeling; stream data; real-time monitoring; heterogeneous sensor data		Recently, the use of sensor-based systems in many areas has led to an exponential increase in the raw sensor data. However, the lack of neither syntactic nor semantic integrity between these sensor data limited their sharing, reusability, and interpretation. These inabilities can cause some problems. For example, different wireless sensor networks may not work together due to the subtle variations in their sensing methods, operating systems, syntax, and data structure. In recent years, to cope with these inabilities, the semantic sensor web approach, which enables us to enrich the meaning of sensor data, has been seen as the critical technology in solving these problems by some researchers. The primary purpose of this study is to create a laboratory environment parameters sensor ontology (LEPSO) that provides a standard data model for heterogeneous sensor data from different platforms by expanding semantic sensor networks (SSN). A case study was conducted using the real-time data collected from Bolu Abant izzet Baysal University, Scientific Industrial Technological Application and Research Center in order to demonstrate that the proposed LEPSO can be used in similar sensor-based applications. A series of semantic queries have been performed on the collected sensor data to evaluate the proposed sensor ontology. The results showed that sensor data, which are heterogeneous by nature, provide benefit results in sensor-based monitoring systems when enriched with semantic web technologies and ontologies. Besides, this study proves that the proposed semantic sensor ontology, which used the semantic sensor network framework, has the capability to provide a common infrastructure for many sensor-based applications. The proposed ontology has the potential to become a more comprehensive ontology by adding different platforms, different sensors, different environments such as school, factory. In the next study, it is aimed to expand the scope of this semantic sensor network, which is formed by including this ontology in the intensive care unit of a hospital.																	1300-0632	1303-6203					2020	28	5					2566	2585		10.3906/elk-1912-160													
J								Construction and performance analysis of a new SAC-OCDMA code based on Latin square matrix	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Spectral amplitude coding (SAC); optical code division multiple access (OCDMA); Latin square code (LSC); zero cross-correlation	CROSS-CORRELATION CODES; SYSTEMS; DESIGN	In this paper a family of novel spreading code called Latin square code (LSC) is proposed for spectral amplitude coding-optical code division multiple access (SAC-OCDMA) system. The main feature of the proposed code is the zero cross-correlation which eliminates both multiple access interference (MAI) and phase induced intensity noise (PIIN). The code construction can be easily accomplished using Latin square matrix (LSM) for any weight and number of users. The simplicity in the construction code has made it a compelling candidate for future OCDMA applications. SAC-OCDMA system employing direct decoding is mathematically analyzed and then numerically simulated using Matlab and OptiSystem respectively. The results show the improvement given by the LSC code to the SAC-OCDMA system compared to the other codes such as: ZCC (zero cross-correlation) and MMS (modified multiservice) by allowing high cardinality and improving BER. Furthermore, the transmission quality, so that the BER does not exceed the value of 10(-9), is ensured by the LSC code with a lower effective source power of -14.5 dBm, a bit rate of 4.6 Gb/s and a cardinality exceeding ZCC and MMS by 1.7 and 1.22 times respectively. The simulation results validate the mathematical analysis and show that the system makes it possible to increase the transmission distance without affecting QoS (quality of service).																	1300-0632	1303-6203					2020	28	5					2630	2642		10.3906/elk-1910-111													
J								Low-profile folded dipole UHF RFID tag antenna with outer strip lines for metal mounting application	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Folded dipole; metal mountable tag antenna; high gain; impedance matching	PATCH ANTENNA; DESIGN; STUBS	A metal mountable UHF RFID tag antenna with a low-profile folded dipole structure is proposed. It is fabricated on a single layer of polytetrafluoroethylene (PTFE) dielectric laminate. It is composed of two symmetrical C-shape resonators integrated with the outer strip lines. The IC chip's terminals are connected directly to the center of the C-shaped resonators. The outer strip lines are integrated with the C-shaped resonators, which function to lower the reflection coefficient so as to match the IC chip impedance. In particular, the outer strip lines increase the inductive reactance of the antenna impedance in order to realize IC chip impedance. The design has a simple structure, due to the fact that it lacks any metallic vias. Moreover, the gain of the tag antenna can be enhanced when positioned on a large metallic sheet. Installed on a 40 x 40 cm(2) metallic plate, the total gain of the proposed tag antenna is 3 dB, with a maximum reading range of 5.77 m, while it is 3.92 m in free space. The simulation results were in excellent agreement with the fabricated design results.																	1300-0632	1303-6203					2020	28	5					2643	2656		10.3906/elk-1912-45													
J								An efficient storage-optimizing tick data clustering model	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Tick data; compression; clustering		Tick data is a large volume of data, related to a phenomenon such as stock market or weather change, with data values changing rapidly over time. An important issue is to store tick data table in a way that it occupies minimum storage space while at the same time it can provide fast execution of queries. In this paper, a mathematical model is proposed to partition tick data tables into clusters with the aim of minimizing the required storage space. The genetic algorithm is then used to solve the mathematical model which is indeed a clustering model. The proposed method has been evaluated on a real-world weather tick dataset and compared to the storage-optimizing hierarchical agglomerative clustering (SOHAC) algorithm. The experiments show that our proposed method substantially outperforms SOHAC in achieving smaller values for compression ratio while reducing the execution time for small number of clusters.																	1300-0632	1303-6203					2020	28	5					2657	2669		10.3906/elk-1901-82													
J								A subsynchronous resonance prevention for DFIG-based wind farms	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										SSR; DFIG-based wind farm; SSR prevention controller; line series capacitor voltage	FED INDUCTION GENERATOR; SYNCHRONOUS CONTROL INTERACTION; POWER-CONTROL; MITIGATION	In this paper, subsynchronous resonance (SSR) instability was accurately analyzed in doubly fed induction generator (DFIG)-based wind farms by the linearization of equations and modal analysis. In addition, the possibility of high compensation for the transmission lines connected to DFIG-based wind farms was provided using a SSR prevention controller (SSRPC). For this purpose, an SSRPC was connected to the output voltage of the grid side converter (GSC) of the DFIG. The GSC output voltage was selected as the connection point of the SSRPC because it directly affects the induction generator effect (IGE) and can be an inhibitor factor in its occurrence. Furthermore, using system dynamic equations and the participation factor, it was shown that the effective factor on subsynchronous mode was the capacitor series voltage of the line, considered an input signal to the SSRPC. To validate the performance of the proposed method, a simulation was performed based on the IEEE SSR first benchmark model using the software MATLAB/Simulink.																	1300-0632	1303-6203					2020	28	5					2670	2685		10.3906/elk-1912-177													
J								Image subset communication for resource-constrained applications in wireless sensor networks	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Wireless sensor networks; data transmission; security; progressive image transmission; resource-constrained applications; JPEG; region of interest; image coefficients	TRANSMISSION; SCHEMES; JPEG	JPEG is the most widely used image compression standard for sensing, medical, and security applications. JPEG provides a high degree of compression but field devices relying on battery power must further economize on data transmissions to prolong deployment duration with particular use cases in wireless sensor networks. Transmitting a subset of image data could potentially enhance the battery life of power-constrained devices and also meet the application requirements to identify the objects within an image. Depending on an application's needs, after the first selected subset is received at the base station, further transmissions of the image data for successive refinements can also be requested. Needs for such progressive refinements exist in applications including tele-medicine, security, and surveillance, where an initial assessment could govern further exploration of only a small region. We propose a scheme for selecting minimum information for a coarser reconstruction by transmitting only the DC coefficients as the first or base layer. This initial layer of information could on request be augmented by transmitting either more data representing an entire image or a selected region of interest. We compare our results with those of other power economization and progressive communications techniques. The proposed scheme offers significant advantages for a range of application scenarios under resource constraints.																	1300-0632	1303-6203					2020	28	5					2686	2701		10.3906/elk-2002-169													
J								Formation of a wireless sensor network using custom-designed sensors having low power and low cost components	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Node design; medium access control; wireless sensor networks; field estimation		In this paper, we first design a sensor with low power and low cost components, namely an MSP430G2553 microcontroller (MCU), nRF24L01+ communication unit, and a light-dependent resistor (LDR). Then, connecting these custom-designed sensors with a central node, a fusion center (FC), we form a wireless sensor network (WSN) in which sensors measure light intensities and send their measurements to the FC for final inference. Since the default addressing structure of nRF24L01+ can simultaneously connect up to 6 devices, in order to have more connections, we define a new addressing scheme for the transmissions between sensors and the FC. Finally, as a test case, we consider the task of the WSN in field estimation. The FC learns the spatial dependence between sensor measurements called a variogram. Then, using the appropriate variogram model, we perform ordinary kriging (OK), where the light intensity at an unobserved location is estimated as a weighted sum of received LDR measurements. Our test results show that the estimated light measurement using OK at a specific location becomes quite close to the actual LDR measurement at that location under the suitable parametric variogram models.																	1300-0632	1303-6203					2020	28	5					2702	2717		10.3906/elk-2001-107													
J								A fuzzy neural network for web service selection aimed at dynamic software rejuvenation	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Software aging; software rejuvenation; fuzzy neural network; web service	POLICY; TRUST	Software rejuvenation is an effective technique to counteract software aging in continuously running applications such as web service-based systems. In these systems, web services are allocated based on the requirements of receivers and the facilities of servers. One of the challenges while assigning web services is how to select appropriate server to reduce faults. In this paper, we propose dynamic software rejuvenation as a proactive fault-tolerance technique based on the neural fuzzy system. While considering a threshold for the rejuvenation of each web service, we completed the training based on the features of the service providers as well as the requirements of the receivers. The results of simulations revealed that our strategy can decrease the failure rate in comparison with state-of-the-art strategies and improve system availability in web services.																	1300-0632	1303-6203					2020	28	5					2718	2734		10.3906/elk-2001-33													
J								Revised polyhedral conic functions algorithm for supervised classification	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Classification; conic functions; machine learning; optimization	REGULARIZATION; OPTIMIZATION; SEPARATION; NETWORKS	In supervised classification, obtaining nonlinear separating functions from an algorithm is crucial for prediction accuracy. This paper analyzes the polyhedral conic functions (PCF) algorithm that generates nonlinear separating functions by only solving simple subproblems. Then, a revised version of the algorithm is developed that achieves better generalization and fast training while maintaining the simplicity and high prediction accuracy of the original PCF algorithm. This is accomplished by making the following modifications to the subproblem: extension of the objective function with a regularization term, relaxation of a hard constraint set and introduction of a new error term. Experimental results show that the modifications provide %12 better generalization on average and up to 10x faster training. This paper also contributes to the literature by providing detailed comparisons of the other classification algorithms that use polyhedral conic functions for the first time.																	1300-0632	1303-6203					2020	28	5					2735	2749		10.3906/elk-2001-62													
J								Mutant selection by using Fourier expansion	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Mutation analysis; finite state machine; Fourier transformation; W method	MUTATION; COST; DESIGN	Mutation analysis is a widely used technique to evaluate the effectiveness of test cases in both hardware and software testing. The original model is mutated systematically under certain fault assumptions and test cases are checked against the mutants created to see whether the test cases can detect the faults or not. Mutation analysis is usually a computationally intensive task, particularly in finite state machine (FSM) testing due to a possibly huge amount of mutants. Random selection could be a practical reduction method under the assumption that each mutant is identical in terms of the probability of occurrence of its associating fault. The present study proposes a mutant selection method based on Fourier analysis of Boolean functions. Fourier helps to identify the most effective transitions on the output so that the mutants related to those transitions can be selected. Such mutants are considered more important since they are more likely to be killed. To evaluate the method, test cases are generated by the well-known W method, which has the capability of detecting every potential fault. The original and reduced sets of mutants are compared with respect to their importance values. Evaluations show that the mutants selected by the proposed technique are more effective, which reduces the cost of mutation analysis without sacrificing the performance of the mutation analysis.																	1300-0632	1303-6203					2020	28	5					2750	2767		10.3906/elk-1909-90													
J								Combined morphology and SVM-based fault feature extraction technique for detection and classification of transmission line faults	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Transmission line protection; fault detection and classification; fault feature extraction; support vector machine; mathematical morphology	WAVELET TRANSFORM; DIAGNOSIS; MACHINE; SCHEME	A transmission line is the main commodity of power transmission network through which power is transmitted to the utility. These lines are often swayed by accidental breakdowns owing to different random origins. Hence, researchers try to detect and track down these failures at the earliest to avoid financial prejudice. This paper offers a new real-time mathematical morphology based approach for fault feature extraction. The morphological open-close-median filter is exploited to wrest unique fault features which are then fed as an input to support vector machine to detect and classify the short circuit faults. The acquired graphical and numerical results of the extracted fault features affirm the potency of the offered scheme. The proposed scheme has been verified for different fault cases simulated on high-voltage transmission line modelled using ATP/EMTP with varying system constraints. The performance of the stated technique is also validated for fault detection and classification in real-field transmission lines. The results state that the proposed method is capable of detecting and classifying the faults with adequate precision and reduced computational complexity, in less than quarter of a cycle.																	1300-0632	1303-6203					2020	28	5					2768	2788		10.3906/elk-1912-7													
J								Highly sensitive fiber optic pressure sensors for wind turbine applications	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Fiber optic sensor; pressure sensor; wind turbines; fiber loop ringdown spectroscopy; spectroscopic technique	MONITORING-SYSTEM; LOOP RINGDOWN; INDEX SENSORS; DEFLECTION; STRAIN	Fiber optic pressure sensors utilizing ultra-high sensitive fiber loop ringdown (FLRD) spectroscopy were fabricated using a bare single mode fiber. The fiber optic pressure sensors were applied to monitor pressure change on a plastic pipe embedded into a sea sand filled container in laboratory conditions to simulate a tower. As the pressure applied to the sensor head was changed from 66.4 kPa to 331.6 kPa, changes in the ringdown time (RDT) were recorded. The lowest baseline stability of 0.20% was obtained in these simple FLRD pressure sensors. The minimum detectable optical loss was 992 mu dB. The results showed that FLRD pressure sensors tested by applying to a pipe embedded into sea sand simulating a tower are highly sensitive and have high potential to be applicable for monitoring wind turbine components such as blades and towers in the sea or on land to determine the pressure on structures due to damage, excessive waves, or strong winds. The study also suggests that this type of FLRD pressure sensor can be utilized for the purpose of early detection in other important structures such as dams, buildings, and bridges.																	1300-0632	1303-6203					2020	28	5					2789	2796		10.3906/elk-2003-69													
J								Improving the efficiency of DNN hardware accelerator by replacing digital feature extractor with an imprecise neuromorphic hardware	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Artificial neural networks; memristor; in-memory computation; convolutional neural networks; imprecise computation; fault tolerance		Mixed-signal in-memory computation can drastically improve the efficiency of the hardware implementing machine learning (ML) algorithms by (i) removing the need to fetch neural network parameters from internal or external memory and (ii) performing a large number of multiply-accumulate operations in parallel. However, this boost in efficiency comes with some disadvantages. Among them, the inability to precisely program nonvolatile memory devices (NVM) with neural network parameters and sensitivity to noise prevent the mixed-signal hardware to perform a precise and deterministic computation. Unfortunately, these hardware-specific errors can get magnified while propagating along with the layers of the deep neural network. In this paper, we show that the inability to implement parameters of the already trained network with enough precision can completely stop the network from performing any meaningful operation. However, even at this level of degradation, the feature extractor section of the network still extracts enough information from which an acceptable level of performance can be achieved by just retraining the last classification layers of the network. Our results suggest that instead of just blindly trying to implement software algorithms in hardware as precisely as possible, it might be more efficient to implement neural networks with imperfect devices and circuits and let the network itself compensate for these imprecise computations by only retraining few layers.																	1300-0632	1303-6203					2020	28	5					2797	2807		10.3906/elk-1911-77													
J								A mechanism of QoS differentiation based on offset time and adjusted burst length in OBS networks	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Optical burst switching; quality of service; feedback; adaptive control; performance evaluation	PERFORMANCE; ALGORITHM; WAVELENGTH; ALLOCATION; CHANNEL; PACKET	Quality of service (QoS) differentiation is an integral component of any networking system, particularly, with the current and future great diversity of users' applications and their manifold requirements. In optical burst switching (OBS) networks, there are two approaches for QoS differentiation: one is based on offset time and the other is based on burst length. This paper presents a mechanism of QoS differentiation based on both offset time and burst length, in which the offset times are calculated to achieve a complete isolation of data loss between priority classes and the burst length is adaptively adjusted according to the feedbacked void size. The simulation results show that the mechanism of QoS differentiation based on offset time and adjusted burst length not only increases the successful scheduling rate but also reduces the burst delay.																	1300-0632	1303-6203					2020	28	5					2808	2820		10.3906/elk-1906-87													
J								Diagnosis of speed sensor faults in an induction machine based on a robust adaptive super-twisting observer	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Sensorless control; fuzzy supervisor; fault detection and isolation; Liyaponov theory; induction machine	DC-LINK VOLTAGE; MOTOR; ORDER	The present paper aims to determine a robust sensor fault-tolerant controller based on fuzzy logic using a robust adaptive super-twisting observer for the control of an induction machine and an inverter set by a state estimation method. The speed sensor is considered in the present case. The modular structure of the fault-tolerant control (FTC) scheme allows integrating this sensor within the existing closed-loop system, and the observer can therefore be designed independently. This article presents a new method to develop a fuzzy decision system that provides fault-tolerant control. This paper also aims at detecting the mechanical speed sensor faults. The proposed approach allows the automatic reconfiguration of the system in the event of a speed sensor failure. The defective fuzzy detection system makes a transition between the speed sensor and the robust observer based on a super-twisting algorithm that ensures the continuity and stability of the system; the fuzzy detection and transition system is required to be robust to parametric variations, and must be fast enough in order to locate the defect and eventually make a transition in the event of a fault. The output of the fuzzy block is injected into the control block to ensure super-twisting speed regulation. The performance of the proposed strategy also the robustness against parameter variation are assessed by simulation thanks to Matlab/Simulink software.																	1300-0632	1303-6203					2020	28	5					2821	2837		10.3906/elk-1912-126													
J								Impulse noise removal by k-means clustering identified fuzzy filter: a new approach	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Impulse noise; random valued impulse noise; k-means clustering; fuzzy filter	SWITCHING MEDIAN FILTER; PEPPER NOISE; LINEAR PREDICTION; DECOMPOSITION; ALGORITHM; IMAGES	Removal of impulse noise from corrupted digital images has been a hitch in the field of image processing. Random nature of impulse noise makes the task of noise removal more critical. Different filters have been designed for noise removal purpose and have shown formidable results mostly for low and medium level noise densities. In this paper, a new two-stage technique called k-means clustering identified fuzzy filter (KMCIFF) is proposed for de-noising gray-scale images. KMCIFF consists of a k-Means clustering-based high density impulse noise detection, followed by a fuzzy logic-oriented noise removal mechanism. In the detection process, a 5 x 5 window centering upon each pixel of the image is considered. K-Means clustering is applied on each 5 x 5 window to group the pixels into different clusters to detect whether the central pixel of each window is noisy or not. In the noise removal process, a 7 x 7 window centering upon each noisy pixel of the image, as detected by the clustering is considered. Fuzzy logic is used to find the nonnoisy pixel in each 7 x 7 window having the highest influence on the central noisy pixel of the window. Finally, that pixel is replaced by the approximated pixel intensity value calculated from the highest influencing non-noisy pixel. KMCIFF is evaluated upon seven different standard test images using peak signal to noise ratio (PSNR), structural similarity index measurement (SSIM), Percentage of actual nonnoisy pixels detected as erroneous out of the total number of pixels (PDAE) and average run time (ART). It has been observed that KMCIFF shows significantly more competitive visual and quantitative performances vis-a-vis most of the extant traditional filters at high noise densities of up to 90%.																	1300-0632	1303-6203					2020	28	5					2838	2862		10.3906/elk-1910-34													
S								The Changing Accounting Landscape	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							15	33		10.1007/978-3-030-29761-9_2	10.1007/978-3-030-29761-9												
S								Cryptocurrencies & The Financial Services Landscape	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							35	46		10.1007/978-3-030-29761-9_3	10.1007/978-3-030-29761-9												
S								Consensus Methodologies	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							47	66		10.1007/978-3-030-29761-9_4	10.1007/978-3-030-29761-9												
S								Stablecoins & The Decentralized Organization	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							67	81		10.1007/978-3-030-29761-9_5	10.1007/978-3-030-29761-9												
S								Artificial Intelligence	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							83	99		10.1007/978-3-030-29761-9_6	10.1007/978-3-030-29761-9												
S								Robotic Process Automation	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							101	107		10.1007/978-3-030-29761-9_7	10.1007/978-3-030-29761-9												
S								The View From the Top	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							111	117		10.1007/978-3-030-29761-9_8	10.1007/978-3-030-29761-9												
S								A New Niche for Practitioners	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							119	130		10.1007/978-3-030-29761-9_9	10.1007/978-3-030-29761-9												
S								Leveraging Technology to Reduce Ambiguity	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance										SUSTAINABILITY																		2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							131	142		10.1007/978-3-030-29761-9_10	10.1007/978-3-030-29761-9												
S								Internal Control Considerations	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							143	150		10.1007/978-3-030-29761-9_11	10.1007/978-3-030-29761-9												
S								Implications & Trends for Financial Services	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							151	164		10.1007/978-3-030-29761-9_12	10.1007/978-3-030-29761-9												
S								Audit Implications of AI & Blockchain	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							165	173		10.1007/978-3-030-29761-9_13	10.1007/978-3-030-29761-9												
S								ESG & Other Emerging Technology Applications	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							175	191		10.1007/978-3-030-29761-9_14	10.1007/978-3-030-29761-9												
S								Cybersecurity & Insurance	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							193	200		10.1007/978-3-030-29761-9_15	10.1007/978-3-030-29761-9												
S								Next Stage Applications	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							201	211		10.1007/978-3-030-29761-9_16	10.1007/978-3-030-29761-9												
S								Data As An Asset	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance										ANALYTICS																		2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							213	239		10.1007/978-3-030-29761-9_17	10.1007/978-3-030-29761-9												
S								Elevation to Strategic Advisor	BLOCKCHAIN, ARTIFICIAL INTELLIGENCE AND FINANCIAL SERVICES: IMPLICATIONS AND APPLICATIONS FOR FINANCE AND ACCOUNTING PROFESSIONALS	Future of Business and Finance																												2662-2467	2662-2475	978-3-030-29761-9; 978-3-030-29760-2				2020							241	254		10.1007/978-3-030-29761-9_18	10.1007/978-3-030-29761-9												
J								Parallelizable Global Conformal Parameterization of Simply-Connected Surfaces via Partial Welding	SIAM JOURNAL ON IMAGING SCIENCES										conformal parameterization; conformal welding; parallelization; simply-connected surface	TEICHMULLER MAP; ALGORITHM; REGISTRATION; CONVERGENCE; MAPPINGS	Conformal surface parameterization is useful in graphics, imaging, and visualization, with applications to texture mapping, atlas construction, registration, remeshing, and so on. With the increasing capability in scanning and storing data, dense 3D surface meshes are common nowadays. While meshes with higher resolution better resemble smooth surfaces, they pose computational difficulties for the existing parameterization algorithms. In this work, we propose a novel parallelizable algorithm for computing the global conformal parameterization of simply-connected surfaces via partial welding maps. A given simply-connected surface is first partitioned into smaller subdomains. The local conformal parameterizations of all subdomains are then computed in parallel. The boundaries of the parameterized subdomains are subsequently integrated consistently using a novel technique called partial welding, which is developed based on conformal welding theory. Finally, by solving the Laplace equation for each subdomain using the updated boundary conditions, we obtain a global conformal parameterization of the given surface, with bijectivity guaranteed by quasi-conformal theory. By including additional shape constraints, our method can be easily extended to achieve disk conformal parameterization for simply-connected open surfaces and spherical conformal parameterization for genus-0 closed surfaces. Experimental results are presented to demonstrate the effectiveness of our proposed algorithm. When compared to the state-of-the-art conformal parameterization methods, our method achieves a significant improvement in both computational time and accuracy.																	1936-4954						2020	13	3					1049	1083		10.1137/19M125337X													
J								Nonnegative Tensor Patch Dictionary Approaches for Image Compression and Deblurring Applications	SIAM JOURNAL ON IMAGING SCIENCES										tensor; patch dictionary; image compression; image deblurring; MRNSD; sparsity constraint	LEAST-SQUARES; FACTORIZATION	In recent work [S. Soltani, M. Kilmer, and P. C. Hansen, BIT, 56 (2016)], an algorithm for non-negative tensor patch dictionary learning in the context of X-ray CT imaging and based on a tensor-tensor product called the t-product [M. E. Kilmer and C. D. Martin, Linear Algebra Appl., 435 (2011), pp. 641-658] was presented. Building on that work, in this paper, we use nonnegative tensor patch-based dictionaries trained on other data, such as facial image data, for the purpose of either compression or image deblurring. We begin with an analysis in which we address issues such as suitability of the tensor-based approach relative to a matrix-based approach, dictionary size, and patch size to balance computational efficiency and qualitative representations. Next, we develop an algorithm that is capable of recovering nonnegative tensor coefficients given a nonnegative tensor dictionary. The algorithm is based on a variant of the modified residual norm steepest descent method. We show how to augment the algorithm to enforce sparsity in the tensor coefficients and note that the approach has broader applicability since it can be applied to the matrix case as well. We illustrate the surprising result that dictionaries trained on image data from one class can be successfully used to represent and compress image data from different classes and across different resolutions. Finally, we address the use of nonnegative tensor dictionaries in image deblurring. We show that tensor treatment of the deblurring problem coupled with nonnegative tensor patch dictionaries can give superior restorations as compared to standard treatment of the nonnegativity constrained deblurring problem.																	1936-4954						2020	13	3					1084	1112		10.1137/19M1297026													
J								Self-Assignment Flows for Unsupervised Data Labeling on Graphs	SIAM JOURNAL ON IMAGING SCIENCES										unsupervised learning; dynamical systems; graph partitioning; image labeling; spatially regularized clustering; assignment manifold; information geometry; replicator equation; evolutionary game dynamics	NYSTROM METHOD	This paper extends the recently introduced assignment flow approach for supervised image labeling to unsupervised scenarios where no labels are given. The resulting self-assignment flow takes a pairwise data affinity matrix as input data and maximizes the correlation with a low-rank matrix that is parametrized by the variables of the assignment flow, which entails an assignment of the data to themselves through the formation of latent labels (feature prototypes). A single user parameter, the neighborhood size for the geometric regularization of assignments, drives the entire process. By smooth geodesic interpolation between different normalizations of self-assignment matrices on the positive definite matrix manifold, a one-parameter family of self-assignment flows is defined. Accordingly, our approach can be characterized from different viewpoints, e.g., as performing spatially regularized, rank-constrained discrete optimal transport, or as computing spatially regularized normalized spectral cuts. Regarding combinatorial optimization, our approach successfully determines completely positive factorizations of self-assignments in large-scale scenarios, subject to spatial regularization. Various experiments, including the unsupervised learning of patch dictionaries using a locally invariant distance function, illustrate the properties of the approach.																	1936-4954						2020	13	3					1113	1156		10.1137/19M1298639													
J								Hypergraph Clustering Using a New Laplacian Tensor with Applications in Image Processing	SIAM JOURNAL ON IMAGING SCIENCES										hypergraph clustering; Laplacian tensor; image processing; hypergraph partitioning; optimization; Stiefel manifold; tensor eigenvalue	EIGENVALUES; OPTIMIZATION; FRAMEWORK	In this paper, we consider the multiclass clustering problem involving a hypergraph model. Fundamentally, we study a new normalized Laplacian tensor of an even-uniform weighted hypergraph. The hypergraph's connectivity is related with the second smallest Z-eigenvalue of the proposed Laplacian tensor. Particularly, an analogue of fractional Cheeger inequality holds. Next, we generalize the Laplacian tensor based approach from biclustering to multiclass clustering. A tensor optimization model with an orthogonal constraint is established and analyzed. Finally, we apply our hypergraph clustering approach to image segmentation and motion segmentation problems. Experimental results demonstrate that our method is effective.																	1936-4954						2020	13	3					1157	1178		10.1137/19M1291601													
J								Cartoon-Texture Image Decomposition using Orientation Characteristics in Patch Recurrence	SIAM JOURNAL ON IMAGING SCIENCES										cartoon-texture decomposition; patch recurrence; regularization method	TOTAL VARIATION MINIMIZATION; SEPARATION; ALGORITHM; COMPONENT; MODEL; LAYER; BV	Cartoon-texture image decomposition is about decomposing an image into the linear sum of two layers: cartoon and texture, where the key challenge is how to resolve the ambiguity between two layers. It is observed that the recurrence of texture patches occurs along multiple orientations, and the recurrence of cartoon patches only occurs along certain orientations. This paper proposes to separate these two layers by exploiting their orientation characteristics of image patch recurrence, i.e., isotropy property of texture patch recurrence versus anisotropy property of cartoon patch recurrence. Together with the sparsity-based regularizations in the image domain, a variational method is then developed in this paper for cartoon-texture decomposition. The experiments show that the proposed method noticeably outperforms many well-established ones on test images.																	1936-4954						2020	13	3					1179	1210		10.1137/19M128898X													
J								Accelerating Sparse Recovery by Reducing Chatter	SIAM JOURNAL ON IMAGING SCIENCES										sparsity promotion; inconsistent linear systems; Kacmarz; linearized Bregman; dynamical systems; chatter; nonsmooth dynamics	SIGNAL RECONSTRUCTION; SUBGRADIENT METHODS; ALGORITHMS	Compressive sensing has driven a resurgence of sparse recovery algorithms with l(1)-norm minimization. While these minimizations are relatively well understood for small underdetermined, possibly inconsistent systems, their behavior for large overdetermined and inconsistent systems has received much less attention. Specifically, we focus on large systems where computational restrictions call for algorithms that use randomized subsets of rows that are touched a limited number of times. In that regime, l(1)-norm minimization algorithms exhibit unwanted fluctuations near the desired solution, and the linear Bregman iterations are no exception. These fluctuations result in uncertainty about the recovery results, forcing increased effort such as longer run times or other additional search efforts. We explain this observed lack of performance in terms of chatter, a well-known phenomenon observed in nonsmooth dynamical systems, where intermediate solutions wander between different states, stifling convergence. By identifying chatter as the culprit, we then reduce it by modifying the Bregman iterations with adaptive elementwise step lengths combined with potential support detection via threshold crossing. We demonstrate the performance of our algorithm on carefully selected stylized examples that mimic real large scale problems and on a realistic seismic imaging problem involving millions of unknowns and matrix-free matrix-vector products that involve expensive wave-equation solves.																	1936-4954						2020	13	3					1211	1239		10.1137/19M129111X													
J								A Diffeomorphic Image Registration Model with Fractional-Order Regularization and Cauchy-Riemann Constraint	SIAM JOURNAL ON IMAGING SCIENCES										diffeomorphic image registration; fractional-order regularization; mesh folding; Cauchy-Riemann equation	CONFORMAL PARAMETERIZATION; SURFACE REGISTRATION; LARGE-DEFORMATION; DIFFUSION; FLOWS; OPTIMIZATION; SCHEME	In order to echo with fractional-order smoothness of image texture and eliminate mesh folding in image registration, we propose a diffeomorphic image registration model with fractional-order regularization and Cauchy-Riemann constraint. For the convenience of numerical implementation, a relaxed model is discussed. The existence of solution for the relaxed model is proved. A convex optimization numerical algorithm is presented, and the convergence of minimizing sequence is proved. Moreover, numerical tests are performed to show the efficiency of the proposed algorithm.																	1936-4954						2020	13	3					1240	1271		10.1137/19M1260621													
J								Data Driven Tight Frame for Compressed Sensing MRI Reconstruction via Off-the-Grid Regularization	SIAM JOURNAL ON IMAGING SCIENCES										magnetic resonance imaging; finite-rate-of-innovation; structured low rank matrix completion; (tight) wavelet frames; data driven tight frames; proximal alternating schemes	PIECEWISE-CONSTANT IMAGES; FINITE RATE; RECOVERY; MINIMIZATION; ALGORITHMS; NONCONVEX; SIGNALS; SVD	Recently, the finite-rate-of-innovation (FRI) based continuous domain regularization is emerging as an alternative to the conventional on-the-grid sparse regularization for compressed sensing (CS) due to its ability to alleviate the basis mismatch between the true support of the shape in the continuous domain and the discrete grid. In this paper, we propose a new off-the-grid regularization for the CS-MRI reconstruction. Following the recent works on two dimensional FRI, we assume that the discontinuities/edges of the image are localized in the zero level set of a band-limited periodic function. This assumption induces the linear dependencies among the Fourier samples of the gradient of the image, which leads to a low rank twofold Hankel matrix. We further observe that the singular value decomposition of a low rank Hankel matrix corresponds to an adaptive tight frame system which can represent the image with sparse canonical coefficients. Based on this observation, we propose a data driven tight frame based off-the-grid regularization model for the CS-MRI reconstruction. To solve the nonconvex and nonsmooth model, a proximal alternating minimization algorithm with a guaranteed global convergence is adopted. Finally, the numerical experiments show that our proposed data driven tight frame based approach outperforms the existing approaches.																	1936-4954						2020	13	3					1272	1301		10.1137/19M1298524													
J								Differential Tomography of Micromechanical Evolution in Elastic Materials of Unknown Micro/Macrostructure	SIAM JOURNAL ON IMAGING SCIENCES										differential imaging; micromechanical evolution; complex materials; ultrasonic sensing; waveform tomography	HETEROGENEOUS FRACTURES; CRACKS	Differential evolution indicators are introduced for 3D spatiotemporal imaging of micromechanical processes in elastic solids where progressive variations due to manufacturing and/or aging are housed in a highly scattering background of a priori unknown or uncertain structure. In this vein, a threetier imaging platform is established where (1) the domain is periodically (or continuously) subject to illumination and sensing in an arbitrary configuration; (2) sequential sets of measured data are deployed to distill far-field signatures of the domain's internal structure through carefully constructed, noniterative solutions to the scattering equation; and (3) the resulting solution sequence is then used to rigorously construct an imaging functional carrying appropriate invariance with respect to the unknown stationary components of the background, e.g., pre-existing interstitial boundaries. This gives birth to differential indicators that specifically recover the 3D support of evolution within a network of unknown scatterers. The direct scattering problem is formulated in the frequency domain where the background consists of a random distribution of monolithic fragments. The constituents are connected through highly heterogeneous interfaces of unknown elasticity and dissipation spanning from perfectly bonded to traction-free contacts which are subject to evolution in time and space. The support of interfacial boundaries is periodically illuminated by a set of incident waves and thus-induced scattered fields are captured over a generic observation surface. The performance of the proposed imaging indicator is illustrated through a set of numerical experiments for sequential reconstruction of evolving damage zones featuring randomly distributed cracks and bubbles.																	1936-4954						2020	13	3					1302	1330		10.1137/19M1305707													
J								Generalized Correlation-Based Imaging for Satellites	SIAM JOURNAL ON IMAGING SCIENCES										passive imaging; cross correlation; sparse networks		We consider imaging of fast moving small objects in space, such as low earth orbit satellites or satellite debris. The imaging system consists of ground based, asynchronous sources of radiation and several passive receivers above the dense atmosphere. We use the cross correlation of the received signals to reduce distortions from ambient medium fluctuations. Imaging with correlations also has the advantage of not requiring any knowledge about the probing pulse and depends weakly on the emitter positions. We account for the target's orbital velocity by introducing the necessary Doppler compensation. We show that over limited imaging regions, a constant Doppler factor can be used, resulting in an efficient data structure for the correlations of the recorded signals. We then investigate and analyze different imaging methods using the cross-correlation data structure. Specifically, we show that using a generalized two-point migration of the cross-correlation data, the top eigenvector of the migrated data matrix provides superior image resolution compared to the usual single-point migration scheme. We carry out a theoretical analysis that illustrates the role of the two-point migration methods as well as that of the inverse aperture in improving resolution. Extensive numerical simulations support the theoretical results and assess the scope of the imaging methodology.																	1936-4954						2020	13	3					1331	1366		10.1137/20M1322789													
J								Mathematical Morphology on the Triangular Grid: The Strict Approach	SIAM JOURNAL ON IMAGING SCIENCES										mathematical morphology; nontraditional grids; dilation; erosion; lattice property; opening; closing	REPRESENTATIONS; 2D	Mathematical morphology provides various tools for image analysis. The two basic operations, dilation and erosion, are based on translations with the help of a given structural element (another image of the grid). In contrast to the case of discrete subgroups of R-n, the triangular grid is not closed under translations; therefore, we use a restriction for the structural elements. Namely, we allow only those trixels (triangle pixels) to be in the structural elements which represent vectors such that the grid is closed under translations by these vectors. We prove that both strict dilation and erosion have nice properties. Strict opening and closing have also been defined by combining strict dilation and erosion.																	1936-4954						2020	13	3					1367	1385		10.1137/19M128017X													
J								Overparameterized Models for Vector Fields	SIAM JOURNAL ON IMAGING SCIENCES										vector fields; overparameterization; denoising; variational methods; cosparsity; inverse problems; regularization; total variation; sparsity	REGULARIZING FLOWS; IMAGES	Vector fields arise in a variety of quantity measure and visualization techniques, such as fluid flow imaging, motion estimation, deformation measures, and color imaging, leading to a better understanding of physical phenomena. Recent progress in vector field imaging technologies has emphasized the need for efficient noise removal and reconstruction algorithms. A key ingredient in the successful extraction of signals from noisy measurements is prior information, which can often be represented as a parameterized model. In this work, we extend the overparameterization variational framework in order to perform model-based reconstruction of vector fields. The overparameterization methodology combines local modeling of the data with global model parameter regularization. By considering the vector field as a linear combination of basis vector fields and appropriate scale and rotation coefficients, we can reduce the denoising problem to a simpler form of coefficient recovery. We introduce two versions of the overparameterization framework: a total variation-based method and a sparsity-based method, which relies on the cosparse analysis model. We demonstrate the efficiency of the proposed frameworks for two- and three-dimensional vector fields with linear and quadratic overparameterization models.																	1936-4954						2020	13	3					1386	1414		10.1137/19M1280697													
J								Relaxed Gauss-Newton Methods with Applications to Electrical Impedance Tomography	SIAM JOURNAL ON IMAGING SCIENCES										Gauss-Newton; nonsmooth; nonconvex; electrical impedance tomography (EIT)	DETERMINING CONDUCTIVITY; ELECTRODE MODELS; CONVERGENCE; ALGORITHMS; UNIQUENESS	As second-order methods, Gauss-Newton-type methods can be more effective than first-order methods for the solution of nonsmooth optimization problems with expensive-to-evaluate smooth components. Such methods, however, often do not converge. Motivated by nonlinear inverse problems with nonsmooth regularization, we propose a new Gauss-Newton-type method with inexact relaxed steps. We prove that the method converges to a set of disjoint critical points given that the linearization of the forward operator for the inverse problem is sufficiently precise. We extensively evaluate the performance of the method on electrical impedance tomography (EIT).																	1936-4954						2020	13	3					1415	1445		10.1137/20M1321711													
J								A Discriminative Projection and Representation-Based Classification Framework for Face Recognition	SIAM JOURNAL ON IMAGING SCIENCES										face recognition; sparse representation; discriminative projection; augmented Lagrangian method of multipliers; subsequence convergence	REGRESSION CLASSIFICATION; SPARSE REPRESENTATION	The sparse representation-based classifier (SRC) has been developed and verified as having great potential for real-world face recognition. In this paper, we propose a discriminative projection and representation-based classification (DPRC) method to enhance the discriminant ability of the SRC. The proposed method first obtains a discriminative projection matrix not only maximizing the ratio of the distance within interclass over the distance within intraclass, but also minimizing the linear approximation error within intraclass. Then it maps the original data onto the discriminative space, and adopts an SRC method to obtain the final solution. An inexact augmented Lagrangian method of multiplier is proposed for finding the optimal representation vector in our framework, and a proximal alternating minimization method is adopted to the iteration subproblems of the proposed method. The proposed method is proven to have the subsequence convergence property. Experimental results on Yale, ORL, and AR face image databases demonstrate that, compared with some existing feature extraction methods based on the SRC, the proposed DPRC method is more efficient.																	1936-4954						2020	13	3					1446	1466		10.1137/19M1253873													
J								Superresolution in Recovering Embedded Electromagnetic Sources in High Contrast Media	SIAM JOURNAL ON IMAGING SCIENCES										inverse source problem; spectral analysis; superresolution; high contrast; diffraction limit	VOLUME INTEGRAL OPERATOR; SCATTERING; LOCALIZATION; NANOPARTICLES; RESONANCES; EQUATIONS; SPECTRUM	The purpose of this work is to provide a rigorous mathematical analysis of the expected superresolution phenomenon in the time-reversal imaging of electromagnetic (EM) radiating sources embedded in a high contrast medium. It is known that the resolution limit is essentially determined by the sharpness of the imaginary part of the EM Green's tensor for the associated background. We first establish the close connection between the resolution and the material parameters and the resolvent of the electric integral operator, via the Lippmann-Schwinger representation formula. We then present an insightful characterization of the spectral structure of the integral operator for a general bounded domain and derive the pole-pencil decomposition of its resolvent in the high contrast regime. For the special case of a spherical domain, we provide some quantitative asymptotic behavior of the eigenvalues and eigenfunctions. These mathematical findings shall enable us to provide a concise and rigorous illustration of the superresolution in the EM source reconstruction in high contrast media. Some numerical examples are also presented to verify our main theoretical results.																	1936-4954						2020	13	3					1467	1510		10.1137/20M1313908													
J								Reconstruction of Smooth 3D Color Functions from Keypoints: Application to Lossy Compression and Exemplar-Based Generation of Color LUTs	SIAM JOURNAL ON IMAGING SCIENCES										3D color LUTs; generic color transformations; compression of smooth data; anisotropic diffusion; exemplar-based CLUT generation	IMAGE COMPRESSION	Three-dimensional (3D) CLUTs (color lookup tables) are popular digital models used in artistic image and video processing for color grading, simulation of analog films, and more generally the description and application of generic nonparametric color transformations. The relatively large size of these models leads to high data storage requirements when trying to distribute them on a large scale (e.g., several hundred at a time). In this article, an effective technique based on a multiscale anisotropic diffusion scheme is proposed, for the lossy compression of generic CLUTs regularly sampled on a 3D grid. Our method exhibits high average compression rates, while ensuring visually indistinguishable differences with the original (uncompressed) CLUTs. In a second step, a variation of our algorithm for exemplar-based generation of CLUTs is developed in order to create a complete CLUT from a single pair of before/after images that accounts for the color transformation.																	1936-4954						2020	13	3					1511	1535		10.1137/19M1306798													
J								A New Efficient Algorithm for Volume-Preserving Parameterizations of Genus-One 3-Manifolds	SIAM JOURNAL ON IMAGING SCIENCES										volumetric stretch energy; energy minimization; volume-preserving; toroidal polyhedra	DISCRETE; MAPS	Parameterizations of manifolds are widely applied to the fields of numerical partial differential equations and computer graphics. To this end, in recent years several efficient and reliable numerical algorithms have been developed by different research groups for the computation of triangular and tetrahedral mesh parameterizations. However, it is still challenging when the topology of manifolds is nontrivial, e.g., the 3-manifold of a topological solid torus. In this paper, we propose a novel volumetric stretch energy minimization algorithm for volume-preserving parameterizations of toroidal polyhedra with a single boundary being mapped to a standard torus. In addition, the algorithm can also be used to compute the equiareal mapping between a genus-one closed surface and the standard torus. Numerical experiments indicate that the developed algorithm is effective and performs well on the bijectivity of the mapping. Applications on manifold registrations and partitions are demonstrated to show the robustness of our algorithms.																	1936-4954						2020	13	3					1536	1564		10.1137/19M1301096													
J								Multitaper Estimation on Arbitrary Domains	SIAM JOURNAL ON IMAGING SCIENCES										spectral estimation; multitaper estimators; spatiospectral concentration; irregular domains; block eigendecomposition; cryo-electron microscopy	SPHEROIDAL WAVE-FUNCTIONS; SPECTRAL ESTIMATION; SPATIOSPECTRAL CONCENTRATION; FOURIER-ANALYSIS; APPROXIMATION; SPACE; TIME	Multitaper estimators have enjoyed significant success in estimating spectral densities from finite samples using as tapers Slepian functions defined on the acquisition domain. Unfortunately, the numerical calculation of these Slepian tapers is only tractable for certain symmetric domains, such as rectangles or disks. In addition, no performance bounds are currently available for the mean squared error of the spectral density estimate. This situation is inadequate for applications such as cryo-electron microscopy, where noise models must be estimated from irregular domains with small sample sizes. We show that the multitaper estimator only depends on the linear space spanned by the tapers. As a result, Slepian tapers may be replaced by proxy tapers spanning the same subspace (validating the common practice of using partially converged solutions to the Slepian eigenproblem as tapers). These proxies may consequently be calculated using standard numerical algorithms for block diagonalization. We also prove a set of performance bounds for multitaper estimators on arbitrary domains. The method is demonstrated on synthetic and experimental datasets from cryo-electron microscopy, where it reduces the mean squared error by a factor of two or more compared to traditional methods.																	1936-4954						2020	13	3					1565	1594		10.1137/19M1278338													
J								Multiplicative Noise Removal: Nonlocal Low-Rank Model and Its Proximal Alternating Reweighted Minimization Algorithm	SIAM JOURNAL ON IMAGING SCIENCES										multiplicative noise removal; nonlocal low-rank regularization; image restoration	VARIATIONAL MODEL; NONSMOOTH ANALYSIS; SINGULAR-VALUES; SPECKLE; NONCONVEX; IMAGES	The goal of this paper is to develop a novel numerical method for efficient multiplicative noise removal. The nonlocal self-similarity of natural images implies that the matrices formed by their nonlocal similar patches are low-rank. By exploiting this low-rank prior with application to multiplicative noise removal, we propose a nonlocal low-rank model for this task and develop a proximal alternating reweighted minimization (PARM) algorithm to solve the optimization problem resulting from the model. Specifically, we utilize a generalized nonconvex surrogate of the rank function to regularize the patch matrices and develop a new nonlocal low-rank model, which is a nonconvex non-smooth optimization problem having a patchwise data fidelity and a generalized nonlocal low-rank regularization term. To solve this optimization problem, we propose the PARM algorithm, which has a proximal alternating scheme with a reweighted approximation of its subproblem. A theoretical analysis of the proposed PARM algorithm is conducted to guarantee its global convergence to a critical point. Numerical experiments demonstrate that the proposed method for multiplicative noise removal significantly outperforms existing methods, such as the benchmark SAR-BM3D method, in terms of the visual quality of the denoised images, and of the peak-signal-to-noise ratio (PSNR) and the structural similarity index measure (SSIM) values.																	1936-4954						2020	13	3					1595	1629		10.1137/20M1313167													
J								Exact Recovery of Multichannel Sparse Blind Deconvolution via Gradient Descent	SIAM JOURNAL ON IMAGING SCIENCES										sparse recovery; blind deconvolution; nonconvex geometry; nonconvex optimization; Riemannian manifold; inverse problem; nonlinear approximation	NONCONVEX OPTIMIZATION; RECONSTRUCTION; CONVERGENCE; ALGORITHMS; FMRI	We study the multichannel sparse blind deconvolution (MCS-BD) problem, whose task is to simultaneously recover a kernel a and multiple sparse inputs {x(i)}(i=1)(p) from their circulant convolution y(i) = a (sic) x(i) (i = 1, ..., p). We formulate the task as a nonconvex optimization problem over the sphere. Under mild statistical assumptions of the data, we prove that the vanilla Riemannian gradient descent (RGD) method, with random initializations, provably recovers both the kernel a and the signals {x(i)}(i=1)(p) up to a signed shift ambiguity. In comparison with state-of-the-art results, our work shows significant improvements in terms of sample complexity and computational efficiency. Our theoretical results are corroborated by numerical experiments, which demonstrate the superior performance of the proposed approach over the previous methods on both synthetic and real datasets.																	1936-4954						2020	13	3					1630	1652		10.1137/19M1291327													
J								3D Orientation-Preserving Variational Models for Accurate Image Registration	SIAM JOURNAL ON IMAGING SCIENCES										orientation-preserving maps; variational model; 3D image registration; generalized Gauss-Newton method	LARGE-DEFORMATION; DIFFEOMORPHISMS; REGULARIZATION; MAPPINGS; FLOWS	The Beltrami coefficient from complex analysis has recently been found to provide a robust constraint for obtaining orientation-preserving and diffeomorphic transformations for registration of planar images. There exists no such concept of the Beltrami coefficient in three or higher dimensions, although a generalized theory of quasi-conformal maps in high dimensions exists. In this paper, we first propose a new algebraic measure in three dimensions (3D) that mimics the Beltrami concept in two dimensions (2D) and then propose a corresponding registration model based on it. We then establish the existence of solutions for the proposed model and further propose a converging generalized Gauss-Newton iterative method to solve the resulting nonlinear optimization problem. In addition, we also provide another two possible regularizers in 3D. Numerical experiments show that the new model can produce more accurate orientation-preserving transformations than competing state-of-the-art registration models.																	1936-4954						2020	13	3					1653	1691		10.1137/20M1320006													
J								A Three-Stage Variational Image Segmentation Framework Incorporating Intensity Inhomogeneity Information	SIAM JOURNAL ON IMAGING SCIENCES										image segmentation; intensity inhomogeneity; Mumford-Shah model; sPADMM; convergence rate	LEVEL SET EVOLUTION; MUMFORD-SHAH MODEL; ACTIVE CONTOURS; GLOBAL MINIMIZATION; TEXTURE; BINARY; COLOR; APPROXIMATION; RESTORATION; DRIVEN	In this paper, we propose a new three-stage segmentation framework based on a convex variant of the Mumford-Shah model and the intensity inhomogeneity information of an image. The first stage in our framework is to perform a dimension lifting method. An intensity inhomogeneity image is added as an additional channel, which results in a vector-valued image. In the second stage, a convex variant of the Mumford-Shah model is applied to each channel of the vector-valued image to obtain a smooth approximation. We use the semi-proximal alternating direction method of multipliers (sPADMM) to solve this model and prove that the sPADMM for solving this convex model has Q-linear convergence rate. In the last stage, we apply a thresholding method to the smoothed vector-valued image to get the final segmentation. Experiments demonstrate clearly that the proposed methods can provide more accurate segmentation results in comparison with five state-of-the-art methods including a deep learning approach.																	1936-4954						2020	13	3					1692	1715		10.1137/20M1310618													
J								Fiber optic chemical sensors for water testing by using fiber loop ringdown spectroscopy technique	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Fiber optic sensors; chemical trace; fiber optic; fiber optic chemical sensors; evanescent field; FLRD spectroscopy technique	N,N-DIMETHYL-P-PHENYLENEDIAMINE; CONCRETE; AMMONIA; IRON	Real-time response, low cost, sensitive and easy setup fiber optic chemical sensors were fabricated by etching a part of single mode fiber in hydrofluoric (HF) acid solution and tested in different water samples such as tap water, DI water, salty and sugar water with different concentrations to record ringdown time (RDT) differences between media due to refractive index differences by employing the fiber loop ringdown (FLRD) spectroscopy technique. Baseline stability of 0.63% and the minimum detectable RDT of 5.05 mu s for this kind of fiber optic chemical sensors were obtained. Fabricated sensors were coated with N,N-Diethyl-p-phenylenediamine for the first time and tested in several water solutions. Afterwards, the sensors were immersed into salty and sugar water solutions in different concentrations. The results showed that this kind of FLRDS fiber optic chemical sensors can be applicable to trace chemicals in water solutions. Moreover, fiber optic sensors can be specially modified to trace specifically any target chemicals in solutions for the special purpose and the early detection.																	1300-0632	1303-6203					2020	28	5					2375	2384		10.3906/elk-2005-39													
J								Field-of-view optimization of magnetically actuated 2D gimballed scanners	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Microscanner; magnetic actuation scheme; electrocoil; total optical scan angle (TOSA); field of view (FOV); experimental optimization	MIRROR	This work presents the field of view (FOV) maximization of a magnetically actuated two-dimensional (2D) gimballed scanner. The process of maximization is completed in two steps. (1) Optimization of the electrocoil providing the magnetic force that moves the scanner and (2) precise choice of optimum respective locations of both the scanner and the electrocoil. We first derived a formula relating the generated magnetic flux density, coil design parameters and driving voltage. Subsequently, we discussed the design trade-offs of an actuating electrocoil. We also conducted several experiments on a stainless steel 430 scanner having a footprint of 15 mm x 15 mm and a thickness of 460 mu m. We determined the precise locations for the system components producing the maximum total optical scan angle (TOSA) hence the largest FOV. Finally, we proposed an empirically demonstrated formula, p(x(1), y(1)) approximate to p(0.25L(s) + 0.25L(m)), for the optimum electrocoil location with respect to the scanner by providing an offset Delta x and Delta y from the center to be able to successfully maximize the displacement and the related total optical scan angle of the system.																	1300-0632	1303-6203					2020	28	5					2385	2399		10.3906/elk-2004-19													
J								Exploring the power of supervised learning methods for company name disambiguation in microblog posts	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Text processing; name disambiguation; entity resolution; supervised classification; microblogs		Twitter is an online social networking website where people can post short messages on any subject, and these messages become visible to other users. Users intentionally express their opinions about companies or products via microblogging texts. Analyzing such messages might help explore what customers think about company products, or what the broad feelings of customers are. Identifying tweets referring to products and companies is becoming an important tool recently. However, company names are often vague. Hence, the first step is to locate the messages that are relevant to a company. In this paper, we present a number of supervised learning techniques to decide whether a given tweet is about a company, e.g., whether a message containing the term `amazon'is related to the company Amazon Inc. or not. Solving this task is challenging in comparison to the classical classification process. The main difficulty with this problem is that tweets and company names include limited information. To make this task tractable, external resources are used to get richer data about a company. More specifically, we generate several profiles for each organization, which contain richer information. Then we perform feature extraction to obtain both numerical and categorical features and we do feature selection to identify the most relevant attributes with our task. Finally, we train several supervised classifiers. Our constructed classifiers and carefully selected features provide high accuracy on the WePS-3 dataset. Our results show considerable improvement of accuracy by 11% over baseline approaches.																	1300-0632	1303-6203					2020	28	5					2400	2415		10.3906/elk-1809-167													
J								Fuzzy genetic based dynamic spectrum allocation approach for cognitive radio sensor networks	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Wireless sensor network; fuzzy logic; genetic algorithm; dynamic spectrum access; cognitive radio sensor	PERFORMANCE ANALYSIS	Cognitive radio sensor network (CRSN) is known as a distributed network of wireless cognitive radio sensor nodes. Such a system senses an event signal and ensures collaborative dynamic communication processes over the spectrum bands. Here the concept of dynamic spectrum access defines the method of reaching progressively to the unused range of spectrum band. As among the essential CRSN user types, the primary user (PU) has the license to access the spectrum band. On the other hand, the secondary user (SU) tries to access the unused spectrum efficiently, by not disturbing the PU. Considering that issue, this study introduces a fuzzy genetic based dynamic spectrum allocation (FGDSA) system for deciding spectrum allocation in cognitive radio sensor networks. In detail, the primary objective of the FGDSA system is to increase channel use without causing too much interference to the PU. In order to achieve that, some parameters such as signal interference noise ratio (SINR), bit error rate (BER), available channel bandwidth, SU transmission power, and the SU data rate are used as input variables for the fuzzy based inference mechanism taking place in the FGDSA. After development of the system, a performance analysis was done by comparing some metrics such as channel utilization, signal noise interference ratio, and the channel access delay for fuzzy based inference and the fuzzy genetic based inference that are both performing spectrum allocation. It was observed that the hybrid system of FGDSA outperforms fuzzy system by 2% in channel utilization, by also ensuring 16% less SINR, and 41% less channel access delay. The FGDSA was compared with also some existing spectrum allocation techniques such as edge coloring heuristic (ECH) and clique heuristic algorithm (CHA). It was seen that the FGDSA outperforms both ECH and CHA in average channel utilization, with the rates of 6% and 8%, respectively.																	1300-0632	1303-6203					2020	28	5					2416	2432		10.3906/elk-1907-206													
J								Reconfiguration-based hierarchical energy management in multimicrogrid systems considering power losses, reliability index, and voltage enhancement	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Reconfiguration; multimicrogrid systems; energy management	NETWORK RECONFIGURATION; LOSS MINIMIZATION; INTELLIGENT ENERGY; INCLUDING WIND; MICROGRIDS; STORAGE; INTEGRATION	This paper presents a reconfiguration-based hierarchical energy management for interconnected microgrids known as multimicrogrid system. The goal is to minimize the operational costs of different entities alongside with finding the best topology to minimize the active power loss, enhance reliability index, and improve the voltage level. The distribution network (DN) includes several dispatchable and undispatchable distributed energy resources, energy storage devices, and multiple microgrids (MGs). The first layer of the optimization process is executed by each MG operator and each MG performs local energy management. Each MG operator informs the DN operator about its optimal schedules. Finally, global energy management with reconfiguration in the network topology is done by the DN operator. The energy management problem is modeled as a mixed-integer nonlinear programming problem. Simulations on a modified IEEE 33-bus distribution test system with multiple MGs is performed in GAMS environment.																	1300-0632	1303-6203					2020	28	5					2433	2447		10.3906/elk-1907-114													
J								Real-time anomaly detection and mitigation using streaming telemetry in SDN	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Streaming telemetry; anomaly detection; software-defined networks	DDOS; FLOW	Measurement and monitoring are crucial for various network tasks such as traffic engineering, anomaly detection, and intrusion prevention. The success of critical capabilities such as anomaly detection and prevention depends on whether the utilized network measurement method is able to provide granular, near real-time, low-overhead measurement data or not. In addition to the measurement method, the anomaly detection and mitigation algorithm is also essential for recognizing normal and abnormal traffic patterns in such a huge amount of measured data with high accuracy and low latency. Software-defined networking is an emerging concept to enable programmable and efficient measurement functions for these kinds of challenging requirements. In this paper, we present a new, real-time, model-driven anomaly detection and mitigation platform. Model-driven streaming telemetry and exponential smoothing are the underlying approaches of the platform. A customized collector is proposed to gather streaming telemetry metrics, and Holt's prediction algorithm is improved to handle real-time streaming data and decrease false positives. The developed system is tested on a campus network and the success rate of the system is calculated as 92%.																	1300-0632	1303-6203					2020	28	5					2448	2466		10.3906/elk-1909-112													
J								An encrypted speech authentication method based on uniform subband spectrum variance and perceptual hashing	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Encrypted speech authentication; perceptual hashing; uniform subband spectrum variance; feature extraction of encrypted speech; tamper location	RETRIEVAL ALGORITHM	In a real-world cloud server, a speech signal is prone to suffer various attacks, such as malicious muting and tampering. In such a context, the privacy security of the speech owner will not be guaranteed. In order to achieve content authentication of encrypted speech in the cloud server, an efficient encrypted speech authentication method based on uniform subband spectrum variance and perceptual hashing is proposed. Firstly, the original speech is scrambled by Henon mapping to construct an encrypted speech library in the cloud, through extracting uniform subband spectrum variance of the encrypted speech and constructing a hashing sequence to generate a hashing template of the cloud. In this way, a one-to-one correspondence between the encrypted speech and the hashing sequence is built. Secondly, the authentication digest of encrypted speech is extracted according to the inquiry result. Finally, the authentication digest and the hashing sequence in the cloud are matched by the Hamming distance algorithm. The experimental results demonstrate that the proposed method has great security and efficiency, and it can directly extract the authentication digest from encrypted speech. The authentication digest not only has good discrimination and robustness, but it accurately locates the tampered area for malicious substitution and mute attacks.																	1300-0632	1303-6203					2020	28	5					2467	2482		10.3906/elk-1907-94													
J								Wavelength sensitivity of indium tin oxide on surface plasmon resonance angles	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Surface plasmon resonance; borosilicate prism; indium tin oxide; silver; gold	OPTICAL-PROPERTIES; AG; SPECTROSCOPY; SENSORS; AU; CO; CU	Surface plasmon resonance (SPR) is a charge-density oscillation that occurs when a beam of p-polarized monochromatic light impinges with a greater angle than the critical angle in a dielectric-metal interface. Because of the high losses related to metals, the generated surface plasmon waves propagate with high attenuation in the visible and near-infrared spectral regions in most of the dielectric-metal interfaces. An alternative to reduce such losses is to use a transparent indium tin oxide (ITO) film In this paper, we compared theoretical calculations and experimental measurements of the SPR angle theta(SPR) on the interfaces of a borosilicate prism (Bp) and ITO, Bp-Ag, and Bp-Au. Three different wavelengths (405, 532, and 650 nm) were used to measure theta(SPR) that covered almost all of the visual range spectrum. Both calculations and experimental data showed that SPR characteristics are strongly influenced by the metal's optical properties. The measured theta(SPR) in the Bp-ITO interface is much smaller than the theta(SPR) measured in the other two interfaces. Hence, ITO can be used in a similar way as Au and Ag in prism-metal interfaces, providing a cheaper and more versatile option to generate the SPR effect.																	1300-0632	1303-6203					2020	28	5					2483	2492		10.3906/elk-1909-44													
J								Low power and low phase noise VCO with dual current shaping for IoT applications	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Internet of things; LC voltage-controlled oscillator; low power; current shaping	CLASS-C VCO; AMPLITUDE FEEDBACK LOOP; QUADRATURE VCO; LC VCO; DESIGN	In this paper, two low phase noise and power consumption VCO circuits, which are suitable for Internet of things (IoT) applications, are proposed. In the first structure, in order to have more control of the current consumption, the current shaping technique is used in the PMOS and NMOS biasing circuit. In the second structure, for increasing the oscillation amplitude and reducing the phase noise, independent biasing for the NMOS section is used. In both structures, to increase the frequency tuning range (FTR), without using a capacitor bank, the varactor is used in the biasing structure. In the first structure the supply voltage, output frequency, power consumption, and phase noise are 0.8 V, 2.44 GHz, 0.37 mW, and -117.5 dBc/Hz, respectively, but in the second structure, the supply voltage, output frequency, power consumption, and phase noise are 0.8 V, 2.44 GHz, 0.62 mW, and -120 dBc/Hz, respectively. It should be noted that the two structures are designed and simulated in 65-nm CMOS technology. Finally, the results show that the figure-of-merit for the first and second structures is -190 dBc/Hz and -190.2 dBc/Hz, respectively.																	1300-0632	1303-6203					2020	28	5					2493	2506		10.3906/elk-1909-47													
J								An electrothermal current prediction method for overload protection of miniature circuit breakers	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Miniature circuit breaker; electrothermal current calculation; fast temperature acquisition; overload protection		Traditional miniature circuit breakers (MCBs) cannot meet the requirement for the intelligence of distributing apparatuses in a smart grid. The intellectualization of MCBs is restricted due to the lack of appropriate current measurement methods. Thus, an electrothermal current prediction method is proposed based on the derived relationship between root-mean-square (RMS) current and steady-state temperature rise. A fast acquisition algorithm is used to obtain the required temperature rise before thermal equilibrium to highly reduce the total time consumption. The presented prediction method is found immunized against the ambient temperature. The theory is validated with experiments using a thermostat. The tested steady-state accuracy and transient performance could meet the overload protection requirements without being affected by the environmental temperature.																	1300-0632	1303-6203					2020	28	5					2523	2537		10.3906/elk-1911-74													
J								Reducing computational complexity in fingerprint matching	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Biometrics; cross-correlation; minutiae points; filtering; matching	MINUTIAE	The performance of cross-correlation functions can decrease computational complexity under optimal fingerprint feature selection. In this paper, a technique is proposed to perform alignment of fingerprints followed by their matching in fewer computations. Minutiae points are extracted and alignment is performed on the basis of their spatial locations and orientation fields. Unlike traditional cross-correlation based matching algorithms, ridges are not included in the matching process to avoid redundant computations. However, optimal cross-correlation is chosen by correlating feature vectors accompanying x-y locations of minutiae points and their aligned orientation fields. As a result, matching time is significantly reduced with much improved accuracy.																	1300-0632	1303-6203					2020	28	5					2538	2551		10.3906/elk-1907-113													
J								Efficient bandwidth management algorithm for NG-EPON	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										NG-EPON; dynamic wavelength and bandwidth allocation (DWBA); packet delay; packet drop ratio; grant utilization	NETWORK TWDM-PON; DYNAMIC WAVELENGTH; NEXT-GENERATION; ALLOCATION ALGORITHMS; SCHEME; IPACT; TIME	Next generation ethernet passive optical network (NG-EPON) is a promising technology to cater huge bandwidth and efficient distribution demands of the future Internet services. IEEE working group has been doing efforts for the standardization of NG-EPON. Four wavelength channels of 25Gbps each are supported by NG-EPON for the transmission of optical network unit (ONU) traffic towards optical line terminal (OLT). Dynamic wavelength and bandwidth allocation (DWBA) algorithms are needed for the efficient arbitration of bandwidth resources between subscribers. In this paper, we have proposed a DWBA algorithm named as efficient bandwidth management algorithm (EBMA) for NG-EPON. EBMA has been designed to manage the diversified traffic requirements of different ONUs. EBMA performance is evaluated comparatively with modified IPACT (M-IPACT) and first fit (FF-DWBA) algorithms. EBMA for NG-EPON proves to be better on the basis of packet delay, packet drop ratio and grant utilization. Simulation results showed improved performance of EBMA in comparison with M-IPACT and FF-DWBA algorithms.																	1300-0632	1303-6203					2020	28	5					2552	2565		10.3906/elk-1903-19													
J								Adaptive modified artificial bee colony algorithms (AMABC) for optimization of complex systems	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Complex system; optimization; parameter setting; artificial bee colony; modified artificial bee colony; adaptive modified artificial bee colony		Complex systems are large scale and involve numerous uncertainties, which means that such systems tend to be expensive to operate. Further, it is difficult to analyze systems of this kind in a real environment, and for this reason agent-based modeling and simulation techniques are used instead. Based on estimation methods, modeling and simulation techniques establish an output set against the existing input set. However, as the data set in a given complex systems becomes very large, it becomes impossible to use estimation methods to create the output set desired. Therefore, a new mechanism is needed to optimize data sets in this context. In this paper, the adaptive modified artificial bee colony algorithm is shown to be successful in optimizing the numerical test function and complex system parameter data sets. Moreover, the results show that this algorithm can be successfully adapted to a given problem. Specifically, this algorithm can be more successful in optimizing problem solving than either the artificial bee colony algorithm or the modified artificial bee colony algorithm. The adaptive modified artificial bee colony algorithm performs a search in response to feedback received from the simulation in run-time. Because of its adaptability, the adaptive modified artificial bee colony algorithm is of great importance for its ability to find solutions to multiple kinds of problems across numerous fields.																	1300-0632	1303-6203					2020	28	5					2602	2629		10.3906/elk-1909-12													
J								mlCoCoA: a machine learning-based congestion control for CoAP	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Internet of Things; CoAP; CoCoA; congestion control; machine learning	INTERNET; THINGS	Internet of Things (IoT) is a technological invention that has the potential to impact on how we live and how we work by connecting any device to the Internet. Consequently, a vast amount of novel applications will enhance our lives. Internet Engineering Task Force (IETF) standardized the Constrained Application Protocol (CoAP) to accommodate the application layer and network congestion needs of such IoT networks. CoAP is designed to be very simple where it employs a genuine congestion control (CC) mechanism, named as default CoAP CC leveraging basic binary exponential backoff. Yet efficient, default CoAP CC does not always utilize the network dynamics the best. As a result, CoCoA has been exposed to better utilize the IoT networks. Although CoCoA considers the network dynamics, the RTO calculation of CoCoA is based on constant coefficient values. However, our experiments show that these constant values, in general, do not achieve the best throughput. Inspired by these observations, we propose a new machine learning-based CC mechanism called as mlCoCoA that is a variation of CoCoA. Particularly, mlCoCoA sets retransmission timeout (RTO) estimation parameters of CoCoA adaptively by using a machine learning method. In this study, we applied support vector machines on a self-created dataset to develop new models for improving the throughput of the IoT network with dynamic selection of CoCoA coefficient values. We carried out extensive simulations in Cooja environment coupled with Californium. Our results indicate that compared to the performance of default CoAP CC and CoCoA mechanisms, mlCoCoA has merit in terms of improving the throughput of CoAP applications.																	1300-0632	1303-6203					2020	28	5					2863	2882		10.3906/elk-2003-17													
J								A supervised learning approach for detecting erroneous samples in embeddings	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Dimensionality reduction; error estimation; t-SNE; random forests; matching	DIMENSIONALITY REDUCTION	Visualizing multidimensional data has been a crucial task in recent years regarding the growing amount of data from various sources. To achieve this, dimensionality reduction algorithms have been used to reduce the number of dimensions for visualization of the data on a screen. However, these algorithms may fail to faithfully represent high dimensional data in lower dimensions and eventually lead to erroneous visualizations. In this work, we propose an error detection algorithm for dimensionality reduction algorithms based on recently developed error prediction algorithms for medical image registration. The proposed algorithm matches the neighborhoods of high and low dimensional data with different similarity measures and predicts the errors using a random forest classifier. The results on three datasets show that the proposed algorithm can successfully detect errors with an accuracy up to 86% and area under the curve score of 0.81.																	1300-0632	1303-6203					2020	28	5					2883	2894		10.3906/elk-1909-162													
J								Optimized idling grid-connection strategy for synchronous condenser	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Direct current transmission; synchronous condenser; static frequency converter; synchronous device; idling grid-connection	DYNAMIC PERFORMANCE; POWER	The rise of large-scale HVDC transmission technology has introduced new requirements for dynamic reactive power compensation in power systems. The new generation of synchronous condensers is independent of grid voltage and does not need to be dragged by a coaxial prime mover, which can improve the dynamic reactive power compensation of the power grid. This new generation of synchronous condensers is dragged by the static frequency converter to a 105% rated speed, after which the static frequency converter logs out. In the process of idling, the excitation mode switching is completed and the unit is connected to the grid simultaneously. The synchronous device passively captures the connection-dot in the process of idling; as a result, increasing the grid-connection success rate and reducing the impact of grid connection become a pair of contradictions. In this paper, the boundary conditions of the new generation of synchronous condenser grid-connection systems are analyzed. These provide the basis for setting the synchronous device parameters. Furthermore, this paper proposes an optimized grid-connection strategy to ensure the new generation of synchronous condensers possesses good grid-connection characteristics.																	1300-0632	1303-6203					2020	28	5					2895	2909		10.3906/elk-1907-139													
J								An improved memetic genetic algorithm based on a complex network as a solution to the traveling salesman problem	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Travelling salesman problem; genetic algorithm; memetic algorithm; local search; complex network	OPTIMIZATION; SYSTEM	A genetic algorithm (GA) is not a good option for finding solutions around in neighborhoods. The current study applies a memetic algorithm (MA) with a proposed local search to the mutation operator of a genetic algorithm in order to solve the traveling salesman problem (TSP). The proposed memetic algorithm uses swap, reversion and insertion operations to make changes in the solution. In the basic GA, unlike in the real world, the relationship between generations has not been considered. This gap is resolved using the proposed complex network to allow selection among possible solutions. The degree measure has been used for analysis the network. Different scenarios have been evaluated to solve seven TSPLib problems. For example, the results indicated that the memetic algorithm with a complex network, the memetic algorithm with the proposed local search and basic GA have 0.31%, 1.15% and 38% errors, respectively, when solving the TSP for 70 cities compared to the best solution in the TSPLib database. These results offered better performance of the memetic algorithm with a complex network compared to the memetic algorithm with the proposed local search and the basic GA. Also, the average run time of the algorithms showed their scalability.																	1300-0632	1303-6203					2020	28	5					2910	2925		10.3906/elk-1911-106													
J								Comparative study between measured and estimated wind energy yield	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Wind energy; wind turbine; Rayleigh approach; energy density; power-speed curve	TURBINE	This paper proposes a power-speed (P-V) model of the wind turbine by assuming three different functions for the first performance region; cubic, quadratic and uncorrected cubic. These three functions have been compared with the manufacturer models of five different wind turbines which were installed in five different locations in Jordan; Tafila, Hofa, Fujeij, Al Rajef, and Deahan. The wind turbine of these wind farms are considered as large scale HAWT in the range of Mw. The generated P-V models are developed by applying a new method described in this paper which is basically based on generating a multiplier factor x. In this study, the quadratic model shows the highest correlation compared with the other models. The wind energy yield for the selected wind farms has been estimated by a mathematical modelling based on Rayleigh distribution function, derived in this paper. The energy yield using this mathematical model has been compared with the measured energy output of four wind farms, Tafila, Hofa, Al Rajef, and Deahan. The measured energy were provided by the operators of these wind farms which are: Jordan Wind Project Company(JWPC), Central Electricity Generation Company (CEGC), Green Watts Renewable Energy (GWRC)and Korean Southern Power Company(KOSPO). Results show that the estimated energy using the quadratic wind turbine model for all wind farms are very close to the actual output. Accuracy analysis for the quadratic model resulted in an error of less than 10% between the measured and estimated energy output for all wind farms. The capacity factors for the selected wind farms have been estimated using the quadratic P-V model. Results show that Tafila wind farm has the highest capacity factor which is around 47%.																	1300-0632	1303-6203					2020	28	5					2926	2939		10.3906/elk-2002-85													
J								Gabor filter-based localization of straight and curved needles in 2D ultrasound images	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Robotic assisted biopsy; Gabor filter; curved needle; shape visualization; ultrasound image processing	BIOPSY; ENHANCEMENT; TRACKING; SEGMENTATION; ALGORITHM	2D ultrasound (US) is one of the most commonly used medical imaging devices for needle localization in biopsies. However, the produced images are low-resolution and contain an excessive number of artifacts, which makes the needle localization challenging. Image processing techniques can help resolve this issue. This paper presents a novel Gabor filter-based method for needle localization in 2D US images, which enhances the needle outline in the images while suppressing other structures. The scheme works in two stages: First, the Gabor filter is applied to the image, the needle insertion angle is estimated, and the needle trajectory is found using a RANSAC line fitting; then, the Gabor filter is repeated using the estimated insertion angle and the location of the needle tip is estimated using probability mapping. The proposed scheme works with both straight and curved needles. An automatic parameter tuning method, which is used to optimize the threshold value of the Otsu's method, is also presented here. The tests on this needle localization scheme were done using two different water mixtures, three different gelatin-based phantoms, and ex vivo experiments. The accuracy was assessed using an infrared-camera-based tracking sensor and computed tomography images. The results showed that the suggested localization scheme can be effectively used in the 2D US image-guided needle procedures.																	1300-0632	1303-6203					2020	28	5					2940	2955		10.3906/elk-1912-181													
J								Detection of hand osteoarthritis from hand radiographs using convolutional neural networks with transfer learning	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Hand osteoarthritis; convolutional neural networks; transfer learning; conventional hand radiography; classification	CLASSIFICATION	Osteoarthritis is the most common type of arthritis. Hand osteoarthritis leads to specific structural changes in the joints, such as asymmetric joint space narrowing and osteophytes (bone spurs). Conventional radiography has traditionally been the primary method of visualizing these structural changes and diagnosing osteoarthritis. We aimed to develop a computerized method that is capable of determining the structural changes seen in radiography of the hand and to assist practitioners in interpreting radiographic changes and diagnosing the disease. In this retrospective study, transfer-learning-based convolutional neural networks were trained on a randomly selected dataset containing 332 radiography images of hands from an original set of 420 and were validated with the remaining 88. Multilayer convolutional neural network models were designed based on a transfer learning method using pretrained AlexNet, GoogLeNet, and VGG-19 networks. The accuracies of the models were 93.2% for AlexNet, 94.3% for GoogLeNet, and 96.6% for VGG-19. The sensitivities of these models were 0.9167 for AlexNet, 0.9184 for GoogLeNet, and 0.9574 for VGG-19, while the specificity values were 0.9500, 0.9744, and 0.9756, respectively. The performance metrics, including accuracy, sensitivity, specificity, and precision, of our newly developed automated diagnosis methods are promising in the diagnosis of hand osteoarthritis. Our computer-aided detection systems may help physicians in interpreting hand radiography images, diagnosing osteoarthritis, and saving time.																	1300-0632	1303-6203					2020	28	5					2968	2978		10.3906/elk-1912-23													
J								Chronic obstructive pulmonary disease severity analysis using deep learning on multi-channel lung sounds	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Deep ELM; RespiratoryDatabase@TR; deep learning; ELM autoencoder; COPD severity	DIFFERENCE PLOT; CLASSIFICATION; COPD; SIGNALS; SYSTEM	Chronic obstructive pulmonary disease (COPD) is one of the deadliest diseases which cannot be treated but can be kept under control in certain stages. COPD has five severities, including at-risk, mild, moderate, severe, and very severe stages. Diagnosis of COPD at early stages needs additional clinical tests for even experienced specialists. The study aims at detecting the severity of the COPD to start treatment for preventing the progression of the disease to the next levels. We analyzed 12-channel lung sounds with different COPD severities from RespiratoryDatabase@TR. The lung sounds were recorded from the clinical auscultation points from 41 patients on posterior (chest) and anterior (back) sides. 3D second-order difference plot was applied to extract characteristic abnormalities on lung sounds. Cuboid and octant-based quantizations were utilized to extract characteristic abnormalities on chaos plot. Deep extreme learning machines classifier (deep ELM), which is one of the most stable and fast deep learning algorithms, was utilized in the classification stage. Novel HessELM and LuELM autoencoder kernels were adapted to deep ELM and reached higher generalization capabilities with a faster training speed against the conventional ELM autoencoder. The proposed deep ELM model with LuELM autoecoder has separated five COPD severities with classification performance rates of 94.31%, 94.28%, 98.76%, and 0.9659 for overall accuracy, weighted-sensitivity, weighted-specificity, and area under the curve (AUC) value, respectively. The proposed deep analysis of 12-channel lung sounds provides a standardized and entire lung assessment for identification of COPD severity. Our study is a pioneering approach that directly focuses on lung sounds. Novel deep ELM kernels have performed a higher generalization and fast training compared to conventional kernels.																	1300-0632	1303-6203					2020	28	5					2979	2996		10.3906/elk-2004-68													
J								Variable gain high order sliding mode control approaches for PMSG based variable speed wind energy conversion system	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Super-twisting algorithm (STA); chattering; maximum power point tracking (MPPT); real-twisting algorithm (RTA); wind energy conversion system (WECS); permanent magnetic synchronous generator (PMSG); uniform robust exact differentiator (URED)	POWER POINT TRACKING; CONTROL STRATEGY; TURBINE SYSTEM; ALGORITHM; TORQUE	This research article proposes two different variants of variable gain higher-order sliding mode control (HOSMC) strategy for a variable-speed wind energy conversion system (WECS) based on a permanent magnet synchronous generator (PMSG). The main objective is to extract the maximum wind power with reduced chattering and mechanical stress. The main flaw of the classical sliding mode control (SMC) is the high-frequency switching, called chattering, which is alleviated by employing HOSMC strategies. The control law design is based on a super-twisting algorithm (STA) and a real-twisting algorithm (RTA) with variable gains. The proposed control techniques inherit the property of robustness and successfully deal with the nonlinear behavior of the system, erratic nature of the wind speed, external disturbances as well as model uncertainties. Also, the significance of smooth control action and variable gains strongly reduce the chattering effect. For a given reference speed, the generator speed and its missing derivative are retrieved by using a uniform robust exact differentiator (URED). The performance validation and effectiveness of the proposed control techniques is supported by Matlab/Simulink simulations, carried out under varying wind speed, parametric variations, and load variations.																	1300-0632	1303-6203					2020	28	5					2997	3012		10.3906/elk-1909-69													
J								Distribution network reconfiguration based on artificial network reconfiguration for variable load profile	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Distribution system; network reconfiguration; artificial neural networks; evolutionary programming	POWER LOSS MINIMIZATION; DISTRIBUTION-SYSTEMS; LOSS REDUCTION; FEEDER RECONFIGURATION; CUCKOO SEARCH; GENERATION; ALLOCATION; ALGORITHM; DG; IMPROVEMENT	Network reconfiguration is a process to change the open-switches in distribution system for a minimum power loss. In the past, metaheuristic techniques were applied widely for network reconfiguration with consideration of a fixed loading profile. When the loading changes, the current configuration may not be the optimal one. Thus, the technique needs to be executed to find a new optimal configuration based on the latest loading. The process is time-consuming since metaheuristic techniques commonly require high computational times and produces inconsistent results. Therefore, this paper proposes a network reconfiguration technique based on artificial neural network (ANN) for variable loading conditions. The proposed ANN model is tested on IEEE 33-bus, IEEE 69-bus, and IEEE-118 bus systems. The test results indicate the efficiency of the proposed technique in three aspects: processing time, simple structure, and high accuracy.																	1300-0632	1303-6203					2020	28	5					3013	3035		10.3906/elk-1912-89													
J								A novel grouping proof authentication protocol for lightweight devices: GPAPXR	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Lightweight; wireless identification and sensing platform; grouping proof authentication protocol; security; Scyther tool; xorshift; xorshiftR; GPAPXR	SECURITY; FAMILY	Radio frequency identification (RFID) tags that meet EPC Gen2 standards are used in many fields such as supply chain operations. The number of the RFID tags, smart cards, wireless sensor nodes, and Internet of things devices is increasing day by day and the areas where they are used are expanding. These devices are very limited in terms of the resources they have. For this reason, many security mechanisms developed for existing computer systems cannot be used for these devices. In order to ensure secure communication, it is necessary to provide authentication process between these lightweight devices and the devices they communicate. The authentication process is the first step that allows the parties to trust each other for communication. Moreover, the authentication protocol should allow simultaneous verification of multiple lightweight devices. Therefore, grouping proof authentication protocol is required. In this study, a new grouping proof authentication protocol is developed for lightweight devices. The proposed protocol implemented on wireless identification and sensing platform passive RFID tag, uses embedded advanced encryption standard encryption method to encrypt transmitted data. Security of the protocol was first evaluated and verified theoretically, then by a tool used for automatic verification of security protocols, called Scyther tool.																	1300-0632	1303-6203					2020	28	5					3036	3051		10.3906/elk-2004-5													
J								Exhaustive hard triplet mining loss for Person Re-Identification	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Person reidentification; triplet loss; hard triplet mining		Person reidentification (Re-ID) is an important task in computer vision and has many applications in video-based surveillance. Recently, the triplet loss has been popular in the deep learning framework for person Re-ID. It is particularly important to note that the selection of hard triplets has significant influence on the performance of the learned deep model. However, the existing triplet losses only focus on some specific forms of hard triplets, thus leading to weaker generalization capability. To address this issue, we propose a novel variant of the triplet loss, named exhaustive hard triplet mining loss (EHTM), which is able to deal with various forms of hard triplets in a comprehensive manner. Moreover, the proposed loss comprises a term to facilitate distinguishing different identities by directly narrowing intraclass distances and indirectly enlarging interclass distances. We also provide an effective training strategy to further enhance model performance. Extensive experiments on several benchmark datasets show that our method outperforms state-of-the-art approaches by a large margin.																	1300-0632	1303-6203					2020	28	5					3052	3067		10.3906/elk-1910-91													
J								Performance optimisation of a sensing chamber using fluid dynamics simulation for electronic nose applications	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Electronic nose; computational fluid dynamics; sensor chamber; baffle; numerical modelling	DISCRIMINATION; SENSORS	The sensor chamber plays a significant role in order to improve the performance of an electronic nose in terms of stability, repeatability, reproducibility, and sensitivity. Fluid dynamics simulations of six different configurations of 3D sensing chambers are presented to facilitate the efficient design of an electronic nose system comprising 64 sensor arrays. Numerical simulations were carried out to investigate the gas (zero air) flow behaviour inside these chambers under steady-state conditions for velocities ranging from 0.1 to 2 m/s using ANSYS software. Design optimisation was performed in terms of area coverage, velocity, and mass fraction. The results show that the area coverage and mass fraction distribution increase with flow velocity. The sensor chambers achieved more than 70% flow coverage over the sensors at a velocity beyond 0.7 m/s. In further chamber designs, four baffles were introduced at different positions in a two inlet and one outlet chamber model to enhance the performance of the chamber. The effect of baffle positions in the flow distribution was investigated through numerical simulations. Chamber designs with the introduction of baffles achieved a maximum mass fraction. Thus, the insertion of baffles improved the area coverage and mass fraction. In addition, to show the real-time applicability further simulations were performed in the optimised sensor chamber.																	1300-0632	1303-6203					2020	28	5					3068	3078		10.3906/elk-1903-103													
J								Modeling compaction parameters using support vector and decision tree regression algorithms	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Regression; compaction; soil index parameters; maximum dry unit weight; optimum water content; support vector machine; decision tree	SOIL COMPACTION; GRAINED SOILS	Shortening the periods of compaction tests can be possible by analyzing the data obtained from previous laboratory tests with regression methods. The regression analysis applied to current data reduces the cost of experiments, saves time, and gives estimated outputs. In this study, the MLS-SVR, KB-SVR, and DTR algorithms were employed for the first time for the estimation of soil compaction parameters. The performances of these regression algorithms in estimating maximum dry unit weight (MDD) and optimum water content (OMC) were compared. Furthermore, the soil properties (fine-grained soil, sand, gravel, specific gravity, liquid limit, and plastic limit) were employed as inputs in the study. The data used for the study were supplied from the experimental soil tests from small dams in Nigde, a province in the southern part of Central Anatolia, Turkey. Polynomial-based KB-SVR yielded the best R-values with 0.93 in the prediction of both OMC and MDD. Moreover, in the multioutput estimation model, polynomial and RBF-based KB-SVR methods were successful with 0.98 and 0.99, respectively. Additionally, while the MSE value was 1.33 in the estimation of OMC, this value was 0.04 in the estimation of MDD. Accordingly, MDD was the most successfully estimated parameter in all processes. It was concluded that through the algorithms used in this study, the prediction of soil compaction parameters could be possible without the need for further laboratory tests.																	1300-0632	1303-6203					2020	28	5					3079	3093		10.3906/elk-1905-179													
J								Cascaded Attention Guidance Network for Single Rainy Image Restoration	IEEE TRANSACTIONS ON IMAGE PROCESSING										Rain; Semantics; Task analysis; Uncertainty; Australia; Decoding; Learning systems; Image de-raining; cascaded attention guidance; semantic consistency; where-and-how learning; pyramid learning; uncertainty map	REMOVAL	Restoring a rainy image with raindrops or rainstreaks of varying scales, directions, and densities is an extremely challenging task. Recent approaches attempt to leverage the rain distribution (e.g., location) as prior to generate satisfactory results. However, concatenation of a single distribution map with the rainy image or with intermediate feature maps is too simplistic to fully exploit the advantages of such priors. To further explore this valuable information, an advanced cascaded attention guidance network, dubbed as CAG-Net, is formulated and designed as a three-stage model. In the first stage, a multi-task learning network is constructed for producing the attention map and coarse de-raining results simultaneously. Subsequently, the coarse results and the rain distribution map are concatenated and fed to the second stage for results refinement. In this stage, the attention map generation network from the first stage is used to formulate a novel semantic consistency loss for better detail recovery. In the third stage, a novel pyramidal "where-and-how" learning mechanism is formulated. At each pyramid level, a two-branch network is designed to take the features from previous stages as inputs to generate better attention-guidance features and de-raining features, which are then combined via a gating scheme to produce the final de-raining results. Moreover, the uncertainty maps are also generated in this stage for more accurate pixel-wise loss calculation. Extensive experiments are carried out for removing raindrops or rainstreaks from both synthetic and real rainy images, and CAG-Net is demonstrated to produce significantly better results than state-of-the-art models. Codes are available at <https://github.com/RobinCSIRO/CAGNet>.																	1057-7149	1941-0042					2020	29						9190	9203		10.1109/TIP.2020.3023773													
J								Multiplex Cellular Communities in Multi-Gigapixel Colorectal Cancer Histology Images for Tissue Phenotyping	IEEE TRANSACTIONS ON IMAGE PROCESSING										Cancer; Multiplexing; Feature extraction; Tumors; Biological tissues; Pathology; Cellular community detection; tissue phenotyping; computational pathology; colon cancer	PATHOLOGY; REPRESENTATION; CLASSIFICATION; VALIDATION; STROMA	In computational pathology, automated tissue phenotyping in cancer histology images is a fundamental tool for profiling tumor microenvironments. Current tissue phenotyping methods use features derived from image patches which may not carry biological significance. In this work, we propose a novel multiplex cellular community-based algorithm for tissue phenotyping integrating cell-level features within a graph-based hierarchical framework. We demonstrate that such integration offers better performance compared to prior deep learning and texture-based methods as well as to cellular community based methods using uniplex networks. To this end, we construct cell-level graphs using texture, alpha diversity and multi-resolution deep features. Using these graphs, we compute cellular connectivity features which are then employed for the construction of a patch-level multiplex network. Over this network, we compute multiplex cellular communities using a novel objective function. The proposed objective function computes a low-dimensional subspace from each cellular network and subsequently seeks a common low-dimensional subspace using the Grassmann manifold. We evaluate our proposed algorithm on three publicly available datasets for tissue phenotyping, demonstrating a significant improvement over existing state-of-the-art methods.																	1057-7149	1941-0042					2020	29						9204	9219		10.1109/TIP.2020.3023795													
J								Projective Double Reconstructions Based Dictionary Learning Algorithm for Cross-Domain Recognition	IEEE TRANSACTIONS ON IMAGE PROCESSING										Dictionary learning; label consistency; data reconstruction; cross-domain recognition	LOW-RANK; DISCRIMINATIVE DICTIONARY; SPARSE REPRESENTATION; K-SVD; IMAGE; ADAPTATION	Dictionary learning plays a significant role in the field of machine learning. Existing works mainly focus on learning dictionary from a single domain. In this paper, we propose a novel projective double reconstructions (PDR) based dictionary learning algorithm for cross-domain recognition. Owing the distribution discrepancy between different domains, the label information is hard utilized for improving discriminability of dictionary fully. Thus, we propose a more flexible label consistent term and associate it with each dictionary item, which makes the reconstruction coefficients have more discriminability as much as possible. Due to the intrinsic correlation between cross-domain data, the data should be reconstructed with each other. Based on this consideration, we further propose a projective double reconstructions scheme to guarantee that the learned dictionary has the abilities of data itself reconstruction and data cross-reconstruction. This also guarantees that the data from different domains can be boosted mutually for obtaining a good data alignment, making the learned dictionary have more transferability. We integrate the double reconstructions, label consistency constraint and classifier learning into a unified objective and its solution can be obtained by proposed optimization algorithm that is more efficient than the conventional l(1) optimization based dictionary learning methods. The experiments show that the proposed PDR not only greatly reduces the time complexity for both training and testing, but also outperforms over the state-of-the-art methods.																	1057-7149	1941-0042					2020	29						9220	9233		10.1109/TIP.2020.3024728													
J								Camera Array for Multi-Spectral Imaging	IEEE TRANSACTIONS ON IMAGE PROCESSING										Cameras; Spatial resolution; Wheels; Image color analysis; Sensor arrays; Videos; Multi-spectral imaging; image acquisition	QUALITY ASSESSMENT; ROBUST; DEMOSAICKING; REGISTRATION; MODEL	Recently, many new applications arose for multi-spectral and hyper-spectral imaging. Besides modern biometric systems for identity verification, also agricultural and medical applications came up, which measure the health condition of plants and humans. Despite the growing demand, the acquisition of multi-spectral data is up to the present complicated. Often, expensive, inflexible, or low resolution acquisition setups are only obtainable for specific professional applications. To overcome these limitations, a novel camera array for multi-spectral imaging is presented in this article for generating consistent multi-spectral videos. As differing spectral images are acquired at various viewpoints, a geometrically constrained multi-camera sensor layout is introduced, which enables the formulation of novel registration and reconstruction algorithms to globally set up robust models. On average, the novel acquisition approach achieves a gain of 2.5 dB PSNR compared to recently published multi-spectral filter array imaging systems. At the same time, the proposed acquisition system ensures not only a superior spatial, but also a high spectral, and temporal resolution, while filters are flexibly exchangeable by the user depending on the application. Moreover, depth information is generated, so that 3D imaging applications, e.g., for augmented or virtual reality, become possible. The proposed camera array for multi-spectral imaging can be set up using off-the-shelf hardware, which allows for a compact design and employment in, e.g., mobile devices or drones, while being cost-effective.																	1057-7149	1941-0042					2020	29						9234	9249		10.1109/TIP.2020.3024738													
J								Sequential Dual Attention Network for Rain Streak Removal in a Single Image	IEEE TRANSACTIONS ON IMAGE PROCESSING										Rain; Feature extraction; Machine learning; Visualization; Convolution; Dictionaries; Snow; Single image rain streaks removal; deraining; dual attention network; dilated convolution; deep learning	DECOMPOSITION	Various weather conditions, such as rain, haze, or snow, can degrade visual quality in images/videos, which may significantly degrade the performance of related applications. In this paper, a novel framework based on sequential dual attention deep network is proposed for removing rain streaks (deraining) in a single image, called by SSDRNet (Sequential dual attention-based Single image DeRaining deep Network). Since the inherent correlation among rain steaks within an image should be stronger than that between the rain streaks and the background (non-rain) pixels, a two-stage learning strategy is implemented to better capture the distribution of rain streaks within a rainy image. The two-stage deep neural network primarily involves three blocks: residual dense blocks (RDBs), sequential dual attention blocks (SDABs), and multi-scale feature aggregation modules (MAMs), which are all delicately and specifically designed for rain removal. The two-stage strategy successfully learns very fine details of the rain steaks of the image and then clearly removes them. Extensive experimental results have shown that the proposed deep framework achieves the best performance on qualitative and quantitative metrics compared with state-of-the-art methods. The corresponding code and the trained model of the proposed SSDRNet have been available online at https://github.com/fityanul/SDAN-for-Rain-Removal.																	1057-7149	1941-0042					2020	29						9250	9265		10.1109/TIP.2020.3025402													
J								On Aggregation of Unsupervised Deep Binary Descriptor With Weak Bits	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image hashing; feature matching; local binary descriptor; similarity retrieval; deep learning	IMAGE; QUANTIZATION; ROBUST	Despite the thrilling success achieved by existing binary descriptors, most of them are still in the mire of three limitations: 1) vulnerable to the geometric transformations; 2) incapable of preserving the manifold structure when learning binary codes; 3) NO guarantee to find the true match if multiple candidates happen to have the same Hamming distance to a given query. All these together make the binary descriptor less effective, given large-scale visual recognition tasks. In this paper, we propose a novel learning-based feature descriptor, namely Unsupervised Deep Binary Descriptor (UDBD), which learns transformation invariant binary descriptors via projecting the original data and their transformed sets into a joint binary space. Moreover, we involve a l(2,1)-norm loss term in the binary embedding process to gain simultaneously the robustness against data noises and less probability of mistakenly flipping bits of the binary descriptor, on top of it, a graph constraint is used to preserve the original manifold structure in the binary space. Furthermore, a weak bit mechanism is adopted to find the real match from candidates sharing the same minimum Hamming distance, thus enhancing matching performance. Extensive experimental results on public datasets show the superiority of UDBD in terms of matching and retrieval accuracy over state-of-the-arts.																	1057-7149	1941-0042					2020	29						9266	9278		10.1109/TIP.2020.3025437													
J								Domain-Translated 3D Object Pose Estimation	IEEE TRANSACTIONS ON IMAGE PROCESSING										Three-dimensional displays; Pose estimation; Feature extraction; Training; Task analysis; Two dimensional displays; Training data; 3D object pose estimation; image-to-image translation; domain-translated; synthetic data		Synthetic 3D object models have been proven crucial in object pose estimation, as they are utilized to generate a huge number of accurately annotated data. The object pose estimation problem is usually solved for images originating from the real data domain by employing synthetic images for training data enrichment, without fully exploiting the fact that synthetic and real images may have different data distributions. In this work, we argue that 3D object pose estimation problem is easier to solve for images originating from the synthetic domain, rather than the real data domain. To this end, we propose a 3D object pose estimation framework consisting of a two-step process, where a novel pose-oriented image-to-image translation step is first employed to translate noisy real images to clean synthetic ones and then, a 3D object pose estimation method is applied on the translated synthetic images to finally predict the 3D object poses. A novel pose-oriented objective function is employed for training the image-to-image translation network, which enforces that pose-related object image characteristics are preserved in the translated images. As a result, the pose estimation network does not require real data for training purposes. Experimental evaluation has shown that the proposed framework greatly improves the 3D object pose estimation performance, when compared to state-of-the-art methods.																	1057-7149	1941-0042					2020	29						9279	9291		10.1109/TIP.2020.3025447													
J								Image Coding With Data-Driven Transforms: Methodology, Performance and Potential	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image coding; Transform coding; Kernel; Quantization (signal); Discrete cosine transforms; Dictionaries; Image compression; Karhunen-Loeve transform (KLT); principal component analysis (PCA); data-driven transform; rate-distortion optimization; adaptive quantization	DISCRETE COSINE; COMPRESSION; ALGORITHM	Image compression has always been an important topic in the last decades due to the explosive increase of images. The popular image compression formats are based on different transforms which convert images from the spatial domain into compact frequency domain to remove the spatial correlation. In this paper, we focus on the exploration of data-driven transform, Karhunen-Loeve transform (KLT), the kernels of which are derived from specific images via Principal Component Analysis (PCA), and design a high efficient KLT based image compression algorithm with variable transform sizes. To explore the optimal compression performance, the multiple transform sizes and categories are utilized and determined adaptively according to their rate-distortion (RD) costs. Moreover, comprehensive analyses on the transform coefficients are provided and a band-adaptive quantization scheme is proposed based on the coefficient RD performance. Extensive experiments are performed on several class-specific images as well as general images, and the proposed method achieves significant coding gain over the popular image compression standards including JPEG, JPEG 2000, and the state-of-the-art dictionary learning based methods.																	1057-7149	1941-0042					2020	29						9292	9304		10.1109/TIP.2020.3025203													
J								Online Alternate Generator Against Adversarial Attacks	IEEE TRANSACTIONS ON IMAGE PROCESSING										Generators; Training; Perturbation methods; Knowledge engineering; Convolutional neural networks; Deep learning; Computational modeling; Deep neural network; adversarial attack; image classification		The field of computer vision has witnessed phenomenal progress in recent years partially due to the development of deep convolutional neural networks. However, deep learning models are notoriously sensitive to adversarial examples which are synthesized by adding quasi-perceptible noises on real images. Some existing defense methods require to re-train attacked target networks and augment the train set via known adversarial attacks, which is inefficient and might be unpromising with unknown attack types. To overcome the above issues, we propose a portable defense method, online alternate generator, which does not need to access or modify the parameters of the target networks. The proposed method works by online synthesizing another image from scratch for an input image, instead of removing or destroying adversarial noises. To avoid pretrained parameters exploited by attackers, we alternately update the generator and the synthesized image at the inference stage. Experimental results demonstrate that the proposed defensive scheme and method outperforms a series of state-of-the-art defending models against gray-box adversarial attacks.																	1057-7149	1941-0042					2020	29						9305	9315		10.1109/TIP.2020.3025404													
J								Noisy-as-Clean: Learning Self-Supervised Denoising From Corrupted Image	IEEE TRANSACTIONS ON IMAGE PROCESSING										Noise measurement; Noise reduction; Training; Image denoising; AWGN; Benchmark testing; Electronics packaging; Image denoising; self-supervision; convolutional neural network	SPARSE	Supervised deep networks have achieved promising performance on image denoising, by learning image priors and noise statistics on plenty pairs of noisy and clean images. Unsupervised denoising networks are trained with only noisy images. However, for an unseen corrupted image, both supervised and unsupervised networks ignore either its particular image prior, the noise statistics, or both. That is, the networks learned from external images inherently suffer from a domain gap problem: the image priors and noise statistics are very different between the training and test images. This problem becomes more clear when dealing with the signal dependent realistic noise. To circumvent this problem, in this work, we propose a novel "Noisy-As-Clean" (NAC) strategy of training self-supervised denoising networks. Specifically, the corrupted test image is directly taken as the "clean" target, while the inputs are synthetic images consisted of this corrupted image and a second yet similar corruption. A simple but useful observation on our NAC is: as long as the noise is weak, it is feasible to learn a self-supervised network only with the corrupted image, approximating the optimal parameters of a supervised network learned with pairs of noisy and clean images. Experiments on synthetic and realistic noise removal demonstrate that, the DnCNN and ResNet networks trained with our self-supervised NAC strategy achieve comparable or better performance than the original ones and previous supervised/unsupervised/self-supervised networks. The code is publicly available at https://github.com/csjunxu/Noisy-As-Clean.																	1057-7149	1941-0042					2020	29						9316	9329		10.1109/TIP.2020.3026622													
J								Graph-Based Transforms for Video Coding	IEEE TRANSACTIONS ON IMAGE PROCESSING										Transforms; Image coding; Laplace equations; Image edge detection; Covariance matrices; Symmetric matrices; Video coding; Transform coding; predictive coding; graph-based transforms; video coding; compression; optimization; statistical modeling	FOURIER-TRANSFORM; INTRA-PREDICTION; COMPRESSION; IMAGE	In many state-of-the-art compression systems, signal transformation is an integral part of the encoding and decoding process, where transforms provide compact representations for the signals of interest. This paper introduces a class of transforms called graph-based transforms (GBTs) for video compression, and proposes two different techniques to design GBTs. In the first technique, we formulate an optimization problem to learn graphs from data and provide solutions for optimal separable and nonseparable GBT designs, called GL-GBTs. The optimality of the proposed GL-GBTs is also theoretically analyzed based on Gaussian-Markov random field (GMRF) models for intra and inter predicted block signals. The second technique develops edge-adaptive GBTs (EA-GBTs) in order to flexibly adapt transforms to block signals with image edges (discontinuities). The advantages of EA-GBTs are both theoretically and empirically demonstrated. Our experimental results show that the proposed transforms can significantly outperform the traditional Karhunen-Loeve transform (KLT).																	1057-7149	1941-0042					2020	29						9330	9344		10.1109/TIP.2020.3026627													
J								Understanding of Curved Corridor Scenes Based on Projection of Spatial Right-Angles	IEEE TRANSACTIONS ON IMAGE PROCESSING										Three-dimensional displays; Layout; Navigation; Cameras; Mobile robots; Robot vision systems; Curved corridor scene; non-Manhattan structure; Manhattan; spatial right angle; monocular vision	SINGLE IMAGE; 3D RECONSTRUCTION; APPEARANCE	Helping mobile robots understand curved corridor scenes has considerable value in computer vision. However, due to the diversity of curved corridor scenes, such as curved structures that do not satisfy Manhattan assumption, understanding them remains a challenge. Curved non-Manhattan structures can be seen as compositions of spatial right angles projected into two dimensional projections, which may help us estimate their original posture in 3D scenes. In this paper, we presented an approach for mobile robots to understand curved corridor scenes including Manhattan and curved non-Manhattan structures, from a single image. Angle projections can be assigned to different clusters via geometric inference. Then coplanar structures can be estimated. Fold structures consisting of coplanar structures can be estimated, and curved non-Manhattan structures can be approximately represented by fold structures. Based on understanding curved non-Manhattan structures, the method is practical and efficient for a navigating mobile robot in curved corridor scenes. The algorithm requires no prior training or knowledge of the camera's internal parameters. With geometric features from a monocular camera, the method is robust to calibration errors and image noise. We compared the estimated curved layout against the ground truth and measured the percentage of pixels that were incorrectly classified. The experimental results showed that the algorithm can successfully understand curved corridor scenes including both Manhattan and curved non-Manhattan structures, meeting the requirements of robot navigation in a curved corridor environment.																	1057-7149	1941-0042					2020	29						9345	9359		10.1109/TIP.2020.3026628													
J								Iterative Local-Global Collaboration Learning Towards One-Shot Video Person Re-Identification	IEEE TRANSACTIONS ON IMAGE PROCESSING										One-shot learning; video person re-identification; variational information bottleneck; local-global label propagation; dynamic sample selection		Video person re-identification (video Re-ID) plays an important role in surveillance video analysis and has gained increasing attention recently. However, existing supervised methods require vast labeled identities across cameras. Although some unsupervised approaches have been exploited for video Re-ID, they are still in their infancy due to the complex nature of learning discriminative features on unlabelled data. In this article, we focus on one-shot video Re-ID and present an iterative local-global collaboration learning approach to learn robust and discriminative person representations. Specifically, it jointly considers the global video information and local frame sequence information to better capture the diverse appearance of the person for feature learning and pseudo-label estimation. Moreover, as the cross-entropy loss may induce the model to focus on identity-irrelevant factors, we introduce the variational information bottleneck as a regularization term to train the model together. It can help filter undesirable information and characterize subtle differences among persons. Since accuracy cannot always be guaranteed for pseudo-labels, we adopt a dynamic selection strategy to select part of pseudo-labeled data with higher confidence to update the training set and re-train the learning model. During training, our method iteratively executes the feature learning, pseudo-label estimation, and dynamic sample selection until all the unlabeled data have been seen. Extensive experiments on two public datasets, i.e., DukeMTMC-VideoReID and MARS, have verified the superiority of our model to several cutting-edge competitors.																	1057-7149	1941-0042					2020	29						9360	9372		10.1109/TIP.2020.3026625													
J								Tiny Obstacle Discovery by Occlusion-Aware Multilayer Regression	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image edge detection; Proposals; Nonhomogeneous media; Roads; Cameras; Three-dimensional displays; Training; Obstacle discovery; occlusion edge; object proposal; obstacle-aware; regression	EDGE-DETECTION; HOMOGRAPHY	Edges are the fundamental visual element for discovering tiny obstacles using a monocular camera. Nevertheless, tiny obstacles often have weak and inconsistent edge cues due to various properties such as small size and similar appearance to the free space, making it hard to capture them. To this end, we propose an occlusion-based multilayer approach, which specifies the scene prior as multilayer regions and utilizes these regions in each obstacle discovery module, i.e., edge detection and proposal extraction. Firstly, an obstacle-aware occlusion edge is generated to accurately capture the obstacle contour by fusing the edge cues inside all the multilayer regions, which intensifies the object characteristics of these obstacles. Then, a multistride sliding window strategy is proposed for capturing proposals that enclose the tiny obstacles as completely as possible. Moreover, a novel obstacle-aware regression model is proposed for effectively discovering obstacles. It is formed by a primary-secondary regressor, which can learn two dissimilarities between obstacles and other categories separately, and eventually generate an obstacle-occupied probability map. The experiments are conducted on two datasets to demonstrate the effectiveness of our approach under different scenarios. And the results show that the proposed method can approximately improve accuracy by 19% over FPHT and PHT, and achieves comparable performance to MergeNet. Furthermore, multiple experiments with different variants validate the contribution of our method. The source code is available at https://github.com/XuefengBUPT/TOD_OMR																	1057-7149	1941-0042					2020	29						9373	9386		10.1109/TIP.2020.3026636													
J								Harmonic effects optimization at a system level using a harmonic power flow controller	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES										Current harmonic flow; harmonic power flow controller; harmonic voltage control; minimum apparant power injection; zero active power injection	FILTER	Increase of nonlinear loads in industries has resulted in high levels of harmonic currents and consequently harmonic voltages in power networks. Harmonics have several negative effects such as higher energy losses and equipment life reduction. To reduce the levels of harmonics in power networks, different methods of harmonic suppression have been employed. The basic idea in all of these methods is to prevent harmonics from flowing into a power network at customer sides and the point of common coupling (PCC). Due to the costs, none of the existing mitigating methods result in a harmonic-free power system. The remaining harmonic currents, which rotate in a power network according to the system impedances, may not necessarily result in an optimum harmonic power flow in terms of harmonic undesirable results such as harmonic losses or harmonic over voltage/current due to possible resonances. This paper proposes a new method to control the flow of the remaining harmonics at a power system level such that the effects of harmonics such as losses are optimized. This task is achieved by the use of series active power filters controlled in a different manner from their conventional methods. In this new application, the series active power injects a controlled harmonic voltage into a power system (e.g., a line, transformer, or other elements) to control the harmonic current (power) flow such that the overall performance of the power system is improved in terms of harmonic effects. The series active power filter in this new application is named as harmonic power flow controller (HPFC). In this paper, the theory, structure, applications, and the basics of the control method of a HPFC are described. To investigate the effects of the HPFC on the power network harmonics, an HPFC is used in the 14-busbar IEEE test system. To make the proposal more practical, an HPFC is designed for Iran north-west transmission system to alleviate the harmonic problem in this region. Simulations are carried out to show the effectiveness of the HPFC. Simulation results show that the HPFC can control the harmonic currents (power) and voltage consequently. In this paper, several control algorithms for an HPFC are also considered to achieve the desired harmonic voltages levels.																	1300-0632	1303-6203					2020	28	5					2586	2601		10.3906/elk-1811-176													
B								Interpretable artificial intelligence: Closing the adoption gap in healthcare	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											NEURAL-NETWORKS; DEEP; ALGORITHM; SUPPORT																				978-0-12-817338-1; 978-0-12-817133-2				2020							3	29		10.1016/B978-0-12-817133-2.00001-X													
B								Artificial intelligence methods in computer-aided diagnostic tools and decision support analytics for clinical informatics	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											GENETIC ALGORITHM; AUTOMATIC DETECTION; CLASSIFICATION; OPTIMIZATION; EXPRESSION; PREDICTION; PNEUMONIA; FRAMEWORK; MACHINE; HINGE																				978-0-12-817338-1; 978-0-12-817133-2				2020							31	59		10.1016/B978-0-12-817133-2.00002-1													
B								Deep learning in precision medicine	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											MODEL																				978-0-12-817338-1; 978-0-12-817133-2				2020							61	90		10.1016/B978-0-12-817133-2.00003-3													
B								Machine learning systems and precision medicine: A conceptual and experimental approach to single individual statistics	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS																															978-0-12-817338-1; 978-0-12-817133-2				2020							91	119		10.1016/B978-0-12-817133-2.00004-5													
B								Machine learning in digital health, recent trends, and ongoing challenges	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											SELF-ASSESSED AFFECT; ARTIFICIAL-INTELLIGENCE; CLASSIFICATION; SIGNALS; TUTORIAL; EMOTION																				978-0-12-817338-1; 978-0-12-817133-2				2020							121	148		10.1016/B978-0-12-817133-2.00005-7													
B								Data mining to transform clinical and translational research findings into precision health	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											INTEGRATING BIOLOGY; RISK PREDICTION; ECONOMIC BURDEN; LYNCH SYNDROME; GENOME; CANCER; VICTIMIZATION; INFORMATICS; EXPERIENCES; STATEMENT																				978-0-12-817338-1; 978-0-12-817133-2				2020							149	173		10.1016/B978-0-12-817133-2.00006-9													
B								Predictive models in precision medicine	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											ARTIFICIAL-INTELLIGENCE; EXPERT-SYSTEM; DISEASE; DIAGNOSIS; CANCER																				978-0-12-817338-1; 978-0-12-817133-2				2020							177	188		10.1016/B978-0-12-817133-2.00007-0													
B								Deep neural networks for phenotype prediction in rare diseases Inclusion body myositis: A case study	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											CLASSIFICATION; RISK																				978-0-12-817338-1; 978-0-12-817133-2				2020							189	202		10.1016/B978-0-12-817133-2.00008-2													
B								Artificial intelligence for management of patients with intracranial neoplasms	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											CENTRAL-NERVOUS-SYSTEM; NEWLY-DIAGNOSED GLIOBLASTOMA; VIRTUAL-REALITY SIMULATION; BRAIN-TUMOR SEGMENTATION; MGMT METHYLATION STATUS; BIG DATA; RAMAN-SPECTROSCOPY; DECISION-SUPPORT; GRADE GLIOMAS; MRI																				978-0-12-817338-1; 978-0-12-817133-2				2020							203	230		10.1016/B978-0-12-817133-2.00009-4													
B								Artificial intelligence to aid the detection of mood disorders	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											HEART-RATE-VARIABILITY; BIPOLAR DISORDER; NEURAL-NETWORKS; SOCIAL RHYTHMS; DEPRESSION; HEALTH; SPACE																				978-0-12-817338-1; 978-0-12-817133-2				2020							231	255		10.1016/B978-0-12-817133-2.00010-0													
B								Use of artificial intelligence in Alzheimer's disease detection	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											STRUCTURAL MRI; FEATURE-SELECTION; BRAIN IMAGES; FDG-PET; CLASSIFICATION; DIAGNOSIS; MCI; REPRESENTATION; PERFORMANCE; FUSION																				978-0-12-817338-1; 978-0-12-817133-2				2020							257	278		10.1016/B978-0-12-817133-2.00011-2													
B								Artificial intelligence to predict atheroma plaque vulnerability	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											SUPPORT VECTOR MACHINES; FIBROUS CAP THICKNESS; INTRAVASCULAR ULTRASOUND; ATHEROSCLEROTIC PLAQUES; CIRCUMFERENTIAL STRESS; NEURAL-NETWORKS; CORONARY ATHEROSCLEROSIS; MECHANICAL-PROPERTIES; STRUCTURAL-ANALYSIS; TISSUE-COMPONENTS																				978-0-12-817338-1; 978-0-12-817133-2				2020							279	312		10.1016/B978-0-12-817133-2.00012-4													
B								Artificial intelligence in cardiovascular medicine: Applications in the diagnosis of infarction and prognosis of heart failure	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											ACUTE MYOCARDIAL-INFARCTION; IN-HOSPITAL MORTALITY; ACUTE CORONARY SYNDROME; NEURAL-NETWORK; CHEST-PAIN; CLASSIFICATION TREE; DECISION-SUPPORT; HEALTH-CARE; RISK; ECG																				978-0-12-817338-1; 978-0-12-817133-2				2020							313	328		10.1016/B978-0-12-817133-2.00013-6													
B								Artificial intelligence-based decision support systems for diabetes	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											SUBCUTANEOUS INSULIN INFUSION; CLOSED-LOOP CONTROL; ADVANCED BOLUS CALCULATOR; NOCTURNAL HYPOGLYCEMIA; PHYSICAL-ACTIVITY; GLUCOSE CONTROL; PUMP THERAPY; IN-SILICO; TYPE-1; MELLITUS																				978-0-12-817338-1; 978-0-12-817133-2				2020							329	357		10.1016/B978-0-12-817133-2.00014-8													
B								Clinical decision support systems to improve the diagnosis and management of respiratory diseases	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											MACHINE LEARNING ALGORITHMS; FORCED OSCILLATION MEASUREMENTS; PULMONARY-FUNCTION TEST; NEURAL-NETWORKS; AIRWAY-OBSTRUCTION; CLASSIFICATION; PREDICTION; MECHANICS; ASTHMA; FLOW																				978-0-12-817338-1; 978-0-12-817133-2				2020							359	391		10.1016/B978-0-12-817133-2.00015-X													
B								Artificial intelligence in neuro, head, and neck surgery	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											HEARING-AID; NETWORK; FEATURES; GLIOMAS; SYSTEM; MODEL																				978-0-12-817338-1; 978-0-12-817133-2				2020							393	404		10.1016/B978-0-12-817133-2.00016-1													
B								Use of artificial intelligence in emergency medicine	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											BIG DATA; PREDICTION; SEPSIS; TRIAGE																				978-0-12-817338-1; 978-0-12-817133-2				2020							405	413		10.1016/B978-0-12-817133-2.00017-3													
B								Use of artificial intelligence in infectious diseases	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											NEURAL-NETWORK; TUBERCULOSIS; PREDICTION; RESISTANCE; SYSTEM; MODEL; DIAGNOSIS; ONTOLOGY; BEHAVIOR; BIOLOGY																				978-0-12-817338-1; 978-0-12-817133-2				2020							415	438		10.1016/B978-0-12-817133-2.00018-5													
B								Artificial intelligence techniques applied to patient care and monitoring	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											HEALTH PARADIGM; SMART HEALTH; BIG DATA; REHABILITATION; SYSTEM; TRENDS																				978-0-12-817338-1; 978-0-12-817133-2				2020							439	464		10.1016/B978-0-12-817133-2.00019-7													
B								Use of artificial intelligence in precision nutrition and fitness	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											HEALTH-CARE; COMPUTATIONAL INTELLIGENCE; PHYSICAL-ACTIVITY; PERSONALIZED NUTRITION; MOBILE APPLICATIONS; QUALITY; REHABILITATION; ACHIEVEMENTS; GAMIFICATION; ALGORITHMS																				978-0-12-817338-1; 978-0-12-817133-2				2020							465	496		10.1016/B978-0-12-817133-2.00020-3													
B								Artificial intelligence in precision health: Systems in practice	ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS											IMMUNE RECOGNITION SYSTEM; MEDICAL DIAGNOSIS; MACHINE; CLASSIFICATION; TUBERCULOSIS; SUPPORT																				978-0-12-817338-1; 978-0-12-817133-2				2020							499	519		10.1016/B978-0-12-817133-2.00021-5													
J								On the integration of symbolic and sub-symbolic techniques for XAI: A survey	INTELLIGENZA ARTIFICIALE										XAI; symbolic and sub-symbolic AI; explainability; interpretability; trustable system	NEURAL-NETWORKS; RULE EXTRACTION; CLASSIFICATION; SUPPORT	The more intelligent systems based on sub-symbolic techniques pervade our everyday lives, the less human can understand them. This is why symbolic approaches are getting more and more attention in the general effort to make AI interpretable, explainable, and trustable. Understanding the current state of the art of AI techniques integrating symbolic and sub-symbolic approaches is then of paramount importance, nowadays-in particular in the XAI perspective. This is why this paper provides an overview of the main symbolic/sub-symbolic integration techniques, focussing in particular on those targeting explainable AI systems.																	1724-8035	2211-0097					2020	14	1					7	32		10.3233/IA-190036													
J								Using local trust measures to form agent CoT groups	INTELLIGENZA ARTIFICIALE										Cloud of things; internet of things; multiagent system; reputation; trust; voting	CLOUD; REPUTATION; INTERNET; INTEGRATION; ISSUES; THINGS	IoT devices dealing with complex tasks usually require powerful hardware capabilities or, as a possible alternative, to get on the Cloud those resources they need. When an IoT device is "virtualized" on the Cloud, it can take benefit from relying on one or more software agents and their social skills to mutually interact and cooperate. In particular, in a Cloud of Things scenario, where agents cooperate to perform complex tasks, the choice of a partner is a sensitive question. In such a context, when an agent is not capable to perform a reliable choice then, like real social communities, it can ask information to other agents it considers as trustworthy. In order to support agents in their partner choices, we conceived a local trust model, based on reliability and reputation measures coming from its ego-network, adopted to partition the agents in groups by exploiting trust relationships to allow agents to be associated with the most reliable partners. To this aim, we designed an algorithm to form agent groups by exploiting available local trust measures and the results obtained in a simulated scenario confirmed the potential advantages of this approach.																	1724-8035	2211-0097					2020	14	1					33	44		10.3233/IA-190039													
J								Trust and autonomy for regulating the users' acceptance of IoT technologies	INTELLIGENZA ARTIFICIALE										Trust; Internet of Things; autonomy	INTERNET; AGENT; THINGS; AUTOMATION; SECURITY	The success of IoT technologies is undeniable. They are entering more and more in our lives, carrying out increasingly complex tasks. However, there are still a few problems we need to face and solve. For instance, it is not given that the users will be prepared to afford all the automation that IoT devices will offer or that it will be compatible with the users' cognitive attitudes and its actual and real goals. Within this work, we start analyzing which reasons undermine the acceptance of IoT systems and then we propose a possible solution, tanking into account not just the user-device interaction, but also how this affects the device-device interaction. Since the complexity of the tasks the user asks may require the cooperation of some devices to be realized, the regulation of this relationship represents a necessary step for this technology. The first contribution of this work is the level characterization of the autonomy a user can grant to an IoT device. The second contribution is a theoretical model to deal with users and to stimulate users' acceptance, taking also into account a possible, collaborative organizational structure, to manage the creation of groups and the partners' selection process.																	1724-8035	2211-0097					2020	14	1					45	58		10.3233/IA-190041													
J								Interval arithmetic to support effective indoor positioning of software agents	INTELLIGENZA ARTIFICIALE										Localization as optimization; indoor localization; software agents	LOCALIZATION; ALGORITHMS; TDOA	The provision of advanced location-based services in indoor environments is based on the possibility of estimating the positions of mobile devices with sufficient accuracy and robustness. An algorithm to allow a software agent hosted on a mobile device to estimate the position of its device in a known indoor environment is proposed under the ordinary assumption that fixed beacons are installed in the environment at known locations. Rather than making use of geometric considerations to estimate the position of the device, the proposed algorithm first transforms the localization problem into a related optimization problem, which is then solved by means of interval arithmetic to provide the agent with accurate and robust position estimates. The adopted approach solves a major problem that severely limits the accuracy of the position estimates that ordinary geometric algorithms provide when the beacons are positioned to maximize line-of-sight coverage. Experimental results confirm that the proposed algorithm provides position estimates that are independent of the positions of the beacons, and they show that the algorithm outperforms a well-known geometric algorithm.																	1724-8035	2211-0097					2020	14	1					59	73		10.3233/IA-190042													
J								Eliciting cities points of interest from people movements and suggesting effective itineraries	INTELLIGENZA ARTIFICIALE										Clustering; geospatial clustering; GPS coordinates; recommendation systems; IoT; tourism	RECOMMENDATION; SYSTEMS	When a person visits an unknown large city having multiple interesting locations, it is not so easy for him to find one location that is lively and convenient to visit in a given time-frame. To overcome such a problem, this paper proposes to make use of two technologies: smartphones, equipped with sensors for reading GPS coordinates; and multi-agent systems, providing assistance to users and gathering collective knowledge. Data collected by means of devices are analysed and organised in such a way to find locations that could be of immediate interest to people. Proposed agents gather opinions from several users, in terms of scores quantifying the level of satisfaction on visiting some place on a given time-frame. While gathering such an opinion, a solution is put into place to preserve user privacy (his location). Suggestions are made to potentially interested users by selecting for them locations according to closeness and satisfaction scores. In this approach, interesting locations emerge from the analysis of data gathered, hence scores and suggestions can be available for any large city in any place, provided that enough people hand data to the system. Moreover, such places are found dynamically according to people behaviour and preferences.																	1724-8035	2211-0097					2020	14	1					75	87		10.3233/IA-190040													
J								A reputation-based framework to support dynamic car-pooling	INTELLIGENZA ARTIFICIALE										Car-pooling; multi-agent system; recommender system; reputation system; routing algorithm	RECOMMENDER SYSTEMS; MANAGEMENT; CONGESTION; RIDE	In the last decades, individual urban traffic flows have increased all over the world with a consequent growth of road congestion and environmental pollution. In this context, car-pooling is an interesting car-based alternative to satisfy the individual mobility demand by optimizing the car loading factor with respect to the number of passengers, provided that all the participants share trip origin and destination in the same time slot. To make the system more appealing, this paper proposes an on-demand car-pooling service adopting variable fares, on the basis of trip length and number of participants. Multi-agent, reputation and recommender system technologies in synergy with a routing algorithm have been used to this aim. Experiments on simulated data proved the potentiality of the proposed approach.																	1724-8035	2211-0097					2020	14	1					89	102		10.3233/IA-190037													
J								ActorNode2Vec: An Actor-based solution for Node Embedding over large networks	INTELLIGENZA ARTIFICIALE										Network science; embedding; node embedding; Node2vec; actodes; distributed systems; data mining; complex systems; actor model		The application of Machine Learning techniques over networks, such as prediction tasks over nodes and edges, is becoming often crucial in the analysis of Complex systems in a wide range of research fields. One of the enabling technologies in that sense is represented by Node Embedding, which enables us to learn features automatically over the network. Among the different approaches proposed in the literature, the most promising are DeepWalk and Node2Vec, where the embedding is computed by combining random walks and neural language models. However, characteristic limitations with these techniques are related to memory requirements and time complexity. In this paper, we propose a distributed and scalable solution, named ActorNode2vec, that keeps the best advantages of Node2Vec and overcomes the limitations with the adoption of the actor model to distribute the computational load. We demonstrate the efficacy of this approach with a large network by analyzing the sensitivity of walk length and number of walks parameters and make a comparison also with Deep walk and an Apache Spark distributed implementation of Node2Vec. Results show that with ActorNode2vec computational times are drastically reduced without losing embedding quality and overcoming memory issues.																	1724-8035	2211-0097					2020	14	1					103	114		10.3233/IA-190038													
J								On the use of the policy gradient and Hessian in inverse reinforcement learning	INTELLIGENZA ARTIFICIALE										Reinforcement learning; inverse reinforcement learning; policy gradient; feature extraction	NUMERICAL OPTIMIZATION	Reinforcement Learning (RL) is an effective approach to solve sequential decision making problems when the environment is equipped with a reward function to evaluate the agent's actions. However, there are several domains in which a reward function is not available and difficult to estimate. When samples of expert agents are available, Inverse Reinforcement Learning (IRL) allows recovering a reward function that explains the demonstrated behavior. Most of the classic IRL methods, in addition to expert's demonstrations, require sampling the environment to evaluate each reward function, that, in turn, is built starting from a set of engineered features. This paper is about a novel model-free IRL approach that does not require to specify a function space where to search for the expert's reward function. Leveraging on the fact that the policy gradient needs to be zero for an optimal policy, the algorithm generates an approximation space for the reward function, in which a reward is singled out employing a second-order criterion. After introducing our approach for finite domains, we extend it to continuous ones. The empirical results, on both finite and continuous domains, show that the reward function recovered by our algorithm allows learning policies that outperform those obtained with the true reward function, in terms of learning speed.																	1724-8035	2211-0097					2020	14	1					117	150		10.3233/IA-180011													
J								Learning fair models and representations	INTELLIGENZA ARTIFICIALE										Algorithmic fairness; fair models; fair representation	DISCRIMINATION; RISK; CLASSIFICATION; PREDICTION; BOUNDS; RATES; BIAS	Machine learning based systems and products are reaching society at large in many aspects of everyday life, including financial lending, online advertising, pretrial and immigration detention, child maltreatment screening, health care, social services, and education. This phenomenon has been accompanied by an increase in concern about the ethical issues that may rise from the adoption of these technologies. In response to this concern, a new area of machine learning has recently emerged that studies how to address disparate treatment caused by algorithmic errors and bias in the data. The central question is how to ensure that the learned model does not treat subgroups in the population unfairly. While the design of solutions to this issue requires an interdisciplinary effort, fundamental progress can only be achieved through a radical change in the machine learning paradigm. In this work, we will describe the state of the art on algorithmic fairness using statistical learning theory, machine learning, and deep learning approaches that are able to learn fair models and data representation.																	1724-8035	2211-0097					2020	14	1					151	178		10.3233/IA-190034													
J								Time-to-contact control: improving safety and reliability of autonomous vehicles	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										autonomous vehicles; time to contact; TTC; danger detection; machine vision; Android smartphones	TRAFFIC DYNAMICS; STABILITY	Under traditional car-following control, i.e., human drivers' behaviour, the stability condition of traffic system isnotsatisfied in general. For safety and reliability of autonomous vehicles, additional danger warning system must be used in the adaptive cruise control system to prevent inevitable potential collisions. One reasonable quantity of evaluating potential collisions is time to contact (TTC): how soon will potential collision occur? In this paper, we provide TTC feedback control to improve safety and reliability of autonomous vehicles, and show the effectiveness of TTC feedback. TTC can be estimated by machine vision techniques with single uncelebrated camera (i.e., passive sensors). We provide detailed mathematical analysis and algorithmic implementation. The machine vision-based TTC algorithm is pretty fast such that the whole system can be implemented on Android smartphones running in real-time. Moreover, it is not trial to estimate relative velocity by differentiating the measured distance between cars with respect to time, because inevitable measurement noise in the distance measurements will be amplified by the derivative operation. The time-to-contact-based algorithm provides an alternative approach to estimating the relative velocity, which can also be fused with measurements from other active sensors, if desired.																	1758-0366	1758-0374					2020	16	2			SI		68	78		10.1504/IJBIC.2020.109676													
J								SmartGC: a software architecture for garbage collection in smart cities	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										smart cities; garbage collection; artificial transportation systems; ATS; software architecture	WASTE COLLECTION; PERFORMANCE; CITY	With populations in cities increasing in a very accelerated pace, the problem of collecting and handling the waste produced becomes a major concern to governmental authorities. Indeed, the amount of garbage they create is increasing even faster than their populations, worsening the problem and turning garbage collection into a very challenging task. In this paper, we see garbage collection through the spectacles of the emerging concept of smart cities, accounting for new performance measures defined on the grounds of sustainability, energy efficiency, optimum resource allocation, and low carbon emission and footprint. We thus devise a smart garbage collection management system, coined SmartGC, whose architecture is detailed and explained. Abstracting out garbage collection from a smart mobility perspective, the underlying methodology supporting the proposed architecture relies on the concept of artificial transportation systems. For the sake of demonstration we have implemented a routing strategy to generate improved itineraries accounting for the content of garbage containers, which are continuously monitored through IoT-based smart meters. Also, we discuss on how the architecture is instantiated and integrated into the smart city agenda of Natal, a medium-size capital in Northeastern Brazil.																	1758-0366	1758-0374					2020	16	2			SI		79	93		10.1504/IJBIC.2020.109675													
J								A novel squeeze YOLO-based real-time people counting approach	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										model compression; people counting; boundary-selection; you only look once; YOLO; SqueezeNet	ALGORITHM	Real-time people counting based on videos is one of the most popular projects in the construction of smart cities. To develop an accurate people counting approach, deep learning can be used as it greatly improves the accuracy of machine learning-based approaches. To this end, we have previously proposed an accurate you only look once (YOLO)-based people counting approach, dubbed YOLO-PC. However, the model of YOLO-PC was very large with an excessive number of parameters, thus it requires large storage space on the device and makes transmission on internet a time consuming task. In this paper, a new real-time people counting method named as squeeze YOLO-based people counting (S-YOLO-PC) is proposed. S-YOLO-PC uses the fire layer of SqueezeNet to optimise the network structure, which reduces the number of parameters used in the model without decreasing its accuracy. Based on the obtained the experimental results, S-YOLO-PC reduces the number of model parameters by 11.5% and 9% compared to YOLO and YOLO-PC, respectively. S-YOLO-PC can also detect and count people with 41 frames per second (FPS) with the average precision (AP) of person of 72%.																	1758-0366	1758-0374					2020	16	2			SI		94	101		10.1504/IJBIC.2020.109674													
J								A variant of EAM to uncover community structure in complex networks	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										single-objective optimisation; evolutionary algorithms; environmental adaptation method; EAM; community detection problem	ALGORITHM	Environmental adaptation method (EAM) was developed to solve single-objective optimisation problems. After the first proposal, other variants have been suggested to speed up the convergence rate and to maintain the diversity of the solutions. Among those variants, IEAM-RP works with real numbers. In this paper, a variant of IEAM-RP has been suggested with major changes in adaptation operator to improve the overall performance of the algorithm. In the proposed method, significant attention has been given for balancing exploration and exploitation of individuals in the population. The performance of the proposed algorithm is compared against 14 state-of-the-art algorithms using standard benchmark functions of the comparing continuous optimisers (COCO) framework. Further, to check the effectiveness of the proposed approach, it has been applied to a real-world problem of community detection in complex networks. Again, the experimental results are found very promising and competitive compared to other algorithms.																	1758-0366	1758-0374					2020	16	2			SI		102	110		10.1504/IJBIC.2020.109713													
J								Nanoindentation analysis comparing dragonfly-inspired biomimetic micro-aerial vehicle (BMAV) wings	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										dragonfly; biomimetic; artificial wing structure; tensile stress; nanoindentation	NANOMECHANICAL PROPERTIES; MECHANICAL-PROPERTIES; FLEXURAL STIFFNESS; ELASTIC-MODULUS; INDENTATION; FLIGHT; MEMBRANES; HARDNESS	Biomimetic micro-aerial vehicle (BMAV) are micro-scaled, unmanned aircraft based on flying biological organisms, generating thrust and lift by flapping their wings. This study investigates and compares the nano mechanical mechanical properties of four sets of fabricated, dragonfly inspired BMAV wings and compares them to actual dragonfly wings used as a baseline reference. The BMAV wings were fabricated using a 3D printer, based on these simplified models. Different 3D printer filament materials were used for each of the four wing sets: acrylonitrile butadiene styrene (or ABS), polylactic acid (or PLA), high impact polystyrene (or HIPS) as well as Ultrat. Nanoindentation tests of the actual dragonfly wings and the BMAV wings were conducted to measure their hardness and Young's modulus. The test result demonstrates the feasibility solution in the development of strong, practical and low cost BMAV wings, this work is a stepping-stone on the path to flying robotic dragonfly.																	1758-0366	1758-0374					2020	16	2			SI		111	120		10.1504/IJBIC.2020.109715													
J								Integrated deteriorating maintenance and patient scheduling for single medical device with heuristic algorithm	INTERNATIONAL JOURNAL OF BIO-INSPIRED COMPUTATION										patient scheduling; maximum tardiness; medical device; time-window deteriorating maintenance; virtual maintenance; bio-inspired computation	MACHINE; NUMBER; JOB	This paper aims to propose a two-phase model integrated patient scheduling and medical device maintenance to improve their reliability, reduce operating costs, and increase operating efficiency. In this paper, one patient scheduling problem with time-window deteriorating maintenance is studied. The objective is to minimise the maximum tardiness of all patients. First, a two-phase mathematical model is developed to characterise the problem. One model is used to solve the lower bound of the number of maintenance activities, and the other is used to obtain the patient scheduling solution. Then, one heuristic is developed for the problem. Finally, numerical experiments can be performed to indicate the efficiency and effectiveness of the proposed methods. The results show that the proposed methods have a better performance for the patient scheduling problem and can be able to obtain one good solution in a short computation time. Few studies have been carried out to integrate decisions between patient scheduling and device maintenance. Their considerations are either incomplete or not realistic enough. A more comprehensive and realistic two-phase model is proposed in this paper.																	1758-0366	1758-0374					2020	16	2			SI		121	131		10.1504/IJBIC.2020.109677													
B								IoT Technologies and Applications	FOG-ENABLED INTELLIGENT IOT SYSTEMS																															978-3-030-23185-9; 978-3-030-23184-2				2020							1	37		10.1007/978-3-030-23185-9_1	10.1007/978-3-030-23185-9												
B								Fog Computing Architecture and Technologies	FOG-ENABLED INTELLIGENT IOT SYSTEMS																															978-3-030-23185-9; 978-3-030-23184-2				2020							39	60		10.1007/978-3-030-23185-9_2	10.1007/978-3-030-23185-9												
B								Analytical Framework for Multi-Task Multi-Helper Fog Networks	FOG-ENABLED INTELLIGENT IOT SYSTEMS											ALLOCATION; CLOUD; MINIMIZATION; RESOURCES																				978-3-030-23185-9; 978-3-030-23184-2				2020							61	98		10.1007/978-3-030-23185-9_3	10.1007/978-3-030-23185-9												
B								Fog-Enabled Multi-Robot System	FOG-ENABLED INTELLIGENT IOT SYSTEMS																															978-3-030-23185-9; 978-3-030-23184-2				2020							99	131		10.1007/978-3-030-23185-9_4	10.1007/978-3-030-23185-9												
B								Fog-EnabledWireless Communication Networks	FOG-ENABLED INTELLIGENT IOT SYSTEMS											RESOURCE-ALLOCATION; MOBILITY MANAGEMENT; JOINT OPTIMIZATION; RADIO; 5G; ARCHITECTURE																				978-3-030-23185-9; 978-3-030-23184-2				2020							133	161		10.1007/978-3-030-23185-9_5	10.1007/978-3-030-23185-9												
B								Fog-Enabled Intelligent Transportation System	FOG-ENABLED INTELLIGENT IOT SYSTEMS											CHALLENGES																				978-3-030-23185-9; 978-3-030-23184-2				2020							163	184		10.1007/978-3-030-23185-9_6	10.1007/978-3-030-23185-9												
B								Fog-Enabled Smart Home and User Behavior Recognition	FOG-ENABLED INTELLIGENT IOT SYSTEMS											IMPLEMENTATION; LOCALIZATION; GESTURE; MIMO																				978-3-030-23185-9; 978-3-030-23184-2				2020							185	210		10.1007/978-3-030-23185-9_7	10.1007/978-3-030-23185-9												
B								Examples of problem statements and functionals	SEMI-EMPIRICAL NEURAL NETWORK MODELING AND DIGITAL TWINS DEVELOPMENT																															978-0-12-815652-0; 978-0-12-815651-3				2020							1	49		10.1016/B978-0-12-815651-3.00001-8													
B								The choice of the functional basis (set of bases)	SEMI-EMPIRICAL NEURAL NETWORK MODELING AND DIGITAL TWINS DEVELOPMENT																															978-0-12-815652-0; 978-0-12-815651-3				2020							51	72		10.1016/B978-0-12-815651-3.00002-X													
B								Methods for the selection of parameters and structure of the neural network model	SEMI-EMPIRICAL NEURAL NETWORK MODELING AND DIGITAL TWINS DEVELOPMENT																															978-0-12-815652-0; 978-0-12-815651-3				2020							73	103		10.1016/B978-0-12-815651-3.00003-1													
B								Results of computational experiments	SEMI-EMPIRICAL NEURAL NETWORK MODELING AND DIGITAL TWINS DEVELOPMENT																															978-0-12-815652-0; 978-0-12-815651-3				2020							105	171		10.1016/B978-0-12-815651-3.00004-3													
B								Methods for constructing multilayer semi-empirical models	SEMI-EMPIRICAL NEURAL NETWORK MODELING AND DIGITAL TWINS DEVELOPMENT																															978-0-12-815652-0; 978-0-12-815651-3				2020							173	236		10.1016/B978-0-12-815651-3.00005-5													
J								Large-scale semantic exploration of scientific literature using topic-based hashing algorithms	SEMANTIC WEB										Document similarity; information search and retrieval; clustering; topic models; hashing		Searching for similar documents and exploring major themes covered across groups of documents are common activities when browsing collections of scientific papers. This manual knowledge-intensive task can become less tedious and even lead to unexpected relevant findings if unsupervised algorithms are applied to help researchers. Most text mining algorithms represent documents in a common feature space that abstract them away from the specific sequence of words used in them. Probabilistic Topic Models reduce that feature space by annotating documents with thematic information. Over this low-dimensional latent space some locality-sensitive hashing algorithms have been proposed to perform document similarity search. However, thematic information gets hidden behind hash codes, preventing thematic exploration and limiting the explanatory capability of topics to justify content-based similarities. This paper presents a novel hashing algorithm based on approximate nearest-neighbor techniques that uses hierarchical sets of topics as hash codes. It not only performs efficient similarity searches, but also allows extending those queries with thematic restrictions explaining the similarity score from the most relevant topics. Extensive evaluations on both scientific and industrial text datasets validate the proposed algorithm in terms of accuracy and efficiency.																	1570-0844	2210-4968					2020	11	5					735	750		10.3233/SW-200373													
J								Grey-based multiple instance learning with multiple bag-representative	AI COMMUNICATIONS										Multiple instance learning; support vector machine; grey relational analysis; bag representative; multi-class learning	SUPPORT VECTOR MACHINE	Multiple instance learning is a modification in supervised learning that handles the classification of collection instances, which called bags. Each bag contains a number of instances whose features are extracted. In multiple instance learning, the standard assumption is that a positive bag contains at least one positive instance, whereas a negative bag is only comprised of negative instances. The complexity of multiple instance learning relies heavily on the number of instances in the training datasets. Since we are usually confronted with a large instance space, it is important to design efficient instance selection techniques to speed up the training process, without compromising the performance. Firstly, a multiple instance learning model of support vector machine based on grey relational analysis is proposed in this paper. The data size can be reduced, and the importance of instances in the bag can be preliminarily judged. Secondly, this paper introduces an algorithm with the bag-representative selector that trains the support vector machine based on bag-level information. Finally, this paper shows how to generalize the algorithm for binary multiple instance learning to multiple class tasks. The experimental study evaluates and compares the performance of our method against 8 state-of-the-art multiple instance methods over 10 datasets, and then demonstrates that the proposed approach is competitive with the state-of-art multiple instance learning methods.																	0921-7126	1875-8452					2020	33	2					59	73		10.3233/AIC-200628													
J								Enhancing profit from stock transactions using neural networks	AI COMMUNICATIONS										Financial time series prediction; stock price; LSTM autoencoder; feature engineering; reinforcement learning	SERIES; FORECAST	Financial time-series forecasting, and profit maximization is a challenging task, which has attracted the interest of several researchers and is immensely important for investors. In this paper, we present a deep learning system, which uses a variety of data for a subset of the stocks on the NASDAQ exchange to forecast the stock price. Our framework allows the use of a variational autoencoder (VAE) to remove noise and time-series data engineering to extract higher-level features. A Stacked LSTM Autoencoder is used to perform multi-step-ahead prediction of the stock closing price. This prediction is used by two profit-maximization strategies that include greedy approach and short selling. Besides, we use reinforcement learning as a third profit-enhancement strategy and compare these three strategies to offline strategies that use the actual future prices. Results show that the proposed methods outperform the state-of-the-art time-series forecasting approaches in terms of predictive accuracy and profitability.																	0921-7126	1875-8452					2020	33	2					75	92		10.3233/AIC-200629													
J								Empirical scaling analyzer: An automated system for empirical analysis of performance scaling	AI COMMUNICATIONS										Empirical scaling analysis; running time scaling		The time complexity of algorithms, i.e., the scaling of the time required for solving a problem instance as a function of instance size, is of key interest in theoretical computer science and practical applications. In this work, we present a fully automated tool - Empirical Scaling Analyzer (ESA) - for performing sophisticated and detailed empirical scaling analyses. The methodological approach underlying ESA is based on a combination of automatic function fitting and bootstrap sampling; previous versions of the methodology have been used in prior work to characterize the empirical scaling behaviour of several prominent, high-performance SAT and TSP solvers. ESA is applicable to any algorithm or system, as long as running time data can be collected on sets of problem instances of various sizes. We present results from rigorous stress-testing to critically assess ESA on scenarios with challenging characteristics. We also give an overview of empirical scaling results obtained using ESA.																	0921-7126	1875-8452					2020	33	2					93	111		10.3233/AIC-200630													
J								BSD-GAN: Branched Generative Adversarial Network for Scale-Disentangled Representation Learning and Image Synthesis	IEEE TRANSACTIONS ON IMAGE PROCESSING										Training; Gallium nitride; Image generation; Generators; Image representation; Manifolds; Image coding; Image Processing; Image Generation; Visual Effects		We introduce BSD-GAN, a novel multi-branch and scale-disentangled training method which enables unconditional Generative Adversarial Networks (GANs) to learn image representations at multiple scales, benefiting a wide range of generation and editing tasks. The key feature of BSD-GAN is that it is trained in multiple branches, progressively covering both the breadth and depth of the network, as resolutions of the training images increase to reveal finer-scale features. Specifically, each noise vector, as input to the generator network of BSD-GAN, is deliberately split into several sub-vectors, each corresponding to, and is trained to learn, image representations at a particular scale. During training, we progressively "de-freeze" the sub-vectors, one at a time, as a new set of higher-resolution images is employed for training and more network layers are added. A consequence of such an explicit sub-vector designation is that we can directly manipulate and even combine latent (sub-vector) codes which model different feature scales. Extensive experiments demonstrate the effectiveness of our training method in scale-disentangled learning of image representations and synthesis of novel image contents, without any extra labels and without compromising quality of the synthesized high-resolution images. We further demonstrate several image generation and manipulation applications enabled or improved by BSD-GAN.																	1057-7149	1941-0042					2020	29						9073	9083		10.1109/TIP.2020.3014608													
J								Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing	IEEE TRANSACTIONS ON IMAGE PROCESSING										Neuromorphic vision sensing; spatio-temporal feature learning; graph convolutional neural networks; object classification; human action recognition	EVENTS	Neuromorphic vision sensing (NVS) devices represent visual information as sequences of asynchronous discrete events (a.k.a., "spikes") in response to changes in scene reflectance. Unlike conventional active pixel sensing (APS), NVS allows for significantly higher event sampling rates at substantially increased energy efficiency and robustness to illumination changes. However, feature representation for NVS is far behind its APS-based counterparts, resulting in lower performance in high-level computer vision tasks. To fully utilize its sparse and asynchronous nature, we propose a compact graph representation for NVS, which allows for end-to-end learning with graph convolution neural networks. We couple this with a novel end-to-end feature learning framework that accommodates both appearance-based and motion-based tasks. The core of our framework comprises a spatial feature learning module, which utilizes residual-graph convolutional neural networks (RG-CNN), for end-to-end learning of appearance-based features directly from graphs. We extend this with our proposed Graph2Grid block and temporal feature learning module for efficiently modelling temporal dependencies over multiple graphs and a long temporal extent. We show how our framework can be configured for object classification, action recognition and action similarity labeling. Importantly, our approach preserves the spatial and temporal coherence of spike events, while requiring less computation and memory. The experimental validation shows that our proposed framework outperforms all recent methods on standard datasets. Finally, to address the absence of large real-world NVS datasets for complex recognition tasks, we introduce, evaluate and make available the American Sign Language letters (ASL-DVS), as well as human action dataset (UCF101-DVS, HMDB51-DVS and ASLAN-DVS).																	1057-7149	1941-0042					2020	29						9084	9098		10.1109/TIP.2020.3023597													
J								MSdB-NMF: MultiSpectral Document Image Binarization Framework via Non-Negative Matrix Factorization Approach	IEEE TRANSACTIONS ON IMAGE PROCESSING										Multispectral; hyperspectral; document image; binarization; non-negative matrix factorization; robustness; sparseness	CONSTRAINED LEAST-SQUARES; NON DESTRUCTIVE DETECTION; IRON-GALL INKS; FAST ALGORITHM; COLOR; EXTRACTION; RESTORATION; QUALITY; OBJECTS; MODEL	In this paper, we propose a novel method for Multispectral document image binarization (MSdB) through the Non-negative Matrix Factorization (NMF) approach. We propose a three-step MSdB-NMF framework: i) NMF-based feature extraction algorithm by introducing a new optimization problem; ii) post-processing method iii); apply any existing gray/RGB binarization scheme. In the first step, we extract N features out of B spectral bands (N < B) and their corresponding coefficient matrix. We introduce a novel objective formulation that considers the robustness (related to the noise and various types of degradations) and sparseness (related to the ratio of text pixels versus the background). We employ the multiplicative updating rules to solve the proposed minimization problem and prove the convergence of the proposed feature extraction algorithm. In the next step, we select an appropriate feature vector, equivalently the corresponding coefficient vector. We propose to select it either visually or automatically via a post-processing method, which uses the benchmark binarization methods as baseline. In the last step, we apply some existing binarization methods such as Sauvola and Howe over the selected coefficient vector. Our proposed binarization framework is applicable for any kind of MS or hyperspectral (HS) document image without considering any prior knowledge such as the side information about the spectral bands of MS/HS document image. We evaluate our proposed binarization framework over two MS document image datasets. The experimental results confirm that our proposed framework outperforms several state-of-the-art binarization schemes including the winner of the contest in MS-TEx-2015.																	1057-7149	1941-0042					2020	29						9099	9112		10.1109/TIP.2020.3023613													
J								STFlow: Self-Taught Optical Flow Estimation Using Pseudo Labels	IEEE TRANSACTIONS ON IMAGE PROCESSING										Optical imaging; Estimation; Optical variables control; Machine learning; Adaptive optics; Unsupervised learning; Optical fiber networks; Deep neural networks; optical flow; self-taught learning; unsupervised learning		The Deep learning of optical flow has been an active area for its empirical success. For the difficulty of obtaining accurate dense correspondence labels, unsupervised learning of optical flow has drawn more and more attention, while the accuracy is still far from satisfaction. By holding the philosophy that better estimation models can be trained with better-approximated labels, which in turn can be obtained from better estimation models, we propose a self-taught learning framework to continually improve the accuracy using self-generated pseudo labels. The estimated optical flow is first filtered by bidirectional flow consistency validation and occlusion-aware dense labels are then generated by edge-aware interpolation from selected sparse matches. Moreover, by combining reconstruction loss with regression loss on the generated pseudo labels, the performance is further improved. The experimental results demonstrate that our models achieve state-of-the-art results among unsupervised methods on the public KITTI, MPI-Sintel and Flying Chairs datasets.																	1057-7149	1941-0042					2020	29						9113	9124		10.1109/TIP.2020.3024015													
J								Consistent Video Style Transfer via Relaxation and Regularization	IEEE TRANSACTIONS ON IMAGE PROCESSING										Optical imaging; Task analysis; Robustness; Training; Adaptive optics; Stability analysis; Image color analysis; Style transfer; video processing; image synthesis; temporal consistency; temporal regularization		In recent years, neural style transfer has attracted more and more attention, especially for image style transfer. However, temporally consistent style transfer for videos is still a challenging problem. Existing methods, either relying on a significant amount of video data with optical flows or using single-frame regularizers, fail to handle strong motions or complex variations, therefore have limited performance on real videos. In this article, we address the problem by jointly considering the intrinsic properties of stylization and temporal consistency. We first identify the cause of the conflict between style transfer and temporal consistency, and propose to reconcile this contradiction by relaxing the objective function, so as to make the stylization loss term more robust to motions. Through relaxation, style transfer is more robust to inter-frame variation without degrading the subjective effect. Then, we provide a novel formulation and understanding of temporal consistency. Based on the formulation, we analyze the drawbacks of existing training strategies and derive a new regularization. We show by experiments that the proposed regularization can better balance the spatial and temporal performance. Based on relaxation and regularization, we design a zero-shot video style transfer framework. Moreover, for better feature migration, we introduce a new module to dynamically adjust inter-channel distributions. Quantitative and qualitative results demonstrate the superiority of our method over state-of-the-art style transfer methods. Our project is publicly available at: https://daooshee.github.io/ReReVST/.																	1057-7149	1941-0042					2020	29						9125	9139		10.1109/TIP.2020.3024018													
J								Towards Unsupervised Deep Image Enhancement With Generative Adversarial Network	IEEE TRANSACTIONS ON IMAGE PROCESSING										Unsupervised learning; image enhancement; global attention; generative adversarial network	DYNAMIC HISTOGRAM EQUALIZATION	Improving the aesthetic quality of images is challenging and eager for the public. To address this problem, most existing algorithms are based on supervised learning methods to learn an automatic photo enhancer for paired data, which consists of low-quality photos and corresponding expert-retouched versions. However, the style and characteristics of photos retouched by experts may not meet the needs or preferences of general users. In this paper, we present an unsupervised image enhancement generative adversarial network (UEGAN), which learns the corresponding image-to-image mapping from a set of images with desired characteristics in an unsupervised manner, rather than learning on a large number of paired images. The proposed model is based on single deep GAN which embeds the modulation and attention mechanisms to capture richer global and local features. Based on the proposed model, we introduce two losses to deal with the unsupervised image enhancement: (1) fidelity loss, which is defined as a $\ell 2$ regularization in the feature domain of a pre-trained VGG network to ensure the content between the enhanced image and the input image is the same, and (2) quality loss that is formulated as a relativistic hinge adversarial loss to endow the input image the desired characteristics. Both quantitative and qualitative results show that the proposed model effectively improves the aesthetic quality of images. Our code is available at: https://github.com/eezkni/UEGAN.																	1057-7149	1941-0042					2020	29						9140	9151		10.1109/TIP.2020.3023615													
J								Siamese Local and Global Networks for Robust Face Tracking	IEEE TRANSACTIONS ON IMAGE PROCESSING										Faces; Nose; Mouth; Correlation; Target tracking; Robustness; Face bounding box tracking; Local and global CNN representations; Correlation filter	VISUAL TRACKING; NEURAL-NETWORK; RECOGNITION	Convolutional neural networks (CNNs) have achieved great success in several face-related tasks, such as face detection, alignment and recognition. As a fundamental problem in computer vision, face tracking plays a crucial role in various applications, such as video surveillance, human emotion detection and human-computer interaction. However, few CNN-based approaches are proposed for face (bounding box) tracking. In this article, we propose a face tracking method based on Siamese CNNs, which takes advantages of powerful representations of hierarchical CNN features learned from massive face images. The proposed method captures discriminative face information at both local and global levels. At the local level, representations for attribute patches (i.e., eyes, nose and mouth) are learned to distinguish a face from another one, which are robust to pose changes and occlusions. At the global level, representations for each whole face are learned, which take into account the spatial relationships among local patches and facial characters, such as skin color and nevus. In addition, we build a new large-scale challenging face tracking dataset to evaluate face tracking methods and to facilitate the research forward in this field. Extensive experiments on the collected dataset demonstrate the effectiveness of our method in comparison to several state-of-the-art visual tracking methods.																	1057-7149	1941-0042					2020	29						9152	9164		10.1109/TIP.2020.3023621													
J								Hierarchical Feature Fusion Network for Salient Object Detection	IEEE TRANSACTIONS ON IMAGE PROCESSING										Feature extraction; Semantics; Image edge detection; Object detection; Fuses; Visualization; Image color analysis; Salient object detection; hierarchical feature fusion; edge information-guided; one-to-one hierarchical supervision strategy	NEURAL-NETWORK; MODEL	Convolutional Neural Network (CNN) has shown their advantages in salient object detection. CNN can generate great saliency maps because it can obtain high-level semantic information. And the semantic information is usually achieved by stacking multiple convolutional layers and pooling layers. However, multiple pooling operations will reduce the size of the feature map and easily blur the boundary of the salient object. Therefore, such operations are not beneficial to generate great saliency results. To alleviate this issue, we propose a novel edge information-guided hierarchical feature fusion network (HFFNet). Our network fuses features hierarchically and retains accurate semantic information and clear edge information effectively. Specifically, we extract image features from different levels of VGG. Then, we fuse the features hierarchically to generate high-level semantic information and low-level edge information. In order to retain better information at different levels, we adopt a one-to-one hierarchical supervision strategy to supervise the generation of low-level information and high-level information respectively. Finally, we use low-level edge information to guide the saliency map generation, and the edge guidance fusion is able to identify saliency regions effectively. The proposed HFFNet has been extensively evaluated on five traditional benchmark datasets. The experimental results demonstrate that the proposed model is fairly effective in salient object detection compared with 10 state-of-the-art models under different evaluation indicators, and it is superior to most of the comparison models.																	1057-7149	1941-0042					2020	29						9165	9175		10.1109/TIP.2020.3023774													
J								Registration of Multi-View Point Sets Under the Perspective of Expectation-Maximization	IEEE TRANSACTIONS ON IMAGE PROCESSING										Iterative closest point algorithm; Robustness; Three-dimensional displays; Solid modeling; Gaussian mixture model; Computational modeling; Gaussian distribution; Gaussian mixture model; expectation-maximization; point set registration	CLOUD REGISTRATION; EFFICIENT	Multi-view registration plays a critical role in 3D model reconstruction. To solve this problem, most previous methods align point sets by either partially exploring available information or blindly utilizing unnecessary information, which may lead to undesired results or extra computation complexity. Accordingly, we propose a novel solution for the multi-view registration under the perspective of Expectation-Maximization (EM). The proposed method assumes that each data point is generated from one unique Gaussian Mixture Model (GMM), where its corresponding points in other point sets are regarded as Gaussian centroids with equal covariance and membership probabilities. As it is difficult to obtain real corresponding points in the registration problem, they are approximated by the nearest neighbor in each other aligned point sets. Based on this assumption, it is reasonable to define the likelihood function including all rigid transformations, which require to be estimated for multi-view registration. Subsequently, the EM algorithm is derived to estimate rigid transformations with one Gaussian covariance by maximizing the likelihood function. Since the GMM component number is automatically determined by the number of point sets, there is no trade-off between registration accuracy and efficiency in the proposed method. Finally, the proposed method is tested on several benchmark data sets and compared with state-of-the-art algorithms. Experimental results demonstrate its superior performance on the accuracy, efficiency, and robustness for multi-view registration.																	1057-7149	1941-0042					2020	29						9176	9189		10.1109/TIP.2020.3024096													
J								Using local trust measures to form agent CoT groups	INTELLIGENZA ARTIFICIALE										Cloud of things; internet of things; multiagent system; reputation; trust; voting	CLOUD; REPUTATION; INTERNET; INTEGRATION; ISSUES; THINGS	IoT devices dealing with complex tasks usually require powerful hardware capabilities or, as a possible alternative, to get on the Cloud those resources they need. When an IoT device is "virtualized" on the Cloud, it can take benefit from relying on one or more software agents and their social skills to mutually interact and cooperate. In particular, in a Cloud of Things scenario, where agents cooperate to perform complex tasks, the choice of a partner is a sensitive question. In such a context, when an agent is not capable to perform a reliable choice then, like real social communities, it can ask information to other agents it considers as trustworthy. In order to support agents in their partner choices, we conceived a local trust model, based on reliability and reputation measures coming from its ego-network, adopted to partition the agents in groups by exploiting trust relationships to allow agents to be associated with the most reliable partners. To this aim, we designed an algorithm to form agent groups by exploiting available local trust measures and the results obtained in a simulated scenario confirmed the potential advantages of this approach.																	1724-8035	2211-0097					2020	14	1					7	18		10.3233/IA-190039													
J								Trust and autonomy for regulating the users' acceptance of IoT technologies	INTELLIGENZA ARTIFICIALE										Trust; Internet of Things; autonomy	INTERNET; AGENT; THINGS; AUTOMATION; SECURITY	The success of IoT technologies is undeniable. They are entering more and more in our lives, carrying out increasingly complex tasks. However, there are still a few problems we need to face and solve. For instance, it is not given that the users will be prepared to afford all the automation that IoT devices will offer or that it will be compatible with the users' cognitive attitudes and its actual and real goals. Within this work, we start analyzing which reasons undermine the acceptance of IoT systems and then we propose a possible solution, tanking into account not just the user-device interaction, but also how this affects the device-device interaction. Since the complexity of the tasks the user asks may require the cooperation of some devices to be realized, the regulation of this relationship represents a necessary step for this technology. The first contribution of this work is the level characterization of the autonomy a user can grant to an IoT device. The second contribution is a theoretical model to deal with users and to stimulate users' acceptance, taking also into account a possible, collaborative organizational structure, to manage the creation of groups and the partners' selection process.																	1724-8035	2211-0097					2020	14	1					19	32		10.3233/IA-190041													
J								Interval arithmetic to support effective indoor positioning of software agents	INTELLIGENZA ARTIFICIALE										Localization as optimization; indoor localization; software agents	LOCALIZATION; ALGORITHMS; TDOA	The provision of advanced location-based services in indoor environments is based on the possibility of estimating the positions of mobile devices with sufficient accuracy and robustness. An algorithm to allow a software agent hosted on a mobile device to estimate the position of its device in a known indoor environment is proposed under the ordinary assumption that fixed beacons are installed in the environment at known locations. Rather than making use of geometric considerations to estimate the position of the device, the proposed algorithm first transforms the localization problem into a related optimization problem, which is then solved by means of interval arithmetic to provide the agent with accurate and robust position estimates. The adopted approach solves a major problem that severely limits the accuracy of the position estimates that ordinary geometric algorithms provide when the beacons are positioned to maximize line-of-sight coverage. Experimental results confirm that the proposed algorithm provides position estimates that are independent of the positions of the beacons, and they show that the algorithm outperforms a well-known geometric algorithm.																	1724-8035	2211-0097					2020	14	1					33	47		10.3233/IA-190042													
J								Eliciting cities points of interest from people movements and suggesting effective itineraries	INTELLIGENZA ARTIFICIALE										Clustering; geospatial clustering; GPS coordinates; recommendation systems; IoT; tourism	RECOMMENDATION; SYSTEMS	When a person visits an unknown large city having multiple interesting locations, it is not so easy for him to find one location that is lively and convenient to visit in a given time-frame. To overcome such a problem, this paper proposes to make use of two technologies: smartphones, equipped with sensors for reading GPS coordinates; and multi-agent systems, providing assistance to users and gathering collective knowledge. Data collected by means of devices are analysed and organised in such a way to find locations that could be of immediate interest to people. Proposed agents gather opinions from several users, in terms of scores quantifying the level of satisfaction on visiting some place on a given time-frame. While gathering such an opinion, a solution is put into place to preserve user privacy (his location). Suggestions are made to potentially interested users by selecting for them locations according to closeness and satisfaction scores. In this approach, interesting locations emerge from the analysis of data gathered, hence scores and suggestions can be available for any large city in any place, provided that enough people hand data to the system. Moreover, such places are found dynamically according to people behaviour and preferences.																	1724-8035	2211-0097					2020	14	1					49	61		10.3233/IA-190040													
J								A reputation-based framework to support dynamic car-pooling	INTELLIGENZA ARTIFICIALE										Car-pooling; multi-agent system; recommender system; reputation system; routing algorithm	RECOMMENDER SYSTEMS; MANAGEMENT; CONGESTION; RIDE	In the last decades, individual urban traffic flows have increased all over the world with a consequent growth of road congestion and environmental pollution. In this context, car-pooling is an interesting car-based alternative to satisfy the individual mobility demand by optimizing the car loading factor with respect to the number of passengers, provided that all the participants share trip origin and destination in the same time slot. To make the system more appealing, this paper proposes an on-demand car-pooling service adopting variable fares, on the basis of trip length and number of participants. Multi-agent, reputation and recommender system technologies in synergy with a routing algorithm have been used to this aim. Experiments on simulated data proved the potentiality of the proposed approach.																	1724-8035	2211-0097					2020	14	1					63	76		10.3233/IA-190037													
J								ActorNode2Vec: An Actor-based solution for Node Embedding over large networks	INTELLIGENZA ARTIFICIALE										Network science; embedding; node embedding; Node2vec; actodes; distributed systems; data mining; complex systems; actor model		The application of Machine Learning techniques over networks, such as prediction tasks over nodes and edges, is becoming often crucial in the analysis of Complex systems in a wide range of research fields. One of the enabling technologies in that sense is represented by Node Embedding, which enables us to learn features automatically over the network. Among the different approaches proposed in the literature, the most promising are Deep Walk and Node2Vec, where the embedding is computed by combining random walks and neural language models. However, characteristic limitations with these techniques are related to memory requirements and time complexity. In this paper, we propose a distributed and scalable solution, named ActorNode2vec, that keeps the best advantages of Node2Vec and overcomes the limitations with the adoption of the actor model to distribute the computational load. We demonstrate the efficacy of this approach with a large network by analyzing the sensitivity of walk length and number of walks parameters and make a comparison also with Deep walk and an Apache Spark distributed implementation of Node2Vec. Results show that with ActorNode2vec computational times are drastically reduced without losing embedding quality and overcoming memory issues.																	1724-8035	2211-0097					2020	14	1					77	88		10.3233/IA-190038													
J								On the use of the policy gradient and Hessian in inverse reinforcement learning	INTELLIGENZA ARTIFICIALE										Reinforcement learning; inverse reinforcement learning; policy gradient; feature extraction		Reinforcement Learning (RL) is an effective approach to solve sequential decision making problems when the environment is equipped with a reward function to evaluate the agent's actions. However, there are several domains in which a reward function is not available and difficult to estimate. When samples of expert agents are available, Inverse Reinforcement Learning (IRL) allows recovering a reward function that explains the demonstrated behavior. Most of the classic IRL methods, in addition to expert's demonstrations, require sampling the environment to evaluate each reward function, that, in turn, is built starting from a set of engineered features. This paper is about a novel model-free IRL approach that does not require to specify a function space where to search for the expert's reward function. Leveraging on the fact that the policy gradient needs to be zero for an optimal policy, the algorithm generates an approximation space for the reward function, in which a reward is singled out employing a second-order criterion. After introducing our approach for finite domains, we extend it to continuous ones. The empirical results, on both finite and continuous domains, show that the reward function recovered by our algorithm allows learning policies that outperform those obtained with the true reward function, in terms of learning speed.																	1724-8035	2211-0097					2020	14	1					91	124		10.3233/IA-180011													
J								Learning fair models and representations	INTELLIGENZA ARTIFICIALE										Algorithmic fairness; fair models; fair representation	DISCRIMINATION; RISK; CLASSIFICATION; PREDICTION; BOUNDS; RATES; BIAS	Machine learning based systems and products are reaching society at large in many aspects of everyday life, including financial lending, online advertising, pretrial and immigration detention, child maltreatment screening, health care, social services, and education. This phenomenon has been accompanied by an increase in concern about the ethical issues that may rise from the adoption of these technologies. In response to this concern, a new area of machine learning has recently emerged that studies how to address disparate treatment caused by algorithmic errors and bias in the data. The central question is how to ensure that the learned model does not treat subgroups in the population unfairly. While the design of solutions to this issue requires an interdisciplinary effort, fundamental progress can only be achieved through a radical change in the machine learning paradigm. In this work, we will describe the state of the art on algorithmic fairness using statistical learning theory, machine learning, and deep learning approaches that are able to learn fair models and data representation.																	1724-8035	2211-0097					2020	14	1					125	152		10.3233/IA-190034													
J								Performance analysis of nature inspired load balancing algorithm in cloud environment	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cloud computing; Task scheduling; Nature inspired algorithms; Cloud analyst	PRIORITY	Cloud computing has emerged as a new technology which allows the users to store their data and retrieve it over internet on demand instead of using their own hardware. Cloud works with different data centers (DCs) (server) and user bases (UBs) (clients). One of the main challenges which requires focus in the cloud computing is task scheduling. In task scheduling the cloud should have the capability of managing the incoming load to achieve the better performance by allocating suitable resources as per the user request. The performance of the cloud can be further increased by selecting suitable DC which is closer to the UB. This article measures the performance analysis of various nature inspired load balancing algorithms to identify total response time (TRT) and data center processing time (DCPT) in cloud environment. The simulation is carried out using cloud analyst tool which is an extension of cloudsim and the results obtained which indicates water wave algorithm performs better in terms of TRT and particle swarm optimization scores well in the aspect of DCPT for varying different number of DCs and UBs.																	1868-5137	1868-5145															10.1007/s12652-019-01655-x		JAN 2020											
J								Agent grouping recommendation method in edge computing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Bayesian probability; K-means algorithm; Influence map; Edge computing; Grouping recommendation		In edge computing, diverse kinds of data are handled in real-time. An increasing number of researches have been carried out to improve the performance of data handling for agent-based data control technology. An important application for edge computing is to control the distributed agents in real-time strategy (RTS) games. One of the key approaches for agent control is the grouping of agents; however, it is difficult to group them in a reasonable cluster. This paper proposes a recommendation method for the best grouping of agents and edge computing devices to reduce the time of handling data and obtaining optimal results for RTS game agent selecting. The proposed method used K-means, influence mapping, and Bayesian probability, and was evaluated by utilizing a game environment in which the performance of handling data is easily evaluated. The comparison result between the recommendation and random modes shows that our method has ability to increase 47% of the percentage the wins.																	1868-5137	1868-5145															10.1007/s12652-019-01658-8		JAN 2020											
J								A hybrid metaheuristic approach for efficient feature selection methods in big data	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Big data; Feature selection; Particle swarm optimization (PSO); Grammatical evolution (GE); Naive Bayes and K-nearest neighbor (KNN)	CLASSIFICATION	The big data is based on the 3V challenges that are the volume, the variety, and velocity. Big data is collected from various sources and it is seen that data comes in a various format in high speed that are gathered together rapidly as well as they are created as an ancient batch models where it is infeasible to process in real time. Big data has become an imminent part of all industries and business sectors today. All organizations in any sector like energy, banking, retail, hardware, networking, etc. all generate huge quantum of heterogenous data which if mined, processed and analyzed accurately can reveal immensely useful patterns for business heads to apply to generate and grow their businesses. There is a very critical challenge in big data that demands data mining to be performed with high-speed information in big technology which has been getting a lot of importance today. The technique of feature selection has been employed for the mining of data stream on the fly for the big data to improve efficiency and for minimizing the process load on mining and its model. In this paper, for achieving an accuracy and to have a minimum processing time for a query and for the reduction of the processing load a Particle Swarm Optimization (PSO), a Grammatical Evolution (GE) and the Hybrid PSO-GE methods has been proposed. The techniques of classification help users in retrieving required information from big database of transactions in a simpler manner. Database management systems have been indispensable to enterprises for decades. As the amount of data dramatically increased, database aggregation has encountered a dilemma between privacy and performance. In traditional database aggregation, all attributes have been encrypted to protect the privacy of data. The results of the experiments demonstrates the efficiency of the hybrid PSO-GE method compared to existing methods.																	1868-5137	1868-5145															10.1007/s12652-019-01656-w		JAN 2020											
J								Rough fuzzy region based bounded support fuzzy C-means clustering for brain MR image segmentation	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Image segmentation; Intensity non-uniformity; Fuzzy C-means; Bias calculation; Bounded support	MEANS ALGORITHM; CLASSIFICATION; INFORMATION	Precise brain tissue segmentation and analysis in the presence of intensity non-uniformity (INU) and noise is the challenging task due to intensity overlaps between data pixels within the image. The clustering method is commonly used to variety of applications for grouping similar data items. Specifically, the fuzzy C-means (FCM) clustering method is extensively used in many real world and research applications. In this paper, the rough fuzzy region based bounded support fuzzy C-means (RFRBSFCM) clustering method is proposed for brain MR image INU estimation and correction, and segmentation. The rough fuzzy regions are estimated based on similarity distance vector and it is determined from both local and global spatial information. In addition, the proposed algorithm incorporates bounded support vector for estimating weighted image. The objective function of proposed algorithm is minimized for segmenting different tissues in brain MR image. The RFRBSFCM algorithm is tested with recent FCM clustering techniques using simulated T1 and T2-weighted brain MR images from public BrainWeb dataset. The quantitative results confirm that the proposed algorithm achieves superior performance than other recent state-of-the-art methods.																	1868-5137	1868-5145															10.1007/s12652-019-01672-w		JAN 2020											
J								Applying integrative situational cases into the effectiveness of interprofessional education programs	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Inter-professional collaboration; Teamwork; Truku aboriginal; Integrative situational cases	PATIENT SAFETY; HEALTH-CARE; SIMULATION; NURSES	During the medical professionals receiving their education, the educational facilities and the environment are almost isolated, and the understanding of the related clinical professionals is limited. During the student period, interactive learning opportunities among different professionals shall be established to enhance mutual understanding and facilitate teamwork after entering the workplace. Therefore, this study explores the effectiveness of teamwork in senior nursing students via investigating the efficiency of Truku tribal's integrative situational cases into inter-professional education workshop. Taking the inter-professional education workshop model as an intervention strategy, senior college students from the Department of Medicine, Physical Therapy and Nursing were invited to participate in the 4-h workshop, before and after the first class. Employing the team-based self-designed questionnaire to collect the differences in cultural care and teamwork cognitive ability before and after the workshop participation, the SPSS 22.0 version software was used for descriptive and inferential statistical data analysis. A total of 45 valid pre-test questionnaires were collected, with a 100% recovery rate; and 43 valid post-test questionnaires were collected, with a 95.56% response rate. Independentttest or two-sample t-test was used for "the workshop of the intervention on the integration of the Truku member's health cases into inter-professional education", the teamwork ability (t = - 3.27, p < 0.05), cultural care ability (t = - 6.74, p < 0.05), and the overall mean (t = - 6.14, p < 0.05) are all reached statistically significant differences. The involvement of situational cases in education workshops not only enhances students' teamwork and communication skills, but also positively evaluates inter-professional activities, inferring the learning process of senior nursing students. Thus, in the multicultural Taiwanese society, continuous promotion and application should be carried out to create a friendly medical institution so as to improve the medical environment and efficiency through effective teamwork skills.																	1868-5137	1868-5145															10.1007/s12652-019-01664-w		JAN 2020											
J								Machine learning for air quality prediction using meteorological and traffic related features	JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS										Air pollution; meteorological features; traffic features; Machine Learning; Linear Regression; Support Vector Machine; Random Forest	PARTICULATE MATTER; POLLUTION; HEALTH; MORTALITY; IMPACTS; CLIMATE; MODELS	The presence of pollutants in the air has a direct impact on our health and causes detrimental changes to our environment. Air quality monitoring is therefore of paramount importance. The high cost of the acquisition and maintenance of accurate air quality stations implies that only a small number of these stations can be deployed in a country. To improve the spatial resolution of the air monitoring process, an interesting idea is to develop data-driven models to predict air quality based on readily available data. In this paper, we investigate the correlations between air pollutants concentrations and meteorological and road traffic data. Using machine learning, regression models are developed to predict pollutants concentration. Both linear and non-linear models are investigated in this paper. It is shown that non-linear models, namely Random Forest (RF) and Support Vector Regression (SVR), better describe the impact of traffic flows and meteorology on the concentrations of pollutants in the atmosphere. It is also shown that more accurate prediction models can be obtained when including some pollutants' concentration as predictors. This may be used to infer the concentrations of some pollutants using those of other pollutants, thereby reducing the number of air pollution sensors.																	1876-1364	1876-1372					2020	12	5					379	391		10.3233/AIS-200572													
J								Analysis and prediction of big stream data in real-time water quality monitoring system	JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS										Water quality monitor system; wavelet analysis; deep learning; big data process; prediction of time series; LSTM		Large scale real-time water quality monitoring system usually produces vast amounts of high frequency data, and it is difficult for traditional water quality monitoring system to process such large and high frequency data generated by wireless sensor network. A real-time processing and early warning system framework is proposed to solve this problem, Apache Storm is used as the big data processing platform, and Kafka message queue is applied to classify the sample data into several data streams so as to reserve the time series data property of a sensor. In storm platform, Daubechies Wavelet is used to decompose the data series to obtain the trend of the series, then Long Short Term Memory Network (LSTM) model is used to model and predict the trend of the data. This paper provides a detailed description concerning the distribution mechanism of aggregated data in Storm, data storage format in HBase, the process of wavelet decomposition, model training and the application of mode for prediction. The application results in Xin' an River in Yantai City reveal that the prosed system framework has a very good ability to model big data with high prediction accuracy and robust processing capability.																	1876-1364	1876-1372					2020	12	5					393	406		10.3233/AIS-200571													
J								The detection of Alternaria solani infection on tomatoes using ensemble learning	JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS										Alternaria solani; plant disease detection; hyperspectral data; random forest; decision tree; machine learning; ensemble learning	RESISTANCE; BLIGHT	This paper presents a detection method of Alternaria solani in tomatoes. Several machine learning models were used to detect the pathogen, such as the implementation of decision trees and ensemble learning methods. The use of these methods requires the acquisition of large volumes of data and adequate preprocessing of this data. For the presented study the dataset of hyperspectral measurements of two varieties of tomatoes was used. Measurements were split into two groups: one inoculated with the Alternaria solani pathogen and the other one was treated as the reference. Measurements were taken by the spectroradiometer in consecutive measurement series. The main part of the study was the evaluation of the decision trees and the popular ensemble learning algorithms to select the most accurate one. After subsequent iterations of the training process and adjustment of hyperparameters, satisfactory accuracy results, equal to 0.987 for random forest, were obtained. This paper also covers the examination of the spectral range required for Alternaria solani identification. From several variants, the accuracy of models based on VIS and NIR spectral range was the closest to the accuracy obtained with the whole spectrum of measured absolute reflectance.																	1876-1364	1876-1372					2020	12	5					407	418		10.3233/AIS-200573													
J								Development of an application to make knowledge available to the farmer: Detection of the most suitable crops for a more sustainable agriculture	JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS										Precision agriculture; sustainable agriculture; intelligent data analysis; clustering analysis	PRECISION AGRICULTURE; MANAGEMENT ZONES; IDENTIFICATION; MODEL	Precision agriculture has different strategies to collect, process and analyze different types and nature data to be able to make decisions that improve the efficiency, productivity, quality, profitability and sustainability of agricultural production. Specifically, crop sustainability is directly related to reducing costs for farmers and minimizing environmental impact. In this paper, an application to help in the decision making about the most convenient type of crop to plant in a certain zone is developed, taking into account the climate conditions of that zone, in order to make a sustainable crop. This application is integrated within the Internet of Things system, which can be adapted and parameterized for any kind of crop and zone. The Internet of Things system components are described in detail and a fuzzy clustering model is proposed for the system's intelligent module. This fuzzy model focuses on making a zone grouping (management zones), taking into account the zone climate conditions. The model manages fuzzy data, which allows us more extensive information and a more natural data treatment. A real study case of the proposed application is presented using data from the Region of Murcia (Spain). In this study case, the entire deployed Internet of Things system has been described, the fuzzy model to group similar areas in terms of meteorology has been validated and evaluated and the recommendation module has been implemented, taking into account the actual production data and the needed resources for the crops in the Region of Murcia (Spain).																	1876-1364	1876-1372					2020	12	5					419	432		10.3233/AIS-200575													
J								Sparse and low-rank multivariate Hawkes processes	JOURNAL OF MACHINE LEARNING RESEARCH										Hawkes processes; Sparsity; Low-Rank; Random matrices; Data-driven concentration		We consider the problem of unveiling the implicit network structure of node interactions (such as user interactions in a social network), based only on high-frequency timestamps. Our inference is based on the minimization of the least-squares loss associated with a multivariate Hawkes model, penalized by ;(1) and trace norm of the interaction tensor. We provide a first theoretical analysis for this problem, that includes sparsity and low-rank inducing penalizations. This result involves a new data-driven concentration inequality for matrix martingales in continuous time with observable variance, which is a result of independent interest and a broad range of possible applications since it extends to matrix martingales former results restricted to the scalar case. A consequence of our analysis is the construction of sharply tuned l(1) and trace-norm penalizations, that leads to a data-driven scaling of the variability of information available for each users. Numerical experiments illustrate the significant improvements achieved by the use of such data-driven penalizations.																	1532-4435						2020	21																						
J								Asynchronous dual-pipeline deep learning framework for online data stream classification	INTEGRATED COMPUTER-AIDED ENGINEERING										Classification; convolutional neural network; data streaming; deep learning; evaluation; online learning	CLASSIFIERS	Data streaming classification has become an essential task in many fields where real-time decisions have to be made based on incoming information. Neural networks are a particularly suitable technique for the streaming scenario due to their incremental learning nature. However, the high computation cost of deep architectures limits their applicability to high-velocity streams, hence they have not yet been fully explored in the literature. Therefore, in this work, we aim to evaluate the effectiveness of complex deep neural networks for supervised classification in the streaming context. We propose an asynchronous deep learning framework in which training and testing are performed simultaneously in two different processes. The data stream entering the system is dual fed into both layers in order to concurrently provide quick predictions and update the deep learning model. This separation reduces processing time while obtaining high accuracy on classification. Several time-series datasets from the UCR repository have been simulated as streams to evaluate our proposal, which has been compared to other methods such as Hoeffding trees, drift detectors, and ensemble models. The statistical analysis carried out verifies the improvement in performance achieved with our dual-pipeline deep learning framework, that is also competitive in terms of computation time.																	1069-2509	1875-8835					2020	27	2					101	119		10.3233/ICA-200617													
J								A membrane parallel rapidly-exploring random tree algorithm for robotic motion planning	INTEGRATED COMPUTER-AIDED ENGINEERING										Optimal motion planning; Rapidly-exploring Random Tree; Membrane Computing; OpenMP; CUDA	FINITE-ELEMENT-ANALYSIS; P-SYSTEMS; WORKSTATIONS; OPTIMIZATION; NETWORK	In recent years, incremental sampling-based motion planning algorithms have been widely used to solve robot motion planning problems in high-dimensional configuration spaces. In particular, the Rapidly-exploring Random Tree (RRT) algorithm and its asymptotically-optimal counterpart called RRT* are popular algorithms used in real-life applications due to its desirable properties. Such algorithms are inherently iterative, but certain modules such as the collision-checking procedure can be parallelized providing significant speedup with respect to sequential implementations. In this paper, the RRT and RRT* algorithms have been adapted to a bioinspired computational framework called Membrane Computing whose models of computation, a.k.a. P systems, run in a non-deterministic and massively parallel way. A large number of robotic applications are currently using a variant of P systems called Enzymatic Numerical P systems (ENPS) for reactive controlling, but there is a lack of solutions for motion planning in the framework. The novel models in this work have been designed using the ENPS framework. In order to test and validate the ENPS models for RRT and RRT*, we present two ad-hoc implementations able to emulate the computation of the models using OpenMP and CUDA. Finally, we show the speedup of our solutions with respect to sequential baseline implementations. The results show a speedup up to 6x using OpenMP with 8 cores against the sequential implementation and up to 24x using CUDA against the best multi-threading configuration.																	1069-2509	1875-8835					2020	27	2					121	138		10.3233/ICA-190616													
J								Routing in congested baggage handling systems using deep reinforcement learning	INTEGRATED COMPUTER-AIDED ENGINEERING										Routing; baggage handling systems; deep reinforcement learning	GAME; GO	The increasing number of people choosing to travel by airplane puts pressure on the baggage handling systems in airports. As the load increases, the risk of deadlocks in the systems increase as well. Therefore, it is increasingly important to find routing solutions which can handle the high loads. Currently this is achieved by using shortest path algorithms and hand engineered site-specific routing rules, based on the experience of the employees and on trial and error processes using complex emulators. This is a time-consuming and costly approach, as every airport needs its own set of routing rules. New development within machine learning, and especially reinforcement learning allows very complex control policies to be found in large environments. This could therefore potentially solve the need of manually creating site-specific routing rules. This paper proposes to use a single global deep reinforcement learning agent to route a fleet of baggage-totes to continuously pick up and deliver baggage in simple yet functionally realistic simulations of baggage handling systems. This is achieved using a Dueling DQN architecture with prioritized experience reply and a multi action approach. Training and testing are performed in three baggage handling system environments of different size and complexity. The results show that by training with a broad distribution of loads, it is possible to get a model, capable of routing in highly congested baggage handling systems. The results also show that the reinforcement learning agent can limit the number of deadlocks up until a higher load than both a static shortest path and a dynamic shortest path method, even if the dynamic shortest path method is using a naive deadlock avoidance add-on.																	1069-2509	1875-8835					2020	27	2					139	152		10.3233/ICA-190613													
J								A domain-specific modeling approach supporting tool-chain development with Bayesian network models	INTEGRATED COMPUTER-AIDED ENGINEERING										Bayesian network; domain-specific modeling; model-based systems engineering; tool-chain assessment; tool-chain formalism	FRAMEWORK	Constructing and evaluating a comprehensive tool-chain with commercial off-the-shelf and proprietary tools for the deployment of model-based systems engineering (MBSE) is a challenging and complex task. Specifically, the lack of early assessment during tool-chain development has led to increased research and development costs when unexpected features are developed or poor decisions are made. In this paper, a domain-specific modeling (DSM) approach is proposed to support decision-makings during tool-chain design and to facilitate quantitative assessment of tool-chain features at early-phases. Using this approach, different views of tool-chains are first formalized under a DSM framework. Then the DSM models are transformed to Bayesian network models for supporting the quantitative assessment of related tools in order to analyze the whole tool-chains' features. In the case study, the approach is verified by comparing two MBSE tool-chains for an auto-braking system design. The results indicate that the DSM approach enhances the understanding of tool-chain concepts, promotes the efficiency of MBSE tool-chain development, and verifies the tool-chain in early development phases using a quantitative approach.																	1069-2509	1875-8835					2020	27	2					153	171		10.3233/ICA-190612													
J								Self-adapted optimization-based video magnification for revealing subtle changes	INTEGRATED COMPUTER-AIDED ENGINEERING										Video magnification; spatio-temporal analysis; optimization problems; Eulerian perspective	ALTERNATING DIRECTION METHOD; COMPUTATIONAL FRAMEWORK; RECOGNITION; ALGORITHM; CLASSIFICATION; NETWORKS; TRACKING	Video magnification techniques can reveal subtle temporal variations that are difficult or even impossible to see with the naked eye and display them in an indicative manner. State-of-the-art approaches rely on hand-designed filters or precise prior knowledge of the target signal and produce magnified outputs that are always bounded by the spatial support of the related pyramids. This paper proposes a method for adaptively magnifying subtle video changes by directly solving three key optimization problems. To efficiently model the magnification transformation, alternating direction method of multipliers is employed to solve convex variation-detection optimization problems. Following the transformation step, the perturbation problem is innovatively solved using a forward additive iterative approach to iteratively minimize the dissimilarity between the original and magnified sequences based on the enhanced correlation coefficient. The proposed method can be applied to videos overlaid with different types of temporal change to obtain motion and color magnification. Quantitative and qualitative experimental comparison of the proposed method with state-of-the-art techniques reveals that it produces magnified videos with improved visual quality and substantially fewer artifacts or blurring.																	1069-2509	1875-8835					2020	27	2					173	193		10.3233/ICA-190614													
J								Depth and thermal information fusion for head tracking using particle filter in a fall detection context	INTEGRATED COMPUTER-AIDED ENGINEERING										Head tracking; sensor fusion; particle filter; thermal sensor; depth sensor	OBJECT TRACKING; SURVEILLANCE	The security of elderly people living alone is a major issue. A system that detects anomalies can be useful for both individual and retirement homes. In this paper, we present an adaptive human tracking method built on particle filter, using depth and thermal information based on the velocity and the position of the head. The main contribution of this paper is the fusion of information to improve tracking. For each frame, there is a new combination of coefficients for each particle based on an adaptive weighting. Results show that the tracking method can deal with the cases of fast motion (fall), partial occultation and scale variation. To assess the impact of fusion on the tracking process, the robustness and accuracy of the method are tested on a variety of challenging scenarios with or without depth-thermal fusion.																	1069-2509	1875-8835					2020	27	2					195	208		10.3233/ICA-190615													
J								Targeted Fused Ridge Estimation of Inverse Covariance Matrices from Multiple High-Dimensional Data Classes	JOURNAL OF MACHINE LEARNING RESEARCH										differential network estimation; Gaussian graphical modeling; generalized fused ridge; high-dimensional data; l(2)-penalized maximum likelihood; structural metaanalysis	B-CELL LYMPHOMA; CLASSIFICATION; MICROARRAY; SELECTION; NETWORKS; MODEL; KEGG	We consider the problem of jointly estimating multiple inverse covariance matrices from high-dimensional data consisting of distinct classes. An l(2)-penalized maximum likelihood approach is employed. The suggested approach is flexible and generic, incorporating several other l(2) -penalized estimators as special cases. In addition, the approach allows specification of target matrices through which prior knowledge may be incorporated and which can stabilize the estimation procedure in high-dimensional settings. The result is a targeted fused ridge estimator that is of use when the precision matrices of the constituent classes are believed to chiefly share the same structure while potentially differing in a number of locations of interest. It has many applications in (multi)factorial study designs. We focus on the graphical interpretation of precision matrices with the proposed estimator then serving as a basis for integrative or meta-analytic Gaussian graphical modeling. Situations are considered in which the classes are defined by data sets and subtypes of diseases. The performance of the proposed estimator in the graphical modeling setting is assessed through extensive simulation experiments. Its practical usability is illustrated by the differential network modeling of 12 large-scale gene expression data sets of diffuse large B-cell lymphoma subtypes. The estimator and its related procedures are incorporated into the R-package rags2ridges.																	1532-4435						2020	21																						
J								QUANTUM INFORMATICS AND SOFT SYSTEMS MODELING	NEURAL NETWORK WORLD										information physics; physical-information analogies; component strength; strength moment; strength potential energy; generalized charge; knowledge cycle; quantum node; static information stability; dynamic information stability; evolutionary field		This paper elaborates on the area of physical information analogies and introduces new features such as the distance between wave probabilistic functions or sets of new information quantities such as strength, strength moment, strength potential energy and generalized charge. New parameters are used to define the rules for a quantum node. The knowledge cycle, which is equivalent to the Otto thermodynamic cycle, is adopted for modeling of the soft systems together with its static and dynamic information stability. Looking at the closed knowledge cycle, the evolutionary field equivalent to a magnetic field is therefore determined.																	1210-0552						2020	30	2					133	144		10.14311/NNW.2020.30.010													
J								Isosceles Constraints for Person Re-Identification	IEEE TRANSACTIONS ON IMAGE PROCESSING										Feature extraction; Training; Measurement; Robustness; Machine learning; Probes; Task analysis; Person re-identification; isosceles constraint; triplet; quadruplet	MULTITARGET; NETWORK	In the existing works of person re-identification (ReID), batch hard triplet loss has achieved great success. However, it only cares about the hardest samples within the batch. For any probe, there are massive mismatched samples (crucial samples) outside the batch which are closer than the matched samples. To reduce the disruptive influence of crucial samples, we propose a novel isosceles contraint for triplet. Theoretically, we show that if a matched pair has equal distance to any one of mismatched sample, the matched pair should be infinitely close. Motivated by this, the isosceles constraint is designed for the two mismatched pairs of each triplet, to restrict some matched pairs with equal distance to different mismatched samples. Meanwhile, to ensure that the distance of mismatched pairs are larger than the matched pairs, margin constraints are necessary. Minimizing the isosceles and margin constraints with respect to the feature extraction network makes the matched pairs closer and the mismatched pairs farther away than the matched ones. By this way, crucial samples are effectively reduced and the performance on ReID is improved greatly. Likewise, our isosceles contraint can be applied to quadruplet as well. Comprehensive experimental evaluations on Market-1501, DukeMTMC-reID and CUHK03 datasets demonstrate the advantages of our isosceles constraint over the related state-of-the-art approaches.																	1057-7149	1941-0042					2020	29						8930	8943		10.1109/TIP.2020.3020648													
J								A Signal-Processing Framework for Occlusion of 3D Scene to Improve the Rendering Quality of Views	IEEE TRANSACTIONS ON IMAGE PROCESSING										Cameras; Three-dimensional displays; Rendering (computer graphics); Image reconstruction; Computational modeling; Mathematical model; Computer vision; Scene surface occlusion; light ray; signal framework; spectrum analysis; rendering quality of views	FREQUENCY-ANALYSIS; SPECTRAL-ANALYSIS; IMAGE; MODEL	Occlusions will reduce the performance of systems in many computer vision applications with discontinuous surfaces of 3D scenes. We explore a signal-processing framework of occlusions based on the light ray visibility to improve the rendering quality of views. An occlusion field (OCF) theory is derived by calculating the relationship between the occluded light rays and the nonoccluded light rays to quantify the occlusion degree (OCD). The OCF framework can describe the various in-scene information captured by the changes in the camera configuration (i.e., position and direction) through a quantitative description of the occlusion information. From a spectral analysis of the OCF, we mathematically derive analytical functions to determine the changing relationship between the scene and the camera configuration. A reconstruction filter can be designed to achieve interference cancellation and compensate for the missing information caused by the occlusions. Our measurements of different occlusions using this OCF framework included both synthetic and actual scenes. The experimental results show that the proposed OCF framework can improves the rendering quality of views and outperforms other known occlusion quantization schemes in a complex scene.																	1057-7149	1941-0042					2020	29						8944	8959		10.1109/TIP.2020.3020650													
J								Group Sparsity Residual Constraint With Non-Local Priors for Image Restoration	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image restoration; Estimation; Minimization; Dictionaries; Task analysis; Adaptation models; Degradation; Image restoration; group sparse representation; group sparsity residual constraint; nonlocal self-similarity	THRESHOLDING ALGORITHM; K-SVD; REPRESENTATION; REGULARIZATION; RECOVERY	Group sparse representation (GSR) has made great strides in image restoration producing superior performance, realized through employing a powerful mechanism to integrate the local sparsity and nonlocal self-similarity of images. However, due to some form of degradation (e.g., noise, down-sampling or pixels missing), traditional GSR models may fail to faithfully estimate sparsity of each group in an image, thus resulting in a distorted reconstruction of the original image. This motivates us to design a simple yet effective model that aims to address the above mentioned problem. Specifically, we propose group sparsity residual constraint with nonlocal priors (GSRC-NLP) for image restoration. Through introducing the group sparsity residual constraint, the problem of image restoration is further defined and simplified through attempts at reducing the group sparsity residual. Towards this end, we first obtain a good estimation of the group sparse coefficient of each original image group by exploiting the image nonlocal self-similarity (NSS) prior along with self-supervised learning scheme, and then the group sparse coefficient of the corresponding degraded image group is enforced to approximate the estimation. To make the proposed scheme tractable and robust, two algorithms, i.e., iterative shrinkage/thresholding (IST) and alternating direction method of multipliers (ADMM), are employed to solve the proposed optimization problems for different image restoration tasks. Experimental results on image denoising, image inpainting and image compressive sensing (CS) recovery, demonstrate that the proposed GSRC-NLP based image restoration algorithm is comparable to state-of-the-art denoising methods and outperforms several testing image inpainting and image CS recovery methods in terms of both objective and perceptual quality metrics.																	1057-7149	1941-0042					2020	29						8960	8975		10.1109/TIP.2020.3021291													
J								Deep Video Deblurring Using Sharpness Features From Exemplars	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image restoration; Feature extraction; Optical imaging; Decoding; Estimation; Learning systems; Kernel; Video deblurring; optical flow; sharp feature fusion; exemplars		Video deblurring is a challenging problem as the blur in videos is usually caused by camera shake, object motion, depth variation, etc. Existing methods usually impose handcrafted image priors or use end-to-end trainable networks to solve this problem. However, using image priors usually leads to highly non-convex problems while directly using end-to-end trainable networks in a regression generates over-smoothes details in the restored images. In this article, we explore the sharpness features from exemplars to help the blur removal and details restoration. We first estimate optical flow to explore the temporal information which can help to make full use of neighboring information. Then, we develop an encoder and decoder network and explore the sharpness features from exemplars to guide the network for better image restoration. We train the proposed algorithm in an end-to-end manner and show that using sharpness features from exemplars can help blur removal and details restoration. Both quantitative and qualitative evaluations demonstrate that our method performs favorably against state-of-the-art approaches on the benchmark video deblurring datasets and real-world images.																	1057-7149	1941-0042					2020	29						8976	8987		10.1109/TIP.2020.3023534													
J								Deterministic Model Fitting by Local-Neighbor Preservation and Global-Residual Optimization	IEEE TRANSACTIONS ON IMAGE PROCESSING										Data models; Computational modeling; Analytical models; Optimization; Approximation algorithms; Computer vision; Task analysis; Model fitting; local-neighbor preservation; global-residual optimization; min-hash; multiple-structure data	ROBUST; CONSENSUS; SEGMENTATION; MAXIMIZATION	Geometric model fitting has been widely used in many computer vision tasks. However, it remains as a challenging task when handing multiple-structural data contaminated by noises and outliers. Most previous work on model fitting cannot guarantee the consistency of their solutions due to their randomness, precluding them from many real-world applications. In this research, we propose a fast two-view approximately deterministic model fitting scheme (called LGF), to provide consistent solutions for multiple-structural data. The proposed LGF scheme starts from defining preference function by preserving local neighborhood relationship, and then adopts the min-hash technique to roughly sample subsets. By this way, it is able to cover all model instances in data in the parameter space with a high probability. After that, LGF refines the previous sampled subsets by global-residual optimization. Furthermore, we propose a simple yet effective model selection framework to estimate the number and the parameters of model instances in data. Extensive experiments on real images show that the proposed LGF scheme is able to observe superior or very competitive performance on both accuracy and speed over several state-of-the-art model fitting methods.																	1057-7149	1941-0042					2020	29						8988	9001		10.1109/TIP.2020.3023576													
J								Robust Face Super-Resolution via Position Relation Model Based on Global Face Context	IEEE TRANSACTIONS ON IMAGE PROCESSING										Faces; Image resolution; Image reconstruction; Degradation; Context modeling; Topology; Robustness; Face super-resolution; mapping relationship; global constraint; face position	HALLUCINATING FACE; IMAGE	Because Face Super-Resolution (FSR) tends to infer High-Resolution (HR) face image by breaking the given Low-Resolution (LR) image into individual patches and inferring the HR correspondence one patch by one separately, Super-Resolution (SR) of face images with serious degradation, especially with occlusion, is still a challenging problem of the computer vision field. To address this problem, we propose a patch-level face model for FSR, which we called the position relation model. This model consists of the mapping relationships in every face position to the rest of the face positions based on similarity. In other words, we build a constraint for each patch position via the relationship in this model from the global range of face. Once an individual input LR image patch is seriously deteriorated, the substitute patch in whole face range can be sought according to the relationship of the model at this position as the provider of the LR information. In this way, the lost facial structures can be compensated by knowledge located in remote pixels or structure information which leads to better high-resolution face images. The LR images with degradations, not only the serious low-quality degradation, e.g. noise, blur, but also the occlusions, can be effectively hallucinated into HR ones. Quantitative and qualitative evaluations on the public datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.																	1057-7149	1941-0042					2020	29						9002	9016		10.1109/TIP.2020.3023580													
J								Learning Long-Term Structural Dependencies for Video Salient Object Detection	IEEE TRANSACTIONS ON IMAGE PROCESSING										Predictive models; Object detection; Feature extraction; Saliency detection; Convolution; Merging; Object recognition; Video salient object detection; graph convolutional network; supervoxel	SEGMENTATION; OPTIMIZATION	Existing video salient object detection (VSOD) methods focus on exploring either short-term or long-term temporal information. However, temporal information is exploited in a global frame-level or regular grid structure, neglecting inter-frame structural dependencies. In this article, we propose to learn long-term structural dependencies with a structure-evolving graph convolutional network (GCN). Particularly, we construct a graph for the entire video using a fast supervoxel segmentation method, in which each node is connected according to spatio-temporal structural similarity. We infer the inter-frame structural dependencies of salient object using convolutional operations on the graph. To prune redundant connections in the graph and better adapt to the moving salient object, we present an adaptive graph pooling to evolve the structure of the graph by dynamically merging similar nodes, learning better hierarchical representations of the graph. Experiments on six public datasets show that our method outperforms all other state-of-the-art methods. Furthermore, We also demonstrate that our proposed adaptive graph pooling can effectively improve the supervoxel algorithm in the term of segmentation accuracy.																	1057-7149	1941-0042					2020	29						9017	9031		10.1109/TIP.2020.3023591													
J								Exploring Task Structure for Brain Tumor Segmentation From Multi-Modality MR Images	IEEE TRANSACTIONS ON IMAGE PROCESSING										Tumors; Task analysis; Image segmentation; Three-dimensional displays; Brain modeling; Two dimensional displays; Semantics; Machine vision; object segmentation; image analysis; supervised learning	OBJECT DETECTION	Brain tumor segmentation, which aims at segmenting the whole tumor area, enhancing tumor core area, and tumor core area from each input multi-modality bio-imaging data, has received considerable attention from both academia and industry. However, the existing approaches usually treat this problem as a common semantic segmentation task without taking into account the underlying rules in clinical practice. In reality, physicians tend to discover different tumor areas by weighing different modality volume data. Also, they initially segment the most distinct tumor area, and then gradually search around to find the other two. We refer to the first property as the task-modality structure while the second property as the task-task structure, based on which we propose a novel task-structured brain tumor segmentation network (TSBTS net). Specifically, to explore the task-modality structure, we design a modality-aware feature embedding mechanism to infer the important weights of the modality data during network learning. To explore the task-task structure, we formulate the prediction of the different tumor areas as conditional dependency sub-tasks and encode such dependency in the network stream. Experiments on BraTS benchmarks show that the proposed method achieves superior performance in segmenting the desired brain tumor areas while requiring relatively lower computational costs, compared to other state-of-the-art methods and baseline models.																	1057-7149	1941-0042					2020	29						9032	9043		10.1109/TIP.2020.3023609													
J								Robust Low-Rank Tensor Recovery via Nonconvex Singular Value Minimization	IEEE TRANSACTIONS ON IMAGE PROCESSING										Tensile stress; Robustness; Optimization; Minimization; Signal processing algorithms; Principal component analysis; Matrix decomposition; Low-rank; tensor recovery; tensor factorization; nonconvex optimization	MATRIX COMPLETION; NORM; FACTORIZATION; EFFICIENT; IMAGE	Tensor robust principal component analysis via tensor nuclear norm (TNN) minimization has been recently proposed to recover the low-rank tensor corrupted with sparse noise/outliers. TNN is demonstrated to be a convex surrogate of rank. However, it tends to over-penalize large singular values and thus usually results in biased solutions. To handle this issue, we propose a new definition of tensor logarithmic norm (TLN) as the nonconvex surrogate of rank, which can decrease the penalization on larger singular values and increase that on smaller ones simultaneously to preserve the low-rank structure of a tensor. Then, the strategy of tensor factorization is combined into the minimization of TLN to improve computational performance. To handle impulsive scenarios, we propose a nonconvex l(p)-ball projection scheme with 0 < p < 1 instead of the conventional convex scheme with p = 1, which enhances the robustness against outliers. By incorporating the TLN minimization and the l(p)-ball projection, we finally propose two low-rank recovery algorithms, whose resulting optimization problems are efficiently solved by the alternating direction method of multipliers (ADMM) with convergence guarantees. The proposed algorithms are applied to the synthetic data recovery and image and video restorations in real-world. Experimental results demonstrate the superior performance of the proposed methods over several state-of-the-art algorithms in terms of tensor recovery accuracy and computational efficiency.																	1057-7149	1941-0042					2020	29						9044	9059		10.1109/TIP.2020.3023798													
J								Pose-Guided Person Image Synthesis in the Non-Iconic Views	IEEE TRANSACTIONS ON IMAGE PROCESSING										Task analysis; Image generation; Visualization; Biological system modeling; Computational modeling; Training; Image reconstruction; Image processing; image generation		Generating realistic images with the guidance of reference images and human poses is challenging. Despite the success of previous works on synthesizing person images in the iconic views, no efforts are made towards the task of pose-guided image synthesis in the non-iconic views. Particularly, we find that previous models cannot handle such a complex task, where the person images are captured in the non-iconic views by commercially-available digital cameras. To this end, we propose a new framework - Multi-branch Refinement Network (MR-Net), which utilizes several visual cues, including target person poses, foreground person body and scene images parsed. Furthermore, a novel Region of Interest (RoI) perceptual loss is proposed to optimize the MR-Net. Extensive experiments on two non-iconic datasets, Penn Action and BBC-Pose, as well as an iconic dataset - Market-1501, show the efficacy of the proposed model that can tackle the problem of pose-guided person image generation from the non-iconic views. The data, models, and codes are downloadable from https://github.com/loadder/MR-Net.																	1057-7149	1941-0042					2020	29						9060	9072		10.1109/TIP.2020.3023853													
J								Exploring communication protocols and centralized critics in multi-agent deep learning	INTEGRATED COMPUTER-AIDED ENGINEERING										Multi-agent systems; neural networks; emergent communication; deep reinforcement learning	NEURAL DYNAMIC CLASSIFICATION; ALGORITHMS; NETWORK; AGENTS; ROBOT	Tackling multi-agent environments where each agent has a local limited observation of the global state is a non-trivial task that often requires hand-tuned solutions. A team of agents coordinating in such scenarios must handle the complex underlying environment, while each agent only has partial knowledge about the environment. Deep reinforcement learning has been shown to achieve super-human performance in single-agent environments, and has since been adapted to the multi-agent paradigm. This paper proposes A3C3, a multi-agent deep learning algorithm, where agents are evaluated by a centralized referee during the learning phase, but remain independent from each other in actual execution. This referee's neural network is augmented with a permutation invariance architecture to increase its scalability to large teams. A3C3 also allows agents to learn communication protocols with which agents share relevant information to their team members, allowing them to overcome their limited knowledge, and achieve coordination. A3C3 and its permutation invariant augmentation is evaluated in multiple multi-agent test-beds, which include partially-observable scenarios, swarm environments, and complex 3D soccer simulations.																	1069-2509	1875-8835					2020	27	4					333	351		10.3233/ICA-200631													
J								Motivation as a tool for designing lifelong learning robots	INTEGRATED COMPUTER-AIDED ENGINEERING										Open-ended learning; motivation; lifelong learning; autonomous robots	COGNITIVE DEVELOPMENTAL ROBOTICS; REINFORCEMENT	Designing robots has usually implied knowing beforehand the tasks to be carried out and in what domains. However, in the case of fully autonomous robots this is not possible. Autonomous robots need to operate in an open-ended manner, that is, deciding on the most interesting goals to achieve in domains that are not known at design time. This obviously poses a challenge from the point of view of designing the robot control structure. In particular, the main question that arises is how to endow the robot with a designer defined purpose and with means to translate that purpose into operational decisions without any knowledge of what situations the robot will find itself in. In this paper, we provide a formalization of motivation from an engineering perspective that allows for the structured design of purposeful robots. This formalization is based on a definition of the concepts of robot needs and drives, which are related through experience to the appropriate goals in specific domains. To illustrate the process, a motivational system to guide the operation of a real robot is constructed using this approach. A series of experiments carried out over it are discussed providing some insights on the design of purposeful motivated operation.																	1069-2509	1875-8835					2020	27	4					353	372		10.3233/ICA-200633													
J								Deep learning-based video surveillance system managed by low cost hardware and panoramic cameras	INTEGRATED COMPUTER-AIDED ENGINEERING										Foreground detection; feed forward neural network; panoramic camera; convolutional neural network	MOTION DETECTION; BACKGROUND SUBTRACTION; NEURAL-NETWORKS; CRACK DETECTION; RECOGNITION; SENSOR; TRACKING; MODEL	The design of automated video surveillance systems often involves the detection of agents which exhibit anomalous or dangerous behavior in the scene under analysis. Models aimed to enhance the video pattern recognition abilities of the system are commonly integrated in order to increase its performance. Deep learning neural networks are found among the most popular models employed for this purpose. Nevertheless, the large computational demands of deep networks mean that exhaustive scans of the full video frame make the system perform rather poorly in terms of execution speed when implemented on low cost devices, due to the excessive computational load generated by the examination of multiple image windows. This work presents a video surveillance system aimed to detect moving objects with abnormal behavior for a panoramic 360 degrees surveillance camera. The block of the video frame to be analyzed is determined on the basis of a probabilistic mixture distribution comprised by two mixture components. The first component is a uniform distribution, which is in charge of a blind window selection, while the second component is a mixture of kernel distributions. The kernel distributions generate windows within the video frame in the vicinity of the areas where anomalies were previously found. This contributes to obtain candidate windows for analysis which are close to the most relevant regions of the video frame, according to the past recorded activity. A Raspberry Pi microcontroller based board is employed to implement the system. This enables the design and implementation of a system with a low cost, which is nevertheless capable of performing the video analysis with a high video frame processing rate.																	1069-2509	1875-8835					2020	27	4					373	387		10.3233/ICA-200632													
J								Deep support vector neural networks	INTEGRATED COMPUTER-AIDED ENGINEERING										Support vector machines; deep learning	CLASSIFICATION	Kernel based Support Vector Machines, SVM, one of the most popular machine learning models, usually achieve top performances in two-class classification and regression problems. However, their training cost is at least quadratic on sample size, making them thus unsuitable for large sample problems. However, Deep Neural Networks (DNNs), with a cost linear on sample size, are able to solve big data problems relatively easily. In this work we propose to combine the advanced representations that DNNs can achieve in their last hidden layers with the hinge and epsilon insensitive losses that are used in two-class SVM classification and regression. We can thus have much better scalability while achieving performances comparable to those of SVMs. Moreover, we will also show that the resulting Deep SVM models are competitive with standard DNNs in two-class classification problems but have an edge in regression ones.																	1069-2509	1875-8835					2020	27	4					389	402		10.3233/ICA-200635													
J								Shallow buried improvised explosive device detection via convolutional neural networks	INTEGRATED COMPUTER-AIDED ENGINEERING										Land mine detection; convolutional neural network; land sensing; image processing; improvised explosive device	MODEL; CLASSIFICATION; RECOGNITION; OBJECTS; NOISE	The issue of detecting improvised explosive devices, henceforth IEDs, in rural or built-up urban environments is a persistent and serious concern for governments in the developing world. In many cases, such devices are plastic, or varied metallic objects containing rudimentary explosives, which are not visible to the naked eye and are difficult to detect autonomously. The most effective strategy for detecting land mines also happens to be the most dangerous. This paper intends to leverage the use of a Convolutional Neural Network (CNN) to aid in the discovery of such IEDs. As part of a related project, an autonomous sensor array was used to detect the devices in terrains too hazardous for a human to survey. This paper presents a CNN and its training methodology, suitable to make use of the sensor system. This convolutional neural network can accurately distinguish between a potential IED and surrounding undergrowth and natural features of the environment in real-time. The training methodology enabled the CNN to successfully recognise the IEDs with an accuracy of 98.7%, in well-lit conditions. The results are evaluated against other convolutional neural systems as well as against a deterministic algorithm, showing that the proposed CNN outperforms its competitors including the deterministic method.																	1069-2509	1875-8835					2020	27	4					403	416		10.3233/ICA-200638													
J								3D mesh simplification with feature preservation based on Whale Optimization Algorithm and Differential Evolution	INTEGRATED COMPUTER-AIDED ENGINEERING										3D mesh simplification; geometric feature preservation; 'undo/redo' mechanism; objective optimization	EFFICIENT; SELECTION	Large-scale 3D models consume large computing and storage resources. To address this challenging problem, this paper proposes a new method to obtain the optimal simplified 3D mesh models with the minimum approximation error. First, we propose a feature-preservation edge collapse operation to maintain the feature edges, in which the collapsing cost is calculated in a novel way by combining Gauss curvature and Quadratic Error Metrics (QEM). Second, we introduce the edge splitting operation into the mesh simplification process and propose a hybrid 'undo/redo' mechanism that combines the edge splitting and edge collapse operation to reduce the number of long and narrow triangles. Third, the proposed 'undo/redo' mechanism can also reduce the approximation error; however, it is impossible to manually choose the best operation sequence combination that can result in the minimum approximation error. To solve this problem, we formulate the proposed mesh simplification process as an optimization model, in which the solution space is composed of the possible combinations of operation sequences, and the optimization objective is the minimum of the approximation error. Finally, we propose a novel optimization algorithm, WOA-DE, by replacing the exploration phase of the original Whale Optimization Algorithm (WOA) with the mutate and crossover operations of Differential Evolution (DE) to compute the optimal simplified mesh model more efficiently. We conduct numerous experiments to test the capabilities of the proposed method, and the experimental results show that our method outperforms the previous methods in terms of the geometric feature preservation, triangle quality, and approximation error.																	1069-2509	1875-8835					2020	27	4					417	435		10.3233/ICA-200641													
J								AFFECTIVE SYMPTOMS AND POSTURAL ABNORMALITIES AS PREDICTORS OF HEADACHE: AN APPLICATION OF ARTIFICIAL NEURAL NETWORKS	NEURAL NETWORK WORLD										affective symptoms; postural abnormalities; headache; artificial neural networks; auto contractive maps	QUALITY-OF-LIFE; MIGRAINE; COMORBIDITY; DEPRESSION; ANXIETY; DISEASE; BURDEN; EUROPE	Chronic headache is a major liability in the individuals' quality of life. Identifying in advance the main features common to patients with headache may allow planning a preventive strategy of intervention. An artificial neural network model (Auto Contractive Maps - AutoCM), aimed at analyzing the correlations between patients' characteristics, affective symptoms and posture indicators has been developed in this paper. Patients suffering from chronic headache were observed at a neurological centre in Sicily (Italy). Headache and affective states were measured using the Profile of Mood States (POMS), the Beck Depression Inventory (BDI), the Toronto Alexithymia Scale (TAS-20) and the Repression Scale. Postural evaluations were carried through a stabilometric platform. The method of analysis selected allowed to reconstruct some records that were missing, through a Recirculation AutoAssociative Neural Network, and to obtain sound results. The results showed how some items from TAS-20, Repression and POMS were closely linked. The postural abnormalities were correlated primarily with repression features. The highest scores of the POMS were correlated with the items of the BDI. The results obtained lead to interesting remarks about the common traits to patients with headache. The main conclusion lies in the potentialities offered by the new methodology applied, that may contribute, overall, to a better understanding of the complexity of chronic diseases, where many factors concur to define patients' health conditions.																	1210-0552						2020	30	1					1	26		10.14311/NNW.2020.30.001													
J								HIGH-ACCURACY MOTION CONTROL OF A MOTOR SERVO SYSTEM WITH DEAD-ZONE BASED ON A SINGLE HIDDEN LAYER NEURAL NETWORK	NEURAL NETWORK WORLD										neural network; motion control; dead zone; adaptive control; parametric uncertainty	ASYMPTOTIC TRACKING CONTROL; ADAPTIVE ROBUST-CONTROL; SLIDING MODE CONTROL; NONLINEAR-SYSTEMS; DC MOTORS; ACTUATORS; SIMULATOR; DESIGN; STATE	There always exist parametric uncertainties, bounded disturbances and some other unknown nonlinearities such as the input dead-zone in physical motor servo systems, which can degrade the system's control performance. In this paper, a composite control strategy is proposed for high-accuracy motion control of a torque-controlled motor servo system with dead-zone. A smooth and continuous mathematical model is used to provide an approximate inverse transformation of the input-output dead-zone needed for feedback linearization. A single-layer neural network capable of on-line learning is designed to compensate for the inversion error, which comes from the approximate inversion. A stable weights adaption law for the on-line neural network is derived. In addition, a parameter adaptation law is also derived for handling the parametric uncertainty, and a nonlinear robust feedback term is designed to inhibit the influence of the imperfect modeling, compensation error or other disturbances. Lyapunov theorem is used to prove the stability of the proposed control algorithm with the weights and parameters adaptation law. Extensive comparative simulation results are used to illustrate the effectiveness and advancement of the proposed controller compared with several other main-stream controllers.																	1210-0552						2020	30	1					27	44		10.14311/NNW.2020.30.002													
J								PARAMETRIC SENSITIVITY IN DECISION MAKING PROCESS	NEURAL NETWORK WORLD										production function; information; knowledge; Tinbergen; sensitivity; decision making; managing systems; business processes		This paper introduces a possibility of application of parametric sensitivity appearing in processes of decision making in systems represented by the general production functions of the Tinbergen type, depending on information content, information flow and qualification of human resources. The so-called parametric sensitivity considering the information content I as an ordering parameter, dependent on the information flow phi, applied on production function. The theory of production function describes the relation between physical outputs of a production process and physical inputs, i.e. factors of production. Finally, the influence of knowledge in information content I, leading to correct decision, is demonstrated through the parametric sensitivity concept. For this invention, J. Tinbergen and R. Frisch achieved in 1969 the "Nobel price of the Swedish National Bank". Besides, the production functions theory surprisingly represents also a tool for finding the reasons of living bodies behavior.																	1210-0552						2020	30	1					45	53		10.14311/NNW.2020.30.003													
J								WAVE COMPOSITION RULES IN QUANTUM SYSTEM THEORY	NEURAL NETWORK WORLD										quantum system theory; quantum information systems; information power; information physics; self-organization; composition rules		The paper presents the new approach to wave composition rules for advanced modeling of soft systems in quantum system theory. Firstly, the interpretation of phase parameters is given. The phase parameters are essential to specify the mathematical operations assigned to different relations among subsystems, e.g. co-operation, connection, co-existence, competition. Using wave composition rules, we are able to create more complex and sophisticated quantum circuits. We present the application of methodology on three illustrative examples.																	1210-0552						2020	30	1					55	64		10.14311/NNW.2020.30.004													
J								UNSUPERVISED FACIAL EXPRESSION DETECTION USING GENETIC ALGORITHM	NEURAL NETWORK WORLD										facial expressions; facial sentiment detection; digital image processing; color format; genetic algorithm	RECOGNITION; FEATURES	Interpersonal communication can be done by understanding the clues of facial expressions. As its importance increase in behavior and clinical studies, so automatic detection of facial expressions is an open research area for the last few decades. Efforts of expression detection by a human being are easy and effective but the machine needs some more understanding. This paper proposes a face expression clustering using a genetic algorithm. Image get convert into binary format for finding the related cluster selection in different phases of genetic algorithm. Proposed work has utilized a modified teacher learning-based optimization algorithm where the population gets updated in each phase to get the best representative features. A real dataset of facial expression was used in this work. A comparison of the proposed model was done with existing models on different evaluation parameters. It was obtained that the proposed work has improved precision, recall, the accuracy of facial expression identification without any training.																	1210-0552						2020	30	1					65	75		10.14311/NNW.2020.30.005													
J								REPRESENTATION LEARNING OF KNOWLEDGE GRAPHS USING CONVOLUTIONAL NEURAL NETWORKS	NEURAL NETWORK WORLD										convolutional neural network; knowledge representation learning; knowledge base; attention		Knowledge graphs have been playing an important role in many Artificial Intelligence (AI) applications such as entity linking, question answering and so forth. However, most of previous studies focused on the symbolic representation of knowledge graphs with structural information, which cannot deal well with new entities or rare entities with little relevant knowledge. In this paper, we propose a new deep knowledge representation architecture that jointly encodes both structure and textual information. We first propose a novel neural model to encode the text descriptions of entities based on Convolutional Neural Networks (CNN). Secondly, an attention mechanism is applied to capture the valuable information from these descriptions. Then we introduce position vectors as supplementary information. Finally, a gate mechanism is designed to integrate representations of structure and text into the joint representation. Experimental results on two datasets show that our models obtain state-of-the-art results on link prediction and triplet classification tasks, and achieve the best performance on the relation classification task.																	1210-0552						2020	30	3					145	160		10.14311/NNW.2020.30.011													
J								AN EFFICIENT METHOD FOR SURFACE RECONSTRUCTION BASED ON LOCAL COORDINATE SYSTEM TRANSFORM AND PARTITION OF UNITY	NEURAL NETWORK WORLD										surface reconstruction; radial basis function; partition of unity; local coordinate system transform	RADIAL BASIS FUNCTIONS; IMPLICIT	Radial basis function (RBF) has been extensively applied for surface reconstruction from scattered 3D point data due to its strong ability of approximation. However, additional information, such as off-surface points, are usually required to be appended into constraints for determining the parameters, which apparently increases the computation cost and data unreliability. To avoid adding additional off surface point constraints, a novel surface reconstruction approach based on local coordinate system transform and partition of unity is proposed in this paper. Firstly, the explicit RBF functions are constructed to approximate the local surface patches, and then it is transformed into an equivalent implicit surface reconstruction form by local system coordinate transformation. Compared with the local implicit surface approximation, the proposed local explicit surface approximation method is capable of avoiding trivial solution occurred in RBF approximating, and does not increase the scale of data solution. A number of comparison experiments of the proposed method with the traditional RBF-based method and the multi-level partition of unity (MPU) method are carried out on some kinds of large dataset, non-uniformity dataset, noisy dataset. The experimental results illustrate that the proposed method is robust and effective in dealing with large-scale point clouds surface reconstruction.																	1210-0552						2020	30	3					161	176		10.14311/NNW.2020.30.012													
J								ROBUST AND FRAGILE WATERMARKING FOR MEDICAL IMAGES USING REDUNDANT RESIDUE NUMBER SYSTEM AND CHAOS	NEURAL NETWORK WORLD										medical image watermarking; fragility; robustness; RNS; RRNS; Chinese Remainder Theorem (CRT); chaotic function	CODING THEORY APPROACH; ERROR CONTROL; INTEGRITY	This research discusses a novel watermarking scheme using redundant residue number system and chaos. The salient feature of said research is that image remains fragile while the watermark information is made robust. Image pixels are converted into residues so that the unaided eye could not see the image contents. To make the image invisible to the unaided eye, only the ROI part of image is passed through the Residue Number System thus, to enhance the secrecy of the image. While converting the ROI part of image into residues, there are some residues which exceed eight bits so, these residues are converted to exact eight bits by pertaining some intelligent mechanism. To achieve the robustness of watermark, firstly redundant residues of watermark are made and then the resultant watermark is encoded through error correcting codes. To achieve the fragility of image, hashing technique is utilized. Hash of the entire image but with the residued ROI is combined with the encoded and redundant residued watermark and then resultant watermark is embedded in the Region of non-interest (RONI) zone of native image rooted on the chaotic key in order to enhance the security of the watermark. In case of no tampering, fragile watermark can be successfully recovered as well as exact recovery of the original image but if the image is attacked, the fragile watermark is destroyed while the robust watermark is extracted with better readability.																	1210-0552						2020	30	3					177	192		10.14311/NNW.2020.30.013													
J								FLOPPY LOGIC AS A GENERALIZATION OF STANDARD BOOLEAN LOGIC	NEURAL NETWORK WORLD										floppy logic; fuzzy logic; multi-valued logic; probabilistic logic; rules of inference; modus ponens; modus tollens		The topic of this article is a floppy logic, a new multi-valued logic. Floppy logic is related to fuzzy logic and the theory of probability, but it also has interesting links to probability logic and standard Boolean logic. It provides a consistent and simple theory that is easy to apply in practice. This article examines the isomorphism theorem, which plays an important role in floppy logic. The theorem is described and proved. The most important consequences of the isomorphism theorem are: 1) All statements which are equivalent in standard Boolean logic are also equivalent in floppy logic. 2) Floppy logic has all the properties of standard Boolean logic which can be formulated as an equivalence. These include, for example, distributivity, the contradiction law, the law of excluded middle, and others. The article mainly examines floppy implication. We show that floppy implication does not satisfy Adam's Thesis and that floppy logic is not limited by Lewis' triviality result. We also present a range of inference rules which are generalizations of modus ponens and modus tollens. These rules hold in floppy logic, and of course, also apply to standard Boolean logic. All these results lead us to the notion that floppy logic is a many-valued generalization of standard Boolean logic.																	1210-0552						2020	30	3					193	209		10.14311/NNW.2020.30.014													
J								Adaptive Graph Representation Learning for Video Person Re-Identification	IEEE TRANSACTIONS ON IMAGE PROCESSING										Feature extraction; Adaptation models; Context modeling; Three-dimensional displays; Deep learning; Visualization; Video person re-identification; graph neural network; consistency		Recent years have witnessed the remarkable progress of applying deep learning models in video person re-identification (Re-ID). A key factor for video person Re-ID is to effectively construct discriminative and robust video feature representations for many complicated situations. Part-based approaches employ spatial and temporal attention to extract representative local features. While correlations between parts are ignored in the previous methods, to leverage the relations of different parts, we propose an innovative adaptive graph representation learning scheme for video person Re-ID, which enables the contextual interactions between relevant regional features. Specifically, we exploit the pose alignment connection and the feature affinity connection to construct an adaptive structure-aware adjacency graph, which models the intrinsic relations between graph nodes. We perform feature propagation on the adjacency graph to refine regional features iteratively, and the neighbor nodes' information is taken into account for part feature representation. To learn compact and discriminative representations, we further propose a novel temporal resolution-aware regularization, which enforces the consistency among different temporal resolutions for the same identities. We conduct extensive evaluations on four benchmarks, i.e. iLIDS-VID, PRID2011, MARS, and DukeMTMC-VideoReID, experimental results achieve the competitive performance which demonstrates the effectiveness of our proposed method. Code is available at https://github.com/weleen/AGRL.pytorch.																	1057-7149	1941-0042					2020	29						8821	8830		10.1109/TIP.2020.3001693													
J								PNEN: Pyramid Non-Local Enhanced Networks	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image resolution; Correlation; Task analysis; Smoothing methods; Neural networks; Image edge detection; Image restoration; non-local; deep convolutional neural networks		Existing neural networks proposed for low-level image processing tasks are usually implemented by stacking convolution layers with limited kernel size. Every convolution layer merely involves in context information from a small local neighborhood. More contextual features can be explored as more convolution layers are adopted. However it is difficult and costly to take full advantage of long-range dependencies. We propose a novel non-local module, Pyramid Non-local Block, to build up connection between every pixel and all remain pixels. The proposed module is capable of efficiently exploiting pairwise dependencies between different scales of low-level structures. The target is fulfilled through first learning a query feature map with full resolution and a pyramid of reference feature maps with downscaled resolutions. Then correlations with multi-scale reference features are exploited for enhancing pixel-level feature representation. The calculation procedure is economical considering memory consumption and computational cost. Based on the proposed module, we devise a Pyramid Non-local Enhanced Networks for edge-preserving image smoothing which achieves state-of-the-art performance in imitating three classical image smoothing algorithms. Additionally, the pyramid non-local block can be directly incorporated into convolution neural networks for other image restoration tasks. We integrate it into two existing methods for image denoising and single image super-resolution, achieving consistently improved performance.																	1057-7149	1941-0042					2020	29						8831	8841		10.1109/TIP.2020.3019644													
J								Learning a Single Model With a Wide Range of Quality Factors for JPEG Image Artifacts Removal	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image coding; Q-factor; Image restoration; Transform coding; Image quality; Quantization (signal); Feature extraction; Compression artifacts removal; deep learning; quantization table	SPARSE REPRESENTATION; REDUCTION	Lossy compression brings artifacts into the compressed image and degrades the visual quality. In recent years, many compression artifacts removal methods based on convolutional neural network (CNN) have been developed with great success. However, these methods usually train a model based on one specific value or a small range of quality factors. Obviously, if the test images quality factor does not match to the assumed value range, then degraded performance will be resulted. With this motivation and further consideration of practical usage, a highly robust compression artifacts removal network is proposed in this article. Our proposed network is a single model approach that can be trained for handling a wide range of quality factors while consistently delivering superior or comparable image artifacts removal performance. To demonstrate, we focus on the JPEG compression with quality factors, ranging from 1 to 60. Note that a turnkey success of our proposed network lies in the novel utilization of the quantization tables as part of the training data. Furthermore, it has two branches in parallel-i.e., the restoration branch and the global branch. The former effectively removes the local artifacts, such as ringing artifacts removal. On the other hand, the latter extracts the global features of the entire image that provides highly instrumental image quality improvement, especially effective on dealing with the global artifacts, such as blocking, color shifting. Extensive experimental results performed on color and grayscale images have clearly demonstrated the effectiveness and efficacy of our proposed single-model approach on the removal of compression artifacts from the decoded image.																	1057-7149	1941-0042					2020	29						8842	8854		10.1109/TIP.2020.3020389													
J								Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds Using Spatial-Aware Capsules	IEEE TRANSACTIONS ON IMAGE PROCESSING										Three-dimensional displays; Feature extraction; Shape; Routing; Aggregates; Machine learning; Spatial resolution; Point cloud; shape representation; feature aggregation; spatial relationships; capsule network	3D; NETWORK	Learning discriminative shape representation directly on point clouds is still challenging in 3D shape analysis and understanding. Recent studies usually involve three steps: first splitting a point cloud into some local regions, then extracting the corresponding feature of each local region, and finally aggregating all individual local region features into a global feature as shape representation using simple max-pooling. However, such pooling-based feature aggregation methods do not adequately take the spatial relationships (e.g. the relative locations to other regions) between local regions into account, which greatly limits the ability to learn discriminative shape representation. To address this issue, we propose a novel deep learning network, named Point2SpatialCapsule, for aggregating features and spatial relationships of local regions on point clouds, which aims to learn more discriminative shape representation. Compared with the traditional max-pooling based feature aggregation networks, Point2SpatialCapsule can explicitly learn not only geometric features of local regions but also the spatial relationships among them. Point2SpatialCapsule consists of two main modules. To resolve the disorder problem of local regions, the first module, named geometric feature aggregation, is designed to aggregate the local region features into the learnable cluster centers, which explicitly encodes the spatial locations from the original 3D space. The second module, named spatial relationship aggregation, is proposed for further aggregating the clustered features and the spatial relationships among them in the feature space using the spatial-aware capsules developed in this article. Compared to the previous capsule network based methods, the feature routing on the spatial-aware capsules can learn more discriminative spatial relationships among local regions for point clouds, which establishes a direct mapping between log priors and the spatial locations through feature clusters. Experimental results demonstrate that Point2SpatialCapsule outperforms the state-of-the-art methods in the 3D shape classification, retrieval and segmentation tasks under the well-known ModelNet and ShapeNet datasets.																	1057-7149	1941-0042					2020	29						8855	8869		10.1109/TIP.2020.3019925													
J								Complexity of Shapes Embedded in Z(n) With a Bias Towards Squares	IEEE TRANSACTIONS ON IMAGE PROCESSING										ARS-RBS morphological analysis methods; shape models and metrics; TEC-PDE partial differential equation based processing; level set methods; OTH-EMR complexity; TEC-FIL nonlinear filtering; TEC-FOR reconstructibility	VISUAL COMPLEXITY; FRACTAL DIMENSION	Shape complexity is a hard-to-quantify quality, mainly due to its relative nature. Biased by Euclidean thinking, circles are commonly considered as the simplest. However, their constructions as digital images are only approximations to the ideal form. Consequently, complexity orders computed in reference to circle are unstable. Unlike circles which lose their circleness in digital images, squares retain their qualities. Hence, we consider squares (hypercubes in Z(n)) to be the simplest shapes relative to which complexity orders are constructed. Using the connection between L-infinity norm and squares we effectively encode squareness-adapted simplification through which we obtain multi-scale complexity measure, where scale determines the level of interest to the boundary. The emergent scale above which the effect of a boundary feature (appendage) disappears is related to the ratio of the contacting width of the appendage to that of the main body. We discuss what zero complexity implies in terms of information repetition and constructibility and what kind of shapes in addition to squares have zero complexity.																	1057-7149	1941-0042					2020	29						8870	8879		10.1109/TIP.2020.3021316													
J								Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting	IEEE TRANSACTIONS ON IMAGE PROCESSING										Forecasting; Predictive models; Training; Uncertainty; Task analysis; Robots; Data models; Action forecasting; weakly supervised learning; action sequence forecasting		Future human action forecasting from partial observations of activities is an important problem in many practical applications such as assistive robotics, video surveillance and security. We present a method to forecast actions for the unseen future of the video using a neural machine translation technique that uses encoder-decoder architecture. The input to this model is the observed RGB video, and the objective is to forecast the correct future symbolic action sequence. Unlike prior methods that make action predictions for some unseen percentage of video one for each frame, we predict the complete action sequence that is required to accomplish the activity. We coin this task action sequence forecasting. To cater for two types of uncertainty in the future predictions, we propose a novel loss function. We show a combination of optimal transport and future uncertainty losses help to improve results. We evaluate our model in three challenging video datasets (Charades, MPII cooking and Breakfast). We extend our action sequence forecasting model to perform weakly supervised action forecasting on two challenging datasets, the Breakfast and the 50Salads. Specifically, we propose a model to predict actions of future unseen frames without using frame level annotations during training. Using Fisher vector features, our supervised model outperforms the state-of-the-art action forecasting model by 0.83% and 7.09% on the Breakfast and the 50Salads datasets respectively. Our weakly supervised model is only 0.6% behind the most recent state-of-the-art supervised model and obtains comparable results to other published fully supervised methods, and sometimes even outperforms them on the Breakfast dataset. Most interestingly, our weakly supervised model outperforms prior models by 1.04% leveraging on proposed weakly supervised architecture, and effective use of attention mechanism and loss functions.																	1057-7149	1941-0042					2020	29						8880	8891		10.1109/TIP.2020.3021497													
J								Progressive Cross-Modal Semantic Network for Zero-Shot Sketch-Based Image Retrieval	IEEE TRANSACTIONS ON IMAGE PROCESSING										Semantics; Image retrieval; Decoding; Training; Task analysis; Knowledge engineering; Measurement; Zero-shot learning; sketch-based image retrieval; progressive generation		Zero-shot sketch-based image retrieval (ZS-SBIR) is a specific cross-modal retrieval task that involves searching natural images through the use of free-hand sketches under the zero-shot scenario. Most previous methods project the sketch and image features into a low-dimensional common space for efficient retrieval, and meantime align the projected features to their semantic features (e.g., category-level word vectors) in order to transfer knowledge from seen to unseen classes. However, the projection and alignment are always coupled; as a result, there is a lack of explicit alignment that consequently leads to unsatisfactory zero-shot retrieval performance. To address this issue, we propose a novel progressive cross-modal semantic network. More specifically, it first explicitly aligns the sketch and image features to semantic features, then projects the aligned features to a common space for subsequent retrieval. We further employ cross-reconstruction loss to encourage the aligned features to capture complete knowledge about the two modalities, along with multi-modal Euclidean loss that guarantees similarity between the retrieval features from a sketch-image pair. Extensive experiments conducted on two popular large-scale datasets demonstrate that our proposed approach outperforms state-of-the-art competitors to a remarkable extent: by more than 3% on the Sketchy dataset and about 6% on the TU-Berlin dataset in terms of retrieval accuracy.																	1057-7149	1941-0042					2020	29						8892	8902		10.1109/TIP.2020.3020383													
J								Efficient and Accurate 3D Finger Knuckle Matching Using Surface Key Points	IEEE TRANSACTIONS ON IMAGE PROCESSING										Hand biometrics; 3D finger knuckle recognition; key points extraction; templates matching	PALMPRINT; SCHEME	Contactless 3D finger knuckle is a new biometric identifier which can offer an accurate, efficient and convenient alternative for the personal identification. The current 3D finger knuckle recognition methods are limited by computationally complex or inefficient matching algorithms, which attempt to compute the matching scores from all possible translational and rotational parameters for matching a pair of templates. The strength of such approach lies in its simplicity and reliability for accurately matching intra-class samples, but expensive computational time is required. Furthermore, attempting on excessive numbers of translational and rotational parameters can also degrade the overall recognition accuracy because the imposter matches can be increased. In fact, this conventional matching approach is commonly adopted in many biometric studies, but its drawbacks have not received adequate attention. This article addresses such 3D finger knuckle recognition problem by developing a more efficient matching approach using surface key points extracted from 3D finger knuckle surfaces. Our comparative experimental results with the state-of-the art method on a publicly available 3D finger knuckle database indicates that our approach can offer over 23 times faster with performance improvement on the accuracy. Although the focus of our work is on 3D finger knuckle recognition, we also present the performance of our method on other publicly available databases with similar 3D biometric patterns including 3D palmprint and 3D fingerprint, to validate the effectiveness of the proposed approach.																	1057-7149	1941-0042					2020	29						8903	8915		10.1109/TIP.2020.3021294													
J								Unified Generative Adversarial Networks for Controllable Image-to-Image Translation	IEEE TRANSACTIONS ON IMAGE PROCESSING										Gallium nitride; Task analysis; Generators; Skeleton; Semantics; Image generation; Generative adversarial networks; GANs; controllable structure; image-to-image translation		We propose a unified Generative Adversarial Network (GAN) for controllable image-to-image translation, i.e., transferring an image from a source to a target domain guided by controllable structures. In addition to conditioning on a reference image, we show how the model can generate images conditioned on controllable structures, e.g., class labels, object keypoints, human skeletons, and scene semantic maps. The proposed model consists of a single generator and a discriminator taking a conditional image and the target controllable structure as input. In this way, the conditional image can provide appearance information and the controllable structure can provide the structure information for generating the target result. Moreover, our model learns the image-to-image mapping through three novel losses, i.e., color loss, controllable structure guided cycle-consistency loss, and controllable structure guided self-content preserving loss. Also, we present the Frechet ResNet Distance (FRD) to evaluate the quality of the generated images. Experiments on two challenging image translation tasks, i.e., hand gesture-to-gesture translation and cross-view image translation, show that our model generates convincing results, and significantly outperforms other state-of-the-art methods on both tasks. Meanwhile, the proposed framework is a unified solution, thus it can be applied to solving other controllable structure guided image translation tasks such as landmark guided facial expression translation and keypoint guided person image generation. To the best of our knowledge, we are the first to make one GAN framework work on all such controllable structure guided image translation tasks. Code is available at https://github.com/Ha0Tang/GestureGAN.																	1057-7149	1941-0042					2020	29						8916	8929		10.1109/TIP.2020.3021789													
J								Validity of machine learning in biology and medicine increased through collaborations across fields of expertise	NATURE MACHINE INTELLIGENCE											INTERDISCIPLINARY RESEARCH; EVOLUTION	Machine learning (ML) has become an essential asset for the life sciences and medicine. We selected 250 articles describing ML applications from 17 journals sampling 26 different fields between 2011 and 2016. Independent evaluation by two readers highlighted three results. First, only half of the articles shared software, 64% shared data and 81% applied any kind of evaluation. Although crucial for ensuring the validity of ML applications, these aspects were met more by publications in lower-ranked journals. Second, the authors' scientific backgrounds highly influenced how technical aspects were addressed: reproducibility and computational evaluation methods were more prominent with computational co-authors; experimental proofs more with experimentalists. Third, 73% of the ML applications resulted from interdisciplinary collaborations comprising authors from at least two of the three disciplines: computational sciences, biology, and medicine. The results suggested collaborations between computational and experimental scientists to generate more scientifically sound and impactful work integrating knowledge from both domains. Although scientifically more valid solutions and collaborations involving diverse expertise did not correlate with impact factors, such collaborations provide opportunities to both sides: computational scientists are given access to novel and challenging real-world biological data, increasing the scientific impact of their research, and experimentalists benefit from more in-depth computational analyses improving the technical correctness of work. Applications of machine learning in the life sciences and medicine require expertise in computational methods and in scientific subject matter. The authors surveyed articles in the life sciences that included machine learning applications, and found that interdisciplinary collaborations increased the scientific validity of published research.																		2522-5839				JAN	2020	2	1					18	24		10.1038/s42256-019-0139-8													
J								AmoebaContact and GDFold as a pipeline for rapid de novo protein structure prediction	NATURE MACHINE INTELLIGENCE											NEURAL-NETWORKS; RESIDUE CONTACTS; CATH	Predicting the structures of proteins from amino acid sequences is of great importance. Recently, the accuracy of de novo protein structure prediction has been substantially improved when assisted by information about the contact between residues, which is also predictable from the sequence. Here, we present a novel pipeline for rapid protein structure prediction, which consists of a residue contact predictor, AmoebaContact, and a contact-assisted folder, GDFold. Unlike mainstream contact predictors that utilize simple, regularized neural networks, AmoebaContact adopts a set of network architectures that are optimized for contact prediction through automatic searching, and it predicts contacts at a series of cutoffs. Unlike conventional contact-assisted folders that only use top-scored contact pairs, GDFold considers all residue pairs from the prediction results of AmoebaContact in a differentiable loss function and optimizes atom coordinates using the gradient descent algorithm. The combination of AmoebaContact and GDFold allows quick modelling of the protein structure with acceptable model quality. Predicting the structure of proteins from amino acid sequences is a hard problem. Convolutional neural networks can learn to predict a map of distances between amino acid residues that can be turned into a three-dimensional structure. With a combination of approaches, including an evolutionary technique to find the best neural network architecture and a tool to find the atom coordinates in the folded structure, a pipeline for rapid prediction of three-dimensional protein structures is demonstrated.																		2522-5839				JAN	2020	2	1					25	33		10.1038/s42256-019-0130-4													
J								Assessing the importance of magnetic resonance contrasts using collaborative generative adversarial networks	NATURE MACHINE INTELLIGENCE											SYNTHETIC-MRI	A unique advantage of magnetic resonance imaging (MRI) is its mechanism for generating various image contrasts depending on tissue-specific parameters, which provides useful clinical information. Unfortunately, a complete set of MR contrasts is often difficult to obtain in a real clinical environment. Recently, there have been claims that generative models such as generative adversarial networks (GANs) can synthesize MR contrasts that are not acquired. However, the poor scalability of existing GAN-based image synthesis poses a fundamental challenge to understanding the nature of MR contrasts: which contrasts matter, and which cannot be synthesized by generative models? Here, we show that these questions can be addressed systematically by learning the joint manifold of multiple MR contrasts using collaborative generative adversarial networks. Our experimental results show that the exogenous contrast provided by contrast agents is not replaceable, but endogenous contrasts such as T-1 and T-2 can be synthesized from other contrasts. These findings provide important guidance for the acquisition-protocol design of MR in clinical environments. Magnetic resonance scans use different contrast agents to generate different images, each giving specific clinical information. Lee et al. use a collaborative generative model to synthesize some magnetic resonance contrasts from others, providing guidance for how clinical imaging times can be reduced.																		2522-5839				JAN	2020	2	1					34	42		10.1038/s42256-019-0137-x													
J								Constructing energy-efficient mixed-precision neural networks through principal component analysis for edge intelligence	NATURE MACHINE INTELLIGENCE											FUTURE	The 'Internet of Things' has brought increased demand for artificial intelligence-based edge computing in applications ranging from healthcare monitoring systems to autonomous vehicles. Quantization is a powerful tool to address the growing computational cost of such applications and yields significant compression over full-precision networks. However, quantization can result in substantial loss of performance for complex image classification tasks. To address this, we propose a principal component analysis (PCA)-driven methodology to identify the important layers of a binary network, and design mixed-precision networks. The proposed Hybrid-Net achieves a more than 10% improvement in classification accuracy over binary networks such as XNOR-Net for ResNet and VGG architectures on CIFAR-100 and ImageNet datasets, while still achieving up to 94% of the energy efficiency of XNOR-Nets. This work advances the feasibility of using highly compressed neural networks for energy-efficient neural computing in edge devices. Neural networks are often implemented with reduced precision in order to meet the tight energy and memory budget required by edge computing devices. Chakraborty et al. develop a technique for assessing which layers can be quantized, and by how much, without sacrificing too much on performance.																		2522-5839				JAN	2020	2	1					43	55		10.1038/s42256-019-0134-0													
J								From local explanations to global understanding with explainable AI for trees	NATURE MACHINE INTELLIGENCE											PREDICTIONS; SUBTYPES; DISEASE; MODELS	Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions. (1) A polynomial time algorithm to compute optimal explanations based on game theory. (2) A new type of explanation that directly measures local feature interaction effects. (3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear mortality risk factors in the US population, (2) highlight distinct population subgroups with shared risk characteristics, (3) identify nonlinear interaction effects among risk factors for chronic kidney disease and (4) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains. Tree-based machine learning models are widely used in domains such as healthcare, finance and public services. The authors present an explanation method for trees that enables the computation of optimal local explanations for individual predictions, and demonstrate their method on three medical datasets.																		2522-5839				JAN	2020	2	1					56	67		10.1038/s42256-019-0138-9													
J								Large-scale automated investigation of free-falling paper shapes via iterative physical experimentation	NATURE MACHINE INTELLIGENCE											DYNAMICS; ROBOT; OPTIMIZATION; AUTOROTATION; TRANSITION; STEADY; ZIGZAG; SEEDS	Free-falling paper shapes exhibit rich, complex and varied behaviours that are extremely challenging to model analytically. Physical experimentation aids in system understanding, but is time-consuming, sensitive to initial conditions and reliant on subjective visual behavioural classification. In this study, robotics, computer vision and machine learning are used to autonomously fabricate, drop, analyse and classify the behaviours of hundreds of shapes. The system is validated by reproducing results for falling discs, which exhibit four falling styles: tumbling, chaotic, steady and periodic. A previously determined mapping from a non-dimensional parameter space to behaviour groups is shown to be consistent with these new experiments for tumbling and chaotic behaviours. However, steady or periodic behaviours are observed in previously unseen areas of the parameter space. More complex hexagon, square and cross shapes are investigated, showing that the non-dimensional parameter space generalizes to these shapes. The system highlights the potential of robotics for the investigation of complex physical systems, of which falling paper is one example, and provides a template for future investigation of such systems. The dynamics of paper shapes in free fall are still not fully understood, despite being discussed for more than 150 years. Collecting large amounts of data has the potential to give us new insights and a robotics system could generate and analyse data in large quantities.																		2522-5839				JAN	2020	2	1					68	75		10.1038/s42256-019-0135-z													
J								Learning as the unsupervised alignment of conceptual systems	NATURE MACHINE INTELLIGENCE											ACQUISITION; REGULARITIES; INFORMATION	Concept induction requires the extraction and naming of concepts from noisy perceptual experience. For supervised approaches, as the number of concepts grows, so does the number of required training examples. Philosophers, psychologists and computer scientists have long recognized that children can learn to label objects without being explicitly taught. In a series of computational experiments, we highlight how information in the environment can be used to build and align conceptual systems. Unlike supervised learning, the learning problem becomes easier the more concepts and systems there are to master. The key insight is that each concept has a unique signature within one conceptual system (for example, images) that is recapitulated in other systems (for example, text or audio). As predicted, children's early concepts form readily aligned systems. By assembling conceptual systems from real-word datasets of text, images and audio, Roads and Love propose that objects embedded within a conceptual system have a unique signature that allows for conceptual systems to be aligned in an unsupervised fashion.																		2522-5839				JAN	2020	2	1					76	82		10.1038/s42256-019-0132-2													
J								Learned Image Downscaling for Upscaling Using Content Adaptive Resampler	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image resizing; downscaling; super-resolution; content adaptive; non-uniform resampling	COMPRESSION	Deep convolutional neural network based image super-resolution (SR) models have shown superior performance in recovering the underlying high resolution (HR) images from low resolution (LR) images obtained from the predefined downscaling methods. In this paper, we propose a learned image downscaling method based on content adaptive resampler (CAR) with consideration on the upscaling process. The proposed resampler network generates content adaptive image resampling kernels that are applied to the original HR input to generate pixels on the downscaled image. Moreover, a differentiable upscaling (SR) module is employed to upscale the LR result into its underlying HR counterpart. By back-propagating the reconstruction error down to the original HR input across the entire framework to adjust model parameters, the proposed framework achieves a new state-of-the-art SR performance through upscaling guided image resamplers which adaptively preserve detailed information that is essential to the upscaling. Experimental results indicate that the quality of the generated LR image is comparable to that of the traditional interpolation based method and the significant SR performance gain is achieved by deep SR models trained jointly with the CAR model. The code is publicly available on: https://github.com/sunwj/CAR.																	1057-7149	1941-0042					2020	29						4027	4040		10.1109/TIP.2020.2970248													
J								GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing	JOURNAL OF MACHINE LEARNING RESEARCH										Machine Learning; Deep Learning; Apache MXNet; Computer Vision; Natural Language Processing		We present GluonCV and GluonNLP, the deep learning toolkits for computer vision and natural language processing based on Apache MXNet (incubating). These toolkits provide state-of-the-art pre-trained models, training scripts, and training logs, to facilitate rapid prototyping and promote reproducible research. We also provide modular APIs with flexible building blocks to enable efficient customization. Leveraging the MXNet ecosystem, the deep learning models in GluonCV and GluonNLP can be deployed onto a variety of platforms with different programming languages. The Apache 2.0 license has been adopted by GluonCV and GluonNLP to allow for software distribution, modification, and usage.																	1532-4435						2020	21																						
J								Near-optimal Individualized Treatment Recommendations	JOURNAL OF MACHINE LEARNING RESEARCH										individualized treatment recommendation; set-valued classification; angle-based classification; reproducing kernel Hilbert space; statistical learning theory	TREATMENT RULES; CLASSIFICATION	The individualized treatment recommendation (ITR) is an important analytic framework for precision medicine. The goal of ITR is to assign the best treatments to patients based on their individual characteristics. From the machine learning perspective, the solution to the ITR problem can be formulated as a weighted classification problem to maximize the mean benefit from the recommended treatments given patients' characteristics. Several ITR methods have been proposed in both the binary setting and the multicategory setting. In practice, one may prefer a more flexible recommendation that includes multiple treatment options. This motivates us to develop methods to obtain a set of near-optimal individualized treatment recommendations alternative to each other, called alternative individualized treatment recommendations (A-ITR). We propose two methods to estimate the optimal A-ITR within the outcome weighted learning (OWL) framework. Simulation studies and a real data analysis for Type 2 diabetic patients with injectable antidiabetic treatments are conducted to show the usefulness of the proposed A-ITR framework. We also show the consistency of these methods and obtain an upper bound for the risk between the theoretically optimal recommendation and the estimated one. An R package aitr has been developed, found at https://github.com/menghaomiao/aitr																	1532-4435						2020	21																						
J								(<= k)-hereditarily Reconstructible Digraphs	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Digraph; isomorphy; hereditary isomorphy; hereditary reconstructibility	ISOMORPHIC TYPES; BINARY; DECOMPOSITION; CONSTRUCTION; GRAPHS	For a vertex subset X of a digraph D, we denote by D[X] the subdigraph of D induced on X. Given a nonnegative integer k, two digraphs D, D' defined on the same vertex set V are (<= k)-hypomorphic if for every subset X of V with at most k elements, the subdigraphs D[X] and D'[X] are isomorphic. A digraph D' is hereditarily isomorphic to D, if for every subset X of V, the subdigraphs D[X] and D'[X] are isomorphic. A digraph D is (<= k)-hereditarily reconstructible, whenever each digraph D' (<= k)-hypomorphic to D, is hereditarily isomorphic to it. In this paper we characterize for each nonnegative integer k, the (<= k)-hereditarily reconstructible digraphs.																	1542-3980	1542-3999					2020	34	5-6					401	421															
J								On the Probability and Cost of Ignorance, Inconsistency, Nonsense and More	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Multiple-valued logics; doxastic reasoning; probabilistic reasoning; probabilistic programming; belief bases; reasoning with uncertainty	LOGIC	Ignorance, inconsistency, nonsense and similar phenomena are omnipresent in everyday reasoning. They have been intensively studied, especially in the area of multiple-valued logics. Therefore we develop a framework for belief bases, combining multiple-valued and probabilistic reasoning, with the main focus on the way belief bases are actually used and accessed through queries. As an implementation tool we use a probabilistic programming language PROBLOG. Though based on distribution semantics with the independence assumption, we show how its constructs can successfully be used in implementing the considered logics and belief bases. In particular, we develop a technique for shifting probabilistic dependencies to the level of symbolic parts of belief bases. We also discuss applications of the framework in reasoning with Likert-type scales, widely exploited in questionnaire-based experimental research in psychology, economics, sociology, politics, public opinion measurements, and related areas.																	1542-3980	1542-3999					2020	34	5-6					423	450															
J								New Way for Finding Shortest Path Problem in a Network	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Vague neutrosophic graph; SPP; score function	ALGORITHM	The shortest path problem (SPP) in graph theory is the problem of assessing a path between two vertices in a graph to minimize the sum of the weights of the edges of its constituent. The SPP ia classical and elementry problem of a graph theory which is applicable in many fields like GIS network analysis, computational geometry, operational research and graph algorithms. SPP are among the elementry problems studied in network optimization. Graphs are very important models of networks. Path-solutions, including location-based services and web-based GIS services, are becoming an important component of many GIS applications. In this paper, we introduced a new method to solve SPP in a network. The SPP is fundamental problems in network optimization. Most traditional solutions for path-finding depends on the shortest path algorithms which tend to minimize travel cost between points. These algorithms use cost criteria which are generally the edge attribute of the graph network. There is a neutrosophical shortest path study in this paper with a vague neutrosophic number (VNsN) on a network. A suggested algorithm also provides the shortest path length (SPL) from source vertex to destination vertex with the ranking function. Here, a VNsN is allocated to each arc length. Lastly, there is a numerical example showing the method proposed.																	1542-3980	1542-3999					2020	34	5-6					451	460															
J								FLQ: An Efficient Single-server Fuzzy Logic Based Queuing Algorithm for Wireless Networks	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										FIFO queuing algorithm; FLQ; fuzzy logic; MATLAB; membership function; OMNeT plus; QoS	MANAGEMENT	In this paper, we propose a novel dynamic and robust queue management algorithm based on fuzzy logic. The presented mathematical framework employs fuzzy decision-making with multiple attributes incorporated in the fuzzy logic controller. The fuzzy inputs in our system are the total queuing time, mean lifetime, and mean queue length associated with the deployed single-server queuing discipline. Besides, service time, queue capacity, and inter-arrival time represent the three fuzzy outputs. A series of extensive simulation experiments are conducted to evaluate and compare the performance of the proposed Fuzzy Logic based Queuing (FLQ) algorithm with the well-known conventional FIFO queuing mechanism. The simulation results validate the superior performance of the wireless network implemented with FLQ algorithm in terms of lower delay, lower queue size, and much higher service rate than the traditional queuing policy. In addition, it eminently reduces unsolicited packet drops and queuing delay encountered by the packets in the network.																	1542-3980	1542-3999					2020	34	5-6					461	477															
J								A Characterization of Distance Matrices of Weighted Hypercube Graphs and Petersen Graphs	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING												Given a positive-weighted simple connected graph with m vertices, labelled by the numbers 1, . . . , m, we can construct an m x m matrix whose entry (i, j), for any i, j is an element of {1, . . ., m}, is the minimal weight of a path between i and j, where the weight of a path is the sum of the weights of its edges. Such a matrix is called the distance matrix of the weighted graph. There is wide literature about distance matrices of weighted graphs. In this paper we characterize distance matrices of positive-weighted n-hypercube graphs. Moreover we show that a connected bipartite n-regular graph with order 2(n) is not necessarily the n-hypercube graph. Finally we give a characterization of distance matrices of positive-weighted Petersen graphs.																	1542-3980	1542-3999					2020	34	5-6					479	497															
J								Relaxing the Fraenkel-Mostowski Set Theory	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Fraenkel-Mostowski set theory; relaxed finite support axiom; amorphous sets; finite-cofinite mathematics		We study the P-A-sets which are (Zermelo-Fraenkel) sets equipped with permutation actions of the group of all bijections of a fixed set A of atoms. These P-A-sets are related to S-A-sets (sets with permutation actions), and also to nominal sets. We prove that some particular P-A-sets have similar properties with nominal sets, although we ignore the finite support requirement. Then we present the Relaxed Fraenkel-Mostowski set theory by weakening the finite support axiom in Fraenkel-Mostowski set theory. In this relaxed version it is not required the existence of a finite support for all the higher-order constructions as in Fraenkel-Mostowski theory, but only for the elements of the powerset of an amorphous set of atoms. Finite-Cofinite Mathematics is presented as a refinement of Zermelo-Fraenkel with atoms formed only by either finite or cofinite atomic sets. Finally, we present a comparison between Fraenkel-Mostowski set theory and other related theories (including Relaxed Fraenkel-Mostowski theory and Finite-Cofinite Mathematics).																	1542-3980	1542-3999					2020	34	5-6					499	526															
J								An Integrated Decision Support System for Hospital Management: Statistical-Based Fuzzy Cognitive Maps	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Statistical-based fuzzy cognitive maps; chronic obstructive pulmonary disease; risk factors; length of stay predictors; medical decision making	LENGTH-OF-STAY; OBSTRUCTIVE PULMONARY-DISEASE; READMISSION; COPD; EXACERBATIONS; DIAGNOSIS; RISK; ASSOCIATION; IMPACT; CARE	Chronic Obstructive Pulmonary Disease (COPD) is one of the most common chronic respiratory diseases. COPD is a global burden that induces many decision-making problems. Medical decisions are naturally originated from personal experience of the physician and statistical analysis of previous data. Because of its structural advantages in revealing the behavior of complex systems, and in capturing human judgment by means of fuzzy information, Fuzzy Cognitive Map (FCM) and its extensions are widely used in medical decisions. In this paper, a novel approach called Statistical-Based Fuzzy Cognitive Map (SBFCM) is proposed which aggregates the power of statistical analysis with dynamical nature FCMs. The SBFCM method is developed in order to evaluate the factors that affect the length of hospital stay (LoS) of COPD patients that apply to the hospital with an acute exacerbation. Fifty factors, including LoS, are adopted as system concepts and observed under four groups. A real-case application is conducted and different scenarios are analyzed for a better understanding of the system behavior.																	1542-3980	1542-3999					2020	34	5-6					527	552															
J								Notion of Complex Pythagorean Fuzzy Graph with Properties and Application	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										Cartesion products; composition; strong product; semi strong product and direct product of CPFG; strong CPFG of cartesion product and union of two CPFG; self complementary of CPFG; application of CPFG	DECISION-MAKING; TOPSIS	A Complex Pythagorean fuzzy set(CPFs) is a energetic mechanism for interpret the vague concepts more definitely. The CPFs-based models has more flexibility as compared to complex fuzzy models and intutionistic fuzzy models. The main goal of this paper is to introducing the concept of CPFs to graph theory in form of complex pythagorean fuzzy graph. This work propose the notion of complex pythagorean fuzzy graph (CPFG) and describes many techniques for their development. We then define properties namely caretesion product, composition, strong product, semi-strong product and direct product on CPFGs and prove them with examples. Related properties are also discussed in it. We will also present notion of strong complex Pythagorean fuzzy graph. We will also discuss self-complementary concept on complex pythagorean fuzzy graph. Finally, we will present application of CPFG.																	1542-3980	1542-3999					2020	34	5-6					553	586															
J								Equivalent Relationship Is the Key of the Synergy Effect on University-Enterprise Cooperation-Based on the Moderating Effect of the Matching Factors on Equivalence	JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING										University-industry cooperation; synergistic effect; partner selection; matching; equivalence	ORGANIZATIONAL-CHANGE; LEARNING ORIENTATION; STRATEGIC ALLIANCES; INNOVATION; KNOWLEDGE; FIRMS; IMPACT; COLLABORATION; TECHNOLOGY; REPUTATION	This article focuses on the synergistic effect of university-industry cooperation. The study believes that reasonable matching can enhance the interdependence of knowledge and organization formed between partners, which in turn affects the synergy of cooperation. To this end, this article relies on Harbin Institute of Technology (HIT) and domestic cooperative enterprises to conduct a equivalence evaluation of matching factors with sample data of 176 university-industry cooperation. Through screening, 74 sample data with equal organization reputation, organization scale, and scientific research and technical capabilities are obtained, and a hierarchical regression model of equivalent matching factors is constructed. The research results show that the relationship between organizational synergy and synergistic effect can be positively adjusted when the organizational reputation and organizational scale are relatively equal, and the relationship between knowledge synergy and synergistic effect can be positively adjusted when the scientific research capability and technical capability are relatively equal. The research results not only help deepen the existing research results of university-industry cooperation, but also enrich the domestic management theory of synergistic innovation. At the same time, it has provided practical guidance for Chinese university-industry strategic alliance, especially in "open innovation" and "network cooperation".																	1542-3980	1542-3999					2020	34	5-6					587	611															
J								Automatic ECG-Based Emotion Recognition in Music Listening	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING										Electrocardiography; Music; Emotion recognition; Physiology; Feature extraction; Multiple signal classification; Algorithm design and analysis; Electrocardiogram; emotion recognition; music; machine learning	HEART-RATE-VARIABILITY; CIRCUMPLEX MODEL; ELECTROCARDIOGRAM; CLASSIFICATION; EXTRACTION; ALGORITHM; FREQUENCY; SELECTION; DYNAMICS	This paper presents an automatic ECG-based emotion recognition algorithm for human emotion recognition. First, we adopt a musical induction method to induce participants' real emotional states and collect their ECG signals without any deliberate laboratory setting. Afterward, we develop an automatic ECG-based emotion recognition algorithm to recognize human emotions elicited by listening to music. Physiological ECG features extracted from the time-, and frequency-domain, and nonlinear analyses of ECG signals are used to find emotion-relevant features and to correlate them with emotional states. Subsequently, we develop a sequential forward floating selection-kernel-based class separability-based (SFFS-KBCS-based) feature selection algorithm and utilize the generalized discriminant analysis (GDA) to effectively select significant ECG features associated with emotions and to reduce the dimensions of the selected features, respectively. Positive/negative valence, high/low arousal, and four types of emotions (joy, tension, sadness, and peacefulness) are recognized using least squares support vector machine (LS-SVM) recognizers. The results show that the correct classification rates for positive/negative valence, high/low arousal, and four types of emotion classification tasks are 82.78, 72.91, and 61.52 percent, respectively.																	1949-3045					JAN-MAR	2020	11	1					85	99		10.1109/TAFFC.2017.2781732													
J								Wide Neural Networks with Bottlenecks are Deep Gaussian Processes	JOURNAL OF MACHINE LEARNING RESEARCH										Bayesian neural networks; deep learning; Gaussian processes; kernels; phase transitions		There has recently been much work on the "wide limit" of neural networks, where Bayesian neural networks (BNNs) are shown to converge to a Gaussian process (GP) as all hidden layers are sent to infinite width. However, these results do not apply to architectures that require one or more of the hidden layers to remain narrow. In this paper, we consider the wide limit of BNNs where some hidden layers, called "bottlenecks", are held at finite width. The result is a composition of GPs that we term a "bottleneck neural network Gaussian process" (bottleneck NNGP). Although intuitive, the subtlety of the proof is in showing that the wide limit of a composition of networks is in fact the composition of the limiting GPs. We also analyze theoretically a single-bottleneck NNGP, finding that the bottleneck induces dependence between the outputs of a multi-output network that persists through extreme post-bottleneck depths, and prevents the kernel of the network from losing discriminative power at extreme post-bottleneck depths.																	1532-4435						2020	21																						
J								Trust-Region Variational Inference with Gaussian Mixture Models	JOURNAL OF MACHINE LEARNING RESEARCH										approximate inference; variational inference; sampling; policy search; mcmc; markov chain monte carlo	MEAN-FIELD-THEORY; APPROXIMATION; DISTRIBUTIONS	Many methods for machine learning rely on approximate inference from intractable probability distributions. Variational inference approximates such distributions by tractable models that can be subsequently used for approximate inference. Learning sufficiently accurate approximations requires a rich model family and careful exploration of the relevant modes of the target distribution. We propose a method for learning accurate GMM approximations of intractable probability distributions based on insights from policy search by using information-geometric trust regions for principled exploration. For efficient improvement of the GMM approximation, we derive a lower bound on the corresponding optimization objective enabling us to update the components independently. Our use of the lower bound ensures convergence to a stationary point of the original objective. The number of components is adapted online by adding new components in promising regions and by deleting components with negligible weight. We demonstrate on several domains that we can learn approximations of complex, multimodal distributions with a quality that is unmet by previous variational inference methods, and that the GMM approximation can be used for drawing samples that are on par with samples created by state-of-the-art MCMC samplers while requiring up to three orders of magnitude less computational resources.																	1532-4435						2020	21																						
J								Optimal Estimation of Sparse Topic Models	JOURNAL OF MACHINE LEARNING RESEARCH										topic models; minimax estimation; sparse estimation; adaptive estimation; high dimensional estimation; non-negative matrix factorization; separability; anchor words		Topic models have become popular tools for dimension reduction and exploratory analysis of text data which consists in observed frequencies of a vocabulary of p words in n documents, stored in a p x n matrix. The main premise is that the mean of this data matrix can be factorized into a product of two non-negative matrices: a p x K word-topic matrix A and a K x n topic-document matrix W. This paper studies the estimation of A that is possibly element-wise sparse, and the number of topics K is unknown. In this under-explored context, we derive a new minimax lower bound for the estimation of such A and propose a new computationally efficient algorithm for its recovery. We derive a finite sample upper bound for our estimator, and show that it matches the minimax lower bound in many scenarios. Our estimate adapts to the unknown sparsity of A and our analysis is valid for any finite n, p, K and document lengths. Empirical results on both synthetic data and semi-synthetic data show that our proposed estimator is a strong competitor of the existing state-of-the-art algorithms for both non-sparse A and sparse A, and has superior performance is many scenarios of interest.																	1532-4435						2020	21																						
J								The Kalai-Smorodinsky solution for many-objective Bayesian optimization	JOURNAL OF MACHINE LEARNING RESEARCH										Gaussian process; Game theory; Stepwise uncertainty reduction	EXPECTED-IMPROVEMENT CRITERIA; MULTIOBJECTIVE OPTIMIZATION; GLOBAL OPTIMIZATION; SEQUENTIAL DESIGN; ALGORITHM; SEARCH	An ongoing aim of research in multiobjective Bayesian optimization is to extend its applicability to a large number of objectives. While coping with a limited budget of evaluations, recovering the set of optimal compromise solutions generally requires numerous observations and is less interpretable since this set tends to grow larger with the number of objectives. We thus propose to focus on a specific solution originating from game theory, the Kalai-Smorodinsky solution, which possesses attractive properties. In particular, it ensures equal marginal gains over all objectives. We further make it insensitive to a monotonic transformation of the objectives by considering the objectives in the copula space. A novel tailored algorithm is proposed to search for the solution, in the form of a Bayesian optimization algorithm: sequential sampling decisions are made based on acquisition functions that derive from an instrumental Gaussian process prior. Our approach is tested on four problems with respectively four, six, eight, and nine objectives. The method is available in the R package GPGame available on CRAN at https://cran.r-project.org/package=GPGame.																	1532-4435						2020	21																						
J								Scikit-network: Graph Analysis in Python	JOURNAL OF MACHINE LEARNING RESEARCH										graph analysis; sparse matrices; python; cython; scipy		Scikit-network is a Python package inspired by scikit-learn for the analysis of large graphs. Graphs are represented by their adjacency matrix in the sparse CSR format of SciPy. The package provides state-of-the-art algorithms for ranking, clustering, classifying, embedding and visualizing the nodes of a graph. High performance is achieved through a mix of fast matrix-vector products (using SciPy), compiled code (using Cython) and parallel processing. The package is distributed under the BSD license, with dependencies limited to NumPy and SciPy. It is compatible with Python 3.6 and newer. Source code, documentation and installation instructions are available online(1).																	1532-4435						2020	21																						
J								Distributed High-dimensional Regression Under a Quantile Loss Function	JOURNAL OF MACHINE LEARNING RESEARCH										Distributed estimation; high-dimensional linear model; quantile loss; robust estimator; support recovery	CONFIDENCE-INTERVALS; VARIABLE SELECTION; MODEL SELECTION; COVARIANCE; FRAMEWORK; ALGORITHM; RECOVERY	This paper studies distributed estimation and support recovery for high-dimensional linear regression model with heavy-tailed noise. To deal with heavy-tailed noise whose variance can be infinite, we adopt the quantile regression loss function instead of the commonly used squared loss. However, the non-smooth quantile loss poses new challenges to high-dimensional distributed estimation in both computation and theoretical development. To address the challenge, we transform the response variable and establish a new connection between quantile regression and ordinary linear regression. Then, we provide a distributed estimator that is both computationally and communicationally efficient, where only the gradient information is communicated at each iteration. Theoretically, we show that, after a constant number of iterations, the proposed estimator achieves a near-oracle convergence rate without any restriction on the number of machines. Moreover, we establish the theoretical guarantee for the support recovery. The simulation analysis is provided to demonstrate the effectiveness of our method.																	1532-4435						2020	21																						
J								Generative Adversarial Nets for Robust Scatter Estimation: A Proper Scoring Rule Perspective	JOURNAL OF MACHINE LEARNING RESEARCH										robust statistics; neural networks; minimax rate; data depth; contamination model; GAN	REGRESSION DEPTH; LOCATION; INFERENCE; MATRIX	Robust covariance matrix estimation is a fundamental task in statistics. The recent discovery on the connection between robust estimation and generative adversarial nets (GANs) by Gao et al. (2019) suggests that it is possible to compute depth-like robust estimators using similar techniques that optimize GANs. In this paper, we introduce a general learning via classification framework based on the notion of proper scoring rules. This framework allows us to understand both matrix depth function, a technique of rateoptimal robust estimation, and various GANs through the lens of variational approximations of f -divergences induced by proper scoring rules. We then propose a new class of robust covariance matrix estimators in this framework by carefully constructing discriminators with appropriate neural network structures. These estimators are proved to achieve the minimax rate of covariance matrix estimation under Huber's contamination model. The results are also extended to robust scatter estimation for elliptical distributions. Our numerical results demonstrate the good performance of the proposed procedures under various settings against competitors in the literature. Keywords: robust statistics, neural networks, minimax																	1532-4435						2020	21								1														
J								Learning Big Gaussian Bayesian Networks: Partition, Estimation and Fusion	JOURNAL OF MACHINE LEARNING RESEARCH										Bayesian network; conditional independence; directed acyclic graph; divide-and-conquer; structure learning	DIRECTED ACYCLIC GRAPHS; PENALIZED ESTIMATION	Structure learning of Bayesian networks has always been a challenging problem. Nowadays, massive-size networks with thousands or more of nodes but fewer samples frequently appear in many areas. We develop a divide-and-conquer framework, called partition-estimation-fusion (PEF), for structure learning of such big networks. The proposed method first partitions nodes into clusters, then learns a subgraph on each cluster of nodes, and finally fuses all learned subgraphs into one Bayesian network. The PEF method is designed in a flexible way so that any structure learning method may be used in the second step to learn a subgraph structure as either a DAG or a CPDAG. In the clustering step, we adapt hierarchical clustering to automatically choose a proper number of clusters. In the fusion step, we propose a novel hybrid method that sequentially adds edges between subgraphs. Extensive numerical experiments demonstrate the competitive performance of our PEF method, in terms of both speed and accuracy compared to existing methods. Our method can improve the accuracy of structure learning by 20% or more, while reducing running time up to two orders-of-magnitude.																	1532-4435						2020	21																						
J								Krylov Subspace Method for Nonlinear Dynamical Systems with Random Noise	JOURNAL OF MACHINE LEARNING RESEARCH										Nonlinear dynamical system; Transfer operator; Krylov subspace methods; Operator theory; Time-series data	APPROXIMATION; OPERATOR	Operator-theoretic analysis of nonlinear dynamical systems has attracted much attention in a variety of engineering and scientific fields, endowed with practical estimation methods using data such as dynamic mode decomposition. In this paper, we address a lifted representation of nonlinear dynamical systems with random noise based on transfer operators, and develop a novel Krylov subspace method for estimating the operators using finite data, with consideration of the unboundedness of operators. For this purpose, we first consider Perron-Frobenius operators with kernel-mean embeddings for such systems. We then extend the Arnoldi method, which is the most classical type of Kryov subspace methods, so that it can be applied to the current case. Meanwhile, the Arnoldi method requires the assumption that the operator is bounded, which is not necessarily satisfied for transfer operators on nonlinear systems. We accordingly develop the shift-invert Arnoldi method for Perron-Frobenius operators to avoid this problem. Also, we describe an approach of evaluating predictive accuracy by estimated operators on the basis of the maximum mean discrepancy, which is applicable, for example, to anomaly detection in complex systems. The empirical performance of our methods is investigated using synthetic and real-world healthcare data.																	1532-4435						2020	21								1														
J								Doubly Distributed Supervised Learning and Inference with High-Dimensional Correlated Outcomes	JOURNAL OF MACHINE LEARNING RESEARCH										Divide-and-conquer; Generalized method of moments; Estimating functions; Parallel computing; Scalable computing	JOINT REGRESSION-ANALYSIS; LIKELIHOOD ESTIMATION; QUASI-LIKELIHOOD; STATISTICS; BINARY; MODELS	This paper presents a unified framework for supervised learning and inference procedures using the divide-and-conquer approach for high-dimensional correlated outcomes. We propose a general class of estimators that can be implemented in a fully distributed and parallelized computational scheme. Modeling, computational and theoretical challenges related to high-dimensional correlated outcomes are overcome by dividing data at both outcome and subject levels, estimating the parameter of interest from blocks of data using a broad class of supervised learning procedures, and combining block estimators in a closed-form meta-estimator asymptotically equivalent to estimates obtained by Hansen (1982)'s generalized method of moments (GMM) that does not require the entire data to be reloaded on a common server. We provide rigorous theoretical justifications for the use of distributed estimators with correlated outcomes by studying the asymptotic behaviour of the combined estimator with fixed and diverging number of data divisions. Simulations illustrate the finite sample performance of the proposed method, and we provide an R package for ease of implementation.																	1532-4435						2020	21																						
J								Consistency of Semi-Supervised Learning Algorithms on Graphs: Probit and One-Hot Methods	JOURNAL OF MACHINE LEARNING RESEARCH										Semi-supervised learning; classification; consistency; graph Laplacian; probit; spectral analysis	SPECTRAL PARTITIONING WORKS; PLANAR GRAPHS; REGULARIZATION; CLASSIFICATION; KERNEL; REGRESSION	Graph-based semi-supervised learning is the problem of propagating labels from a small number of labelled data points to a larger set of unlabelled data. This paper is concerned with the consistency of optimization-based techniques for such problems, in the limit where the labels have small noise and the underlying unlabelled data is well clustered. We study graph-based probit for binary classification, and a natural generalization of this method to multi-class classification using one-hot encoding. The resulting objective function to be optimized comprises the sum of a quadratic form defined through a rational function of the graph Laplacian, involving only the unlabelled data, and a fidelity term involving only the labelled data. The consistency analysis sheds light on the choice of the rational function defining the optimization.																	1532-4435						2020	21								1														
J								Rationally Inattentive Inverse Reinforcement Learning Explains YouTube Commenting Behavior	JOURNAL OF MACHINE LEARNING RESEARCH										Inverse Reinforcement Learning; Bayesian Revealed Preference; YouTube; Rational Inattention; Renyi Mutual Information; Framing; Behavioral Economics; Deep Embedded Clustering; Contextual Bandits	REVEALED PREFERENCE; MODELS; DIVERGENCE	We consider a novel application of inverse reinforcement learning with behavioral economics constraints to model, learn and predict the commenting behavior of YouTube viewers. Each group of users is modeled as a rationally inattentive Bayesian agent which solves a contextual bandit problem. Our methodology integrates three key components. First, to identify distinct commenting patterns, we use deep embedded clustering to estimate framing information (essential extrinsic features) that clusters users into distinct groups. Second, we present an inverse reinforcement learning algorithm that uses Bayesian revealed preferences to test for rationality: does there exist a utility function that rationalizes the given data, and if yes, can it be used to predict commenting behavior? Finally, we impose behavioral economics constraints stemming from rational inattention to characterize the attention span of groups of users. The test imposes a Renyi mutual information cost constraint which impacts how the agent can select attention strategies to maximize their expected utility. After a careful analysis of a massive YouTube dataset, our surprising result is that in most YouTube user groups, the commenting behavior is consistent with optimizing a Bayesian utility with rationally inattentive constraints. The paper also highlights how the rational inattention model can accurately predict commenting behavior. The massive YouTube dataset and analysis used in this paper are available on GitHub and completely reproducible.																	1532-4435						2020	21																						
J								Asymptotic Consistency of alpha-Renyi-Approximate Posteriors	JOURNAL OF MACHINE LEARNING RESEARCH										alpha-Renyi divergence; Asymptotic consistency; Bayesian computation; Variational inference	VARIATIONAL INFERENCE	We study the asymptotic consistency properties of alpha-Renyi approximate posteriors, a class of variational Bayesian methods that approximate an intractable Bayesian posterior with a member of a tractable family of distributions, the member chosen to minimize the alpha-Renyi divergence from the true posterior. Unique to our work is that we consider settings with alpha > 1, resulting in approximations that upperbound the log-likelihood, and consequently have wider spread than traditional variational approaches that minimize the Kullback-Liebler (KL) divergence from the posterior. Our primary result identifies sufficient conditions under which consistency holds, centering around the existence of a 'good' sequence of distributions in the approximating family that possesses, among other properties, the right rate of convergence to a limit distribution. We further characterize the good sequence by demonstrating that a sequence of distributions that converges too quickly cannot be a good sequence. We also extend our analysis to the setting where alpha equals one, corresponding to the minimizer of the reverse KL divergence, and to models with local latent variables. We also illustrate the existence of good sequence with a number of examples. Our results complement a growing body of work focused on the frequentist properties of variational Bayesian methods.																	1532-4435						2020	21																						
J								Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes	JOURNAL OF MACHINE LEARNING RESEARCH										ff-policy evaluation; Markov decision processes; Semiparametric efficiency; Double machine learning	SEQUENTIAL MOMENT RESTRICTIONS; DYNAMIC TREATMENT REGIMES; SAMPLE PROPERTIES; CAUSAL INFERENCE; PANEL-DATA; MODELS	ff-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of q-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness.																	1532-4435						2020	21																						
J								Cramer-Wold Auto-Encoder	JOURNAL OF MACHINE LEARNING RESEARCH										Auto-Encoder; Generative model; Wasserstein Auto-Encoder; Cramer-Wold Theorem; Deep neural network	INVARIANT INTEGRATION; TESTS	The computation of the distance to the true distribution is a key component of most state-of-the-art generative models. Inspired by prior works on the Sliced-Wasserstein Auto-Encoders (SWAE) and the Wasserstein Auto-Encoders with MMD-based penalty (WAE-MMD), we propose a new generative model - a Cramer-Wold Auto-Encoder (CWAE). A fundamental component of CWAE is the characteristic kernel, the construction of which is one of the goals of this paper, from here on referred to as the Cramer-Wold kernel. Its main distinguishing feature is that it has a closed-form of the kernel product of radial Gaussians. Consequently, CWAE model has a closed-form for the distance between the posterior and the normal prior, which simplifies the optimization procedure by removing the need to sample in order to compute the loss function. At the same time, CWAE performance often improves upon WAE-MMD and SWAE on standard benchmarks.																	1532-4435						2020	21																						
J								The Optimal Ridge Penalty for Real-world High-dimensional Data Can Be Zero or Negative due to the Implicit Ridge Regularization	JOURNAL OF MACHINE LEARNING RESEARCH										High-dimensional; ridge regression; regularization	REGRESSION; SELECTION	A conventional wisdom in statistical learning is that large models require strong regularization to prevent overfitting. Here we show that this rule can be violated by linear regression in the underdetermined n << p situation under realistic conditions. Using simulations and real-life high-dimensional datasets, we demonstrate that an explicit positive ridge penalty can fail to provide any improvement over the minimum-norm least squares estimator. Moreover, the optimal value of ridge penalty in this situation can be negative. This happens when the high-variance directions in the predictor space can predict the response variable, which is often the case in the real-world high-dimensional data. In this regime, low-variance directions provide an implicit ridge regularization and can make any further positive ridge penalty detrimental. We prove that augmenting any linear model with random covariates and using minimum-norm estimator is asymptotically equivalent to adding the ridge penalty. We use a spiked covariance model as an analytically tractable example and prove that the optimal ridge penalty in this case is negative when n << p.																	1532-4435						2020	21								1														
J								Estimate Sequences for Stochastic Composite Optimization: Variance Reduction, Acceleration, and Robustness to Noise	JOURNAL OF MACHINE LEARNING RESEARCH										convex optimization; variance reduction; stochastic optimization	APPROXIMATION ALGORITHMS; GRADIENT METHODS	In this paper, we propose a unified view of gradient-based algorithms for stochastic convex composite optimization by extending the concept of estimate sequence introduced by Nesterov. More precisely, we interpret a large class of stochastic optimization methods as procedures that iteratively minimize a surrogate of the objective, which covers the stochastic gradient descent method and variants of the incremental approaches SAGA, SVRG, and MISO/Finito/SDCA. This point of view has several advantages: (i) we provide a simple generic proof of convergence for all of the aforementioned methods; (ii) we naturally obtain new algorithms with the same guarantees; (iii) we derive generic strategies to make these algorithms robust to stochastic noise, which is useful when data is corrupted by small random perturbations. Finally, we propose a new accelerated stochastic gradient descent algorithm and a new accelerated SVRG algorithm that is robust to stochastic noise.																	1532-4435						2020	21																						
J								Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction	JOURNAL OF MACHINE LEARNING RESEARCH										decentralized optimization; federated learning; communication efficiency; gradient tracking; variance reduction	CONVERGENCE; ALGORITHM; CONSENSUS; EXTRA	There is growing interest in large-scale machine learning and optimization over decentralized networks, e.g. in the context of multi-agent learning and federated learning. Due to the imminent need to alleviate the communication burden, the investigation of communicationefficient distributed optimization algorithms - particularly for empirical risk minimization - has flourished in recent years. A large fraction of these algorithms have been developed for the master/slave setting, relying on the presence of a central parameter server that can communicate with all agents. This paper focuses on distributed optimization over networks, or decentralized optimization, where each agent is only allowed to aggregate information from its neighbors over a network (namely, no centralized coordination is present). By properly adjusting the global gradient estimate via local averaging in conjunction with proper correction, we develop a communication-efficient approximate Newton-type method, called Network-DANE, which generalizes DANE to accommodate decentralized scenarios. Our key ideas can be applied, in a systematic manner, to obtain decentralized versions of other master/slave distributed algorithms. A notable development is Network-SVRG/SARAH, which employs variance reduction at each agent to further accelerate local computation. We establish linear convergence of Network-DANE and Network-SVRG for strongly convex losses, and Network-SARAH for quadratic losses, which shed light on the impacts of data homogeneity, network connectivity, and local averaging upon the rate of convergence. We further extend Network-DANE to composite optimization by allowing a nonsmooth penalty term. Numerical evidence is provided to demonstrate the appealing performance of our algorithms over competitive baselines, in terms of both communication and computation efficiency. Our work suggests that by performing a judiciously chosen amount of local communication and computation per iteration, the overall efficiency can be substantially improved.																	1532-4435						2020	21																						
J								Optimal Convergence for Distributed Learning with Stochastic Gradient Methods and Spectral Algorithms	JOURNAL OF MACHINE LEARNING RESEARCH										Kernel Methods; Stochastic Gradient Methods; Regularization; Distributed Learning	APPROXIMATION; REGRESSION; ROBUST; INEQUALITIES; OPERATORS; BOUNDS; RATES	We study generalization properties of distributed algorithms in the setting of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We first investigate distributed stochastic gradient methods (SGM), with mini-batches and multi-passes over the data. We show that optimal generalization error bounds (up to logarithmic factor) can be retained for distributed SGM provided that the partition level is not too large. We then extend our results to spectral algorithms (SA), including kernel ridge regression (KRR), kernel principal component regression, and gradient methods. Our results show that distributed SGM has a smaller theoretical computational complexity, compared with distributed KRR and classic SGM. Moreover, even for a general non-distributed SA, they provide optimal, capacity-dependent convergence rates, for the case that the regression function may not be in the RKHS in the well-conditioned regimes.																	1532-4435						2020	21																						
J								Local Causal Network Learning for Finding Pairs of Total and Direct Effects	JOURNAL OF MACHINE LEARNING RESEARCH										causal networks; directed acyclic graphs; total effects; direct effects; indirect effects	MARKOV EQUIVALENCE CLASSES; BOUNDS	In observational studies, it is important to evaluate not only the total effect but also the direct and indirect effects of a treatment variable on a response variable. In terms of local structural learning of causal networks, we try to find all possible pairs of total and direct causal effects, which can further be used to calculate indirect causal effects. An intuitive global learning approach is first to find an essential graph over all variables representing all Markov equivalent causal networks, and then enumerate all equivalent networks and estimate a pair of the total and direct effects for each of them. However, it could be inefficient to learn an essential graph and enumerate equivalent networks when the true causal graph is large. In this paper, we propose a local learning approach instead. In the local learning approach, we first learn locally a chain component containing the treatment. Then, if necessary, we learn locally a chain component containing the response. Next, we locally enumerate all possible pairs of the treatment's parents and the response's parents. Finally based on these pairs, we find all possible pairs of total and direct effects of the treatment on the response.																	1532-4435						2020	21																						
J								New Insights and Perspectives on the Natural Gradient Method	JOURNAL OF MACHINE LEARNING RESEARCH										natural gradient methods; 2nd-order optimization; neural networks; convergence rate; parameterization invariance	ALGORITHMS; MATRIX	Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of 2nd-order optimization method, with the Fisher information matrix acting as a substitute for the Hessian. In many important cases, the Fisher information matrix is shown to be equivalent to the Generalized Gauss-Newton matrix, which both approximates the Hessian, but also has certain properties that favor its use over the Hessian. This perspective turns out to have significant implications for the design of a practical and robust natural gradient optimizer, as it motivates the use of techniques like trust regions and Tikhonov regularization. Additionally, we make a series of contributions to the understanding of natural gradient and 2nd-order methods, including: a thorough analysis of the convergence speed of stochastic natural gradient descent (and more general stochastic 2nd-order methods) as applied to convex quadratics, a critical examination of the oft-used "empirical" approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by natural gradient methods (which we show also holds for certain other curvature matrices, but notably not the Hessian).																	1532-4435						2020	21								1														
J								Randomization as Regularization: A Degrees of Freedom Explanation for Random Forest Success	JOURNAL OF MACHINE LEARNING RESEARCH										Regularization; Bagging; Degrees of Freedom; Model Selection; Interpolation	MOLECULAR DESCRIPTORS; CLASSIFICATION; REGRESSION; PREDICTION; PERFORMANCE; ENSEMBLES; MODELS	Random forests remain among the most popular off-the-shelf supervised machine learning tools with a well-established track record of predictive accuracy in both regression and classification settings. Despite their empirical success as well as a bevy of recent work investigating their statistical properties, a full and satisfying explanation for their success has yet to be put forth. Here we aim to take a step forward in this direction by demonstrating that the additional randomness injected into individual trees serves as a form of implicit regularization, making random forests an ideal model in low signal-to-noise ratio (SNR) settings. Specifically, from a model-complexity perspective, we show that the mtry parameter in random forests serves much the same purpose as the shrinkage penalty in explicitly regularized regression procedures like lasso and ridge regression. To highlight this point, we design a randomized linear-model-based forward selection procedure intended as an analogue to tree-based random forests and demonstrate its surprisingly strong empirical performance. Numerous demonstrations on both real and synthetic data are provided.																	1532-4435						2020	21								1														
J								Topology of Deep Neural Networks	JOURNAL OF MACHINE LEARNING RESEARCH										neural networks; topology change; Betti numbers; topological complexity; persistent homology	VIETORIS-RIPS COMPLEXES; BETTI NUMBERS; CLASSIFICATION; HOMOLOGY; SPACES	We study how the topology of a data set M = MaUMb subset of R-d, representing two classes a and b in a binary classification problem, changes as it passes through the layers of a well-trained neural network, i.e., one with perfect accuracy on training set and near-zero generalization error (approximate to 0:01%). The goal is to shed light on two mysteries in deep neural networks: (i) a nonsmooth activation function like ReLU outperforms a smooth one like hyperbolic tangent; (ii) successful neural network architectures rely on having many layers, even though a shallow network can approximate any function arbitrarily well. We performed extensive experiments on the persistent homology of a wide range of point cloud data sets, both real and simulated. The results consistently demonstrate the following: (1) Neural networks operate by changing topology, transforming a topologically complicated data set into a topologically simple one as it passes through the layers. No matter how complicated the topology of M we begin with, when passed through a well-trained neural network f : R-d -> R-p, there is a vast reduction in the Betti numbers of both components Ma and Mb; in fact they nearly always reduce to their lowest possible values: beta(k)(f(M-i)) = 0 for k >= 1 and beta(0)(f(M-i)) = 1, i = a, b. (2) The reduction in Betti numbers is significantly faster for ReLU activation than for hyperbolic tangent activation as the former defines nonhomeomorphic maps that change topology, whereas the latter defines homeomorphic maps that preserve topology. (3) Shallow and deep networks transform data sets differently - a shallow network operates mainly through changing geometry and changes topology only in its final layers, a deep one spreads topological changes more evenly across all layers.																	1532-4435						2020	21																						
J								Adaptive Approximation and Generalization of Deep Neural Network with Intrinsic Dimensionality	JOURNAL OF MACHINE LEARNING RESEARCH										Deep Learning; Deep Neural Network; Generalization Analysis; Intrinsic Dimension; Minimax Optimal Rate	BOUNDS	In this study, we prove that an intrinsic low dimensionality of covariates is the main factor that determines the performance of deep neural networks (DNNs). DNNs generally provide outstanding empirical performance. Hence, numerous studies have actively investigated the theoretical properties of DNNs to understand their underlying mechanisms. In particular, the behavior of DNNs in terms of high-dimensional data is one of the most critical questions. However, this issue has not been sufficiently investigated from the aspect of covariates, although high-dimensional data have practically low intrinsic dimensionality. In this study, we derive bounds for an approximation error and a generalization error regarding DNNs with intrinsically low dimensional covariates. We apply the notion of the Minkowski dimension and develop a novel proof technique. Consequently, we show that convergence rates of the errors by DNNs do not depend on the nominal high dimensionality of data, but on its lower intrinsic dimension. We further prove that the rate is optimal in the minimax sense. We identify an advantage of DNNs by showing that DNNs can handle a broader class of intrinsic low dimensional data than other adaptive estimators. Finally, we conduct a numerical simulation to validate the theoretical results.																	1532-4435						2020	21																						
J								Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey	JOURNAL OF MACHINE LEARNING RESEARCH										curriculum learning; reinforcement learning; transfer learning	NEURAL-NETWORKS; ROBOT; ACQUISITION; STRATEGIES; MODELS	Reinforcement learning (RL) is a popular paradigm for addressing sequential decision tasks in which the agent has only limited environmental feedback. Despite many advances over the past three decades, learning in many domains still requires a large amount of interaction with the environment, which can be prohibitively expensive in realistic scenarios. To address this problem, transfer learning has been applied to reinforcement learning such that experience gained in one task can be leveraged when starting to learn the next, harder task. More recently, several lines of research have explored how tasks, or data samples themselves, can be sequenced into a curriculum for the purpose of learning a problem that may otherwise be too difficult to learn from scratch. In this article, we present a framework for curriculum learning (CL) in reinforcement learning, and use it to survey and classify existing CL methods in terms of their assumptions, capabilities, and goals. Finally, we use our framework to find open problems and suggest directions for future RL curriculum learning research.																	1532-4435						2020	21																						
J								High Dimensional Forecasting via Interpretable Vector Autoregression	JOURNAL OF MACHINE LEARNING RESEARCH										forecasting; group lasso; multivariate time series; variable selection; vector autoregression	REGULATORY NETWORKS; MODEL SELECTION; LASSO; REGRESSION; SHRINKAGE; REGULARIZATION; COMPONENTS; SPARSITY; NUMBER; RANK	Vector autoregression (VAR) is a fundamental tool for modeling multivariate time series. However, as the number of component series is increased, the VAR model becomes overparameterized. Several authors have addressed this issue by incorporating regularized approaches, such as the lasso in VAR estimation. Traditional approaches address overparameterization by selecting a low lag order, based on the assumption of short range dependence, assuming that a universal lag order applies to all components. Such an approach constrains the relationship between the components and impedes forecast performance. The lasso-based approaches perform much better in high-dimensional situations but do not incorporate the notion of lag order selection. We propose a new class of hierarchical lag structures (HLag) that embed the notion of lag selection into a convex regularizer. The key modeling tool is a group lasso with nested groups which guarantees that the sparsity pattern of lag coefficients honors the VAR's ordered structure. The proposed HLag framework offers three basic structures, which allow for varying levels of flexibility, with many possible generalizations. A simulation study demonstrates improved performance in forecasting and lag order selection over previous approaches, and macroeconomic, financial, and energy applications further highlight forecasting improvements as well as HLag's convenient, interpretable output.																	1532-4435						2020	21																						
J								Streamlined Computing for Variational Inference with Higher Level Random Effects	JOURNAL OF MACHINE LEARNING RESEARCH										Factor Graph Fragment; Longitudinal Data Analysis; Mixed Models; Multi-level Models; Variational Message Passing		We derive and present explicit algorithms to facilitate streamlined computing for variational inference for models containing higher level random effects. Existing literature, such as Lee and Wand (2016), is such that streamlined variational inference is restricted to mean field variational Bayes algorithms for two-level random effects models. Here we provide the following extensions: (1) explicit Gaussian response mean field variational Bayes algorithms for three-level models, (2) explicit algorithms for the alternative variational message passing approach in the case of two-level and three-level models, and (3) an explanation of how arbitrarily high levels of nesting can be handled based on the recently published matrix algebraic results of the authors. A pay-off from (2) is simple extension to non-Gaussian response models. In summary, we remove barriers for streamlining variational inference algorithms based on either the mean field variational Bayes approach or the variational message passing approach when higher level random effects are present.																	1532-4435						2020	21																						
J								Robust Reinforcement Learning with Bayesian Optimisation and Quadrature	JOURNAL OF MACHINE LEARNING RESEARCH										Reinforcement Learning; Bayesian Optimisation; Bayesian Quadrature; Significant rare events; Environment variables		Bayesian optimisation has been successfully applied to a variety of reinforcement learning problems. However, the traditional approach for learning optimal policies in simulators does not utilise the opportunity to improve learning by adjusting certain environment variables: state features that are unobservable and randomly determined by the environment in a physical setting but are controllable in a simulator. This article considers the problem of finding a robust policy while taking into account the impact of environment variables. We present alternating optimisation and quadrature (ALOQ), which uses Bayesian optimisation and Bayesian quadrature to address such settings. We also present transferable ALOQ (TALOQ), for settings where simulator inaccuracies lead to difficulty in transferring the learnt policy to the physical system. We show that our algorithms are robust to the presence of significant rare events, which may not be observable under random sampling but play a substantial role in determining the optimal policy. Experimental results across different domains show that our algorithms learn robust policies efficiently.																	1532-4435						2020	21																						
J								Generating Weighted MAX-2-SAT Instances with Frustrated Loops: an RBM Case Study	JOURNAL OF MACHINE LEARNING RESEARCH										Maximum Satisfiability; Restricted Boltzmann Machine; Frustration Index; Loop Algorithm; Phase Transition	COMPUTATIONAL-COMPLEXITY; OPTIMIZATION; ALGORITHM	Many optimization problems can be cast into the maximum satisfiability (MAX-SAT) form, and many solvers have been developed for tackling such problems. To evaluate a MAX-SAT solver, it is convenient to generate hard MAX-SAT instances with known solutions. Here, we propose a method of generating weighted MAX-2-SAT instances inspired by the frustrated-loop algorithm used by the quantum annealing community. We extend the algorithm for instances of general bipartite couplings, with the associated optimization problem being the minimization of the restricted Boltzmann machine (RBM) energy over the nodal values, which is useful for effectively pre-training the RBM. The hardness of the generated instances can be tuned through a central parameter known as the frustration index. Two versions of the algorithm are presented: the random- and structured-loop algorithms. For the random-loop algorithm, we provide a thorough theoretical and empirical analysis on its mathematical properties from the perspective of frustration, and observe empirically a double phase transition behavior in the hardness scaling behavior driven by the frustration index. For the structured-loop algorithm, we show that it offers an improvement in hardness over the random-loop algorithm in the regime of high loop density, with the variation of hardness tunable through the concentration of frustrated weights.																	1532-4435						2020	21								1														
J								Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning	JOURNAL OF MACHINE LEARNING RESEARCH										Reinforcement Learning; Multi-Agent Learning; Multi-Agent Coordination	LEVEL	In many real-world settings, a team of agents must coordinate its behaviour while acting in a decentralised fashion. At the same time, it is often possible to train the agents in a centralised fashion where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a mixing network that estimates joint action-values as a monotonic combination of per-agent values. We structurally enforce that the joint-action value is monotonic in the per-agent values, through the use of non-negative weights in the mixing network, which guarantees consistency between the centralised and decentralised policies. To evaluate the performance of QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new benchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a challenging set of SMAC scenarios and show that it significantly outperforms existing multi-agent reinforcement learning methods.																	1532-4435						2020	21																						
J								Distributionally Ambiguous Optimization for Batch Bayesian Optimization	JOURNAL OF MACHINE LEARNING RESEARCH										Bayesian Optimization; Convex Optimization; Distributionally Robust Optimization; Batch Optimization; Black-Box Optimization		We propose a novel, theoretically-grounded, acquisition function for Batch Bayesian Optimization informed by insights from distributionally ambiguous optimization. Our acquisition function is a lower bound on the well-known Expected Improvement function, which requires evaluation of a Gaussian expectation over a multivariate piecewise affine function. Our bound is computed instead by evaluating the best-case expectation over all probability distributions consistent with the same mean and variance as the original Gaussian distribution. Unlike alternative approaches, including Expected Improvement, our proposed acquisition function avoids multi-dimensional integrations entirely, and can be computed exactly - even on large batch sizes - as the solution of a tractable convex optimization problem. Our suggested acquisition function can also be optimized efficiently, since first and second derivative information can be calculated inexpensively as by-products of the acquisition function calculation itself. We derive various novel theorems that ground our work theoretically and we demonstrate superior performance via simple motivating examples, benchmark functions and real-world problems.																	1532-4435						2020	21																						
J								Efficient Adjustment Sets for Population Average Causal Treatment Effect Estimation in Graphical Models	JOURNAL OF MACHINE LEARNING RESEARCH										adjustment sets; back-door formula; Bayesian networks; causal inference; semiparametric inference	MARKOV EQUIVALENCE CLASSES; SEMIPARAMETRIC EFFICIENCY	The method of covariate adjustment is often used for estimation of total treatment effects from observational studies. Restricting attention to causal linear models, a recent article (Henckel et al., 2019) derived two novel graphical criteria: one to compare the asymptotic variance of linear regression treatment effect estimators that control for certain distinct adjustment sets and another to identify the optimal adjustment set that yields the least squares estimator with the smallest asymptotic variance. In this paper we show that the same graphical criteria can be used in non-parametric causal graphical models when treatment effects are estimated using non-parametrically adjusted estimators of the interventional means. We also provide a new graphical criterion for determining the optimal adjustment set among the minimal adjustment sets and another novel graphical criterion for comparing time dependent adjustment sets. We show that uniformly optimal time dependent adjustment sets do not always exist. For point interventions, we provide a sound and complete graphical criterion for determining when a non-parametric optimally adjusted estimator of an interventional mean, or of a contrast of interventional means, is semiparametric efficient under the non-parametric causal graphical model. In addition, when the criterion is not met, we provide a sound algorithm that checks for possible simplifications of the efficient influence function of the parameter. Finally, we find an interesting connection between identification and efficient covariate adjustment estimation. Specifically, we show that if there exists an identifying formula for an interventional mean that depends only on treatment, outcome and mediators, then the non-parametric optimally adjusted estimator can never be globally efficient under the causal graphical model.																	1532-4435						2020	21								1														
J								apricot: Submodular selection for data summarization in Python	JOURNAL OF MACHINE LEARNING RESEARCH										submodular selection; submodularity; big data; machine learning; subset selection		We present apricot, an open source Python package for selecting representative subsets from large data sets using submodular optimization. The package implements several efficient greedy selection algorithms that offer strong theoretical guarantees on the quality of the selected set. Additionally, several submodular set functions are implemented, including facility location, which is broadly applicable but requires memory quadratic in the number of examples in the data set, and a feature-based function that is less broadly applicable but can scale to millions of examples. Apricot is extremely efficient, using both algorithmic speedups such as the lazy greedy algorithm and memoization as well as code optimization using numba. We demonstrate the use of subset selection by training machine learning models to comparable accuracy using either the full data set or a representative subset thereof. This paper presents an explanation of submodular selection, an overview of the features in apricot, and applications to two data sets. The code and tutorial Jupyter notebooks are available at https://github.com/jmschrei/apricot																	1532-4435						2020	21																						
J								Breaking the Curse of Nonregularity with Subagging - Inference of the Mean Outcome under Optimal Treatment Regimes	JOURNAL OF MACHINE LEARNING RESEARCH										optimal (dynamic) treatment regime; optimal value function; precision medicine; subsample aggregating; nonregularity	ROBUST ESTIMATION; CAUSAL INFERENCE; PERFORMANCE; DECISION	Precision medicine is an emerging medical approach that allows physicians to select the treatment options based on individual patient information. The goal of precision medicine is to identify the optimal treatment regime (OTR) that yields the most favorable clinical outcome. Prior to adopting any OTR in clinical practice, it is crucial to know the impact of implementing such a policy. Although considerable research has been devoted to estimating the OTR in the literature, less attention has been paid to statistical inference of the OTR. Challenges arise in the nonregular cases where the OTR is not uniquely defined. To deal with nonregularity, we develop a novel inference method for the mean outcome under an OTR (the optimal value function) based on subsample aggregating (subagging). The proposed method can be applied to multi-stage studies where treatments are sequentially assigned over time. Bootstrap aggregating (bagging) and subagging have been recognized as effective variance reduction techniques to improve unstable estimators or classifiers (Buhlmann and Yu, 2002). However, it remains unknown whether these approaches can yield valid inference results. We show the proposed confidence interval (CI) for the optimal value function achieves nominal coverage. In addition, due to the variance reduction effect of subagging, our method enjoys certain statistical optimality. Specifically, we show that the mean squared error of the proposed value estimator is strictly smaller than that based on the simple sample-splitting estimator in the nonregular cases. Moreover, under certain conditions, the length of our proposed CI is shown to be on average shorter than CIs constructed based on the existing state-of-the-art method (Luedtke and van der Laan, 2016) and the "oracle" method which works as well as if an OTR were known. Extensive numerical studies are conducted to back up our theoretical findings.																	1532-4435						2020	21																						
J								Convex and Non-Convex Approaches for Statistical Inference with Class-Conditional Noisy Labels	JOURNAL OF MACHINE LEARNING RESEARCH										generalized linear model; non-convexity; class-conditional label noise; PU-learning; regularization	PRESENCE-ONLY DATA; LOGISTIC-REGRESSION; M-ESTIMATORS; MISCLASSIFICATION; EFFICIENCY	We study the problem of estimation and testing in logistic regression with class-conditional noise in the observed labels, which has an important implication in the Positive-Unlabeled (PU) learning setting. With the key observation that the label noise problem belongs to a special sub-class of generalized linear models (GLM), we discuss convex and non-convex approaches that address this problem. A non-convex approach based on the maximum likelihood estimation produces an estimator with several optimal properties, but a convex approach has an obvious advantage in optimization. We demonstrate that in the low-dimensional setting, both estimators are consistent and asymptotically normal, where the asymptotic variance of the non-convex estimator is smaller than the convex counterpart. We also quantify the efficiency gap which provides insight into when the two methods are comparable. In the high-dimensional setting, we show that both estimation procedures achieve '2-consistency at the minimax optimal root slog p/n rates under mild conditions. Finally, we propose an inference procedure using a de-biasing approach. We validate our theoretical findings through simulations and a real-data example.																	1532-4435						2020	21																						
J								Variational Inference for Computational Imaging Inverse Problems	JOURNAL OF MACHINE LEARNING RESEARCH										Inverse Problems; Approximate Inference; Bayesian Inference; Computational Imaging	NEURAL-NETWORKS; BAYESIAN-INFERENCE; PHASE RETRIEVAL; DECONVOLUTION; ALGORITHMS	Machine learning methods for computational imaging require uncertainty estimation to be reliable in real settings. While Bayesian models offer a computationally tractable way of recovering uncertainty, they need large data volumes to be trained, which in imaging applications implicates prohibitively expensive collections with specific imaging instruments. This paper introduces a novel framework to train variational inference for inverse problems exploiting in combination few experimentally collected data, domain expertise and existing image data sets. In such a way, Bayesian machine learning models can solve imaging inverse problems with minimal data collection efforts. Extensive simulated experiments show the advantages of the proposed framework. The approach is then applied to two real experimental optics settings: holographic image reconstruction and imaging through highly scattering media. In both settings, state of the art reconstructions are achieved with little collection of training data.																	1532-4435						2020	21																						
J								Kriging Prediction with Isotropic Matern Correlations: Robustness and Experimental Designs	JOURNAL OF MACHINE LEARNING RESEARCH										Computer Experiments; Uncertainty Quantification; Scattered Data Approximation; Space-filling Designs; Bayesian Machine Learning	SCATTERED-DATA INTERPOLATION; RADIAL BASIS; REGRESSION PROBLEMS; COVARIANCE FUNCTIONS; RATES; APPROXIMATION; CONTRACTION; ASYMPTOTICS; QUANTIZATION; CONVERGENCE	This work investigates the prediction performance of the kriging predictors. We derive some error bounds for the prediction error in terms of non-asymptotic probability under the uniform metric and L-p metrics when the spectral densities of both the true and the imposed correlation functions decay algebraically. The Matern family is a prominent class of correlation functions of this kind. Our analysis shows that, when the smoothness of the imposed correlation function exceeds that of the true correlation function, the prediction error becomes more sensitive to the space-filling property of the design points. In particular, the kriging predictor can still reach the optimal rate of convergence, if the experimental design scheme is quasi-uniform. Lower bounds of the kriging prediction error are also derived under the uniform metric and Lp metrics. An accurate characterization of this error is obtained, when an oversmoothed correlation function and a space-filling design is used.																	1532-4435						2020	21																						
J								Learning from Binary Multiway Data: Probabilistic Tensor Decomposition and its Statistical Optimality	JOURNAL OF MACHINE LEARNING RESEARCH										binary tensor; CANDECOMP/PARAFAC tensor decomposition; constrained maximum likelihood estimation; diverging dimensionality; generalized linear model	PRINCIPAL COMPONENT ANALYSIS; REGRESSION; NORM	We consider the problem of decomposing a higher-order tensor with binary entries. Such data problems arise frequently in applications such as neuroimaging, recommendation system, topic modeling, and sensor network localization. We propose a multilinear Bernoulli model, develop a rank-constrained likelihood-based estimation method, and obtain the theoretical accuracy guarantees. In contrast to continuous-valued problems, the binary tensor problem exhibits an interesting phase transition phenomenon according to the signal-tonoise ratio. The error bound for the parameter tensor estimation is established, and we show that the obtained rate is minimax optimal under the considered model. Furthermore, we develop an alternating optimization algorithm with convergence guarantees. The efficacy of our approach is demonstrated through both simulations and analyses of multiple data sets on the tasks of tensor completion and clustering.																	1532-4435						2020	21																						
J								Spectral Algorithms for Community Detection in Directed Networks	JOURNAL OF MACHINE LEARNING RESEARCH										directed networks; community detection; clustering; degree-corrected block model; k-means; principle component analysis		Community detection in large social networks is affected by degree heterogeneity of nodes. The D-SCORE algorithm for directed networks was introduced to reduce this effect by taking the element-wise ratios of the singular vectors of the adjacency matrix before clustering. Meaningful results were obtained for the statistician citation network, but rigorous analysis on its performance was missing. First, this paper establishes theoretical guarantee for this algorithm and its variants for the directed degree-corrected block model (Directed-DCBM). Second, this paper provides significant improvements for the original D-SCORE algorithms by attaching the nodes outside of the community cores using the information of the original network instead of the singular vectors.																	1532-4435						2020	21																						
J								Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information	JOURNAL OF MACHINE LEARNING RESEARCH										Pairwise Comparison; Ranking; Regression; Interactive Learning	RISK BOUNDS	In supervised learning, we typically leverage a fully labeled dataset to design methods for function estimation or prediction. In many practical situations, we are able to obtain alternative feedback, possibly at a low cost. A broad goal is to understand the usefulness of, and to design algorithms to exploit, this alternative feedback. In this paper, we consider a semi-supervised regression setting, where we obtain additional ordinal (or comparison) information for the unlabeled samples. We consider ordinal feedback of varying qualities where we have either a perfect ordering of the samples, a noisy ordering of the samples or noisy pairwise comparisons between the samples. We provide a precise quantification of the usefulness of these types of ordinal feedback in both nonparametric and linear regression, showing that in many cases it is possible to accurately estimate an underlying function with a very small labeled set, effectively escaping the curse of dimensionality. We also present lower bounds, that establish fundamental limits for the task and show that our algorithms are optimal in a variety of settings. Finally, we present extensive experiments on new datasets that demonstrate the efficacy and practicality of our algorithms and investigate their robustness to various sources of noise and model misspecification.																	1532-4435						2020	21																						
J								Dual Iterative Hard Thresholding	JOURNAL OF MACHINE LEARNING RESEARCH										Iterative hard thresholding; Duality theory; Sparsity recovery; Non-convex optimization	SPARSITY; OPTIMIZATION; ALGORITHM; SELECTION; LASSO	Iterative Hard Thresholding (IHT) is a popular class of first-order greedy selection methods for loss minimization under cardinality constraint. The existing IHT-style algorithms, however, are proposed for minimizing the primal formulation. It is still an open issue to explore duality theory and algorithms for such a non-convex and NP-hard combinatorial optimization problem. To address this issue, we develop in this article a novel duality theory for l(2)-regularized empirical risk minimization under cardinality constraint, along with an IHT-style algorithm for dual optimization. Our sparse duality theory establishes a set of sufficient and/or necessary conditions under which the original non-convex problem can be equivalently or approximately solved in a concave dual formulation. In view of this theory, we propose the Dual IHT (DIHT) algorithm as a super-gradient ascent method to solve the non-smooth dual problem with provable guarantees on primal-dual gap convergence and sparsity recovery. Numerical results confirm our theoretical predictions and demonstrate the superiority of DIHT to the state-of-the-art primal IHT-style algorithms in model estimation accuracy and computational efficiency.(1)																	1532-4435						2020	21																						
J								Complete Dictionary Learning via l(4)-Norm Maximization over the Orthogonal Group	JOURNAL OF MACHINE LEARNING RESEARCH										sparse dictionary learning; l(4)-norm maximization; orthogonal group; measure concentration; fixed point algorithm	SPARSE; ALGORITHMS; EQUATIONS; NORM	This paper considers the fundamental problem of learning a complete (orthogonal) dictionary from samples of sparsely generated signals. Most existing methods solve the dictionary (and sparse representations) based on heuristic algorithms, usually without theoretical guarantees for either optimality or complexity. The recent l(1)-minimization based methods do provide such guarantees but the associated algorithms recover the dictionary one column at a time. In this work, we propose a new formulation that maximizes the l(4)-norm over the orthogonal group, to learn the entire dictionary. We prove that under a random data model, with nearly minimum sample complexity, the global optima of the l(4)-norm are very close to signed permutations of the ground truth. Inspired by this observation, we give a conceptually simple and yet effective algorithm based on "matching, stretching, and projection" (MSP). The algorithm provably converges locally and cost per iteration is merely an SVD. In addition to strong theoretical guarantees, experiments show that the new algorithm is significantly more efficient and effective than existing methods, including KSVD and l(1)-based methods. Preliminary experimental results on mixed real imagery data clearly demonstrate advantages of so learned dictionary over classic PCA bases.																	1532-4435						2020	21																						
J								Novel Cross-Entropy Based on Multi-attribute Group Decision-Making with Unknown Experts' Weights Under Interval-Valued Intuitionistic Fuzzy Environment	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Interval-valued intuitionistic fuzzy set; Experts' weights; Cross-entropy; Multi-attribute group decision-making	DIVERGENCE; MAGDM	This paper studies the multi-attribute group decision-making problems with unknown experts' weights under interval-valued intuitionistic fuzzy environment. First, in order to provide more flexibilities for decision-makers in actual decision-making problems, a novel cross-entropy measure with parameter of interval-valued intuitionistic fuzzy set (IVIFS) based on J-divergence is proposed. The novel cross-entropy measure can obtain more flexible and practical optimal ranking results by adjusting the parameter. Then, by using the designed cross-entropy measure, two models are established to obtain experts' weights, which consider the influence of experts' experience and professional knowledge on experts' weights. Finally, two examples are provided to illustrate the effectiveness and applicability of optimizing the group decision-making approach. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1295	1304		10.2991/ijcis.d.200817.001													
J								Who Is the Designer? ARC-100 Database and Benchmark on Architecture Classification	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Architecture; Building; Classification; Segmentation; CNN		Architecture is about evolution, there exist many types of architectural styles that depend on the geography, traditions, and culture of the particular regions. An architectural designer may have a similar preference in creating the new architectural building, which can be easily recognized from the physical attributes and characteristics. This paper performs an architect classification based on the outward appearance of the building. An architecture database with 100 images (ARC-100) that have balanced class distribution is constructed. Among the architectural buildings, the best performance is 71% for 5-class classification. Convolutional neural networks (CNNs) have demonstrated breakthrough performance on various classification tasks in recent studies, and even outperform human experts in specific tasks. Thus, for the baseline evaluation, multiple pretrained CNN models are employed with slight modifications. Prior to the feature extraction and classification processes, the removal of background noise is performed using two approaches: manually and automatically. The former approach requires high human intervention, while the latter utilizes the cutting-edge object segmentation technology, namely mask regional convolutional neural network (R-CNN). The illustration of the experiment training progress and the confusion matrix are reported, to allow further interpretation and analysis for the model trained. Notably, this is the first work that performs automatic classification based on architectural styles. This framework can be used to improve the cultural understanding and practices in providing education for holistic development and enhance the learning experience and progressions from an aesthetic perspective. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1305	1314		10.2991/ijcis.d.200824.001													
J								Quantum Behavior-Based Enhanced Fruit Fly Optimization Algorithm with Application to UAV Path Planning	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Fruit fly optimization algorithm; Continuous function optimization; Delta potential well; Quantum behavior; Path planning	GA ALGORITHM	As a newly developed simple and effective optimization technology, the fruit fly optimization algorithm (FOA) has been successfully applied in many fields. To accelerate the algorithm convergence and avoid the local optimum, the enhanced FOA based on quantum theory called QFOA is proposed in this paper. When establishing the quantum Delta potential well around the location of fruit fly swarm, QFOA introduces the quantum behavior-based searching mechanism into the original osphresis-based search procedure of FOA. In the process that fruit flies find and move toward the food source, fruit flies follow the wave function property of the Delta potential well rather than the Newtonian mechanics. Taking advantage of the probability and uncertainty of quantum theory, the proposed QFOA can effectively overcome the weakness in premature convergence and easy trapping into local optimum. Since there are two popular models of the basic FOA, this paper also develops two corresponding QFOAs. Experimental results on various benchmark functions show that both the two QFOA models has overall better performance compared with the basic FOA as well as other FOA variants and other well-known optimization algorithms. In addition, the proposed QFOAs are also applied to unmanned aerial vehicle (UAV) path planning problem in the three-dimensional environment, and comparative results about the obtained optimal flight path and population convergence process show the effectiveness of QFOAs. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1315	1331		10.2991/ijcis.d.200825.001													
J								Learning Layer-Skippable Inference Network	IEEE TRANSACTIONS ON IMAGE PROCESSING										Task analysis; Visualization; Computational modeling; Biological information theory; Computational efficiency; Neurons; Learning (artificial intelligence); Supervised learning; neural networks	ALLOCATION; MIXTURES; MODEL	The process of learning good representations for machine learning tasks can be very computationally expensive. Typically, the model learned on training set is leveraged to infer the labels of testing data. Interestingly, this learning and inference paradigm, however, is quite different from the typical inference scheme of human biological visual systems. Essentially, neuroscience studies have shown that the right hemisphere of the human brain predominantly makes a fast processing of low-frequency spatial signals, while the left hemisphere more focuses on analyzing high-frequency information in a slower way. And the low-pass analysis helps facilitate the high-pass analysis via feedback. Inspired by this biological vision mechanism, this article explores the possibility of learning a layer-skippable inference network. Specifically, we propose a layer-skippable network that dynamically carries out coarse-to-fine object categorization. Such a network has two branches to jointly deal with both coarse and fine-grained classification tasks. The layer-skipping mechanism is proposed to learn a gating network by generating dynamic inference graphs, and reducing the computational cost by detouring the inference path from some layers. This adaptive path inference strategy endows the deep networks with dynamic structures, making the networks enjoy greater flexibility and larger capacity. To efficiently train the gating network, a novel ranking-based loss function is adopted. Furthermore, the learned representations are enhanced by the proposed top-down feedback mechanism and feature-wise affine transformation, individually. The former one employs features of a coarse branch to help the fine-grained object recognition task, while the latter one encodes the selected path to enhance the final feature representations. Extensive experiments are conducted on several widely used coarse-to-fine object categorization benchmarks, and promising results are achieved by our proposed model. Quite surprisingly, our layer-skipping mechanism improves the network robustness to adversarial attacks.																	1057-7149	1941-0042					2020	29						8747	8759		10.1109/TIP.2020.3018269													
J								EraseNet: End-to-End Text Removal in the Wild	IEEE TRANSACTIONS ON IMAGE PROCESSING										Scene text removal; privacy protection; generative adversarial network (GAN)		Scene text removal has attracted increasing research interests owing to its valuable applications in privacy protection, camera-based virtual reality translation, and image editing. However, existing approaches, which fall short on real applications, are mainly because they were evaluated on synthetic or unrepresentative datasets. To fill this gap and facilitate this research direction, this article proposes a real-world dataset called SCUT-EnsText that consists of 3,562 diverse images selected from public scene text reading benchmarks, and each image is scrupulously annotated to provide visually plausible erasure targets. With SCUT-EnsText, we design a novel GAN-based model termed EraseNet that can automatically remove text located on the natural images. The model is a two-stage network that consists of a coarse-erasure sub-network and a refinement sub-network. The refinement sub-network targets improvement in the feature representation and refinement of the coarse outputs to enhance the removal performance. Additionally, EraseNet contains a segmentation head for text perception and a local-global SN-Patch-GAN with spectral normalization (SN) on both the generator and discriminator for maintaining the training stability and the congruity of the erased regions. A sufficient number of experiments are conducted on both the previous public dataset and the brand-new SCUT-EnsText. Our EraseNet significantly outperforms the existing state-of-the-art methods in terms of all metrics, with remarkably superior higher-quality results. The dataset and code will be made available at https://github.com/HCIILAB/SCUT-EnsText.																	1057-7149	1941-0042					2020	29						8760	8775		10.1109/TIP.2020.3018859													
J								Texture Classification Using Pair-Wise Difference Pooling-Based Bilinear Convolutional Neural Networks	IEEE TRANSACTIONS ON IMAGE PROCESSING										Feature extraction; Visualization; Convolutional neural networks; Principal component analysis; Machine learning; Image recognition; Training; Texture classification; texture features; texture; CNNs; BCNNs	FEATURES; HISTOGRAMS; SCALE	Texture is normally represented by aggregating local features based on the assumption of spatial homogeneity. Effective texture features are always the research focus even though both hand-crafted and deep learning approaches have been extensively investigated. Motivated by the success of Bilinear Convolutional Neural Networks (BCNNs) in fine-grained image recognition, we propose to incorporate the BCNN with the Pair-wise Difference Pooling (i.e. BCNN-PDP) for texture classification. The BCNN-PDP is built on top of a set of feature maps extracted at a convolutional layer of the pre-trained CNN. Compared with the outer product used by the original BCNN feature set, the pair-wise difference not only captures the pair-wise relationship between two sets of features but also encodes the difference between each pair of features. Considering the importance of the gradient data to the representation of image structures, we further generalise the BCNN-PDP feature set to two sets of feature maps computed from the original image and its gradient magnitude map respectively, i.e. the Fused BCNN-PDP (F-BCNN-PDP) feature set. In addition, the BCNN-PDP can be applied to two different CNNs and is referred to as the Asymmetric BCNN-PDP (A-BCNN-PDP). The three PDP-based BCNN feature sets can also be extracted at multiple scales. Since the dimensionality of the BCNN feature vectors is very high, we propose a new yet simple Block-wise PCA (BPCA) method in order to derive more compact feature vectors. The proposed methods are tested on seven different datasets along with 21 baseline feature sets. The results show that the proposed feature sets are superior, or at least comparable, to their counterparts across different datasets.																	1057-7149	1941-0042					2020	29						8776	8790		10.1109/TIP.2020.3019185													
J								Simultaneous Surface Reflectance and Fluorescence Spectra Estimation	IEEE TRANSACTIONS ON IMAGE PROCESSING										Estimation; Photonics; Cameras; Optimization; Light sources; Fluorescence; Reflectance and fluorescence spectra recovery; multispectral and hyperspectral imaging; image color analysis; inverse problems	SPECTROSCOPY; COMPONENTS; SIGNALS; SCENES; LIGHT	There is widespread interest in estimating the fluorescence properties of natural materials in an image. However, the separation between reflected and fluoresced components is difficult, because it is impossible to distinguish reflected and fluoresced photons without controlling the illuminant spectrum. We show how to jointly estimate the reflectance and fluorescence from a single set of images acquired under multiple illuminants. We present a framework based on a linear approximation to the physical equations describing image formation in terms of surface spectral reflectance and fluorescence due to multiple fluorophores. We relax the non-convex, inverse estimation problem in order to jointly estimate the reflectance and fluorescence properties in a single optimization step. We provide a software implementation of the solver for our method and prior methods. We evaluate the accuracy and reliability of the method using both simulations and experimental data. To evaluate the methods experimentally we built a custom imaging system using a monochrome camera, a filter wheel with bandpass transmissive filters and a small number of light emitting diodes. We compared the methods based upon our framework with the ground truth as well as with prior methods.																	1057-7149	1941-0042					2020	29						8791	8804		10.1109/TIP.2020.2973810													
J								Spatiotemporal Tree Filtering for Enhancing Image Change Detection	IEEE TRANSACTIONS ON IMAGE PROCESSING										Maximum likelihood detection; Nonlinear filters; Information filters; Filtering theory; Spatiotemporal phenomena; Change detection; binary mask enhancement; tree filtering; spatiotemporal filtering; post-processing	SEGMENTATION; SEQUENCES	Change detection has received extensive attention because of its realistic significance and broad application fields. However, none of the existing change detection algorithms can handle all scenarios and tasks so far. Different from the most of contributions from the research community in recent years, this paper does not work on designing new change detection algorithms. We, instead, solve the problem from another perspective by enhancing the raw detection results after change detection. As a result, the proposed method is applicable to various kinds of change detection methods, and regardless of how the results are detected. In this paper, we propose Fast Spatiotemporal Tree Filter (FSTF), a purely unsupervised detection method, to enhance coarse binary detection masks obtained by different kinds of change detection methods. In detail, the proposed FSTF has adopted a volumetric structure to effectively synthesize spatiotemporal information of the same target from the current time and history frames to enhance detection. The computational complexity analyzed in the view of graph theory also show that the fast realization of FSTF is a linear time algorithm, which is capable of handling efficient on-line detection tasks. Finally, comprehensive experiments based on qualitative and quantitative analysis verify that FSTF-based change detection enhancement is superior to several other state-of-the-art methods including fully connected Conditional Random Field (CRF), joint bilateral filter, and guided filter. It is illustrated that FSTF is versatile enough to also improve saliency detection as well as semantic image segmentation.																	1057-7149	1941-0042					2020	29						8805	8820		10.1109/TIP.2020.3017339													
J								Predicting short-term traffic flow in urban based on multivariate linear regression model	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Multivariate linear regression model; short-term traffic flow in urban; flow prediction; spatial static attributes		In order to overcome the problems of low accuracy and time-consuming of traditional prediction methods for short-term traffic flow in urban, a prediction methods for short-term traffic flow in urban based on multiple linear regression model is proposed. The corresponding data attributes of short-term traffic flow in urban are selected by traffic operation status, and used as the original data of traffic flow prediction. According to the selected attributes, spatial static attributes data and traffic flow dynamic attributes data are collected, and fault data are identified and repaired. A multiple linear regression model for prediction of short-term traffic flow in urban is constructed to realize the prediction of short-term traffic flow in urban. The experimental results show that, compared with other methods, the average prediction accuracy of the proposed method is as high as 98.48%, and the prediction time is always less than 0.7 s, which is shorter.																	1064-1246	1875-8967					2020	39	2					1417	1427		10.3233/JIFS-179916													
J								Early warning for abnormal load fluctuation of wind farm load based on probabilistic neural network	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Probabilistic neural network; wind farm load; abnormal fluctuation; early warning	FREQUENCY	In order to overcome the serious errors of wind farm load abnormal fluctuation forecasting results caused by traditional forecasting methods, a wind farm load abnormal fluctuation forecasting method based on probabilistic neural network is proposed in this paper. The probabilistic density is screened out by probabilistic neural network, and the maximum posterior probability density neuron is used as the output to realize wind farm load forecasting. According to the prediction results, a comprehensive severity subordinate function is constructed based on fuzzy reasoning to classify the severity of wind farm anomalies. According to the fuzzy operation rules, the abnormal fluctuation of wind farm load can be warned. The experimental results show that the operation error of the proposed method is only 0.49, the accuracy of early warning is high, and the effective fitting index is up to 0.95, which shows that the proposed method has high practical application value.																	1064-1246	1875-8967					2020	39	2					1429	1438		10.3233/JIFS-179917													
J								Power instability prediction method for wind turbine based on fuzzy decision tree	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Fuzzy decision tree; wind turbine power; instability prediction; prediction model	STATIONS	In order to improve the accuracy and efficiency of power instability prediction for wind turbines, a power instability prediction method for wind turbines based on fuzzy decision tree is proposed. According to the variation curve of maximum output power, the maximum power of wind turbine is searched and controlled by climbing hill. The maximum power of wind turbine is tracked by the control results. The power fluctuation periodicity rule is obtained based on the fuzzy decision tree. The power instability prediction model of wind turbine is established to realize the power instability prediction. The experimental results show that the proposed method has high effectiveness, the highest prediction accuracy can reach 95.53%, and the maximum prediction time is only 1.8 s, which fully shows that the proposed method is more suitable for the power instability prediction of wind turbines.																	1064-1246	1875-8967					2020	39	2					1439	1447		10.3233/JIFS-179918													
J								Optimal defense strategy model based on differential game in edge computing	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Edge computing; differential game; defense strategy		Edge computing extends the cloud computing paradigm to the edge of the network to offset the shortcomings of traditional cloud computing in mobile support, low delay, and location awareness. However, traditional complicated encryption algorithms, access control measures, identification protocols, and privacy protection methods are inapplicable to security defense of edge computing given the multisource data fusion characteristics of edge computing, superposition of mobile and the Internet, and resource limitations in storage, computing, and battery capacity of edge terminals. Therefore, a reasonable defense model for complicated dynamic edge computing environment must be established. In accordance with the characteristics of limited resources of edge devices, combined with dynamic game theory, this study proposes an optimal defense strategy model based on a differential game and solves the optimal defense strategy of edge nodes in infinite and finite-horizons. The optimal defense strategy of the edge nodes was simulated under different conditions, and the simulation verifies that the edge nodes can obtain the optimal defense effect with minimum resource consumption when cooperating to form the defense system.																	1064-1246	1875-8967					2020	39	2					1449	1459		10.3233/JIFS-179919													
J								Analysis of vibration high-frequency dynamic characteristics of wheelless rail vehicle system based on fuzzy logic control	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Ballastless track; wheel-rail vehicle; high frequency vibration; dynamic characteristics; fuzzy logic control	MODEL	Track irregularity is the main source of vibration excitation of vehicle-track weighing system, which has an important impact on the safety, stability and comfort of train operation, and it is also the main factor limiting the speed of train operation. Higher requirements are put forward for track smoothness with the rapid development of China's railways. Therefore, it has a great theoretical and practical significance to study the relationship between track irregularity and random vibration of vehicle-track cooker-in system and the evaluation method of track smoothness. In this paper, a model construction method is proposed based on machine learning fuzzy logic control and neural network algorithm to analyze the high frequency dynamic characteristics of ballastless track wheel-rail vehicle system. Firstly, a numerical analysis model of high frequency dynamic characteristics of ballastless track wheel-rail vehicle system is established by using linear discrete elastic-yellow damper element connection model; Secondly, the Rough Set Block Neural Network is introduced to optimize the dynamic characteristic analysis model, and the intelligent model of model optimization analysis is established. Finally, the validity of the proposed algorithm is verified by simulation experiments of practical examples.																	1064-1246	1875-8967					2020	39	2					1461	1469		10.3233/JIFS-179920													
J								Social network visual simulation for process reengineering of construction change management under building information modelling technology	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Construction change management; process reengineering; building information modelling; visual analysis; social; network analysis		Construction change management is an important part of construction project management. Previous studies usually focus on the various steps of construction change control: analyzing the causes of change, avoiding the risk of change, tracking the process of change, management and feedback of change. This study focused on improving the information flow and organizational relationship of the participants in the process of construction change management, which was reengineered with the use of Building Information Modelling (BIM) technology for better information integration. As BIM technology provides technical means for information transaction and management, a reengineered construction change management process based on BIM technology was proposed to form a more effective way of putting forward, examine, issuing, updating and archiving the information. Both the workflow and the organizational units involved in each work step were reengineered to improve the information flow. To verify the effect of process reengineering, Uncinet, a visual analysis tool for Social network analysis (SNA) was applied to quantitatively analyze and compare the traditional and BIM based organizational structure. The research results demonstrated that BIM was helpful to strengthen organizational coordination and information exchange in construction change management process.																	1064-1246	1875-8967					2020	39	2					1471	1480		10.3233/JIFS-179921													
J								Influence model of wind power capacity in load response system under smart grid environment	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Smart grid; consumption; load response; power system	OPTIMIZATION; ALGORITHM; MANAGEMENT; STRATEGY	With the increasing global energy crisis, wind power is gradually favored by people for its sustainability and cleanliness. When the wind power is connected with the power system, the problem of grid connection must be overcome. In order to better meet the demand load interactive response in smart grid environment, a multi-layer scheduling two-dimensional operation model was proposed. The mechanism of wind power uncertainty was analyzed. Thus, wind power prediction algorithm was established, and the concept of probability based multi-level scheduling was introduced to improve the adaptability of the model as a whole. In order to verify the reliability and effectiveness of the method, case experiments were carried out. The results show that the method can effectively help wind power consumption when ensuring economic and reliable conditions.																	1064-1246	1875-8967					2020	39	2					1481	1488		10.3233/JIFS-179922													
J								Uncertainty prediction method for traffic flow based on K-nearest neighbor algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										K-nearest neighbor algorithm; traffic flow; uncertainty prediction; Kalman filtering concept		In order to overcome the problem of low fitting between traffic uncertainty prediction results and actual values in existing research methods, a traffic flow uncertainty prediction method based on K-nearest neighbor algorithm is proposed. The original database, classification center database, k-nearest neighbor database and intermediate search database are used to construct the database needed in the prediction process. Based on the database, multivariate linear regression is used to assign weights to state variables, and k-nearest neighbor algorithm and Kalman filter are used to update the weights to adapt to the uncertainties of traffic flow until the predicted values are obtained, and the uncertainties of traffic flow are predicted. The experimental results show that the maximum average absolute error and average relative error of the proposed method are 0.018 and 0.02, respectively. Compared with the traditional method, the proposed method has higher overall prediction accuracy, higher fitting degree, and is feasible.																	1064-1246	1875-8967					2020	39	2					1489	1499		10.3233/JIFS-179923													
J								Short-term forecasting method for dynamic traffic flow based on stochastic forest algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Stochastic forest algorithm; dynamic traffic; short-term forecasting; traffic flow; forecasting method		In order to overcome the problems of low accuracy and long time-consuming in traditional short-term forecasting methods for dynamic traffic flow, a short-term forecasting method for dynamic traffic flow based on stochastic forest algorithm is proposed in this paper. This method chooses short-term forecasting equipment for dynamic traffic flow, eliminates invalid data from the collected data, and normalizes the available data to complete data preprocessing before traffic flow forecasting. A combined forecasting model is established to optimize the output of the pretreatment results and complete the dynamic traffic flow rate forecasting. On this basis, the stochastic forest algorithm is introduced to train the sampling set of flow rate decision tree and generate short-term flow decision tree to realize short-term forecasting of dynamic traffic flow. The experimental results show that the forecasting time of the proposed method is short, always less than 0.5 s, and the forecasting accuracy is high, with more than 97%, so it is feasible.																	1064-1246	1875-8967					2020	39	2					1501	1513		10.3233/JIFS-179924													
J								A risk investment evaluation method based on dynamic bayesian network and fuzzy system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Multi-factor; dynamic bayes; mortgage loan; demand analysis; fuzzy system		In order to enhance the risk investment evaluation algorithm precision of forestry rights mortgage of farmers, this paper provides a method of risk investment validating process of forestry rights mortgage of farmers based on dynamic Bayes network (DBN) and fuzzy system. For that have to be processed fuzzy data in time arrangement and evaluate the circumstance viably, Intuitionistic Fuzzy Dynamic Bayesian Network (IFDBN) is assembled. Intuitionistic fuzzy thinking is implanted into DBN as a virtual node in this method. Also, another technique to change over the intuitionistic fuzzy thinking yield into likelihood that could contribution to DBN as proof is proposed. Firstly, it analyzes the risk investment of forestry rights mortgage of farmers, raises the risk evaluation system and adopts normalization and factor analysis methods to pre-process the model index; secondly, by aid of a four-layer DBN model, it puts forward the hierarchical DBN model of risk investment, having input layer, fuzzy layer, fuzzy inference layer and output layer, designs the composition and calculation mode of fuzzy function module and DBN module; Finally, it verifies the viability of the calculation through experimental examination.																	1064-1246	1875-8967					2020	39	2					1515	1523		10.3233/JIFS-179925													
J								Application of hybrid GA-PSO based on intelligent control fuzzy system in the integrated scheduling in automated container terminal	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Automated container terminal; intelligent control fuzzy system; loading and unloading operation; intelligent optimization	QUAY CRANE; GENETIC ALGORITHM; BAT ALGORITHM; YARD CRANE; OPTIMIZATION; TRUCK; STRATEGY; STORAGE; TIME; OPERATIONS	With the development of the large ship, automated container terminals (ACTs) have serious energy consumption and carbon emission problems, reducing the loading and unloading time of ships can ease energy consumption, improve the working efficiency and service level of automated terminals. This paper studies the integrated scheduling problem of the gantry cranes (QCs), automated guided vehicles (AGVs) and automated rail-mounted gantry (ARMG) in automated terminal. According to the loading and unloading operation mode, we build the mixed integer programming model with the goal of minimizing the ship loading and unloading time, and through various algorithms of heuristic and hybrid improved to solve this problem, it proves the effectiveness of the model to obtain optimized scheduling scheme by numerical experiments, and comparing the different performance of algorithms, the results show that the hybrid GA-PSO algorithm with adaptive auto tuning is superior to other algorithms in terms of solution time and quality, which can effectively solve the problem of integrated scheduling to save the energy of automated container terminal.																	1064-1246	1875-8967					2020	39	2					1525	1538		10.3233/JIFS-179926													
J								Fuzzy clustering discrete equilibrium analysis on the promotion of government venture investment to enterprise innovation	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										International perspective; enterprise innovation; fuzzy clustering; discrete equilibrium analysis	CEREBROSPINAL-FLUID	In order to effectively improve the accuracy of related analysis models in the application of government risk investment, a government risk investment prediction model based on fuzzy clustering discrete algorithm is put forward in this paper. First of all, government risk investment problem is analyzed. Based on Markowitz theory, the general government risk investment model is considered, and the market value constraint and the upper bound constraint are combined to improve the government risk investment model and obtain the mixed constraint government risk investment model. Secondly, the fuzzy clustering discrete algorithm is introduced in the analysis process of government venture investment model, and it is used to solve the mixed constraint analysis model of government venture investment. In addition, to further improve the performance of discrete algorithm based on fuzzy clustering in the model solving process, automatic contraction and expansion of factors is used to carry out adaptive learning of related parameters based fuzzy clustering discrete algorithm, and improve the convergence of the algorithm. Finally, the simulation experiments on some stock samples of investment sector show that the algorithm in this paper can obtain more ideal government venture investment schemes, so as to reduce investment risk and obtain greater investment returns.																	1064-1246	1875-8967					2020	39	2					1539	1546		10.3233/JIFS-179927													
J								A group authentication and privacy-preserving level for vehicular networks based on fuzzy system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Group authentication; key agreement; LTE-A; vehicular network; fuzzy system	HANDOVER AUTHENTICATION; SCHEME; SECURITY; PROTOCOL; MACHINE	Vehicular ad hoc networks play an important role in current intelligent transportation networks, which have attracted much attention from academia and industry. Vehicular networks can be implemented by Long-Term Evolution Advanced (LTE-A) networks, which have been formally defined in a series of standards by third-generation partnership projects (3GPP). Abundant challenges exist in the authentication processes in LTE-A-based vehicular networks. This paper aimed to improve the security functionality of these vehicular networks by proposing a secure and efficient group authentication and privacy-preserving scheme for vehicular networks based on fuzzy system: the group authentication and privacy-preserving level (GAPL). Compared with existing schemes, the proposed scheme can greatly reduce the number of control message transmissions from mass vehicular equipment (VEs) to the network and substantially avoid overhead in LTE-A-based vehicular networks. Privacy-preserving levels are established to protect VE privacy in authentication. Furthermore, the scheme contains security functions, including privacy preservation, non-frameability and non-repudiation verification.																	1064-1246	1875-8967					2020	39	2					1547	1562		10.3233/JIFS-179928													
J								Performance evaluation of enterprises' innovation capacity based on fuzzy system model and convolutional neural network	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Innovation network; fuzzy system model; convolutional neural network (CNN)	RISK-ASSESSMENT; UNCERTAINTY	Influenced by national policies and macro-economic environment, large domestic enterprises is actively promoting strategic transformation to enhance their core competitiveness, and performance evaluation of enterprises' innovation capacity has become a hot topic in recent years. This paper proposes a performance evaluation method of enterprises' innovation capacity based on deep learning fuzzy system model and convolutional neural network analysis of innovation network. First of all, on account of the characteristics of breakthrough innovation and drawing on the traditional innovation performance evaluation model, this paper constructs a breakthrough innovation performance evaluation index system for enterprises from the six dimensions of main resource input, technology out-turn, process management, product performance, social value and commercial Value. Secondly, the introduction of machine learning of fuzzy convolutional neural network to assess the advancement execution of enterprises is of great significance for enterprise managers to find out the problems and causes of enterprises' innovation, optimize the allocation of enterprises' resources and further improve the innovation performance of enterprises. The experimental results show to verify the adequacy of the algorithm.																	1064-1246	1875-8967					2020	39	2					1563	1571		10.3233/JIFS-179929													
J								Permanent magnet synchronous motor algorithms based on nonlinear identification generalized predictive and Intelligent fuzzy control system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Nonlinear identification; generalized predictive control; permanent magnet synchronous motor; intelligent fuzzy control system	NEURAL-NETWORK	A control strategy of permanent magnet-oriented field synchronous motor based on intelligent fuzzy control system and generalized predictive control with non-linear identification is proposed to develop the effectiveness of the controlling method of constant magnet-oriented field synchronous motor, the accessor can be split into stabilization control part and intelligent control part. The input of traditional feedback control is used as the stabilization control part, while the feed-forward is incorporated into the intelligent part to compensate for the uncertainties of repetitive load torque and model parameters. The proposed feed forward compensation term uses simple learning rules without any load torque disturbance observer. The additional learning feed forward term does not require information about motor parameters and load torque values, it is insensitive to load torque uncertainty and model parameters, and does not need to identify the system model. With that, the solidness and intermingling confirmation of the proposed control framework reaction is given. The exploratory outcomes demonstrate that the proposed technique has littler speed overshoot list, and the heap torque against aggravation capacity list is improved by over 30%.																	1064-1246	1875-8967					2020	39	2					1573	1579		10.3233/JIFS-179930													
J								Wireless sensor network model with uncertain delay and packet loss based on intelligent fuzzy system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Time delay; intelligent fuzzy system; linear matrix inequality (LMIs); memory robust H-infinity controller		The utilization of fuzzy logic in WSNs is demonstrated to be a promising procedure since it permits joining and assessing various parameters in an effective way. Fuzzy logic is a decent methodology because of the execution prerequisites can be effectively supported by sensor hubs, while it can improve the general system execution. This paper studies the robust Hy, control considering time delay and packet loss related uncertainty in wireless sensor network system based on the basic theory of intelligent fuzzy systems. The model of a wireless sensor network with questionable time lag and packet loss is given first. The stability of the system is proved by the augmented Lyapunov functional and the linear matrix inequality (LMIs) method, with its demonstrated Hy, property. In order to solve the uncertain time delay and packet loss, the memory robust Hy, controller is proposed based on LMIs. Numerical examples and simulation results examines the potency of the presented method in solving the delay and packet loss of wireless sensor networks as well as the accuracy and precision of the system.																	1064-1246	1875-8967					2020	39	2					1581	1590		10.3233/JIFS-179931													
J								Numerical simulation of three dimensional flow in Yazidang Reservoir based on image processing	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Water flow movement; the Yazidang Reservoir; image stitching; edge detection; 3D k - epsilon mathematical model; numerical simulation; flow field	MODEL	In order to study the water flow movement of the Yazidang Reservoir, this paper generates the initial terrain for the researched water area with the image stitching technology and image edge detection technology, establishes a 3D k - epsilon mathematical model, solves the equations discretely by FVM and SIMPLEC algorithms, studies the numerical simulation of the water flow movement of the reservoir under four working conditions, and analyzes the flow field on the surface and at the bottom of the reservoir. The results show the improved terrain pre-processing accuracy and efficiency of the researched water area and the rationality of the water flow field and rate simulation results, which means that the established 3D turbulence mathematical model can be applied to the numerical simulation of the reservoirs similar to the Yazidang Reservoir. The numerical simulation of 3D turbulence in Yazidang Reservoir provides a theoretical basis and practical application value for the numerical simulation of similar reservoirs.																	1064-1246	1875-8967					2020	39	2					1591	1600		10.3233/JIFS-179932													
J								The effect of experienced buyers' feedback on consumer behavior: Evidence from the largest online marketplace in China	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Online feedback mechanism; fake online reviews; e-commerce; experienced consumer reviews	WORD-OF-MOUTH; EPISTEMIC AUTHORITY; REPUTATION; REVIEWS; TRUST; COOPERATION; DYNAMICS; QUALITY; DESIGN; PRICE	Fake online reviews are so prevalent that e-commerce platforms attempt to control it from affecting the trustwor-thiness between buyers and sellers. The issue has also attracted sporadic scholarly endeavor to understand this new field. To address this issue, we propose a new model to examine three interrelated stakeholders of e-Commerce platforms: experienced buyers, future buyers and the online sellers in terms of purchasing behaviors and sales with three objectives. Experienced buyers influence future consumers' behaviors and increase sales from sellers. Using data collected from the largest online e-commerce platform in China, we test relevant hypotheses. Our findings show that experienced buyers and their positive reviews increase future buyers' purchasing and promote corporate sales. These findings contribute knowledge to the online feedback mechanism and literature on fake review studies. This study also provides a novel method to help buyers avoid fake online review from a market structure perspective.																	1064-1246	1875-8967					2020	39	2					1601	1610		10.3233/JIFS-179933													
J								Cellular cholesterol prediction of mammalian ATP-binding cassette (ABC) proteins based on fuzzy c-means with support vector machine algorithms	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										ABC transporter; FCM; SVM; Prokaryotes/ Eukaryotes; CRAC/CARC	MULTIDRUG-RESISTANCE; TANGIER-DISEASE; ORGANIZATION; MODEL	Over the years protein interaction and prediction of membrane protein have been a pivotal research area for all researchers. For both prokaryotes and eukaryotes Adenosine Triphosphate-(ATP) binding cassette (ABC) genes plays a significant role. In our analysis, we concentrate on human part of ABC genes. In case of living organisms transport of precise molecules across lipid membranes has been treated as vital part and for that reason a bigger transporter is required to carry out the molecules. Here ABC transporter families are evolved to transport the specific molecules such as sugars, amino acid, peptides, proteins, ions etc. within the plasma membrane. As we know another important component of human being is cholesterol, which is a major component in cell membrane and its main functions are to maintain integrity and mechanical stability. Each and every time, membrane cholesterolsareinteracted with membrane protein in both N-C terminuses and target valid sequence(s) which has relevance in human diseases. In this manuscript we have applied Fuzzy C-Means (FCM) with Support Vector Machine (SVM) algorithm for prediction of cellular cholesterol with ABC genes. Our experiments have been performed well using ABCdata set.																	1064-1246	1875-8967					2020	39	2					1611	1618		10.3233/JIFS-179934													
J								Application of artificial fish swarm optimization semi-supervised kernel fuzzy clustering algorithm in network intrusion	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Network intrusion detection; semi-supervised learning; fuzzy C-means clustering; kernel function; artificial fish population optimization	SECURITY	For the unsupervised learning based clustering algorithm, the intrusion detection rate is low, and the training sample based on supervised learning clustering algorithm is insufficient. A semi-supervised kernel fuzzy C-means clustering algorithm based on artificial fish swarm optimization (AFSA-KFCM) is proposed. Firstly, the kernel function is used to change the distance function in the traditional semi-supervised fuzzy C-means clustering algorithm to define a new objective function, thus improving the probabilistic constraints of the fuzzy C-means algorithm. Then, the artificial fish swarm algorithm with strong global optimization ability is used to improve the KFCM sensitivity to the initial cluster center and easy to fall into the local extremum, thus improving the convergence speed and improving the classification effect. The test results in the Wine and IRIS public datasets show that the AFSA-KFCM clustering algorithm is superior to the traditional algorithm in clustering accuracy and time efficiency. At the same time, the experimental results in KDDCUP99 experimental data show that the algorithm can obtain the ideal detection rate and false detection rate in intrusion detection.																	1064-1246	1875-8967					2020	39	2					1619	1626		10.3233/JIFS-179935													
J								Encryption algorithm for network communication information based on binary logistic regression	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Binary logistic regression; network communication; information encryption; information integrity		In order to overcome the problems of long encrypting time, low information availability, low information integrity and low encrypting efficiency when using the current method to encrypt the communication information in the network without constructing the sequence of communication information. This paper proposes a network communication information encryption algorithm based on binary logistic regression, analyses the development of computer architecture, builds a network communication model, layers the main body of information exchange, and realizes the information synchronization of device objects at all levels. Based on the binary Logistic regression model, network communication information sequence is generated, and the fusion tree is constructed by network communication information sequence. The network communication information is encrypted through system initialization stage, data preparation stage, data fusion stage and data validation stage. The experimental results show that the information availability of the proposed algorithm is high, and the maximum usability can reach 97.7%. The encryption efficiency is high, and the shortest encryption time is only 1.9 s, which fully shows that the proposed algorithm has high encryption performance.																	1064-1246	1875-8967					2020	39	2					1627	1637		10.3233/JIFS-179936													
J								Decision tree classification algorithm for non-equilibrium data set based on random forests	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Random forest; non-equilibrium data set; decision tree; classification; SNM algorithm; RFID	IMAGING DATA	In order to overcome the problems of poor accuracy and high complexity of current classification algorithm for non-equilibrium data set, this paper proposes a decision tree classification algorithm for non-equilibrium data set based on random forest. Wavelet packet decomposition is used to denoise non-equilibrium data, and SNM algorithm and RFID are combined to remove redundant data from data sets. Based on the results of data processing, the non-equilibrium data sets are classified by random forest method. According to Bootstrap resampling method with certain constraints, the majority and minority samples of each sample subset are sampled, CART is used to train the data set, and a decision tree is constructed. Obtain the final classification results by voting on the CART decision tree classification. Experimental results show that the proposed algorithm has the characteristics of high classification accuracy and low complexity, and it is a feasible classification algorithm for non-equilibrium data set.																	1064-1246	1875-8967					2020	39	2					1639	1648		10.3233/JIFS-179937													
J								Modeling of network communication instability based on K-means algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										K-means algorithm; network communication; Instability; modeling		In order to overcome the problems of invulnerability and low communication efficiency when analyzing network communication instability with current methods, this paper proposes a modeling method of network communication instability based on K-means algorithm. The network element nodes are generated by clustering idea, and the initial communication topology is constructed. K-means algorithm is used to optimize the initial communication model, build a comprehensive mathematical model of network communication, and solve the model to realize the optimization of communication model. The network efficiency function is used to further quantify the network invulnerability, and the function is used to find the most vulnerable nodes in the network, and strengthen them to achieve efficient control of network invulnerability. The experimental results show that the model has strong invulnerability, up to 99.9%, high communication efficiency and coverage, and the maximum communication delay is only 0.35 s. It is a feasible network communication model.																	1064-1246	1875-8967					2020	39	2					1649	1658		10.3233/JIFS-179938													
J								Prediction of traffic flow with small time granularity at intersection based on probabilistic network	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Probabilistic network; intersection; small time granularity; traffic flow prediction; bayesian network		In order to overcome the inaccuracy of current research results of traffic flow prediction, this paper proposes a prediction method for traffic flow with small time granularity at intersection based on probability network. This method takes one minute as time granularity, collects traffic data such as cross-section flow, section traffic flow velocity data, traffic density, road occupancy, section delay and steering ratio by using RFID technology, and analyzes and processes the data. By introducing Bayesian network in probabilistic network and combining K-nearest neighbor method, historical data and predicted traffic flow state are classified to realize the prediction of traffic flow with small time granularity at intersections. The experimental results show that this method has high prediction accuracy and reliability, and is a feasible traffic flow prediction method.																	1064-1246	1875-8967					2020	39	2					1659	1670		10.3233/JIFS-179939													
J								Public service hot issue discovery with binary differential evolution algorithm based on fuzzy system theory	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Word vector; semantic clustering; binary system; fuzzy system theory; hot issue detection	FRAMEWORK	Social media is becoming more and more closely related to the real life. More and more netizens choose to obtain news and publish notice through social networks. Such huge amount of social media information generated by these users contains a lot of information related to hot topics and events. At the same time, problem of information overload has posed a challenge for people to use the information. It has become an important research issue to discover and track hot events and topics automatically from mass social media data. On the one hand, the short, highly noisy and real-time features of the social media data bring challenges to the discovery and tracking methods of traditional hot issues. On the other hand, the social media data contains abundant information of geography, time, and social relations, which brings great convenience to relevant researches. Based on these features of the social media data, this paper makes a deep study on the discovery, extraction, and tracking of hot issues in the social media based on fuzzy system theory and the word vector semantic clustering.																	1064-1246	1875-8967					2020	39	2					1671	1677		10.3233/JIFS-179940													
J								Spatial-temporal dynamic simulation of anti-noise urban expansion based on fuzzy intelligent control system and GIS	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										GIS system; anti-noise; urban expansion; spatial-temporal dynamic simulation; fuzzy intelligent control system	INFERENCE SYSTEM; CITY; GROWTH; MODEL	On the basis of FHWA model of the Federal Highway Administration and the combination with the geographic information system (GIS) and Fuzzy intelligent control system, the group independently researches and develops a simulation and evaluation system for the traffic noise in the urban road. This system is able to simulate the influence of traffic source, point source, and arbitrary shape area source on the urban sound field environment. It is combined with the noise radiation and the communication model, and the occlusion and attenuation by the buildings and forest belts on the traffic noise have been considered. It can calculate the traffic noise in urban areas and directly render the predicted results on the GIS map, and form a traffic noise map, which visually and clearly displays the pollution degree and distribution map of the traffic noise in urban areas. The noise maps of Guangzhou inner ring roads and Zhujiang New Town are drawn to provide scientific decision-making basis for the control of urban traffic noise pollution.																	1064-1246	1875-8967					2020	39	2					1679	1684		10.3233/JIFS-179941													
J								Intelligent interaction design research based on block chain communication technology and fuzzy system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Block chain; Communication technology; fuzzy system; intelligent interaction design; data transfer	DELIVERY	With the increasing amount of information on the Internet, data storage management tends to be distributed. In distributed storage environment, users pay more and more attention to the timeliness of user interaction experience and the reliability of information interaction. However, the efficiency of users is often limited by the efficiency of data communication between distributed sites. One of the important goals of distributed data management is to improve the efficiency of data transmission and ensure the reliability of data transmission. Block chain technology is one of the emerging technologies supporting the development of management information system; it provides a solution for the storage, verification, transmission and communication of the distributed data. This paper focuses on solving the problem of block chain data transmission, and studies it from three aspects: improving the efficiency of data communication, ensuring the reliability of transmission, and improving the fairness of service, and different block chain data communication performance optimization strategies are proposed under the constraints of node communication capability, node trust, weight, priority of service request and other influencing factors.																	1064-1246	1875-8967					2020	39	2					1685	1691		10.3233/JIFS-179942													
J								Public opinion analysis of complex network information of local similarity clustering based on intelligent fuzzy system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Local similarity; clustering; complex networks; information public opinion; based Intelligent fuzzy system	NEURAL-NETWORK	With the rise of the network society, as the mapping Internet space, the public opinion has become the most active way of expressing social public opinion. It gradually gets deeply involved in the development and change of various social phenomena, social problems and social events, and evolves into the real politics and public management. In this context, it is of great practical significance to explore the evolution process and laws of online public opinions and systematically analyze the influence mechanism in the evolution process of online public opinions. This paper comprehensively uses the modeling simulation, empirical analysis, fuzzy systems and other research methods, adopts the reasonable abstraction of the main behavior characteristics, behavior motives and network relations of network users, and then constructs the evolution model of network public opinion in the complex social network. Besides, from the new research perspective of network members and network relations of the dynamic interaction between the government, media and netizen, this paper makes an in-depth study on the influence mechanism of the dynamic evolution of online public opinion.																	1064-1246	1875-8967					2020	39	2					1693	1700		10.3233/JIFS-179943													
J								Forecast of export demand based on artificial neural network and fuzzy system theory	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Fuzzy system theory; evolutionary form; neural network; foreign trade; competitiveness analysis	EVOLUTION; TIME	This paper analyses the significance and methods of foreign trade export forecasting. The index system of foreign trade export forecasting is determined based on the analysis of foreign trade export forecasting research results. The concepts and principles of artificial neural network and fuzzy system theory are expounded, and their respective advantages and disadvantages as well as their complementarities are analyzed. This paper introduces the types and training algorithms of evolutionary morphological neural network, combines the neural network with the fuzzy system theory, and establishes the prediction model. Finally, the evolutionary morphological neural network model is applied to the prediction of foreign trade export in view of the characteristics of export and considering the influence of various factors, the whole process of establishing evolutionary morphological neural network forecasting model is introduced in detail, and the change range of export is predicted, and the ideal forecasting results are obtained.																	1064-1246	1875-8967					2020	39	2					1701	1709		10.3233/JIFS-179944													
J								A pretreatment method of wastewater based on artificial intelligence and fuzzy neural network system	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Similarity; fuzzy neural network; saline sewage; pretreatment	SALINE SEWAGE-TREATMENT; SANI(R) PROCESS; REACTOR; PERFORMANCE	A pretreatment method of industrial saline wastewater based on Artificial Intelligence based fuzzy neural network analysis was proposed to improve the pretreatment accuracy of industrial saline wastewater. This method uses a four-layer AI fuzzy neural network model and proposes a graded fuzzy neural network model for pretreatment method of industrial saline wastewater, it includes input layer, fuzzification layer, fuzzy logical layer and output layer, and designs the framework and calculation mode of the fuzzy function block and the neural network module. Finally, the dynamic simulation experiments of dissolved oxygen control in the fifth zone and nitrate nitrogen control in the second zone are carried out based on the simulation benchmark model (BSM1) platform. The experimental results show that this approach can effectively raise the adaptive control accuracy of the system compared with PID, feed forward neural network and conventional recurrent neural network.																	1064-1246	1875-8967					2020	39	2					1711	1720		10.3233/JIFS-179945													
J								Research and analysis of intelligent English learning system based on improved neural network	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Neural network; improved algorithm; intelligent platform; English learning; system construction		It is of great significance to explore the prospects of English intelligent learning in the field of basic education and to understand the current status and practical needs of mobile learning technology. Based on the intelligent English learning and teaching needs, this study constructs an intelligent English learning system based on improved neural network. The system uses wavelets to replace the neurons in the traditional neural network, establishes the connection between the wavelet transform and the network coefficients through affine transformation, and uses the wavelet neural network to correct the network parameters, so as to avoid the problem of being partially optimal due to the sensitivity of the initial value to some extent. Moreover, the English learning system adopts a mature C/S structure, and the system is divided into two parts and four layers. In addition, this study designed the experiment to analyze the performance of the English learning system, set the experimental group and the control group to conduct practical analysis. The research results show that the system constructed in this paper has certain effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1721	1731		10.3233/JIFS-179946													
J								Application of SVGA video real-time transmission technology in music education information communication	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										SVGA video; real-time communication technology; music education information; feature extraction		The current music education information has certain information loss in the real-time transmission process, which leads to poor educational effect. The research content of this thesis is based on FPGA video image acquisition and processing system. At the same time, this research mainly uses FPGA as the platform to realize and simulate video acquisition, transformation, storage, display and transmission. This research solves the problem of long-distance real-time transmission of high-definition video stream, and in order to improve the subjective quality of the recovered video at the receiving end, the algorithm processing is added to reduce the blockiness phenomenon in the video displayed at the receiving end. Finally, the validation test was designed to validate the research perspective. The experimental results show that the system works stably and realizes the functions of video image acquisition, conversion, display and transmission, and achieves the design goal. However, due to time constraints and other conditions, the entire design needs further improvement, so that it can provide a basis for the development of subsequent music education information communication technology.																	1064-1246	1875-8967					2020	39	2					1733	1744		10.3233/JIFS-179947													
J								English vocabulary online teaching based on machine learning recognition and target visual detection	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Machine learning; target recognition; target vision; English vocabulary; teaching method		Online education has become an important way of learning English at present, and English vocabulary teaching can improve the efficiency of English vocabulary teaching through target visual detection. However, from the existing research, it can be seen that there are still some shortcomings in English vocabulary recognition. In order to improve the English vocabulary recognition effect, based on machine learning recognition technology, this study combines English vocabulary recognition needs of online education to construct an English vocabulary detection model based on convolutional neural network. The model takes the word's overall feature as the feature extraction principle and adopts the analysis and extraction of the joint segment feature. Moreover, it discards the complicated process of first dividing a single letter and then performing feature extraction and recognition. In addition, this study design example tests to perform algorithm performance analysis. The experimental results show that the proposed algorithm model has certain effects, and it can be used as an auxiliary algorithm for online English vocabulary teaching.																	1064-1246	1875-8967					2020	39	2					1745	1756		10.3233/JIFS-179948													
J								Text recognition and classification of english teaching content based on SVM	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Machine learning; convolutional neural network; english teaching content; text recognition; text classification		When the English teaching text is regarded as the ontology, it must involve how to describe the attribute effectively. However, in the current research, the research on the automatic extraction of labels for English teaching texts is still insufficient. Intelligent English teaching has become an inevitable trend in the development of future English teaching models, so it is necessary to cooperate with intelligent text recognition technology. Based on SVM, this study applies convolutional neural network algorithm to text recognition of English teaching content, and effectively recognizes text features. After feature extraction, the original text content has been changed into data that the machine can directly identify and analyze, and semantic analysis is performed. In order to verify the performance of the algorithm, the performance of the algorithm was analyzed by example verification. It can be seen from the results that the proposed method has a certain accuracy rate and can be applied to the text recognition classification of English teaching content and can provide reference direction for related research.																	1064-1246	1875-8967					2020	39	2					1757	1767		10.3233/JIFS-179949													
J								Attendance automatic recognition and learning behavior of web-based course attendance based on machine learning algorithms	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Feature recognition; automatic identification; personnel management; machine learning algorithms	CARE	At present, the automatic attendance mode of distance education is not conducive to the confirmation and analysis of information after class. In order to study the effective automatic recognition algorithm of remote education classroom, this study takes the educational classroom of intelligent innovation and entrepreneurship of Internet + as an example for analysis. Moreover, this paper adopts facial features as the basis of recognition, establishes corresponding positioning points, and constructs precise positioning methods for real-time feature capture. At the same time, the ASM algorithm is used to extract facial features, and the algorithm is improved to improve the extraction effect. In addition, this paper proposes Gabor-wavelet packet set and Gabor beamlet set for auxiliary recognition, which improves the recognition rate. Finally, this paper designs experiments to analyze the performance of the algorithm of this study. The results show that the proposed algorithm has certain practical effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1769	1777		10.3233/JIFS-179950													
J								Annotador: a temporal tagger for Spanish	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Time expression; temporal tagger; Spanish language; NLP		Temporal information is crucial in knowledge extraction. Being able to locate events in a timeline is necessary to understand the narrative behind every text. To this aim, several temporal taggers have been proposed in literature -nevertheless, not all languages received the same attention. Most taggers work only for English texts, and not many have been developed for other languages. Also the scarcity of annotated corpora in other languages notably hinders the task. In this paper we present a new rule-based tagger called Annotador (Anotador in Spanish) able to process texts both in Spanish and English. Furthermore, a new corpus with more than 300 short texts containing common temporal expressions, called the HourGlass corpus, has been built in order to test it and to facilitate the development of new resources and tools. Professionals from different domains intervened in the gathering of the text, making it heterogeneous and easy to use thanks to the tags added to each entry. Finally, we analyzed main challenges in the time expression extraction task.																	1064-1246	1875-8967					2020	39	2					1979	1991		10.3233/JIFS-179865													
J								A study of lexical function detection with word2vec and supervised machine learning	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Word embeddings; word2vec; supervised machine learning; lexical function; Meaning-Text Theory		In this work, we report the results of our experiments on the task of distinguishing the semantics of verb-noun collocations in a Spanish corpus. This semantics was represented by four lexical functions of the Meaning-Text Theory. Each lexical function specifies a certain universal semantic concept found in any natural language. Knowledge of collocation and its semantic content is important for natural language processing, as collocation comprises the restrictions on how words can be used together. We experimented with word2vec embeddings and six supervised machine learning methods most commonly used in a wide range of natural language processing tasks. Our objective was to study the ability of word2vec embeddings to represent the context of collocations in a way that could discriminate among lexical functions. A difference from previous work with word embeddings is that we trained word2vec on a lemmatized corpus after stopwords elimination, supposing that such vectors would capture a more accurate semantic characterization. The experiments were performed on a collection of 1,131 Excelsior newspaper issues. As the experimental results showed, word2vec representation of collocations outperformed the classical bag-of-words context representation implemented in a vector space model and fed into the same supervised learning methods.																	1064-1246	1875-8967					2020	39	2					1993	2001		10.3233/JIFS-179866													
J								An orthographic and phonetic knowledge-based measure for confused drug names	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										LASA error; knowledge-based similarity measure; confused drug names; orthographic measure; phonetic measure	LOOK-ALIKE; SIMILARITY; ERRORS; IDENTIFICATION; PHARMACY	A drug name could be confused because it looks or sounds like another. Nevertheless, it is not possible to know a priori the causes of the confusion. Nowadays, sophisticated similarity measures have been proposed focused on improving the score of the detection. However, when a new drug name is proposed, the Federal Drug Administration (FDA) only can reject or accept the drug name based on this value. This paper not only improves the detection of confused drug names by integrating the strengths of different similarity measures but also the orthographic and phonetic knowledge of these measures are used to give an a priori explanation of the causes of confusion. In this paper, a novel measure that integrates 24 individual measures is developed for this problem. With our proposal, each individual measure contributes to this problem. Finally, we present examples of how our proposal is used for explaining the causes of the confusion which could assist to the FDA to accept or reject a new drug name or to know the confusion causes of previously reported cases.																	1064-1246	1875-8967					2020	39	2					2003	2013		10.3233/JIFS-179867													
J								Probabilistic vs deep learning based approaches for narrow domain NER in Spanish	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Named entity recognition; CRF; Bi-LSTM; Spanish; news reports	NAMED ENTITY RECOGNITION; CLASSIFICATION	This work presents an experimental study on the task of Named Entity Recognition (NER) for a narrow domain in Spanish language. This study considers two approaches commonly used in this kind of problem, namely, a Conditional Random Fields (CRF) model and Recurrent Neural Network (RNN). For the latter, we employed a bidirectional Long Short-Term Memory with ELMO's pre-trained word embeddings for Spanish. The comparison between the probabilistic model and the deep learning model was carried out in two collections, the Spanish dataset from CoNLL-2002 considering four classes under the IOB tagging schema, and aMexican Spanish news dataset with seventeen classes under IOBES schema. The paper presents an analysis about the scalability, robustness, and common errors of both models. This analysis indicates in general that the BiLSTM-ELMo model is more suitable than the CRF model when there is "enough" training data, and also that it is more scalable, as its performance was not significantly affected in the incremental experiments (by adding one class at a time). On the other hand, results indicate that the CRF model is more adequate for scenarios having small training datasets and many classes.																	1064-1246	1875-8967					2020	39	2					2015	2025		10.3233/JIFS-179868													
J								Improving the identification of confused drug names in Spanish	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Look-alike and sound-alike drug names; Spanish LASA problem; similarity measures; combined similarity measures	LOOK-ALIKE; SIMILARITY; RISK	Since a drug name goes through different communication means and circumstances when it is prescribed, written, advertised, listened to, searched and administered; it tends to be confused with similar drug names that Look-Alike and Sound-Alike (LASA). LASA drug names have caused costs and damage to health. For this problem, the institutions of the United Kingdom, Canada, and the United States have implemented programs for several decades to report lists of confusing drug names pairs. Thanks to these kinds of list, it has been possible to propose newmodels to identify confusing drug names in English and are used to reject new drug name proposals or to alert when a confusing drug name is being dispensed. However, countries such as Spain also have published a list with the Spanish LASA drug names, and it is not clear enough whether the models previously proposed for the drug names in English are useful for the list in Spanish or if it is necessary to adjust and update them for the Spanish language. This paper focuses on updating and improving the identification of LASA drug names in Spanish. First, we update the state-of-the-art by evaluating all the individual similarity measures proposed previously and all the models that combine these measures with the list in Spanish. Second, we updated the models with new individual measures and then adjusted them with the list in Spanish to improve the identification of LASA drug names in Spanish. After that, 25 individual similarity measures and 8 models to identify confused drug names in Spanish are compared to obtain the best result and conclusions.																	1064-1246	1875-8967					2020	39	2					2027	2036		10.3233/JIFS-179869													
J								LegoNet - classification and extractive summarization of Indian legal judgments with Capsule Networks and Sentence Embeddings	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Law Domain; Capsule Network; Sentence Embedding; Unsupervised Extractive Summarization; Natural Language Processing; Text Classification		In this paper, we propose the LegoNet - a system to classify and summarize legal judgments using Sentence Embedding, Capsule Networks and Unsupervised Extractive Summarization. To train and test the system, we have created a mini-corpus of Indian legal judgments which have been annotated according to the classes: Facts, Arguments, Evidences and Judgments. The proposed framework uses Sentence Embedding and Capsule Networks to classify parts of legal judgments into the classes mentioned above. This is then used by the extractive summarizer to generate a concise and succinct summary of the document grouped according to the above mentioned classes. Such a system could be used to help enable the Legal Community by speeding up the processes involving reading and summarizing legal documents which a Law professional would undertake in preparing for a case. The performance of the Machine Learning Model in this architecture can improve over time as more annotated training data is added to the corpus.																	1064-1246	1875-8967					2020	39	2					2037	2046		10.3233/JIFS-179870													
J								Impact of passive and negative sentences in automatic generation of static UML diagram using NLP	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Unified modeling language; class diagram; natural language processing; functional requirements	LANGUAGE; MODELS	In this research work, we propose a rule based approach for the automatic extraction of UML diagram from the unstructured format of software functional requirements. The existing work provides decent results for active sentences and positive sentences but the challenge in our work is to automatic extract class diagram elements from passive voice type sentences and negative sentences. Furthermore, there is scope to do more research in extraction process using multi-word terms. Thus, we have endeavored to automatic extract the class diagram elements by overcoming these challenges. The methodology uses the Stanford CoreNLP Tools along with Java for the practical implementation of formulated rules. Our approach has proved that without supplant the human being and their decision making, one could reduce the human effort while designing functional requirements. Several case studies were performed to compare class diagrams generated by our methodology to the ones created by experts. Our methodology outperforms the existingwork and provides impressiveAverage completeness (0.82), Average correctness (0.92) and Average redundancy (0.15). Results show that class diagram elements extracted by our methodology are precise as well as accurate and hence, in practice, such class diagrams would be a good preliminary diagram to converge towards to precise and comprehensive class diagrams.																	1064-1246	1875-8967					2020	39	2					2047	2059		10.3233/JIFS-179871													
J								Using automatic constructed thesauri instead of dictionaries in the verbal phraseological units validation task	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Multiword expression; compositionality; pointwise mutual information; thesaurus	SIMILARITY	Automatic validation of compositionality vs non-compositionality is a very challenging problem in NLP. A very small number of papers in literature report results in this particular problem. Recently, some new approaches have arised with respect to this particular linguistic task. One of these approaches that have called our attention is based on what authors call "lexical domain". In this paper, we analyze the use of Pointwise Mutual Information for constructing thesauri on the fly, which can be further employed instead of dictionaries for determining whether or not a given phraseological unit is compositional or not. The experimental results carried out in this paper show that this dissimilarity measure (PMI), can effectively be used when determining compositionality of a given verbal phraseological unit. Moreover, we show that the use of thesauri improves the results obtained in comparison with those experiments employing dictionaries, highlighting the use of self-constructed lexical resources which are, in fact, taking advantage of the same vocabulary of the target dataset.																	1064-1246	1875-8967					2020	39	2					2061	2070		10.3233/JIFS-179872													
J								Neural machine translation of Hindi and English	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Bilingual embeddings; machine translation; autoencoder		Translation has been one of the oldest problems in natural language processing. Despite its age, it is still one where there is a tremendous scope for improvement and creativity; the quantity and quality of research in it is testament to that fact. The subfield of primarily using deep neural networks for translation has recently started to gain traction. Many techniques have been developed using deep encoder-decoder networks for bilingual translation using both parallel as well as non-parallel corpora. There is a lot of potential in applying concepts such as bilingual embeddings to create generic translation architecture, which doesn't need huge parallel corpora to train. These ideas are particularly pertinent in the case of Indic languages, where it is generally difficult to obtain such corpus. In this paper, we try to adapt some of newest techniques in autoencoder networks and bilingual embeddings to the task of translating between English and Hindi. The models considerably outperform state of the art translating systems for these languages.																	1064-1246	1875-8967					2020	39	2					2071	2079		10.3233/JIFS-179873													
J								Argumentative relation identification in academic texts	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Argument component relation; argument mining; academic writing; argumentation studies; annotated theses corpus		The argumentation in academic writings is necessary to clearly communicate the ideas of the students. The relations between argumentative components are an essential part since this shows the contrast or support of the presented ideas. In this paper, we present two approaches to relation identification between pairs of components. In the first, we detect initially which components are related, to later classify them in support or attack relation. In the second approach, we identify directly which components have a support relation. For these approaches, we employed machine learning techniques with representations of several lexical, syntactic, semantic, structural and indicator features. Experiments in argumentative sections of academic theses showed that the models achieve encouraging results solving the task, and revealing the argumentative structures prevailing in student writings.																	1064-1246	1875-8967					2020	39	2					2081	2091		10.3233/JIFS-179874													
J								Combination of similarity measures based on symbolic regression for confusing drug names identification	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Confusing drug names; symbolic regression; look-alike; sound-alike; similarity measures	LOOK-ALIKE; MEDICATION ERRORS; SOUND; PREVENTION; MEDICINES; MOVEMENT	Despite advances in medical safety, errors related to adverse drug reactions are still very common. The most common reason for a patient to develop an adverse reaction to a medication is confusion over the prescribed medication. The similarity of drug names (by their spelling or phonetic similarity) is recognized as the most critical factor causing medication confusion. Several studies have studied techniques for the identification of confusing medications pairs, the most important of which employ techniques based on similarity measures that indicate the degree of similarity that exists between two drugs names. Although it generates good results in the identification of confusing drug names, each of the similarity measures used detects to a greater or lesser degree of similarity that exists between a pair. Recent studies indicate that the optimized combination of several similarity measures can generate better results than the individual application of each one. This paper presents an optimized method of combining various similarity measures based on symbolic regression. The obtained results show an improvement in the identification of confusing drug names.																	1064-1246	1875-8967					2020	39	2					2093	2103		10.3233/JIFS-179875													
J								Automatic Generation of Dialogues based on Grammatical Inference and the use of a Knowledge Base	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Grammatical inference; dialogue system; knowledge base	IDENTIFICATION	In this work, we present a model for the automatic generation of written dialogues, through the use of grammatical inference. This model allows the automatic recognition of grammars from a set dialogues employed as a training set. The inferred grammars are then used to generate templates of responses within the dialogues. The final objective is to apply this model in a specific domain dialogue system that answers questions in Spanish with the use of a knowledge base. The experiments carried out have been performend using the DIHANA project corpus which contains dialogues written in Spanish about schedules and prices of a rail system.																	1064-1246	1875-8967					2020	39	2					2105	2113		10.3233/JIFS-179876													
J								A semantics of intentional silence in omissive implicature	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Intentional silence; omission; omissive implicature; logic; semantics; says predicate; answer set programming		When people communicate, we often face situations where decisions have to be made, regardless of silence of one of the interlocutors. That is, we have to decide from incomplete information, guessing the intentions of the silent person. Implicatures allow to make inferences from what is said, but we can also infer from omission, or specifically from intentional silence in a conversation. In some contexts, not saying p generates a conversational implicature: that the speaker did not have sufficient reason, all things considered, to say p. This behaviour has been studied by several disciplines but barely touched in logic or artificial intelligence. After reviewing some previous studies of intentional silence and implicature, we formulate a semantics with five different interpretations of omissive implicature, in terms of the Says() predicate, and focus on puzzles involving assertions or testimonies, to analyze their implications. Several conclusions are derived from the different possibilities that were opened for analysis after taking into account silence. Finally, we develop a general strategy for the use of the proposed semantics in cases involving some kind of silence.																	1064-1246	1875-8967					2020	39	2					2115	2126		10.3233/JIFS-179877													
J								K-means based method for overlapping document clustering	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Clustering; overlapping clustering; document clustering	ALGORITHM; DENSITY	Overlapping clustering algorithms have shown to be effective for clustering documents. However, the current overlapping document clustering algorithms produce a big number of clusters, which make them little useful for the user. Therefore, in this paper, we propose a k-means based method for overlapping document clustering, which allows to specify by the user the number of groups to be built. Our experiments with different corpora show that our proposal allows obtaining better results in terms of FBcubed than other recent works for overlapping document clustering reported in the literature.																	1064-1246	1875-8967					2020	39	2					2127	2135		10.3233/JIFS-179878													
J								Improved fast partitional clustering algorithm for text clustering	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Document clustering; large collection; high dimensionality	K-MEANS	Document clustering has become an important task for processing the big amount of textual information available on the Internet. On the other hand, k-means is the most widely used algorithm for clustering, mainly due to its simplicity and effectiveness. However, k-means becomes slow for large and high dimensional datasets, such as document collections. Recently the FPAC algorithm was proposed to mitigate this problem, but the improvement in the speed was reached at the cost of reducing the quality of the clustering results. For this reason, in this paper, we introduce an improved FPAC algorithm, which, according our experiments on different document collections, allows obtaining better clustering results than FPAC, without highly increasing the runtime.																	1064-1246	1875-8967					2020	39	2					2137	2145		10.3233/JIFS-179879													
J								Irony detection in Twitter with imbalanced class distributions	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Irony detection; class imbalance; imbalanced learning		Irony detection is a not trivial problem and can help to improve natural language processing tasks as sentiment analysis. When dealing with social media data in real scenarios, an important issue to address is data skew, i.e. the imbalance between available ironic and non-ironic samples available. In this work, the main objective is to address irony detection in Twitter considering various degrees of imbalanced distribution between classes. We rely on the emotIDM irony detection model. We evaluated it against both benchmark corpora and skewed Twitter datasets collected to simulate arealistic distribution of ironic tweets. We carry out a set of classification experiments aimed to determine the impact of class imbalance on detecting irony, and we evaluate the performance of irony detection when different scenarios are considered. We experiment with a set of classifiers applying class imbalance techniques to compensate class distribution. Our results indicate that by using such techniques, it is possible to improve the performance of irony detection in imbalanced class scenarios.																	1064-1246	1875-8967					2020	39	2					2147	2163		10.3233/JIFS-179880													
J								Self-attention for Twitter sentiment analysis in Spanish	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Twitter; sentiment analysis; transformer encoders		This paper describes our proposal for Sentiment Analysis in Twitter for the Spanish language. The main characteristics of the system are the use of word embedding specifically trained from tweets in Spanish and the use of self-attention mechanisms that allow to consider sequences without using convolutional nor recurrent layers. These self-attention mechanisms are based on the encoders of the Transformer model. The results obtained on the Task 1 of the TASS 2019 workshop, for all the Spanish variants proposed, support the correctness and adequacy of our proposal.																	1064-1246	1875-8967					2020	39	2					2165	2175		10.3233/JIFS-179881													
J								Ranking based multi-label classification for sentiment analysis	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Sentiment analysis; multi-label classification; ranking		This paper proposes a sentiment analysis framework based on ranking learning. The framework utilizes BERT model pre-trained on large-scale corpora to extract text features and has two sub-networks for different sentiment analysis tasks. The first sub-network of the framework consists of multiple fully connected layers and intermediate rectified linear units. The main purpose of this sub-network is to learn the presence or absence of various emotions using the extracted text information, and the supervision signal comes from the cross entropy loss function. The other sub-network is a ListNet. Its main purpose is to learn a distribution that approximates the real distribution of different emotions using the correlation between them. Afterwards the predicted distribution can be used to sort the importance of emotions. The two sub-networks of the framework are trained together and can contribute to each other to avoid the deviation from a single network. The framework proposed in this paper has been tested on multiple datasets and the results have shown the proposed framework's potential.																	1064-1246	1875-8967					2020	39	2					2177	2188		10.3233/JIFS-179882													
J								Psychological attachment style prediction based on short biographies	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Psychological attachment; autobiography; text classification; bilateral gated recurrent units; anxiety-avoidance attachment model		In this work we experiment with the hypothesis that words subjects use can be used to predict their psychological attachment style (secure, fearful, dismissing, preoccupied) as defined by Bartholomew and Horowitz. In order to verify this hypothesis, we collected a series of autobiographic texts written by a set of 202 participants. Additionally, a psychological instrument (Fnas questionnaire) was applied to these same participants to measure their attachment style. We identified characteristic patterns for each style of attachment by means of two approaches: (1) mapping words into a word space model composed of unigrams, bigrams and/or trigrams on which different classifiers were trained (Naive Bayes (NB), Bernoulli NB, Multinomial NB, Multilayer Perceptrons); and (2) using a word-embedding based representation and a neural network architecture based on different units (LSTM, Gated Recurrent Units (GRU) and Bilateral GRUs). We obtained the best accuracy of 0.4079 for the first approach by using a Boolean Multinomial NB on unigrams, bigrams and trigrams altogether, and an accuracy of 0.4031 for the second approach using Bilateral GRUs.																	1064-1246	1875-8967					2020	39	2					2189	2199		10.3233/JIFS-179883													
J								Sentiment analysis in Nepali: Exploring machine learning and lexicon-based approaches	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Lexicon-based sentiment analysis; Nepali language; Twitter sentiment analysis; Nepali SentiWordNet; Nepali SenticNet; deep learning; sentiment analysis		In recent times, sentiment analysis research has achieved tremendous impetus on English textual data, however, a very less amount of research has been focused on Nepali textual data. This work is focused towards Nepali textual data. We have explored machine learning approaches and proposed a lexicon-based approach using linguistic features and lexical resources to perform sentiment analysis for tweets written in Nepali language. This lexicon-based approach, first pre-process the tweet, locate the opinion-oriented features and then compute the sentiment polarity of tweet. We have investigated both conventional machine learning models (Multinomial Naive Bayes (NB), Decision Tree, Support Vector Machine (SVM) and logistic regression) and deep learning models (Convolution Neural Network (CNN), Long Short-Term Memory (LSTM) and CNN-LSTM) for sentiment analysis of Nepali text. These machine learning models and lexicon-based approach have been evaluated on tweet dataset related to Nepal Earthquake 2015 and Nepal blockade 2015. Lexicon based approach has outperformed than conventional machine learning models. Deep learning models have outperformed than conventional machine learning models and lexicon-based approach. We have also created Nepali SentiWordNet and Nepali SenticNet sentiment lexicon from existing English language resources as by-product.																	1064-1246	1875-8967					2020	39	2					2201	2212		10.3233/JIFS-179884													
J								Using weighted directed graphs for identification of flow of emotions in poems	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Poem emotion recognition corpus; emotion recognition; emotion analysis; poem emotion trajectory system; poem emotion trajectory graph; dominant emotion flow trajectory; natural language processing; artificial intelligence	MODEL	Poem is a spontaneous flow of emotions. There are several emotion detection systems to identify emotions from speech, gestures, and text (blogs, newspapers, stories and medical reports). Since such systems do not exist for poetry, we take the first step in building a system to recognize emotions in poetry by constructing a benchmark corpus, the PERC (Poem Emotion Recognition Corpus), of poems written by Indian poets in English. In this research a novel graphical method, Poem Emotion Trajectory System (PETS), is proposed to depict the flow of emotion in a poem. PETS is based on the construction of a weighted directed graph as a means to represent the emotion flow among the verses of a given poem. The weights represent the transition probability among the emotion states considered. The significant advantage is that a dominant path for each emotion category is identified. Emotion flow along verses is analyzed using a graph-based approach. This method, applied to each emotion category, generalizes the emotion flow in each emotion class. This PETS can be applied in poetry therapy and to enhance creative thinking and writing.																	1064-1246	1875-8967					2020	39	2					2213	2227		10.3233/JIFS-179885													
J								Ranking concrete and abstract words using Google Books Ngram data	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Concreteness of words; bigrams; dictionary		Creation of dictionaries of abstract and concrete words is a well-known task. Such dictionaries are important in several applications of text analysis and computational linguistics. Usually, the process of assembling of concreteness scores for words begins with a lot of manual work. However, the process can be automated significantly using information from large corpora. In this paper we combine two datasets: a dictionary with concreteness scores of 40,000 English words and the GoogleBooks Ngram dataset, in order to test the following hypothesis: in text concrete words tend to occur with more concrete words, than with abstract words (and inverse: abstract words tend to occur with more abstract words, than with concrete words). Using the hypothesis, we proposed a method for automatic evaluation concreteness scores of words using a small amount of initial markup.																	1064-1246	1875-8967					2020	39	2					2229	2237		10.3233/JIFS-179886													
J								Deep fusion of multiple term-similarity measures for biomedical passage retrieval	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Biomedical passage retrieval; neural networks; question answering; deep learning		Passage retrieval is an important stage of question answering systems. Closed domain passage retrieval, e.g. biomedical passage retrieval presents additional challenges such as specialized terminology, more complex and elaborated queries, scarcity in the amount of available data, among others. However, closed domains also offer some advantages such as the availability of specialized structured information sources, e.g. ontologies and thesauri, that could be used to improve retrieval performance. This paper presents a novel approach for biomedical passage retrieval which is able to combine different information sources using a similarity matrix fusion strategy based on convolutional neural network architecture. The method was evaluated over the standard BioASQ dataset, a dataset specialized on biomedical question answering. The results show that the method is an effective strategy for biomedical passage retrieval able to outperform other state-of-the-art methods in this domain.																	1064-1246	1875-8967					2020	39	2					2239	2248		10.3233/JIFS-179887													
J								iHDT plus plus : improving HDT for SPARQL triple pattern resolution	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										HDT; RDF compression; triple pattern resolution; SPARQL; linked data	REPRESENTATION	RDF self-indexes compress the RDF collection and provide efficient access to the data without a previous decompression (via the so-called SPARQL triple patterns). HDT is one of the reference solutions in this scenario, with several applications to lower the barrier of both publication and consumption of Big Semantic Data. However, the simple design of HDT takes a compromise position between compression effectiveness and retrieval speed. In particular, it supports scan and subject-based queries, but it requires additional indexes to resolve predicate and object-based SPARQL triple patterns. A recent variant, HDT++, improves HDT compression ratios, but it does not retain the original HDT retrieval capabilities. In this article, we extend HDT++ with additional indexes to support full SPARQL triple pattern resolution with a lower memory footprint than the original indexed HDT (called HDT-FoQ). Our evaluation shows that the resultant structure, iHDT++, requires 70 - 85% of the original HDT-FoQ space (and up to 48 - 72% for an HDT Community variant). In addition, iHDT++ shows significant performance improvements (up to one level of magnitude) for most triple pattern queries, being competitive with state-of-the-art RDF self-indexes.																	1064-1246	1875-8967					2020	39	2					2249	2261		10.3233/JIFS-179888													
J								Measuring semantic similarity of documents with weighted cosine and fuzzy logic	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Semantic similarity; semantic matching; document similarity; cosine enrichment; keyword enrichment		Currently, the semantic analysis is used by different fields, such as information retrieval, the biomedical domain, and natural language processing. The primary focus of this research work is on using semantic methods, the cosine similarity algorithm, and fuzzy logic to improve the matching of documents. The algorithms were applied to plain texts in this case CVs (resumes) and job descriptions. Synsets of WordNet were used to enrich the semantic similarity methods such as the Wu-Palmer Similarity (WUP), Leacock-Chodorow similarity (LCH), and path similarity (hypernym/hyponym). Additionally, keyword extraction was used to create a postings list where keywords were weighted. The task of recruiting new personnel in the companies that publish job descriptions and reciprocally finding a company when workers publish their resumes is discussed in this research work. The creation of a new gold standard was required to achieve a comparison of the proposed methods. A web application was designed to match the documents manually, creating the new gold standard. Thereby the new gold standard confirming benefits of enriching the cosine algorithm semantically. Finally, the results were compared with the new gold standard to check the efficiency of the new methods proposed. The measures used for the analysis were precision, recall, and f-measure, concluding that the cosine similarity weighted semantically can be used to get better similarity scores.																	1064-1246	1875-8967					2020	39	2					2263	2278		10.3233/JIFS-179889													
J								Cross-dataset email classification	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Email classification; data mining; machine learning; cross-dataset classification		Email is one of the most popular ways of communication. Nevertheless, it is also a potential tool to deceive and fill users with unwanted publicity, which reduces productivity. To alleviate such fact, a common solution has been building machine learning models based on the content of emails to automatically separate emails (spam vs ham). In this work, a study of a set of machine learning models and content-based features for the problem of cross-dataset email classification is presented. This problem consists in training and testing the models using different datasets; considering the fact that the datasets were collected under different independent setups. This has the purpose of simulating future variable or unpredictable conditions in the emails content distributions as could happen in a real setting, where models are trained using emails from a certain period of time, group of users or accounts, but tested with emails from other users or accounts. Experiments were conducted with the models and features using different datasets and two setups, same-dataset, and cross-dataset, to show the complexity of the later. The performance was evaluated using the Area Under the ROC Curve, a common metric in email classification. The results show interesting insights for the problem.																	1064-1246	1875-8967					2020	39	2					2279	2290		10.3233/JIFS-179890													
J								Natural ontologies with elastic matching for elicited knowledge comparison	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Natural ontologies; modern frechet; ontology elicitation; elastic matching; dynamic time warping		Natural Ontologies are presented in this work as a useful tool to model the way in which concepts are organized inside the human mind. In order to be compared, ontologies are represented as matrices and an elastic matching technique is used. For this purpose, a distance measure called Modern Frechet is proposed, which is an approximation to the NP-Complete problem of elastic matching between matrices. An applied case of study is presented in which human knowledge is compared among different groups of people in the Computer Science domain.																	1064-1246	1875-8967					2020	39	2					2291	2303		10.3233/JIFS-179891													
J								A computational model for speech disorders using problematic phonemes with ontological reasoning	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Corpus building; ontology; speech disorders; problematic phonemes		This work presents a method for data gathering to construct a corpus related to speech disorders in children; such corpus will serve as the base to generate some semi-automatic ontologies, in order to become a computational model to support therapists for diagnosis and possible treatment. Speech disorders, phonemes and some additional information are classified using taxonomies obtained from speech disorders specialized literature. Based on the obtained taxonomies, the ontologies, which structure and formalize concepts defined by the main topic authors, are developed. The ontologies are constructed following some parts of classic methodologies and their subsequent validation is made through competency questions. The development of the model is based on Natural Language Processing (NLP) and Information Retrieval (IR) techniques. Integration of the ontologies is made to be able to make a classification based in problematic phonemes; this is suggested as a complement to the diagnostic tool in the model.																	1064-1246	1875-8967					2020	39	2					2305	2315		10.3233/JIFS-179892													
J								PIANI: An ontology-based platform for outdoor activity recognition and non-intrusive assistance to the elderly	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Ambient assisted living; outdoor activity recognition; ontologies		In this paper, we introduce a Platform for Non-Intrusive Assistance (named PIANI), as an assistance platform for elderly people able to do activities in outdoor environments without strict supervision. PIANI includes an ontology used to characterize outdoor activities of interest (activities to be observed). PIANI also defines a risk level of the activity that an elderly person is currently doing out of his home by comparing such activity to its characterization. In addition, the proposed platform uses the smartphone of the person in order to collect geographic and time information, which is used by PIANI to infer activity risk and send alert notifications based on semantic knowledge base. An experimental test was developed as a proof of concept about the utilization of PIANI to identify outdoors activities of elderly people, compute a level of risk and finally send non intrusive alert notification to the user.																	1064-1246	1875-8967					2020	39	2					2317	2329		10.3233/JIFS-179893													
J								Author detection: Analyzing tweets by using a Naive Bayes classifier	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Naive Bayes classifier; authorship detection; social network analysis; Twitter; confusion matrix		In the context of digital social media, where users have multiple ways to obtain information, it is important to have tools to detect the authorship within a corpus supposedly created by a single author. With the tremendous amount of information coming from social networks there is a lot of research concerning author profiling, but there is a lack of research about the authorship identification. In order to detect the author of a group of tweets, a Naive Bayes classifier is proposed which is an automatic algorithm based on Bayes' theorem. The main objective is to determine if a particular tweet was made by a specific user or not, based on its content. The data used correspond to a simple data set, obtained with the Twitter API, composed of four political accounts accompanied by their username and tweet identifier as it is mixed with multiple user tweets. To describe the performance of the classification model and interpret the obtained results, a confusion matrix is used as it contains values like accuracy, sensitivity, specificity, Kappa measure, the positive predictive and negative predictive value. These results show that the prediction model, after several cases of use, have acceptable values against the observed probabilities.																	1064-1246	1875-8967					2020	39	2					2331	2339		10.3233/JIFS-179894													
J								#Brexit: Leave or remain? the role of user's community and diachronic evolution on stance detection	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Stance detection; Twitter; brexit; NLP; community detection		Interest has grown around the classification of stance that users assume within online debates in recent years. Stance has been usually addressed by considering users posts in isolation, while social studies highlight that social communities may contribute to influence users' opinion. Furthermore, stance should be studied in a diachronic perspective, since it could help to shed light on users' opinion shift dynamics that can be recorded during the debate. We analyzed the political discussion in UK about the BREXIT referendum on Twitter, proposing a novel approach and annotation schema for stance detection, with the main aim of investigating the role of features related to social network community and diachronic stance evolution. Classification experiments show that such features provide very useful clues for detecting stance.																	1064-1246	1875-8967					2020	39	2					2341	2352		10.3233/JIFS-179895													
J								A study of deep learning methods for same-genre and cross-genre author profiling	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Author profiling; deep learning; gender identification; ensemble methods; age identification; same-genre author profiling; cross-genre author profiling	NEURAL-NETWORK; CLASSIFICATION	The aim of the author profiling task is to automatically predict various traits of an author (e.g. age, gender, etc.) from written text. The problem of author profiling has been mainly treated as a supervised text classification task. Initially, traditional machine learning algorithms were used by the researchers to address the problem of author profiling. However, in recent years, deep learning has emerged as a state-of-the-art method for a range of classification problems related to image, audio, video, and text. No previous study has carried out a detailed comparison of deep learning methods to identify which method(s) are most suitable for same-genre and cross-genre author profiling. To fulfill this gap, the main aim of this study is to carry out an in-depth and detailed comparison of state-of-the-art deep learning methods, i.e. CNN, Bi-LSTM, GRU, and CRNN along with proposed ensemble methods, on four PAN Author Profiling corpora. PAN 2015 corpus, PAN 2017 corpus and PAN 2018 Author Profiling corpus were used for same-genre author profiling whereas PAN 2016 Author Profiling corpus was used for cross-genre author profiling. Our extensive experimentation showed that for same-genre author profiling, our proposed ensemble methods produced best results for gender identification task whereas CNN model performed best for age identification task. For cross-genre author profiling, the GRU model outperformed all other approaches for both age and gender.																	1064-1246	1875-8967					2020	39	2					2353	2363		10.3233/JIFS-179896													
J								Predicting consumers engagement on Facebook based on what and how companies write	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Social media branding; impact analysis; data mining; features engineering; natural language processing	SOCIAL MEDIA; METRICS; IMPACT	Engaged customers are a very import part of current social media marketing. Public figures and brands have to be very careful about what they post online. That is why the need for accurate strategies for anticipating the impact of a post written for an online audience is critical to any public brand. Therefore, in this paper, we propose a method to predict the impact of a given post by accounting for the content, style, and behavioral attributes as well as metadata information. For validating our method we collected Facebook posts from 10 public pages, we performed experiments with almost 14000 posts and found that the content and the behavioral attributes from posts provide relevant information to our prediction model.																	1064-1246	1875-8967					2020	39	2					2365	2377		10.3233/JIFS-179897													
J								Author profiling on bi-lingual tweets	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Twitter; author profiling; roman-urdu; deep learning; bi-lingual; gender identification	SENTIMENT ANALYSIS	The task of author profiling aims to distinguish the author's profile traits from a given content. It has got potential applications in marketing, forensic analysis, fake profile detection, etc. In recent years, the usage of bi-lingual text has raised due to the global reach of social media tools as people prefer to use language that expresses their true feelings during online conversations and assessments. It has likewise impacted the use of bi-lingual (English and Roman-Urdu) text in the sub-continent (Pakistan, India, and Bangladesh) over social media. To develop and evaluate methods for bi-lingual author profiling, benchmark corpora are needed. The majority of previous efforts have focused on developing mono-lingual author profiling corpora for English and other languages. To fulfill this gap, this study aims to explore the problem of author profiling on bi-lingual data and presents a benchmark corpus of bi-lingual (English and Roman-Urdu) tweets. Our proposed corpus contains 339 author profiles and each profile is annotated with six different traits including age, gender, education level, province, language, and political party. As a secondary contribution, a range of deep learning methods, CNN, LSTM, Bi-LSTM, and GRU, are applied and compared on the three different bi-lingual corpora for age and gender identification, including our proposed corpus. Our extensive experimentation showed that the best results for both gender identification task (Accuracy = 0.882, F1-Measure = 0.839) and age identification (Accuracy = 0.735, F1-Measure = 0.739) are obtained using Bi-LSTM deep learning method. Our proposed bi-lingual tweets corpus is free and publicly available for research purposes.																	1064-1246	1875-8967					2020	39	2					2379	2389		10.3233/JIFS-179898													
J								Authorship attribution of Spanish poems using n-grams and the Web as Corpus	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Authorship attribution; self-training; web corpora		In many areas of professional development, the categorization of textual objects is of critical importance. A prominent example is the attribution of authorship, where symbolic information is manipulated using natural language processing techniques. In this context, one of the main limitations is the necessity of a large number of pre-labeled instances for each author that is to be identified. This paper proposes a method based on the use of n-grams of characters and the use of the web to enrich the training sets. The proposed method considers the automatic extraction of the unlabeled examples from the Web and its iterative integration into the training data set. The evaluation of the proposed approach was done by using a corpus formed by poems corresponding to 5 contemporary Mexican poets. The results presented allow evaluating the impact of the incorporation of new information into the training set, as well as the role played by the selection of classification attributes using information gain.																	1064-1246	1875-8967					2020	39	2					2391	2396		10.3233/JIFS-179899													
J								Unsupervised extractive multi-document text summarization using a Genetic Algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Genetic algorithm; heuristics; unsupervised; extractive multi-document text; summarization		The task of Extractive Multi-Document Text Summarization (EMDTS) aims at building a short summary with essential information from a collection of documents. In this paper, we propose an EMDTS method using a Genetic Algorithm (GA). The fitness function considering two unsupervised text features: sentence position and coverage. We propose the binary coding representation, selection, crossover, and mutation operators. We test the proposed method on the DUC01 and DUC02 data set, four different tasks (summary lengths 200 and 400 words), for each of the collections of documents (in total, 876 documents) are tested. Besides, we analyze the most frequently used methodologies to summarization. Moreover, different heuristics such as topline, baseline, baseline-random, and lead baseline are calculated. In the results, the proposed method achieves to improve the state-of-art results.																	1064-1246	1875-8967					2020	39	2					2397	2408		10.3233/JIFS-179900													
J								Extractive summarization using siamese hierarchical transformer encoders	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Siamese neural networks; self attention; extractive summarization		In this paper, we present an extractive approach to document summarization, the Siamese Hierarchical Transformer Encoders system, that is based on the use of siamese neural networks and the transformer encoders which are extended in a hierarchical way. The system, trained for binary classification, is able to assign attention scores to each sentence in the document. These scores are used to select the most relevant sentences to build the summary. The main novelty of our proposal is the use of self-attention mechanisms at sentence level for document summarization, instead of using only attentions at word level. The experimentation carried out using the CNN/DailyMail summarization corpus shows promising results in-line with the state-of-the-art.																	1064-1246	1875-8967					2020	39	2					2409	2419		10.3233/JIFS-179901													
J								Determining the importance of sentence position for automatic text summarization	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Automatic Text Summarization; n-gram Model; bag of words model; slope calculation; genetic algorithm	PERFORMANCE	The methods of Automatic Extractive Summarization (AES) uses the features of the sentences of the original text to extract the most important information that will be considered in summary. It is known that the first sentences of the text are more relevant than the rest of the text (this heuristic is called baseline), so the position of the sentence (in reverse order) is used to determine its relevance, which means that the last sentences have practically no possibility of being selected. In this paper, we present a way to soften the importance of sentences according to the position. The comprehensive tests were done on one of the best AES methods using the bag of words and n-grams models with the with DUC02 and DUC01 data sets to determine the importance of sentences.																	1064-1246	1875-8967					2020	39	2					2421	2431		10.3233/JIFS-179902													
J								A grammar for specifying full-body gestures elicited for abstract tasks	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Gesture elicitation study; gesture grammar; gesture recognition; gesture user interfaces; engineering interactive computing systems; one-shot learning	RECOGNITION	A gesture elicitation study consists of a popular method for eliciting a sample of end end users to propose gestures for executing functions in a certain context of use, specified by its users and their functions, the device or the platform used, and the physical environment in which they are working. Gestures proposed in such a study needs to be classified and, perhaps, extended in order to feed a gesture recognizer. To support this process, we conducted a full-body gesture elicitation study for executing functions in a smart home environment by domestic end users in front of a camera. Instead of defining functions opportunistically, we define them based on a taxonomy of abstract tasks. From these elicited gestures, a XML-compliant grammar for specifying resulting gestures is defined, created, and implemented to graphically represent, label, characterize, and formally present such full-body gestures. The formal notation for specifying such gestures is also useful to generate variations of elicited gestures to be applied on-the-fly on gestures in order to allow one-shot learning.																	1064-1246	1875-8967					2020	39	2					2433	2444		10.3233/JIFS-179903													
J								Towards building a Urdu Language Corpus using Common Crawl	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Urdu web corpus; Perso-Arabic script; web content analysis; common crawl corpus		Urdu is the most popular language in Pakistan which is spoken by millions of people across the globe. While English is considered the dominant web content language, characteristics of Urdu language web content are still unknown. In this paper, we study the World-Wide-Web (WWW) by focusing on the content present in the Perso-Arabic script. Leveraging from the Common Crawl Corpus, which is the largest publicly available web content of 2.87 billion documents for the period of December 2016, we examine different aspects of Urdu web content. We use the Compact Language Detector (CLD2) for language detection. We find that the global WWW population has a share of 0.04% for Urdu web content with respect to document frequency. 70.9% of the top-level Urdu domains consist of .com, .org, and .info. Besides, urdulughat is the most dominating second-level domain. 40% of the domains are hosted in the United States while only 0.33% are hosted within Pakistan. Moreover, 25.68% web-pages have Urdu as primary language and only 11.78% of web-pages are exclusively in Urdu. Our Urdu corpus consists of 1.25 billion total and 18.14 million unique tokens. Furthermore, the corpus follows the Zipf's law distribution. This Urdu Corpus can be used for text summarization, text classification, and cross-lingual information retrieval.																	1064-1246	1875-8967					2020	39	2					2445	2455		10.3233/JIFS-179904													
J								"Bend the truth": Benchmark dataset for fake news detection in Urdu language and its evaluation	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Fake news detection; Urdu corpus; language resources; benchmark dataset; classification; machine learning		The paper presents a new corpus for fake news detection in the Urdu language along with the baseline classification and its evaluation. With the escalating use of the Internet worldwide and substantially increasing impact produced by the availability of ambiguous information, the challenge to quickly identify fake news in digital media in various languages becomes more acute. We provide a manually assembled and verified dataset containing 900 news articles, 500 annotated as real and 400, as fake, allowing the investigation of automated fake news detection approaches in Urdu. The news articles in the truthful subset come from legitimate news sources, and their validity has been manually verified. In the fake subset, the known difficulty of finding fake news was solved by hiring professional journalists native in Urdu who were instructed to intentionally write deceptive news articles. The dataset contains 5 different topics: (i) Business, (ii) Health, (iii) Showbiz, (iv) Sports, and (v) Technology. To establish our Urdu dataset as a benchmark, we performed baseline classification. We crafted a variety of text representation feature sets including word n-grams, character n-grams, functional word n-grams, and their combinations. After applying a variety of feature weighting schemes, we ran a series of classifiers on the train-test split. The results show sizable performance gains by AdaBoost classifier with 0.87 F1(Fake) and 0.90 F1(Real). We provide the results evaluated against different metrics for a convenient comparison of future research. The dataset is publicly available for research purposes.																	1064-1246	1875-8967					2020	39	2					2457	2469		10.3233/JIFS-179905													
J								Revisiting subject classification in academic databases: A comparison of the classification accuracy of Web of Science, Scopus & Dimensions	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Academic databases; research category; subject classification	FIELD CLASSIFICATION; JOURNALS; PUBLICATIONS; RELIABILITY; SYSTEMS	Classification of research articles into different subject areas is an extremely important task in bibliometric analysis and information retrieval. There are primarily two kinds of subject classification approaches used in different academic databases: journal-based (aka source-level) and article-based (aka publication-level). The two popular academic databases-Web of Science and Scopus-use journal-based subject classification scheme for articles, which assigns articles into a subject based on the subject category assigned to the journal in which they are published. On the other hand, the recently introduced Dimensions database is the first large academic database that uses article-based subject classification scheme that assigns the article to a subject category based on its contents. Though the subject classification schemes of Web of Science have been compared in several studies, no research studies have been done on comparison of the article-based and journal-based subject classification systems in different academic databases. This paper aims to compare the accuracy of subject classification system of the three popular academic databases: Web of Science, Scopus and Dimensions through a large-scale user-based study. Results show that the commonly held belief of superiority of article-based subject classification over the journal-based subject classification scheme does not hold at least at the moment, as Web of Science appears to have the most accurate subject classification.																	1064-1246	1875-8967					2020	39	2					2471	2476		10.3233/JIFS-179906													
J								Measuring interdisciplinarity of research articles: An analysis of inter-relatedness of different parameters	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Diversity; interdisciplinarity; interdisciplinary research; multidisciplinary research	DIVERSITY; SCIENCE; COLLABORATION; INDICATOR; EVOLUTION; PATTERNS; FIELDS	With evolution of knowledge disciplines and cross fertilization of ideas, research outputs reported as scientific papers are now becoming more and more interdisciplinary. An interdisciplinary research work usually involves ideas and approaches from multiple disciplines of knowledge applied to solve a specific problem. In many cases the interdisciplinary areas eventually emerge as full-fledged disciplines. In the last two decades, several approaches have been proposed to measure the Interdisciplinarity of a scientific article, such as propositions based on authorship, references, set of keywords etc. Among all these approaches, reference-set based approach is most widely used. The diversity of knowledge in the reference set has been measured with three parameters, namely variety, balance, and disparity. Different studies tried to combine these measures in one way or other to propose an aggregate measure of interdisciplinarity, called integrated diversity. However, there is a lack of understanding on inter-relations between these parameters. This paper tries to look into inter-relatedness between the three parameters by analytical study on an important interdisciplinary research area, Internet of Things (IoT). Research articles in IoT, as obtained from Web of Science for the year 2018 have been analyzed to compute the three measures and understand their inter-relatedness. Results obtained show that variety and balance are negatively correlated, variety and disparity do not show a stable relatedness and balance and disparity are negatively correlated. Further, the integrated diversity measure is negatively correlated with variety and weakly positively correlated with balance and disparity. The results imply that the composite integrated diversity measure may not be a suitably constructed composite measure of interdisciplinarity.																	1064-1246	1875-8967					2020	39	2					2477	2485		10.3233/JIFS-179907													
J								Improving unsupervised neural aspect extraction for online discussions using out-of-domain classification	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Aspect extraction; out-of-domain classification; deep learning; topic models; topic coherence		Deep learning architectures based on self-attention have recently achieved and surpassed state of the art results in the task of unsupervised aspect extraction and topic modeling. While models such as neural attention-based aspect extraction (ABAE) have been successfully applied to user-generated texts, they are less coherent when applied to traditional data sources such as news articles and newsgroup documents. In this work, we introduce a simple approach based on sentence filtering in order to improve topical aspects learned from newsgroups-based content without modifying the basic mechanism of ABAE. We train a probabilistic classifier to distinguish between out-of-domain texts (outer dataset) and in-domain texts (target dataset). Then, during data preparation we filter out sentences that have a low probability of being in-domain and train the neural model on the remaining sentences. The positive effect of sentence filtering on topic coherence is demonstrated in comparison to aspect extraction models trained on unfiltered texts.																	1064-1246	1875-8967					2020	39	2					2487	2496		10.3233/JIFS-179908													
J								Career path level estimation and skill qualification feedback from textual descriptions	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Project manager career path level; profile classification; skill qualification estimation; natural language processing; word embeddings	PERSON-ORGANIZATION FIT; ENVIRONMENT FIT; CONGRUENCE; PREDICTORS	LinkedIn is a social medium oriented to professional career handling and networking. In it, users write a textual profile on their experience, and add skill labels in a free format. Users are able to apply for different jobs, but specific feedback on the appropriateness of their application according to their skills is not provided to them. In this work we particularly focus on applicants of the project management branch from information technologies-although the presented methodology could be extended to any area following the same mechanism. Using the information users provide in their profile, it is possible to establish the corresponding level in a predefined Project Manager career path (PM level). 1500+ experiences and skills from 300 profiles were manually tagged to train and test a model to automatically estimate the PM level. In this proposal we were able to perform such prediction with a precision of 98%. Additionally, the proposed model is able to provide feedback to users by offering a guideline of necessary skills to be learned to fulfill the current PM level, or those needed in order to upgrade to the following PM level. This is achieved through the clustering of skill qualification labels. Results of experiments with several clustering algorithms are provided as part of this work.																	1064-1246	1875-8967					2020	39	2					2497	2507		10.3233/JIFS-179909													
J								An unsupervised lower-baseline localization method based on writing style features for historical documents	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Lower-baseline localization; historical document analysis; text line segmentation; writing style features	TEXT; SEGMENTATION	There is a lot of cultural heritage information in historical documents that have not been explored or exploited yet. Lower-Baseline Localization (LBL) is the first step in information retrieval from images of manuscripts where groups of handwritten text lines representing a message are identified. An LBL method is described depending on how the features of the writing style of an author are treated: the character shape and size, gap between characters and between lines, the shape of ascendant and descendant strokes, character body, space between characters, words and columns, and touching and overlapping lines. For example, most of the supervised LBL methods only analyze the gap between characters as part of the preprocessing phase of the document and the rest of features of the writing style of the author are left for the learning phase of the classifier. For such reason, supervised LBL methods tend to learn particular styles and collections. This paper presents an unsupervised LBL method that explicit analyses all the features of the writing style of the author and processes the document by windows. In this sense, the proposed method is more independent from the writing style of the author, and it is more reliable with new collections in real scenarios. According to the experimentation, the proposed method surpasses the state-of-the-art methods with the standard READ-BAD historical collection with 2,036 manuscripts and 132,124 manually annotated baselines from 9 libraries in 500 years.																	1064-1246	1875-8967					2020	39	2					2509	2520		10.3233/JIFS-179910													
J								Solving arithmetic word problems: A deep learning based approach	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Solving arithmetic word problems; solving math word problems; BiLSTM-based operation prediction; irrelevant; information removal		This paper presents a novel deep learning based approach to solving arithmetic word problems. Solving different types of mathematical (math) word problems (MWP) is a very complex and challenging task as it requires Natural Language Understanding (NLU) and Commonsense knowledge. An application on this can benefit learning (education) technologies such as E-learning systems, Intelligent tutoring, Learning Management Systems (LMS), Innovative teaching/learning, etc. We propose Deep Learning based Arithmetic Word Problem Solver, DLAWPS, an intelligent MWP solver system. DLAWPS consists of a Recurrent Neural Network (RNN) based Bi-directional Long Short-Term Memory (BiLSTM) to classify operation among four basic operations {+, -, *, /}, and a knowledge-based irrelevant information removal unit (IIRU) to identify the relevant quantities to form an equation to solve arithmetic MWPs. Our system generates state-of-the-art results on the standard arithmetic word problem datasets - AddSub, SingleOp, and a Combined dataset.																	1064-1246	1875-8967					2020	39	2					2521	2531		10.3233/JIFS-179911													
J								Brain signal classification for creative tasks	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Affect; creativity; external feedback; flow; motivation; self-feedback	DESIGN; ACHIEVEMENT; EMOTIONS; FEEDBACK; ART; RESOLUTION; EDUCATION; CORTEX	We tried to determine if emotive self-feedback from conscious assessment of artists' own works generates sufficient impetus for accomplishment of goals. Self-reports from participants of an 'experimental' group working independently and without external feedback on their work are examined. The performance of this group is compared to 'control' performers in tutored sessions (with external feedback). On the whole a two-fold analysis was carried out. First, verbal reports of the participants' feelings about their work in both experimental and control settings were analyzed. Second, a brainwave analysis of each participant was conducted while they were engaged in the same tasks so as to examine effects of concentration and energy output. The Hilbert-Huang transform was used to filter data frequency for brainwaves emitted at channels AF4, AF3, F6 and F7, all positioned along the pre-frontal cortex. Results of participants' brainwave behavior within frequency ranges of 14-16 Hz, as well as for higher ranges (above 60 Hz), do not show significant difference in the two groups. This indicates that brainwave activity is sustained in individuals who depend on self-feedback appraisals, at least within the domain of creativity investigated in this paper.																	1064-1246	1875-8967					2020	39	2					2533	2544		10.3233/JIFS-179912													
J								PROMISE: PRoposing an Ontological Model for developing collaboratIve SystEms	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Ontological model; computer supported cooperative work; collaborative system; web ontology language; PROMISE	WORKFLOW ONTOLOGY; AWARENESS; FRAMEWORK; REPRESENTATION	Currently, there is a great necessity in the organizations to support communication, collaboration, and coordination -important aspects that characterize collaborative systems- between its workers and enterprises; in order to simplify and improve their production processes. However, the development and maintenance of these systems are very complex. Although several proposals to develop them have been made, they usually lack theoretical models, which allow specifying and creating both group and interactive activities in a conceptual and formal way to sustain the requirements of group work. Therefore, this paper PRoposes an Ontological Model for developing collaboratIve SystEms (PROMISE), it tries to be a guide for the analysis, design, and implementation of such systems in a formal, explicit manner. This model is based on an ontology, created using OWL (Web Ontology Language), providing a model of knowledge about in what way entities should be used and combined to control the execution of a set of orderly steps to develop these systems. Furthermore, this ontology has been validated through a set of academic's projects, showing be great usefulness to developers.																	1064-1246	1875-8967					2020	39	2					2545	2557		10.3233/JIFS-179913													
J								Digital processing of ultrasound images on dilated blood vessels from diabetic patients	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Lower extremity; diabetic patients; images processing; magnetic field; patch	NEUROPATHIC FOOT; FLOW	Introduction Peripheral arterial disease (PAD) is a fairly common degenerative vascular condition in diabetic patients that leads to inadequate blood flow (BF), this disease is mainly due to atherosclerosis that causes chronic narrowing of arteries, which can precipitate acute thrombotic events. In patients with diabetes, atherosclerosis is the main reason for reducing life expectancy, as long as diabetic nephropathy and retinopathy are the largest contributors to end-stage renal disease and blindness, respectively. Objective This was an assessment of dilatation of the blood vessels on diabetic patients vs. healthy volunteers by using digital processing of imaging's. Materials and Methods The study subject was ultrasound imaging processing of blood vessels dilation on low extremities of diabetic patients, the results were compared with ultrasound images of healthy subjects. Results The digital images processing suggests that there is a significant difference among images experimental of the diabetic group and healthy volunteers' images, the control group. Discussion The digital imaging processing performed in the Matlab platform is an adequate procedure for blood vessels dilation analysis of the ultrasound images taken from the lower extremities in diabetic patients.																	1064-1246	1875-8967					2020	39	2					2559	2564		10.3233/JIFS-179914													
J								Distributed H-infinity Filtering for Switched Stochastic Delayed Systems Over Sensor Networks With Fading Measurements	IEEE TRANSACTIONS ON CYBERNETICS										Average dwell time (ADT); distributed H-infinity filtering; fading measurements; sensor networks; switched stochastic systems	WIRELESS SENSOR; RESILIENT CONTROL; MATRICES; ATTACKS; NOISES; DESIGN; STATE	This paper is concerned with the problem of distributed H-infinity filtering for switched stochastic time-delay systems with fading measurements over sensor networks. The underlying target plants are subject to fading measurements where the fading rates are described by continuous-time random variables with known statistical properties dependent on the system modes. The adjacency matrices characterizing the topology of the sensor networks arc also allowed to be mode-dependent. Based on the multiple Lyapunov functional approach and average dwell-time concept, the distributed H-infinity filter is designed by means of the convex optimization scheme. A dedicated technique is developed via a simple algebraic equality in order to avoid solving a transcendental equation used in the existing results. With the designed filter, the error dynamics of the state estimation is guaranteed to have the mean-square exponential stability with a prescribed H-infinity disturbance attenuation level. Finally, a numerical example is used to demonstrate the effectiveness of the method.																	2168-2267	2168-2275				JAN	2020	50	1					2	14		10.1109/TCYB.2018.2852290													
J								Neuroadaptive Robotic Control Under Time-Varying Asymmetric Motion Constraints: A Feasibility-Condition-Free Approach	IEEE TRANSACTIONS ON CYBERNETICS										Adaptive neural control; feasibility conditions; position and velocity constraints; robotic manipulator	BARRIER LYAPUNOV FUNCTIONS; NONLINEAR-SYSTEMS; ADAPTIVE-CONTROL; TRACKING CONTROL; MODE	This paper presents a neuroadaptive tracking control approach for uncertain robotic manipulators subject to asymmetric yet time-varying full-state constraints without involving feasibility conditions. Existing control algorithms either ignore motion constraints or impose additional feasibility conditions. In this paper, by integrating a nonlinear state-dependent transformation into each step of backstepping design, we develop a control scheme that not only directly accommodates asymmetric yet time-varying motion (position and velocity) constraints but also removes the feasibility conditions on virtual controllers, simplifying design process, and making implementation less demanding. Neural network (NN) unit accounting for system uncertainties is included in the loop during the entire system operational envelope in which the precondition on the NN training inputs is always ensured. The effectiveness and benefits of the proposed control method for robotic manipulator are validated via computer simulation.																	2168-2267	2168-2275				JAN	2020	50	1					15	24		10.1109/TCYB.2018.2856747													
J								Adaptive Fault-Tolerant Consensus Protocols for Multiagent Systems With Directed Graphs	IEEE TRANSACTIONS ON CYBERNETICS										Adaptive control protocol; fault-tolerant consensus; multiagent systems (MASs); tracking consensus	TRACKING CONTROL; SLIDING MODE; ACTUATOR FAULT; LINEAR-SYSTEMS; LEADER; NETWORK; DESIGN; TEAM	This paper investigates the problem of adaptive fault-tolerant tracking control for the multiagent systems (MASs) under the time-varying actuator faults and bounded unknown control input of the leader. On the basis of the local state information of neighboring agents, an adaptive fault-tolerant control protocol, which consists of the adaptive estimation of faults, is constructed to compensate for the loss of actuator effectiveness in the leader-follower consensus of MASs. Moreover, the modification term in the adaptive estimation can avoid high-frequency oscillations. It is shown that the tracking errors converge to a neighborhood around the origin in the presence of actuator faults, and the performance of the tracking problem is improved. Furthermore, the protocol is distributed in the sense that the coupling gains are independent. Finally, two examples are given to show the effectiveness of the proposed control protocol.																	2168-2267	2168-2275				JAN	2020	50	1					25	35		10.1109/TCYB.2018.2859421													
J								Impulsive Consensus of Multiagent Systems With Limited Bandwidth Based on Encoding-Decoding	IEEE TRANSACTIONS ON CYBERNETICS										Encoding-decoding; exponential consensus; impulsive consensus; limited bandwidth communication; nonlinear dynamics	LEADER-FOLLOWING CONSENSUS; 2ND-ORDER CONSENSUS; STATE ESTIMATION; SYNCHRONIZATION; NETWORKS; COORDINATION; STRATEGIES; DELAYS; MODEL	Energy constrains are always significant to be considered in control of multiagent systems. Besides, nonlinear phenomena are often involved into such systems. In this paper, we discuss the impulsive consensus problem of nonlinear multiagent systems via impulsive protocol with limited bandwidth communication based on encoding-decoding. The scheme based on encoding-decoding with impulsive protocol is introduced to multiagent systems in general directed networks topology of which the graph is strongly connected. The impulsive protocols and limited bandwidth communication enhance the performance on energy saving and the involvement of nonlinear dynamics could suit more real-world cases. The design of encoders and decoders is presented, which is the key to achieve the goal that the information exchanged is subject to limited bandwidth communication. The conditions to guarantee the impulsive consensus and the conditions to avoid quantizer saturation arc obtained. Moreover, the convergence rate of such multiagent systems are also characterized by the analysis of the exponential consensus. The numerical simulations are presented to support the theoretical results.																	2168-2267	2168-2275				JAN	2020	50	1					36	47		10.1109/TCYB.2018.2863108													
J								Resilient Control of Wireless Networked Control System Under Denial-of-Service Attacks: A Cross-Layer Design Approach	IEEE TRANSACTIONS ON CYBERNETICS										Delta domain; denial-of-service (DoS) attack; game theory; resilient control; wireless networked control system (WNCS)	MULTIAGENT SYSTEMS; THEORETIC METHODS; PERFORMANCE; SECURITY; STRATEGY; GAMES	The resilient control refers to the control methodology which provides an interdisciplinary solution to secure the control system. In this paper, the resilient control problem is investigated for a class of wireless networked control systems (WNCS) under a denial-of-service (DoS) attack. In the presence of the DoS attacker, the control command sent by the transmitter may be interfered, which can cause the degradation of the signal-to-interference-plus-noise ratio and further lead to packet dropout phenomenon. Such a packet dropout phenomenon is described by a two-state Markov-chain. A cross-layer view is adopted toward the security issue of the considered WNCS. The Nash power strategies and optimal control strategy in the delta-domain are obtained in the cyber- and physical-layer, respectively. Based on the obtained strategies, the coupled-design problem is solved which aims to drive the underlying control performance to the desired security region by dynamically manipulating the cyber-layer pricing parameters. Finally, a numerical simulation is conducted to verify the validity of the proposed methodology.																	2168-2267	2168-2275				JAN	2020	50	1					48	60		10.1109/TCYB.2018.2863689													
J								Shared Gaussian Process Latent Variable Model for Incomplete Multiview Clustering	IEEE TRANSACTIONS ON CYBERNETICS										Clustering; Gaussian process (GP); Gaussian process latent variable model (GPLVM); incomplete multiview	SUPPORT VECTOR MACHINES; DIMENSIONALITY; FRAMEWORK	These days, many multiview learning methods have been proposed by integrating the complementary information of multiple views and can significantly improve the performance of machine learning tasks comparing with single-view learning methods. However, most of these methods fail to learn better models when the multiview data are unpaired (or partially paired) or incomplete (or partially complete). Although some previous attempts have been made to address these problems, these methods often lead to poor results when dealing with incomplete multiview data that contain a relatively large number of missing instances. In fact, this incomplete problem is more challenging than the unpaired problem since less shared information can be caught by the model in the former case. In this paper, we propose a shared Gaussian process (GP) latent variable model for incomplete multiview clustering to gain the merits of two worlds (i.e., GP and multiview learning). Specifically, it learns a set of intentionally aligned representative auxiliary points in individual views jointly to not only compensate for missing instances but also implement the group-level constraint. Thus, the shared information among these views can be explicitly built into the model. All of the hyper-parameters and auxiliary points are simultaneously learned by variational inference. Compared with the existing methods, our method naturally inherits the advantages of GP. Furthermore, it is also straightforwardly extended to cases with more than two views without adding any complexity in formulation. In the experiments, we compare it with the state-of-the-art methods for incomplete multiview data clustering to demonstrate its superiorities.																	2168-2267	2168-2275				JAN	2020	50	1					61	73		10.1109/TCYB.2018.2863790													
J								Multitask Feature Selection by Graph-Clustered Feature Sharing	IEEE TRANSACTIONS ON CYBERNETICS										Graph-guided regularization; multitask feature selection (MTFS); smooth proximal gradient; task grouping	REGRESSION; SPARSITY	Multitask feature selection (MTFS) methods have become more important for many real world applications, especially in a high-dimensional setting. The most widely used assumption is that all tasks share the same features, and the l(2,1) regularization method is usually applied. However, this assumption may not hold when the correlations among tasks are not obvious. Learning with unrelated tasks together may result in negative transfer and degrade the performance. In this paper, we present a flexible MTFS by graph-clustered feature sharing approach. To avoid the above limitation, we adopt a graph to represent the relevance among tasks instead of adopting a hard task set partition. Furthermore, we propose a graph-guided regularization approach such that the sparsity of the solution can be achieved on both the task level and the feature level, and a variant of the smooth proximal gradient method is developed to solve the corresponding optimization problem. An evaluation of the proposed method on multitask regression and multitask binary classification problem has been performed. Extensive experiments on synthetic datasets and real-world datasets demonstrate the effectiveness of the proposed approach to capture task structure.																	2168-2267	2168-2275				JAN	2020	50	1					74	86		10.1109/TCYB.2018.2864107													
J								A Deep Evaluator for Image Retargeting Quality by Geometrical and Contextual Interaction	IEEE TRANSACTIONS ON CYBERNETICS										Content match; geometrical shape; image retargeting quality assessment; perception simulation; segmented stacked AutoEnCoder (SAE)	ITERATIVE QUANTIZATION; SPARSE REPRESENTATION; PROCRUSTEAN APPROACH; INFORMATION; STATISTICS; DISTORTION; SCENE; SHAPE	An image is compressed or stretched during the multidevice displaying, which will have a very big impact on perception quality. In order to solve this problem, a variety of image retargeting methods have been proposed for the retargeting process. However, how to evaluate the results of different image retargeting is a very critical issue. In various application systems, the subjective evaluation method cannot be applied on a large scale. So we put this problem in the accurate objective-quality evaluation. Currently, most of the image retargeting quality assessment algorithms use simple regression methods as the last step to obtain the evaluation result, which are not corresponding with the perception simulation in the human vision system (HVS). In this paper, a deep quality evaluator for image retargeting based on the segmented stacked AutoEnCoder (SAE) is proposed. Through the help of regularization, the designed deep learning framework can solve the overfitting problem. The main contributions in this framework are to simulate the perception of retargeted images in HVS. Especially, it trains two separated SAE models based on geometrical shape and content matching. Then, the weighting schemes can be used to combine the obtained scores from two models. Experimental results in three well-known databases show that our method can achieve better performance than traditional methods in evaluating different image retargeting results.																	2168-2267	2168-2275				JAN	2020	50	1					87	99		10.1109/TCYB.2018.2864158													
J								Feature Extraction for Classification of Hyperspectral and LiDAR Data Using Patch-to-Patch CNN	IEEE TRANSACTIONS ON CYBERNETICS										Deep convolutional neural network (CNN); feature extraction; hyperspectral image (HSI) classification; multisensor fusion	REMOTE-SENSING DATA; LAND-COVER CLASSIFICATION; DEEP FEATURE-EXTRACTION; EXTINCTION PROFILES; FUSION; DIMENSIONALITY; FRAMEWORK	Multisensor fusion is of great importance in Earth observation related applications. For instance, hyperspectral images (HSIs) provide wealthy spectral information while light detection and ranging (LiDAR) data provide elevation information, and using HSI and LiDAR data together can achieve better classification performance. In this paper, an unsupervised feature extraction framework, named as patch-to-patch convolutional neural network (PToP CNN), is proposed for collaborative classification of hyperspectral and LiDAR data. More specific, a three-tower PToP mapping is first developed to seek an accurate representation from HSI to LiDAR data, aiming at merging multiscale features between two different sources. Then, by integrating hidden layers of the designed PToP CNN, extracted features are expected to possess deeply fused characteristics. Accordingly, features from different hidden layers are concatenated into a stacked vector and fed into three fully connected layers. To verify the effectiveness of the proposed classification framework, experiments are executed on two benchmark remote sensing data sets. The experimental results demonstrate that the proposed method provides superior performance when compared with some state-of-the-art classifiers, such as two-branch CNN and context CNN.																	2168-2267	2168-2275				JAN	2020	50	1					100	111		10.1109/TCYB.2018.2864670													
J								A Learning-Based Hierarchical Control Scheme for an Exoskeleton Robot in Human-Robot Cooperative Manipulation	IEEE TRANSACTIONS ON CYBERNETICS										Asymmetric barrier Lyapunov function (ABLE); exoskeleton robot; Gaussian mixture; human-robot cooperative manipulation; impedance-based task; learning human skills from demonstration	ADAPTIVE NEURAL-CONTROL; NONLINEAR-SYSTEMS; INTENTION ESTIMATOR; TRACKING CONTROL; REHABILITATION; PRIMITIVES; FRAMEWORK	Exoskeleton robots can assist humans to perform activities of daily living with little effort. In this paper, a hierarchical control scheme is presented which enables an exoskeleton robot to achieve cooperative manipulation with humans. The control scheme consists of two layers. In low-level control of the upper limb exoskeleton robot, an admittance control scheme with an asymmetric barrier Lyapunov function-based adaptive neural network controller is proposed to enable the robot to be back drivable. In order to achieve high-level interaction, a strategy for learning human skills from demonstration is proposed by utilizing Gaussian mixture models, which consists of the learning and reproduction phase. During the learning phase, the robot observes and learns how a demonstrator performs a specific impedance-based task successfully, and in the reproduction phase, the robot can provide the subjects with just enough assistance by extracting human skills from demonstrations to prevent the motion of the robot end-effector deviating far from desired ones, due to variation in the interaction force caused by environmental disturbances. Experimental results of two different tasks show that the proposed control scheme can provide human subjects with assistance as needed during cooperative manipulation.																	2168-2267	2168-2275				JAN	2020	50	1					112	125		10.1109/TCYB.2018.2864784													
J								Adaptive Fuzzy Tracking Control for Strict-Feedback Markov Jumping Nonlinear Systems With Actuator Failures and Unmodeled Dynamics	IEEE TRANSACTIONS ON CYBERNETICS										Adaptive tracking control; backstepping control; fault-tolerant control; fuzzy control; Markovian jumping nonlinear systems	SLIDING MODE CONTROL; COMPENSATION CONTROL; UNCERTAIN SYSTEMS; QUADRATIC GAMES; LINEAR-SYSTEMS; NEURAL-CONTROL; ROBUST-CONTROL; DEAD-ZONE; STABILIZATION; DESIGN	In this paper, an adaptive fuzzy tracking controller is developed fill- a class of strict-feedback Markovian jumping systems subjected to multisource uncertainties. The unpredictable actuator failures, the unknown nonlinearities, and the unmodeled dynamics are simultaneously taken into consideration, which evolve according to the Markov chain. It is noted that the elements in the transition rate matrix of the Markov chain are not fully available. In virtue of the norm estimation approach, the challenges caused by the complex multiple uncertainties and actuator failures are effectively handled. Furthermore, to compensate for the unavailable switching nonlinearities, the fuzzy logic systems are employed as online approximators. As a result, a novel adaptive fuzzy fault-tolerant tracking control structure is constructed. The sufficient condition is provided to guarantee that the studied system is stochastically stable. Finally, a number of illustrative examples are employed to demonstrate the effectiveness of the proposed methodology.																	2168-2267	2168-2275				JAN	2020	50	1					126	139		10.1109/TCYB.2018.2865677													
J								Enhancing Gaussian Estimation of Distribution Algorithm by Exploiting Evolution Direction With Archive	IEEE TRANSACTIONS ON CYBERNETICS										Archive; evolution direction; Gaussian estimation of distribution algorithm (GEDA); premature convergence	DIFFERENTIAL EVOLUTION; OPTIMIZATION ALGORITHM; DECOMPOSITION; POPULATION; DIVERSITY; STRATEGY; EDAS	As a typical model-based evolutionary algorithm, estimation of distribution algorithm (EDA) possesses unique characteristics and has been widely applied in global optimization. However, the commonly used Gaussian EDA (GEDA) usually suffers from premature convergence, which severely limits its search efficiency. This paper first systematically analyzes the reasons for the deficiency of traditional GEDA, then tries to enhance its performance by exploiting the evolution direction, and finally develops a new GEDA variant named EDA(2). Instead of only utilizing some good solutions produced in the current generation to estimate the Gaussian model, EDA(2) preserves a certain number of high-quality solutions generated in the previous generations into an archive and employs these historical solutions to assist estimating the covariance matrix of Gaussian model. By this means, the evolution direction information hidden in the archive is naturally integrated into the estimated model, which in turn can guide EDA(2) toward more promising solution regions. Moreover, the new estimation method significantly reduces the population size of EDA(2) since it needs fewer individuals in the current population for model estimation. As a result, a fast convergence can be achieved. To verify the efficiency of EDA(2), we tested it on a variety of benchmark functions and compared it with several state-of-the-art EAs. The experimental results demonstrate that EDA(2) is efficient and competitive.																	2168-2267	2168-2275				JAN	2020	50	1					140	152		10.1109/TCYB.2018.2869567													
J								Evaluation of Gaze Tracking Calibration for Longitudinal Biomedical Imaging Studies	IEEE TRANSACTIONS ON CYBERNETICS										Accuracy; biomedical imaging; calibration; data analysis; gaze tracking; testing; ultrasonography	VISUAL-SEARCH PATTERNS; EYE-TRACKING; EXPERTISE; PERCEPTION; MODEL; PERFORMANCE; EXPERIENCE; RADIOLOGISTS; RECOGNITION; ALGORITHMS	Gaze tracking is a promising technology for studying the visual perception of clinicians during image-based medical exams. It could he used in longitudinal studies to analyze their perceptive process, explore human-machine interactions, and develop innovative computer-aided imaging systems. However, using a remote eye tracker in an unconstrained environment and over time periods of weeks requires a certain guarantee of performance to ensure that collected gaze data are fit for purpose. We report the results of evaluating eye tracking calibration for longitudinal studies. First, we tested the performance of an eye tracker on a cohort of 13 users over a period of one month. For each participant, the eye tracker was calibrated during the first session. The participants were asked to sit in front of a monitor equipped with the eye tracker, but their position was not constrained. Second, we tested the performance of the eye tracker on sonographers positioned in front of a cart-based ultrasound scanner. Experimental results show a decrease of accuracy between calibration and later testing of 0.30 degrees and a further degradation over time at a rate of 0.13 degrees . month(-1) . The overall median accuracy was 1.00 degrees (50.9 pixels) and the overall median precision was 0.16 degrees (83 pixels). The results from the ultrasonography setting show a decrease of accuracy of 0.16 degrees between calibration and later testing. This slow degradation of gaze tracking accuracy could impact the data quality in long-term studies. Therefore, the results we present here can help in planning such long-term gaze tracking studies.																	2168-2267	2168-2275				JAN	2020	50	1					153	163		10.1109/TCYB.2018.2866274													
J								Immune-Endocrine System Inspired Hierarchical Coevolutionary Multiobjective Optimization Algorithm for IoT Service	IEEE TRANSACTIONS ON CYBERNETICS										Coevolutionary optimization; hierarchical multipopulation; immune-endocrine system; Internet of Things (IoT); multiobjective optimization; services selection	EVOLUTIONARY ALGORITHM; GENETIC ALGORITHM; SELECTION; INTERNET; NETWORK; DESIGN	The intelligent devices in Internet of Things (IoT) not only provide services but also consider how to allocate heterogeneous resources and reduce resource consumption and service time as far as possible. This issue becomes crucial in the case of large-scale IoT environments. In order for the IoT service system to respond to multiple requests simultaneously and provide Pareto optimal decisions, we propose an immune-endocrine system inspired hierarchical coevolutionary multiobjective optimization algorithm (IE-HCMOA) in this paper. In IE-HCMOA, a multiobjective immune algorithm based on global ranking with vaccine is designed to choose superior antibodies. Meanwhile, we adopt clustering in top population to make the operations more directional and purposeful and realize self-adaptive searching. And we use the human forgetting memory mechanism to design two-level memory storage for the choice problem of solutions to achieve promising performance. In order to validate the practicability and effectiveness of IE-HCMOA, we apply it to the field of agricultural IoT service. The simulation results demonstrate that the proposed algorithm can obtain the best Pareto, the strongest exploration ability, and excellent performance than nondominated neighbor immune algorithms and NSGA-II.																	2168-2267	2168-2275				JAN	2020	50	1					164	177		10.1109/TCYB.2018.2866527													
J								Incremental Class Learning for Hierarchical Classification	IEEE TRANSACTIONS ON CYBERNETICS										Fuzzy adaptive resonance theory-supervised predictive mapping (ARTMAP); hierarchical classification; incremental class learning; multimedia recommendation system; online normalization	STRATEGIES; MACHINE	Objects can be described in hierarchical semantics, and people also perceive them this way. It leads to the need for hierarchical classification in machine learning. On the other hand, when a new data that belongs to a new class is given, the existing classification methods should be retrained for all data including the new data. To deal with these issues, we propose an adaptive resonance theory-supervised predictive mapping for hierarchical classification (ARTMAP-HC) network that allows incremental class learning for raw data without normalization in advance. Our proposed ARTMAP-HC is composed of hierarchically stacked modules, and each module incorporates two fuzzy ARTMAP networks. Regardless of the level of the class hierarchy and the number of classes for each level, ARTMAP-HC is able to incrementally learn sequentially added input data belonging to new classes. By using a novel online normalization process, ARTMAP-HC can classify the new data without prior knowledge of the maximum value of the dataset. By adopting the prior labels appending process, the class dependency between class hierarchy levels is reflected in ARTMAP-HC. The effectiveness of the proposed ARTMAP-HC is validated through experiments on hierarchical classification datasets. To demonstrate the applicability, ARTMAP-HC is applied to a multimedia recommendation system for digital storytelling.																	2168-2267	2168-2275				JAN	2020	50	1					178	189		10.1109/TCYB.2018.2866869													
J								Scale-Free Loopy Structure Is Resistant to Noise in Consensus Dynamics in Complex Networks	IEEE TRANSACTIONS ON CYBERNETICS										Distributed average consensus; Gaussian white noise; network coherence; resistance distance; scale-free network; small-world network	NORMALIZED LAPLACIAN; FREE WEB; DISTANCE; PERFORMANCE; COHERENCE; TRIANGULATIONS; LIMITATIONS; ALGORITHMS; DIMENSION; TOPOLOGY	The vast majority of real-world networks are scale-free, loopy, and sparse, with a power-law degree distribution and a constant average degree. In this paper, we study first-order consensus dynamics in binary scale-free networks, where vertices arc subject to white noise. We focus on the coherence of networks characterized in terms of the H-2-norm, which quantifies how closely the agents track the consensus value. We first provide a lower bound of coherence of a network in terms of its average degree, which is independent of the network order. We then study the coherence of some sparse, scale-free real-world networks, which approaches a constant. We also study numerically the coherence of Barabisi-Albert networks and high-dimensional random Apollonian networks, which also converges to a constant when the networks grow. Finally, based on the connection of coherence and the Kirchhoff index, we study analytically the coherence of two deterministically growing sparse networks and obtain the exact expressions, which tend to small constants. Our results indicate that the effect of noise on the consensus dynamics in power-law networks is negligible. We argue that scale-free topology, together with loopy structure, is responsible for the strong robustness with respect to noisy consensus dynamics in power-law networks.																	2168-2267	2168-2275				JAN	2020	50	1					190	200		10.1109/TCYB.2018.2868124													
J								Event-Triggered Adaptive Output Feedback Control for a Class of Uncertain Nonlinear Systems With Actuator Failures	IEEE TRANSACTIONS ON CYBERNETICS										Event-triggered control; fault-tolerant control; networked control systems; neural networks (NNs); strict-feedback nonlinear systems	FAULT-TOLERANT CONTROL; H-INFINITY; NETWORKS; DESIGN; STATE	This paper investigates the event-triggered adaptive output feedback control problem for a class of uncertain nonlinear systems in the presence of actuator failures and unknown control direction. By utilizing the adaptive backstopping technique, an event-based output feedback controller is developed together with a time-variant event-triggered rule. In this design, the radial basis function neural network algorithms are first introduced to identify the unknown terms of the systems. Then, a new state observer with adaptive compensation is designed to estimate the state vector. The overall control strategy guarantees that the output signal tracks the reference signal and all the signals of the closed-loop systems are bounded. Unlike the existing methods, the proposed control scheme can handle the coupling term incurred by the loss of effectiveness fault of the actuator, the event-triggered rule, and unknown control direction. Finally, an example is performed to demonstrate the validity of the proposed strategy.																	2168-2267	2168-2275				JAN	2020	50	1					201	210		10.1109/TCYB.2018.2868169													
J								Type-2 Fuzzy Logic-Based Linguistic Pursuing Strategy Design and Its Deployment to a Real-World Pursuit Evasion Game	IEEE TRANSACTIONS ON CYBERNETICS										Footprint of uncertainty (FOU); interval type-2 (T2) fuzzy sets; pursuing strategy (PS); T2 fuzzy logic systems (FLSs)	INTERVAL TYPE-2; MOBILE ROBOT; SYSTEMS; PI	This paper presents a systematic and interpretable design approach to generate type-2 (T2) fuzzy logic-based linguistic pursuing strategies (PSs) and their deployment to a real-world pursuit-evasion game (PEG). First, we have developed a novel T2 fuzzy logic-based strategy planner (T2-FSP). Then, through detailed theoretical investigations on the input- output mapping of the T2-FSP, it has been shown that it is possible to design a linguistic PS which defines both pursuer's approaching behavior (aggressive, smooth) and side (left or right) to the evader by simply tuning the footprint of uncertainty (FOU) sizes of the T2 fuzzy sets. Hence, an interpretable relationship has been revealed between the FOU sizes and the PSs through comparative theoretical explorations and derivations. Additionally, as there is a need to employ different PSs in a dynamic PEG environment, a type-1 fuzzy decision making (T1-FDM) mechanism has been designed to tune the FOU sizes of the T2-FSP and, thus, adjust the PS to be employed in real time. A real-world game environment is constructed in order to validate the developed T2 fuzzy logic-based PSs and T1-FDM mechanism in real time. Comparative experimental results have been presented to show that the T2 fuzzy logic-based PSs have satisfactory performance against a human user.																	2168-2267	2168-2275				JAN	2020	50	1					211	221		10.1109/TCYB.2018.2868405													
J								Controllability Ensured Leader Group Selection on Signed Multiagent Networks	IEEE TRANSACTIONS ON CYBERNETICS										Leader group selection; multiagent system; network controllability; signed graph	STRUCTURAL CONTROLLABILITY; CONTAINMENT CONTROL; GRAPH; CONSENSUS; OBSERVABILITY; SYSTEMS; PARTITION; CONSTRAINTS; ACTUATOR; CYCLES	Leader-follower controllability on signed multiagent networks is investigated in this paper. Specifically, we consider a dynamic signed multiagent network, where the agents interact via neighbor-based Laplacian feedback and the network allows positive and negative edges to capture cooperative and competitive interactions among agents. The agents are classified as either leaders or followers, thus forming a leader-follower signed network. To enable full control of the leader-follower signed network, controllability ensured leader group selection approaches are investigated in this paper, that is, identifying a small subset of nodes in the signed network, such that the selected nodes are able to drive the network to a desired behavior, even in the presence of antagonistic interactions. In particular, graphical characterizations of the controllability of signed networks are first developed based on the investigation of the interaction between network topology and agent dynamics. Since signed path and cycle graphs are basic building blocks for a variety of networks, the developed topological characterizations are then exploited to develop leader selection methods for signed path and cycle graphs to ensure leader-follower controllability. Along with illustrative examples, heuristic algorithms are also developed showing how leader selection methods developed for path and cycle graphs can be potentially extended to more general signed networks. In contrast to existing results that mainly focus on unsigned networks, this paper characterizes controllability and develops leader selection methods for signed networks. In addition, the developed results are generic, in the sense that they are not only applicable to signed networks but also to unsigned networks, since unsigned networks are a particular case of signed networks that only contain positive edges.																	2168-2267	2168-2275				JAN	2020	50	1					222	232		10.1109/TCYB.2018.2868470													
J								Bi-objective Elite Differential Evolution Algorithm for Multivalued Logic Networks	IEEE TRANSACTIONS ON CYBERNETICS										Differential evolution (DE); multiobjective; multivalued logic (MVL); network; Pareto optimal solution	MULTIPLE-VALUED LOGIC; LOCAL SEARCH; DIRECT COVER; COMPUTING CAPACITY; NEURAL-NETWORKS; LEARNING-METHOD; MVL FUNCTIONS; OPTIMIZATION; DESIGN; REPRESENTATION	In this paper, a novel algorithm called bi-objective elite differential evolution (BOEDE) is proposed to optimize multivalued logic (MVL) networks. It is a multiobjective algorithm completely different from all previous single-objective optimization ones. The two objective functions, error and optimality, are put into evaluating the fitness of individuals in evolution simultaneously. BOEDE innovatively uses an archive population with different ranks to store elite individuals and off-springs. Moreover, a characteristic updating method based on this archive structure is designed to produce the parent population. Because of the particularity of MVL network problems, the performance of BOEDE to solve them is further improved by strictly distinguishing elite solutions and Pareto optimal solutions, and by modifying the method of dealing with illegal variables. The simulations show that BOEDE can collect a great number of solutions to provide decision support for a variety of applications. The comparison results also indicate that BOEDE is significantly better than the existing algorithms.																	2168-2267	2168-2275				JAN	2020	50	1					233	246		10.1109/TCYB.2018.2868493													
J								Spectral Clustering by Joint Spectral Embedding and Spectral Rotation	IEEE TRANSACTIONS ON CYBERNETICS										Normalized cut (Ncut); spectral clustering; spectral rotation	FACE-RECOGNITION; KERNEL; ILLUMINATION	Spectral clustering is an important clustering method widely used for pattern recognition and image segmentation. Classical spectral clustering algorithms consist of two separate stages: 1) solving a relaxed continuous optimization problem to obtain a real matrix followed by 2) applying K-means or spectral rotation to round the real matrix (i.e., continuous clustering result) into a binary matrix called the cluster indicator matrix. Such a separate scheme is not guaranteed to achieve jointly optimal result because of the loss of useful information. To obtain a better clustering result, in this paper, we propose a joint model to simultaneously compute the optimal real matrix and binary matrix. The existing joint model adopts an orthonormal real matrix to approximate the orthogonal but nonorthonormal cluster indicator matrix. It is noted that only in a very special case (i.e., all clusters have the same number of samples), the cluster indicator matrix is an orthonormal matrix multiplied by a real number. The error of approximating a nonorthonormal matrix is inevitably large. To overcome the drawback, we propose replacing the nonorthonormal cluster indicator matrix with a scaled cluster indicator matrix which is an orthonormal matrix. Our method is capable of obtaining better performance because it is easy to minimize the difference between two orthonormal matrices. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed method (called JSESR).																	2168-2267	2168-2275				JAN	2020	50	1					247	258		10.1109/TCYB.2018.2868742													
J								Distributed Secure State Estimation and Control for CPSs Under Sensor Attacks	IEEE TRANSACTIONS ON CYBERNETICS										Cyber-physical system (CPS); distributed secure control; secure state estimation; sensor attacks	CYBER-PHYSICAL SYSTEMS; OBSERVERS	In this paper, we investigate the distributed secure state estimation and control problems for interconnected cyber-physical systems (CPSs) with some sensors being attacked. First, by exploring the distinct properties of the unidentifiable attacks to a CPS, an explicit sufficient condition that the secure state estimation problem can be solvable is established. Then distributed preselectors and observers are presented to solve the secure state estimation problems. Furthermore, with the obtained state estimation, fractional dynamic surface-based distributed secure controllers are also proposed for the secure control problem. Theoretical analysis shows that, with the proposed distributed secure observers and controllers, not only the state of the CPS under attacks can be obtained in a given finite time but also the dynamic surface can be achieved and maintained in a finite time. Finally, the results are applied to an islanded micro-grid system as an illustration, which verifies the effectiveness of the proposed schemes.																	2168-2267	2168-2275				JAN	2020	50	1					259	269		10.1109/TCYB.2018.2868781													
J								Learning Scale-Adaptive Tight Correlation Filter for Object Tracking	IEEE TRANSACTIONS ON CYBERNETICS										Correlation filter; object tracking; ridge regression; scale adaption	ROBUST VISUAL TRACKING	In this paper, we propose a novel tracking method by formulating tracking as a correlation filtering as well as a ridge regression problem. First, we develop a tight correlation filter-based tracking framework from the signal detection perspective. In this formulation, the correlation filter is set as the same size as the target, which can make full use of the relations of the adjacent image patches and effectively exclude the influence of the background. Specifically, we point out that the novel correlation filter model can be regarded as the ridge regression model which takes into account the different importance of the samples and has the consistent objective with tracking. Second, we focus on the scale variation problem in tracking. By making use of the spatial structure of the correlation filter, the multiscale filter banks can be generated via interpolation to handle the scale estimation problem easily. Third, we present a novel distance importance-based confidence calculation model to determine the final tracking result, which not only makes use of the fine discriminability of the correlation filter but also takes the distance importance of the candidate samples into account to alleviate the impact of similar distractors. Experimental results demonstrate that our method is superior to several state-of-the-art trackers and many other correlation filter-based methods in the benchmark datasets.																	2168-2267	2168-2275				JAN	2020	50	1					270	283		10.1109/TCYB.2018.2868782													
J								Event-Based Multiagent Consensus Control: Zeno-Free Triggering via L-p Signals	IEEE TRANSACTIONS ON CYBERNETICS										Event-based control; L-p signals; multiagent consensus; Zeno-free triggering	COOPERATIVE CONTROL; DYNAMICAL-SYSTEMS; COORDINATION; STABILITY; GAIN	In this paper, we develop some new event-triggered algorithms for achieving distributed consensus for a multiagent system that guarantees fully Zeno-free triggerings for all the agents. In the proposed framework, each agent updates its control input only at its own triggering instants by using local measurements (i.e., relative states) with respect to neighboring agents, and such local measurements can be done in a local coordinate frame. For all agents, a positive L-p signal function is embedded in the event detector functions, which aims to avoid the possible comparison of an event error term to a zero threshold that may happen in a zero-crossing scenario. We further propose a Zeno-free self triggered algorithm to achieve multiagent consensus, which enables discrete-time measurements and thus avoids continuous measurements between the neighboring agents. We also show that the proposed event-based consensus algorithms guarantee less frequent triggered events in a bounded time interval compared to the conventional algorithm without L-p signals. Simulations and comparisons are provided to validate the performance and effectiveness of the proposed event-based consensus schemes.																	2168-2267	2168-2275				JAN	2020	50	1					284	296		10.1109/TCYB.2018.2868786													
J								Ensemble Decision for Spam Detection Using Term Space Partition Approach	IEEE TRANSACTIONS ON CYBERNETICS										Ensemble decision; feature construction; machine learning; spam detection; term space partition (TSP)	NEGATIVE SELECTION ALGORITHM; NETWORK; FILTER	This paper proposes an ensemble decision approach which combines global and local features of e-mails together to detect spam effectively. In the proposed method, a special feature construction method named term space partition (TSP) is utilized to divide the whole term space into several subspaces and adopt different feature construction strategies on each of them, respectively. This method can make each term play a distinct and important role when conducting detection. This method is utilized and extended by introducing the sliding window technique to extract local features from e-mails. The global classifier and local classifiers are constructed on a global feature vector set and local feature vector sets, respectively, and together make the ensemble decision by adopting the voting technique. The principles of the TSP-based approach and mechanism of the ensemble decision method are presented in detail. Five different and standard benchmark corpora are applied to experiments for performance evaluation of this proposed method. Comprehensive experimental results show that the proposed method brings significant performance improvement and better robustness on the basis of the TSP-based approach. In addition, the proposed method outperforms the current prevalent and state-of-the-art approaches, especially when a comprehensive consideration of performance, efficiency, and robustness is taken. This endows it with flexible capability and adaptivity in the real-world applications.																	2168-2267	2168-2275				JAN	2020	50	1					297	309		10.1109/TCYB.2018.2868794													
J								Multipoint Rendezvous in Multirobot Systems	IEEE TRANSACTIONS ON CYBERNETICS										Hierarchical consensus; multirobot coordination; networked robots; rendezvous control	COORDINATION; CONVERGENCE	Multirobot rendezvous control and coordination strategies have garnered significant interest in recent years because of their potential applications in decentralized tasks. In this paper, we introduce a coordinate-free rendezvous control strategy to enable multiple robots to gather at different locations (dynamic leader robots) by tracking their hierarchy in a connected interaction graph. A key novelty in this strategy is the gathering of robots in different groups rather than at a single consensus point, motivated by autonomous multipoint recharging and flocking control problems. We show that the proposed rendezvous strategy guarantees convergence and maintains connectivity while accounting for practical considerations such as robots with limited speeds and an obstacle-rich environment. The algorithm is distributed and handles minor faults such as a broken immobile robot and a sudden link failure. In addition, we propose an approach that determines the locations of rendezvous points based on the connected interaction topology and indirectly optimizes the total energy consumption for rendezvous in all robots. Through extensive experiments with the Robotarium multirobot testbed, we verified and demonstrated the effectiveness of our approach and its properties.																	2168-2267	2168-2275				JAN	2020	50	1					310	323		10.1109/TCYB.2018.2868870													
J								Context-Patch Face Hallucination Based on Thresholding Locality-Constrained Representation and Reproducing Learning	IEEE TRANSACTIONS ON CYBERNETICS										Context-patch; face hallucination; image super-resolution; position-patch; reproducing learning (RL)	IMAGE SUPERRESOLUTION; SPARSE; FRAMEWORK; ALGORITHM; MODELS	Face hallucination is a technique that reconstructs high-resolution (HR) faces from low-resolution (LR) faces, by using the prior knowledge learned from HR/LR face pairs. Most state-of-the-arts leverage position-patch prior knowledge of the human face to estimate the optimal representation coefficients for each image patch. However, they focus only the position information and usually ignore the context information of the image patch. In addition, when they are confronted with misalignment or the small sample size (SSS) problem, the hallucination performance is very poor. To this end, this paper incorporates the contextual information of the image patch and proposes a powerful and efficient context-patch-based face hallucination approach, namely, thresholding locality-constrained representation and reproducing learning (TLcR-RL). Under the context-patch-based framework, we advance a thresholding-based representation method to enhance the reconstruction accuracy and reduce the computational complexity. To further improve the performance of the proposed algorithm, we propose a promotion strategy called reproducing learning. By adding the estimated HR face to the training set, which can simulate the case that the HR version of the input LR face is present in the training set, it thus iteratively enhances the final hallucination result. Experiments demonstrate that the proposed TLcR-RL method achieves a substantial increase in the hallucinated results, both subjectively and objectively. In addition, the proposed framework is more robust to face misalignment and the SSS problem, and its hallucinated HR face is still very good when the LR test face is from the real world. The MATLAB source code is available at https://github.com/junjun-jiang/TLcR-RL.																	2168-2267	2168-2275				JAN	2020	50	1					324	337		10.1109/TCYB.2018.2868891													
J								Optimal Decentralized Output-Feedback LQG Control With Random Communication Delay	IEEE TRANSACTIONS ON CYBERNETICS										Communication delay; decentralized control; optimal; output-feedback; random	NONLINEAR-SYSTEMS; CONTROL STRATEGIES; NETWORKED SYSTEMS; STATE-FEEDBACK; INFORMATION	This paper is concerned with the optimal decentralized output-feedback control of the large-scale systems. A random information pattern is considered, where the information is transmitted among the subsystems with random communication delays. For the random information pattern, the optimal LQC; problems for both global estimation case and local estimation case are studied. It is difficult to derive the optimal controller under random framework, because the gains of the controller must be designed to satisfy the random sparse structure constraints. In this paper, we design the optimal controller by Hadamard product method. For global estimation case, the gains of the controller are obtained by solving linear matrix equation. For local estimation case, an iterative algorithm is exploited to compute the gains. In addition, the value of the cost function achieved by the designed controller is found and shown to monotonically increase with the increase of the delay probability for both global and local estimation cases. Finally, the theoretical results are illustrated by two numerical examples.																	2168-2267	2168-2275				JAN	2020	50	1					338	350		10.1109/TCYB.2018.2868968													
J								Average Quasi-Consensus Algorithm for Distributed Constrained Optimization: Impulsive Communication Framework	IEEE TRANSACTIONS ON CYBERNETICS										Distributed optimization; impulsive average quasi-consensus algorithm; impulsive communication framework; multiagent networks	NEURODYNAMIC APPROACH; CONVEX-OPTIMIZATION; GRADIENT ALGORITHM; ECONOMIC-DISPATCH; MULTIAGENT SYSTEM; NETWORKS; INITIALIZATION; STABILITY	This paper presents the impulsive average quasi-consensus algorithm for distributed constrained convex optimization. First, the constrained optimization problem can be transformed into an unconstrained problem using the interior point method, and then a distributed algorithm is modeled by means of impulsive differential equation. In the framework of the continuous-time gradient method and algebraic graph theory, each agent can deal with one local objective function with local constraints. At the impulsive instants, each agent can communicate with its neighboring agents over the network. Under certain conditions, the impulsive average quasi-consensus is achieved. It is shown that the state of average quasi-consensus is the optimal solution of the aforementioned unconstrained optimization problem, and the state of each agent can also reach the neighborhood of the optimal solution. Finally, two numerical examples show the effectiveness of the proposed impulsive average quasi-consensus algorithm. Moreover, the feasibility of the approach is verified by an application to one sensor network localization problem.																	2168-2267	2168-2275				JAN	2020	50	1					351	360		10.1109/TCYB.2018.2869249													
J								Visual Tracking and Depth Estimation of Mobile Robots Without Desired Velocity Information	IEEE TRANSACTIONS ON CYBERNETICS										Depth estimation; Lyapunov methods; mobile robot; visual trajectory tracking	SERVO REGULATION; CONSENSUS; POSITION; GEOMETRY; POINT	In this paper, a visual servoing approach is developed for the trajectory tracking control and depth estimation problem of a mobile robot without a priori knowledge about desired velocities. By exploiting the multiple images captured by the on-board camera, the current and desired poses (i.e., scaled translation and orientation) of the mobile robot are reconstructed to define system errors. Then, an adaptive time-varying controller is proposed to achieve the trajectory tracking task in the presence of nonholonomic constraint and unknown depth parameters. Most of previous works require the measurement of the desired velocity information to facilitate the controller design, leading to tedious offfine computation. In this paper, to eliminate this requirement, the desired velocities are estimated in real-time based on a reduced order observer. Moreover, an augmented update law is designed to compensate fir the unknown depth parameters and identify the inverse depth constant. The Lyapunov-based method is employed to prove that the proposed controller achieves asymptotic tracking, and the inverse depth estimate converges to its actual value provided that a persistent excitation condition is satisfied. Subsequently, a robust data-driven algorithm is introduced to ensure the convergence of the inverse depth estimate under a relaxed finite excitation condition. Simulation and experimental results are provided to demonstrate the effectiveness of the proposed approach.																	2168-2267	2168-2275				JAN	2020	50	1					361	373		10.1109/TCYB.2018.2869623													
J								Robust Online Multilabel Learning Under Dynamic Changes in Data Distribution With Labels	IEEE TRANSACTIONS ON CYBERNETICS										Concept drift; dynamic changes; multilabel data streams; online multilabel learning (OMLL)	CLASSIFIERS; REGRESSION; NETWORKS; MACHINE; SYSTEM	In this paper, a robust online multilabel learning method dealing with dynamically changing multilabel data streams is proposed. The proposed method has three advantages: 1) higher accuracy due to a newly defined objective function based on labels ranking; 2) fast training and update based on a newly derived closed-form (rather than gradient descent based) solution for the new objective function; and 3) high robustness to a newly identified concept drift in multilabel data streams, namely, changes in data distribution with labels (CDDL). The high robustness benefits from two novel works: 1) a new sequential update rule that preserves the labels ranking information learned from all old (but discarded) samples while updating the model only based on new incoming samples and 2) a fixed threshold for label bipartition that is insensitive to any kind of changes in data distribution including CDDL. The proposed method has been evaluated over 13 benchmark datasets from various domains. As shown in the experimental results, the proposed work is highly robust to CDDL in both the sequential model update and multilabel thresholding. Furthermore, the proposed method improves the performance in different evaluation measures, including Hamming loss, Fl-measure, Precision, and Recall while taking short training time on most evaluated datasets.																	2168-2267	2168-2275				JAN	2020	50	1					374	385		10.1109/TCYB.2018.2869476													
J								Products of Generalized Stochastic Matrices With Applications to Consensus Analysis in Networks of Multiagents With Delays	IEEE TRANSACTIONS ON CYBERNETICS										Consensus; generalized stochastic matrices; multiagent systems; negative coupling coefficients	EVENT-TRIGGERED CONSENSUS; SWITCHING TOPOLOGIES; BIPARTITE CONSENSUS; SYSTEMS; AGENTS; COORDINATION	Product theory of stochastic matrices provides a powerful tool in the consensus analysis of discrete-time multiagent systems. However, the classic theory cannot deal with networks with general coupling coefficients involving negative ones, which have been discussed only in very few papers due to the technicalities involved. Motivated by these works, here we developed some new results for the products of matrices which generalize that of the classical stochastic matrices by admitting negative entries. Particularly, we obtained a generalized version of the classic Hajnal inequality on this generalized matrix class. Based on these results, we proved some convergence results for a class of discrete-time consensus algorithms with time-varying delays and general coupling coefficients. At last, these results were applied to the analysis of a class of continuous-time consensus algorithms with discrete-time controller updates in the existence of communication/actuation delays.																	2168-2267	2168-2275				JAN	2020	50	1					386	399		10.1109/TCYB.2018.2868994													
J								Multimedia English teaching analysis based on deep learning speech enhancement algorithm and robust expression positioning	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Deep learning; multimedia english; emotion; expression recognition; feature recognition	FACE RECOGNITION; REPRESENTATION	In multimedia English teaching, learners face such an indifferent computer screen without emotion and feel the fun of interaction and emotional stimulation, which will cause resentment and affect the learner's learning effect. In order to improve the efficiency of multimedia English teaching, aiming at the lack of emotion in multimedia English education, this study proposes an intelligent network teaching system model based on deep learning speech enhancement and facial expression recognition. Moreover, this study uses emotional calculation as the theoretical basis and uses facial expression recognition as the core technology to judge and understand the emotional state by capturing and recognizing the facial expressions of online learners. In addition, this study has carried out experimental tests on the effect of the identification method of this paper and verified that the method has good detection effect on the real smile micro-expressions through two sets of experiments and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1779	1791		10.3233/JIFS-179951													
J								Network education platform in flipped classroom based on improved cloud computing and support vector machine	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Cloud computing; improved SVM algorithm; support vector; Network teaching; flipping classroom		The current online education platform has gradually replaced the traditional teaching mode and has become an efficient teaching method. Flipping classroom is a new teaching mode under the background of the rapid development of information technology. It is also an important way of multimedia network teaching. However, compared with the traditional teaching mode, teachers in the online teaching platform cannot judge the students' psychological activities through the students' state of mind, and they can grasp the students' learning status through the teaching process. Based on this, based on the cloud computing platform, this study improves the data transmission effect and improves the algorithm according to the learning process of the online education platform. Moreover, this study combines support vector machine to construct a student state recognition system suitable for online education platform and conducts algorithm performance analysis through experiments. In addition, this study uses MKmeans algorithm, Kmeans algorithm and improved Kmeans algorithm, that is, K-mediods and Xmeans algorithm to compare the pre-processed final data sets. The research results show that the proposed algorithm is suitable for network teaching platform and has certain practical effects.																	1064-1246	1875-8967					2020	39	2					1793	1803		10.3233/JIFS-179952													
J								Innovation of English teaching model based on machine learning neural network and image super resolution	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Machine learning; neural network; image super-resolution; english teaching; innovation		At present, applying image recognition technology to promote English teaching is a kind of teaching innovation that meets the needs of the times. Therefore, based on machine learning neural network and image super-resolution, this study conducted an innovative analysis of English teaching mode. This paper combined the current situation of English teaching classroom to study and analyze English classroom, combined classroom characteristics as the basis of English teaching innovation and constructed a feature recognition model suitable for current English teaching status. Moreover, this paper formed an initial high-resolution image for low-resolution image reconstruction by sparse representation method, and then established a mixed sample spine regression model to re-estimate the high-frequency components of the initial high-resolution image to realize various behavioral characteristics of students in English teaching classroom. In addition, this article builds a verification test. The research shows that the proposed algorithm has certain effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1805	1816		10.3233/JIFS-179953													
J								Performance appraisal of business administration based on artificial intelligence and convolutional neural network	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Artificial intelligence; convolutional neural network; business management; performance evaluation; simulation analysis		Performance appraisal in business administration has a great impact on social and economic development, so a sound performance appraisal system should be established. Moreover, in the information age, scientific methods are needed to improve business management performance. Based on this, this study links artificial intelligence with convolutional neural networks, and builds a corresponding performance research model based on actual conditions. When building the model, this paper selects the data width of 8Bit and 32 data per line, and shifts storage 2 rows, and sets the read/write enable signal to be half of the clock signal. In addition, the image matrix of the input image subjected to nonlinear processing by the excitation function ReLU will exhibit sparsity. Finally, combined with the model and data constructed in this study, the model is validated and the relevant strategies for performance evaluation are obtained.																	1064-1246	1875-8967					2020	39	2					1817	1829		10.3233/JIFS-179954													
J								Application of machine learning and cloud computing in social media behavior analysis	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Machine learning; cloud computting; microblogging; behavior analysis; user characteristics		It is of great theoretical significance and practical value to analyze the characteristics of users and behaviors in social networks, to study the personalized recommendation algorithms of users, to explore the inherent laws of event development, and to predict the movement of information or opinions. This paper analyzes the Weibo behavior through machine learning and cloud computing technology. Moreover, this paper studies and analyzes traditional network algorithms, and proposes a microblog recommendation algorithm based on statistical features. At the same time, the research content of this paper focuses on microblog contents, user characteristics, user preferences, and influence levels. The algorithm has simple structure and strong computing performance and performs feature data mining through cloud computing big data method, which is suitable for online mining microblog behavior. In addition, the performance of the algorithm was analyzed by design comparison experiments. The research indicates that the research algorithm proposed in this paper has certain advantages, which can be applied to network behavior analysis mining, and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1831	1842		10.3233/JIFS-179955													
J								Construction of science and technology achievement transfer and transformation platform based on deep learning and data mining technology	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Deep learning; data mining; transfer of scientific and technological achievements; convolutional neural network; system analysis		The transfer of scientific and technological achievements is an inevitable stage in the application of science and technology to the process of productivity. This process is accompanied by various influencing factors. How to eliminate the influence of adverse influence factors on the transformation of technology into productivity is crucial to the development of social productive forces. Based on this, from the perspective of deep learning, this study builds a technology transfer transformation platform through deep learning combined with data mining technology and analyzes the method in detail. On this basis, this paper takes a city as an example to analyze the platform of scientific and technological achievements transfer. In addition, by collecting existing data as system input and data mining analysis, this paper summarizes the advantages, disadvantages, opportunities and threats of the city's enterprises in the transformation of results and proposes corresponding countermeasures. The example verification shows that the method proposed in this study has certain practical effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1843	1854		10.3233/JIFS-179956													
J								Analysis of English teaching based on convolutional neural network and improved random forest algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Convolutional neural network; random forest; static image; English classroom; feature recognition	FACE RECOGNITION	At present, English teaching does not play the role of a smart classroom, and it is difficult to grasp the student status and characteristics in real time in actual teaching. Based on this, starting from the video image and static image and the actual situation of English classroom teaching, this study, based on the convolutional neural network and random forest algorithm, performs static image human behavior recognition under different image representation conditions, and studies the influence of background information of image and spatial distribution information of image features on recognition accuracy. Then, based on the similarity between different behavior classes, a static image human body behavior recognition method based on improved random forest is proposed. In addition, through theoretical research, an algorithm model that can identify the characteristics of English classrooms is constructed, and the static and dynamic images of English teaching are taken as an example to conduct experimental analysis. The research shows that the proposed method has certain effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1855	1865		10.3233/JIFS-179957													
J								Application of image content feature retrieval based on deep learning in sports public industry	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Deep learning; image content retrieval; feature extraction; sports industry; image feature analysis		The image content retrieval can effectively promote the development of the entire industry. At present, sports competition is becoming more and more fierce, and the requirements for image content retrieval are getting higher and higher. In this paper, research has been carried out on image descriptor generation, image feature quantization and coding, accurate nearest neighbor cluster center fast search, multi-dimensional inverted index construction and fast retrieval. Moreover, based on deep learning, this paper constructed an effective detection algorithm for the characteristics of sports images, and compared the image shape and color as examples. It can be seen from the comparative study that the research method of this paper can effectively reduce the size of the candidate set of query results without affecting the accuracy of the query, which is of great significance for improving the speed of image query and has certain significance for promoting the development of sports public industry.																	1064-1246	1875-8967					2020	39	2					1867	1877		10.3233/JIFS-179958													
J								Development of computer aided classroom teaching system based on machine learning prediction and artificial intelligence KNN algorithm	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Machine learning prediction; artificial intelligence; KNN algorithm; auxiliary teaching; feature recognition	LESSONS	With the continuous development of science and technology, computer-aided teaching has become a common mode of school teaching. From the current situation, it can be seen that the current computer-aided teaching mostly replaces the traditional teaching mode with multimedia, and does not play the role of functional teaching, and teachers cannot effectively grasp the students' psychological thoughts in teaching. Based on this, this study combines machine learning prediction and artificial intelligence KNN algorithm to actual teaching. Moreover, this study collects video and instructional images for student feature behavior recognition, and distinguishes individual features from group feature recognition, and can detect student expression recognition in detail. In addition, this study designed a case study to analyze the performance of the algorithm. From the experimental results, it can be seen that the proposed algorithm has certain effects and can be used as an algorithm to assist the teaching process and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1879	1890		10.3233/JIFS-179959													
J								Analysis of the characteristics of English part of speech based on unsupervised machine learning and image recognition model	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Unsupervised learning; image recognition; feature recognition; English recognition; characteristic analysis	IDENTIFICATION	If there are more external interference factors in the process of intelligent recognition in English, the recognition accuracy will be greatly reduced. It is of great academic value and application significance to deeply study feature recognition of English part-of-speech and realize automatic image processing of English recognition. Based on unsupervised machine learning and image recognition technology, this study combines the actual factors of English recognition to set the corresponding influencing factors and proposes a reliable method to identify multi-body rotating characters. This method utilizes the principle of the periodic characteristics of the trajectory rotation on the feature space. Moreover, this study conducts a comparative analysis of recognition accuracy by comparative experiments. In addition, this paper analyzes the recognition principles of 4 fonts in detail. The research results show that the proposed method has certain effects and can provide theoretical reference for subsequent related research.																	1064-1246	1875-8967					2020	39	2					1891	1901		10.3233/JIFS-179960													
J								Analysis of task degree of English learning based on deep learning framework and image target recognition	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Deep learning; task degree; learning feature recognition; english classroom; score	FACE RECOGNITION; REPRESENTATION	Task degree has become one of the important indicators to measure students' English learning intensity and learning quality, and the difference in task degree has different effects on students' English learning. In order to realize the task recognition of English classroom teaching, combined with the characteristics of deep learning, this study combines the actual situation of English classroom teaching to analyze, and distinguishes characters through student positioning and feature recognition. Moreover, this paper combines the characteristics of English learning scoring to judge students' learning situation, and designs a shallow convolutional neural network based on TensorFlow architecture for identifying images and uses GPU training acceleration to solve the problem of training time-consuming in the face of large data volume. In addition, the task results feedback is evaluated by scoring method, and the performance of the algorithm is analyzed by experiments. By setting the category of sensitive targets, this paper can perceive the results according to the target location and mark the sensitive targets in the input scene image. The research results show that the method proposed in this paper has certain effects.																	1064-1246	1875-8967					2020	39	2					1903	1914		10.3233/JIFS-179961													
J								Application of MapReduce parallel association mining on IDS in cloud computing environment	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Cloud computing; intrusion detection; association rule data mining; Apriori; Hadoop; MapReduce; parallelization	BIG DATA; SECURITY; STORAGE; HADOOP	The rise of the cloud computing model has resulted in more than terabytes of data being stored in the cloud platform every day on the Internet. Mining valuable information from these massive data has become an emerging industry direction, but the current Intrusion-detection system (IDS) has been unable to adapt to large-scale log information mining. Therefore, an association rule mining algorithm based on MapReduce parallel computing framework is proposed. Firstly, the frequent itemsets mining algorithm Apriori is analyzed, and the MapReduce model is used to parallelize and improve it to more efficiently complete the mining of frequent itemsets. Secondly, the parallel Apriori is designed to run on IDS. Finally, the simulation experiment was carried out by building an open source cloud computing framework Hadoop cluster. Finally, the simulation experiment was carried out by building an open source cloud computing framework Hadoop cluster. The results show that the proposed method has higher detection efficiency when processing massive data, and requires less processing time.																	1064-1246	1875-8967					2020	39	2					1915	1923		10.3233/JIFS-179962													
J								Recognize basic emotional statesin speech by machine learning techniques using mel-frequency cepstral coefficient features	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Emotion recognition; back propagation neural network; extreme learning machine; Mel-frequency cepstral coefficients; smart home; support vector machine	SYSTEM; IMPLEMENTATION; EXTRACTION; NETWORKS; TRACKING	Speech Emotion Recognition (SER) has been widely used in many fields, such as smart home assistants commonly found in the market. Smart home assistants that could detect the user's emotion would improve the communication between a user and the assistant enabling the assistant to offer more productive feedback. Thus, the aim of this work is to analyze emotional states in speech and propose a suitable algorithm considering performance verses complexity for deployment in smart home devices. The four emotional speech sets were selected from the Berlin Emotional Database (EMO-DB) as experimental data, 26 MFCC features were extracted from each type of emotional speech to identify the emotions of happiness, anger, sadness and neutrality. Then, speaker-independent experiments for our Speech emotion Recognition (SER) were conducted by using the Back Propagation Neural Network (BPNN), Extreme Learning Machine (ELM), Probabilistic Neural Network (PNN) and Support Vector Machine (SVM). Synthesizing the recognition accuracy and processing time, this work shows that the performance of SVM was the best among the four methods as a good candidate to be deployed for SER in smart home devices. SVM achieved an overall accuracy of 92.4% while offering low computational requirements when training and testing. We conclude that the MFCC features and the SVM classification models used in speaker-independent experiments are highly effective in the automatic prediction of emotion.																	1064-1246	1875-8967					2020	39	2					1925	1936		10.3233/JIFS-179963													
J								Scale design of opinion leaders' impact on online consumers' purchasing intention	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Opinion leader; purchase intention; scale design; questionnaire	WORD-OF-MOUTH; PERCEIVED VALUE; PRODUCT; MODEL	With the promotion of opinion leader's impact on online purchase intention, the problem of how to measure the characteristics of opinion leader, the characteristics of opinion leader's recommendation information and the influence of consumers' characteristics on purchase intention is becoming more and more urgent. Based on numbers of popular scales, this paper designs the questionnaire items for the variables of professional knowledge, product involvement, visual cues, interactivity, functional value and trust involved in the opinion leader influence model, and forms the initial scale. On this basis, with the help of small-scale interviews, small sample pre-test and large sample test, trust and purchase intention fail to pass the validity test. Through correlation coefficient analysis, some questions with lower coefficient value are eliminated, and then the final scale with good reliability and validity is obtained.																	1064-1246	1875-8967					2020	39	2					1937	1949		10.3233/JIFS-179964													
J								Optimization of parallel random forest algorithm based on distance weight	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Distance weights; parallel algorithm; random forest algorithm; algorithm optimization		In order to overcome the problems of long execution time and low parallelism of existing parallel random forest algorithms, an optimization method for parallel random forest algorithm based on distance weights is proposed. The concept of distance weights is introduced to optimize the algorithm. Firstly, the training sample data are extracted from the original data set by random selection. Based on the extracted results, a single decision tree is constructed. The single decision tree is grouped together according to different grouping methods to form a random forest. The distance weights of the training sample data set are calculated, and then the weighted optimization of the random forest model is realized. The experimental results show that the execution time of the parallel random forest algorithm after optimization is 110 000 ms less than that before optimization, and the operation efficiency of the algorithm is greatly improved, which effectively solves the problems existing in the traditional random forest algorithm.																	1064-1246	1875-8967					2020	39	2					1951	1963		10.3233/JIFS-179965													
J								Optimization of architectural art teaching model based on Naive Bayesian classification algorithm and fuzzy model	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS										Bayesian classification algorithm; fuzzy model; architectural art; differential evolution algorithm	ENERGY SIMULATION	At present, the teaching of architectural art in China is still relatively traditional, and there are still some problems in the actual teaching. Based on this, this study combines the Naive Bayesian classification algorithm with the fuzzy model to construct a new architectural art teaching model. In teaching, the Naive Bayesian classification algorithm generates only a small number of features for each item in the training set, and it only uses the probability calculated in the mathematical operation to train and classify the item. Moreover, by combining the fuzzy model, the materials needed for architectural art teaching can be quickly generated, and the teaching principles and implementation strategies of architectural art are summarized. In addition, this paper proposes an attribute weighted classification algorithm combining differential evolution algorithm with Naive Bayes. The algorithm assigns weights to each attribute based on the Naive Bayesian classification algorithm and uses differential evolution algorithm to optimize the weights. The research shows that the method proposed in this paper has certain effect on the optimization of architectural art teaching mode.																	1064-1246	1875-8967					2020	39	2					1965	1976		10.3233/JIFS-179966													
J								Dynamic Feature Integration for Simultaneous Detection of Salient Object, Edge, and Skeleton	IEEE TRANSACTIONS ON IMAGE PROCESSING										Task analysis; Feature extraction; Skeleton; Image edge detection; Object segmentation; Logic gates; Mobile handsets; Salient object segmentation; edge detection; skeleton extraction; joint learning	IMAGE SEGMENTATION; BOUNDARIES	Salient object segmentation, edge detection, and skeleton extraction are three contrasting low-level pixel-wise vision problems, where existing works mostly focused on designing tailored methods for each individual task. However, it is inconvenient and inefficient to store a pre-trained model for each task and perform multiple different tasks in sequence. There are methods that solve specific related tasks jointly but require datasets with different types of annotations supported at the same time. In this article, we first show some similarities shared by these tasks and then demonstrate how they can be leveraged for developing a unified framework that can be trained end-to-end. In particular, we introduce a selective integration module that allows each task to dynamically choose features at different levels from the shared backbone based on its own characteristics. Furthermore, we design a task-adaptive attention module, aiming at intelligently allocating information for different tasks according to the image content priors. To evaluate the performance of our proposed network on these tasks, we conduct exhaustive experiments on multiple representative datasets. We will show that though these tasks are naturally quite different, our network can work well on all of them and even perform better than current single-purpose state-of-the-art methods. In addition, we also conduct adequate ablation analyses that provide a full understanding of the design principles of the proposed framework.																	1057-7149	1941-0042					2020	29						8652	8667		10.1109/TIP.2020.3017352													
J								An alpha-Matte Boundary Defocus Model-Based Cascaded Network for Multi-Focus Image Fusion	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image fusion; multi-focus; CNNs; defocus model	ENHANCEMENT	Capturing an all-in-focus image with a single camera is difficult since the depth of field of the camera is usually limited. An alternative method to obtain the all-in-focus image is to fuse several images that are focused at different depths. However, existing multi-focus image fusion methods cannot obtain clear results for areas near the focused/defocused boundary (FDB). In this article, a novel alpha-matte boundary defocus model is proposed to generate realistic training data with the defocus spread effect precisely modeled, especially for areas near the FDB. Based on this alpha-matte defocus model and the generated data, a cascaded boundary-aware convolutional network termed MMF-Net is proposed and trained, aiming to achieve clearer fusion results around the FDB. Specifically, the MMF-Net consists of two cascaded subnets for initial fusion and boundary fusion. These two subnets are designed to first obtain a guidance map of FDB and then refine the fusion near the FDB. Experiments demonstrate that with the help of the new alpha-matte boundary defocus model, the proposed MMF-Net outperforms the state-of-the-art methods both qualitatively and quantitatively.																	1057-7149	1941-0042					2020	29						8668	8679		10.1109/TIP.2020.3018261													
J								Video Coding for Machines: A Paradigm of Collaborative Compression and Intelligent Analytics	IEEE TRANSACTIONS ON IMAGE PROCESSING										Image coding; Video coding; Machine learning; Visualization; Encoding; Collaboration; Transform coding; Video coding for machine; video compression; feature compression; generative model; prediction model	RECURRENT NEURAL-NETWORK; RECOGNITION; SELECTION; FEATURES	Video coding, which targets to compress and reconstruct the whole frame, and feature compression, which only preserves and transmits the most critical information, stand at two ends of the scale. That is, one is with compactness and efficiency to serve for machine vision, and the other is with full fidelity, bowing to human perception. The recent endeavors in imminent trends of video compression, e.g. deep learning based coding tools and end-to-end image/video coding, and MPEG-7 compact feature descriptor standards, i.e. Compact Descriptors for Visual Search and Compact Descriptors for Video Analysis, promote the sustainable and fast development in their own directions, respectively. In this article, thanks to booming AI technology, e.g. prediction and generation models, we carry out exploration in the new area, Video Coding for Machines (VCM), arising from the emerging MPEG standardization efforts. (1) Towards collaborative compression and intelligent analytics, VCM attempts to bridge the gap between feature coding for machine vision and video coding for human vision. Aligning with the rising Analyze then Compress instance Digital Retina, the definition, formulation, and paradigm of VCM are given first. Meanwhile, we systematically review state-of-the-art techniques in video compression and feature compression from the unique perspective of MPEG standardization, which provides the academic and industrial evidence to realize the collaborative compression of video and feature streams in a broad range of AI applications. Finally, we come up with potential VCM solutions, and the preliminary results have demonstrated the performance and efficiency gains. Further direction is discussed as well. (1) https://lists.aau.at/mailman/listinfo/mpeg-vcm																	1057-7149	1941-0042					2020	29						8680	8695		10.1109/TIP.2020.3016485													
J								Self-Supervised Learning of Detailed 3D Face Reconstruction	IEEE TRANSACTIONS ON IMAGE PROCESSING										Face; Three-dimensional displays; Solid modeling; Image reconstruction; Computational modeling; Training; Supervised learning; 3D face reconstruction; self-supervised learning; depth displacement; coarse-to-fine model		In this article, we present an end-to-end learning framework for detailed 3D face reconstruction from a single image. Our approach uses a 3DMM-based coarse model and a displacement map in UV-space to represent a 3D face. Unlike previous work addressing the problem, our learning framework does not require supervision of surrogate ground-truth 3D models computed with traditional approaches. Instead, we utilize the input image itself as supervision during learning. In the first stage, we combine a photometric loss and a facial perceptual loss between the input face and the rendered face, to regress a 3DMM-based coarse model. In the second stage, both the input image and the regressed texture of the coarse model are unwrapped into UV-space, and then sent through an image-to-image translation network to predict a displacement map in UV-space. The displacement map and the coarse model are used to render a final detailed face, which again can be compared with the original input image to serve as a photometric loss for the second stage. The advantage of learning displacement map in UV-space is that face alignment can be explicitly done during the unwrapping, thus facial details are easier to learn from large amount of data. Extensive experiments demonstrate the superiority of our method over previous work.																	1057-7149	1941-0042					2020	29						8696	8705		10.1109/TIP.2020.3017347													
J								RPD-GAN: Learning to Draw Realistic Paintings With Generative Adversarial Network	IEEE TRANSACTIONS ON IMAGE PROCESSING										Painting; Gallium nitride; Feature extraction; Generative adversarial networks; Task analysis; Generators; Semantics; Style transfer; generative adversarial networks; image-to-image transformation		Painting style transfer is an attractive and challenging computer vision problem that aims to transfer painting styles onto natural images. Existing advanced methods tackle this problem from the perspective of Neural Style Transfer (NST) or unsupervised cross-domain image translation. For both two types of methods, attention has been focused on reproducing artistic painting styles of representative artists (e.g., Vincent Van Gogh). In this article, instead of transferring styles of artistic paintings, we focus on automatic generation of realistic paintings, for example, making the machine draw a gouache before a still life, paint a sketch of a landscape, or draw a pen-and-ink portrait of a person, etc. Besides capturing the precise target styles, synthesis of realistic paintings is more demanding in preserving original content features and image structures, for which existing advanced methods are not sufficient to generate satisfactory results. Aimed at this problem, we propose RPD-GAN (Realistic Painting Drawing Generative Adversarial Network), an unsupervised cross-domain image translation framework for realistic painting style transfer. At the heart of our model is the decomposition of the image stylization mapping into four stages: feature encoding, feature de-stylization, feature re-stylization, and feature decoding, where the functionalities of these stages are implemented by additionally embedding a content-consistency constraint and a style-alignment constraint at feature space to the classic CycleGAN architecture. By enforcing these constraints, both the content-preserving and style-capturing capabilities of the model are enhanced, leading to higher-quality stylization results. Extensive experiments demonstrate the effectiveness and superiority of our RPD-GAN in drawing realistic paintings.																	1057-7149	1941-0042					2020	29						8706	8720		10.1109/TIP.2020.3018856													
J								Reconstructing 3D Shapes From Multiple Sketches Using Direct Shape Optimization	IEEE TRANSACTIONS ON IMAGE PROCESSING										Shape; Three-dimensional displays; Image reconstruction; Solid modeling; Machine learning; Geometry; Optimization; 3D shape reconstruction; sketches; multiple angles; voxels; optimization	FEATURES	3D shape reconstruction from multiple hand-drawn sketches is an intriguing way to 3D shape modeling. Currently, state-of-the-art methods employ neural networks to learn a mapping from multiple sketches from arbitrary view angles to a 3D voxel grid. Because of the cubic complexity of 3D voxel grids, however, neural networks are hard to train and limited to low resolution reconstructions, which leads to a lack of geometric detail and low accuracy. To resolve this issue, we propose to reconstruct 3D shapes from multiple sketches using direct shape optimization (DSO), which does not involve deep learning models for direct voxel-based 3D shape generation. Specifically, we first leverage a conditional generative adversarial network (CGAN) to translate each sketch into an attenuance image that captures the predicted geometry from a given viewpoint. Then, DSO minimizes a project-and-compare loss to reconstruct the 3D shape such that it matches the predicted attenuance images from the view angles of all input sketches. Based on this, we further propose a progressive update approach to handle inconsistencies among a few hand-drawn sketches for the same 3D shape. Our experimental results show that our method significantly outperforms the state-of-the-art methods under widely used benchmarks and produces intuitive results in an interactive application.																	1057-7149	1941-0042					2020	29						8721	8734		10.1109/TIP.2020.3018865													
J								Multilevel Optimization for Registration of Deformable Point Clouds	IEEE TRANSACTIONS ON IMAGE PROCESSING										Strain; Three-dimensional displays; Geometry; Shape; Deformable models; Optimization; Iterative closest point algorithm; Deformable registration; quaternion; gauss-newton; nonlinear least squares; Gaussian mixture model; expectation maximization	SET REGISTRATION; TRANSFORMATION; ALGORITHM; MODEL	Handling deformation is one of the biggest challenges associated with point cloud registration. When deformation happens due to the motion of an animated object which actively changes its location and general shape, registration of two instances of the same object turns out to be a challenging task. The focus of this work is to address the problem by leveraging the complementary attributes of local and global geometric structures of the point clouds. We define an energy function which consists of local and global terms, as well as a semi-local term to model the intermediate level geometry of the point cloud. The local energy estimates the transformation parameters at the lowest level by assuming a reduced deformation model. The parameters are estimated in a closed form solution, which are then used to assign the initial probability of a stochastic model working at the intermediate level. The global energy term estimates the overall transformation parameters by minimizing a nonlinear least square function via Gauss-Newton optimization framework. The total energy is optimized in a block coordinate descent fashion, updating one term at a time while keeping others constant. Experiments on three publicly available datasets show that the method performs significantly better than several state-of-the-art algorithms in registering pairwise point cloud data.																	1057-7149	1941-0042					2020	29						8735	8746		10.1109/TIP.2020.3019649													
J								Revealing the Invisible With Model and Data Shrinking for Composite-Database Micro-Expression Recognition	IEEE TRANSACTIONS ON IMAGE PROCESSING										Task analysis; Data models; Complexity theory; Feature extraction; Analytical models; Histograms; Optical imaging; Micro-expression recognition; composite database; recurrent convolutional network; model and data shrinking; parameter-free module; searchable architecture		Composite-database micro-expression recognition is attracting increasing attention as it is more practical for real-world applications. Though the composite database provides more sample diversity for learning good representation models, the important subtle dynamics are prone to disappearing in the domain shift such that the models greatly degrade their performance, especially for deep models. In this article, we analyze the influence of learning complexity, including input complexity and model complexity, and discover that the lower-resolution input data and shallower-architecture model are helpful to ease the degradation of deep models in composite-database task. Based on this, we propose a recurrent convolutional network (RCN) to explore the shallower-architecture and lower-resolution input data, shrinking model and input complexities simultaneously. Furthermore, we develop three parameter-free modules (i.e., wide expansion, shortcut connection and attention unit) to integrate with RCN without increasing any learnable parameters. These three modules can enhance the representation ability in various perspectives while preserving not-very-deep architecture for lower-resolution data. Besides, three modules can further be combined by an automatic strategy (a neural architecture search strategy) and the searched architecture becomes more robust. Extensive experiments on the MEGC2019 dataset (composited of existing SMIC, CASME II and SAMM datasets) have verified the influence of learning complexity and shown that RCNs with three modules and the searched combination outperform the state-of-the-art approaches.																	1057-7149	1941-0042					2020	29						8590	8605		10.1109/TIP.2020.3018222													
J								Object Discovery From a Single Unlabeled Image by Mining Frequent Itemsets With Multi-Scale Features	IEEE TRANSACTIONS ON IMAGE PROCESSING										Object discovery; pattern mining; convolutional neural networks	SALIENT REGION DETECTION; MODEL	The goal of our work is to discover dominant objects in a very general setting where only a single unlabeled image is given. This is far more challenge than typical co-localization or weakly-supervised localization tasks. To tackle this problem, we propose a simple but effective pattern mining-based method, called Object Location Mining (OLM), which exploits the advantages of data mining and feature representation of pre-trained convolutional neural networks (CNNs). Specifically, we first convert the feature maps from a pre-trained CNN model into a set of transactions, and then discovers frequent patterns from transaction database through pattern mining techniques. We observe that those discovered patterns, i.e., co-occurrence highlighted regions, typically hold appearance and spatial consistency. Motivated by this observation, we can easily discover and localize possible objects by merging relevant meaningful patterns. Extensive experiments on a variety of benchmarks demonstrate that OLM achieves competitive localization performance compared with the state-of-the-art methods. We also evaluate our approach compared with unsupervised saliency detection methods and achieves competitive results on seven benchmark datasets. Moreover, we conduct experiments on fine-grained classification to show that our proposed method can locate the entire object and parts accurately, which can benefit to improving the classification results significantly.																	1057-7149	1941-0042					2020	29						8606	8621		10.1109/TIP.2020.3015543													
J								Deep Spatial Transformation for Pose-Guided Person Image Generation and Animation	IEEE TRANSACTIONS ON IMAGE PROCESSING										Task analysis; Animation; Image generation; Transforms; Videos; Strain; Feature extraction; Image spatial transformation; image animation; pose-guided image generation		Pose-guided person image generation and animation aim to transform a source person image to target poses. These tasks require spatial manipulation of source data. However, Convolutional Neural Networks are limited by the lack of ability to spatially transform the inputs. In this article, we propose a differentiable global-flow local-attention framework to reassemble the inputs at the feature level. This framework first estimates global flow fields between sources and targets. Then, corresponding local source feature patches are sampled with content-aware local attention coefficients. We show that our framework can spatially transform the inputs in an efficient manner. Meanwhile, we further model the temporal consistency for the person image animation task to generate coherent videos. The experiment results of both image generation and animation tasks demonstrate the superiority of our model. Besides, additional results of novel view synthesis and face image animation show that our model is applicable to other tasks requiring spatial transformation. The source code of our project is available at https://github.com/RenYurui/Global-Flow-Local-Attention.																	1057-7149	1941-0042					2020	29						8622	8635		10.1109/TIP.2020.3018224													
J								Screen Content Video Quality Assessment: Subjective and Objective Study	IEEE TRANSACTIONS ON IMAGE PROCESSING										Quality assessment; Databases; Spatiotemporal phenomena; Video recording; Distortion; Image edge detection; Tensile stress; Screen content videos (SCVs); video quality assessment (VQA); subjective assessment; objective measurement; spatiotemporal feature tensor	NATURAL SCENE; IMAGE; SIMILARITY; SELECTIVITY	In this article, we make the first attempt to study the subjective and objective quality assessment for the screen content videos (SCVs). For that, we construct the first large-scale video quality assessment (VQA) database specifically for the SCVs, called the screen content video database (SCVD). This SCVD provides 16 reference SCVs, 800 distorted SCVs, and their corresponding subjective scores, and it is made publicly available for research usage. The distorted SCVs are generated from each reference SCV with 10 distortion types and 5 degradation levels for each distortion type. Each distorted SCV is rated by at least 32 subjects in the subjective test. Furthermore, we propose the first full-reference VQA model for the SCVs, called the spatiotemporal Gabor feature tensor-based model (SGFTM), to objectively evaluate the perceptual quality of the distorted SCVs. This is motivated by the observation that 3D-Gabor filter can well stimulate the visual functions of the human visual system (HVS) on perceiving videos, being more sensitive to the edge and motion information that are often-encountered in the SCVs. Specifically, the proposed SGFTM exploits 3D-Gabor filter to individually extract the spatiotemporal Gabor feature tensors from the reference and distorted SCVs, followed by measuring their similarities and later combining them together through the developed spatiotemporal feature tensor pooling strategy to obtain the final SGFTM score. Experimental results on SCVD have shown that the proposed SGFTM yields a high consistency on the subjective perception of SCV quality and consistently outperforms multiple classical and state-of-the-art image/video quality assessment models.																	1057-7149	1941-0042					2020	29						8636	8651		10.1109/TIP.2020.3018256													
J								Point at the Triple: Generation of Text Summaries from Knowledge Base Triples	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH											CONTEXT	We investigate the problem of generating natural language summaries from knowledge base triples. Our approach is based on a pointer-generator network, which, in addition to generating regular words from a fixed target vocabulary, is able to verbalise triples in several ways. We undertake an automatic and a human evaluation on single and open-domain summaries generation tasks. Both show that our approach significantly outperforms other data-driven baselines.																	1076-9757	1943-5037					2020	69						1	31															
J								Constraint and Satisfiability Reasoning for Graph Coloring	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH											ALGORITHM	Graph coloring is an important problem in combinatorial optimization and a major component of numerous allocation and scheduling problems. In this paper we introduce a hybrid CP/SAT approach to graph coloring based on the addition-contraction recurrence of Zykov. Decisions correspond to either adding an edge between two non-adjacent vertices or contracting these two vertices, hence enforcing inequality or equality, respectively. This scheme yields a symmetry-free tree and makes learnt clauses stronger by not committing to a particular color. We introduce a new lower bound for this problem based on Mycielskian graphs; a method to produce a clausal explanation of this bound for use in a CDCL algorithm; a branching heuristic emulating Brelaz' heuristic on the Zykov tree; and dedicated pruning techniques relying on marginal costs with respect to the bound and on reasoning about transitivity when unit propagating learnt clauses. The combination of these techniques in both a branch-and-bound and in a bottom-up search outperforms other SAT-based approaches and Dsatur on standard benchmarks both for finding upper bounds and for proving lower bounds.																	1076-9757	1943-5037					2020	69						33	65		10.1613/jair.1.11313													
J								Synchronization of Delayed Inertial Cohen-Grossberg Neural Networks Under Adaptive Feedback Controller	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										CGNNs; Adaptive synchrenization; Inertial term; Time varying delay	MATRIX MEASURE STRATEGIES; EXPONENTIAL SYNCHRONIZATION; PERIODIC-SOLUTIONS; STABILITY; PARAMETERS; LAG	This paper inaestigates the uadaptive synchronization of delayed inertial Cohen-Grossberg neural networks (ICGN By adopting the method of variable transformation, the addressed model, which includes the so-called inertial term, is trails formed into first-order differential equations. On the basis of the well-known invariant principle of functional differential equations, a novel and analytic scheme Which ensures the adaptive synchronization between the drive-response system is proposed in component form. It is worth mentioning that we only need to impose one controller to the spilt systems to realize the adaptive synchronization, which is of less conservgism. At the end of this paper, a numerical example is provided to verify the feasibility of the derived theoretical results. The established figures validate that the numerical simulations coincide well with the developed theoretical results. (C) 2020 The Authors. Published by Atlantic Press SARL.																	1875-6891	1875-6883					2020	13	1					472	478		10.2991/ijcis.d.200402.001													
J								Online Streaming Feature Selection via Multi-Conditional Independence and Mutual Information Entropy	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Streaming feature; Feature selection; Conditional independence; Mutual information		The goals of feature selection are to remove redundant and irrelevant features from high-dimensional data, extract the 'optimal feature subset" of the original feature space to improve the classification accuracy, and reduce the time complexity. Traditional feature selection algorithms are based on static feature spaces that are difficult to apply in dynamic streaming data environments. Existing works, such as Alpha-investing and Online Streaming Feature Selection (OSFS), and Scalable and Accurate OnLine Approach (SAOLA), have been proposed to serve the feature selection with streaming feature, but they have drawbacks, including low prediction accuracy and a large number of selected features if the streaming features exhibit characteristics such as low redundancy and high relevance. To address the limitations of the abovementioned Works we propose the algorithm of Online Streaming Feature Selection via Conditional dependence and Mutual information (OSFSCM) for streaming feature, which is found to be superior to Alpha-investing and OSFS for datasets with low redundancy and high relevance. The efficiency of the proposed OSFSCM algorithm is validated through a performance test on widely used datasets, e.g., NIPS 2003 and Causality Workbench. Through extensive experimental results, we demonstrate that OSESCAM significantly improves the prediction accuracy and requires fewer selected features compared with Alpha-investing and OSFS. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					479	487		10.2991/ijcis.d.200423.002													
J								Supervised Filter Learning for Coronary Artery Vesselness Enhancement Diffusion in Coronary CT Angiography Images	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Computed tomography angiography; Coronary artery filtering; Vesseiness enhancement; Machine learning; Vessel segmentation		In medical imaging, vesselness diffusion is usually performed to enhance the vessel structures of interest and reduce background noises, before vessel segmentation and analysis. Numerous learning-based techniques have recently. become very popular for coronary artery filtering due to their impressive results. In this work, a supervised machine leaning method for coronary artery vesselness diffusion with high accuracy and minimal user interaction is designed. The fully discriminative filter learning method jointly learning a classifier the weak learners rely on and the features of the classifier is developed. Experimental results demonstrate that this scheme achieves good isotropic filtering performances on both synthetic and real patient. Coronary Conlputed Tomography Angiography (CCTA) datasets. Furthermore, region gmwing-based segmentation approach is performed over filtered images obtained by using different schemes. The proposed diffusion scheme is able to achieve higher average pertbrmance measures (87.8% +/- 1.5% for Dice, 86.5% +/- 1.3% for Precision and 88.5% +/- 2.6% for Sensitivity). In conclusion, the devekiped diffusion method is capable of filtering coronary artery structures and suppressing nonvessel tissues, and cm be further used in clinical practice as eal-time CCTA images preprocessiiv tool. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					488	495		10.2991/ijcis.d.200422.001													
J								Enhancing of Artificial Bee Colony Algorithm for Virtual Machine Scheduling and Load Balancing Problem in Cloud Computing	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Artificial bee colony algorithm; Cloud computing; Scheduling algorithms; Load balance; Resource management; Distribution	GENETIC ALGORITHM; ENVIRONMENTS	This paper proposes the combination of Swann Intelligence algorithm ofartific a! her colony caalh heuristic scheduling algorithm, called Heuristic `task Scheduling with Artificial lice Colony (UMW). This algorithm is applied to improve virtual machines scheduling solution for cloud computing within homogeneous and heterogeneous environments. It was introduced to minimize makespan and balance the loads. The scheduling performance of the cloud computing system With HABC was compared to that supplemented with other swarm intelligence algorithms: Ant Colony Optimization (ACO) with standard heuristic algorithm, Particle Swarm Optimization (PSO) with standard heuristic algorithm and improved PSO (IPSO) with standard heuristic algorithm. In our experiments, CloudSim was used to simulate systems that used different supplementing algorithms for the purpose of comparing their makespan and load balancing capability. The experimental results can he concluded that virtual machine scheduling management with artificial bee colony algorithm and largest job first (HABC_LJT) outperformed those with ACO, PSO, and IPSO. (C) 2020 The Authors. Published by Atlantis Press SARI.																	1875-6891	1875-6883					2020	13	1					496	510		10.2991/ijeis.d.200110.003													
J								A Novel Cause-Effect Variable Analysis in Enterprise Architecture by Fuzzy Logic Techniques	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Decision-making; Formal analysis of rules; Enterprise architecture; Fuzzy relation equations; Fuzzy sets	BUSINESS; SYSTEMS	In this paper, or present a new integration approach for managing Information Technology variables within enterprise architecture in an integrated way. Additionially, a novel method based on fuzzy logic for cause-effect variable analysis is proposed as a useful support decision-making tool for companies in order to lmow the main actions they must perform for increasing their benefits. This is employed to assess the Integration Management System in Enterprises, based on Enterprise Architecture and Information Technology. We show as fuzzy logic plays an important role M this area due to these variables can be affected for multifactorial elements iinpregnated with uncertainty. The knowledge given by the experts is translated into dependence rules, Which have also been analyzed from a fuzzy point of view using a combination of two fuzzy techniques, namely, fuzzy relation equation theory and fuzzy graph. Firstly, fuzzy dependence rules are computed froth fuzzy relation equations and, secondly an analysis based on incidence subgraph is performed. The resulLisa strategic plan automatically generated from the data captured of each enterprise in which the most import variables to be improved are detailed. (C) 2020 The Authors. Published by Atlantis Press SARI..																	1875-6891	1875-6883					2020	13	1					511	523		10.2991/ijcis.d.200415.001													
J								A Decomposition-Based Multiobjective Chemical Reaction Optimization Algorithm for Community Detection in Complex Networks	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Multiobjective optianizatton; Chemical reaction optimization; Community detection; Complex network	PARTICLE SWARM OPTIMIZATION; EVOLUTIONARY ALGORITHM; GENETIC ALGORITHM; TIME	Community detection structure is very important for understanding the organization of the complex networks. This problem is NP-hard, which is modeled as a seriously nonlinear optimization problem. Recently, different intelligence algorithm has shown promising results for this problem. The chemical reaction optimization (CRO) algorithm is a novel evolutionary algorithm which mimics the phenommon of interactions among molecules in a container. The one characteristic of CRO is that the size of the population is changing. In this paper, we redefined the operator of CRC), and using the method of multiobjective decomposition decomposed the conununity detection problem into a scalar of sub-problems and using the proposed a discrete variant of CRO (MODCRO) to optimization. In the proposed method, neighbor-based turbulence of on-wall ineffective collision operator and decomposition operator are redefined which is responsible for searching local exploitation ability of algorithm, and the intermolecular ineffective collisions operator and synthesis operator is also redesigned which is responsible for searching global exploration ability of algorithm. Experimental results clearly demonstrate that the proposed algorithm outperforms a number of state-of-the-art multiobjective optimization evolutionary algorithms (MORAs) on modularity. (C) 2020 The Authors. Published by Atlantis Press SARI.																	1875-6891	1875-6883					2020	13	1					524	537		10.2991/ijcis.d.200413.001													
J								Bi-GRU Sentiment Classification for Chinese Based on Grammar Rules and BERT	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Sentiment classification; Grammar rules; BERT; Bi-GR11		Sentiment classification is a fundamental task in NIT, and its aim to predict the se sin polarities of the given texts. Recent researches show great interest in modeling Chinese sentiment classification. However, the complexity of Chinese grammar makes the performance of the exist ng Chinese set ii classification model not perforns well. In order to address the above problem, we propose a sentiment classification met sod based on grammar rules and bidirectional encoder representation from transformers (BERT). We first preprocess data tlirough URI' model. Then we conibine the Chinese grammar ides with Bi-gated recurrent neural network (GRU) in the form of constraints, and simulate the linguistic functions at the sentence by standardizing the output of adjacent positions. Extensive experiments on two public dalasels demonstrate the effectiveness of our pmposed method, and our findings in the experiment provide new insights for the future development of Chinese sentiment classification. (C) 2020 The Authors. Published by Atlantis Press SARI.																	1875-6891	1875-6883					2020	13	1					538	548		10.2991/ijcis.d.200423.001													
J								A Fuzzy Framework to Evaluate Players' Performance in Handball	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Group decision-making; Handball player evaluation; Rating system; Aggregation operators; Linguistic model		The evaluation of the players' performance in sports teams is commonly based on the opinion of experts who do not always agree on the importance of the chosen indicators. This paper presents a novel approach based on fuzzy multi-criteria group decision-making tools for selecting those criteria that best represent the handball player's performance in a match and for setting their relevance weights. Our approach consists of a fuzzy model to aggregate expert judgments. This methodology overcomes some drawbacks of classical systems including the definition of the relevance of each criteria using linguistic labels. A preliminary evaluation analyzes handball players' performance indicators and their application to a short tournament. Considering the obtained results, we can conclude that the proposal is relevant and provides useful insights regarding player performance in different matches. The proposed methodology has also been compared with a basic plus-minus rating methodology. This comparison illustrates the feasibility of our approach. Results suggest that plus-minus rating is not the best solution to represent the performance of specialized players who only play When their leans attack or defense. Our approach demonstrates being more appropriate for sports such as handball because it includes the valuation of a full set of positive actions in defense and attack. (C) 2020 The AuthorsPublished by Atlantis Press SARI.																	1875-6891	1875-6883					2020	13	1					549	558		10.2991/ijcis.d.200416.001													
J								Vegetable Recognition and Classification Based on Improved VGG Deep Learning Network Model	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Vegetable recognition and classification; Deep learning; VGG-nets Framework of Gaffe	FRUIT	To improve the accuracy of automaticn and classification of vegetables, this paper presents a method of recognition and classification of vegetable image based on deep learning, using the open source deep learning framework of Gaffe, the improved VGG network model was used to train the vegetable image data set. We propose to combine the output 'feature of the first two lected layers '-M). The Batch Normalization layers are added VGG-M network to improve the convergence speed and accuracy of the network (VGG-M-BN). The experimental verification, this paper method in the test data set on the classification of recognition accuracy rate as high as 96.5%, compared vzith VGG network (92.1%) and AlexNet network (86.39,0, the accuracy rate has been greatly improved. At the same time, increasing the Batch Normalization layers make the network convergence speed nearly tripled. Improve the generalization ability of the model by expanding the scale of the training, data set. Using VGG-1 4-BN network to train different number of vegetable image data sets, the experimental results show that the recognition accuracy decreases as the number of data sets decreases. By contrasting the activation functions, it is verified that the Rectified Linear Unit (ReLD) activation function is better than the traditional Sigmoid and 'Emil functions M VGG-M-BN networks. The paper also verifies that the classification accuracy of VGG-M-BN network is improved due to the increase of batch size. (C) 2020 The Authors. published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					559	564		10.2991/ijcis.d.200425.001													
J								Solution to Resolve Cognitive Ambiguity in Interactive Customization of Product Shape	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										ITser customization; Decision-making; Product shape design; Cognitive ambiguity; Interactive genetic algorithm	GENETIC ALGORITHM; DESIGN; SYSTEM; REDUCE	Interactive genetic algorithms have been used in a wide variety of applications and extensively developed to facilitate the personalization and customization of products for users. However, the ambiguity effect or cognitive ainbiguity of users during the product customization process will affect the effects of the final customized product. Here, we first deconstructed the ambiguity effect into cognitive ambiguity during early decision-making and that during the decision-making process. A spatial map imp strategy that invoives "text-image-symbor and a clustering strategy were then pmposed to mitigate cognitive ambiguity in the two different stages, respectively Then, a specific application example "Chinese vase design was studied. Based on the proposed strategy and interactive genetic algorithm, a prototype of computer-aided design system for product modeling Was developed by MATLAB software. Then, 10 users were invited to experiment at three different cases (not using the proposed strategy, using spatial mapping strategy, using spatial mapping strategy and scheme clustering strategy). The experiment results have verified that the spatial mapping strategy was efficient to solve cognitive ambiguity during early decision-making, and clustering strategy was efficient M solve cognitive ambiguity during the decision-making process. (C) 2020 The Authors. Published by Atlantis Press SAR I.																	1875-6891	1875-6883					2020	13	1					565	575		10.2991/ijcis.d.200511.001													
J								Multi-view Genetic Programming Learning to Obtain Interpretable Rule-Based Classifiers for Semi-supervised Contexts. Lessons Learnt	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Multi-view learning; Rule-based classification; Comprehensibility; Semi-supervised learning; Co-training; Grammar-based genetic programming	CLASSIFICATION RULES; ALGORITHMS	Multi-view learning analyzes the information from several perspectives and has largely been applied on semi-supervised contexts. It has not been extensively analyzed for inducing interpretable rule-based classifiers. We present a mull Cow and grammar-based genetic programming model for inducing rules for semi-supervised contexts. It evolves several tic mist and views, and promotes both accuracy and agreement among the views. This work details how and why common practices may not produce the expected results when inducing ruk-based classifiers under this methodology. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					576	590		10.2991/ijcis.d.200511.002													
J								Machine Learning Techniques for the Detection of Inappropriate Erotic Content in Text	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Inappropriate content; Machine learning; Text classification; Natural language processing; Text encoders	CLASSIFICATION; TWITTER	Nowadays, children have access to Internet on a regular basis. Just like the real world, the Internet has many unsafe locations where kids may be exposed to inappropriate content in the form of obscene, aggressive, erotic or rude comments. In this work, we address the problem of detecting erotic/sexual content on text documents using Natural Language Processing (NLP) techniques. Following an approach based on Machine Learning techniques, we have assessed twelve models resulting from the combination of three text encoders (Bag of Words, Term Frequency-Inverse Document Frequency and Word2vec) together with four classifiers (Support Vector Machines (SVMs), Logistic Regression, k-Nearest Neighbors and Random Forests). We evaluated these alternatives on a new created dataset extracted from public data on the Reddit Website. The best performance result was achieved by the combination of the text encoder TF-IDF and the SVM classifier with linear kernel with an accuracy of 0.97 and F-score 0.96 (precision 0.96/recall 0.95). This study demonstrates that it is possible to detect erotic content on text documents and therefore, develop filters for minors or according to user's preferences. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					591	603		10.2991/ijcis.d.200519.003													
J								Using Fuzzy Logic Algorithms and Growing Hierarchical Self-Organizing Maps to Define Efficient Security Inspection Strategies in a Container Terminal	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Container terminal; Port: Security inspection; Fuzzy logic; Growing hierarchical self-organizing map	OPTIMIZATION; NETWORK; PORT; SOM; VISUALIZATION; GHSOM	Maritime transport is one of the oldest methods of moving various types of goods, and it continues to have an important role in our modern society. More than 20 million containers are transported across the oceans daily. However, this form of transportation is constantly threatened by illegal operations, such as the smuggling of goods or people and merchandise theft. Port security departments must be prepared to face the different threats and challenges that accompany the use of innovative techniques and devices to achieve efficient inspection strategies. Two inspection strategies are presented in this study. The first strategy is based on fuzzy logic (FL), and the second strategy is based on the growing hierarchical self-organizing map (GHSOM) approach. The weight variation and security index (SI) of a container and the readings from certain technologies, such as radio-frequency identification (RFID) and X-ray scanning, are considered as the input data. To minimize the inspection time and considering the costs associated with the security inspections of containers, the results of both inspection strategies are compared and analyzed. The findings indicate there is potential for improving the effectiveness of security inspections by employing both techniques, and the specific relevance in the case of GHSOMs is discussed. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					604	623		10.2991/ijcis.d.200430.001													
J								An Integrated Decision Framework for Group Decision-Making with Double Hierarchy Hesitant Fuzzy Linguistic Information and Unknown Weights	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Bayesian approximation; Borda method; Double hierarchy hesitant fuzzy linguistic term set; Evidence theory; Group decision-making; Maclaurin symmetric mean	BORDA COUNT; TERM SET; CONSENSUS; TRUST	As an attractive generalization to hesitant fuzzy linguistic term set, double hierarchy hesitant fuzzy linguistic term set (DHHFLTS) is used to represent complex linguistic expressions by providing rich and flexible context. Previous studies on DHHFLTS show that aggregation of preference information does not consider the interrelationship among attributes. Motivated by this challenge, in this paper, we extend the generalized Maclaurin symmetric mean (GMSM) operator to DHHFLTS. The GMSM operator is highly generalized and captures the interrelationship among attributes effectively. The attributes' weight values are determined by using statistical variance method under DHHFLTS context. The decision makers' weights are calculated by using newly proposed evidence theory-based Bayesian approximation method with double hierarchy preference information. A new extension to the Borda method is provided under DHHFLTS context for prioritizing objects. Also, the applicability of the proposed method is demonstrated by using a green supplier selection problem for a sports company. Finally, the superiorities and limitations of the proposed method are discussed in comparison with similar methods. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					624	637		10.2991/ijcis.d.200527.002													
J								Technology State Control Based on Multi-source Heterogeneous Data Fusion in Manufacturing	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Decision-making; Data fusion; Rough set; D-S evidence		The technology state is determined not by a single data, but by multiple data sources that has a certain degree of uncertainty and ambiguity, and even be contradictory which is difficult to support decision-making effectively. In this paper, an efficient intelligent decision-making method based on multi-source heterogeneous data fusion is proposed. Firstly, under the rough set theory, the attribute reduction method based on the improved particle swarm optimization is proposed to efficiently obtain decision-related attributes. Secondly, using the improved Dempster-Shafer (D-S) evidence theory to fuse and calculate the reduced information sources to obtain the final decision results. Finally, the production process of satellite separation station was taken as the application object to verify the feasibility of proposed technology. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					638	644		10.2991/ijcis.d.200518.001													
J								Automatic Music Generator Using Recurrent Neural Network	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Music generation; Music composition; Long short-term memory; Gated recurrent units; Subjective evaluation		In this paper, we developed an automatic music generator with midi as the input file. This study uses long short-term memory (LSTM) and gated recurrent units (GRUs) network to build the generator and evaluator model. First, a midi file is converted into a midi matrix in midi encoding process. Then, each midi is trained on a single layer and double stacked layer model of each network as a generator model. Next, classification model, based on LSTM and GRU, are trained and chosen as an objective evaluator to analyze the performance of each generator model which classify each midi based on its musical era. Subjective evaluation is conducted by an interview with volunteer respondents with various backgrounds such as classical music interest, performance, composer, and digital composer. The result shows that the double stacked layer GRU model perform better to resemble the composer pattern in music with 70% score of recall. Moreover, subjective evaluation shows that the generated music is listenable and interesting with the highest score of 6.85 out of 10 on double stacked layer GRU. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					645	654		10.2991/ijcis.d.200519.001													
J								Incorporating Active Learning into Machine Learning Techniques for Sensory Evaluation of Food	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Sensory evaluation of food; Active learning; Machine learning	ARTIFICIAL NEURAL-NETWORK; QUALITY; MODEL	The sensory evaluation of food quality using a machine learning approach provides a means of measuring the quality of food products. Thus, this type of evaluation may assist in improving the composition of foods and encouraging the development of new food products. However, human intervention has been often required in order to obtain labeled data for training machine learning models used in the evaluation process, which is time-consuming and costly. This paper aims at incorporating active learning into machine learning techniques to overcome this obstacle for sensory evaluation task. In particular, three algorithms are developed for sensory evaluation of wine quality. The first algorithm called Uncertainty Model (UCM) employs an uncertainty sampling approach, while the second algorithm called Combined Model (CBM) combines support vector machine with Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, and both of which are aimed at selecting the most informative samples from a large dataset for labeling during the training process so as to enhance the performance of the classification models. The third algorithm called Noisy Model (NSM) is then proposed to deal with the noisy labels during the learning process. The empirical results showed that these algorithms can achieve higher accuracies in this classification task. Furthermore, they can be applied to optimize food ingredients and the consumer acceptance in real markets. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					655	662		10.2991/ijcis.d.200525.001													
J								A Neural Network for Moore-Penrose Inverse of Time-Varying Complex-Valued Matrices	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Zhang neural network; MoorePenrose inverse; Finite-time convergence; Noise suppression	SYLVESTER EQUATION; CONVERGENCE; MODEL	The MoorePenrose inverse of a matrix plays a very important role in practical applications. In general, it is not easy to immediately solve the MoorePenrose inverse of a matrix, especially for solving the MoorePenrose inverse of a complex-valued matrix in time-varying situations. To solve this problem conveniently, in this paper, a novel Zhang neural network (ZNN) with time-varying parameter that accelerates convergence is proposed, which can solve MoorePenrose inverse of a matrix over complex field in real time. Analysis results show that the state solutions of the proposed model can achieve super convergence in finite time with weighted sign-bi-power activation function (WSBP) and the upper bound of the convergence time is calculated. A related noise-tolerance model which possesses finite-time convergence property is proved to be more efficient in noise suppression. At last, numerical simulation illustrates the performance of the proposed model as well. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					663	671		10.2991/ijcis.d.200527.001													
J								A Novel Combinational ATP Based on Contradiction Separation for First-Order Logic	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										First-order logic; Theorem proving; Prover9; Contradiction separation rule; Dynamic multi-clause synergized deduction		At present, most of the first-order logic theorem provers use a binary-resolution method, which can effectively solve the general first-order logic problems to a certain extent. However, the cooperative processing ability of this method for multiple clauses is insufficient, and it is easy to cause rapid expansion of clause set in the deductive process. In this paper, we propose a novel first-order logic theorem prover based on the standard contradiction separation (S-CS) rule. This prover can realize the dynamic cooperative deduction of multiple clauses in each deduction process, as well as it can effectively learn and control the deduction process. This paper incorporates the S-CS rule with the well-known prover Prover9, to build a combined system, which effectively integrates the advantages of the two methods, not only improves the binary-resolution prover's ability, but also solves more than 100 problems that cannot be solved by other provers. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					672	680		10.2991/ijcis.d.200521.001													
J								Quasi-Copulas, Copulas and Fuzzy Implicators	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Copula; Fuzzy conjunctor; Fuzzy implicator; Quasi-copula; Semicopula	CONSTRUCTION	In this paper, we study relations between fuzzy implicators and some kinds of fuzzy conjunctors, in particular, quasi-copulas and copulas. We show that there is a one-to-one correspondence between the classes of all quasi-copulas and 1-Lipschitz fuzzy implicators. A similar relation holds for copulas and 2-increasing 1-Lipschitz fuzzy implicators. Based on these relations, we introduce, discuss and exemplify several new construction methods for fuzzy implicators, and also discuss several dualities on the class of all 1-Lipschitz fuzzy implicators. In addition, we introduce a construction method for fuzzy implicators based on any two copulas and a Lebesgue integrable fuzzy implicator, and discuss some of its special cases. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					681	689		10.2991/ijcis.d.200527.004													
J								A Novel Density Peaks Clustering Algorithm Based on Local Reachability Density	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Clustering algorithm; Density peaks clustering; Local reachability density; Domino effect		A novel clustering algorithm named local reachability density peaks clustering (DPC) which uses local reachability density, improve the performance of the density peaks clustering algorithm (DPC) is proposed in this paper. This algorithm enhances robustness by removing the cutoff distance dc which is a sensitive parameter from the DPC. In addition, anew allocation strategy is developed to eliminate the domino effect, which often occurs in DPC. The experimental results confirm that this algorithm is feasible and effective. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					690	697		10.2991/ijcis.d.200603.001													
J								Individual Heterogeneous Learning with Global Centrality in Prisoner Dilemma Evolutionary Game on Complex Network	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Evolution game.; Individual heterogeneity; Global centrality; Cooperation rate	COOPERATION	The influence of individual heterogeneity on the evolutionary game has been studied extensively in recent years. Whereas many theoretical studies have found that the heterogeneous learning ability effects cooperation rate, the individual learning ability in networks is still not well understood. It is known that an individual's learning ability is influenced not only by its first order neighbors, hut also by higher order individuals, and even by the whole network. At present, existing methods to represent individual learning ability are based on degree centrality, resulting in ignoring the global centrality of nodes. In this paper, we design a method for describing the heterogeneous learning ability by taking advantage of a pre-factor theta(x) related to the node betweenness. And a parameter alpha is used to tune theta(x). Experiments show that individual heterogeneous learning ability-is effected by global information. Our findings provide a new perspective to understand the important influence of the global attributes of nodes on the evolutionary game. (C) 2020 The Authors. Published lay Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					698	705		10.2991/ijcis.d.200603.002													
J								Using Recurrent Neural Networks for Part-of-Speech Tagging and Subject and Predicate Classification in a Sentence	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Natural language processing; Part-of-speech (POS) tagging; Recurrent neural networks; Syntactic analysis		In natural language processing the use of deep learning techniques is very common. In this paper, a technique to identify the subject and predicate in a sentence is introduced. To achieve this, the proposed technique completes POS tagging identifying in a later stage the subject and. the predicate in a sentence. Two different deep neural networks are used to complete this process. A first one to establish a. correspondence between individual Words and part-of-speech (POS) tags and a second one that, taking as input these tags, identifies relevant elements of the sentence such like the subject and the predicate. To validate the architecture of our proposal a set of tests over public datasets have been designed. In these experiments, this model achieves high rates of accuracy in POS tagging and in subject and predicate classification. Finally; a comparison of the results obtained for each individual network with similar fools such as NLTK, pyStatParser and spaCy is made. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					706	716		10.2991/ijcis.d.200527.005													
J								Dose Regulation Model of Norepinephrine Based on LSTM Network and Clustering Analysis in Sepsis	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Time series data; LSTM; Clustering; Sepsis; Blood pressure regulation		Sepsis is a life-threatening condition that arises when the body's response to infection causes injury to its own tissues and organs. Despite the advancement of medical diagnosis and treatment technologies, the morbidity and mortality of sepsis are still relatively high. In this paper, a two-layer long short-term memory (LSTM) mode is proposed to predict the dose of norepinephrine, in order to control the blood pressure of patients. The proposed modeling approach is evaluated using the MIMIC-III data set achieving higher performance. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					717	726		10.2991/ijcis.d.200512.001													
J								Optimizing Production Mix Involving Linear Programming with Fuzzy Resources and Fuzzy Constraints	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Fuzzy resources; Fuzzy constraints; Fuzzy objective function; Fuzzy optimization	MEMRISTOR	In this paper, Fuzzy Linear Programming (FLP) was used to model the production processes at a university-based bakery for optimal decisions in the daily productions of the bakery, Using the production data of five products from the bakery., a fuzzy linear programme was developed to help make decisions when fuzzy resources were involved. As usual, classical linear programme gave only one feasible solution. However, while it was established that solving the linear programme from the production mix when fuzzy constraints were introduced (Verdegay's model) gave a more robust and alternative set of decisions than the classical model, it was equally established that a better result could be obtained when all the constraints and the objective function were fuzzy (Werners' Model). (C) 2020 The Authors. Published by Atlantis SARL.																	1875-6891	1875-6883					2020	13	1					727	733		10.2991/ijcis.d.200519.002													
J								Weighted Nonnegative Matrix Factorization for Image Inpainting and Clustering	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Recovery; Dimensionality reduction; Weighted nonnegative matrix factorization; Noise	MODEL	Conventional nonnegative matrix factorization and its variants cannot separate the noise data space into a clean space and learn an effective low-dimensional subspace from Salt and Pepper noise or Contiguous Occlusion. This paper proposes a weighted nonnegative matrix factorization (WNMF) to improve the robustness of existing nonnegative matrix factorization. In WNMF, a weighted graph is constructed to label the uncorrupted data as 1 and the corrupted data as 0, and an effective matrix factorization model is proposed to recover the noise data and achieve clustering from the recovered data. Extensive experiments on the image datasets corrupted by Salt and Pepper noise or Contiguous Occlusion are presented to demonstrate the effectiveness and robustness of the proposed method in image inpainting and clustering. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					734	743		10.2991/ijcis.d.200527.003													
J								Fine-Grained Sentiment Analysis for Measuring Customer Satisfaction Using an Extended Set of Fuzzy Linguistic Hedges	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Customer satisfaction; Fine grained sentiment analysis; Fuzzy logic; Linguistic hedges; Membership function	SYSTEM	In recent years, the boom in social media sites such as Facebook and Twitter has brought people together for the sharing of mons, sentiments, emotions, and experiences about products, events, politics, and other topics. In particular, sentiment-based applications are growing in popularity among individuals and businesses for the making of purchase decisions. Fuzzy-based sentiment analysis aims at classifying customer sentiment at a fine-grained level. This study deals with the development of a fuzzy-based sentiment analysis by extending fuzzy hedges and rule-sets fora more efficient classification of customer sentiment and satisfaction. Prior studies have used a limited number of linguistic hedges and polarity classes in their rule-sets, resulting in the degraded efficiency of their fuzzy-based sentiment analysis systems. The proposed analysis of the current study classifies customer reviews using fuzzy linguistic hedges and an extended rule set with seven sentiment analysis classes, namely extremely positive, wry positive, positive, neutral, negative, very negative, and extremely negative. Then, a fuzzy logic system is applied to measure customer satisfaction at a fine-grained level. The experimental results demonstrate that the proposed analysis has an improved performance over the baseline works. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					744	756		10.2991/ijcis.d.200513.001													
J								An Efficient Clustering Algorithm for Mixed Dataset of Postoperative Surgical Records	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Data clustering; Meta-heuristic; Artificial electric field algorithm; Distance measure; Mixed dataset	PARTICLE SWARM OPTIMIZATION; GRAVITATIONAL SEARCH ALGORITHM; GENETIC ALGORITHM; EVOLUTION	In data mining, data clustering is a prevalent data analysis methodology that organizes unlabeled data points into distinct clusters based on a similarity measure. In recent years, several clustering algorithms found, dependent on a predefined number of clusters and centered around the dataset with either numeric or categorical attributes only. However, many real-world engineering, scientific., and industrial applications involve datasets with mixed numeric as well as categorical attributes hut lack domain knowledge (target labels). Clustering unlabeled-mixed datasets is a challenging task as (I) it is difficult to estimate the number of clusters in the absence of domain knowledge and (2) mathematical operations cannot be applied directly to the mixed dataset. In this paper, an efficient searching and fast convergent automatic data clustering algorithm based on population-based metaheuristic optimization is proposed to deal with the mixed dataset. The proposed clustering algorithm aims to find the optimal number of cluster partitions automatically. It utilizes a real-coded variable-length candidate solution to detect the optimal number of clusters automatically, The concepts of threshold setting and cut-off ratio are used in the optimization process to refine the clusters. The similarity between data points and different cluster centers is measured using Euclidean distance (for numeric attributes) and the probability of co-occurrence of values (for categorical attributes). The proposed algorithm is compared with existing mixed data clustering techniques based on a statistical significance test and two robustness measures: Average accuracy and Standard deviation. Finally, the proposed algorithm is validated by applying to a real historical postoperative surgical mixed data set obtained from a surgical department of a multispecialty hospital in India. Results show the effectiveness, robustness, and usefulness of the proposed clustering algorithm. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					757	770		10.2991/ijcis.d.200601.001													
J								VGG16-T: A Novel Deep Convolutional Neural Network with Boosting to Identify Pathological Type of Lung Cancer in Early Stage by CT Images	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Pathological type, identification; Lung cancer; Data enhancement; Boosting	PULMONARY NODULES; CLASSIFICATION; DIAGNOSIS	Lung cancer is known as the highest mortality rate cancer, winch needs biopsy to determine its subtype for further treatment. Recently; deep learning has provided powerful tools in lung cancer diagnose and therapeutic regimen making. However, it is still a challenge to identify the pathological type of lung cancer in early stage by CT images due to the lack of public training data set and powerful artificial intelligent models. In this work, we firstly build up a data set of CT images from 125 patients of lung cancer in early stage. The data set is enhanced by revolving, shifting and reproducing operations to avoid its inherent imbalance. After that, a deep convolutional neural network namely VGG16-T is proposed and multiple VGG16-T worked as weak classifiers are trained With a boosting strategy. Such method achieves significant performance in identifying pathological type of lung cancer with CT images by joint voting. Experiments conducted on the enhanced data set of Cl images show that 3 weak classifiers VGG16-T are sufficient to achieve accuracy 86.58% in identifying pathological type, which performs better than some state-of-the-art deep learning models, including A lexNet. ResNet-34 and DenseNet with or without Softmax weights. As well, VGG16-T is with accuracy 85% by diagnosing 20 randomly selected CT images, while two respiratory doctors from Grade 3A level hospitals obtain accuracy 55% and 65% by handcrafted diagnosing, respectively To our best acknowledge, this is the first attempt of using deep models and boosting to identify pathological type of lung cancer in early stage from small scale CT images. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					771	780		10.2991/ijcis.d.200608.001													
J								An Efficient Evolutionary Meta heuristic for the Traveling Repairman (Minimum Latency) Problem	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Metaheuristics; Traveling repairman problem; Minimum latency problem; Discrete optimization; Memetic algorithm	APPROXIMATION ALGORITHMS; MEMETIC ALGORITHM	In this paper we revisit the memetic evolutionary family of metaheuristics, called Discrete Bacterial Memetic Evolutionary Algorithm (DBMEA), whose members combine Furuhashi's Bacterial Evolutionary Algorithm and various discrete local search techniques. These algorithms have proven to be efficient approaches for the solution of NP-hard discrete optimization problems such as the Traveling Salesman Problem (TSP) with Time Windows.. This paper presents our results in solving the Traveling Repairman Problem (also called Minimum Latency Problem) with a DBMEA variant. he results are compared With state-of-the-art heuristics found in the literature. The DBMEA in most cases turned out to be faster than all other methods, and for the bigger benchmark instances it was also found to have better solutions than the former best-known results. Based on these test results we claim to have found the best approach and thus we suggest the use of the DBMEA for the Traveling Repairman Problem, especially for large instances. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					781	793		10.2991/ijcis.d.200529.001													
J								New Kind of MV-Modules	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										MV-algebra; PMV-algebra; A(k)-module; Free A(k)-module; Radical of an A(k)-module; Noetherian A(k)-module	A-IDEALS	In this paper, by considering the notion of MV-modules, which is the structure that naturally correspond to lu-modules over lu-rings, we investigate some properties of a new kind of MV-modules, that we introduced in Borzooei and Saidi Goraghani, Free MV-modules, J. Intell. Fuzzy Syst. 31 (2016), 151161 as A(k)-modules. With the current situation, it was not easy for us to work on some concepts such as free MV-modules and Noetherian MV-modules. So we limited our scope of work by introducing a new kind of MV-modules. We define and study the notions of free A(k)-modules, radical of A(k)-modules and Noetherian A(k)-modules, where A is a product MV-algebra and k is an element of N. For example, we state a general representation for a free A(k)-module, and we obtain conditions in which an A(k)-module can be Noetherian. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					794	801															
J								An Intelligent Traffic Light System Using Object Detection and Evolutionary Algorithm for Alleviating Traffic Congestion in Hong Kong	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Intelligent traffic light system; Traffic congestion; Object detection; Evolutionary-algorithm		High traffic flow is a typical characteristic of a mobilized city with a high population. Efficient traffic management is a proper solution to reduce the stress and anxiety associated with driving or traveling. The road users can have better timing for traveling as they will not experience journey delays due to traffic congestion. In Hong Kong, until September 2017, over 2,100 kilometers long roads around Hong Kong Island, Kowloon Peninsula, and New Territories are serving over 762,000 vehicles. However, the current traffic signal control systems used in Hong Kong are mainly pre-defined fixed-cycle traffic light systems. These systems do not consider too much about the real traffic situations such as vehicle and pedestrian counts, delay and waiting time of the road users. They respond slowly to regulate traffic flow especially when there is a high volume of traffic. A study of effective optimization technologies in controlling traffic signals is conducted which aims to relief the congestion problem and increase road efficiency according to the specific needs of Hong Kong. In this paper, a new traffic light system using machine learning with object detection and analyzing by the evolutionary algorithm that aims to perform a real-time strategic signal switching arrangement to traffic lights at the intersection was designed to reduce the waiting time of pedestrians and vehicles, and provide better traveling experience to road users. (C) 2020 The,Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					802	809															
J								A Hybrid Firefly and Multi-Strategy Artificial Bee Colony Algorithm	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Firefly algorithm; Artificial bee colony; Multi-strategy; Hybrid algorithm; Global optimization	PARTICLE SWARM OPTIMIZATION; ENSEMBLE	Many hard optimization problems have been efficiently solved by two notable swarm intelligence algorithms, artificial bee colony (ABC) and firefly algorithm (FA). In this paper, a collaborative hybrid algorithm based on firefly and multi-strategy artificial bee colony, abbreviated as FA-MABC, is proposed for solving single-objective optimization problems. In the proposed algorithm, FA investigates the search space globally to locate favorable regions of convergence. A novel multi-strategy ABC is employed to perform local search. The proposed algorithm incorporates a diversity measure to help in the switch criteria. The FA-MABC is tested on 40 benchmark functions with diverse complexities. Comparative results with the basic FA, ABC and other recent state-of-the-art metaheuristic algorithms demonstrate the competitive performance of the FA-MABC. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					810	821															
J								Group Decision-Making Using Complex q-Rung Orthopair Fuzzy Bonferroni Mean	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Complex q-rung orthopair fuzzy sets; Bonferroni mean operators; Multi-attribute group decision-making problems	AGGREGATION; OPERATORS; SETS	Complex q-rung orthopair fuzzy set (CQROFS), as a modified notion of complex fuzzy set (CFS), is an important tool to cope with awkward and complicated information. CQROFS contains two functions which are called truth grade and falsity grade by the form of complex numbers belonging to unit disc in a complex plane. The condition of CQROFS is that the sum of q-powers of the real part (Also for imaginary part) of the truth grade and real part (Also for imaginary part) of the falsity grade is limited to the unit interval. Bonferroni mean (BM) operator is an important and meaningful concept to examine the interrelationships between the different attributes. Keeping the advantages of the CQROFS and BM operator, in this manuscript, the complex q-rung orthopair fuzzy BM (CQROFBM) operator, complex q-rung orthopair fuzzy weighted BM (CQROFWBM) operator, complex q-rung orthopair fuzzy geometric BM (CQROFGBM) operator, and complex q-rung orthopair fuzzy weighted geometric BM (CQROFWGBM) operator are proposed, and some properties are discussed, further, based on the CQROFWGBM operator, a multi-attribute group decision-making (MAGDM) method is developed, and the ranking results are examined by score function. Finally, we give some numerical examples to verify the rationality of the established method, and show its advantages by comparative analysis with some existing methods. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					822	851															
J								An Intelligent and Automated Approach for Smart Minimarkets	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Smart cities; ANN; Smart minimarket; Smart shopping; Networked embedded systems; Queueing analysis		This paper presents the design and implementation of a smart and safe minimarket prototype for deployment in busy smart cities to mitigate the overhead of shopping experience. The prototype allows customers to remotely access and browse the available products at the minimarket using a special smart-phone application. The system can intelligently detect the nearby location of customers and subsequently provide location-dependent services such as allowing orders to be placed using the application, predicting weekly customer expenditures based on artificial-neural-network machine-learning approach, and automatically delivering purchased products using a robotic shopping cart. This proposal is believed to support safe shopping which became a critical issue after COVID-19 pandemic. From a service provider view point, the application allows the provider to remotely manage the minimarket by adding/removing product items, keeping track of shortage in products, and getting revenue information. Empirical results show that the average service time of the minimarket is approximate to 60 seconds per customer. However, an analytical model based on queueing theory was used to analyze the performance of the system when customers arrive according to a Poisson random process and get served according to a general-service-time distribution (M/G/1). The case of batch customer arrivals (M-[H]/G/1) was also analyzed, where batch size is also assumed to be random. Various traffic intensities and the effect of variable service times were studied and cross-validated with simulation results. Worst-case scenario shows that under heavy load of 95%, when customers arrive at the minimarket every 63 seconds on average, the average response time for each customer is minutes. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					852	863															
J								An Integer Cat Swarm Optimization Approach for Energy and Throughput Efficient MPSoC Design	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Design space exploration (DSE); Multicore architecture; Integer cat swarm optimizatiom	SPACE EXPLORATION; FRAMEWORK; SYSTEM	Modern multicore architectures have an ability to allocate optimum system resources for a specific application to have improved energy and throughput balance. The system resources can be optimized automatically by using optimization algorithms. State-of-the-art using optimization algorithm in the field of such architectures has shown promising results in terms of minimized energy consumption through configuration of number of CPU cores, limited cache sizes and operating frequency. We propose, in this work, a Cat Swarm Optimization (CSO) algorithm-based technique, Integer CSO (ICSO) for the design space exploration (DSE) of multicore computer architectures to find improved energy and throughput balance. The proposed integer variant of CSO algorithm demonstrates convergent behavior for all of design space parameters variations. The Pareto front proposed by ICSO is explored by using various SPLASH-2 benchmarks. Results show significant decrease in energy consumption without affecting throughput severely. Simulation results also validate the use of ICSO in DSE for multicore architectures. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					864	874		10.2991/ijcis.d.200617.001													
J								Fuzzy Load Forecast with Optimized Parametric Adjustment Using Jaya Optimization Algorithm	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Advanced fuzzy load forecasting model; Hybrid fuzzy-MJO load forecasting algorithm; Minimal total energy error; Minimal peak energy error; Modified Jaya optimization (MJO) algorithm	NEURAL-NETWORK; MODEL	This paper proposes an advanced fuzzy load forecast method optimized by modified Jaya optimization (MJO) algorithm. MATLAB (R) platform is used to implement the proposed hybrid Fuzzy-MJO load forecasting algorithm and to verify the outperforming features of a Jaya technique over a fuzzy load forecast model. The novel Fuzzy-MJO load forecasting systems uses the day-time and the daily power consumption to efficiently predict the forecast power consumption. The comparative load forecasting results between proposed Fuzzy-MJO with the latest other algorithms are adequately presented. The full week forecast results using proposed hybrid Fuzzy-MJO load forecasting algorithm demonstrates an outperforming superiority, through the various tested cases, regarding to the total and the peak power error in comparison with the fuzzy-based load forecast model. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					875	892		10.2991/ijcis.d.200617.002													
J								An Improved Parameter Control Based on a Fuzzy System for Gravitational Search Algorithm	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Gravitational search algorithm; Fuzzy system; Fuzzy rules; Optimization		Recently, a kind of heuristic optimization algorithm named gravitational search algorithm (GSA) has been rapidly developed. In GSA, there are two main parameters that control the search process, namely, the number of applied agents (Kbest) and the gravity constant (G). To balance exploration and exploitation, a fuzzy system containing twelve fuzzy rules is proposed to intelligently control the parameter setting of the GSA. The proposed method can enhance the convergence ability and yield better optimization results. The performance of fuzzy GSA (FGSA) is examined by fifteen benchmark functions. Extensive experimental results are tested and compared with those of the original GSA, CGSA, CLPSO, NFGSA, PSGSA and EKRGSA. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					893	903		10.2991/ijcis.d.200615.001													
J								A Human-Machine Language Dictionary	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Text mining; Natural language processing; Knowledge representation		In this paper, we propose a framework for building a human-machine language dictionary. Given a concept/word, an application can extract the definition of the concept from the dictionary, and consequently understand its meaning. In the dictionary, a concept is defined through its relations with other concepts. Relations are specified in the machine language. To a certain degree, the proposed dictionary has a resemblance to WordNet, which consists of a set of concepts/words with synonyms being linked to form the net. WordNet plays an important role in text mining, such as sentiment analysis, document classification, text summarization and question answering systems, etc. However, merely providing synonyms is not sufficient. The proposed dictionary provides a definition for each concept. Based on the definition, the application can accurately estimate the distance and similarity between concepts. As a monotonic mapping, the algorithm for estimating distances and similarities is proved to be always convergent. We envisage that the dictionary will become an important tool in all Text Mining disciplines. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					904	913		10.2991/ijcis.d.200602.002													
J								Accuracy Improvement of Autonomous Straight Take-off Flying Forward, and Landing of a Drone with Deep Reinforcement Learning	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Drones; Deep reinforcement learning; Q-learning; Autonomous flight		Nowadays, drones are expected to be used in several engineering and safety applications both indoors and outdoors, e.g., exploration, rescue, sport, entertainment, and convenience. Among those applications, it is important to make a drone capable of flying autonomously to carry out an inspection patrol. In this paper, we present a novel method that uses ArUco markers as a reference to improve the accuracy of a drone on autonomous straight take-off, flying forward, and landing based on Deep Reinforcement Learning (DRL). More specifically, the drone first detects a specific marker with one of its onboard cameras. Then it calculates the position and orientation relative to the marker so as to adjust its actions for achieving better accuracy with a DRL method. We perform several simulation experiments with different settings, i.e., different sets of states, different sets of actions and even different DRL methods, by using the Robot Operating System (ROS) and its Gazebo simulator. Simulation results show that our proposed methods can efficiently improve the accuracy of the considered actions. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					914	919		10.2991/ijcis.d.200615.002													
J								A New Hybrid Metaheuristic Algorithm for Multiobjective Optimization Problems	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Sine-cosine algorithm; Nondominated sorting genetic algorithm; Multiobjective optimization problems; The economic emission dispatch problem; TOPSIS	PARTICLE SWARM OPTIMIZATION; EMISSION DISPATCH PROBLEMS; SORTING GENETIC ALGORITHM; ECONOMIC LOAD DISPATCH; SINE COSINE ALGORITHM; DIFFERENTIAL EVOLUTION; LOCAL SEARCH; LINE FLOW; POWER; DESIGN	The elitist nondominated sorting genetic algorithm (NSGA-II) is hybridized with the sine-cos le algorithm (SCA) in this paper to solve multiobjective optimization problems. The proposed hybrid algorithm is named nondominated sorting sine-cosine genetic algorithm (NS-SCGA). The main idea of this algorithm is the following: NS-SCGA integrates the merits of exploitation capability of NSGA-II and exploration capability of SCA for a better search ability and speeds up the searching process. 'Elie performance of NS-SCGA is tested on the set of benchmark functions provided for CEC09. The NS-SCGA results are compared with other recently developed multiobjective algorithms in terms of convergence, spacing, and spread of the obtained nondominated solutions to the true Pareto front. The statistical analysis of the results obtained is performed by nonparametric Friedman and Wilcoxon signed-rank tests. The results prove that NS-SCGA is superior to or competitive with other multiobjective optimization algorithms considered in the comparison. Furthermore, the economic emission dispatch problem (EEDP) is solved by NS-SCGA. operating cost (fuel cost) and pollutant emission of the standard IEEE 30-bus network with six generating units are minimized simultaneously by the NS-SCGA considering the losses. The results show the superiority of NS-SCGA and confirm its ability in solving EEDE TOESIS technique is applied to choose the best compromise solution from the obtained Pareto-optimal solutions of EEDP according to the decision maker's preference. (C) 2020 The Authors. Publishedby Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					920	940															
J								Whale Optimization for Wavelet-Based Unsupervised Medical Image Segmentation: Application to CT and MR Images	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Medical segmentation; neupervised machine learning; Wavelet transform; Texture features; Clustering; K-means; Fuzzy K-means; Particle swarm optimization; Genetic algorithm; Whale optimization; CT and MRI		Image segmentation plays crucial role in medical analysis and forms the basis tor clinical diagnosis and patient's treatment planning. But the large variation in organ shapes, inhomogeneous intensities, poor contrast, organic nature of textures and complex boundaries in medical images makes segmentation process adverse and challenging. Further, the absence of annotated ground-truth dataset in medical field limits the advantages of the trending deep learning techniques causing several setbacks. Though numerous unsupervised methods are reported in literature to combat the challenges in medical domain, achieving better segmentation quality still remains as an open issue. This mirk aim to address this issue integrating the strength of multiresolution analysis and the meta heuristic optimization techniques for unsupervised medical image segmentation. The proposed approach employs undecimated wavelet frames to extract translation invariant texture and gray information at different orientations to effectively characterize the textures M medical images. Next, the approach introduces the latest meta-heuristic whale optimization algorithm (\VOA), the global optimizer to enhance the performance c unsupervised clustering algorithm With optimized cluster centers to cluster the extracted Wavelet texture features. Moreover; the study contributes to fill the gap in hterature investigating for the first time different intelligence algorithms such as fuzzy, genetic algorithm (GA) and particle swarm optimization (PSO) for unsupervised medical image segmentation to demonstrate the efficacy of the proposed approach. Evaluation was performed on medical CT and MR images based on 'feature similarity (FSIM), dice (DC) and 'feature of merits (F 0Ms). Experimental results demonstrates the supremacy of the proposed approach over other intelligence algorithms. Finally, statistical study with ANOVA analysis was carried out to confirm the significance of the proposed approach in determining the optimal solution and displaying promising segmentation results toward diagnostic support for radiologist. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					941	953		10.2991/ijcis.d.20065.001													
J								Group-Like Uninorms	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Uninorms; Construction; Characterization	INVARIANT T-NORMS; ROTATION	Uninnorms play a prominent role both in the theory and the applications of aggregations and fuzzy logic. called group-like uninorms will be introduced and a complete structural description will be given for a large subclass of them. First, the four versions of a general construction called partial lex product will be recalled. Then two particular variants of them will be specified: the first variant constructs, starting from HI (the additive group of the real s) and modifying it in some way by 7's (the additive group of the integers) what we will coin basic group-like uninorms, whereas the second variant can enlarge any group-like uMnorm by a basic group-like uninorm resulting in another group-like uninorm. All group like uninorms obtained this My are "square" and have finitely many idempotent. elements. On the other hand, We prove that any square group-like uninorm which has finitely many idempotein elements can be constructed by consecutive applications of the second variant (finitely many times) using only basic group. The uninorms as building blocks. Any basic group-like uninorm can he built by the first variant using only IR and 7, and any square group-like uninorm which has finitely many idempotent elements can be built using the second variant using only basic group-like uninorms: ultimately, all such uninorms can be built from it and Z. In this way a complete characterization for square gfimp4ike uninornIs which possess finitely many idenmotent elements is given. The characterization provides, for potential applications M several fields of fuzzy theory or aggregation theory, the Whole spectrum of choice of those square group-like uMnonns which possess finitely many idempotent elements. (C) 2020 The Authors. Published by Atlantis Press SARL.																	1875-6891	1875-6883					2020	13	1					954	965															
J								Kernels of Residuated Maps as Complete Congruences in Lattices	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Complete lattice; Lattice-valued fuzzy se; Congruence; Residuated map	ORDERED STRUCTURES; FUZZY-SETS	In a context of lattice-valued functions (also called lattice-valued fuzzsets), where the codomain is a complete lattice L, an equivalence relation defined on L by the equality of related cuts is investigated. It is known that this relation is a complete congruence on the join-semilattice reduct of L. In terms of residuated maps, necessary and sufficient conditions under which this equivalence is a complete congruence on L are given. In the same framework of residuated maps some known representation theorems for lattices and also for lattice-valued fuzzy sets are formulated in a new way. As a particular application of the obtained results a representation theorem of finite lattices by meet-irreducible elements is given. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					966	973		10.2991/ijcis.d.200714.001													
J								Teaching Explainable Artificial Intelligence to High School Students	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Explainable artificial intelligence; Interpretable computational intelligence; Decision trees; l'uzzy rule-based classifiers; Educational AT resources		Artificial Intelligence (Al) is part of our everyday life and has become one of the most outstanding and strategic technologies. Explainable Al (XAI) is expected to endow intelligent systems with fairness, accountability, transparency and explanation ability when interacting with humans. This paper describes how to teach fundamentals of XAI to high school students who take part in interactive workshop activities at CiTIUS-USC. These workshop activities are carried out in the context of a strategic plan lot promoting careers on Science, Technology Engineering and Mathematics. Students learn (1) how to build datasets free of bias, (2) how to build interpretable classifiers and (3) how to build multi-modal explanations. (C) 2020 The ituthors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					974	987		10.2991/ijcis.d.200715.003													
J								Classical and Fuzzy Two-Layered Modal Logics for Uncertainty: Translations and Proof-Theory	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Mathematical fuzzy logic; Logics of uncertainity; Lukasiewicz logic; Probability logics; Two-layered modal logics; Hypersequent calculi		This paper is a contribution to the study of two distinct kinds of logics for modelling uncertainty es use logics with a two-layered modal syntax, but Wh i le one employs classical logic on both levels and infinitely-many multimodal operators, the other involves a suitable system of fuzzy logic in the upper layer and only one monadic modality. We take two prominent examples of the former approach, the probability logics Pr-parallel to n and Pr(po)l (whose modal operators correspond to all possible linear/polynomial inequalities with integer coefficients), and three logics of the latter approach: PrE, PrLA and PrPL Delta (given by the Lukasiewicz logic and its expansions by the Baal Monteiro projection connective Delta and also by the product conjunction). We describe the relation between the two approaches by giving faithful translations of Pr-lin and Pr-pol into, respectively, PrLA and Pr-PL Delta, and vice versa. We also contribute to the proof theory of two-layered modal logics of uncertainty by introducing a hypersequent calculus Pr-parallel to n for the logic PrL. Using this formalism, we obtain a translation of Priin into the logic Pei-, seen as a logic on hypersequents of relations, and give an alternative proof of the axiomatization of Pr-parallel to n. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					988	1001		10.2991/ijcis.d.200703.001													
J								Coreference Resolution Using Semantic Features and Fully Connected Neural Network in the Persian Language	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Coreference resolution; Fully connected neural net-works; Deep learning; Hierarchical accumulative clustering; Persian language		Coreference resolution is one of the most critical issues in various applications of natural language processing, such as machine translation, sentiment analysis, suinmarization, etc. In the process of coreference resolution, in this paper, a fully connected neural network approach has been adopted to enhance the performance of 'feature extraction Whilst also facihlating the mention pair classification process for coreference resolution in the Persian language. For tins purpose, first, we focus on the feature extraction phase by fusing some handcrafted features, word enlbedding features and. semantic features. Then, a fully connected deep neural network is utilized to determine the probability of the validity of the mention pairs. After that, the numeric output of the last layer of the utilized neural network is considered as the feature vector of the valid mention pairs. Finally, the coreference mention pairs are specified by utilizing a hierarchical accumulative clustering method. Tie proposed method's evaluation on the Uppsala dataset demonstrates a meaningful impro,,TMent, as indicated by the F-score 61.51%, in comparison to state-of-the-art methods. (C) 2020 The Authors. Published by Atlantis Press SARI.																	1875-6891	1875-6883					2020	13	1					1002	1013		10.2991/ijcis.d.200706.002													
J								Computation of Support and Confidence for Interval-Valued Fuzzy Association Rules	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Interval valued data; Fuzzy association rules; Support; Confidence; Algorithm		The aim of this paper is to provide an algorithm for the computation of support and confidence of the association rules on interval-valued fuzzy sets. Each element of the interval-valued fuzzy set has a membership degree defined as an interval. In other Words, the membership intervals maybe interpreted as partial knowledge when the precise value is not known. The computations of the support and the confidence are discussed with respect to the three most common triangular norms (minimum, product and Lukasiewicz), which act as conjunction in support and confidence definitions. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1014	1026		10.2991/ijcis.d.200515.001													
J								Automated Recognition of Hand Grasps Using Electromyography Signal Based on LWT and DTCWT of Wavelet Energy	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Signal processing; Electnmnyogram; Discrete wavelet transform; Feature extraction; Pattern recognition; Support vector machine; Deep learning Neural Network	MYOELECTRIC PATTERN-RECOGNITION; SUPPORT VECTOR MACHINE; CLASSIFICATION ACCURACY; EMG; SELECTION; SYSTEM	This paper presents a novel framework that automatically classifies hand grasps using Ele yogram (EMG) signals based on advanced Wavelet `transform (WT). This method is motivated by the observation that there lies a unique correlation between different samples of the signal at various frequency levels obtained by Discrete WT. In the proposed approach.. EMG signals captured from the subjects are subjected to denoising using sym let wavelets, followed by Principal Component Analysis (PCA) for dimensionality reduction. Further, the important attributes of the signal are extracted using lifting lAravelet Transform (IWT) and Dual Tree Complex WT (DTCWT). Multiple classifiers such as Feed Forward Neural Networks (FENN), Cascaded Feed Forward Neural Networks (CPN), Support Vector Machine (WM) and Deep Learning Neural Network (DINN) are used for classification. The simulation results are compared with various training algorithms and it is observed that DECVF`f features combined with CFNN and trained with Gradient Descent With Adaptive Back Propagation (GDABP) algorithm achieved the best performance. The advantages of the proposed method were proved by comparing with the earlier conventional methods, in terms of recognition performance. These experimental results prove that the proposed method gives a potential performance in the recognition of hand grasps using EMG signals. In addition, the proposed method supports clinicians to improve the nce of mvoelectric pattern recognition. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1027	1035		10.2991/ijcis.d.200524.001													
J								Climbing the Hill with ILP to Grow Patterns in Fuzzy Tensors	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Disjunctive box cluster model; Fuzzy temor; Hill-climbing; Integer Linear Programming; Forward selection		Fuzzy tensors encode to what extent n-ary predicates are satisfied. The disjunctive box cluster model is a regression model where sub-tensors are explanatory variables for the values in the fuzzy tensor. In this article, locally optimal patterns for that model, with high areas times squared densities, are grown by hill-climbing from fragments of them. A forward selection then chooses among the discovered patterns a non-redundant subset that fits, but does not overfit, the tensor. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1036	1047		10.2991/ijcis.d.200715.002													
J								Novel Optimization Based Hybrid Self-Organizing Map Classifiers for Iris Image Recognition	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Biometrics; Artificial neural network; hybrid classifier; Optimization; Iris	CNN	The concern over security in all fields has intensified over the years. The prefatory phase of providing security begins with authentication to provide access. In many scenarios, this authentication is provided by biometric systems. Moreover, the threat of pandemic has made the people to think of hygienic systems which are noninvasive. Iris image recognition is one such noninvasive biometric system that can provide automated authentication. Self-organizing map is an artificial neural network which helps in iris image recognition. This network has the ability to team the input features and perform classification. However, from the literature it is observed that the performance of this classifier has scope for refinement to yield better classification. In this paper, heterogeneous methods are adapted to improve the performance of the classifier for iris image recognition. The heterogeneous methods involve the application of Gravity Search Optimization, Teacher Learning Based Optimization, Whale Optimization and Gray Wolf Optimization in the training process of the self-organizing map classifier. This method was tested on iris images from IIT-Delhi database. The results of the experiment show that the proposed method performs better. (C) 2020 The Authors. Published hi Atlantis Press RV.																	1875-6891	1875-6883					2020	13	1					1048	1058		10.2991/ijcis.d.200721.001													
J								Comparison of Recent Metaheuristic Algorithms for Shape Detection in Images	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Metaheuristics; Shape detection; Image processing; Machine lemming	OPTIMIZATION ALGORITHM; CIRCLE DETECTION; SELECTION; ELLIPSE	Shape recognition in images represents one of the complex and hard-solving problems in computer vision due to its nonlinear, stochastic and incomplete nature. Classical image processing techniques have been normally used to solve this problem. Alternatively, shape recognition has also been conducted through metaheuristic algorithms. They have demonstrated to have a competitive performance in terms of robustness and accuracy. However, all of these schemes use old metaheuristic algorithms as the basis to identify geometrical structures in images. Original metaheuristic approaches experiment several limitations such as premature convergence and low diversity. Through the introduction of new models and evolutionary operators, recent metaheuristic methods have addressed these difficulties providing in general better results. This paper presents a comparative analysis on the application of five recent metaheuristic schemes to the shape recognition problem such as the Grey Wolf Optimizer (GWO), Whale Optimizer Algorithm (WOA), Crow Search Algorithm (CSA), Gravitational Search Algorithm (GSA) and Cuckoo Search (CS). Since such approaches have been successful in several new applications, the objective is to determine their efficiency when they face a complex problem such as shape detection. Numerical simulations, performed on a set of experiments composed of images With different difficulty levels, demonstrates the capacities of each approach. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1059	1071		10.2991/ijcis.d.200729.001													
J								Specific Types of q-Rung Picture Fuzzy Yager Aggregation Operators for Decision-Making	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										q-rung picture fuzzy numbers; Yager operators; Arithmetic; Geometric; Multi-attribute decision-making problems	FUNDAMENTAL PROPERTIES; SET	q-rung picture fuzzy sets can handle complex fuzzy and. impression information by changing a parameter q based on the different hesitation degree, and Yager per or is a useful aggregation technology that can control the uncertainty of valuating data from some experts and thus get intensive information in the process of decision-making. Thus, in this paper, we develop specific types of operators, namely, q-rung picture fuzzy Yager weighted average, q-rung picture fuzzy Yager ordered weighted average, q-rung picture fuzzy Yager hybrid weighted average, q-rung picture fuzzy Yager weighted geometric, q-rung picture fuzzy Yager ordered weighted geometric and q-rung picture fuzzy Yager hybrid weighted geometric operators. We propose q-rung picture fuzzy Yager aggregation operators to handle multiple attribute decision-making problems in a modernize way. Moreover, we discuss the effect of parameter on the decision-making results. To demonstrate the superiority and advantage of our proposed method, a comparison with existing methods is presented. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1072	1091		10.2991/ijcis.d.200717.001													
J								A Heuristic and ANN based Classification Model for Early Screening of Cervical Cancer	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS										Cervical cancer; SMOTE; SVM classttier; Backpropagation; Deep Learning	HPV	Cervical cancer is one of the most leading causes of mortality among women worldwide. This deadly disease could be prevented by vaccines and easily cured if detected at an early stage. Various researchers focus on providing methods for unambiguous results of screening tests for early diagnosis of cervical cancer and also on detecting stages of cervical cancer through Pap smear images of the cervix. Various socio-economic factors of women in underdeveloped countries limit the regular Pap smear test for screening of cervical cancer. It is pragmatic that the prediction on the likelihood of cervical cancer is not always possible based on the fewer inquiries from the patients and the data remain inadequate. Oversampling of the data is needed to any dataset for preprocessing the data and this is achieved by using Synthetic Minority Oversampling Technique (SMOTE). In the proposed work, chi-square, a filter-based feature selection method is used to select the attributes based on their correlation between feature and the class to remove the irrelevant attributes from the dataset. Further genetic-based feature selection is used to filter the best optimal features from the selected attributes. Linear Support Vector Machine (SVM) classifier is applied to the selected attributes from the genetic algorithm to aid in predicting the model through training and testing, resulting in an accuracy of 93.82%. Backpropagation, a deep learning method is used as a classification model for cervical cancer, resulting in an improved accuracy of 97.25%. The experimental results show the efficiency of the proposed model is better in comparison to the previous models in terms of accuracy. (C) 2020 The Authors. Published by Atlantis Press B.V.																	1875-6891	1875-6883					2020	13	1					1092	1100		10.2991/ijcis.d.200730.003													
