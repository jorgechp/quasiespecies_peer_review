PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Similarity Search for Dynamic Data Streams	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Heuristic algorithms; Hash functions; Approximation algorithms; Indexes; Measurement; Knowledge engineering; Data engineering; Dynamic streaming; locality-sensitive hashing; nearest neighbor searching		Nearest neighbor searching systems are an integral part of many online applications, including but not limited to pattern recognition, plagiarism detection, and recommender systems. With increasingly larger data sets, scalability has become an important issue. Many of the most space and running time efficient algorithms are based on locality-sensitive hashing. Here, we view the data set as an n by vertical bar U vertical bar matrix where each row corresponds to one of n users and the columns correspond to items drawn from a universe U. The de-facto standard approach to quickly answer nearest neighbor queries on such a data set is usually a form of min-hashing. Not only is min-hashing very fast, but it is also space efficient and can be implemented in many computational models aimed at dealing with large data sets such as MapReduce and streaming. However, a significant drawback is that minhashing and related methods are only able to handle insertions to user profiles and tend to perform poorly when items may be removed. We initiate the study of scalable locality-sensitive hashing (LSH) for fully dynamic data-streams. Specifically, using the Jaccard index as similarity measure, we design (1) a collaborative filtering mechanism maintainable in dynamic data streams and (2) a sketching algorithm for similarity estimation. Our algorithms have little overhead in terms of running time compared to previous LSH approaches for the insertion only case, and drastically outperform previous algorithms in case of deletions.																	1041-4347	1558-2191				NOV 1	2020	32	11					2241	2253		10.1109/TKDE.2019.2916858													
J								SURGE: Continuous Detection of Bursty Regions Over a Stream of Spatial Objects	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Surges; Real-time systems; Vehicles; Search problems; Monitoring; Mobile handsets; Spatial data; data stream; burst detection; region detection	ALGORITHM	With the proliferation of mobile devices and location-based services, continuous generation of massive volume of streaming spatial objects (i.e., geo-tagged data) opens up new opportunities to address real-world problems by analyzing them. In this paper, we present a novel continuous bursty region detection (SURGE) problem that aims to continuously detect a bursty region of a given size in a specified geographical area from a stream of spatial objects. Specifically, a bursty region shows maximumspike in the number of spatial objects in a given time window. The SURGE problem is useful in addressing several real-world challenges such as surge pricing problemin online transportation and disease outbreak detection. To solve the problem, we propose an exact solution and two approximate solutions, and the approximation ratio is 1-alpha/4 in terms of the burst score, where a is a parameter to control the burst score. We further extend these solutions to support detection of top-k bursty regions. Extensive experiments with real-world data are conducted to demonstrate the efficiency and effectiveness of our solutions.																	1041-4347	1558-2191				NOV 1	2020	32	11					2254	2268		10.1109/TKDE.2019.2915654													
J								Understanding Urban Dynamics via Context-Aware Tensor Factorization with Neighboring Regularization	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Urban areas; Data models; Global Positioning System; Trajectory; Public transportation; Sociology; Urban dynamics; tensor factorizations; urban planning; spatio-temporal pattern; GPS trajectory	PATTERNS; MOBILITY	Recent years have witnessed the world-wide emergence of mega-metropolises with incredibly huge populations. Understanding residents mobility patterns, or urban dynamics, thus becomes crucial for building modern smart cities. In this paper, we propose a Neighbor-Regularized and context-aware Non-negative Tensor Factorization model (NR-cNTF) to discover interpretable urban dynamics from urban heterogeneous data. Different from many existing studies concerned with prediction tasks via tensor completion, NR-cNTF focuses on gaining urban managerial insights from spatial, temporal, and spatio-temporal patterns. This is enabled by high-quality Tucker factorizations regularized by both POI-based urban contexts and geographically neighboring relations. NR-cNTF is also capable of unveiling long-term evolutions of urban dynamics via a pipeline initialization approach. We apply NR-cNTF to a real-life data set containing rich taxi GPS trajectories and POI records of Beijing. The results indicate: 1) NR-cNTF accurately captures four kinds of city rhythms and seventeen spatial communities; 2) the rapid development of Beijing, epitomized by the CBD area, indeed intensifies the job-housing imbalance; 3) the southern areas with recent government investments have shown more healthy development tendency. Finally, NR-cNTF is compared with some baselines on traffic prediction, which further justifies the importance of urban contexts awareness and neighboring regulations.																	1041-4347	1558-2191				NOV 1	2020	32	11					2269	2283		10.1109/TKDE.2019.2915231													
J								A Functional Representation for Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Strain; Linear programming; Time complexity; Measurement; Optimization; Pattern matching; Graph matching; functional representation; Frank-Wolfe method; geometric deformation	ALGORITHM	Graph matching is an important and persistent problem in computer vision and pattern recognition for finding node-to-node correspondence between graphs. However, graph matching that incorporates pairwise constraints can be formulated as a quadratic assignment problem (QAP), which is NP-complete and results in intrinsic computational difficulties. This paper presents a functional representation for graph matching (FRGM) that aims to provide more geometric insights on the problem and reduce the space and time complexities. To achieve these goals, we represent each graph by a linear function space equipped with a functional such as inner product or metric, that has an explicit geometric meaning. Consequently, the correspondence matrix between graphs can be represented as a linear representation map. Furthermore, this map can be reformulated as a new parameterization for matching graphs in Euclidean space such that it is consistent with graphs under rigid or nonrigid deformations. This allows us to estimate the correspondence matrix and geometric deformations simultaneously. We use the representation of edge-attributes rather than the affinity matrix to reduce the space complexity and propose an efficient optimization strategy to reduce the time complexity. The experimental results on both synthetic and real-world datasets show that the FRGM can achieve state-of-the-art performance.																	0162-8828	1939-3539				NOV	2020	42	11					2737	2754		10.1109/TPAMI.2019.2919308													
J								Context Based Emotion Recognition Using EMOTIC Dataset	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Emotion recognition; Databases; Face; Face recognition; Observers; Computer vision; Emotion recognition; affective computing; pattern recognition	FACIAL EXPRESSIONS; FACE	In our everyday lives and social interactions we often try to perceive the emotional states of people. There has been a lot of research in providing machines with a similar capacity of recognizing emotions. From a computer vision perspective, most of the previous efforts have been focusing in analyzing the facial expressions and, in some cases, also the body pose. Some of these methods work remarkably well in specific settings. However, their performance is limited in natural, unconstrained environments. Psychological studies show that the scene context, in addition to facial expression and body pose, provides important information to our perception of people's emotions. However, the processing of the context for automatic emotion recognition has not been explored in depth, partly due to the lack of proper data. In this paper we present EMOTIC, a dataset of images of people in a diverse set of natural situations, annotated with their apparent emotion. The EMOTIC dataset combines two different types of emotion representation: (1) a set of 26 discrete categories, and (2) the continuous dimensions Valence, Arousal, and Dominance. We also present a detailed statistical and algorithmic analysis of the dataset along with annotators' agreement analysis. Using the EMOTIC dataset we train different CNN models for emotion recognition, combining the information of the bounding box containing the person with the contextual information extracted from the scene. Our results show how scene context provides important information to automatically recognize emotional states and motivate further research in this direction.																	0162-8828	1939-3539				NOV	2020	42	11					2755	2766		10.1109/TPAMI.2019.2916866													
J								DART: Distribution Aware Retinal Transform for Event-Based Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Feature extraction; Object tracking; Object recognition; Shape; Retina; Event-based vision; log-polar grids; bag-of-words model; object recognition; object tracking; feature matching	FEATURES; TRACKING; BAG; CATEGORIZATION	We introduce a generic visual descriptor, termed as distribution aware retinal transform (DART), that encodes the structural context using log-polar grids for event cameras. The DART descriptor is applied to four different problems, namely object classification, tracking, detection and feature matching: (1) The DART features are directly employed as local descriptors in a bag-of-words classification framework and testing is carried out on four standard event-based object datasets (N-MNIST, MNIST-DVS, CIFAR10-DVS, NCaltech-101); (2) Extending the classification system, tracking is demonstrated using two key novelties: (i) Statistical bootstrapping is leveraged with online learning for overcoming the low-sample problem during the one-shot learning of the tracker, (ii) Cyclical shifts are induced in the log-polar domain of the DART descriptor to achieve robustness to object scale and rotation variations; (3) To solve the long-term object tracking problem, an object detector is designed using the principle of cluster majority voting. The detection scheme is then combined with the tracker to result in a high intersection-over-union score with augmented ground truth annotations on the publicly available event camera dataset; (4) Finally, the event context encoded by DART greatly simplifies the feature correspondence problem, especially for spatio-temporal slices far apart in time, which has not been explicitly tackled in the event-based vision domain.																	0162-8828	1939-3539				NOV	2020	42	11					2767	2780		10.1109/TPAMI.2019.2919301													
J								Deep Imbalanced Learning for Face Recognition and Attribute Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Face; Face recognition; Training; Task analysis; Protocols; Semantics; Image segmentation; Imbalanced learning; deep convolutional neural networks; face recognition; attribute prediction	CLASSIFICATION; SMOTE	Data for face analysis often exhibit highly-skewed class distribution, i.e., most data belong to a few majority classes, while the minority classes only contain a scarce amount of instances. To mitigate this issue, contemporary deep learning methods typically follow classic strategies such as class re-sampling or cost-sensitive training. In this paper, we conduct extensive and systematic experiments to validate the effectiveness of these classic schemes for representation learning on class-imbalanced data. We further demonstrate that more discriminative deep representation can be learned by enforcing a deep network to maintain inter-cluster margins both within and between classes. This tight constraint effectively reduces the class imbalance inherent in the local data neighborhood, thus carving much more balanced class boundaries locally. We show that it is easy to deploy angular margins between the cluster distributions on a hypersphere manifold. Such learned Cluster-based Large Margin Local Embedding (CLMLE), when combined with a simple k-nearest cluster algorithm, shows significant improvements in accuracy over existing methods on both face recognition and face attribute prediction tasks that exhibit imbalanced class distribution.																	0162-8828	1939-3539				NOV	2020	42	11					2781	2794		10.1109/TPAMI.2019.2914680													
J								Direction-Aware Spatial Context Features for Shadow Detection and Removal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Feature extraction; Image color analysis; Training; Semantics; Benchmark testing; Recurrent neural networks; Shadow detection; shadow removal; spatial context features; deep neural network	DECOMPOSITION	Shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics. This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner. To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN. By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting and removing shadows. This design is developed into the DSC module and embedded in a convolutional neural network (CNN) to learn the DSC features at different levels. Moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs. We employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method. Experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.																	0162-8828	1939-3539				NOV	2020	42	11					2795	2808		10.1109/TPAMI.2019.2919616													
J								Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Face; Image resolution; Image reconstruction; Optimization; Reinforcement learning; Visualization; Image restoration; Face hallucination; reinforcement learning; recurrent neural network	IMAGE SUPERRESOLUTION; ALIGNMENT	Face hallucination is a domain-specific super-resolution problem that aims to generate a high-resolution (HR) face image from a low-resolution (LR) input. In contrast to the existing patch-wise super-resolution models that divide a face image into regular patches and independently apply LR to HR mapping to each patch, we implement deep reinforcement learning and develop a novel attention-aware face hallucination (Attention-FH) framework, which recurrently learns to attend a sequence of patches and performs facial part enhancement by fully exploiting the global interdependency of the image. Specifically, our proposed framework incorporates two components: a recurrent policy network for dynamically specifying a new attended region at each time step based on the status of the super-resolved image and the past attended region sequence, and a local enhancement network for selected patch hallucination and global state updating. The Attention-FH model jointly learns the recurrent policy network and local enhancement network through maximizing a long-term reward that reflects the hallucination result with respect to the whole HR image. Extensive experiments demonstrate that our Attention-FH significantly outperforms the state-of-the-art methods on in-the-wild face images with large pose and illumination variations.																	0162-8828	1939-3539				NOV	2020	42	11					2809	2824		10.1109/TPAMI.2019.2915301													
J								H-Patches: A Benchmark and Evaluation of Handcrafted and Learned Local Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Local features; feature descriptors; image matching; patch classification	IMAGE DESCRIPTORS; REPRESENTATION; PERFORMANCE	In this paper, a novel benchmark is introduced for evaluating local image descriptors. We demonstrate limitations of the commonly used datasets and evaluation protocols, that lead to ambiguities and contradictory results in the literature. Furthermore, these benchmarks are nearly saturated due to the recent improvements in local descriptors obtained by learning from large annotated datasets. To address these issues, we introduce a new large dataset suitable for training and testing modern descriptors, together with strictly defined evaluation protocols in several tasks such as matching, retrieval and verification. This allows for more realistic, thus more reliable comparisons in different application scenarios. We evaluate the performance of several state-of-the-art descriptors and analyse their properties. We show that a simple normalisation of traditional hand-crafted descriptors is able to boost their performance to the level of deep learning based descriptors once realistic benchmarks are considered. Additionally we specify a protocol for learning and evaluating using cross validation. We show that when training state-of-the-art descriptors on this dataset, the traditional verification task is almost entirely saturated.																	0162-8828	1939-3539				NOV	2020	42	11					2825	2841		10.1109/TPAMI.2019.2915233													
J								Learning Low-Dimensional Temporal Representations with Latent Alignments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Feature extraction; Hidden Markov models; Training; Motion segmentation; Dimensionality reduction; Three-dimensional displays; Data models; Dimensionality reduction; latent alignment; temporal sequences; discriminant analysis	ACTION RECOGNITION; DISCRIMINANT-ANALYSIS; REDUCTION; MODELS; SEGMENTATION; POSE	Low-dimensional discriminative representations enhance machine learning methods in both performance and complexity. This has motivated supervised dimensionality reduction (DR), which transforms high-dimensional data into a discriminative subspace. Most DR methods require data to be i.i.d. However, in some domains, data naturally appear in sequences, where the observations are temporally correlated. We propose a DR method, namely, latent temporal linear discriminant analysis (LT-LDA), to learn low-dimensional temporal representations. We construct the separability among sequence classes by lifting the holistic temporal structures, which are established based on temporal alignments and may change in different subspaces. We jointly learn the subspace and the associated latent alignments by optimizing an objective that favors easily separable temporal structures. We show that this objective is connected to the inference of alignments and thus allows for an iterative solution. We provide both theoretical insight and empirical evaluations on several real-world sequence datasets to show the applicability of our method.																	0162-8828	1939-3539				NOV	2020	42	11					2842	2857		10.1109/TPAMI.2019.2919303													
J								Learning Visual Instance Retrieval from Failure: Efficient Online Local Metric Adaptation from Negative Samples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Measurement; Probes; Visualization; Testing; Feature extraction; Training; Image retrieval; Visual instance retrieval; online metric adaptation; hard negative samples	PERSON REIDENTIFICATION; NEURAL-NETWORK	Existing visual instance retrieval (VIR) approaches attempt to learn a faithful global matching metric or discriminative feature embedding offline to cover enormous visual appearance variations, so as to directly use it online on various unseen probes for retrieval. However, their requirement for a huge set of positive training pairs is very demanding in practice and the performance is largely constrained for the unseen testing samples due to the severe data shifting issue. In contrast, this paper advocates a different paradigm: part of the learning can be performed online but with nominal costs, so as to achieve online metric adaptation for different query probes. By exploiting easily-available negative samples, we propose a novel solution to achieve the optimal local metric adaptation effectively and efficiently. The insight of our method is the local hard negative samples can actually provide tight constraints to fine tune the metric locally. Our local metric adaptation method is generally applicable to be used on top of any offline-learned baselines. In addition, this paper gives in-depth theoretical analyses of the proposed method to guarantee the reduction of the classification error both asymptotically and practically. Extensive experiments on various VIR tasks have confirmed our effectiveness and superiority.																	0162-8828	1939-3539				NOV	2020	42	11					2858	2873		10.1109/TPAMI.2019.2918208													
J								Local-Aggregation Graph Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Convolution; Neural networks; Message passing; Laplace equations; Aggregates; Pattern recognition; Function approximation; Local-aggregation function; local-aggregation graph neural network; non-Euclidean structured signal		Convolutional neural networks (CNNs) provide a dramatically powerful class of models, but are subject to traditional convolution that can merely aggregate permutation-ordered and dimension-equal local inputs. It causes that CNNs are allowed to only manage signals on Euclidean or grid-like domains (e.g., images), not ones on non-Euclidean or graph domains (e.g., traffic networks). To eliminate this limitation, we develop a local-aggregation function, a sharable nonlinear operation, to aggregate permutation-unordered and dimension-unequal local inputs on non-Euclidean domains. In the context of the function approximation theory, the local-aggregation function is parameterized with a group of orthonormal polynomials in an effective and efficient manner. By replacing the traditional convolution in CNNs with the parameterized local-aggregation function, Local-Aggregation Graph Networks (LAGNs) are readily established, which enable to fit nonlinear functions without activation functions and can be expediently trained with the standard back-propagation. Extensive experiments on various datasets strongly demonstrate the effectiveness and efficiency of LAGNs, leading to superior performance on numerous pattern recognition and machine learning tasks, including text categorization, molecular activity detection, taxi flow prediction, and image classification.																	0162-8828	1939-3539				NOV	2020	42	11					2874	2886		10.1109/TPAMI.2019.2915591													
J								Matched Filters for Noisy Induced Subgraph Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Noise measurement; Approximation algorithms; Correlation; Social networking (online); Computer vision; Stochastic processes; Symmetric matrices; Multiple graph inference; subgraph detection; graph matching	GRAPH; ALGORITHM	The problem of finding the vertex correspondence between two noisy graphs with different number of vertices where the smaller graph is still large has many applications in social networks, neuroscience, and computer vision. We propose a solution to this problem via a graph matching matched filter: centering and padding the smaller adjacency matrix and applying graph matching methods to align it to the larger network. The centering and padding schemes can be incorporated into any algorithm that matches using adjacency matrices. Under a statistical model for correlated pairs of graphs, which yields a noisy copy of the small graph within the larger graph, the resulting optimization problem can be guaranteed to recover the true vertex correspondence between the networks. However, there are currently no efficient algorithms for solving this problem. To illustrate the possibilities and challenges of such problems, we use an algorithm that can exploit a partially known correspondence and show via varied simulations and applications to Drosophila and human connectomes that this approach can achieve good performance.																	0162-8828	1939-3539				NOV	2020	42	11					2887	2900		10.1109/TPAMI.2019.2914651													
J								MOSES: A Streaming Algorithm for Linear Dimensionality Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Dimensionality reduction; Estimation; Optimization; Approximation algorithms; Principal component analysis; Ear; Principal component analysis; linear dimensionality reduction; subspace identification; streaming algorithms; non-convex optimisation	FREQUENT DIRECTIONS; MATRIX; SUBSPACE; APPROXIMATION; RECOVERY; PCA	This paper introduces Memory-limited Online Subspace Estimation Scheme (MOSES) for both estimating the principal components of streaming data and reducing its dimension. More specifically, in various applications such as sensor networks, the data vectors are presented sequentially to a user who has limited storage and processing time available. Applied to such problems, MOSES can provide a running estimate of leading principal components of the data that has arrived so far and also reduce its dimension. MOSES generalises the popular incremental Singular Vale Decomposition (iSVD) to handle thin blocks of data, rather than just vectors. This minor generalisation in part allows us to complement MOSES with a comprehensive statistical analysis, thus providing the first theoretically-sound variant of iSVD, which has been lacking despite the empirical success of this method. This generalisation also enables us to concretely interpret MOSES as an approximate solver for the underlying non-convex optimisation program. We find that MOSES consistently surpasses the state of the art in our numerical experiments with both synthetic and real-world datasets, while being computationally inexpensive.																	0162-8828	1939-3539				NOV	2020	42	11					2901	2911		10.1109/TPAMI.2019.2919597													
J								Recomputation of the Dense Layers for Performance Improvement of DCNN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Training; Mathematical model; Optimization; Neurons; Convolutional neural networks; Deep learning; Deep convolutional neural networks; non-iterative learning; image object recognition; deep learning	EXTREME LEARNING-MACHINE; SCENE; RECOGNITION; NETWORK; MODEL	Gradient descent optimization of learning has become a paradigm for training deep convolutional neural networks (DCNN). However, utilizing other learning strategies in the training process of the DCNN has rarely been explored by the deep learning (DL) community. This serves as the motivation to introduce a non-iterative learning strategy to retrain neurons at the top dense or fully connected (FC) layers of DCNN, resulting in, higher performance. The proposed method exploits the Moore-Penrose Inverse to pull back the current residual error to each FC layer, generating well-generalized features. Further, the weights of each FC layers are recomputed according to the Moore-Penrose Inverse. We evaluate the proposed approach on six most widely accepted object recognition benchmark datasets: Scene-15, CIFAR-10, CIFAR-100, SUN-397, Places365, and ImageNet. The experimental results show that the proposed method obtains improvements over 30 state-of-the-art methods. Interestingly, it also indicates that any DCNN with the proposed method can provide better performance than the same network with its original Backpropagation (BP)-based training.																	0162-8828	1939-3539				NOV	2020	42	11					2912	2925		10.1109/TPAMI.2019.2917685													
J								Semantic Face Hallucination: Super-Resolving Very Low-Resolution Face Images with Supplementary Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Face; Spatial resolution; Image reconstruction; Semantics; Facial features; Feature extraction; Face; super-resolution; hallucination; attribute	SUPERRESOLUTION; MODELS	Given a tiny face image, existing face hallucination methods aim at super-resolving its high-resolution (HR) counterpart by learning a mapping from an exemplary dataset. Since a low-resolution (LR) input patch may correspond to many HR candidate patches, this ambiguity may lead to distorted HR facial details and wrong attributes such as gender reversal and rejuvenation. An LR input contains low-frequency facial components of its HR version while its residual face image, defined as the difference between the HR ground-truth and interpolated LR images, contains the missing high-frequency facial details. We demonstrate that supplementing residual images or feature maps with additional facial attribute information can significantly reduce the ambiguity in face super-resolution. To explore this idea, we develop an attribute-embedded upsampling network, which consists of an upsampling network and a discriminative network. The upsampling network is composed of an autoencoder with skip-connections, which incorporates facial attribute vectors into the residual features of LR inputs at the bottleneck of the autoencoder, and deconvolutional layers used for upsampling. The discriminative network is designed to examine whether super-resolved faces contain the desired attributes or not and then its loss is used for updating the upsampling network. In this manner, we can super-resolve tiny (16x16 pixels) unaligned face images with a large upscaling factor of 8x while reducing the uncertainty of one-to-many mappings remarkably. By conducting extensive evaluations on a large-scale dataset, we demonstrate that our method achieves superior face hallucination results and outperforms the state-of-the-art.																	0162-8828	1939-3539				NOV	2020	42	11					2926	2943		10.1109/TPAMI.2019.2916881													
J								Toward Bridging the Simulated-to-Real Gap: Benchmarking Super-Resolution on Real Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Benchmark testing; Databases; Spatial resolution; Observers; Cameras; Hardware; Super-resolution; ground truth; simulated-to-real gap; benchmark; quantitative evaluation; observer study	IMAGE QUALITY ASSESSMENT; RECONSTRUCTION; ALGORITHMS; LIMITS	Capturing ground truth data to benchmark super-resolution (SR) is challenging. Therefore, current quantitative studies are mainly evaluated on simulated data artificially sampled from ground truth images. We argue that such evaluations overestimate the actual performance of SR methods compared to their behavior on real images. Toward bridging this simulated-to-real gap, we introduce the Super-Resolution Erlangen (SupER) database, the first comprehensive laboratory SR database of all-real acquisitions with pixel-wise ground truth. It consists of more than 80k images of 14 scenes combining different facets: CMOS sensor noise, real sampling at four resolution levels, nine scene motion types, two photometric conditions, and lossy video coding at five levels. As such, the database exceeds existing benchmarks by an order of magnitude in quality and quantity. This paper also benchmarks 19 popular single-image and multi-frame algorithms on our data. The benchmark comprises a quantitative study by exploiting ground truth data and qualitative evaluations in a large-scale observer study. We also rigorously investigate agreements between both evaluations from a statistical perspective. One interesting result is that top-performing methods on simulated data may be surpassed by others on real data. Our insights can spur further algorithm development, and the publicy available dataset can foster future evaluations.																	0162-8828	1939-3539				NOV	2020	42	11					2944	2959		10.1109/TPAMI.2019.2917037													
J								Multivariate Extension of Matrix-Based Renyi's alpha-Order Entropy Functional	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Renyi's alpha-order entropy functional; multivariate information quantities; feature selection	FEATURE-SELECTION; MUTUAL INFORMATION	The matrix-based Renyi's alpha-order entropy functional was recently introduced using the normalized eigenspectrum of a Hermitian matrix of the projected data in a reproducing kernel Hilbert space (RKHS). However, the current theory in the matrix-based Renyi's alpha-order entropy functional only defines the entropy of a single variable or mutual information between two random variables. In information theory and machine learning communities, one is also frequently interested in multivariate information quantities, such as the multivariate joint entropy and different interactive quantities among multiple variables. In this paper, we first define the matrix-based Renyi's alpha-order joint entropy among multiple variables. We then show how this definition can ease the estimation of various information quantities that measure the interactions among multiple variables, such as interactive information and total correlation. We finally present an application to feature selection to show how our definition provides a simple yet powerful way to estimate a widely-acknowledged intractable quantity from data. A real example on hyperspectral image (HSI) band selection is also provided.																	0162-8828	1939-3539				NOV	2020	42	11					2960	2966		10.1109/TPAMI.2019.2932976													
J								An Experimental Analysis on Propeller Performance in a Climate-controlled Facility	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS										Propeller performance; Unmanned aircraft system test bench; Harsh environmental coditions; Blade element theory		Despite many commercial applications make extensive use of Unmanned Aircraft Systems (UAS), there is still lack of published data about their performance under unconventional weather conditions. In the last years, multirotors and fixed wing vehicles, commonly referred to as drones, have been studied in wind environments so that stability and controllability have been improved. However, other important weather variables have impact on UAS performance and they should be properly investigated for a deeper understanding of such vehicles. The primary objective of our study is the preliminary characterization of a propeller in a climate-controlled chamber. Mechanical and electrical data have been measured while testing the propeller at low pressure and cold temperatures. Test results point out that thrust and electric power are strongly affected by air density. A comparison between the experimental data and the results of the Blade Element Theory is carried out to assess the theory capability to estimate thrust in unconventional environments. The overlap between experimental data and theory computation is appropriate despite geometrical uncertainties and corroborate the need of a reliable aerodynamic database. Propeller performance data under unconventional atmospheres will be leveraged to improve UAS design, propulsion system modelling as well as provide guidelines to certify operations in extreme environments.																	0921-0296	1573-0409				NOV	2020	100	2					505	517		10.1007/s10846-019-01132-9													
J								Deep feature fusion through adaptive discriminative metric learning for scene recognition	INFORMATION FUSION										Deep feature fusion; Adaptive discriminative metric learning; Scene recognition	IMAGE CLASSIFICATION; SCALE	With the development of deep learning techniques, fusion of deep features has demonstrated the powerful capability to improve recognition performance. However, most researchers directly fuse different deep feature vectors without considering the complementary and consistent information among them. In this paper, from the view-point of metric learning, we propose a novel deep feature fusion method, called deep feature fusion through adaptive discriminative metric learning (DFF-ADML), to explore the complementary and consistent information for scene recognition. Concretely, we formulate an adaptive discriminative metric learning problem, which not only fully exploits discriminative information from each deep feature vector, but also adaptively fuses complementary information from different deep feature vectors. Besides, we map different deep feature vectors of the same image into a common space by different linear transformations, such that the consistent information can be preserved as much as possible. Moreover, DFF-ADML is extended to a kernelized version. Extensive experiments on both natural scene and remote sensing scene datasets demonstrate the superiorly and robustness of the proposed deep feature fusion method.																	1566-2535	1872-6305				NOV	2020	63						1	12		10.1016/j.inffus.2020.05.005													
J								A trust-similarity analysis-based clustering method for large-scale group decision-making under a social network	INFORMATION FUSION										Trust-similarity analysis (TSA); Clustering method; Large-scale group decision-making (LSGDM); Social network analysis (SNA); Trust relationship; Opinion similarity	CONSENSUS REACHING PROCESS; MODEL; INFORMATION; CONFIDENCE; TOPSIS	Large-scale group decision-making (LSGDM) under a social network context has attracted much attention in the field of decision science. The clustering of individual opinions and the handling of trust relationships are the main research topics. Opinion similarity and trust relationship are considered to be two important measurement attributes for implementing clustering. Traditional clustering methods often use a single attribute to divide the original group without requiring a combination of the above two attributes. However, these two attributes play different roles in the clustering process, insofar as opinion similarity is used to measure the level of difference among individual opinions, whereas the trust relationship represents the trustworthiness of decision makers. This paper develops a trust-similarity analysis (TSA)-based clustering method to manage the clustering operation in LSGDM events under a social network context. First, the trust-similarity matrix is established to collectively describe the decision information. Second, all measurement attribute values are mapped to a trust-similarity plot from which the joint threshold can be calculated. Finally, a TSA-based clustering method is proposed that considers the attributes of opinion similarity and trust relationship and that allocates their importance to achieve specific clustering objectives. The numerical experiment and comparative analysis reveal the feasibility and advantages of the proposed method.																	1566-2535	1872-6305				NOV	2020	63						13	29		10.1016/j.inffus.2020.05.004													
J								A dynamic ensemble outlier detection model based on an adaptive k-nearest neighbor rule	INFORMATION FUSION										Outlier detection; Ensemble learning; Dynamic classifier selection; Adaptive k-nearest neighbor	ONE-CLASS CLASSIFIERS; MULTIPLE CLASSIFIERS; SELECTION; CLASSIFICATION; SYSTEMS; COMPETENCE; ALGORITHMS; SUPPORT; FUSION	Ensembles of outlier detectors are drawing increasing attentions recently, in spite of the difficulty on developing ensembles in the framework of unsupervised learning. We have noted that existing outlier ensembles often use certain fusion rules (e.g. majority voting) to aggregate individual learners. Theoretically, these individuals are assumed to be error-independent so that single models can be outperformed by the ensemble. However, it is of great difficulty to satisfy this assumption in practical applications. By dynamic selecting more competent individual(s) for each test pattern, this problem can be alleviated effectively. Inspired by this idea, this paper proposes a dynamic ensemble outlier detection model using one-class classifiers as base learners. As the competences of base detectors are estimated totally on data points in the validation set, its impact on the selection is significant. In order to achieve an efficient selection, we propose an adaptive k-nearest neighbor (KNN) rule, instead of traditional KNN algorithm, to constitute the validation set for each test pattern. Our adaptive KNN rule firstly uses algorithm support vector data description (SVDD) to mine the local area where class conditional probabilities are not constant in terms of the corresponding test pattern. Competences estimated with neighbor patterns in this area should thus be more accurate than that by traditional KNN rule. A probabilistic model that uses posterior probabilities of one-class classifiers is used then to estimate classifier competences. We present experimental evidence of the detection performance improvement over single models and over a variety of static ensemble models, by using data sets from UCI repository.																	1566-2535	1872-6305				NOV	2020	63						30	40		10.1016/j.inffus.2020.05.001													
J								A scheduler for SCADA-based multi-source fusion systems	INFORMATION FUSION										Multi-source fusion; SCADA systems; Schedulers	RESOURCE FAIR ALLOCATION; INFORMATION FUSION; IMPLEMENTATION; PERFORMANCE; ALGORITHMS; MULTICORE; SERVICES; DESIGN; MODEL	In this article, we report on our experience regarding devising, implementing, and deploying a scheduler for multi-source fusion in the context of SCADA systems (Supervisory Control and Data Acquisition). They are challenging because they commonly rely on low-end boards with very limited computing, memory, and storage capabilities, but have to run hundreds if not thousands of agents that co-ordinate by means of complex multi-way rendezvouses. Our work was carried out in the context of a solar plant in which we could easily confirm that not scheduling the rendez-vouses fairly may easily drive the system into as many as 3 779.10 critical-failure states per hour, whereas a straightforward solution to the problem can reduce the figure to 1 094.76 critical-failure states per hour. Unfortunately, that is far from zero, which is the ideal number. In the literature, there are several proposals to deal with this problem, but most of them could not be adapted to our context, namely: some of them can deal with two-way rendez-vouses only, whereas ours involve an average of 12.89 agents; others require to instrument the agents, but many of them are hardware devices that cannot be modified; a few others cannot work with rendez-vouses that can get intermittently enabled and disabled along an execution, which makes them of little interest in our context; and some require to use shared memory, which is an advanced hardware feature that is not supported by our low-end computing boards. The two proposals that we managed to adapt were not efficient enough in our context since they led to an average of 1 102.77 and 1 458.65 critical-failure states per hour, respectively. That motivated us to work on a new proposal that does not have any of the previous problems. It relies on a incremental approach that was implemented very efficiently using bounded counters and queues. Furthermore, the experimental results and the corresponding statistical analysis confirm that it works very well in practice.																	1566-2535	1872-6305				NOV	2020	63						41	55		10.1016/j.inffus.2020.05.007													
J								Distributed optimal linear fusion estimators	INFORMATION FUSION										Multi-sensor system; Distributed linear fusion estimation; Steady-state estimator; Cross-covariance matrix; Feedback	STOCHASTIC UNCERTAIN SYSTEMS; MULTISENSOR SYSTEMS; NETWORKED SYSTEMS; STATE ESTIMATION; FILTER; SCALARS; SENSORS	This paper is concerned with the distributed information fusion estimation problem in multi-sensor environments. A universal distributed optimal linear fusion estimation (DOLFE) algorithm, which has a Kalman-type structure with matrix gains, is presented under the linear unbiased minimum variance criterion. To reduce the computational burden, two suboptimal linear fusion estimation algorithms with diagonal-matrix gains and scalar gains are also presented. Based on the proposed DOLFE algorithm, a distributed optimal linear fusion filter (DOLFF) is presented for multi-sensor linear discrete-time stochastic systems. It has better accuracy than that based on the matrix-weighted fusion of local estimators but worse accuracy than the centralized fusion filter (CFF). The stability and steady-state property of the proposed DOLFF are analyzed. Then, the corresponding multi-step predictor and smoother are also developed based on DOLFF. To obtain the distributed fusion estimators, some estimation error cross-covariance matrices that are used to compute the gains are derived. At last, distributed optimal linear fusion estimators with feedback are also presented. Furthermore, it is strictly proved that the proposed distributed optimal linear fusion filter with feedback (DOLFFWF) has the same accuracy as the CFF. Two simulation examples show the effectiveness of the proposed algorithms.																	1566-2535	1872-6305				NOV	2020	63						56	73		10.1016/j.inffus.2020.05.006													
J								Managing classification-based consensus in social network group decision making: An optimization-based approach with minimum information loss	INFORMATION FUSION										Group decision making; Consensus; Alternative classification; Social network; Minimum information loss; Optimization model	PERSONALIZED INDIVIDUAL SEMANTICS; PREFERENCE RELATIONS; MODEL; COST; TRUST; CONSISTENCY; ADJUSTMENT; MECHANISM	This study proposes a classification-based consensus framework in social network group decision making, which aims to classify alternatives into several ordinal classes from best to worst. In the classification-based consensus framework, a maximum consensus-based optimization model is devised to determine the weight of decision makers by linearly combining three reliable sources: in-degree centrality, consistency and similarity indexes. This is done by maximizing the consensus level among decision makers regarding the collective classification of alternatives. Following this, a minimum information loss-based optimization model is constructed to generate the consensual collective classification of alternatives. It seeks to minimize the information loss between the additive preference relations provided by decision makers and their preference vectors. Particularly, the proposed optimization models are converted into 0-1 mixed linear programming models to easily find their optimal solutions. Finally, a numerical example and a detailed comparison analysis are provided to show the effectiveness of the proposed approach.																	1566-2535	1872-6305				NOV	2020	63						74	87		10.1016/j.inffus.2020.05.008													
J								The four dimensions of social network analysis: An overview of research methods, applications, and software tools	INFORMATION FUSION										Social network analysis; Social media mining; Social data visualization; Data science; Big data	WORD-OF-MOUTH; BIG DATA; SENTIMENT ANALYSIS; FAKE NEWS; INFORMATION DIFFUSION; CUSTOMER ENGAGEMENT; COMMUNITY STRUCTURE; BRAND RELATIONSHIPS; USER INTERESTS; MEDIA	Social network based applications have experienced exponential growth in recent years. One of the reasons for this rise is that this application domain offers a particularly fertile place to test and develop the most advanced computational techniques to extract valuable information from the Web. The main contribution of this work is three-fold: (1) we provide an up-to-date literature review of the state of the art on social network analysis (SNA); (2) we propose a set of new metrics based on four essential features (or dimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of popular SNA tools and frameworks. We have also performed a scientometric study to detect the most active research areas and application domains in this area. This work proposes the definition of four different dimensions, namely Pattern & Knowledge discovery, Information Fusion & Integration, Scalability, and Visualization, which are used to define a set of new metrics (termed degrees) in order to evaluate the different software tools and frameworks of SNA (a set of 20 SNA-software tools are analyzed and ranked following previous metrics). These dimensions, together with the defined degrees, allow evaluating and measure the maturity of social network technologies, looking for both a quantitative assessment of them, as to shed light to the challenges and future trends in this active area.																	1566-2535	1872-6305				NOV	2020	63						88	120		10.1016/j.inffus.2020.05.009													
J								Multi-user activity recognition: Challenges and opportunities	INFORMATION FUSION										Multi-user activity recognition; Group recognition; Data fusion; Collaboration	RESIDENT ACTIVITY RECOGNITION; CONDITIONAL RANDOM-FIELDS; MODELS; FRAMEWORK; TRACKING; DOPPLER; FUSION; RADAR; HOME	Human activity recognition has attracted enormous research interest thanks to its fundamental importance in several domains spanning from health-care to security, safety, and entertainment. Robust and consolidated literature focused on the study of activities performed by single individuals, with a great variety of approaches in terms of sensing modalities, recognition techniques, a specific set of recognized activities, and final application objectives. However, much less research attention has been devoted to scenarios in which multiple people perform individual or joint actions and activities forming groups to achieve given common goals. This problem is often referred to as multi-user activity recognition. With the advent of the Internet-of-Things, smart objects are being pervasively spread in the environment and worn on the human body, enabling contextual and distributed recognition of group and multi-user activities. Therefore, this survey discusses clear motivations and advantages of multi-user activity recognition based on sensing methods, recognition approaches, and practical applications with attention to related data fusion challenges and techniques. By identifying the critical aspects of this multi-faceted problem, the survey aims to provide a systematic categorization and comparison framework of the state-of-the-art that drives the discussion to important open research challenges and future directions.																	1566-2535	1872-6305				NOV	2020	63						121	135		10.1016/j.inffus.2020.06.004													
J								Real evaluation for designing sensor fusion in UAV platforms	INFORMATION FUSION										UAVS sensor fusion; EKF; Real data analysis; System design	TRAJECTORY RECONSTRUCTION; NAVIGATION; GNSS; LOCALIZATION	Evaluation of UAV systems is mostly based on simulation tools that are manually configured to define the trajectory (ground truth trajectory) for comparing with the system output. In this work, the authors present an original method to evaluate the performance of UAV platform in real situations without considering simulations. The proposed evaluation methodology allows calculating the system accuracy and robustness with a considerable number of samples, accumulating the performance of different missions in the same conditions. The main innovation is an alternative evaluation for designing sensor fusion parameters using real performance indicators of navigation accuracy in UAVs based on a commercially available flight controller and peripherals. This methodology and selected performance indicators allow to select the best parameters for the fusion system of a determined configuration of sensors and a predefined real mission not requiring ground truth. The selected platform is described highlighting the available sensors and data processing software, and the experimental methodology is proposed to characterize the sensor data fusion output. The results show in detail the presented performance metrics for a set of trajectories in order to determine the best choice of parameters using quality measurements of navigation output.																	1566-2535	1872-6305				NOV	2020	63						136	152		10.1016/j.inffus.2020.06.003													
J								Attributed heterogeneous network fusion via collaborative matrix tri-factorization	INFORMATION FUSION										Attributed heterogeneous networks; Matrix factorization; Data fusion; Insufficient relations; LncRNA-disease associations	LONG NONCODING RNAS; LNCRNA; PREDICTION; PROMOTES	Heterogeneous network based data fusion can encode diverse inter- and intra-relations between objects, and has been sparking increasing attention in recent years. Matrix factorization based data fusion models have been invented to fuse multiple data sources. However, these models generally suffer from the widely-witnessed insufficient relations between nodes and from information loss when heterogeneous attributes of diverse network nodes are transformed into ad-hoc homologous networks for fusion. In this paper, we introduce a general data fusion model called Attributed Heterogeneous Network Fusion (AHNF). AHNF firstly constructs an attributed heterogeneous network composed with different types of nodes and the diverse attribute vectors of these nodes. It uses indicator matrices to differentiate the observed inter-relations from the latent ones, and thus reduces the impact of insufficient relations between nodes. Next, it collaboratively factorizes multiple adjacency matrices and attribute data matrices of the heterogeneous network into low-rank matrices to explore the latent relations between these nodes. In this way, both the network topology and diverse attributes of nodes are fused in a coordinated fashion. Finally, it uses the optimized low-rank matrices to approximate the target relational data matrix of objects and to effectively accomplish the relation prediction. We apply AHNF to predict the lncRNA-disease associations using diverse relational and attribute data sources. AHNF achieves a larger area under the receiver operating curve 0.9367 (by at least 2.14%), and a larger area under the precision-recall curve 0.5937 (by at least 28.53%) than competitive data fusion approaches. AHNF also outperforms competing methods on predicting de novo lncRNA-disease associations, and precisely identifies lncRNAs associated with breast, stomach, prostate, and pancreatic cancers. AHNF is a comprehensive data fusion framework for universal attributed multi-type relational data. The code and datasets are available at http://'mlda.swu.edu.cn/codes.php?name=AHNF.																	1566-2535	1872-6305				NOV	2020	63						153	165		10.1016/j.inffus.2020.06.012													
J								FuCiTNet: Improving the generalization of deep learning networks by the fusion of learned class-inherent transformations	INFORMATION FUSION										Deep neural networks; Generalization; Pre-processing; Transformation; GANs (Generative Adversarial Networks); Classification; Small dataset		It is widely known that very small datasets produce overfitting in Deep Neural Networks (DNNs), i.e., the network becomes highly biased to the data it has been trained on. This issue is often alleviated using transfer learning, regularization techniques and/or data augmentation. This work presents a new approach, independent but complementary to the previous mentioned techniques, for improving the generalization of DNNs on very small datasets in which the involved classes share many visual features. The proposed model, called FuCiTNet (Fusion Class inherent Transformations Network), inspired by GANs, creates as many generators as classes in the problem. Each generator, k, learns the transformations that bring the input image into the k-class domain. We introduce a classification loss in the generators to drive the leaning of specific k-class transformations. Our experiments demonstrate that the proposed transformations improve the generalization of the classification model in three diverse datasets.																	1566-2535	1872-6305				NOV	2020	63						188	195		10.1016/j.inffus.2020.06.015													
J								Random forest explainability using counterfactual sets	INFORMATION FUSION										Explainable machine learning; Counterfactual sets; Counterfactual; Information fusion; Random forest; Decision tree		Nowadays, Machine Learning (ML) models are becoming ubiquitous in today's society, supporting people with their day-to-day decisions. In this context, Explainable ML is a field of Artificial Intelligence (AI) that focuses on making predictive models and their decisions interpretable by humans, enabling people to trust predictive models and to understand the underlying processes. A counterfactual is an effective type of Explainable ML technique that explains predictions by describing the changes needed in a sample to flip the outcome of the prediction. In this paper, we introduce counterfactual sets, an explanation approach that uses a set of counterfactuals to explain a prediction rather than a single counterfactual, by defining a sub-region of the feature space where the counterfactual holds. A method to extract counterfactual sets from a Random Forest (RF), the Random Forest Optimal Counterfactual Set Extractor (RF - OCSE), is presented. The method is based on a partial fusion of tree predictors from a RF into a single Decision Tree (DT) using a modification of the CART algorithm, and it obtains a counterfactual set that contains the optimal counterfactual. The proposal is validated through several experiments against existing alternatives on ten well-known datasets by comparing the percentage of valid counterfactuals, distance to the factual sample, and counterfactual sets quality.																	1566-2535	1872-6305				NOV	2020	63						196	207		10.1016/j.inffus.2020.07.001													
J								A smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion	INFORMATION FUSION										Feature extraction; Feature fusion; Heart disease prediction; Deep learning; Ontology	DECISION-SUPPORT-SYSTEM; RECOMMENDATION SYSTEM; WEIGHTING FILTER; FUZZY; RISK; MACHINE; DIAGNOSIS; ALGORITHM; ONTOLOGY; INTERNET	The accurate prediction of heart disease is essential to efficiently treating cardiac patients before a heart attack occurs. This goal can be achieved using an optimal machine learning model with rich healthcare data on heart diseases. Various systems based on machine learning have been presented recently to predict and diagnose heart disease. However, these systems cannot handle high-dimensional datasets due to the lack of a smart framework that can use different sources of data for heart disease prediction. In addition, the existing systems utilize conventional techniques to select features from a dataset and compute a general weight for them based on their significance. These methods have also failed to enhance the performance of heart disease diagnosis. In this paper, a smart healthcare system is proposed for heart disease prediction using ensemble deep learning and feature fusion approaches. First, the feature fusion method combines the extracted features from both sensor data and electronic medical records to generate valuable healthcare data. Second, the information gain technique eliminates irrelevant and redundant features, and selects the important ones, which decreases the computational burden and enhances the system performance. In addition, the conditional probability approach computes a specific feature weight for each class, which further improves system performance. Finally, the ensemble deep learning model is trained for heart disease prediction. The proposed system is evaluated with heart disease data and compared with traditional classifiers based on feature fusion, feature selection, and weighting techniques. The proposed system obtains accuracy of 98.5%, which is higher than existing systems. This result shows that our system is more effective for the prediction of heart disease, in comparison to other state-of-the-art methods.																	1566-2535	1872-6305				NOV	2020	63						208	222		10.1016/j.inffus.2020.06.008													
J								Renewable energy harvesting schemes in wireless sensor networks: A Survey	INFORMATION FUSION										Wireless sensor networks; Energy management; Renewable energy harvesting; Energy harvesting awareness; Solar energy harvesting; Wind energy harvesting	CLOCK SYNCHRONIZATION; SCHEDULING ALGORITHMS; ROUTING PROTOCOLS; NODE PLACEMENT; COVERAGE; TRANSMISSION; MANAGEMENT; DESIGN; ARCHITECTURE; AGRICULTURE	Wireless Sensor Networks (WSNs) are emerging as they demands for various applications, for example, military surveillance, home automation, vehicle tracking, environmental monitoring, wildlife tracking, health monitoring, and scientific exploration. Usually, sensor nodes operate with limited battery capacity. Using conventional batteries, it is not always efficient to design long-lasting sensor networks. Moreover, the replacement of the batteries is too challenging to operate in harsh environmental conditions. Therefore, to overcome, one such technique is to recharge the battery of sensor nodes using an energy harvesting system. On the other hand, some of the existing energy harvesting WSNs still lacking the intelligent strategy for judiciously utilizing both the energy management and harvesting system. The review work we present is categorized into energy management and renewable energy harvesting techniques. In energy management techniques, we discuss various methods to save energy consumption of the energy harvesting sensor networks. Notably, we study their protocol design strategies for energy-saving and essential strategies such as prediction for maximizing the energy harvesting of the sensor nodes. We also summarize their shortcomings and ability to deal with the energy harvesting system. In renewable energy harvesting schemes, we present various energy harvesting mechanisms such as solar, wind and others. We also discuss the different energy harvesting mechanisms, especially their protocol design strategies for maximizing energy harvesting, and summarize their merits and demerits. The work also discusses various challenging issues for energy harvesting WSNs followed by future research directions, and some recent applications.																	1566-2535	1872-6305				NOV	2020	63						223	247		10.1016/j.inffus.2020.07.005													
J								Multi-level information fusion to alleviate network congestion	INFORMATION FUSION										Information flow; Fusion process; Urban flow; Traffic network; Social dynamics; Ising model	DECISION-MAKING; BRAESS PARADOX; PERSPECTIVE; STATISTICS; GAMES	While increasing urban traffic can be an indicator of development, this inevitably results in traffic congestion in urban road networks. Is there a way to manage traffic flow through the control of traffic signals such that the overall network congestion is improved? Traffic light signals can be represented as two states of an Ising model. It is possible for traffic lights to "communicate" with each other through a fusion process from a remote management control system. This requires collection of information which can be fed to a centralized decision-making control mechanism. We first explore the fusion process between traffic signals and show that it is possible for traffic flow in a city to follow the phase transition as exhibited in the 2D Ising model. The model will be extended to show that a random switching between signalling control mechanisms can result in congested traffic being susceptible to transit out of congestion.																	1566-2535	1872-6305				NOV	2020	63						248	255		10.1016/j.inffus.2020.06.006													
J								CochleaNet: A robust language-independent audio-visual model for real-time speech enhancement	INFORMATION FUSION										Audio-Visual; Speech enhancement; Speech separation; Deep learning; Real noisy audio-visual corpus; Speaker independent; Noise-independent; Language-independent; Multi-modal; Hearing aids	NOISE; RECOGNITION; DEEP	Noisy situations cause huge problems for the hearing-impaired, as hearing aids often make speech more audible but do not always restore intelligibility. In noisy settings, humans routinely exploit the audio-visual (AV) nature of speech to selectively suppress background noise and focus on the target speaker. In this paper, we present a novel language-, noise- and speaker-independent AV deep neural network (DNN) architecture, termed CochleaNet, for causal or real-time speech enhancement (SE). The model jointly exploits noisy acoustic cues and noise robust visual cues to focus on the desired speaker and improve speech intelligibility. The proposed SE framework is evaluated using a first of its kind AV binaural speech corpus, ASPIRE, recorded in real noisy environments, including cafeteria and restaurant settings. We demonstrate superior performance of our approach in terms of both objective measures and subjective listening tests, over state-of-the-art SE approaches, including recent DNN based SE models. In addition, our work challenges a popular belief that scarcity of a mull-lingual, large vocabulary AV corpus and a wide variety of noises is a major bottleneck to build robust language, speaker and noise-independent SE systems. We show that a model trained on a synthetic mixture of the benchmark GRID corpus (with 33 speakers and a small English vocabulary) and CHiME 3 noises (comprising bus, pedestrian, cafeteria, and street noises) can generalise well, not only on large vocabulary corpora with a wide variety of speakers and noises, but also on completely unrelated languages such as Mandarin.																	1566-2535	1872-6305				NOV	2020	63						273	285		10.1016/j.inffus.2020.04.001													
J								Handwritten Mathematical Expression Recognition via Paired Adversarial Learning	INTERNATIONAL JOURNAL OF COMPUTER VISION										Handwritten ME recognition; Paired adversarial learning; Semantic-invariant features; Convolutional decoder; Coverage of decoding	RETRIEVAL	Recognition of handwritten mathematical expressions (MEs) is an important problem that has wide applications in practice. Handwritten ME recognition is challenging due to the variety of writing styles and ME formats. As a result, recognizers trained by optimizing the traditional supervision loss do not perform satisfactorily. To improve the robustness of the recognizer with respect to writing styles, in this work, we propose a novel paired adversarial learning method to learn semantic-invariant features. Specifically, our proposed model, named PAL-v2, consists of an attention-based recognizer and a discriminator. During training, handwritten MEs and their printed templates are fed into PAL-v2 simultaneously. The attention-based recognizer is trained to learn semantic-invariant features with the guide of the discriminator. Moreover, we adopt a convolutional decoder to alleviate the vanishing and exploding gradient problems of RNN-based decoder, and further, improve the coverage of decoding with a novel attention method. We conducted extensive experiments on the CROHME dataset to demonstrate the effectiveness of each part of the method and achieved state-of-the-art performance.																	0920-5691	1573-1405				NOV	2020	128	10-11			SI		2386	2401		10.1007/s11263-020-01291-5													
J								The benefits of target relations: A comparison of multitask extensions and classifier chains	PATTERN RECOGNITION										Multitask learning; Multi-objective trees; Stacking; Classifier chains; Ensemble learning	PREDICTION; ALGORITHM	Multitask (multi-target or multi-output) learning (MTL) deals with simultaneous prediction of several outputs. MTL approaches rely on the optimization of a joint score function over the targets. However, defining a joint score in global models is problematic when the target scales are different. To address such problems, single target (i.e. local) learning strategies are commonly employed. Here we propose alternative tree-based learning strategies to handle the issue with target scaling in global models, and to identify the learning order for chaining operations in local models. In the first proposal, the problems with target scaling are resolved using alternative splitting strategies which consider the learning tasks in a multi-objective optimization framework. The second proposal deals with the problem of ordering in the chaining strategies. We introduce an alternative estimation strategy, minimum error chain policy, that gradually expands the input space using the estimations that approximate to true characteristics of outputs, namely out-of-bag estimations in tree-based ensemble framework. Our experiments on benchmark datasets illustrate the success of the proposed multitask extension of trees compared to the decision trees with de facto design especially for datasets with large number of targets. In line with that, minimum error chain policy improves the performance of the state-of-the-art chaining policies. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107507	10.1016/j.patcog.2020.107507													
J								Detection of rotational symmetry in curves represented by the slope chain code	PATTERN RECOGNITION										Rotational-symmetry detection; Slope chain code; Chain coding; 2D Curves	SHAPES	We present a new approach based on the Slope Chain Code to determine whether a curve is rotational symmetrical and its order of symmetry. The proposed approach works for open and closed perfectly symmetrical or quasi-symmetrical 2D curves. Simple operations on the SCC and its invariant properties are central to our methodology. To evaluate the proposed methodology, we use 1400 curves from a public database. For the symmetrical/asymmetrical classification task, a recall (R) of 0.86, a balanced accuracy (BA) of 0.92, and a precision (P) of 0.87 were obtained. For the quasi-symmetrical/quasi-asymmetrical classification task, R=0.77, BA=0.83, and P=0.70 were obtained. For the order of rotational symmetry detection task, the following performance was achieved: R=0.97, BA=0.98, and P=0.95 for a symmetrical set of curves, and R=0.98, BA=0.98, and P=0.90 for a quasi-symmetrical set of curves. We conclude our presentation demonstrating the usefulness of our methodology with three practical applications (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107421	10.1016/j.patcog.2020.107421													
J								On the stability of persistent entropy and new summary functions for topological data analysis	PATTERN RECOGNITION										Persistent homology; Persistent entropy; Stability; Dimensionality reduction		Persistent homology and persistent entropy have recently become useful tools for patter recognition. In this paper, we find requirements under which persistent entropy is stable to small perturbations in the input data and scale invariant. In addition, we describe two new stable summary functions combining persistent entropy and the Betti curve. Finally, we use the previously defined summary functions in a material classification task to show their usefulness in machine learning and pattern recognition. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107509	10.1016/j.patcog.2020.107509													
J								Cylinders extraction in non-oriented point clouds as a clustering problem	PATTERN RECOGNITION										Cylinder extraction; Dual quaternions; Point clouds; Industrial inspection; Game theory	GEOMETRIC PRIMITIVES; ROBUST; RECONSTRUCTION; SEGMENTATION; PARAMETERS; FRAMEWORK; SYSTEM	Finding geometric primitives in 3D point clouds is a fundamental task in many engineering applications such as robotics, autonomous-vehicles and automated industrial inspection. Among all solid shapes, cylinders are frequently found in a variety of scenes, comprising natural or man-made objects. Despite their ubiquitous presence, automated extraction and fitting can become challenging if performed "in-the-wild", when the number of primitives is unknown or the point cloud is noisy and not oriented. In this paper we pose the problem of extracting multiple cylinders in a scene by means of a Game-Theoretic inlier selection process exploiting the geometrical relations between pairs of axis candidates. First, we formulate the similarity between two possible cylinders considering the rigid motion aligning the two axes to the same line. This motion is represented with a unitary dual-quaternion so that the distance between two cylinders is induced by the length of the shortest geodesic path in SE(3). Then, a Game-Theoretical process exploits such similarity function to extract sets of primitives maximizing their inner mutual consensus. The outcome of the evolutionary process consists in a probability distribution over the sets of candidates (ie axes), which in turn is used to directly estimate the final cylinder parameters. An extensive experimental section shows that the proposed algorithm offers a high resilience to noise, since the process inherently discards inconsistent data. Compared to other methods, it does not need point normals and does not require a fine tuning of multiple parameters. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107443	10.1016/j.patcog.2020.107443													
J								Multi-Label classification of multi-modality skin lesion via hyper-connected convolutional neural network	PATTERN RECOGNITION										Classification; Melanoma; Convolutional neural networks (cnns)	7-POINT CHECKLIST; SEGMENTATION; MELANOMA; IMAGES	Objective: Clinical and dermoscopy images (multi-modality image pairs) are routinely used sequentially in the assessment of skin lesions. Clinical images characterize a lesion's geometry and color; dermoscopy depicts vascularity, dots and globules from the sub-surface of the lesion. Together these modalities provide labels to characterize a skin lesion. Recently, convolutional neural networks (CNNs), due to the ability to learn low-level features and high-level semantic information in an end-to-end architecture, have been shown to be the state-of-the-art in skin lesion classification. Most of the CNN methods have relied on dermoscopy alone. In the few published papers that support multi-modalities, the methods are based on 'late-fusion' to integrate extracted clinical and dermoscopy image features separately. These late-fusion methods tend to ignore the accessible complementary image features between the paired images at the early stage of the CNN architecture. Methods: We propose a hyper-connected CNN (HcCNN) to classify skin lesions. Compared to existing multi-modality CNNs, our HcCNN has an additional hyper-branch that integrates intermediary image features in a hierarchical manner. The hyper-branch enables the network to learn more complex combinations between the images at all, early and late, stages of the network. We also coupled the HcCNN with a multi-scale attention block (MsA) to prioritize semantically important subtle regions in the two modalities across various image scales. Results: Our HcCNN achieved an average accuracy of 74.9% for multi-label classification on the 7-point Checklist dataset, which is a well-benchmarked public dataset. Conclusions: Our method is more accurate than the state-of-the-art methods and, in particular, our method achieved consistent and the best results in datasets with imbalanced label distributions. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107502	10.1016/j.patcog.2020.107502													
J								Zero-shot Handwritten Chinese Character Recognition with hierarchical decomposition embedding	PATTERN RECOGNITION										Chinese character recognition; Radical analysis; Zero-shot learning; Label embedding	NETWORK	Handwritten Chinese Character Recognition (HCCR) is a challenging topic in the field of pattern recognition due to large-scale character vocabulary, complex hierarchical structure, various writing styles, and scarce training samples. In this paper, we explored the hierarchical knowledge of Chinese characters and presented a novel zero-shot HCCR method. First, we handled the relations between the characters and their primitives, such as radicals and structures, to obtain a tree layout of primitives. Then, we presented a novel zero-shot hierarchical decomposition embedding method to encode the tree layout into a semantic vector. Next, we devised a Convolutional Neural Network (CNN) based framework to learn both radicals and structures of characters via the semantic vector. As different Chinese characters share some common radicals and structures, our method is able to recognize new categories without any labeled samples from them. Moreover, our method is effective in both traditional HCCR and zero-shot HCCR tasks. It achieves competitive performance on the traditional experiment setting and significantly surpasses the state-of-the-art methods on the zero-shot experiment setting. (C) 2020 Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107488	10.1016/j.patcog.2020.107488													
J								Towards more discriminative features for texture recognition	PATTERN RECOGNITION										Local binary patterns; Texture recognition; Feature representations; Feature optimization; Deep texture features; Mutual information	LOCAL BINARY PATTERNS; CLASSIFICATION; REPRESENTATION; OPERATOR	Local binary patterns (LBP) are considered to be one of the most computationally efficient descriptor that can also be combined jointly among different variants to increase accuracy. In this study, we propose a method to obtain more discriminative 2D LBP features by optimizing projections of a joint LBP distribution onto the marginal histograms. To find a more efficient representation of the feature vector, we seek the least redundant marginal histograms of a joint LBP distribution via optimizing several constraints. In this way, we aim to have a more compact yet accurate feature vector in contrast to the methods that flatten the joint distribution. Experiments we perform on five popular texture datasets show that the feature vectors optimized with the proposed method provide higher recognition rates with the same size vectors and comparable results even with lower dimensional vectors. We also compare the proposed algorithm to more recent texture recognition methods based on convolutional neural networks and show that it can still provide comparable results even though the resulting feature vectors are smaller by orders of magnitude. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107473	10.1016/j.patcog.2020.107473													
J								Covariance descriptors on a Gaussian manifold and their application to image set classification	PATTERN RECOGNITION										Covariance descriptors; Riemannian local difference vector; Riemannian covariance descriptors; Image set classification		Covariance descriptors (CovDs) for image set classification have been widely studied recently. Different from the conventional CovDs, which describe similarities between pixels at different locations, we focus more on similarities between regions that convey more comprehensive information. In this paper, we extract pixel-wise features of image regions and represent them by Gaussian models. We extend the conventional covariance computation onto a special type of Riemannian manifold, namely a Gaussian manifold, so that it is applicable to our image set data representation provided in terms of Gaussian models. We present two methods to calculate a Riemannian local difference vector on the Gaussian manifold (RieLDV-G) and generate our proposed Riemannian covariance descriptors (RieCovDs) using the resulting RieLDV-G. By measuring the recognition accuracy achieved on benchmarking datasets, we demonstrate experimentally the superior performance of our proposed RieCovDs descriptors, as compared with stateof-the-art methods. (The code is available at: https://github.com.kai-Xuan/RiemannianCovDs) (C) 2020 Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107463	10.1016/j.patcog.2020.107463													
J								Generative attention adversarial classification network for unsupervised domain adaptation	PATTERN RECOGNITION										Unsupervised domain adaptation; Generated adversarial network; Attention learning; Pseudo labels	KERNEL	Domain adaptation is a significant and popular issue of solving distribution discrepancy among different domains in computer vision. Generally, previous works proposed are mainly devoted to reducing domain shift between source domain with labeled data and target domain without labels. Adversarial learning in deep networks has already been widely applied to learn disentangled and transferable features between two different domains to minimize domains distribution discrepancy. However, these methods rarely consider class distributions among source data during adversarial learning, and they pay little attention to these transferable regions among source and target domains images. In this paper, we propose a Generative Attention Adversarial Classification Network (GAACN) model for unsupervised domain adaptation. To learn a joint feature distribution between source and target domains, we present an improved generative adversarial network (GAN) following the feature extractor. Firstly, the discriminator of GAN discriminates the distribution of domains and the classes distribution among source data during adversarial learning, so that our feature extractor can learn a joint feature distribution between source and target domains and maintain the classes consistent simultaneously. Secondly, we present an attention module embedded in GAN, which allows the discriminator to discriminate the transferable regions among the images of source and target domains. Lastly, we propose a simple and efficient method which allocates pseudo-labels for unlabeled target data, and it can improve the performance of our model GAACN while mitigating negative transfer. Extensive experiments demonstrate that our proposed model achieves perfect results on several standard domain adaptation datasets. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107440	10.1016/j.patcog.2020.107440													
J								Graph-based parallel large scale structure from motion	PATTERN RECOGNITION										Clustering; Structure from motion; Minimum spanning tree	MODEL; OPTIMIZATION; ACCURATE; CUTS	While Structure from Motion achieves great success in 3D reconstruction, it still meets challenges on large scale scenes. Incremental SfM approaches are robust to outliers, but are limited by low efficiency and easy suffer from drift problem. Though Global SfM methods are more efficient than incremental approaches, they are sensitive to outliers, and would also meet memory limitation and time bottleneck. In this work, large scale SfM is deemed as a graph problem, where graph are respectively constructed in image clustering step and local reconstructions merging step. By leveraging the graph structure, we are able to handle large scale dataset in divide-and-conquer manner. Firstly, images are modelled as graph nodes, with edges are retrieved from geometric information after feature matching. Then images are divided into independent clusters by a image clustering algorithm, and followed by a subgraph expansion step, the connection and completeness of scenes are enhanced by walking along a maximum spanning tree, which is utilized to construct overlapping images between clusters. Secondly, Image clusters are distributed into servers to execute SfM in parallel mode. Thirdly, after local reconstructions complete, we construct a minimum spanning tree to find accurate similarity transformations. Then the minimum spanning tree is transformed into a Minimum Height Tree to find a proper anchor node, and is further utilized to prevent error accumulation. We evaluate our approach on various kinds of datasets and our approach shows superiority over the state-of-the-art in accuracy and efficiency. Our algorithm is open-sourced in https://github.com/AIBluefisher/GraphSfM. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107537	10.1016/j.patcog.2020.107537													
J								Face re-identification challenge: Are face recognition models good enough?	PATTERN RECOGNITION										Face re-identification; Surveillance facial imagery; Low-resolution; Super-resolution; Open-set matching; Deep learning; Face recognition	NEURAL-NETWORK; SINGLE-IMAGE; SUPERRESOLUTION; REPRESENTATION; HALLUCINATION; PATTERNS	Face re-identification (Re-ID) aims to track the same individuals over space and time with subtle identity class information in automatically detected face images captured by unconstrained surveillance camera views. Despite significant advances of face recognition systems for constrained social media facial images, face Re-ID is more challenging due to poor-quality surveillance face imagery data and remains under-studied. However, solving this problem enables a wide range of practical applications, ranging from law enforcement and information security to business, entertainment and e-commerce. To facilitate more studies on face Re-ID towards practical and robust solutions, a true large scale Surveillance Face Re-ID benchmark (SurvFace) is introduced, characterised by natively low-resolution, motion blur, uncontrolled poses, varying occlusion, poor illumination, and background clutters. This new benchmark is the largest and more importantly the only true surveillance face Re-ID dataset to our best knowledge, where facial images are captured and detected under realistic surveillance scenarios. We show that the current state-of-the-art FR methods are surprisingly poor for face Re-ID. Besides, face Re-ID is generally more difficult in an open-set setting as naturally required in surveillance scenarios, owing to a large number of non-target people (distractors) appearing in open ended scenes. Moreover, the low-resolution problem inherent to surveillance facial imagery is investigated. Finally, we discuss open research problems that need to be solved in order to overcome the under-studied face Re-ID problem. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107422	10.1016/j.patcog.2020.107422													
J								Counter-examples generation from a positive unlabeled image dataset	PATTERN RECOGNITION										Generative adversarial networks (GANs); Generative models; Semi-supervised learning; Partially supervised learning; Deep learning		This paper considers the problem of positive unlabeled (PU) learning. In this context, we propose a two-stage GAN-based model. More specifically, the main contribution is to incorporate a biased PU risk within the standard GAN discriminator loss function. In this manner, the discriminator is constrained to steer the generator to converge towards the unlabeled samples distribution while diverging from the positive samples distribution. Consequently, the proposed model, referred to as D-GAN, exclusively learns the counter-examples distribution without prior knowledge. Experimental results on simple and complex image datasets demonstrate that our approach outperforms state-of-the-art PU methods without prior by overcoming issues such as sensitivity to prior knowledge or first-stage overfitting. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107527	10.1016/j.patcog.2020.107527													
J								Adaptive core fusion-based density peak clustering for complex data with arbitrary shapes and densities	PATTERN RECOGNITION										Clustering; Density peak; Core fusion; Arbitrary shape; Arbitrary density	FAST SEARCH; MEAN-SHIFT; BIG DATA; ALGORITHM; FIND	A challenging issue of clustering in real-word application is to detect clusters with arbitrary shapes and densities in complex data. Many conventional clustering algorithms are capable of detecting non-spherical clusters, but their performance is limited when processing data with complex shapes and multiple density peaks in a cluster without knowing the number of clusters. This paper proposes an adaptive core fusion-based density peak clustering (CFDPC) for detecting clusters in any shape and density adaptively. An initial clustering based on automatic finding of density peaks is proposed first. An adaptive searching approach is then proposed to find core points, and a within-cluster similarity-based core fusion strategy is proposed to obtain the final clustering results. The CFDPC where the number of clusters arises intuitively is simple and efficient. The performance of CFDPC is successfully verified in clustering several benchmark complex datasets with diverse shapes and densities. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107452	10.1016/j.patcog.2020.107452													
J								A novel hybrid approach for crack detection	PATTERN RECOGNITION										Crack detection; Defect detection; Object detection; Convolutional neural network; Faster R-CNN; Bayesian fusion	INSPECTION	Vision-based crack detection is of crucial importance in various industries, and it is very challenging due to weak signals in noisy backgrounds. In this paper, we propose a novel hybrid approach for crack detection in raw images, which combines deep learning models and Bayesian probabilistic analysis for robust crack detection. First, we re-train a state-of-the-art object detector (e.g. a Faster R-CNN) to detect crack patches of suitable SNR (signal-noise-ratio). We design a semi-automatic method to generate ground truths of crack patches along crack lines for training. To further improve the accuracy of crack detections over the whole image, we propose a Bayesian integration algorithm to suppress false detections. Specifically, we use a deep CNN to recognize the orientation of the crack segment in each detected patch. Then, a Bayesian probability is computed on the accumulated evidence from detected adjacent patches within a neighborhood based on spatial proximity, orientation consistency and alignment consistency. The patch which lacks local supports is suppressed as false detection. An algorithm to learn the parameters of Bayesian integration is also derived. Extensive experiments and evaluations are performed on a new comprehensive dataset of crack images. The results show that our approach outperforms the state-of-the-art baseline approach on deep CNN classifier. Ablation experiments are also conducted to show the effectiveness of proposed techniques. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107474	10.1016/j.patcog.2020.107474													
J								Point attention network for semantic segmentation of 3D point clouds	PATTERN RECOGNITION										Semantic segmentation; 3D point cloud; Point attention network; Deep learning	EFFICIENT	Convolutional Neural Networks (CNNs) have performed extremely well on data represented by regularly arranged grids such as images. However, directly leveraging the classic convolution kernels or parameter sharing mechanisms on sparse 3D point clouds is inefficient due to their irregular and unordered nature. We propose a point attention network that learns rich local shape features and their contextual correlations for 3D point cloud semantic segmentation. Since the geometric distribution of the neighboring points is invariant to the point ordering, we propose a Local Attention-Edge Convolution (LAE-Conv) to construct a local graph based on the neighborhood points searched in multi-directions. We assign attention coefficients to each edge and then aggregate the point features as a weighted sum of its neighbors. The learned LAE-Conv layer features are then given to a point-wise spatial attention module to generate an interdependency matrix of all points regardless of their distances, which captures long-range spatial contextual features contributing to more precise semantic information. The proposed point attention network consists of an encoder and decoder which, together with the LAE-Conv layers and the point-wise spatial attention modules, make it an end-to-end trainable network for predicting dense labels for 3D point cloud segmentation. Experiments on challenging benchmarks of 3D point clouds show that our algorithm can perform at par or better than the existing state of the art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107446	10.1016/j.patcog.2020.107446													
J								Play and rewind: Context-aware video temporal action proposals	PATTERN RECOGNITION										Temporal action proposal generation and detection; Deep learning; Untrimmed video analysis	ACTION RECOGNITION	In this paper, we investigate the problem of Temporal Action Proposal (TAP) generation, which plays a fundamental role in large-scale untrimmed video analysis but remains largely unsolved. Most of the prior works proposed the temporal actions by predicting the temporal boundaries or actionness scores of video units. Nevertheless, context information among surrounding video units has not been adequately explored, which may result in severe loss of information. In this work, we propose a context-aware temporal action proposal network which makes full use of the contextual information in two aspects: 1) To generate initial proposals, we design a Bi-directional Parallel LSTMs to extract the visual features of a video unit by considering its contextual information. Therefore, the prediction of temporal boundaries and actionness scores will be more accurate because it knows what happened in the past and what will happen in the future; and 2) To refine the initial proposals, we design an action-attention based reranking network which considers both surrounding proposal and initial actionness scores to assign true action proposals with high confidence scores. Extensive experiments are conducted on two challenging datasets for both temporal action proposal generation and detection tasks, demonstrating the effectiveness of the proposed approach. In particular, on THUMOS'14 dataset, our method significantly surpasses state-of-the-art methods by 7.73% on AR@50. Our code is released at: https://github.com/Rheelt/TAPG. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107477	10.1016/j.patcog.2020.107477													
J								Active contour model for inhomogenous image segmentation based on Jeffreys divergence	PATTERN RECOGNITION										Active contour model; Inhomogenous image segmentation; Local and global data fitting energies; Jeffreys divergence; Adaptive weight	SCALABLE FITTING ENERGY; VARIATIONAL MODEL; DRIVEN; FEATURES; INFORMATION; LIKELIHOOD; ENTROPY	Inhomogenous image segmentation has been a research challenge in recent years. To deal with this difficulty, we propose a new local and global active contour model based on Jeffreys divergence. First, unlike the local data fitting energy of the region-scalable fitting model, a new local data fitting energy based on Jeffreys divergence is proposed instead of Euclidean distance, which achieves relatively better segmentation. Second, to improve the versatility of the model, a new global data fitting energy based on Jeffreys divergence is proposed. Finally, the adaptive weights of the local and global data fitting energies are developed to increase the robustness to the initial curve. Experiments on real-world and medical images with inhomogeneities indicate that the proposed model can obtain accurate segmentation results efficiently and is not strictly dependent on setting up initial curves. (C) 2020 Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107520	10.1016/j.patcog.2020.107520													
J								A divide-and-conquer strategy for facial landmark detection using dual-task CNN architecture	PATTERN RECOGNITION										Facial landmark detection; Convolutional neural network; Face landmark modeling; Hierarchical divider; Cascade detector	FACE ALIGNMENT; REPRESENTATION; CASCADE; NETWORK; MODELS	In this paper, we propose a novel deep learning-based framework for facial landmark detection. This framework takes as input face image returned by a face detector (Faster R-CNN) and generates as output a set of landmarks positions. Prior CNN-based methods often select randomly small local patches to predict an initial guess of landmarks locations. One issue with these local patches is that the adjacent landmarks might share the same regions due to the overlapping, thus, they might not convey precise information of each individual landmark. By contrast, our approach formulates this problem as a divide-conquer search for facial patches using CNN architecture in a hierarchy, where the input face image is re-cursively split into two cohesive non-overlapped subparts until each one contains only the region around the expected landmark. To attain better division of face topology, the search is carried out in a structured coarse-to-fine manner, where a learned hierarchical model of the face defining the granularity of each division level is introduced. We also propose a cascaded regressor to detect and refine the position of the individual landmark in each predicted non-overlapped patch. We adopt a carefully designed shallow CNN architecture so that to improve real-time performance. In addition, unlike previous cascaded methods, our regressor does not require auxiliary input such as initial landmarks locations. Extensive experiments on several challenging datasets (including MTFL, AFW, AFLW, COFW, 300W, and 300VW) show that our approach is particularly impressive in the unconstrained scenarios where it outperforms prior arts in both accuracy and efficiency. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107504	10.1016/j.patcog.2020.107504													
J								Modality adversarial neural network for visible-thermal person re-identification	PATTERN RECOGNITION										Cross-modality; Adversarial learning; Person re-identification		Existing Visible-Thermal Person Re-identification (VT-REID) methods usually adopt two-stream networks for cross-modality images. The two streams are trained to extract features from different modality images respectively. In contrast, we design a Modality Adversarial Neural Network (MANN) to solve VT-REID problem. Our proposed MANN includes a one-stream feature extractor and a modality discriminator. The heterogeneous images are processed by the feature extractor to generate modality-invariant features. And the designed modality discriminator aims to distinguish whether the extracted features are from visible or thermal modality. Moreover, our advanced dual-constrained triplet loss is introduced for better cross-modality matching performance. The experiments on two cross-modality person re-identification datasets show that MANN can effectively learn modality-invariant features and outperform state-of-the-art methods by a large margin. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107533	10.1016/j.patcog.2020.107533													
J								Self-adaptive manifold discriminant analysis for feature extraction from hyperspectral imagery	PATTERN RECOGNITION										Hyperspectral remote sensing; Feature extraction; Self-adaptive optimization; Manifold margin; Discriminant features	DIMENSIONALITY REDUCTION; SPARSE-REPRESENTATION; CLASSIFICATION; FRAMEWORK; RECOGNITION; GRAPH	Traditional manifold learning methods generally include a single projection stage that maps high-dimensional data into lower-dimensional space. However, these methods cannot guarantee that the projection matrix is optimal for classification, which limits their practical application. To address this issue, we propose a two-stage projection matrix optimization model termed self-adaptive manifold discriminant analysis (SAMDA). In pre-training projection stage, SAMDA obtains an initial projection matrix by constructing an interclass graph and an intraclass graph under the graph embedding (GE) framework. In weight optimization stage, a maximal manifold margin criterion is developed to further optimize the weights of projection matrix by feature similarity. A self-adaptive optimization process is introduced to increase the margins among different manifolds in low-dimensional space and extract discriminant features that are beneficial to classification. Experimental results on PaviaU, Indian Pines and Heihe data sets demonstrate that the proposed SAMDA method can achieve better classification results than some state-of-the-art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107487	10.1016/j.patcog.2020.107487													
J								Multiple strong and balanced cluster-based ensemble of deep learners	PATTERN RECOGNITION										Deep learning, Ensemble classifier; Neural networks; Clustering	CLASSIFIER ENSEMBLES; RANDOM FORESTS; REGRESSION	Convolutional Neural Networks (CNNs), also known as deep learners have seen much success in the last few years due to the availability of large amounts of data and high-performance computational resources. A CNN can be trained effectively if large amounts of data are available as it enables a CNN to find the optimal set of features and weights that can achieve the highest generalization performance. However, due to the requirement of large data size, CNNs require a lot of resources for example running time and computational resources to achieve a reasonable performance. Additionally, unbalanced data makes it difficult to train a CNN effectively that can achieve good generalization performance. In order to alleviate these limitations, in this paper, we propose a novel ensemble of deep learners that learns by combining multiple deep learners trained on small strongly class associated input data effectively. We propose a novel methodology of generating random subspace through clustering input data and propose a measure which can classify each cluster as a strong data cluster and a balanced data cluster. A methodology is also proposed that balances all strong data clusters in the pool so that an architecturally simple CNN can be trained on all balanced data clusters simultaneously. Classification decisions on all trained CNNs are then fused through majority voting to generate class decisions of the ensemble. The performance of the proposed ensemble approach is evaluated on UCI benchmark datasets, and results are compared with existing state-of-the-art ensemble approaches. Significance testing was conducted to further validate the efficacy of the results and a significance test analysis is presented. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107420	10.1016/j.patcog.2020.107420													
J								Hierarchical dense recursive network for image super-resolution	PATTERN RECOGNITION										Super-resolution; Hierarchical dense connection; Global feature fusion; Recursive network; Multi-scale		Image super-resolution (SR) techniques with deep convolutional network (CNN) have achieved significant improvements compared to previous shallow-learning-based methods. Especially for dense connection based networks, these methods have yielded unprecedented achievements but bring the higher complexity and more parameters. To this end, this paper considers both reconstruction performance and efficiency, and advocates a novel hierarchical dense connection network (HDN) for image SR. First of all, we construct a hierarchical dense residual block (HDB) to promote the feature representation while saving the memory footprint with a hierarchical matrix structure design. In this way, it can provide additional interleaved pathways for information fusion and gradient optimization but with a shallower depth compare to the previous networks. In particular, a group of convolutional layers with small size (1 x 1) are embedded in HDB, releasing the computational burden and parameters by rescaling the feature dimensions. Furthermore, HDBs are connected to each other in a sharing manner, thereby allowing the network to fuse the features in different stages. At the final, the multi-scale features from these HDBs are integrated into global fusion module (GFM) for a global fusion and representation, and then the final profile-enriched residual map is obtained by realigning and sub-pixel upsampling the fusion maps. Extensive experimental results on benchmark datasets and really degraded images show that our model outperforms the state-of-the-art methods in terms of quantitative indicators and realistic visual effects, as well as enjoys a fast and accurate reconstruction. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107475	10.1016/j.patcog.2020.107475													
J								Enhanced automatic twin support vector machine for imbalanced data classification	PATTERN RECOGNITION										Imbalanced data; Kernel methods; Twin support vector machines	DECISION TREE; ENSEMBLE; MODEL; SMOTE	Most of the classification approaches assume that the sample distribution among classes is balanced. Still, such an assumption leads to biased performance over the majority class. This paper proposes an enhanced automatic twin support vector machine - (EATWSVM) to deal with imbalanced data, which incorporates a kernel representation within a TWSVM-based optimization. To learn the kernel function, we impose a Gaussian similarity, ruled by a Mahalanobis distance, and couple a centered kernel alignment-based approach to improving the data separability. Besides, we suggest a suitable range to fix the regularization parameters concerning both the dataset' imbalance ratio and overlap. Lastly, we adopt One-vs-One and One-vs-Rest frameworks to extend our EATWSVM formulation for multi-class tasks. Obtained results on synthetic and real-world datasets show that our approach outperforms state-of-the-art methods concerning classification performance and training time. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107442	10.1016/j.patcog.2020.107442													
J								Dirichlet Variational Autoencoder	PATTERN RECOGNITION										Representation learning; Variational autoencoder; Deep generative model; Multi-modal latent representation; Component collapse		This paper proposes Dirichlet Variational Autoencoder (DirVAE) using a Dirichlet prior. To infer the parameters of DirVAE, we utilize the stochastic gradient method by approximating the inverse cumulative distribution function of the Gamma distribution, which is a component of the Dirichlet distribution. This approximation on a new prior led an investigation on the component collapsing, and DirVAE revealed that the component collapsing originates from two problem sources: decoder weight collapsing and latent value collapsing. The experimental results show that 1) DirVAE generates the result with the best log-likelihood compared to the baselines; 2) DirVAE produces more interpretable latent values with no collapsing issues which the baselines suffer from; 3) the latent representation from DirVAE achieves the best classification accuracy in the (semi-)supervised classification tasks on MNIST, OMNIGLOT, COIL-20, SVHN, and CIFAR-10 compared to the baseline VAEs; and 4) the DirVAE augmented topic models show better performances in most cases. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107514	10.1016/j.patcog.2020.107514													
J								Sparse regularized low-rank tensor regression with applications in genomic data analysis	PATTERN RECOGNITION										Tensor regression; Tensor decomposition; Sparse penalty	MELANOMA; EXPRESSION; INHIBITION; MUTATIONS; INVASION; PARALLEL; LASSO	Many applications in biomedical informatics deal with data in the tensor form. Traditional regression methods which take vectors as covariates may encounter difficulties in handling tensors due to their ultrahigh dimensionality and complex structure. In this paper, we introduce a novel sparse regularized Tucker tensor regression model to exploit the structure of tensor covariates and perform feature selection on tensor data. Based on Tucker decomposition of the regression coefficient tensor, we reduce the ultrahigh dimensionality to a manageable level. To make our model identifiable, we impose the orthonormality constraint on the factor matrices. Unlike previous tensor regression models that impose sparse penalty on the factor matrices of the coefficient tensor, our model directly imposes sparse penalty on the coefficient tensor to select the relevant features on tensor data. An efficient optimization algorithm based on alternating direction method of multiplier (ADMM) algorithm is designed to solve our proposed model. The performance of our model is evaluated on both synthetic and real genomic data. Experiment results on synthetic data demonstrate that our model could identify the true related signals more accurately than other state-of-the-art regression models. The analysis on genomic data of melanoma demonstrates that our model can achieve better prediction performance and identify markers with important implications. Our model and the associated studies can provide useful insights to disease or pathogenesis mechanisms, and will benefit further studies in variable selection. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107516	10.1016/j.patcog.2020.107516													
J								Visual tracking by dynamic matching-classification network switching	PATTERN RECOGNITION										Visual Tracking; Deep Learning; Ensemble learning	OBJECT TRACKING	Existing deep trackers can be roughly divided into either matching-based or classification-based methods. The formers are fast but not very robust; while the latter ones introduce more discriminative information but often very slow. In this work, we present a novel real-time robust tracking method to take full use of the benefits from both kinds of networks. First, we propose a matching-classification network switching (MCS) framework to integrate the matching, classification, verification networks and conduct dynamic switching among them. Second, to speed up online update, we devlop a meta learning method as a critical component in our classification network. The meta classifier is trained offline to obtain general discriminative ability and updated online to the current frame just through one iteration. Extensive experiments are conducted on two popular benchmark datasets. Both qualitative and quantitative evaluations show that our tracker performs favorably against other state-of-the-art trackers with real-time performance. (C) 2020 Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107419	10.1016/j.patcog.2020.107419													
J								Depth image super-resolution using correlation-controlled color guidance and multi-scale symmetric network	PATTERN RECOGNITION										Depth image super-resolution; Deep convolutional neural network; Encoder-decoder structure; Color guidance; Channel correlation	RESOLUTION	Depth image super-resolution (DISR) is an effective solution to improve the quality of depth images captured by real world low-cost cameras. In this paper, we propose a multi-scale symmetric network with the correlation-controlled color guidance block (CCGB) for DISR. The proposed network consists of two multi-scale sub-networks to respectively provide guidance and estimate depth. A symmetric unit (SU), which is a mini-encoder-decoder structure with residual learning, is designed and used as a basic network atom. The encoder part in SU aims to extract essential features, while the decoder part works to restore edge details. The way the SU processes information matches well with the textureless and sharpedge characteristics of depth images. The two sub-networks present a high-level symmetric structure connected by dense guidance links in between. Based on the correlation analyses between the two subnetworks, each guidance link will transfer information trough a CCGB designed to implement channel-wise re-weighting mechanism. The accurate color guidance from CCGB helps avoiding artifacts introduced by non-co-occurrence of depth discontinuities and color edges. Experimental results demonstrate the superiority of the proposed method over several state-of-the-art DISR works. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107513	10.1016/j.patcog.2020.107513													
J								Learning discriminative features via weights-biased softmax loss	PATTERN RECOGNITION										Classification; Softmax; CNNs; Fully connected layer units; Classifier weights		Loss functions play a key role in training superior deep neural networks. In convolutional neural networks (CNNs), the popular cross entropy loss together with softmax does not explicitly guarantee minimization of intra-class variance or maximization of inter-class variance. In the early studies, there is no theoretical analysis and experiments explicitly indicating how to choose the number of units in fully connected layer. To help CNNs learn features more fast and discriminative, there are two contributions in this paper. First, we determine the minimum number of units in FC layer by rigorous theoretical analysis and extensive experiment, which reduces CNNs' parameter memory and training time. Second, we propose a negative-focused weights-biased softmax (W-Softmax) loss to help CNNs learn more discriminative features. The proposed W-Softmax loss not only theoretically formulates the intra-class compactness and inter-class separability, but also can avoid overfitting by enlarging decision margins. Moreover, the size of decision margins can be flexibly controlled by adjusting a hyperparameter alpha. Extensive experimental results on several benchmark datasets show the superiority of W-Softmax in image classification tasks. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107405	10.1016/j.patcog.2020.107405													
J								An efficient volume repairing method by using a modified Allen-Cahn equation	PATTERN RECOGNITION										Volume rendering; Volume repairing; Allen-Cahn equation; Mean curvature flow	RECONSTRUCTION; SURFACE; SETS	Classifying and rendering volumes of the structure are two essential goals of the visualization process. However, loss of some voxels can cause poor visualization results, such as small holes or non-smooth patches in visualized volumes. Beginning with the classified volumes, we propose a modified Allen-Cahn equation, which has the motion of mean curvature, to recover lost voxels and to fill holes. Consequently, a probability function can be obtained, which indicates the probability of each voxel being a volume voxel. Usually, the obtained probability function is smooth due to the motion of the mean curvature flow. Therefore visualization quality of volumes can be significantly improved. The equation is numerically computed by the unconditional stable operator splitting method with a large time step size. Thus the numerical scheme is fast and can be straightforwardly applied to GPU-accelerated DCT implementation that performs up to many times faster than CPU-only alternatives. Many experimental results have been performed to demonstrate the efficiency of the proposed method. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107478	10.1016/j.patcog.2020.107478													
J								Deep Matching Network for Handwritten Chinese Character Recognition	PATTERN RECOGNITION										HCCR; CNN; Matching Network; Deep Learning	EXTRACTION; ONLINE	Just like its remarkable achievements in many computer vision tasks, the convolutional neural networks (CNN) provide an end-to-end solution in handwritten Chinese character recognition (HCCR) with great success. However, the process of learning discriminative features for image recognition is difficult in cases where little data is available. In this paper, we propose a matching network which builds a connection between template characters and handwritten characters inspired by the human learning process of writing Chinese characters. The matching network replaces the parameters in the softmax regression layer with the features extracted from the template character images. After the training process has been finished, the powerful discriminative features help us to generalize the predictive power not just to new data, but to entire new Chinese characters that never appear in the training set before. Experiments performed on the ICDAR-2013 offline HCCR datasets have shown that the proposed method achieves a comparable performance to current CNN-based classifiers. Besides, the matching network has a very promising generalization ability to new Chinese characters that never appear in the existing training set. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107471	10.1016/j.patcog.2020.107471													
J								Defocus map estimation from a single image using improved likelihood feature and edge-based basis	PATTERN RECOGNITION										Defocus map estimation; Regression tree fields; Localized 2D frequency analysis	BLUR ESTIMATION; DEPTH; RESTORATION	Defocus map estimation (DME) is very useful in many computer vision applications and has drawn much attention in recent years. Edge-based DME methods can generate sharp defocus discontinuities but usually suffer from textures of the input image. Region-based methods are free of textures but cannot catch the defocus discontinuities very well. In this paper, we propose a DME method combining edge-based and region-based methods together to keep their respective advantages while eliminating the shortcomings. The combination is achieved via regression tree fields (RTF). In an RTF, the input feature and the linear basis are of vital importance. For our RTF, they are obtained as follows. (i) Two orthogonal gradient operators with the corresponding subsets of Gabor filters are employed in localized 2D frequency analysis to generate accurate likelihood, and the first K highest local maximums of likelihood are sent to an RTF as input feature. (ii) At the same time, the input image is processed by three edge-based methods and the results serve as the linear basis of RTF. The experiments demonstrate that the proposed method outperforms state-of-the-art DME methods. Moreover, the proposed method can be readily applied to defocused image deblurring and defocus blur detection. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107485	10.1016/j.patcog.2020.107485													
J								Density peaks clustering based on density backbone and fuzzy neighborhood	PATTERN RECOGNITION										Fuzzy kernel; Density peaks clustering; Noise detection; Label propagation	FAST SEARCH; PATTERN-RECOGNITION; FIND	Density peaks clustering (DPC) is as an efficient clustering algorithm due for using a non-iterative process. However, DPC and most of its improvements suffer from the following shortcomings: (1) highly sensitive to its cutoff distance parameter, (2) ignoring the local structure of data in computing local densities, (3) using a crisp kernel to calculate local densities, and (4) suffering from the cause of chain reaction. To address these issues, in this paper a new method called DPC-DBFN is proposed. The proposed method uses a fuzzy kernel for improving separability of clusters and reducing the impact of outliers. DPC-DBFN uses a density-based kNN graph for labeling backbones. This strategy prevents the chain reaction and effectively assigns true labels to those instances located on the border regions to effectively cluster data with various shapes and densities. The DPC-DBFN is evaluated on some real-world and synthetic datasets. The experimental results show the effectiveness and robustness of the proposed algorithm. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107449	10.1016/j.patcog.2020.107449													
J								Learning to complete partial observations from unpaired prior knowledge	PATTERN RECOGNITION										Completion; Partial observation; Weak supervision; Prior knowledge	PREDICTION	We present a novel training strategy that allows convolutional encoder-decoder networks, to complete partially observed data by means of hallucination. As input, it takes data from a partially observed domain, for which no complete ground truth is available, and data from an unpaired prior knowledge domain and trains the network in an end-to-end manner. This strategy is demonstrated for the task of completing 2-D road layouts as well as 3-D vehicle shapes. In contrast to alternative approaches, our strategy is compatible with networks that use skip connections, to improve detail in the completed output, while not requiring adversarial supervision. To demonstrate its benefits, our training strategy is benchmarked against two state-of-the-art baselines, one using a two-step auto-encoder training strategy and one using an adversarial strategy. Our novel strategy achieves an improvement up to +12% F-measure on the Cityscapes dataset. The learned network intrinsically generalizes better than the baselines on unseen datasets, which is demonstrated by an improvement up to +24% F-measure on the unseen KITTI dataset. Moreover, our approach outperforms the baselines using the same backbone network on the 3-D shape completion benchmark by reducing the Hamming distance with 15%. (C) 2020 The Author(s). Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107426	10.1016/j.patcog.2020.107426													
J								AutoPruner: An end-to-end trainable filter pruning method for efficient deep model inference	PATTERN RECOGNITION										Neural network pruning; Model compression; CNN acceleration	NETWORKS	Channel pruning is an important method to speed up CNN model's inference. Previous filter pruning algorithms regard importance evaluation and model fine-tuning as two independent steps. This paper argues that combining them into a single end-to-end trainable system will lead to better results. We propose an efficient channel selection layer, namely AutoPruner, to find less important filters automatically in a joint training manner. Our AutoPruner takes previous activation responses as an input and generates a true binary index code for pruning. Hence, all the filters corresponding to zero index values can be removed safely after training. By gradually erasing several unimportant filters, we can prevent an excessive drop in model accuracy. Compared with previous state-of-the-art pruning algorithms (including training from scratch), AutoPruner achieves significantly better performance. Furthermore, ablation experiments show that the proposed novel mini-batch pooling and binarization operations are vital for the success of model pruning. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107461	10.1016/j.patcog.2020.107461													
J								Cost-sensitive deep forest for price prediction	PATTERN RECOGNITION										Cost-sensitive Deep Forest; Ensemble Deep Learning; Price Prediction; Modified K-means	ENSEMBLE CLASSIFIERS	For many real-world applications, predicting a price range is more practical and desirable than predicting a concrete value. In this case, price prediction can be regarded as a classification problem. Although deep forest is recognized as the best solution to many classification problems, a crucial issue limits its direct application to price prediction, i.e., it treated all the misclassifications equally no matter how far away they are from the real classes, since their impacts on the accuracy are the same. This is unreasonable to price prediction as the misclassification should be as close to the real price range as possible even if they have to be wrongly classified. To address this issue, we propose a cost-sensitive deep forest for price prediction, which maintains the high accuracy of deep forest, and propels the misclassifications to be closer to the real price range to reduce the cost of misclassifications. To make the classification more meaningful, we develop a discretization method to pre-define the classes of price, by modifying the conventional K-means method. The experimental results based on multiple real-world datasets (i.e., car sharing, house renting and real estate selling) show that, the cost-sensitive deep forest can significantly reduce the cost in comparison with the conventional deep forest and other baselines, while keeping satisfactory accuracy. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107499	10.1016/j.patcog.2020.107499													
J								Low-rank quaternion tensor completion for recovering color videos and images	PATTERN RECOGNITION										Quaternion; Color videos; Color images; Tensor completion; Low-rank	FACTORIZATION; REPRESENTATION; DECOMPOSITION; MATRICES	Low-rank quaternion tensor completion method, a novel approach to recovery color videos and images, is proposed in this paper. We respectively reconstruct a color image and a color video as a quaternion matrix (second-order tensor) and a third-order quaternion tensor by encoding the red, green, and blue channel pixel values on the three imaginary parts of a quaternion. Different from some traditional models which treat color pixel as a scalar and represent color channels separately, whereas, during the quaternion-based reconstruction, it is significant that the inherent color structures of color images and color videos can be completely preserved. Under the definition of Tucker rank, the global low-rank prior to quaternion tensor is encoded as the nuclear norm of unfolding quaternion matrices. Then, by applying the ADMM framework, we provide the tensor completion algorithm for any order ( >= 2) quaternion tensors, which theoretically can be well used to recover missing entries of any multidimensional data with color structures. Simulation results for color videos and color images recovery show the superior performance and efficiency of the proposed method over some state-of-the-art existing ones. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107505	10.1016/j.patcog.2020.107505													
J								A new unified method for detecting text from marathon runners and sports players in video (PR-D-19-01078R2)	PATTERN RECOGNITION										Video text analysis; Gradient direction; Bayesian classifier; Face detection; Torso detection; Deep learning; Text detection	RECOGNITION; TRACKING; FRAMEWORK	Detecting text located on the torsos of marathon runners and sports players in video is a challenging issue due to poor quality and adverse effects caused by flexible/colorful clothing, and different structures of human bodies or actions. This paper presents a new unified method for tackling the above challenges. The proposed method fuses gradient magnitude and direction coherence of text pixels in a new way for detecting candidate regions. Candidate regions are used for determining the number of temporal frame clusters obtained by K-means clustering on frame differences. This process in turn detects key frames. The proposed method explores Bayesian probability for skin portions using color values at both pixel and component levels of temporal frames, which provides fused images with skin components. Based on skin information, the proposed method then detects faces and torsos by finding structural and spatial coherences between them. We further propose adaptive pixels linking a deep learning model for text detection from torso regions. The proposed method is tested on our own dataset collected from marathon/sports video and three standard datasets, namely, RBNR, MMM and R-ID of marathon images, to evaluate the performance. In addition, the proposed method is also tested on the standard natural scene datasets, namely, CTW1500 and MS-COCO text datasets, to show the objectiveness of the proposed method. A comparative study with the state-of-the-art methods on bib number/text detection of different datasets shows that the proposed method outperforms the existing methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107476	10.1016/j.patcog.2020.107476													
J								3DSymm: Robust and Accurate 3D Reflection Symmetry Detection	PATTERN RECOGNITION										Reflection symmetry; Point cloud; Optimization	ALGORITHMS; SHAPE	Reflection symmetry is a very commonly occurring feature in both natural and man-made objects, which helps in understanding objects better and makes them visually pleasing. Detection of reflection symmetry is a fundamental problem in the field of computer vision and computer graphics which aids in understanding and representing reflective symmetric objects. In this work, we attempt the problem of detecting the 3D global reflection symmetry of a 3D object represented as a point cloud. The main challenge is to handle outliers, missing parts, and perturbations from the perfect reflection symmetry. We propose a descriptor-free approach, in which, we pose the problem of reflection symmetry detection as an optimization problem and provide a closed-form solution. We show that the proposed method achieves state-of-the-art performance on the standard dataset. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107483	10.1016/j.patcog.2020.107483													
J								Handling incomplete heterogeneous data using VAEs	PATTERN RECOGNITION										Generative models; Variational autoencoders; Incomplete heterogenous data	IMPUTATION; MODELS	Variational autoencoders (VAEs), as well as other generative models, have been shown to be efficient and accurate for capturing the latent structure of vast amounts of complex high-dimensional data. However, existing VAEs can still not directly handle data that are heterogenous (mixed continuous and discrete) or incomplete (with missing data at random), which is indeed common in real-world applications. In this paper, we propose a general framework to design VAEs suitable for fitting incomplete heterogenous data. The proposed HI-VAE includes likelihood models for real-valued, positive real valued, interval, categorical, ordinal and count data, and allows accurate estimation (and potentially imputation) of missing data. Furthermore, HI-VAE presents competitive predictive performance in supervised tasks, outperforming supervised models when trained on incomplete data. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107501	10.1016/j.patcog.2020.107501													
J								Self-supervised deep reconstruction of mixed strip-shredded text documents	PATTERN RECOGNITION										Deep learning; Self-supervised learning; Fully convolutional neural networks; Document reconstruction; Forensics; Optimization search	ALGORITHM	The reconstruction of shredded documents consists of coherently arranging fragments of paper (shreds) to recover the original document(s). A great challenge in computational reconstruction is to properly evaluate the compatibility between the shreds. While traditional pixel-based approaches are not robust to real shredding, more sophisticated solutions compromise significantly time performance. The solution presented in this work extends our previous deep learning method for single-page reconstruction to a more realistic/complex scenario: the reconstruction of several mixed shredded documents at once. In our approach, the compatibility evaluation is modeled as a two-class (valid or invalid) pattern recognition problem. The model is trained in a self-supervised manner on samples extracted from simulated-shredded documents, which obviates manual annotation. Experimental results on three datasets - including a new collection of 100 strip-shredded documents produced for this work - have shown that the proposed method outperforms the competing ones on complex scenarios, achieving accuracy superior to 90%. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107535	10.1016/j.patcog.2020.107535													
J								Semantic segmentation using stride spatial pyramid pooling and dual attention decoder	PATTERN RECOGNITION										Semantic segmentation; Convolutional neural networks; Pyramid pooling; Attention mechanism	NETWORKS; FORCE	Semantic segmentation is an end-to-end task that requires both semantic and spatial accuracy. It is important for deep learning-based segmentation methods to effectively utilize the high-level feature map whose semantic information is abundant and the low-level feature map whose spatial information is accurate. However, existing segmentation networks typically cannot take full advantage of these two kinds of feature maps, leading to inferior performance. This paper attempts to overcome this challenge by introducing two novel structures. On the one hand, we propose a structure called stride spatial pyramid pooling (SSPP) to capture multiscale semantic information from the high-level feature map. Compared with existing pyramid pooling methods based on the atrous convolution, the SSPP structure is able to gather more information from the high-level feature map with faster inference speed, which improves the utilization efficiency of the high-level feature map significantly. On the other hand, we propose a dual attention decoder consisting of a channel attention branch and a spatial attention branch to make full use of the high- and low-level feature maps simultaneously. The dual attention decoder can result in a more "semantic" low-level feature map and a high-level feature map with more accurate spatial information, which bridges the gap between these two kinds of feature maps and benefits their fusion. We evaluate the proposed model on several publicly available semantic image segmentation benchmarks including PASCAL VOC 2012, Cityscapes and COCO-Stuff. The qualitative and quantitative results demonstrate that our method can achieve the state-of-the-art performance. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107498	10.1016/j.patcog.2020.107498													
J								TPM: Multiple object tracking with tracklet-plane matching	PATTERN RECOGNITION										Multiple object tracking; Tracklet; Tracklet-plane; Representative-selection network		Multiple object tracking (MOT) aims to model the temporal relationship among detected objects and associate them into trajectories. Thus, one major challenge of MOT lies in the confusion from noisy object detection results. In this paper, we propose Tracklet-Plane Matching (TPM), a new approach which improves the performance of MOT by modeling and reducing the interferences from noisy or confusing object detections. TPM first constructs good temporally-related object detections into short tracklets. Then, a tracklet-plane matching process is introduced to organize related tracklets into planes and associate them into long trajectories. The tracklet-plane matching process assigns visually confusing tracklets into different tracklet planes according to their contextual information, thus properly reducing the confusion among similar tracklets. At the same time, it also allows association among temporally non-neighboring or overlapping tracklets, which provides good flexibility to handle confusion from noisy detections. Under this process, a tracklet-importance evaluation scheme and a representative-based similarity modeling scheme are introduced. These two schemes can properly evaluate the reliability of detection results and identify reliable ones during association so that the impact of noisy or confusing detections can be well-mitigated. Experimental results on benchmark datasets demonstrate that the proposed approach outperforms the state-of-the-art MOT methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107480	10.1016/j.patcog.2020.107480													
J								Deep co-training for semi-supervised image segmentation	PATTERN RECOGNITION										Deep learning; Semi-supervised learning; Ensemble learning; Co-training; Image segmentation		In this paper, we aim to improve the performance of semantic image segmentation in a semi-supervised setting where training is performed with a reduced set of annotated images and additional non-annotated images. We present a method based on an ensemble of deep segmentation models. Models are trained on subsets of the annotated data and use non-annotated images to exchange information with each other, similar to co-training. Diversity across models is enforced with the use of adversarial samples. We demonstrate the potential of our method on three challenging image segmentation problems, and illustrate its ability to share information between simultaneously trained models, while preserving their diversity. Results indicate clear advantages in terms of performance compared to recently proposed semi-supervised methods for segmentation. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107269	10.1016/j.patcog.2020.107269													
J								Generative adversarial classifier for handwriting characters super-resolution	PATTERN RECOGNITION										Super-Resolution; Generative adversarial networks (GAN); Handwriting characters recognition	NETWORK; FACES	Generative Adversarial Networks (GAN) receive great attention recently due to its excellent performance in image generation, transformation, and super-resolution. However, less emphasis or study has been put on GAN for classification with super-resolution. Moreover, though GANs may fabricate images which perceptually looks realistic, they usually fabricate some fake details especially in character data; this would impose further difficulties when they are input for classification. In this paper, we propose a novel Generative Adversarial Classifier (GAC) for low-resolution handwriting character recognition. Specifically, we design an additional classifier component in GAC, leading to a novel three-player GAN model which is not only able to generate high-quality super-resolved images, but also favorable for classification. Experimental results show that our proposed method can obtain remarkable performance in handwriting characters with 8 x super-resolution, achieving new state-of-the-art on benchmark dataset CASIA-HWDB1.1, and MNIST. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107453	10.1016/j.patcog.2020.107453													
J								Skeleton-based action recognition with hierarchical spatial reasoning and temporal stack learning network	PATTERN RECOGNITION										Skeleton-based action recognition; Hierarchical spatial reasoning; Temporal stack learning; Clip-based incremental loss		Skeleton-based action recognition aims to recognize human actions by exploring the inherent characteristics from the given skeleton sequences and has attracted far more attention due to its great important potentials in practical applications. Previous methods have illustrated that learning discriminative spatial and temporal features from the skeleton sequences is a crucial factor to recognize human actions. Nevertheless, how to model spatio-temporal evolutions is still a challenging problem. In this work, we propose a novel model with hierarchical spatial reasoning and temporal stack learning network (HSR-TSL) to explore the discriminative spatial and temporal features for human action recognition, which consists of a hierarchical spatial reasoning network (HSRN) and a temporal stack learning network (TSLN). Specifically, the HSRN employs a hierarchical residual graph neural network to capture two-level spatial features: intra spatial information of each part and body-level structural information between each part. The TSLN models the detailed temporal dynamics of skeleton sequences by a composition of multiple skip-clip LSTMs. During training, we develop a clip-based incremental loss to effectively optimize the model. We perform extensive experiments on five challenging benchmarks to verify the effectiveness of each component of our model. The comparison results illustrate that our approach significantly boosts the performances for skeleton-based action recognition. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107511	10.1016/j.patcog.2020.107511													
J								Nonlinear dimensionality reduction for clustering	PATTERN RECOGNITION										Nonlinearity; Dimensionality reduction; Divisive hierarchical clustering; Manifold clustering		We introduce an approach to divisive hierarchical clustering that is capable of identifying clusters in nonlinear manifolds. This approach uses the isometric mapping (Isomap) to recursively embed (subsets of) the data in one dimension, and then performs a binary partition designed to avoid the splitting of clusters. We provide a theoretical analysis of the conditions under which contiguous and high-density clusters in the original space are guaranteed to be separable in the one-dimensional embedding. To the best of our knowledge there is little prior work that studies this problem. Extensive experiments on simulated and real data sets show that hierarchical divisive clustering algorithms derived from this approach are effective. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107508	10.1016/j.patcog.2020.107508													
J								Binary coyote optimization algorithm for feature selection	PATTERN RECOGNITION										Wrapper feature selection; Classification; Coyote optimization algorithm (COA); Bio-inspired optimization;Metaheuristics; Binary COA	PARTICLE SWARM OPTIMIZATION; GREY WOLF OPTIMIZATION; CROW SEARCH ALGORITHM; ARTIFICIAL BEE COLONY; CLASSIFICATION	The Coyote Optimization Algorithm (COA) is a bio-inspired optimization algorithm based on the intelligent behavior of coyotes. COA was proposed recently and it considers the social organization of the coyotes and its adaptation to the environment in order to solve continuous optimization problems. In addition, it is a population-based algorithm and it can be classified as both, swarm intelligence and evolutionary heuristics, because contributes with a different algorithmic structure. This paper proposes a binary version of the COA, named Binary COA (BCOA) applying to select the optimal feature subset for classification, based on the hyperbolic transfer function in a wrapper model. By this way, the features are selected based on the performance evaluation of a classification algorithm. We tested the effectiveness of the BCOA wrapper with the Naive Bayes classifier and were used seven public domain benchmark datasets to compare the proposed approach in terms of classification accuracy, number of selected features and computational cost with other state-of-art algorithms of the literature. The results shown that BCOA was able to find subsets with few features while it still performs well in terms of classification accuracy. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107470	10.1016/j.patcog.2020.107470													
J								Efficient sampling-based energy function evaluation for ensemble optimization using simulated annealing	PATTERN RECOGNITION										Diabetic retinopathy; Ensemble; Microaneurysm detection; Parameter optimization; Sampling-based evaluation; Simulated annealing	DIABETIC-RETINOPATHY; MICROANEURYSM DETECTION; AUTOMATED DETECTION; SYSTEM; NOISY	In this study, we attempted to develop a method for accelerating parameter optimization of an object detector ensemble over large image datasets by using simulated annealing. We propose a novel sampling-based evaluation method that considers the minimum portion of the dataset required in each iteration to maintain solution quality. This approach can be considered a noisy evaluation of the energy. The sample sizes required during the search process are theoretically determined by adapting the convergence results for noisy evaluation. To determine applicability, we prepared and optimized two ensembles for diabetic retinopathy pre-screening based on microaneurysm detection with convolutional neural network-based and traditional object detectors. Our experimental results indicate that the proposed sampling-based evaluation method substantially reduced the computational time required for optimizing the parameters of the ensembles while preserving solution quality. (C) 2020 The Authors. Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107510	10.1016/j.patcog.2020.107510													
J								Joint and individual matrix factorization hashing for large-scale cross-modal retrieval	PATTERN RECOGNITION										Hashing; Multimodal; Retrieval; Cross-modal; Matrix factorization	CODES	Multimodal hashing methods have gained considerable attention in recent years due to their effectiveness and efficiency for cross-modal similarity searches. Existing multimodal hashing methods either learn unified hash codes for different modalities or learn individual hash codes for each modality and then explore cross-correlations between them. Generally, learning unified hash codes tends to preserve the shared properties of multimodal data and learning individual hash codes tends to preserve the specific properties of each modality. There remains a crucial bottleneck regarding how to learn hash codes that simultaneously preserve the shared properties and specific properties of multimodal data. Therefore, we present a joint and individual matrix factorization hashing UIMFH) method, which not only learns unified hash codes for multimodal data to preserve their common properties but also learns individual hash codes for each modality to retain its specific properties. The proposed JIMFH learns unified hash codes by joint matrix factorization, which jointly factorizes all modalities into a shared latent semantic space. In addition, JIMFH learns individual hash codes by individual matrix factorization, which separately factorizes each modality into a modal-specific latent semantic space. Finally, unified hash codes and individual hash codes are combined to obtain the final hash codes. In this way, hash codes learned by JIMFH can preserve both the shared properties and specific properties of multimodal data, and therefore the retrieval performance is enhanced. Comprehensive experiments show that the proposed JIMFH performs much better than many state-of-the-art methods on cross-modal retrieval applications. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107479	10.1016/j.patcog.2020.107479													
J								A linear multivariate binary decision tree classifier based on K-means splitting	PATTERN RECOGNITION										Hierarchical classifier; Binary tree; Multivariate decision tree; K-means; Supervised classification	INDUCTION	A novel linear multivariate decision tree classifier, Binary Decision Tree based on K-means Splitting (BDTKS), is presented in this paper. The unsupervised K-means clustering is recursively integrated into the binary tree, building a hierarchical classifier. The introduction of the unsupervised K-means clustering provides the powerful generalization ability for the resulting BDTKS model. Then, the good generalization ability of BDTKS ensures the classification performance. A novel non-split condition with an easy-setting hyperparameter which focuses more on minority classes of the current node is proposed and applied in the BDTKS model, avoiding ignoring the minority classes in the class imbalance cases. Furthermore, the K-means centroid based BDTKS model is converted into the hyperplane based decision tree, speeding up the process of classification. Extensive experiments on the publicly available data sets have demonstrated that the proposed BDTKS matches or outperforms the previous decision trees. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107521	10.1016/j.patcog.2020.107521													
J								Dynamic graph convolutional network for multi-video summarization	PATTERN RECOGNITION										Multi-video summarization; Graph convolutional network; Class imbalance problem		Multi-video summarization is an effective tool for users to browse multiple videos. In this paper, multi-video summarization is formulated as a graph analysis problem and a dynamic graph convolutional network is proposed to measure the importance and relevance of each video shot in its own video as well as in the whole video collection. Two strategies are proposed to solve the inherent class imbalance problem of video summarization task. Moreover, we propose a diversity regularization to encourage the model to generate a diverse summary. Extensive experiments are conducted, and the comparisons are carried out with the state-of-the-art video summarization methods, the traditional and novel graph models. Our method achieves state-of-the-art performances on two standard video summarization datasets. The results demonstrate the effectiveness of our proposed model in generating a representative summary for multiple videos with good diversity. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107382	10.1016/j.patcog.2020.107382													
J								Fast sparse coding networks for anomaly detection in videos	PATTERN RECOGNITION										Anomaly detection; Encoding-decoding networks; Sparse coding networks; Spatial-temporal information; Video representation	ABNORMAL EVENT DETECTION; REPRESENTATION	The semi-supervised video anomaly detection assumes that only normal video clips are available for training. Therefore, the intuitive idea is either to learn a dictionary by sparse coding or to train encoding-decoding neural networks by minimizing the reconstruction errors. For the former, the optimization of sparse coefficients is extremely time-consuming. For the latter, this manner cannot guarantee that an abnormal data corresponds to a larger reconstruction error due to the strong generalization of neural networks. To remedy their weaknesses and leverage their strengths, we propose a Fast Sparse Coding Network (FSCN) based on High-level Features. First, we propose a two-stream neural network to extract Spatial-Temporal Fusion Features (STFF) in hidden layers. With the STFF at hand, we use a Fast Sparse Coding Network to build a normal dictionary. By leveraging the predictor to produce approximate sparse coefficients, our FSCN generates sparse coefficients within a forward pass, which is simple and computationally efficient. Compared with traditional sparse coding based methods, FSCN is hundreds of or even thousands of times faster at the test stage. Extensive experiments on benchmark datasets demonstrate that our method reaches the state-of-the-art level.(1 )(C)( )2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107515	10.1016/j.patcog.2020.107515													
J								Precise detection of Chinese characters in historical documents with deep reinforcement learning	PATTERN RECOGNITION										Deep reinforcement learning; Historical documents; Character detection; Reward function	SCENE TEXT DETECTION; IMAGES	The decision-making ability of deep reinforcement learning has been proved successfully in a variety of fields. Here, we use this method for precise character detection by making tight bounding boxes around the Chinese characters in historical documents. An agent is trained to learn the control policy of fine-tuning a bounding box step-by-step through a Markov Decision Process. We introduce a novel fully convolutional network with position-sensitive Region-of-Interest (RoI) pooling (FCPN). The network receives character patches as input without fixed size, and it can fuse position information into the features of actions. Besides, we propose a dense reward function (DRF) that provides excellent rewards according to different actions and environment states, improving the decision-making ability of the agent. Our approach is designed as a universal method that can be applied to the output of all character-level or word-level text detectors to obtain more precise detection results. Application to the Tripitaka Koreana in Han (TKH) and Multiple Tripitaka in Han (MTH) datasets confirm the very promising performance of this method. In particular, our approach yields a significant improvement under a large Intersection over Union (IoU) of 0.8. The robustness and generality are also proved by experiments on the scene text datasets ICDAR2013 and ICDAR2015. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107503	10.1016/j.patcog.2020.107503													
J								Semi-supervised learning framework based on statistical analysis for image set classification	PATTERN RECOGNITION										Semi-supervised learning; Data dependent kernel; Gaussian descriptor; Image set classification; Fuzzy discriminant analysis	FACE RECOGNITION; MANIFOLD; REPRESENTATION	Statistical models have been widely adopted for image set classification owing to their capacity in characterizing the data distribution more flexibly and faithfully. However, these methods typically suffer from the problem that the query image set has weak statistical correlations with the training sets, which leads to larger fluctuations in performance. To address this problem, we propose a semi-supervised fuzzy discriminative learning framework based on Log-Euclidean multivariate Gaussians descriptor to facilitate more robust image set classification. Specifically, by using the semi-supervised setting which definitely has access to the labeled training data and the available unlabeled testing data, we adopt manifold distance metric to construct a "fully trusted" graph and derive two new data dependent probabilistic kernels to strongly reflect the underlying connection relationships between the training and query Gaussian manifold components. The resulted kernel representations are eventually integrated into a kernel fuzzy discriminant framework to enhance the compactness of intra-class Gaussian components and enlarge the margin for inter-class Gaussian components. Thus, more discriminating power of our learning machine is obtained for the classification of the query image set. Extensive experiments on several datasets well demonstrate the effectiveness of the proposed method compared with other image set algorithms. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107500	10.1016/j.patcog.2020.107500													
J								Complex heterogeneity learning: A theoretical and empirical study	PATTERN RECOGNITION										Heterogeneous learning; Multi-task learning; Multi-view learning; Multi-instance learning	MULTIPLE; FRAMEWORK	Data heterogeneity such as task heterogeneity, view heterogeneity, and instance heterogeneity often coexist in many real-world applications including insider threat detection, traffic prediction, brain image analysis, quality control in manufacturing processes, etc. However, most of the existing techniques might not take fully advantage of the rich heterogeneity. To address this problem, we propose a novel graph-based approach named M-3 to simultaneously model triple heterogeneity in a principled framework. The main idea is to employ the hybrid graphs to jointly model the task relatedness, view consistency, and bag-instance correlation by enhancing the labeling consistency between nearby nodes on the graphs. Furthermore, we analyze the generalization performance of the proposed method based on Rademacher complexity, which sheds light on the benefits of jointly modeling multiple types of heterogeneity. The resulting optimization problem is challenging since the objective function is non-smooth and non-convex. We propose an iterative algorithm based on block coordinate descent and bundle method to solve the problem. Experimental results on various datasets demonstrate the effectiveness of the proposed method. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107519	10.1016/j.patcog.2020.107519													
J								A sparsity-promoting image decomposition model for depth recovery	PATTERN RECOGNITION										Image decomposition; Depth recovery; Depth discontinuities; Depth cameras		This paper proposes a novel image decomposition model for scene depth recovery from low-quality depth measurements and its corresponding high resolution color image. Through our observation, the depth map mainly contains smooth regions separated by additive step discontinuities, and can be simultaneously decomposed into a local smooth surface and an approximately piecewise constant component. Therefore, the proposed unified model combines the least square polynomial approximation (for smooth surface) and a sparsity-promoting prior (for piecewise constant) to better portray the 2D depth signal intrinsically. As we know, the representation of the piecewise constant signal in gradient domain is extremely sparse. Previous researches using total variation filter based on L-1-norm or L-p-norm (0 < p < 1) are both sub-optimal when addressing the tradeoff between enhancing the sparsity and keeping the model convex. We propose a novel non-convex penalty based on Moreau envelope, which promotes the prior sparsity and simultaneously maintains the convexity of the whole model for each variable. We prove the convexity of the proposed model and give the convergence analysis of the algorithm. We also introduce an iterative reweighted strategy applied on the sparsity prior to deal with the depth-color inconsistent problem and to locate the depth boundaries. Moreover, we provide an accelerated algorithm to deal with the problem of non-uniform down-sampling when transforming the depth observation matrix into the Fourier domain for fast processing. Experimental results demonstrate that the proposed method can handle various types of depth degradation and achieve promising performance in terms of recovery accuracy and running time. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107506	10.1016/j.patcog.2020.107506													
J								Neural network with multiple connection weights	PATTERN RECOGNITION										Neural network; Neurotransmitter; Interpretability; Extending dimension	REPRESENTATION; AUTOENCODERS; MACHINES	Biological studies have shown that the interaction between neurons are based on neurotransmitters, which transmit signals between neurons, and that one neuron sends information to another neuron by releasing a number of different neurotransmitters, which play different roles. Motivated by this biological discovery, a novel neural networks model is proposed by extending the dimension of connection weights from one to multiple, i.e. there are multiple not only one connections between each two units. The number of dimensions of connection weight represents the number of categories of neurotransmitters and different components of the weight correspond to different neurotransmitters. In order to make these neurotransmitters collaborate and compete appropriately, the input and output for each unit in our proposed model have been heuristically defined. From the biological perspective, the proposed neural network is much closer to biological neural network. From the viewpoint of new model structure, the characteristic that the activation of each hidden unit is based on several filters, can improve the interpretability of features learned by the proposed neural network. Experimental results on MNIST, NORB and several other data sets have demonstrated that the performances of traditional neural networks can be improved by extending the dimension of connection weight between units, and the idea of multiple connection weights provides a new paradigm for the design of neural networks. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107481	10.1016/j.patcog.2020.107481													
J								A robust matching pursuit algorithm using information theoretic learning	PATTERN RECOGNITION										Orthogonal matching pursuit; Information theoretic learning; ITL-Correlation; Kernel minimization; Data recovery; Image reconstruction; Image classification	FACE RECOGNITION; SIGNAL RECOVERY; SPARSE REPRESENTATION; CORRENTROPY; REGRESSION	Current orthogonal matching pursuit (OMP) algorithms calculate the correlation between two vectors using the inner product operation and minimize the mean square error, which are both suboptimal when there are non-Gaussian noises or outliers in the observation data. To overcome these problems, a new OMP algorithm is developed based on information theoretic learning (ITL), which is built on the following new techniques: (1) an ITL-based correlation (ITL-Correlation) is developed as a new similarity measure which can better exploit higher-order statistics of the data, and is robust against many different types of noise and outliers in a sparse representation framework; (2) a non-second order statistic measurement and minimization method is developed to improve the robustness of OMP by overcoming the limitation of Gaussianity inherent in a cost function based on second-order moments. The experimental results on both simulated and real-world data consistently demonstrate the superiority of the proposed OMP algorithm in data recovery, image reconstruction, and classification. Crown Copyright (C) 2020 Published by Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107415	10.1016/j.patcog.2020.107415													
J								Attention and boundary guided salient object detection	PATTERN RECOGNITION										Salient object detection; Visual saliency; Feature learning; Fully convolutional neural network		In recent years, fully convolutional neural network (FCN) has broken all records in various vision task. It also achieves great performance in salient object detection. However, most of the state-of-the-art methods have suffered from the challenge of precisely segmenting the entire salient object with uniform region and explicit boundary and effectively suppressing the backgrounds on complex images. There is still a large room for improvement over the FCN-based saliency detection approaches. In this paper, we propose an attention and boundary guided deep neural network for salient object detection to better locate and segment the salient objects with uniform interior and explicit boundary. A channel-wise attention module is utilized to emphasize the important regions, which selects the important feature channels and assigns large weights to them. A boundary information localization module is proposed for suppressing the irrelevant boundary information to better locate and explore the useful structure of objects. The proposed approach achieves state-of-the-art performance on four well-known benchmark datasets. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107484	10.1016/j.patcog.2020.107484													
J								Gesture recognition based on deep deformable 3D convolutional neural networks	PATTERN RECOGNITION										Gesture recognition; Spatiotemporal deformable convolution; Spatiotemporal convolutional neural network	DATASET; FUSION; TIME	Dynamic gesture recognition, which plays an essential role in human-computer interaction, has been widely investigated but not yet fully addressed. The challenge mainly lies in three folders: 1) to model both of the spatial appearance and the temporal evolution simultaneously; 2) to address the interference from the varied and complex background; 3) the requirement of real-time processing. In this paper, we address the above challenges by proposing a novel deep deformable 3D convolutional neural network for end-to-end learning, which not only gains impressive accuracy in challenging datasets but also can meet the requirement of the real-time processing. We propose three types of very deep 3D CNNs for gesture recognition, which can directly model the spatiotemporal information with their inherent hierarchical structure. To eliminate the background interference, a light-weight spatiotemporal deformable convolutional module is specially designed to augment the spatiotemporal sampling locations of the 3D convolution by learning additional offsets according to the preceding feature map. It can not only diversify the shape of the convolution kernel to better fit the appearance of the hands and arms, but also help the models pay more attention to the discriminative frames in the video sequence. The proposed method is evaluated on three challenging datasets, EgoGesture, Jester and Chalearn-IsoGD, and achieves the state-of-the-art performance on all of them. Our model ranked first on Jester's official leader-board until the submission time. The code and the trained models are released for better communication and future works(1). (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107416	10.1016/j.patcog.2020.107416													
J								Multi-head enhanced self-attention network for novelty detection	PATTERN RECOGNITION										One-class classification; Multihead attention network; Adversarial-balance loss; Adversarial Learning; Multihead enhanced self-attention	ANOMALY DETECTION; CLASSIFICATION; LOCALIZATION	One-class classification (OCC) is a classical problem in computer vision that can be described as the task of classifying outlier class samples (OC samples) from the OCC model trained on inlier class samples (IC samples) when datasets are highly biased toward one class due to the insufficient sample size of the other class. Currently, the adversarial learning OCC (ALOCC) method has been proven to significantly improve OCC performance. However, its drawbacks include instability issues and non-evident reconstruction between the IC and OC samples. Therefore, we propose multihead enhanced self-attention in the ALOCC network, thereby increasing the difference between the IC and OC samples and significantly increasing OCC accuracy compared with ALOCC accuracy. For training, we propose a new loss, called adversarial-balance loss, that effectively solves the training instability problem, further increasing OCC accuracy. The experiments show the effectiveness of the proposed method compared with state-of-art methods. (C) 2020 The Authors. Published by Elsevier Ltd.																	0031-3203	1873-5142				NOV	2020	107								107486	10.1016/j.patcog.2020.107486													
J								Accelerating information entropy-based feature selection using rough set theory with classified nested equivalence classes	PATTERN RECOGNITION										Feature selection; Rough set theory; Attribute reduction; Information entropy	DEPENDENCY CALCULATION TECHNIQUE; ATTRIBUTE REDUCTION; DECISION TABLES; APPROXIMATION; UNCERTAINTY; GRANULATION; SEARCH	Feature selection effectively reduces the dimensionality of data. For feature selection, rough set theory offers a systematic theoretical framework based on consistency measures, of which information entropy is one of the most important significance measures of attributes. However, an information-entropy-based significance measure is computationally expensive and requires repeated calculations. Although many accelerating strategies have been proposed thus far, there remains a bottleneck when using an information-entropy-based feature selection algorithm to handle large-scale datasets with high dimensions. In this study, we introduce a classified nested equivalence class (CNEC)-based approach to calculate the information-entropy-based significance for feature selection using rough set theory. The proposed method extracts knowledge of the reducts of a decision table to reduce the universe and construct CNECs. By exploring the properties of different types of CNECs, we can not only accelerate both outer and inner significance calculation by discarding useless CNECs but also effectively decrease the number of inner significance calculations by using one type of CNECs. The use of CNECs is shown to significantly enhance three representative entropy-based feature selection algorithms that use rough set theory. The feature subset selected by the CNEC-based algorithms is the same as that selected by algorithms using the original definition of information entropies. Experiments conducted using 31 datasets from multiple sources, such as the UCI repository and KDD Cup competition, including large-scale and high-dimensional datasets, confirm the efficiency and effectiveness of the proposed method. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107517	10.1016/j.patcog.2020.107517													
J								A novel strategy to balance the results of cross-modal hashing	PATTERN RECOGNITION										Cross-modal hashing; Semantic gap; Semantic augmentation; Cross-modal retrieval	CODES	Hashing methods for cross-modal retrieval has drawn increasing research interests and has been widely studied in recent years due to the explosive growth of multimedia big data. However, a significant phenomenon which has been ignored is that there is a large gap between the results of cross-modal hashing in most cases. For example, the results of Text-to-Image frequently outperform that of Image-to-Text with a large margin. In this paper, we propose a strategy named semantic augmentation to improve and balance the results of cross-modal hashing. An intermediate semantic space is constructed to re-align the feature representations that embedded with weak semantic information. By using the intermediate semantic space, the semantic information of visual features can be further augmented before being sent to cross-modal hashing algorithms. Extensive experiments are carried out on four datasets via seven state-of-the-art cross-modal hashing methods. Compared against the results without semantic augmentation, the Image-to-Text results of these methods with semantic augmentation are improved considerably, which demonstrates the effectiveness of the proposed semantic augmentation strategy in bridging the gap between the results of cross-modal retrieval. Additional experiments are conducted on the real-valued, semi-supervised, semi-paired, partial-paired, and unpaired cross-modal retrieval methods, the results further indicates the effectiveness of our strategy in improving performance of cross-modal retrieval. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107523	10.1016/j.patcog.2020.107523													
J								Two-stage knowledge transfer framework for image classification	PATTERN RECOGNITION										Image classification; Teacher-student model; Two-stage classification; Sparse representation	KERNEL SPARSE REPRESENTATION; FACE; RECOGNITION	The two-stage strategy has been widely used in image classification. However, these methods barely take the classification criteria of the first stage into consideration in the second prediction stage. In this paper, we propose a novel Two-Stage Representation method (TSR), and convert it to a Single-Teacher Single-Student (STSS) problem in our two-stage knowledge transfer framework for image classification. Specifically, the first stage classifier is formulated as the teacher, which holds the 'gate value' to supervise the student classifier in the second stage. To transfer knowledge from the teacher classifier, we seek the nearest neighbours of the test sample to generate a set of candidate target classes in the first stage. Then, a student classifier learns from the samples belonging to these candidate classes in the second stage. Under the supervision of the teacher classifier, the teacher approves the student only if it obtains a higher score than the 'gate value'. In actuality, the proposed framework generates a stronger classifier by staging two weaker classifiers in a novel way. The experiments on several databases show that our proposed framework is effective, which outperforms multiple popular classification methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107529	10.1016/j.patcog.2020.107529													
J								Distractor-aware discrimination learning for online multiple object tracking	PATTERN RECOGNITION										Multi-object tracking; Distractor-aware discrimination learning; Relational attention learning		Online multi-object tracking needs to overcome the intrinsic detector deficiencies, e.g., missing detections, false alarms, and inaccurate detection responses, to grow multiple object trajectories without using future information. Various distractions exist during this growing process like background clutters, similar targets, and occlusions, which present a great challenge. We in this work propose a method for learning a distractor-aware discriminative model that can handle continuous missed and inaccurate detection problems due to the occlusion or the motion blur. To deal with target appearance variations, a relational attention learning mechanism is proposed to capture the distinctive target appearances by selectively aggregating features from history states with weights extracted from their appearance topological relationship. Based on the discrimination model, a multi-stage tracking pipeline is designed for automatic trajectory initialization, propagation, and termination. Extensive experimental analyses and comparisons demonstrate its state-of-the-art performance on widely used challenging MOT16 and MOT17 benchmarks. The source code of this work is released to facilitate further studies on the multi-object tracking problem. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107512	10.1016/j.patcog.2020.107512													
J								Learning spatial-temporal deformable networks for unconstrained face alignment and tracking in videos	PATTERN RECOGNITION										Face alignment; Face tracking; Spatial transformer; Relational reasoning; Video analysis; Biometrics	IMAGE	In this paper, we propose a spatial-temporal deformable networks approach to investigate both problems of face alignment in static images and face tracking in videos under unconstrained environments. Unlike conventional feature extractions which cannot explicitly exploit augmented spatial geometry for various facial shapes, in our approach, we propose a deformable hourglass networks (DHGN) method, which aims to learn a deformable mask to reduce the variances of facial deformation and extract attentional facial regions for robust feature representation. However, our DHGN is limited to extract only spatial appearance features from static facial images, which cannot explicitly exploit the temporal consistency information across consecutive frames in videos. For efficient temporal modeling, we further extend our DHGN to a temporal DHGN (T-DHGN) paradigm particularly for video-based face alignment. To this end, our T-DHGN principally incorporates with a temporal relational reasoning module, so that the temporal order relationship among frames is encoded in the relational feature. By doing this, our T-DHGN reasons about the temporal offsets to select a subset of discriminative frames over time steps, thus allowing temporal consistency information memorized to flow across frames for stable landmark tracking in videos. Compared with most state-of-the-art methods, our approach achieves superior performance on folds of widely-evaluated benchmarking datasets. Code will be made publicly available upon publication. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107354	10.1016/j.patcog.2020.107354													
J								Semi-supervised elastic manifold embedding with deep learning architecture	PATTERN RECOGNITION										Graph-based embedding; Elastic embedding; Deep learning architecture; Supervised learning; Semi-supervised learning	FRAMEWORK	Graph-based embedding aims to reduce the dimension of high dimensional data and to extract relevant features for learning tasks. In this letter, we propose an Elastic graph-based embedding with deep architecture which deeply explores the structural information of the data. We introduce a flexible deep learning that can overcome the limitations and weaknesses of single-layer learning models. The proposed deep architecture incorporates the geometrical manifold structure of the data. The resulting framework can be used for semi-supervised and supervised settings. Besides, the resulting optimization problems can be solved efficiently. We apply the algorithm on five public image datasets including scene, face and object datasets. These experiments demonstrate the effectiveness of the proposed embedding method, and also show that the proposed method compares favorably with many competing state-of-the-art graph-based methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				NOV	2020	107								107425	10.1016/j.patcog.2020.107425													
J								A multi-population, multi-objective memetic algorithm for energy-efficient job-shop scheduling with deteriorating machines	EXPERT SYSTEMS WITH APPLICATIONS										Job-shop scheduling; Machine speed scaling; Cumulative deterioration effect; Maintenance activity; Memetic algorithm; Periodic local search	TOTAL WEIGHTED TARDINESS; GENETIC ALGORITHM; SINGLE-MACHINE; LOCAL SEARCH; CONSUMPTION; OPTIMIZATION; MINIMIZATION; DESIGN; MODEL	This paper focuses on an energy-efficient job-shop scheduling problem within a machine speed scaling framework, where productivity is affected by deterioration. To alleviate the deterioration effect, necessary maintenance activities must be put in place during the scheduling process. In addition to sequencing operations on machines, the problem at hand aims to determine the appropriate speeds of machines and positions of maintenance activities for the schedule, in order to minimise the total weighted tardiness and total energy consumption simultaneously. To deal with this problem, a multi-population, multi-objective memetic algorithm is proposed, in which the solutions are distributed into sub-populations. Besides a general local search, an advanced objective-oriented local search is also executed periodically on a portion of the population. These local search methods are designed based on a new disjunctive graph introduced to cover the solution space. Furthermore, an efficient non-dominated sorting method for bi-objective optimisation is developed. The performance of the memetic algorithm is evaluated via a series of comprehensive computational experiments, comparing it with state-of-the-art algorithms presented for job-shop scheduling problems with/without considering energy efficiency. Experimental results confirm that the proposed algorithm can outperform other algorithms being compared across a range of performance metrics. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113348	10.1016/j.eswa.2020.113348													
J								Negation and entropy: Effectual knowledge management equipment for learning organizations	EXPERT SYSTEMS WITH APPLICATIONS										Entropy; Negation; Learning organization; Knowledge management; Decision making	BELIEF FUNCTIONS; INFORMATION; SYSTEMS; PERSPECTIVE; TECHNOLOGY; ATTENTION; PROJECT; MODEL; SET	The present paper aims to put forward negation and entropy as novel perspectives for knowledge management in learning organizations. The present work considers the surrounding factors of information to enumerate the effectiveness of information in the knowledge management field. Moreover, by utilizing the effectiveness of surrounding factors, a framework inspired by Dempster-Shafer theory has been presented to generate negation. Finally, the present paper defines and calculates entropy for information. We have applied negation and entropy concepts to two well-known cases of organizational systems and management domains to study their impact on the knowledge management domain. The cases have supported our decisions taken after the calculation of proposed negation and entropy concepts. The proposed method has a quality interpretation of the information operators and has the merit of simplifying knowledge management and decision making problems in the context of a learning organization. The present study combines multiple aspects of knowledge management, organizational systems, decision making, and organizational learning. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113497	10.1016/j.eswa.2020.113497													
J								PV-DAE: A hybrid model for deceptive opinion spam based on neural network architectures	EXPERT SYSTEMS WITH APPLICATIONS										Deceptive opinion spam; Neural networks; Machine learning; Deep learning; Paragraph vector model; Denoising autoencoder model		Opinion review is of great importance for both customers and organizations. Indeed, it helps customers in buying decisions and represents a valuable feedback for the companies, allowing them to improve their productions. However, numerous greedy companies resort to fake reviews in order to influence the customer and brighten the brand image, or to defame the one of their competitors. Various models are proposed in order to detect deceptive opinion reviews. Most of these models adopt traditional methods focusing on feature extraction and traditional classifiers. Unfortunately, these models do not capture the semantic aspect while ignoring the opinion's context. In order to tackle this issue, we propose a new approach based on Paragraph Vector Distributed Bag of Words (PV-DBOW) and the Denoising Autoencoder (DAE). The proposed customized model provides a strong representation which is based on a global representation of the opinions while preserving their semantics. Indeed, the embedding vectors capture the semantic meaning of all words in the context of each opinion. The generated review representations are fed into a fully connected neural network in order to detect deceptive opinion spam. The obtained results concerning the deception dataset show that our model is effective and outperforms the existing state-of-the-art methodologies. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113517	10.1016/j.eswa.2020.113517													
J								Rationalized fruit fly optimization with sine cosine algorithm: A comprehensive analysis	EXPERT SYSTEMS WITH APPLICATIONS										Fruit fly optimization algorithm; Sine cosine algorithm; Global optimization; Swarm intelligence; Kernel extreme learning machine	EXTREME LEARNING-MACHINE; PARTICLE SWARM OPTIMIZATION; SUPPORT VECTOR MACHINES; WHALE OPTIMIZATION; GLOBAL OPTIMIZATION; INSPIRED OPTIMIZER; FEATURE-SELECTION; NEURAL-NETWORK; MODEL; IDENTIFICATION	The fruit fly optimization algorithm (FOA) is a well-regarded algorithm for searching the global optimal solution by simulating the foraging behavior of fruit flies. However, when solving high dimensional mathematical and practical application problems, FOA is not competitive in convergence speed, and it may quickly fall into the local optimum. Therefore, in this paper, an enhanced fruit fly optimizer, termed SCA_FOA, is developed by introducing the logic of the sine cosine algorithm (SCA). Specifically, in the process of searching for food utilizing the osphresis organ, the individual fruit fly adopts the way inspired by the SCA to fly outward or inward to find the global optimum. A comprehensive set of 28 benchmark functions were used to measure the exploitation and exploration abilities of the proposed SCA_FOA. The results demonstrate that SCA_FOA is superior to other competitive algorithms. Moreover, 10 practical problems from IEEE CEC 2011, three engineering problems, three shifted and asymmetrical functions, and optimization problems of kernel extreme learning machines (KELM) were also solved, effectively. The results and observations indicate that not only the proposed SCA_FOA can be used for simulated problems as a very efficient method, but also it can be employed for real-world applications. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113486	10.1016/j.eswa.2020.113486													
J								Two-stage additive network DEA: Duality, frontier projection and divisional efficiency	EXPERT SYSTEMS WITH APPLICATIONS										Data envelopment analysis; Additive network model; Duality; Frontier projection; Divisional efficiency	DATA ENVELOPMENT ANALYSIS; DECOMPOSITION; MODELS; WEIGHTS	In the previous literature, it is demonstrated that the dual equivalence of multiplier and envelopment models that exists in standard data envelopment analysis (DEA) is not necessarily true for network DEA to derive frontier projection and divisional efficiency. Multiplier network model is often used for computing the divisional efficiency while envelopment network model is often used for identifying the frontier projection for inefficient decision making units (DMUs). In this paper, we show that the duality of standard DEA can be extended to two-stage additive network DEA. We propose an improved golden section method to solve parametric linear multiplier network model. Based on the primal-dual corre-spondence of parametric linear programming, we subsequently develop envelopment network model in parametric linear form to determine frontier projection and to find divisional efficiency as well. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113478	10.1016/j.eswa.2020.113478													
J								HBoost: A heterogeneous ensemble classifier based on the Boosting method and entropy measurement	EXPERT SYSTEMS WITH APPLICATIONS										Ensemble learning; Heterogeneous models; Boosting classifier; Ensemble pruning; Ensemble diversity	FEATURE-SELECTION; DIVERSITY; DES	In recent years, ensemble classifiers have attracted a lot of attention in the field of machine learning. The main challenges with these classifiers are 1) to select the base classifiers and 2) to combine the outputs. The key point for an ensemble to be successful is the diversity and accuracy of the base classifiers. This paper proposes a heterogeneous Boosting-based ensemble classifier (HBoost) which is inspired by Boosting algorithm and aims at increasing the diversity by recruiting distinct learning algorithms. In this approach, for each learning algorithm, several classifiers are generated by using the Boosting method and a matrix of heterogeneous classifiers is formed. Since all generated classifiers may not be appropriate for generating the final output, the subset of those that make the most diverse and accurate classifiers is selected and the rest of the classifiers are eliminated. Finally, the classifiers in the subset are combined based on the weight assigned to each classifier. HBoost is a self-configured algorithm i.e., unlike existing methods, it does not require a human expert to specify the type of base classifiers manually. It can also automatically determine the optimum number of base classifiers which should be combined. For evaluating the HBoost, two evaluation metrics have been used: Accuracy and Geometric Mean which are the most popular metrics to measure the performance of a classifier. We compare the proposed approach in three different scenarios 1) all the base classifiers are in the ensemble, 2) four traditional ensemble methods including Bagging, Boosting, Stacking, and StackingC, 3) two state-of-the-art approaches in the literature including Random Forest and Classifier Subset Selection (CSS). HBoost is performed on 20 datasets from the UCI repository and experimental results reveal how adequate the HBoost is in comparison to other approaches. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113482	10.1016/j.eswa.2020.113482													
J								Wearable payment: A deep learning-based dual-stage SEM-ANN analysis	EXPERT SYSTEMS WITH APPLICATIONS										Mobile payment; Smart wearable devices; Deep learning; Fashion Theory; Technology Readiness Theory	NEURAL-NETWORK ANALYSIS; MOBILE CREDIT CARD; MODELING PLS-SEM; TECHNOLOGY READINESS; USER ACCEPTANCE; ADOPTION; FASHION; PRODUCT; INTENTIONS; SYSTEMS	The research paper purports to assess the antecedents that affect users' behavioral intention to use wearable payment. Specifically, this empirical research examines the roles of perceived aesthetics, technology readiness, mobile usefulness, and mobile ease of use on behavioral intention. Differing from past mobile payment studies, a newly proposed methodology that involves a dual-stage analysis and an emerging Artificial Intelligence analysis named deep learning was performed on 307 usable responses. Findings revealed that all relationships were supported except for the linkage between mobile ease of use and behavioral intention. The results of this study provide valuable insights to payment companies and smart wearable device manufacturers to come up with plans and marketing strategies to convince the potential adopters to adopt wearable payment, guiding marketers to design a more successful wearable payment solution. Theoretically, the newly integrated theoretical model that incorporates Mobile Technology Acceptance Model, Fashion Theory, and Technology Readiness Theory could help ascertain the relative significance of certain determinants, providing a clearer insight on the acceptance of wearable payment among consumers. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113477	10.1016/j.eswa.2020.113477													
J								On the design of hardware architectures for parallel frequent itemsets mining	EXPERT SYSTEMS WITH APPLICATIONS										Frequent itemsets mining; Data streams; Custom architectures; FPGAs; ECLAT	ALGORITHMS	Algorithms for Frequent Itemsets Mining have proved their effectiveness for extracting frequent sets of patterns in datasets. However, in some specific cases, they do not obtain the expected results in an acceptable time. For this reason, Field Programmable Gates Array-based architectures for Frequent Itemsets Mining have been proposed to accelerate this task. The current paper proposes a search strategy for Frequent Itemsets Mining based on equivalence classes partitioning. The partitioning on equivalence classes allows dividing the search space into disjoint sets that can be processed in parallel. Consequently, this paper presents the design and implementation of two hardware architectures that exploit the nested parallelism in the proposed search strategy. These hardware architectures are capable of obtaining frequent itemsets regardless of the number of distinct items and the number of transactions in the dataset, which are the main issues reported in the reviewed literature. Furthermore, the proposed architectures explore the trade-off between acceleration and hardware resource utilization. The experimental results obtained demonstrate that the proposed search strategy can be scaled to achieve a speedup in the processing time of 40 times faster than software-based implementations. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113440	10.1016/j.eswa.2020.113440													
J								An online isotonic separation with cascade architecture for binary classification	EXPERT SYSTEMS WITH APPLICATIONS										Isotonic separation; Cascade Isotonic separation; Cascading	PREDICTION; TUTORIAL	Isotonic separation (IS) is a non-parametric classification technique which constructs an isotonic function from ordered data. The rationale is to convert partially isotonic data into isotonic using a linear programming problem (LPP) and partition the input space into isotonic and non-isotonic regions to make predictions easier. Despite the widespread applications of IS in diverse domains where monotonicity exists, it has certain limitations: Firstly, computing time and the constraints of the LPP in isotonic separation increase polynomially as size of the data increases and it is highly complex to solve the LPP and obtain the model on large data sets. In order to support dynamic stream data and address the computational overhead and size of the LPP issues, this paper proposes an online isotonic separation algorithm called Cascade-IS (CIS) for binary classification. The rationale behind CIS is that it splits the data set into a sequence of partitions and models are obtained and combined in cascade. Statistical and experimental analysis are done on datasets with isotonic properties and the results prove that CIS is superior to its variants in terms of training time, performance measures and number of constraints in the LPP. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113466	10.1016/j.eswa.2020.113466													
J								Modeling adaptive E-Learning environment using facial expressions and fuzzy logic	EXPERT SYSTEMS WITH APPLICATIONS										Intelligent E-Learning system; Adaptive E-Learning environment; Expert E-Learning system; Fuzzy learning flow; Deep learning; Facial expression recognition	INTELLIGENT TUTORING SYSTEMS; EMOTION RECOGNITION	The integration of two or more intelligent systems, such as deep neural networks and fuzzy techniques, results in so-called hybrid intelligent systems. These have recently attracted considerable attention owing to their broad success in several complex real-world applications. An interesting example is the development of adaptive computer-based learning environments, in which learner responses to certain questions are considered so that the next level of the learning process may be determined. However, these methods fail to capture the behavior and emotional expressions of the learner during the learning process. Capturing these could make the learning flow more adaptive, and could allow the learning environment to redirect learners to different learning paths based on their capabilities and interaction levels. In this regard, the contribution of the present study is threefold. First, it proposes an approach for modeling an intelligent adaptive e-learning environment by considering the integration of the learner responses to questions and their emotional states. In the proposed approach, a loosely coupled integration between a convolutional neural network (CNN) and a fuzzy system is adopted. The CNN is used to detect a learner's facial expressions, and outperforms other CNN models on the same training benchmark. The fuzzy system is used to determine the next learning level based on the extracted facial expression states from the CNN and several response factors by the learner. Second, the study introduces methods whereby a group of facial expressions is aggregated into a single representative. Third, it introduces corpora for evaluating the performance of the proposed approach. The corpora of 12 learners contain 72 learning activities and 1735 data points of distinct emotional states. The experimental results using these corpora demonstrate that the proposed approach provides adaptive learning flows that match the learning capabilities of all learners in a group. Moreover, the approach allows decision makers to monitor the learning performance for each learner. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113460	10.1016/j.eswa.2020.113460													
J								An ACS-based memetic algorithm for the heterogeneous vehicle routing problem with time windows	EXPERT SYSTEMS WITH APPLICATIONS										Heterogeneous VRPTW; Ant colony system; Memetic algorithms; VNTS	ANT COLONY OPTIMIZATION; NEIGHBORHOOD TABU SEARCH; FLEET SIZE	This paper presents a solution methodology to solve the heterogeneous vehicle routing problem with time windows (HVRPTW). This problem appears when a limited fleet of vehicles, characterized by different capacities, fixed costs and variable costs, is available for serving a set of customers which have to be visited within a predefined time window. The objective is to perform the route design minimizing the total fixed vehicle costs and distribution costs and satisfying all problem constraints. The problem is solved using an Ant Colony System (ACS) algorithm which has been successfully applied to combinatorial optimization problems. Moreover, to improve the performance of the ACS on the HVRPTW, a hybridized ACS with local search, called memetic ACS algorithm is proposed where the local search is performed by a variable neighborhood Tabu Search algorithm. Experiments are conducted on sets of benchmark instances from the scientific literature to evaluate the performance of the proposed algorithm. The results show that the algorithm has a good performance on the HVRPTW. In particular, out of the 80 instances, it obtained 65 new best solutions and matched 6 within reasonable computational times. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113379	10.1016/j.eswa.2020.113379													
J								Boundary constrained voxel segmentation for 3D point clouds using local geometric differences	EXPERT SYSTEMS WITH APPLICATIONS										Octree; Point cloud segmentation; Segmentation dataset; Weighting	EXTRACTION; RECONSTRUCTION; CLASSIFICATION	In 3D point cloud processing, the spatial continuity of points is convenient for segmenting point clouds obtained by 3D laser scanners, RGB-D cameras and LiDAR (light detection and ranging) systems in general. In real life, the surface features of both objects and structures give meaningful information enabling them to be identified and distinguished. Segmenting the points by using their local plane directions (normals), which are estimated by point neighborhoods, is a method that has been widely used in the literature. The angle difference between two nearby local normals allows for measurement of the continuity between the two planes. In real life, the surfaces of objects and structures are not simply planes. Surfaces can also be found in other forms, such as cylinders, smooth transitions and spheres. The proposed voxel-based method developed in this paper solves this problem by inspecting only the local curvatures with a new merging criteria and using a non-sequential region growing approach. The general prominent feature of the proposed method is that it mutually one-to-one pairs all of the adjoining boundary voxels between two adjacent segments to examine the curvatures of all of the pairwise connections. The proposed method uses only one parameter, except for the parameter of unit point group (voxel size), and it does not use a mid-level over-segmentation process, such as supervoxelization. The method checks the local surface curvatures using unit normals, which are close to the boundary between two growing adjacent segments. Another contribution of this paper is that some effective solutions are introduced for the noise units that do not have surface features. The method has been applied to one indoor and four outdoor datasets, and the visual and quantitative segmentation results have been presented. As quantitative measurements, the accuracy (based on the number of true segmented points over all points) and F1 score (based on the means of precision and recall values of the reference segments) are used. The results from testing over five datasets show that, according to both measurement techniques, the proposed method is the fastest and achieves the best mean scores among the methods tested. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113439	10.1016/j.eswa.2020.113439													
J								Gold volatility prediction using a CNN-LSTM approach	EXPERT SYSTEMS WITH APPLICATIONS										Gold price volatility; Volatility forecasting; Deep learning; CNN; LSTM; Stock returns forecasting; Hyperparameter setting	SAFE HAVEN; PRICE-VOLATILITY; HEDGE; MODEL; FORECAST; TIME	Prediction of volatility for different types of financial assets is one of the tasks of greater mathematical complexity in time series prediction, mainly due to its noisy, non-stationary and heteroscedastic structure. On the other hand, gold is an asset of particular importance for hedging and diversification of investment portfolios, and therefore it is important to predict future volatility of this asset. This paper seeks to significantly improve the forecast of gold volatility by combining two deep learning methodologies: short-term memory networks (LSTM) added to convolutional neural networks (specifically a pre-trained VGG16 network). It is important to mention that these types of hybrid architectures have not been used in time series prediction, so it is a completely new approach to solving these types of problems. The CNN-LSTM hybrid model is capable of including images as input which provides a wide variety of information associated with both static and dynamic characteristics of the series. In parallel, different lags of profitability of the series are entered as input, which allows it to learn from the temporal structure. The results show a substantial improvement when this hybrid model is compared to the GARCH and LSTM models. A 37% reduction in MSE is observed compared to the classic GARCH model, and 18% compared to the LSTM model. Finally, the Model Confidence Model (MCS) determines a significant improvement in the prediction of the hybrid model. The fundamental importance of this research lies in the application of a new type of architecture capable of processing various sources of information for any time series prediction task. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113481	10.1016/j.eswa.2020.113481													
J								Cost-sensitive multiple-instance learning method with dynamic transactional data for personal credit scoring	EXPERT SYSTEMS WITH APPLICATIONS										Credit risk assessment; Dynamic transactional data; Cost-sensitive learning; Multiple-instance learning	ART CLASSIFICATION ALGORITHMS	We study how to assess an applicant's credit risk with dynamic transactional data. The problem arises when an applicant applies for loans from financial institutions. A traditional credit-risk assessment model utilizes individual demographic and loan information from an application form. Nevertheless, dynamic transactional data is good indicators of an applicant's credit risk. However, the lack of available data and the preexisting limitations of conventional approaches limit the use of the dynamic transactional data. In this study, we propose a cost-sensitive multiple-instance learning (MIL) approach to evaluate applicants' credit scores that incorporate their dynamic transactional data and static individual information. Traditionally, MIL approaches can handle the variable number of input instances. However, to facilitate the implementation of MIL into credit scoring, we extend the MIL to consider the dynamic transactional data and cost-sensitive problem simultaneously. We compare our model with several benchmark MIL models by testing them on real-world data sets. Experimental results show that our model outperforms most benchmarks in many widely used criteria. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113489	10.1016/j.eswa.2020.113489													
J								Entrotaxis-Jump as a hybrid search algorithm for seeking an unknown emission source in a large-scale area with road network constraint	EXPERT SYSTEMS WITH APPLICATIONS										Source seeking; Autonomous search; Road network constraint; Bayesian inference; Intermittent search strategy; Entrotaxis-Jump algorithm	IDENTIFICATION; LOCALIZATION; OPTIMIZATION; PATTERNS; LEVY	In a sudden hazardous material leakage accident, the rapid and accurate localization of the leakage source can effectively reduce casualties and property losses. Utilizing the sensible robot to seek an unknown emission source has become a promising field, while most researches in this field fail to consider some intractable but practical factors, such as the large spatial scale of some search domains and the road network (that can obstruct robot's maneuver). This paper proposes an efficient search algorithm, named as Entrotaxis-Jump, to seek an unknown emission source and obtain other source terms (e.g., source strength) in a large-scale (>0.1 km(2)) practical scene with road network constraints, such as a chemical cluster. The hybrid algorithm incorporates the Entrotaxis algorithm (a kind of cognitive search algorithm) with the intermittent search strategy, so it can utilize the triggering jump motion to alleviate the negative factors for search (road network constraints, expansive search domain, and turbulence effect). We select a chemical cluster in Shanghai, China as the typical research area and conduct a series of simulations in it to compare the performance of the Entrotaxis with the Entrotaxis-Jump under various release strength Q and wind speed V. The performance is reflected by the success rate (SR) and mean search time (MST), and we propose a skill score S to consider the two indexes synthetically. The results denote that the Entrotaxis-Jump outperforms Entrotaxis in all of our simulated scenarios, especially when the wind speed V > 2, in which case the SR of Entrotaxis drops sharply while the SR of the Entrotaxis-Jump witnesses a little decline but remains over 90%. The Entrotaxis-Jump algorithm proposed in this paper considers more practical factors, compared to previous researches, and is suitable and robust to utilize in real scenarios. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				NOV 1	2020	157								113484	10.1016/j.eswa.2020.113484													
J								Replay spoofing countermeasure using autoencoder and siamese networks on ASVspoof 2019 challenge	COMPUTER SPEECH AND LANGUAGE											FEATURES																		0885-2308	1095-8363				NOV	2020	64								101105	10.1016/j.csl.2020.101105													
J								Novel textual features for language modeling of intra-sentential code-switching data	COMPUTER SPEECH AND LANGUAGE										Code-switching; Textual features; Factored language modeling		Code-switching refers to the frequent use of non-native language words/phrases by speakers while conversating in their native languages. Traditionally, for training a language model (LM) for code-switching data, one is required to tediously collect a large amount of text corpus in the respective code-switching domain. Alternately, we recently proposed a more viable approach that adapts an existing native LM to handle the code-switching data. In this work, we present our efforts for language modeling of code-switching data following both the traditional and the proposed approaches. The salient contributions of this paper includes: (i) creation of the Hindi-English code-switching text corpus, (ii) an improved parts-of-speech (POS) labeling scheme for accurate tagging of non-native words embedded in the code-switching data, and (iii) the proposal of a novel textual feature referred to as the code-switching location (CSL) feature, that allows LMs to predict the code-switching instances. The evaluation of the proposed features has been done on two code-switching datasets: Hindi-English and Mandarin-English. On experimental evaluation, a substantial reduction in the perplexity is achieved with the use of the improvised POS features. It is also observed that the proposed CSL features provide an independent and additive improvement over the POS features in terms of perplexity. (c) 2020 Elsevier Ltd. All rights reserved.																	0885-2308	1095-8363				NOV	2020	64								101099	10.1016/j.csl.2020.101099													
J								Determination of glottal closure instants from clean and telephone quality speech signals using single frequency filtering	COMPUTER SPEECH AND LANGUAGE											EPOCH EXTRACTION; LINEAR PREDICTION; EMOTIONAL SPEECH; EXCITATION																		0885-2308	1095-8363				NOV	2020	64								101097	10.1016/j.csl.2020.101097													
J								Vocal tract shaping of emotional speech	COMPUTER SPEECH AND LANGUAGE											AREA FUNCTIONS; MODEL																		0885-2308	1095-8363				NOV	2020	64								101100	10.1016/j.csl.2020.101100													
J								Investigating topics, audio representations and attention for multimodal scene -aware dialog	COMPUTER SPEECH AND LANGUAGE																													0885-2308	1095-8363				NOV	2020	64								101102	10.1016/j.csl.2020.101102													
J								Transfer learning for multimodal dialog	COMPUTER SPEECH AND LANGUAGE																													0885-2308	1095-8363				NOV	2020	64								101093	10.1016/j.csl.2020.101093													
J								Hybrid -task learning for robust automatic speech recognition	COMPUTER SPEECH AND LANGUAGE											DEEP NEURAL-NETWORKS; FRONT-END; NOISE																		0885-2308	1095-8363				NOV	2020	64								101103	10.1016/j.csl.2020.101103													
J								Cluster -based beam search for pointer -generator chatbot grounded by knowledge	COMPUTER SPEECH AND LANGUAGE																													0885-2308	1095-8363				NOV	2020	64								101094	10.1016/j.csl.2020.101094													
J								ASVspoof 2019: A large-scale public database of synthetized, converted and replayed speech	COMPUTER SPEECH AND LANGUAGE											SPEAKER; COUNTERMEASURES; VOCODER																		0885-2308	1095-8363				NOV	2020	64								101114	10.1016/j.csi.2020.101114													
J								Replay anti -spoofing countermeasure based on data augmentation with post selection	COMPUTER SPEECH AND LANGUAGE											SPEAKER VERIFICATION; NEURAL-NETWORK; FEATURES; ATTACK																		0885-2308	1095-8363				NOV	2020	64								101115	10.1016/j.csl.2020.101115													
J								Hyperspectral image classification based on discriminative locality broad	KNOWLEDGE-BASED SYSTEMS										Broad learning system; Hyperspectral images; Information fusion; Local manifold structure	REMOTE-SENSING IMAGES; FEATURE-EXTRACTION; FRAMEWORK	Recently, broad learning system (BLS) has been widely used for its simple, fast and excellent generalization ability in hyperspectral image (HSI) classification. However, how to implement a broad learning system for fine-grained classification of hyperspectral images with a few-shot setting is still a challenging problem. In this paper, we proposed a new method based on the discriminative locality preserving broad learning system (DPBLS) for hyperspectral image classification by exploiting the manifold structure between neighbouring pixels of hyperspectral image. To make full use of the spectral and spatial information of hyperspectral images.we firstly leverage edge-preserving filters to fuse both spectral and spatial features of hyperspectral image samples. Secondly, we introduce discriminative information and local manifold structure of samples into the broad learning system to enhance the discriminative ability of output weights and improve its performance on hyperspectral image classification task. In order to verify the performance of the framework proposed in this paper, we conducted experiments on four hyperspectral image datasets. experiment results show that the method we proposed is well-performed on hyperspectral image classification tasks. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106319	10.1016/j.knosys.2020.106319													
J								Novel metrics for computing semantic similarity with sense embeddings	KNOWLEDGE-BASED SYSTEMS										Semantic similarity; Semantic similarity metrics; Sense embeddings; Word embeddings; Sense identification; Lexical semantics; Cognitively plausible similarity metrics	TERM-MEMORY; WORD; REPRESENTATIONS; FEATURES; CONTEXT	In the last years many efforts have been spent to build word embeddings, a representational device in which word meanings are described through dense unit vectors of real numbers over a continuous, high-dimensional Euclidean space, where similarity can be interpreted as a metric. Afterwards, sense-level embeddings have been proposed to describe the meaning of senses, rather than terms. More recently, additional intermediate representations have been designed, providing a vector description for pairs (term, sense), and mapping both term and sense descriptions onto a shared semantic space. However, surprisingly enough, this wealth of approaches and resources has not been supported by a parallel refinement in the metrics used to compute semantic similarity: to date, the semantic similarity featuring two input entities is mostly computed as the maximization of some angular distance intervening between vector pairs, typically cosine similarity. In this work we introduce two novel similarity metrics to compare sense-level representations, and show that by exploiting the features of sense-embeddings it is possible to substantially improve on existing strategies, by obtaining enhanced correlation with human similarity ratings. Additionally, we argue that semantic similarity needs to be complemented by another task, involving the identification of the senses at the base of the similarity rating. We experimentally verified that the proposed metrics are beneficial when dealing with both semantic similarity task and sense identification task. The experimentation also provides a detailed how-to illustrating how six important sets of sense embeddings can be used to implement the proposed similarity metrics. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106346	10.1016/j.knosys.2020.106346													
J								Mining user interest based on personality-aware hybrid filtering in social networks	KNOWLEDGE-BASED SYSTEMS										Interest mining; Personality computing; User modeling; Interest graph; Personality traits; Big five; User interest; Social computing	PREDICTION; BEHAVIOR; TOPICS; MEDIA	With the emergence of online social networks and microblogging websites, user interest mining has been an active research topic for the past few years. However, most of the existing works suffer from two significant drawbacks, firstly, they focus on the user's explicit content and social network structure to predicate the user's interests, neglecting the fact that the user's personality might be a rich source to infer the topical interests. Secondly, they represent the user's content using the bag-of-words model that ignores the chronological order of the posted content, hence the predicted interests might contain outdated topics that the user does not interest anymore. In this paper, we propose a novel user interest mining system based on Big Five personality traits and dynamic interests. To prove the effectiveness of incorporating the user's personality traits in the interest mining process, we have implemented a social network for news sharing and conducted different experiments on the collected data. The experiment results show that considering personality traits can increase the precision and recall of interest mining systems, as well as can help to tackle the cold start problem. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106227	10.1016/j.knosys.2020.106227													
J								Sequentially spherical data modeling with hidden Markov models and its application to fMRI data analysis	KNOWLEDGE-BASED SYSTEMS										Spherical data; Hidden Markov models; Von Mises-Fisher; Mixture models; Variational Bayes; fMRI data analysis	VARIATIONAL INFERENCE; DIRICHLET; MIXTURES; SPACE	Due to the reason that spherical data (i.e. L-2 normalized vectors) are often involved with various real life applications (such as anomaly detection, gesture recognition, intrusion detection in networks, gene expression data analysis, etc.), spherical data modeling has recently become an important research topic. In this work, we address the problem of modeling sequentially spherical data through continuous hidden Markov models (HMMs). Instead of adopting Gaussian mixture models (GMMs) as the emission distributions as in common continuous HMMs, we propose a continuous HMM by considering the mixture of von Mises-Fisher (VMF) distributions as its emission densities. Then, we systematically propose an effective method based on variational Bayes (VB) to learn the VMF-based HMM. The developed learning method has the following merits: (1) It is convergence-guaranteed; (2) It can be optimized with closed-form solutions. The proposed VMF-HMM with VB learning is validated by conducting experiments on both simulated sequential spherical data and a real application about fMRI data analysis. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106341	10.1016/j.knosys.2020.106341													
J								Density peaks clustering with gap-based automatic center detection	KNOWLEDGE-BASED SYSTEMS										Data clustering; Density peaks clustering; Decision graph; Automatic center detection	FAST SEARCH; INTRUSION DETECTION; ALGORITHM; FIND; SYSTEM; NEIGHBORS; STREAM	Clustering is a task used to group data from variegated sources, including Big Data, the Internet of Things, and social media. Density peaks clustering (DPC) has become a popular clustering technique for its simplicity and quality. However, DPC requires a proper subset of input data points to be selected as centers using a plot called "decision graph". This manual specification adds subjectivity and instability, besides breaking the continuous flow of the algorithm. Automatic center detection approaches struggle with obtaining good results while avoiding to add parameters and complexity to the algorithm. We propose an approach to automatically determine cluster centers by detecting gaps between data points in a one-dimensional version of the decision graph; we detect these gaps heuristically by comparing the distance (difference) between pairs of consecutive points in terms of their gamma score. We tested our approach on synthetic and UCI data sets. Results show that the number of clusters is accurately predicted in comparison to other state-of-the-art methods using F-score and Adjusted Rand Index. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106350	10.1016/j.knosys.2020.106350													
J								A distance correlation-based Kriging modeling method for high-dimensional problems	KNOWLEDGE-BASED SYSTEMS										Kriging; Distance correlation; High-dimensional expensive problems; Metamodels	GLOBAL SENSITIVITY-ANALYSIS; VARIABLE SELECTION; OPTIMIZATION METHOD; DEPENDENCE; DESIGN; APPROXIMATION; IMPROVEMENT; OUTPUT	By using the kriging modeling method, the design efficiency of computationally expensive optimization problems is greatly improved. However, as the dimension of the problem increases, the time for constructing a kriging model increases significantly. It is unaffordable for limited computing resources, especially for the cases where the kriging model needs to be constructed frequently. To address this challenge, an efficient kriging modeling method which utilizes a new spatial correlation function, is developed in this article. More specifically, for the characteristics of optimized hyper-parameters, distance correlation (DIC) is used to estimate the relative magnitude of hyper-parameters in the new correlation function. This translates the hyper-parameter tuning process into a one-dimensional optimization problem, which greatly improves the modeling efficiency. Then the corrector step is used to further exploit the hyper-parameters space. The proposed method is validated through nine representative numerical benchmarks from 10-D to 60-D and an engineering problem with 35 variables. Results show that when compared with the conventional kriging, the modeling time of the proposed method is dramatically reduced. For the problems with more than 30 variables, the proposed method can obtain a more accurate kriging model. Besides, the proposed method is compared with another state-of-the-art high-dimensional Kriging modeling method, called KPLS+K. Results show that the proposed method has higher modeling accuracy for most problems, while the modeling time of the two methods is comparable. It can be conclusive that the proposed method is very promising and can be used to significantly improve the efficiency for approximating high-dimensional expensive problems. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106356	10.1016/j.knosys.2020.106356													
J								Surrogate dropout: Learning optimal drop rate through proxy	KNOWLEDGE-BASED SYSTEMS										Deep neural networks; Dropout; Regularization	NEURAL-NETWORKS	Dropout is commonly used in deep neural networks to alleviate the problem of overfitting. Conventionally, the neurons in a layer indiscriminately share a fixed drop probability, which results in difficulty in determining the appropriate value for different tasks. Moreover, this static strategy will also incur serious degradation on performance when the conventional dropout is extensively applied to both shallow and deep layers. A question is whether selectively dropping the neurons would realize a better regularization effect. This paper proposes a simple and effective surrogate dropout method whereby neurons are dropped according to their importance. The proposed method has two main stages. The first stage trains a surrogate module that can be jointly optimized along with the neural network to evaluate the importance of each neuron. In the second stage, the output of the surrogate module is regarded as a guidance signal for dropping certain neurons, approximating the optimal per neuron drop rate when the network converges. Various convolutional neural network architectures and multiple datasets, including CIFAR-10, CIFAR-100, SVHN, Tiny ImageNet, and two medical image datasets are used to evaluate the surrogate dropout method. The experimental results demonstrate that the proposed method achieves a better regularization effect than the baseline methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106340	10.1016/j.knosys.2020.106340													
J								Self-centralized jointly sparse maximum margin criterion for robust dimensionality reduction	KNOWLEDGE-BASED SYSTEMS										Maximum margin criterion; Robustness; Adaptive centroid; L-1,L-2-norm sparsity; Dimensionality reduction	LINEAR DISCRIMINANT-ANALYSIS; FACE RECOGNITION	Linear discriminant analysis (LDA) is among the most popular supervised dimensionality reduction algorithms, which has been largely followed in the fields of pattern recognition and data mining. However, LDA has three major drawbacks. One is the challenge brought by small-sample-size (SSS) problem; second makes it sensitive to outliers due to the use of squared L-2-norms in the scatter loss evaluation; the third is the case that the feature loadings in projection matrix are relatively redundant and there is a risk of overfitting. In this paper, we put forward a novel functional expression for LDA, which combines maximum margin criterion (MMC) with a weighted strategy formulated by L-1,L-2-norms to against outliers. Meanwhile, we simultaneously realize the adaptive calculation of weighted intra-class and global centroid to further reduce the influence of outliers, and employ the L-2,L-1-norm to constrain row sparsity so that subspace learning and feature selection could be performed cooperatively. Besides, an effective alternating iterative algorithm is derived and its convergence is verified. From the complexity analysis, our proposed algorithm can deal with large-scale data processing. Our proposed model can address the sensitivity problem of outliers and extract the most representative features while preventing overfitting effectively. Experiments performed on several benchmark databases demonstrate that the proposed algorithm is more effective than some other state-of-the-art methods and has better generalization performance. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106343	10.1016/j.knosys.2020.106343													
J								Relation classification via knowledge graph enhanced transformer encoder	KNOWLEDGE-BASED SYSTEMS										Relation classification; Knowledge graph embedding; Transformer		Relation classification is an important task in natural language processing fields. The goal is to predict predefined relations for the marked nominal pairs in given sentences. State-of-the-art works usually focus on using deep neural networks as classifier to conduct the relation prediction. The rich semantic information of relationships in the triples of existing knowledge graph (KG) can be used as additional supervision for relation classification. However, these relationships were simply used as labels to specify the class of sentences in previous works, and their semantic information was completely ignored. In this paper, a novel approach is proposed for relation classification, which jointly uses information from textual sentences and knowledge graphs. To this end, we introduce a Transformer encoder to measure the semantic similarity between sentences and relation types. Besides, we connect the semantic information of marked nominals in sentences with that of the corresponding entities in knowledge graph to generate the semantic matching information between textual relations and KG relations. The matching information can provide additional supervision for relation classification. Since the words and entities are used interactively with each other in our work, we propose an embedding translating strategy to handle the semantic gap problem between word embeddings and entity embeddings. Experimental results on two widely used datasets, SemEval-2010 Task 8 and TACRED, show that our approach is able to efficiently use the semantic information from the knowledge graph to enhance the performance of the Transformer encoder for relation classification. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106321	10.1016/j.knosys.2020.106321													
J								Suppression techniques for privacy-preserving trajectory data publishing	KNOWLEDGE-BASED SYSTEMS										Trajectories; Privacy protection; Indexing structures; Pruning strategies	ANONYMIZATION	In this paper, we study the problem of protecting privacy in trajectory datasets from adversaries who can exploit their partial knowledge to infer unknown locations. To efficiently solve this problem, we propose a tree-based indexing structure to store all trajectory data and develop pruning strategies. We provide two algorithms to find a safe counterpart of the original trajectory dataset by using the pruning strategies. Finally, our experimental results demonstrate the efficiency of the proposed algorithms. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106354	10.1016/j.knosys.2020.106354													
J								Predicting taxi demands via an attention-based convolutional recurrent neural network	KNOWLEDGE-BASED SYSTEMS										Taxi demand prediction; Convolutional recurrent neural networks; Context-aware attention mechanism; Multi-view spatial-temporal feature extraction		As a flexible public transportation in urban areas, taxis play an important role in providing comfortable and convenient services for passengers. Due to the existence of the imbalance between supply of drivers and demand of passengers, an accurate fine-grained taxi demand prediction in real time can help guide drivers to plan their routes and reduce the waiting time of passengers. Recently, several methods based on deep neural networks have been provided to predict taxi demands. However, these works are limited in properly incorporating multi-view features of taxi demands together, with considering the influences of context information. In this paper, we propose a convolutional recurrent network model for fine-grained taxi demand prediction. Local convolutional layers and gated recurrent units are employed in our model to extract multi-view spatial-temporal features of taxi demands. Moreover, a novel context-aware attention module is designed to incorporate the predictions of each region with considering its contextual information, which is our first attempt. We also conduct comprehensive experiments based on multiple real-world datasets in New York City and Chengdu. The experimental results show that our model outperforms state-of-the-art methods, and validate the usefulness of each module in our model. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106294	10.1016/j.knosys.2020.106294													
J								Fast t-SNE algorithm with forest of balanced LSH trees and hybrid computation of repulsive forces	KNOWLEDGE-BASED SYSTEMS										Visualization of high-dimensional data; Dimensionality reduction; Stochastic neighbor embedding; t-SNE; Forest of locality-sensitive hashing trees; Locality-sensitive hashing; Balanced trees	DIMENSIONALITY REDUCTION; NEAREST-NEIGHBOR	An acceleration of the well-known t-Stochastic Neighbor Embedding (t-SNE) (Hinton and Roweis, 2003; Maaten and Hinton, 2008) algorithm, probably the best (nonlinear) dimensionality reduction and visualization method, is proposed in this article. By using a specially-tuned forest of balanced trees constructed via locality sensitive hashing is improved significantly upon the results presented in Maaten (2014), achieving a complexity significantly closer to true O(n log n), and vastly improving behavior for huge numbers of instances and attributes. Such acceleration removes the necessity to use PCA to reduce dimensionality before the start of t-SNE. Additionally, a fast hybrid method for repulsive forces computation (a part of the t-SNE algorithm), which is currently the fastest method known, is proposed. A parallelized version of our algorithm, characterized by a very good speedup factor, is proposed. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106318	10.1016/j.knosys.2020.106318													
J								Hierarchical text interaction for rating prediction	KNOWLEDGE-BASED SYSTEMS										Hierarchical neural network; Interactive networks; Review texts; Rating prediction		Traditional recommender systems encounter several challenges such as data sparsity and unexplained recommendation. To address these challenges, many works propose to exploit semantic information from review data. However, these methods have two major limitations in terms of the way to model textual features and capture textual interaction. For textual modeling, they simply concatenate all the reviews of a user/item into a single review. However, feature extraction at word/phrase level can violate the meaning of the original reviews. As for textual interaction, they defer the interactions to the prediction layer, making them fail to capture complex correlations between users and items. To address those limitations, we propose a novel Hierarchical Text Interaction model (HTI) for rating prediction. In HTI, we propose to model low-level word semantics and high-level review representations hierarchically. The hierarchy allows us to exploit textual features at different granularities. To further capture complex user-item interactions, we propose to exploit semantic correlations between each user-item pair at different hierarchies. At word level, we propose an attention mechanism specialized to each user-item pair, and capture the important words for representing each review. At review level, we mutually propagate textual features between the user and item, and capture the informative reviews. The aggregated review representations are integrated into a collaborative filtering framework for rating prediction. Experiments on five real-world datasets demonstrate that HTI outperforms stateof-the-art models by a large margin. Further case studies provide a deep insight into HTI's ability to capture semantic correlations at different levels of granularities for rating prediction. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106344	10.1016/j.knosys.2020.106344													
J								Time series forecasting based on kernel mapping and high-order fuzzy cognitive maps	KNOWLEDGE-BASED SYSTEMS										Fuzzy cognitive maps; Time series prediction; Feature selection; Kernel mapping	NEURAL-NETWORKS; PREDICTION; DESIGN; BINARY	Fuzzy cognitive maps (FCMs) have emerged as a powerful tool for dealing with the task of time series prediction. Most existing research devoted to designing an effective method to extract feature time series from the original time series, which are used to construct FCMs and predict the time series. However, in existing methods, all extracted feature time series, including the redundant feature time series, were used to develop FCMs instead of selecting the key feature time series (KFTS) to construct FCMs, which limits the generalization and prediction accuracy of the models. In this paper, we propose a framework based on kernel mapping and high-order FCMs (HFCM) to forecast time series inspired by the kernel methods and support vector regression (SVR). The model is termed as Kernel-HFCM. Kernel mapping is designed to map the original one-dimensional time series into multidimensional feature time series, and then the feature selection algorithm is proposed to select the KFTS from the multidimensional feature time series to develop the HFCM. Finally, reverse kernel mapping is used to map the feature time series back to the predicted one-dimensional time series. In comparison to the existing methods, the experimental results on seven benchmark datasets demonstrate the effectiveness of Kernel-HFCM in time series prediction. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106359	10.1016/j.knosys.2020.106359													
J								A multi-feature fusion model for Chinese relation extraction with entity sense	KNOWLEDGE-BASED SYSTEMS										Chinese relation extraction; Character-level feature; Word-level feature; Entity sense		Relation extraction is an important task of information extraction. Most existing methods of Chinese language relation extraction are based on word input. They are highly dependent on the quality of word segmentation and suffer from the ambiguity of polysemic words. Therefore, a multi-feature fusion model is presented on the basis of character input, which integrates character-level features, word-level features and entity sense features into deep neural network models. Specifically, to alleviate the ambiguity of polysemy, the entity sense is introduced as external language knowledge to provide supplementary information for understanding the semantics of an entity in a given sentence. The Attention-Based Bidirectional Long Short-Term Memory Networks (Att-BLSTM) are proposed to capture features at the character level. To obtain more structural information, the convolutional layer (C-AttBLSTM) is built upon the Att-BLSTM to capture features at the word level. Experiments are conducted on a public dataset of SanWen, and show that the proposed model achieves state-of-the-art results. (C) 2020 The Authors. Published by Elsevier B.V.																	0950-7051	1872-7409				OCT 28	2020	206								106348	10.1016/j.knosys.2020.106348													
J								SpiderNet: A spiderweb graph neural network for multi-view gait recognition	KNOWLEDGE-BASED SYSTEMS										Multi-view; Gait knowledge; Spiderweb graph convolutional network; Feature fusion; Capsule network; Long-short term memory; Spatio-temporal information		Human gait is a proven biometric trait with applications in security for authentication and disease diagnosis. However, it is one-sided to express and interpret gait data from a single point of view, which cannot reflect multi-dimensional characteristics of gait changes. Moreover, if the gait pattern observed from other views has pathological or abnormal behavior, or has micro movement, it is not easy to be detected and thus affects the recognition rate of gait. In addition, the multi-view fusion of gait knowledge can be challenging due to the close correlation between various visual angles. Owing to the above facts, we propose a spiderweb graph neural network (SpiderNet) to solve the multi view gait recognition problem, which connects the gait data of single view with that of other views concurrently and constructs an active graph convolutional neural network. The gait trajectory of each view is analyzed by the combination of a memory module and a capsule module, which accomplishes the multi-view feature fusion, as well as the spatio-temporal feature extraction of single view. The experimental results show that the SpiderNet is superior to fifteen state-of-the-art methods, such as random forest, long-short term memory and convolutional neural network, and achieves 98.54%, 98.77%, and 96.91% of the results on three challenging gait datasets: SDUgait, CASIA-B, and OU-MVLP. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106273	10.1016/j.knosys.2020.106273													
J								TSASNet: Tooth segmentation on dental panoramic X-ray images by Two-Stage Attention Segmentation Network	KNOWLEDGE-BASED SYSTEMS										Panoramic X-ray image; Attention model; Tooth segmentation	TARGET DETECTION; SET; TEETH; ALGORITHMS; SYSTEM	Tooth segmentation acts as a crucial and fundamental role in dentistry for doctors to make diagnosis and treatment plans. In this paper, we propose a Two-Stage Attention Segmentation Network (TSASNet) on dental panoramic X-ray images to address the issues suffered in the tooth boundary and tooth root segmentation task which are caused by the low contrast and uneven intensity distribution. We firstly adopt an attention model which is embedded with global and local attention modules to roughly localize the tooth region in the first stage. Without any interactive operator, the attention model so constructed can automatically aggregate pixel-wise contextual information and identify coarse tooth boundaries. To better obtain final boundary information, we use a fully convolutional network as the second stage to further segment the real tooth area from the attention maps obtained from the first stage. The effectiveness of TSASNet is substantiated on the benchmark dataset containing 1,500 dental panoramic X-ray images, our proposed method achieves 96.94% of accuracy, 92.72% of dice and 93.77% of recall, significantly superior to the current state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106338	10.1016/j.knosys.2020.106338													
J								High-dimensional feature selection for genomic datasets	KNOWLEDGE-BASED SYSTEMS										Feature selection; Dimensionality reduction; Perturbation theory; Singular value decomposition; Disease diagnoses; Classification	NONLINEAR FEATURE-SELECTION; PARKINSONS-DISEASE; DIAGNOSIS	A central problem in machine learning and pattern recognition is the process of recognizing the most important features. In this paper, we provide a new feature selection method (DRPT) that consists of first removing the irrelevant features and then detecting correlations between the remaining features. Let D = [A vertical bar b] be a dataset, where b is the class label and A is a matrix whose columns are the features. We solve Ax = b using the least squares method and the pseudo-inverse of A. Each component of x can be viewed as an assigned weight to the corresponding column (feature). We define a threshold based on the local maxima of x and remove those features whose weights are smaller than the threshold. To detect the correlations in the reduced matrix, which we still call A, we consider a perturbation (A) over tilde of A. We prove that correlations are encoded in Delta x =vertical bar x - (x) over tilde vertical bar, where (x) over tilde is the least squares solution of (A) over tilde(x) over tilde = b. We cluster features first based on Delta x and then using the entropy of features. Finally, a feature is selected from each sub-cluster based on its weight and entropy. The effectiveness of DRPT has been verified by performing a series of comparisons with seven state-of-the-art feature selection methods over ten genetic datasets ranging up from 9,117 to 267,604 features. The results show that, over all, the performance of DRPT is favorable in several aspects compared to each feature selection algorithm. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106370	10.1016/j.knosys.2020.106370													
J								Do all roads lead to Rome? Understanding the role of initialization in iterative back-translation	KNOWLEDGE-BASED SYSTEMS										Back-translation; Machine translation; Natural language processing		Back-translation provides a simple yet effective approach to exploit monolingual corpora in Neural Machine Translation (NMT). Its iterative variant, where two opposite NMT models are jointly trained by alternately using a synthetic parallel corpus generated by the reverse model, plays a central role in unsupervised machine translation. In order to start producing sound translations and provide a meaningful training signal to each other, existing approaches rely on either a separate machine translation system to warm up the iterative procedure, or some form of pre-training to initialize the weights of the model. In this paper, we analyze the role that such initialization plays in iterative back-translation. Is the behavior of the final system heavily dependent on it? Or does iterative back-translation converge to a similar solution given any reasonable initialization? Through a series of empirical experiments over a diverse set of warmup systems, we show that, although the quality of the initial system does affect final performance, its effect is relatively small, as iterative back-translation has a strong tendency to convergence to a similar solution. As such, the margin of improvement left for the initialization method is narrow, suggesting that future research should focus more on improving the iterative mechanism itself. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106401	10.1016/j.knosys.2020.106401													
J								An adaptive dimension level adjustment framework for differential evolution	KNOWLEDGE-BASED SYSTEMS										Differential evolution; Reinitialization framework; Improvement framework; Dimension level adjustment; Global optimization	GLOBAL OPTIMIZATION; DIRECTION INFORMATION; ALGORITHM; MUTATION; NEIGHBORHOOD; PARAMETERS; ENSEMBLE	Differential evolution (DE) has been recognized as one of the most popular evolutionary algorithms. There are numerous DE variants adopting multi-operators based cooperation strategy to improve their performance, but almost all of the adopted cooperation strategies are essentially implemented at the individual level or population level, and the implementation at the dimension level are scarce. In this paper, an adaptive dimension level adjustment (ADLA) framework is designed to relieve the premature convergence or stagnation problem faced by DE algorithm, which can be easily combined with diverse DE variants. When the current optimal individual cannot get improved for a given uninterrupted iterations, ADLA framework will be triggered to select some individuals at random according to specific rule and reinitialize portion of their dimensions from a dynamic search space that adjusted by a population level macroparameter and one individual level microparameter. Moreover, ADLA framework contains two reinitialization operators with different search characteristics, and the coordination between them is executed at the dimension level, which has potential advantages in balancing the global exploration ability and local exploitation ability. Extensive comparison experiments are carried out based on IEEE CEC 2014 test platform, two basic DE algorithms and six outstanding DE variants. The experimental results demonstrate that ADLA framework can memorably enhance the performance of every DE algorithm used for comparison. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106388	10.1016/j.knosys.2020.106388													
J								MFS-MCDM: Multi-label feature selection using multi-criteria decision making	KNOWLEDGE-BASED SYSTEMS										Information fusion; Multi-criteria decision making; TOPSIS; Entropy; Ridge regression; Multi-label feature selection	GRAVITATIONAL SEARCH ALGORITHM; EXTENDED TOPSIS METHOD	In this paper, for the first time, a feature selection procedure is modeled as a multi-criteria decision making (MCDM) process. This method is applied to a multi-label data and we have used the TOPSIS (Technique of Order Preference by Similarity to Ideal Solution) method as a famous MCDM algorithm to evaluate the features based on their relationship with multiple labels as different criteria. Our proposed method, Multi-label Feature Selection using Multi-Criteria Decision Making (MFS-MCDM) which treated the multi-label feature selection as an information fusion process, first obtains a decision matrix using the ridge regression algorithm and then calculates the weight of each column of this matrix based on the entropy of each label. Then, the TOPSIS approach is used to assign a score to each feature based on the weighted decision matrix. Finally, a rank vector for the features is generated as output which the user can select a desired number of features. The superiority of the proposed method is shown in experimental results comparing to other similar methods in terms of all evaluation metrics. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106365	10.1016/j.knosys.2020.106365													
J								Learning domain invariant unseen features for generalized zero-shot classification	KNOWLEDGE-BASED SYSTEMS										Generalized zero shot classification; Domain invariant unseen features; Support seen class sets; Maximum Mean Discrepancy		Generalized zero-shot classification is a challenging task to recognize test data which may come from seen or unseen classes. Existing methods suffer from the bias problem that the unseen images are easy to be misclassified to seen classes. Generating some fake unseen samples by Generative Adversarial Network has been a popular method. However, these models are not easy to train. In this paper, we proposed a method by learning domain invariant unseen features for generalized zero-shot classification. Specifically, we learn the support seen class set for each unseen class for transferring knowledge from source to target domain. The unseen samples of each class are generated based on the combinations of the samples from its support seen class set. In addition, for dealing with the domain shift problem between source and target domains, we learn domain invariant unseen features by minimizing the Maximum Mean Discrepancy distance of seen data, generated unseen data and then project target data to the common space. For dealing with the bias problem, we select some confident target unseen samples to augment training samples for training the classifier. In experiments, we demonstrate that the proposed method significantly outperforms other state-of-the-art methods. (C) 2020 Published by Elsevier B.V.																	0950-7051	1872-7409				OCT 28	2020	206								106378	10.1016/j.knosys.2020.106378													
J								Effective public service delivery supported by time-decayed Bayesian personalized ranking	KNOWLEDGE-BASED SYSTEMS										Personalized e-government; Bayesian personalized ranking; Implicit feedback	MATRIX FACTORIZATION; RECOMMENDATION	Information overload is becoming a prominent problem that hinders the effectiveness of e-government. Personalized e-government services with recommendation techniques may provide a solution by helping users find the target service items based on her interaction histories. Most existing e-government recommendation methods are rating based, but the ratings in e-government are unavailable. Besides, the interactions in e-government are sequence-dependent while the sequential information are usually ignored. These two problems negatively affect the efficiency of the service distribution of e-government platforms. In this paper, we studied the sequential implicit feedback recommendation problem in e-government and design a novel learning algorithm called time-decayed Bayesian personalized ranking. Time-decayed BPR captures the sequence effects using time-decayed Ordinal Utility and inherits the seminal pairwise learning framework of BPR. It digests users' sequential behavior naturally, and combines the benefits of time-aware information (i.e. sequential behavior) and time-invariant information (i.e. general taste). An empirical analysis of real-world e-government datasets shows that our time-decayed-BPR approach improves the performance significantly regarding various evaluation metrics compared with the state-of-the-art baseline methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106376	10.1016/j.knosys.2020.106376													
J								Recommender system using Long-term Cognitive Networks	KNOWLEDGE-BASED SYSTEMS										Recommender system; Prior knowledge; Long-term Cognitive Networks	AUTOENCODER	In this paper, we build a recommender system based on Long-term Cognitive Networks (LTCNs), which are a type of recurrent neural network that allows reasoning with prior knowledge structures. Given that our approach is context-free and that we did not involve human experts in our study, the prior knowledge is replaced with Pearson's correlation coefficients. The proposed architecture expands the LTCN model by adding Gaussian kernel neurons that compute estimates for the missing ratings. These neurons feed the recurrent structure that corrects the estimates and makes the predictions. Moreover, we present an extension of the non-synaptic backpropagation algorithm to compute the proper non-linearity of each neuron together with its activation boundaries. Numerical results using several case studies have shown that our proposal outperforms most state-of-the-art methods. Towards the end, we explain how can we inject expert knowledge to the proposed neural system. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106372	10.1016/j.knosys.2020.106372													
J								Towards optimal wireless sensor network lifetime in three dimensional terrains using relay placement metaheuristics	KNOWLEDGE-BASED SYSTEMS										Wireless sensor networks; Load balancing; Network lifetime; Relay node placement	TRANSMISSION RANGE ADJUSTMENT	In wireless sensor networks, sensor nodes located close to the base station or sink are more susceptible to energy loss, leading to premature disconnection of the network or energy holes. This is due to the fact that all traffic is forwarded towards the sink, increasing the workloads for these closer nodes. One solution for this issue is to shorten the hop distance a sensor's data has to travel until reaching the sink, by deploying additional relay nodes. This paper considers the problem of optimal relay node placement for maximizing the network lifetime of wireless sensor networks in three-dimensional terrains. We first design a mathematical model of the problem and reformulate it as a mixed-integer programming model to provide a basis for finding lower bound solutions. We divide the problem into two phases and show that the second phase can be solved exactly using an algorithm based on maximum flow and binary search. We then propose a local search algorithm for the first phase, utilizing the exact algorithm to create full solutions. Experimental validation on 3D datasets has been carried out to demonstrate the performance of our algorithms. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106407	10.1016/j.knosys.2020.106407													
J								Fast anytime retrieval with confidence in large-scale temporal case bases	KNOWLEDGE-BASED SYSTEMS										Large-scale case-based reasoning; Exact and approximate k-nearest neighbor search; Anytime algorithms	NEAREST-NEIGHBOR; ALGORITHMS	This work is about speeding up retrieval in Case-Based Reasoning (CBR) for large-scale case bases (CBs) comprised of temporally related cases in metric spaces. A typical example is a CB of electronic health records where consecutive sessions of a patient forms a sequence of related cases. k-Nearest Neighbors (kNN) search is a widely used algorithm in CBR retrieval. However, brute-force kNN is impossible for large CBs. As a contribution to efforts for speeding up kNN search, we introduce an anytime kNN search methodology and algorithm. Anytime Lazy kNN finds exact kNNs when allowed to run to completion with remarkable gain in execution time by avoiding unnecessary neighbor assessments. For applications where the gain in exact kNN search may not suffice, it can be interrupted earlier and it returns best-so-far kNNs together with a confidence value attached to each neighbor. We describe the algorithm and methodology to construct a probabilistic model that we use both to estimate confidence upon interruption and to automatize the interruption at desired confidence thresholds. We present the results of experiments conducted with publicly available datasets. The results show superior gains compared to brute-force search. We reach to an average gain of 87.18% with 0.98 confidence and to 96.84% with 0.70 confidence. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106374	10.1016/j.knosys.2020.106374													
J								Knowledge configuration model for fast derivation design of electronic equipment and its implementation	KNOWLEDGE-BASED SYSTEMS										Knowledge template; Ontology; Rapid design; Derivative design; Electronic equipment	RAPID DESIGN; REPRESENTATION; FRAMEWORK; EVOLUTION; SYSTEMS	There has contradictions in timeliness and diversity in the design schemes of complex product systems. The traditional solidified knowledge template for the knowledge reuse purpose cannot meet the rapid design needs of complex products. This paper proposes a configurable knowledge ontology model (CKOM) and a corresponding design method for rapid derivation of complex products. Based on the combination of basic knowledge elements (BKE), customized knowledge elements (CKE), and assorted knowledge elements (AKE), a knowledge structural body (KSB) is constructed by unitizing knowledge ontology into units of knowledge. And a dynamic structured knowledge template configuration method based on physical form (Pf) configuration and virtual form (Vf) association is proposed. The knowledge configuration information is transmitted and parsed in XML form, and the virtual form is established to associate and dynamically configure the corresponding physical form knowledge structure. Based on the structured knowledge model configuration template, a rapid derivative design method for electronic equipment is proposed. The rapid derivation design process is divided into three stages: requirement analysis, index demonstration, and scheme formation. By establishing seven knowledge attributes, such as global, local, scope, retrieval, the required product knowledge elements, rule knowledge elements and tools are dynamically configured to realize the dynamic processing of design parameters based on configuration knowledge elements and then form a corresponding design scheme. Finally, a rapid derivation design system is developed and applied to electronic equipment, which verifies the rationality and effectiveness of the proposed model and method. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106360	10.1016/j.knosys.2020.106360													
J								Long-range forecasting in feature-evolving data streams	KNOWLEDGE-BASED SYSTEMS										Feature-evolving streams; Time series; Deep neural networks; Forecasting		Accurate long-range forecasting in high-dimensional feature-evolving time series is a pressing issue with multiple applications in optimal resource allocation, monitoring and budget planning. Stochastic nature of feature-evolving time series coupled with their temporal dependency pose a great challenge in their forecasting. This is because the length of input sequence (rows) may vary as data points evolve with their feature values (columns) changing. In high-dimensional feature-evolving heterogeneous time series, it is impractical to train a forecasting model per single time series across millions of metrics, leave alone space required to maintain the forecasting model and evolving time series in memory for timely streaming processing. Thus this paper proposes One sketch Fits All Time series algorithm, which is a stochastic deep neural network framework to address stated problems collectively. Extensive experiments on real-life datasets and rigorous evaluation showcases that OFAT is fast, robust, accurate and superior to the state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106405	10.1016/j.knosys.2020.106405													
J								GLLPA: A Graph Layout based Label Propagation Algorithm for community detection	KNOWLEDGE-BASED SYSTEMS										Community detection; Label propagation; Graph layout; Node attraction; Node influence; Label influence	NETWORKS; BEHAVIOR; ECHOLOCATION	Community is an important property of networks. Recently, label propagation based community detection algorithms develop rapidly, since they can discover communities with high efficiency. However, the results of most of them are inaccurate and unstable because the node order of label updating and the mechanism of label propagation are random. In this paper, a new label propagation algorithm, Graph Layout based Label Propagation Algorithm (GLLPA), is proposed to reveal communities in networks, which aims at detecting accurate communities and improving stability by exploiting multiple graph layout information. Firstly, GLLPA draws networks to compact layout based on the force-directed methods with (a,r)-energy model, then a label initialization strategy is proposed to assign the nodes locating in a position with the same label. Secondly, GLLPA begins to draw networks to uniform layout and conduct community detection simultaneously, in which we design node influence and label influence based on node attraction in the uniform layout to handle the instability problem and enhance its accuracy and efficiency. Experimental results on 16 synthetic and 15 real-world networks demonstrate that the proposed method outperforms state-of-the-art algorithms in most networks. (C) 2020 Elsevier B.V. All rights reserved.																	0950-7051	1872-7409				OCT 28	2020	206								106363	10.1016/j.knosys.2020.106363													
J								Leader-following synchronization of complex dynamic networks via event-triggered impulsive control	NEUROCOMPUTING										Synchronization; Complex networks; Event-trigger; Impulsive control; Zeno behaviour	NEURAL-NETWORKS; SYSTEMS; STABILIZATION	This paper deals with the synchronization of complex dynamical networks. Based on the idea of event-trigger and impulsive control theory, an event-based impulsive control strategy is proposed to achieve synchronization of leader-follower coupled dynamical networks, where a class of forced impulse sequence is introduced to promote the synchronization. Moreover, the possible accumulations of event-times (i.e., Zeno behaviour) in control strategy can be excluded. Unlike classical event-triggered control that involve control inputs incessantly based on the sampled information in last event-triggered instant, the proposed control inputs are only carried out at some discrete event-triggered instants. In other words, it is not necessary to activate the sensor and control computation and/or communication between leader and followers when the controls do not need attention. The proposed event-triggered conditions in control strategy can be derived by solving linear matrix inequalities (LMIs). Finally, a chaotic neural network is discussed to illustrate the application of our proposed results. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						1	10		10.1016/j.neucom.2020.05.071													
J								CardioID: learning to identification from electrocardiogram data	NEUROCOMPUTING										Deep Neural Network; Biometric Identification; Electrocardiogram	CLASSIFICATION; NETWORKS	Human identification is an important task that can help protect information security. Building deep learning models for human identification from Electrocardiogram (ECG) data is one of the highly promising technique. It has several unique advantages such as liveness detection, insensitive, easy to collect, higher security and so on. However, existing classifier-based methods only support closed-set identification, while existing matching-based methods are limited to high computational complexity. Besides, almost all methods only consider one-shot identification, which might be affected by occasional noise. In this paper, we propose CardioID to solve the above problems. CardioID learns binary codes from continuous ECG data which can identify faster than existing methods. It also supports identifying new person without the need to reconstructed or re-train the model. Besides, it can theoretically guarantee the recognition accuracy by introducing statistical hypothesis testing for making an identification decision. Experiments on real world ECG data show that CardioID can achieve 9.84% higher identification accuracy while saving 30.90% of running time compared with each of the second best baselines. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						11	18		10.1016/j.neucom.2020.05.099													
J								A multi-path adaptive fusion network for multimodal brain tumor segmentation	NEUROCOMPUTING										Multimodal brain tumor segmentation; DenseNets; Skip connection; Multi-path; Adaptive	QUANTITATIVE-ANALYSIS; MRI	The deep learning method has shown its outstanding performance in object recognition and becomes the first choice for medical image analysis. However, how to effectively propagate features in the learning layer and how to fuse low-level visual features and high-level semantic features, is still a challenging task. In addition, with the rapid development of the neural network, an increasing need of running Convolutional Neural Network (CNN) models with limited computing power and memory resource. To address these problems, this paper proposes a novel multi-path adaptive fusion network. More specifically, we apply the idea of "skip connection" in ResNets to the dense block so as to effectively reserve and propagate more low-level visual features. A contiguous memory mechanism has been realized by adopting direction connections from the state of preceding dense block to all layers of current dense block in the network. Then, a multi-path adaptive fusion dense block was adopted in the up-sampling process to adaptively adjust the low-level visual feature and then to fuse with high-level semantic features. By evaluating the proposed framework on the challenging BRATS2015 dataset, it can be proven that this framework achieves state-of-the-art results by comparing with other counterpart methods. Moreover, parameters of the proposed framework are much less than most published methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						19	30		10.1016/j.neucom.2020.06.078													
J								Learning heterogeneous information network embeddings via relational triplet network	NEUROCOMPUTING										Heterogeneous information networks; Relational triplet network; Representation learning; Network embedding		Network embedding algorithms learn low-dimensional features from the relationships and attributes of networks. The basic principle of these algorithms is to preserve the similarities in the original networks as much as possible. However, in heterogeneous information networks, existing algorithms are not sufficiently expressive to capture detailed semantic patterns between nodes. In this paper, we propose a novel heterogeneous information network embedding algorithm called the relational triplet network (RTN). In the data sampling phase, meta-schema-based random walks are performed to extract semi-hard quadruplets based on the node type and degree. In the representation learning phase, a relational triplet loss is designed to optimize the distance of triplet embeddings on diverse heterogeneous relationships. The empirical results demonstrate that our algorithm can obtain multiple types of representations and outperform other state-of-the-art methods in node classification and link prediction. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						31	41		10.1016/j.neucom.2020.06.043													
J								Multimodal graph convolutional networks for high quality content recognition	NEUROCOMPUTING										High quality content recognition; Graph convolutional networks; Positive unlabeled learning		With the development of the Internet, more and more creators publish articles on social media. How to automatically filter high quality content from a large number of multimedia articles is one of the core functions of information recommendation, search engine, and other systems. However, existing approaches typically suffer from two limitations: (1) They usually model content as word sequences, which ignores the semantics provided by non-consecutive phrases, long-distance word dependency, and visual information. (2) They rely on a large amount of manually annotated data to train a quality assessment model while users may only provide labels of interest in a single class for a small number of samples in reality. To address these limitations, we propose a Multimodal Graph Convolutional Networks (MGCN) to model the semantic representations in a unified framework for High Quality Content Recognition. Instead of viewing text content as word sequences, we convert them into graphs, which can model non-consecutive phrases and long-distance word dependency for better obtaining the composition of semantics. Besides, visual content is also modeled into the graphs to provide complementary semantics. A well-designed graph convolutional network is proposed to capture the semantic representations based on these graphs. Furthermore, we employ a non-negative risk estimator for high quality content recognition and the loss is back-propagated for model learning. Experiments on real data sets validate the effectiveness of our approach. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						42	51		10.1016/j.neucom.2020.04.145													
J								Speculative text mining for document-level sentiment classification	NEUROCOMPUTING										Speculative sentiment classification; Speculative similar document		Many existing solutions perform document-level sentiment classification based on local document only, ignoring other texts that might contribute to better classification accuracy. In this paper, we propose a novel speculative sentiment classification model named SSC. In SSC, we speculate that users with similar rating behaviours are more likely to write documents of similar sentiments toward a product. The motivation of SSC, therefore, is to exploit those speculative similar documents for improving classification accuracy. The proposed SSC model consists of three main components, namely, user-product interaction (UPI) component, document encoding (DE) component, and speculative similar document (SSD) component. The UPI component models user-product interactions, and encodes user/product ratings behaviours into user/product embeddings. The DE component utilizes learned user/product embeddings to capture the informative word vectors for comprising more accurate document representations. The SSD component aggregates documents written by similar users toward the same product for speculative sentiment classification. Because the user similarities are calculated based on user embeddings that encode user rating behaviours, the aggregated documents are more likely to have similar sentiments. The three components are seamlessly integrated into a unified model. In the unified manner, these three components are jointly optimized, and they mutually complement each other to enhance sentiment classification. We conduct extensive experiments on three public datasets, and demonstrate the advantage of the proposed SSC model over state-of-the-art baselines. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						52	62		10.1016/j.neucom.2020.06.024													
J								Heterogeneous formation control of multiple UAVs with limited-input leader via reinforcement learning	NEUROCOMPUTING										Formation control; Multi-agent systems; Heterogeneous systems; Reinforcement learning; Unmanned aerial vehicles	ADAPTIVE OPTIMAL-CONTROL; TRACKING CONTROL; MULTIAGENT SYSTEMS; SYNCHRONIZATION	In this brief, a distributed optimal control method via reinforcement learning is proposed to address the heterogeneous unmanned aerial vehicle (UAV) formation trajectory tracking problem. The UAV formation is composed of a virtual leader with limited nonzero input and several follower vehicles with different unknown dynamics. The proposed control law contains a distributed observer and a model-free off policy reinforcement learning (RL) protocol. The distributed optimal trajectory tracking problem is formulated for the heterogeneous formation system. A RL algorithm is designed to obtain the optimal control input online without any knowledge of the followers' dynamics. Simulation example illustrates the effectiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						63	71		10.1016/j.neucom.2020.06.040													
J								Robust nonnegative matrix factorization with structure regularization	NEUROCOMPUTING										Nonnegative matrix factorization; Global structure; Manifold regularization; Clustering	PARTS; FRAMEWORK; OBJECTS; FACE	Nonnegative matrix factorization (NMF) has attracted more and more attention due to its wide applications in computer vision, information retrieval, and machine learning. In contrast to the original NMF and its variants, this paper proposes a novel unsupervised learning framework, called robust structured nonnegative matrix factorization (RSNMF) which respects both global and local structures of the data space. Specifically, to learn a discriminative representation, RSNMF explores both the global structure via considering the data variance and the local structure via exploiting the data neighborhood. To well address the problem of noise and outliers, it imposes joint L-2,L-1-norm minimization on both the loss function of NMF and the regularization of the basis matrix. The geometric structure and the joint L-2,L-1-norm are formulated as an optimization model, which is solved by the proposed iterative algorithm. Finally, the convergence of RSNMF is analyzed theoretically and empirically. The experimental results on real-world data sets show the effectiveness of our proposed algorithm in comparison to state-of-the-art algorithms. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						72	90		10.1016/j.neucom.2020.06.049													
J								On stability and stabilization of T-S fuzzy systems with multiple random variables dependent time-varying delay	NEUROCOMPUTING										T-S fuzzy model; Stability; Stabilization; Multiple random variables dependent time-varying delay; Lyapunov-Krasovskii (L-K) functional	NETWORKED CONTROL-SYSTEMS; H-INFINITY CONTROL; NONLINEAR-SYSTEMS; INEQUALITY	This paper is concerned with the problems of stability and stabilization for Takagi-Sugeno (T-S) fuzzy systems with multiple random variables dependent time-varying delay. Different from the previous works, we assume that probability distributions of delay in N intervals can be observed in advance. (N 1) Bernoulli distributed random variables are utilized to indicate which interval the time-varying delay falls into at a certain time instant. Then the original T-S fuzzy systems are transformed into a new model of T-S fuzzy systems with multiple random variables dependent time-varying delay, which includes the existed ones as its special cases. Based on the new model, an appropriate Lyapunov-Krasovskii (L-K) functional is constructed. Generalized Finsler's lemma is introduced to avoid directly dealing with the interrelationship between these correlated random variables, and Reciprocally convex inequality is used to estimate integral terms from the infinitesimal operator of L-K functional. Less conservative stability criteria and stabilization conditions are proposed in the form of linear matrix inequalities (LMIs). Finally, two examples are given to demonstrate the effectiveness of the proposed methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						91	100		10.1016/j.neucom.2020.06.073													
J								Cooperative control for multi-player pursuit-evasion games with reinforcement learning	NEUROCOMPUTING										Pursuit-evasion game; Reinforcement learning; Distributed control; Communication network	ALGORITHM; SYSTEMS; GO	In this paper, we consider a pursuit-evasion game in which multiple pursuers attempt to capture one superior evader. A distributed cooperative pursuit strategy with communication is developed based on reinforcement learning. The centralized critic and distributed actor structure and the learning-based communication mechanism are adopted to solve the cooperative pursuit control problem. Instead of using broadcast to share information among the pursuers, we construct the ring topology network and the leader-follower line topology network for communication, which could significantly reduce the complexity and save the communication and computation resources. The training algorithms for these two network topologies are developed based on the deep deterministic policy gradient algorithm. Furthermore, the proposed approach is implemented in a simulation environment. The training and evaluation results demonstrate that the pursuit team could learn highly efficient cooperative control and communication policies. The pursuers can capture a superior evader driven by an intelligent escape policy with a high success rate. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						101	114		10.1016/j.neucom.2020.06.031													
J								Joint distribution matching embedding for unsupervised domain adaptation	NEUROCOMPUTING										Domain adaptation; Joint distribution; Maximum mean discrepancy; Grassmann manifold	KERNEL	When the distributions between the source (training) and target (test) datasets are different, the performance of classical statistical learning methods degrades significantly. Domain adaptation (DA) aims at correcting this distribution mismatch and narrowing down the distribution discrepancy. Existing methods mostly focus on correcting the mismatch between the marginal distributions and/or the class-conditional distributions. In this paper, we assume that the distribution mismatch in domain adaptation is the joint distribution mismatch, and propose an Extended Maximum Mean Discrepancy (EMMD) metric to measure the distance between joint distributions. Based on this metric, we propose the Joint Distribution Matching Embedding (JDME) approach, which finds a mapping matrix to project the samples into a latent space, where the EMMD between the source and target joint distributions is minimized. The resultant orthogonal-constrained optimization problem can be solved in the form of an unconstrained problem on the Grassmann manifold. After the joint distribution matching, we can expect the classical statistical learning methods to perform well on the target dataset. Experiments on object recognition, face recognition, and spam filtering demonstrate that our method statistically outperforms the state-of-the-art shallow methods and is also on par with the deep learning methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						115	128		10.1016/j.neucom.2020.05.098													
J								A digital hardware implementation of spiking neural networks with binary FORCE training	NEUROCOMPUTING										FORCE learning; Field programmable gate array (FPGA); Spiking neural network (SNN); Recursive least square (RLS); QR decomposition; Systolic array	STATE MACHINE; COMPUTATION; MODEL; FPGA	The brain, a network of spiking neurons, can learn complex dynamics by adapting its spontaneous chaotic activity. One of the dominant approaches used to train such a network, the FORCE method, has recently been applied to spiking neural networks. This method employs a pool of randomly connected spiking neurons, called a reservoir, to create chaos and uses the recursive least square (RLS) method to change its dynamic to what is required to follow a teacher signal. Here, we propose a digital hardware architecture for spiking FORCE with some modifications to the original method. First, to reduce the memory usage in hardware implementation, we show that careful binarization of the reservoir weights could pre-serve its initial chaotic activity. Second, we generate the connection matrix on-the-fly instead of storing the whole matrix. Third, a single processor systolic array implementation of the RLS using the inverse QR decomposition is exploited to update the readout layer weights. This implementation is not only more hardware-friendly but also more numerically stable in reduced precision than the standard RLS implementation. Fourth, we implement the design in both single and custom-precision floating-point number systems. Finally, we implement a network of 510 Izhikevic neurons on a Xilinx Artix-7 FPGA with 32, 24, and 18 bits floating-point numbers. To confirm the correctness of our architecture, we successfully train our hardware using three different teacher signals. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 28	2020	412						129	142		10.1016/j.neucom.2020.05.044													
J								Model free adaptive fault-tolerant tracking control for a class of discrete-time systems	NEUROCOMPUTING										Fault-tolerant tracking control; Discrete-time system; Model-free adaptive control (MFAC); Fault estimation; RBFNN	CONTROL DESIGN	This paper investigates the fault-tolerant tracking control issue for a class of discrete-time systems with sensor fault. A novel model-free adaptive fault-tolerant tracking control scheme is proposed by utilizing the dynamic linearization approach, in which only input/output (I/O) data of controlled plant are required. Moreover, due to the characteristics of simple structure and powerful approximation ability, RBF neural network (RBFNN) is introduced to approximate the fault dynamics after the sensor fault is detected. The approximated fault dynamic is utilized to reconstruct the controller. The major feature of this paper is that the whole fault-tolerant tracking controller structure is derived from the dynamic linearization of the ideal controller, rather than the criterion function. Finally, the proposed model-free adaptive fault-tolerant tracking controller is verified to be effective by numerical simulations. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						143	151		10.1016/j.neucom.2020.06.027													
J								An inverse-free Zhang neural dynamic for time-varying convex optimization problems with equality and affine inequality constraints	NEUROCOMPUTING										Time-varying optimization problem; Inverse-free; Zhang neural dynamic; Convergence and robustness	NETWORK; STABILITY; EQUATION; SCHEME; DESIGN	Time-varying convex optimization problems have attracted a great deal of attention in many fields due to its widespread application. Particularly, the approach to time-varying convex optimization problems with equality and affine inequality constraints simultaneously is a comprehensive but complicated problem at present. In this paper, three types of inverse-free Zhang neural dynamic (ZND) including two noise-tolerance ZND models are proposed and investigated for solving time-varying convex optimization problems with equality and affine inequality constraints. It is noted that the proposed noise-tolerance ZND models own the ability to suppress noise and one of those even achieves finite-time convergency. Compared with previous work, the proposed inverse-free ZND models effectively reduce the computation complexity by simplifying the model structure and conquer the problem of solving real-time matrix inverse during the computation process, which is more appropriate for a wider practical application. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						152	166		10.1016/j.neucom.2020.06.051													
J								Neural networks-based optimal tracking control for nonzero-sum games of multi-player continuous-time nonlinear systems via reinforcement learning	NEUROCOMPUTING										Neural networks; Multi-player nonzero-sum game; Optimal tracking control; Continuous-time nonlinear systems; Coupled Hamilton-Jacobi equations; Reinforcement learning	EXPERIENCE REPLAY; ALGORITHMS; SECURITY	In this paper, optimal tracking control for nonzero-sum games of multi-player continuous-time nonlinear systems is investigated by using a novel reinforcement learning scheme. Based on the multi-player non linear systems and reference signal, we firstly formulate the tracking problem by constructing an augmented multi-player nonlinear systems. The optimal tracking control problem for nonzero-sum games of original multi-player nonlinear systems is thus transformed into solving the coupled Hamilton-Jacobi equations of the augmented multi-player nonlinear systems. The novel neural networks (NNs) - based online reinforcement learning (RL) method can learn the solution to coupled Hamilton-Jacobi equations in a forward-in-time manner without requiring any value, policy iterations. In order to relax the dependence of the traditional reinforcement learning method on Persistence of Excitation (PE) conditions, historical data from a period of time has been collected to design NNs tuning laws. The drift dynamic of the augmented system is not required in our scheme. The Uniformly Ultimately Boundedness (UUB) of NNs weight errors and closed-loop augmented system states are rigorous proved. Numerical simulation examples are given to demonstrate the effectiveness of our proposed scheme. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						167	176		10.1016/j.neucom.2020.06.083													
J								Dilated residual networks with multi-level attention for speaker verification	NEUROCOMPUTING										Speaker verification; Dilated residual networks; Multi-level attention	EMBEDDINGS	With the development of deep learning techniques, speaker verification (SV) systems based on deep neural network (DNN) achieve competitive performance compared with traditional i-vector-based works. Previous DNN-based SV methods usually employ time-delay neural network, limiting the extension of the network for an effective representation. Besides, existing attention mechanisms used in DNN-based SV systems are only applied to a single level of network architectures, leading to insufficiently extraction of important features. To address above issues, we propose an effective deep speaker embedding architecture for SV, which combines a residual connection of one-dimensional dilated convolutional layers, called dilated residual networks (DRNs), with a multi-level attention model. The DRNs can not only capture long time frequency context information of features, but also exploit information from multiple layers of DNN. In addition, the multi-level attention model, which consists of two-dimensional convolutional block attention modules employed at the frame level and the vector-based attention utilized at the pooling layer, can emphasize important features at multiple levels of DNN. Experiments conducted on NIST SRE 2016 data set show that the proposed architecture achieves a superior equal error rate (EER) of 7.094% and a better detection cost function (DCF16) of 0.552 compared with state-of-the-art methods. Furthermore, the ablation experiments demonstrate the effectiveness of dilated convolutions and the multi-level attention on SV tasks. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						177	186		10.1016/j.neucom.2020.06.079													
J								Joint image deblurring and super-resolution with attention dual supervised network	NEUROCOMPUTING										Image deblurring; Super-resolution; Attention mechanism; Dual supervision	REGRESSION	Image deblurring and super-resolution (SR) are computer vision tasks aiming to restore image detail and spatial scale, respectively. Despite significant research effort over the past years, it remains challenging for joint image deblurring and SR via deep networks. Besides, only a few recent literatures contribute to this task, as conventional methods deal with SR or deblurring separately. To rectify the weakness, we propose a novel network that handles both tasks jointly and in this way boosts the SR performance from blurry input greatly. To fully exploit the representation capacity of our model, dual supervised learning is proposed to impose the constraint between low-resolution (LR) and high-resolution (HR) images. Our model consists of three parts: (i) a deblurring module equipped with channel attention residual blocks that removes the fuzziness from input images, (ii) an SR module to super-resolve the image based on the feature maps from the deblurring module serving as input, and (iii) a dual module which exploits the dependencies between LR and HR images. Extensive experiments indicate that the proposed attention dual supervised network (ADSN) not only generates remarkably clear HR images, but also achieves compelling results for joint image deblurring and SR task. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						187	196		10.1016/j.neucom.2020.05.069													
J								Multimodal multitask deep learning model for Alzheimer's disease progression detection based on time series data	NEUROCOMPUTING										Alzheimer's disease; Progression detection; Multimodal multitask learning; Deep learning; Machine learning; Time series data analysis	MILD COGNITIVE IMPAIRMENT; PREDICTION	Early prediction of Alzheimer's disease (AD) is crucial for delaying its progression. As a chronic disease, ignoring the temporal dimension of AD data affects the performance of a progression detection and medically unacceptable. Besides, AD patients are represented by heterogeneous, yet complementary, multi modalities. Multitask modeling improves progression-detection performance, robustness, and stability. However, multimodal multitask modeling has not been evaluated using time series and deep learning paradigm, especially for AD progression detection. In this paper, we propose a robust ensemble deep learning model based on a stacked convolutional neural network (CNN) and a bidirectional long short-term memory (BiLSTM) network. This multimodal multitask model jointly predicts multiple variables based on the fusion of five types of multimodal time series data plus a set of background (BG) knowledge. Predicted variables include AD multiclass progression task, and four critical cognitive scores regression tasks. The proposed model extracts local and longitudinal features of each modality using a stacked CNN and BiLSTM network. Concurrently, local features are extracted from the BG data using a feed forward neural network. Resultant features are fused to a deep network to detect common patterns which jointly used to predict the classification and regression tasks. To validate our model, we performed six experiments on five modalities from Alzheimer's Disease Neuroimaging Initiative (ADNI) of 1536 subjects. The results of the proposed approach achieve state-of-the-art performance for both multiclass progression and regression tasks. Moreover, our approach can be generalized in other medial domains to analyze heterogeneous temporal data for predicting patient's future status. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).																	0925-2312	1872-8286				OCT 28	2020	412						197	215		10.1016/j.neucom.2020.05.087													
J								FoolChecker: A platform to evaluate the robustness of images against adversarial attacks	NEUROCOMPUTING										Deep neural network; Adversarial examples; Non-robust features; Differential evolution; Greedy algorithm		Deep neural network (DNN) is inherently vulnerable to well-designed input samples called adversarial examples, which can easily alter the output of the DNN by adding slight perturbations to the input. The recent study proved that adversarial vulnerability is caused by non-robust features and is not inherently tied to DNN. The paper presents a platform called FoolChecker to evaluate the image robustness against adversarial attacks from the perspective of image itself rather than DNN models. We define the minimum perceptual distance between the original examples and the adversarial ones to quantify the robustness against adversarial attacks. Firstly, differential evolution is applied to generate candidate perturbation units with high perturbation priority. And then, the greedy algorithm tries to add the pixel with the current highest perturbation priority into perturbation units until the DNN model is fooled. Finally, the perceptual distance of perturbation units is calculated as a index to evaluate the robustness of images against adversarial attacks. Experimental results show that the FoolChecker can give proper evaluation of the robustness of images against adversarial attacks with acceptable time. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 28	2020	412						216	225		10.1016/j.neucom.2020.05.062													
J								LMI-based criterion for global Mittag-Leffler lag quasi-synchronization of fractional-order memristor-based neural networks via linear feedback pinning control	NEUROCOMPUTING										Linear feedback pinning control; Memristor-based neural networks (MNNs); Global Mittag-Leffler lag quasi-synchronization (GMLQS); Fractional-order nonlinear systems; Global Mittag-Leffler ultimate boundedness (GMUB); Linear matrix inequality (LMI)	TIME-VARYING DELAYS; ROBUST STABILITY; STABILIZATION; DYNAMICS; HYPERCHAOS; CHAOS	This paper addresses global Mittag-Leffler lag quasi-synchronization (GMLQS) of fractional-order memristor-based neural networks (FMNNs). Firstly, for a general class of fractional-order nonlinear systems with interval uncertainties, a kind of linear feedback pinning controller, which works by feeding back partial state errors to the partial controlled variables, is designed to achieve global Mittag-Leffler ultimate boundedness (GMUB). Correspondingly, a GMUB criterion in the form of linear matrix inequality (LMI) is derived with the aid of a Lyapunov function and a newly established fractional-order differential inequality. Then, the linear feedback pinning controller is employed for GMUB of the synchronization error system, which is equivalent to GMLQS of FMNNs. Since there exists the propagation delay between drive-response FMNNs and the synchronization error system can not be obtained straightforwardly, an identical equation about Caputo's fractional derivatives is established to overcome this difficulty. Moreover, the detailed pinning control scheme design procedures for a prescribed GMLQS performance are presented, where the performance involves both ultimate error bound and transient behavior. In the control scheme, an auxiliary LMI and an optimization objective function are introduced, which can significantly reduce control cost. Finally, a numerical example is presented to show the feasibility of the control scheme. The results obtained in this paper have improved the existing criterion on quasi synchronization of FMNNs, and will also provide a novel insight into pinning control of fractional order nonlinear systems. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						226	243		10.1016/j.neucom.2020.05.074													
J								Jointly detecting and multiple people tracking by semantic and scene information	NEUROCOMPUTING										Online multiple object tracking; Detection; Semantic information; Scene information		In this paper, we propose a new method for online multiple people tracking, which combines the detection process and the single object tracking process, and establishes the interactions between them. The detector detects objects in the still images which ignores the sequential information. Meantime, the single object tracker does not use the category semantic information during tracking. To take both the sequential and semantic information into account, we exchange information among the detector and the trackers. More specifically, the trackers deliver sequential information to the detector by providing the detector with the extra proposals. The detector supplements each tracker with the robust semantic information by using bounding box regression to modify the tracking result. Besides, the interactions also happen among the trackers through the occlusion speculation, the perspective model interpretation and the trajectory merging process. The experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art MOT methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						244	251		10.1016/j.neucom.2020.06.076													
J								Scene image retrieval with siamese spatial attention pooling	NEUROCOMPUTING										Siamese networks; Spatial attention; Pooling; Image embedding; Image retrieval		Content-based image retrieval (CBIR) aims to retrieve images from a given image collection according to similarities of image contents. In this paper, we focus on retrieval of scene images. We propose a siamese spatial attentive model which bases on siamese architecture and incorporates attention mechanism to generate compatible image embeddings. It extracts local features with a convolutional neural network (CNN), which starts with pre-trained parameters and is well fine-tuned for retrieval. Spatial attention pooling is proposed to take feature maps as input and generate weights for local features, which are then used to refine local features via weighted sum-pooling. Such pooling alleviates impacts from disturbance and concentrates on meaningful parts of images. Therefore, the model is able to output robust representations for noisy images. We also propose a multi-stage training scheme for the model, which leads to better performance than normal one-pass training scheme. Extensive experimental results on benchmark image retrieval datasets show that our model is competitive in retrieval performance. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						252	261		10.1016/j.neucom.2020.05.090													
J								Scalable deep asymmetric hashing via unequal-dimensional embeddings for image similarity search	NEUROCOMPUTING										Image retrieval; Matrix tri-factorization; Supervised learning; Semantic hashing; Unequal-dimensional embeddings	BINARY-CODES; SCALE; QUANTIZATION; ALGORITHMS; NEIGHBOR	In recent years, Hashing has become a popular technique used to support large-scale image retrieval, due to its significantly reduced storage, high search speed and capability of mapping high dimensional original features into compact similarity-preserving binary codes. Although effectiveness achieved, most existing hashing methods are still some limitations, including: (1) Many supervised hashing methods only transform the label information into pairwise similarities to guide the hash code learning process, which will lead to the loss of rich semantic information between image pairs. (2) Some pioneer hashing methods use a relaxation-based strategy to solve discrete problems, resulting in a large quantization error. (3) Some supervised hashing methods handle the hashing learning procedure based on an asymmetric learning manner, and although this partially solves the problems of low efficiency and accuracy of symmetric learning strategy, they are all based on the embeddings of equal dimension, which leads to the reduction in the models representation ability and an increase in potential noise. To overcome the above limitations, in this paper, we propose a novel yet simple but effective hashing method, named Scalable Deep Asymmetric Hashing (SDAH). Specifically, SDAH is an end-to-end deep hashing method based on a fast iterative optimization strategy, which utilizes two real-valued embeddings of unequal dimensions, i.e., real-valued embeddings of images and labels, to flexibly perform asymmetric similarity computation. It can circumvent the use of the large pairwise similarity matrix by introducing an intermediate label matrix term which results in a remarkable reduction in the memory space cost. By doing this, the learned hash codes are more semantically informative for image retrieval tasks. Experimental results on several benchmark datasets highlight the superiority of SDAH in comparison with many state-of-theart hashing methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						262	275		10.1016/j.neucom.2020.06.036													
J								Leader-following mean square consensus of stochastic multi-agent systems with ROUs and RONs under periodically variable impulse time windows	NEUROCOMPUTING										Leader-following mean square consensus; Randomly occurring nonlinearities; Randomly occurring uncertainties; Stochastic multi-agent systems; Periodically variable impulse time windows	RANDOMLY OCCURRING UNCERTAINTIES; EXPONENTIAL STABILITY; DIFFERENTIAL-SYSTEMS; NEURAL-NETWORKS; SYNCHRONIZATION; NONLINEARITIES; DISTURBANCES	In order to bring the theoretical results into harmony or agreement with the reality, this paper copes with the leader-following mean square consensus issue for a class of nonlinear stochastic multi-agent systems with randomly occurring nonlinearities (RONs) and randomly occurring uncertainties (ROUs) under impulse time windows (ITWs). As a majorizing preconfigured mechanism of the windows, the configuration named periodically variable impulse time windows (PVITWs) is put forward. It not only ensures the periodic-based layout of impulse time window (ITW), but also allows the position and width of the window to be arbitrarily adjustable, so that the preset of ITW is more suitable for applications. Based on the Lyapunov stability theory and graph theory, the corresponding sufficient mean square consensus criteria are given. Finally, the feasibility of theoretical analysis is illustrated by numerical simulations. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						276	286		10.1016/j.neucom.2020.05.041													
J								Stability criteria of quaternion-valued neutral-type delayed neural networks	NEUROCOMPUTING										Stability; Quaternion-valued neural networks; Linear matrix inequality; Neutral-type; Delay	GLOBAL EXPONENTIAL STABILITY; DISCRETE	Stability problem of quaternion-valued neutral-type delayed neural networks (QVNTDNNs) is researched in this paper. By utilizing homeomorphism principle, matrix inequality technique and Lyapunov method, both delay-independent and delay-dependent stability criteria are established in the form of linear matrix inequalities to pledge the existence, uniqueness and global stability of the equilibrium point of the considered QVNTDNNs. An example with simulations is given to manifest the validity of the exported results. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						287	294		10.1016/j.neucom.2020.06.086													
J								Capped L-1-norm distance metric-based fast robust twin bounded support vector machine	NEUROCOMPUTING										Twin bounded support vector machine; Least squares twin bounded support vector machine; Capped L-1-norm; Robustness; Outliers	DISCRIMINANT-ANALYSIS; CLASSIFICATION; TSVH	In this paper, to improve the performance of capped L-1-norm twin support vector machine (CTSVM), we first propose a new robust twin bounded support vector machine (RTBSVM) by introducing the regularization term. The significant advantage of our RTBSVM over CTSVM is that the structural risk minimization principle is implemented. This embodies the marrow of statistical learning theory, so this modification can improve the performance of classification. Furthermore, to accelerate the computation of RTBSVM and simultaneously inherit the merit of robustness, we construct a least squares version of RTBSVM (called RTBSVM). This formulation leads to a simple and fast algorithm for binary classifiers by solving just two systems of linear equations. Finally, we derive two simple and effective iterative optimization algorithms for solving RTBSVM and FRTBSVM, respectively. Simultaneously, we theoretically rigorously analyze and prove the computational complexity, local optimality and convergence of the algorithms. Experimental results on one synthetic dataset and nine UCI datasets demonstrate that our methods are competitive with other methods. Additionally, the FRTBSVM is directly applied to recognize the purity of hybrid maize seeds using near-infrared spectral data. Experiments show that our method achieves better performance than the traditional methods in most spectral regions. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						295	311		10.1016/j.neucom.2020.06.053													
J								Anti-synchronization for complex-valued neural networks with leakage delay and time-varying delays	NEUROCOMPUTING										Anti-synchronization; CVNNs; Leakage delay; Time-varying delays	STABILITY ANALYSIS; EXPONENTIAL STABILITY	This paper discusses the anti-synchronization control of complex-valued neural networks(CVNNs) with leakage delay and time-varying delays. Based on different types of activation functions meeting different assumption conditions, via some inequalities techniques and the Lyapunov approach, some sufficient conditions are acquired of the anti-synchronization of CVNNs by choosing the suitable controllers. Finally, two examples are presented to validate the effectiveness of the obtained criteria. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						312	319		10.1016/j.neucom.2020.06.080													
J								Event-triggered adaptive neural control of fractional-order nonlinear systems with full-state constraints	NEUROCOMPUTING										Fractional order nonlinear system (FONS); Full-state constraints; Barrier Lyapunov function (BLF); Neural networks (NNs); Event-triggered control (ETC)	BARRIER LYAPUNOV FUNCTIONS; TRACKING CONTROL	In this article, we present an event-triggered scheme for fractional order nonlinear systems under full state constraints. The neural networks are employed to approximate the continuous nonlinear unknown functions in the system. Moreover, a new adaptive event-triggered strategy is designed under the unified framework of backstepping control method, which can largely reduce the amount of communications. Since the state constraints are frequently emerged in the control procedure, the barrier Lyapunov functions is used to avoid the violation of state constraints. The stability of the closed-loop system is ensured through fractional Lyapunov stability analysis. Finally, the effectiveness of the proposed scheme is verified by simulation examples. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						320	326		10.1016/j.neucom.2020.06.082													
J								CoHoMo: A cluster-attribute correlation aware graph clustering framework	NEUROCOMPUTING										Attributed graph; Graph clustering; Bi-objective optimization	COMMUNITY DETECTION; NETWORKS; ORGANIZATION	An attributed graph is a graph where nodes are associated with attributes describing their features. Clustering on an attributed graph is to detect clusters that have not only (1) cohesive structure; but also (2) homogeneous attribute values. We observe that in an attributed graph, different clusters tend to correlate to different attributes. For example, a cluster may show homogeneous values on attribute A but random values on attribute B, while for another cluster the situation could be the reverse. Existing attributed graph clustering methods ignore this phenomenon, thus leading to unsatisfactory clustering results. In this paper, we propose a novel attributed graph clustering framework called CoHoMo to detect clusters with different attribute correlation patterns. The objective is to detect clusters that show both high structural cohesiveness and value homogeneity on some of the attributes. CoHoMo defines and optimizes a correlation weight vector for each cluster to capture its correlation degrees to different node attributes. We formalize this problem as a bi-objective optimization problem and design an efficient heuristic optimizing method. The correlation weights for a cluster can be updated in two ways, synchronous updating or asynchronous updating, during the process of clustering. CoHoMo is parameter-free and has near linear scalability. Theoretical analysis shows that all the results on the Pareto front generated by CoHoMo are weak Pareto optimal solutions. Extensive experiments on attributed graphs based on several real world networks verify the effectiveness and show that our method outperforms the state-of-the-art method. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						327	338		10.1016/j.neucom.2020.06.002													
J								Dynamic spatial-temporal feature optimization with ERI big data for Short-term traffic flow prediction	NEUROCOMPUTING										Traffic flow prediction; Dynamic spatial-temporal feature; ERI big data; Gradient-boosted regression tree; Principal component analysis	NETWORKS; VOLUME	Accurate short-term traffic flow prediction is an important basis of intelligent transportation systems (ITS) such as transportation operations and urban planning applications. However, due to the lack of complete directly measured data on urban traffic flow, existing studies cannot adequately mine the dynamic spatial-temporal correlations characterizing traffic flows in urban road networks. Electronic registration identification (ERI), which is an emerging technology for uniquely identifying a vehicle, can help collect the travel records of all vehicles. This inspires us to employ ERI big data for traffic flow prediction. In this paper, we propose a dynamic spatial-temporal feature optimization method with ERI big data for shortterm traffic flow prediction based on a gradient-boosted regression tree, called DSTO-GBRT. Firstly, the framework of DSTO-GBRT is built. Secondly, we analyze the dynamic spatial-temporal correlations among the current prediction point and upstream correlative points using the Pearson correlation coefficient (PCC). Thirdly, to eliminate the linear correlations among features, we exploit principal component analysis (PCA) to optimize the original training data and obtain optimized training data. In the experiment, real-world ERI big data from Chongqing are employed for the proposed DSTO-GBRT method. Compared with ST-GBRT, ARIMA, DSTO-BPNN and DSTO-SVM, the results demonstrate that DSTOGBRT can provide timely and adaptive prediction even in rush hour, when traffic conditions change rapidly. Furthermore, compared with DSO-GBRT and DTO-GBRT, the results show that the proposed DSTO-GBRT method is more accurate. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						339	350		10.1016/j.neucom.2020.05.038													
J								Learning in multi-agent systems with asymmetric information structure	NEUROCOMPUTING										Asymmetric information; Learning based control policy; Linear minimum mean square unbiased estimation; Online qudratic optimization; Regret	NETWORKED CONTROL-SYSTEMS; DELAY	In this paper, we study multi-agent systems with asymmetric information structure. Due to limited channel capacity in communication network, the information in routing path suffers a transmission delay. Instead of the game theoretic setting, we formulate the problem as an online quadratic optimization problem subject to stochastic systems involving input delay. Since the probability statistics of system noise is unknown, the decision-maker can not utilize the traditional optimal control strategies. Motivated by online convex optimization theory, we introduce the notion of regret, which measures the cumulative performance difference between the optimal statistics known (offline) index value and the statistics unknown (online) index value. The contributions of this paper are twofold. First, utilizing the linear minimum mean square biased estimate, we derive a learning based control policy and then characterize its behavior. Second, under some basic assumptions, we further prove that the regret grows at a sub-linear rate and it is explicitly bounded by O(ln T). (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						351	359		10.1016/j.neucom.2019.08.112													
J								Delay-partitioning-based reachable set estimation of Markovian jump neural networks with time-varying delay	NEUROCOMPUTING										Delay-partitioning; Markovian jump neural networks; Reachable set estimation; Time-varying delay	INFINITY STATE ESTIMATION; STABILITY ANALYSIS; H-INFINITY; LINEAR-SYSTEMS; DISCRETE; SYNCHRONIZATION; INEQUALITY; INTERVAL; CRITERIA	The objective of this paper is to estimate the reachable set for a class of delayed neural networks (NNs) subject to Markovian jump parameters and bounded disturbance. First, by virtue of delay-partitioning method, the time-varying delay is divided into some delay components. With suitably constructing Lyapunov-Krasovskii functionals (LKFs), a less conservative delay-dependent condition of finding an ellipsoid-like set to contain all state trajectories that start from the origin is derived in terms of linear matrix inequalities (LMIs). Then the integrally free-matrix-based inequality approach together with the extended reciprocally convex technique is employed to further reduce the conservatism on characterizing bounds of some integral terms. Thanks to a group of free-connection weighting matrices, the proposed reachable set estimation approach is extended to the case that transition probabilities are partially known. Finally, numerical simulations indicate that the derived results are effective and less conservative. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						360	371		10.1016/j.neucom.2020.06.015													
J								Popularity prediction on vacation rental websites	NEUROCOMPUTING										Vacation rental websites; Popularity prediction; Dual-gated recurrent unit; Inter-event time and rating score		In the personal house renting scenario, customers usually make quick assessments based on previous customers' reviews, which makes such reviews essential for the business. If the house is assessed as popular, a Matthew effect will be observed as more people will be willing to book it. Due to the lack of definition and quantity assessment measures, however, it is difficult to make a popularity evaluation and prediction. To solve this problem, the concept of house popularity is well defined in this paper. Specifically, the house popularity is decided by inter-event timeand rating score at the same time. To make a more effective prediction over these two correlated variables, a dual-gated recurrent unit (DGRU) is employed. Furthermore, an encoder-decoder framework with DGRU is proposed to perform popularity prediction. Empirical results show the effectiveness of the proposed DGRU and the encoder decoder framework in two-correlated sequences prediction and popularity prediction, respectively. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						372	380		10.1016/j.neucom.2020.05.092													
J								A Fast Deep AutoEncoder for high-dimensional and sparse matrices in recommender systems	NEUROCOMPUTING										Recommender System; Collaborative Filtering; Latent Factor Analysis; AutoEncoder; Parallelization; High-dimensional and Sparse Matrix; Deep Neural Network		A latent factor analysis (LFA)-based model has outstanding performance in extracting desired patterns from High-dimensional and Sparse (HiDS) data for building a recommender systems. However, they mostly fail in acquiring non-linear features from an HiDS matrix. An AutoEncoder (AE)-based model can address this issue efficiently, but it requires filling unknown data of an HiDS matrix with pre assumptions that leads to the following limitations: a) prefilling unknown data of an HiDS matrix might skew its known data distribution to generate ridiculous recommendations; and b) incorporating a deep AE-style structure to improve its representative learning ability. Experimental results on three HiDS matrices from real recommender systems show that an FDAE-based model significantly outperforms state-of-the-art recommenders in terms of recommendation accuracy. Meanwhile, its computational efficiency is comparable with the most efficient recommenders with the help of parallelization. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						381	391		10.1016/j.neucom.2020.06.109													
J								Probabilistic inference of Bayesian neural networks with generalized expectation propagation	NEUROCOMPUTING										Generalized expectation propagation; Bayesian neural networks; Approximate inference		Deep learning plays an important role in the field of machine learning. However, deterministic methods such as neural networks cannot capture the model uncertainty. Bayesian neural network (BNN) are recently under consideration since Bayesian models provide a theoretical framework to infer model uncertainty. Since it is often difficult to find an analytical solution for BNNs, an effective and efficient approximate inference method is very important for model training and prediction. The generalized version of expectation propagation (GEP) was recently proposed and considered a powerful approximate inference method, which is based on the minimization of Kullback-Leibler (KL) divergence of the true posterior and the approximate distributions. In this paper, we further instantiate the GEP to provide an effective and efficient approximate inference method for BNNs. We assess this method on BNNs including fully connected neural networks and convolutional neural networks on multiple benchmark datasets and show a better performance than some state-of-the-art approximate inference methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						392	398		10.1016/j.neucom.2020.06.060													
J								Exponential input-to-state stability of stochastic dela reaction-diffusion neural networks	NEUROCOMPUTING										Mean square exponential input-to-state stability; Stochastic delay neural networks; Reaction-diffusion; Distributed input; Boundary input	NONLINEAR-SYSTEMS; TRACKING CONTROL; SYNCHRONIZATION; STABILIZATION	This paper considers the mean square exponential input-to-state stability (EISS) for stochastic delay reaction-diffusion neural networks (SDRDNNS). SDRDNNS with distributed input and boundary input are investigated. In addition, constant delay and time-varying delay are considered. With the help of Lyapunov-Krasovskii functional method, Ito formula and Wirtinger-type inequality, delay-dependent sufficient conditions on mean square EISS of SDRDNNS are presented. These sufficient conditions show the effects of time-delay and diffusion term on mean-square EISS. Moreover, by means of numerical simulation, the effectiveness of our theoretical results is illustrated. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						399	405		10.1016/j.neucom.2019.09.118													
J								Learning longer-term dependencies via grouped distributor unit	NEUROCOMPUTING										Recurrent neural network; Sequence learning; Long-term memory		Learning long-term dependencies remains difficult for recurrent neural networks (RNNs) despite their success in sequence modeling recently. In this paper, we propose a novel gated RNN structure, which contains only one gate. Hidden states in the proposed grouped distributor unit (GDU) are partitioned into groups. For each group, the proportion of memory to be overwritten in each state transition is limited to a constant and is adaptively distributed to each group member. In other words, every separate group has a fixed overall update rate, yet all units are allowed to have different paces. Information is therefore forced to be latched in a flexible way, which helps the model to capture long-term dependencies in data. Besides having a simpler structure, GDU is demonstrated experimentally to outperform other models such as LSTM and GRU on both pathological problems and tasks on natural datasets. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						406	415		10.1016/j.neucom.2020.06.105													
J								Biologically plausible mechanisms underlying motor response correction during reward-based decision-making	NEUROCOMPUTING										Reward-based decision-making; Spiking network models; Anterior cingulate cortex; Prefrontal cortex; Neural substrates of adaptive behaviors	ANTERIOR CINGULATE CORTEX; PREFRONTAL CORTEX; WORKING-MEMORY; INTEGRATIVE THEORY; ERROR-DETECTION; CONFLICT; DOPAMINE; RECEPTORS; DYNAMICS; MODEL	Our propensity to acclimate to new surroundings and flexibly choose an optimal behavior for a maximal reward (i.e., optimal outcome) is natural, for it affects our survival. A line of studies suggested that the anterior cingulate cortex (ACC) could be a potential hub for adaptive behaviors, but its exact functions remain poorly understood. One experimental study suggested that ACC can enable monkeys to correct errors, but another study found that a legion of ACC did not impair monkeys' ability to correct errors. Instead, it made monkeys incapable of maintaining their optimal actions. Given the importance of ACC in reward-based decision-making, it is imperative to better understand the functions of ACC in reward-based decision-making. To this end, we sought biologically-plausible mechanisms to account for the two seemingly conflicting results mentioned above by utilizing a computational model. From our simulations, we found that 1) the interplay between the prefrontal cortex (PFC) and ACC can account for both experimental observations and 2) ACC can correct behavioral responses by reading out and updating motor plans (guiding future motor responses) stored in PFC. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						416	425		10.1016/j.neucom.2020.06.103													
J								Deep and wide feature based extreme learning machine for image classification	NEUROCOMPUTING										Extreme Learning Machine; Image Classification; Wide Residual Network	CNN-SVM	Extreme Learning Machine (ELM) is a powerful and favorable classifier used in various applications due to its fast speed and good generalization capability. However, when dealing with complex visual tasks, the shallow architecture of ELM makes it infeasible to have good performance when raw image data are directly fed in as input. Therefore, several works tried to make use of deep neural networks (DNNs) to extract features before ELM classification. On the other hand, when the depth of DNN is too deep, the ELM classifier may suffer from overfitting problem. To solve this issue, a novel deep and wide feature based Extreme Learning Machine (DW-ELM) has been proposed in this research work. We show that the overfitting problem can be largely remedied by employing a "widened" convolutional neural network (CNN) for feature extraction, in the sense that the number of feature maps for each convolutional layer is increased by factor of k compared to a reference model, i.e. deep residual networks (ResNets). While the wide design of residual networks has been shown to benefit image classification in terms of accuracy and efficiency, its application for feature extraction is not fully investigated. We provide an extensive experimental study in this work, showing that when combined with ELM that serves as a classifier, using wide ResNets (WRNs) for feature extraction can produce a performance leap on all benchmark datasets compared to a plain end-to-end trained network over a wide range of selections regardless of architecture choices and ELM designs, while normal ResNets as feature extractors do not provide a performance gain. The gap is even larger when fewer training iterations are employed. This indicates that a good feature extractor for ELM must be wide and deep. Experiments conducted on five benchmark datasets (CIFAR-100, CIFAR-10, STL-10, Flower-102 and Fashion-MNIST) have shown significant accuracy enhancement as well as training stability of the proposed DW-ELM. Ablation studies also demonstrate that the ELM classifier is an important component for DW-ELM which enables superior performance compared with SVM based image classification approaches. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						426	436		10.1016/j.neucom.2020.06.110													
J								Real-time salient object detection with boundary information guidance	NEUROCOMPUTING										Salient object detection; Low-contrast; Saliency information; Boundary information; Multi-level feature fusion; Real-time	VISUAL-ATTENTION; MODEL	The low contrast between salient objects and background may result in errors in salient object detection. The low-contrast areas are likely distinguished away from salient objects by saliency information. However, salient objects near the boundary are often detected wrongly based on current methods. In this paper, a novel network with boundary information guidance is proposed to distinguish low-contrast areas near the boundary effectively. We design two separate decoding sub-networks including a saliency sub-network and a boundary sub-network to learn saliency and boundary information respectively based on multi-level feature fusion. We further design a connection module to exchange the information between two sub-networks and a fusion module to fuse information of salient objects and boundaries. The boundary sub-network supervised by boundary maps outputs the error map calculated by ground truth to focus on boundary information. The boundary sub-network is only used in training and the optimal weight of the total loss is obtained by experiments to balance the two sub-network losses. With the guidance of boundary information, salient objects are detected accurately. Extensive evaluations on six benchmark and two video datasets demonstrate that our model outperforms the state-of-the-art methods. Furthermore, the proposed model can run at more than 34 FPS. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						437	446		10.1016/j.neucom.2020.06.072													
J								From pedestrian to group retrieval via siamese network and correlation	NEUROCOMPUTING										Siamese Network; Minimum Distance Matching; Group Retrieval Correlation; Benchmark		In many public security applications such as anomaly detection, it is important to re-identify a group of pedestrians by other surveillance cameras, which ascribes to the group retrieval problem. Most previous studies focus on single-person re-identification (re-id) and ignore the correlations among group members, and they lack a large and comprehensive group retrieval benchmark to associate these two tasks. To address this issue, this paper focuses on solving the group retrieval problem and uses it to improve re-id. First, the paper build a comprehensive benchmark for both group retrieval and the group-aided re-id task by proposing a novel pedestrian group retrieval dataset named "SYSU-Group" and a corresponding group-associated re-id dataset named "Group-reID", which introduces realistic challenges such as variations of pose, viewpoint, illumination, and intra-group layout. The paper then proposes the Siamese Verification-Identification-based Group Retrieval (SVIGR) method, which combines verification and identification modules in a Siamese network to extract robust person features and follows the principle of minimum distance matching to realize group retrieval. Finally, a group-guided re-id method named group retrieval correlation (GRC) is proposed to improve re-id with additional group information. Experimental results on three various group retrieval benchmarks demonstrate the superiority and effectiveness of our method. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 28	2020	412						447	460		10.1016/j.neucom.2020.06.055													
J								A simulation-based few samples learning method for surface defect segmentation	NEUROCOMPUTING										Surface defect segmentation; Small-sample leaning; Dataset augmentation; Defect sample simulation; Image restoration	INSPECTION	In industrial production, it is difficult to obtain a well-trained surface detection algorithm since the real defect samples are lacking. In this paper, we propose a surface defect segmentation method based on defect sample simulation, which only needs few defect training samples. The entire method includes two modules: a local defect simulation algorithm and a residual-restored-based segmentation algorithm. In order to ensure both structural and local texture consistency of the simulated defects, we design a two stage simulation algorithm based on generation adversarial net and neural style transfer. The simulation method requires one single defect reference sample for training, and can generate the same type of defect in the specified area. The segmentation algorithm, trained with the simulated images and reference samples, can restore the defect area and yield the predicted label from the residual image. We carry out experiments on the button, road crack, and silicon steel strip datasets. The results show that the proposed method can remarkably improve the defect segmentation accuracy, attaining F1 score of 0.82. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						461	476		10.1016/j.neucom.2020.06.090													
J								Discrete-time nonlinear optimization via zeroing neural dynamics based on explicit linear multi-step methods for tracking control of robot manipulators	NEUROCOMPUTING										Discrete-time nonlinear optimization; Robot manipulators; Continuous-time zeroing neural dynamics model; Explicit linear multi-step methods; Discrete-time zeroing neural dynamics models	ZNN MODELS; NETWORK; EQUALITY; DESIGN; INVERSE	In this paper, discrete-time nonlinear optimization (DTNO) for tracking control of robot manipulators is investigated. By utilizing zeroing neural dynamics (ZND) method, a continuous-time ZND (CTZND) model is first proposed for solving the corresponding continuous-time nonlinear optimization (CTNO) problem. Afterwards, three different explicit linear multi-step methods (i.e., explicit linear 3-step, 2-step, and 1 step methods) are respectively presented and investigated. To solve such a DTNO problem, the explicit linear 3-step method is adopted to combine with the CTZND model, and hence a 3-step discrete-time ZND (DTZND) model is proposed. For comparison purposes, 2-step and 1-step DTZND models are also developed. Besides, theoretical analyses indicate the validity and superiority of the proposed 3-step DTZND model. Finally, the numerical experimental results based on a 2-joint robot manipulator and a PUMA560 robot manipulator further verify that the proposed 3-step DTZND model is much superior to the other two DTZND models. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						477	485		10.1016/j.neucom.2020.05.093													
J								BNGBS: An efficient network boosting system with triple incremental learning capabilities for more nodes, samples, and classes	NEUROCOMPUTING										Additive model; Broad network; Cascade model; Greedy strategy; Gradient boosting machine; Incremental learning	MACHINE; ALGORITHM	As an ensemble algorithm, network boosting enjoys a powerful classification ability but suffers from the tedious and time-consuming training process. To tackle the problem, in this paper, a broad network gradient boosting system (BNGBS) is developed by integrating gradient boosting machine with broad networks, in which the classification loss caused by a base broad network is learned and eliminated by followed networks in a cascade manner. The proposed system is constructed as an additive model and can be easily optimized by a greedy strategy instead of the tedious back-propagation algorithm, resulting in a more efficient learning process. Meanwhile, triple incremental learning capabilities including the increment of feature nodes, increment of input samples, and increment of target classes are designed. The proposed system can be efficiently updated and expanded based on the current status instead of being entirely retrained when the demands for more feature nodes, input samples, and target classes are proposed. The node-increment ability allows to add more feature nodes into the built system if the current structures are not effective for learning. The sample-increment ability is developed to allow the model to keep learning from the coming batch data. The class-increment ability is used to tackle the issue that the coming batch data may contain unseen categories. In comparison with existing popular machine learning methods, comprehensive results based on eight benchmark datasets illustrate the effectiveness of the proposed broad network gradient boosting system for the classification task. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						486	501		10.1016/j.neucom.2020.06.100													
J								Robust adaptive neural practical fixed-time tracking control for uncertain Euler-Lagrange systems under input saturations	NEUROCOMPUTING										Tracking control of Euler-Lagrange systems; Unknown dynamics; Input saturation; Auxiliary dynamic system; Adaptive neural network; Fixed time	MIMO NONLINEAR-SYSTEMS; FAULT-TOLERANT CONTROL; SLIDING MODE CONTROL; ROBOT MANIPULATORS; OUTPUT CONSTRAINTS; NETWORK CONTROL; STABILIZATION; PERFORMANCE; SPACECRAFT; DESIGN	This paper develops a robust adaptive neural practical fixed-time tracking control scheme for Euler-Lagrange systems (ELSs) with unknown dynamics and external disturbances under input saturations. A novel auxiliary dynamic system governed by a smooth piecewise continuous function is constructed to handle the input saturation effect, while promoting to achieve the fixed-time convergence of tracking errors. Moreover, the unknown dynamics of ELSs and the bound vector of unknown external disturbances are synthesized into a compounded uncertain vector in this paper. Here, adaptive neural networks with the epsilon-modification updating laws are employed to only approximate the compounded uncertain vector, rather than each dynamic matrix of ELSs, such that the computational burden of the developed control scheme is significantly reduced. It is theoretically proven that the trajectory tracking is able to be achieved in a fixed time under the developed adaptive neural tracking control scheme, while all signals in the Euler-Lagrange closed-loop tracking control system are bounded. The simulation results on a 2-link robotic manipulator are included to illuminate the effectiveness of our developed tracking control scheme and superiority to a finite-time control scheme. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						502	513		10.1016/j.neucom.2020.05.057													
J								EDNC: Evolving Differentiable Neural Computers	NEUROCOMPUTING										Deep Learning; Artificial Neural Network with External Memory; Evolutionary Differentiable Neural Computer; Adaptive Layer NeuroEvolution; Matrix-based Adaptive Layer; NeuroEvolution	ARCHITECTURES	One recent study in the field of deep learning is extending Artificial Neural Networks (ANNs) by coupling them to external memory resources. Neural Turing Machine (NTM) and Differentiable Neural Computer (DNC) are two counterparts in this field. Research activities fall into two categories of either interacting with memory or choosing controller components. The first approach uses a try and error fashion to provide the controller's structure that would be a problem when there is no prior knowledge on the controller's structure for particular tasks. The second approach includes methods for choosing the controller's structure and weight optimization. NeuroEvolution falls in the second category that automatically and without prior knowledge obtains an appropriate network structure. This research presents Evolutionary Differentiable Neural Computer (EDNC), which uses a novel NeuroEvolution algorithm that is introduced in two types of nested object-oriented encoding called Adaptive Layer NeuroEvolution (ALNE) and Matrix-based one called M_ALNE. These NeuroEvolution algorithms use the following sub-algorithms: Self-Adaptivity in the Initial Population (SAIP), Self-Adaptivity in Evolutionary Structures (SAES), Layer Recombination (LR), Layer Mutation (LM), and Self-Adaptivity in Mutation (SAM). The evolution process starts with SAIP, and then it takes short and long steps to explore a variety of neural structures by SAES algorithm that uses both LR and LM algorithms to provide a variety of structures. Finally, the SAM algorithm guides the selected structures to a target structure. In this research, experiments applied EDNC on well-known tasks, including Facebook bAbI, copy, graph (shortest path), and 8-puzzle. The experiments show that the proposed method in both encodings automatically and without prior knowledge, produces an appropriate controller structure in the shortest time. It though shows that both proposed encodings reduce the evolution time by at least 73% in comparison with the baseline methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 28	2020	412						514	542		10.1016/j.neucom.2020.06.018													
J								Automatic Detection of Oil Palm Tree from UAV Images Based on the Deep Learning Method	APPLIED ARTIFICIAL INTELLIGENCE											CLASSIFICATION	Palm oil is a major contributor to Malaysia's GDP in the agriculture sector. The sheer vastness of oil palm plantations requires a huge effort to administer. An oil palm plantation in regards to the irrigation process, fertilization, and planning for planting new trees require an audit process to correctly count the oil palm trees. Currently, the audit is done manually using aerial view images. Therefore, an effective and efficient method is imperative. This paper proposes a new automatic end-to-end method based on deep learning (DL) for detection and counting oil palm trees from images obtained from unmanned aerial vehicle (UAV) drone. The acquired images were first cropped and sampled into small size of sub-images, which were divided into a training set, a validation set, and a testing set. A DL algorithm based on Faster-RCNN was employed to build the model, extracts features from the images and identifies the oil palm trees, and gives information on the respective locations. The model was then trained and used to detect individual oil palm tree based on data from the testing set. The overall accuracy of oil palm tree detection was measured from three different sites with 97.06%, 96.58%, and 97.79% correct oil palm detection. The results show that the proposed method is more effective, accurate detection, and correctly counts the number of oil palm trees from the UAV images.																	0883-9514	1087-6545															10.1080/08839514.2020.1831226		OCT 2020											
J								Moving target extraction and background reconstruction algorithm	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Moving target extraction; Background reconstruction; RGB; Time dimension; Space dimension	OBJECT SEGMENTATION; INFRARED TARGET; ACTIVE CONTOUR; MODEL	It is difficult for the computer to distinguish the target from the background due to the long-time static of the target after moving. A new moving target detection and background reconstruction algorithm is proposed and is applied into the RGB video for the first time. Firstly, the proposed algorithm builds a model from the time dimension to extract the changed region. Then, it combines with the space dimension information to completely extract the moving target. The spatiotemporal correlation model is established to realize the construction of pure background. The experimental results show that the proposed algorithm can effectively reconstruct the background and the recognition rate of moving target is high.																	1868-5137	1868-5145															10.1007/s12652-020-02619-2		OCT 2020											
J								Diagnosis of secondary pulmonary tuberculosis by an eight-layer improved convolutional neural network with stochastic pooling and hyperparameter optimization	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Secondary pulmonary tuberculosis; Deep learning; Convolutional neural network; Stochastic pooling; Dynamic learning rate; Hyper-parameter optimization	BATCH NORMALIZATION; RECOGNITION; DROPOUT	To more efficiently diagnose secondary pulmonary tuberculosis, we build an improved convolutional neural network (ICNN) based on recent deep learning technologies. First, a 12-way data augmentation (DA-12) was proposed to increase size of training set. Second, stochastic pooling was introduced to replace the standard average pooling and max pooling. Third, batch normalization and dropout techniques were included and associated with conv layers and fully-connected layers, respectively. Fourth, a dynamic learning rate was employed to replace traditional fixed learning rate. Fifth, hyperparameter optimization was used to optimize the number of layers within proposed network. Our eight-layer ICNN demonstrated excellent results on the test set, yielding a sensitivity of 94.19%, a specificity of 93.72%, and an accuracy of 93.95%. Our ICNN provides better performances than other four state-of-the-art algorithms. It can help radiologists to make more accurate diagnosis on secondary pulmonary tuberculosis.																	1868-5137	1868-5145															10.1007/s12652-020-02612-9		OCT 2020											
J								Position-aware lightweight object detectors with depthwise separable convolutions	JOURNAL OF REAL-TIME IMAGE PROCESSING										Object detection; Knowledge distillation; Depthwise separable convolution; Attention model		Recently, significant improvements have been achieved for object detection algorithm by increasing the size of convolutional neural network (CNN) models, but the resulting increase of computational complexity poses an obstacle to practical applications. And some of the lightweight methods fail to consider the characteristics of object detection into and suffer a huge loss of accuracy. In this paper, we design a multi-scale feature lightweight network structure and specific convolution module for object detection based on depthwise separable convolution, which not only reduces the computational complexity but also improves the accuracy by using the specific position information in object detection. Furthermore, in order to improve the detection accuracy for small objects, we construct a multi-channel position-aware map and propose training based on knowledge distillation for object detection to train the lightweight model effectively. Last, we propose a training strategy based on a key-layer guiding structure to balance performance with training time. The experimental results show that on the COCO dataset that takes the state-of-the-art object detection algorithm, YOLOv3, as the baseline, our model size is compressed to 1/11 while accuracy drops by 7.4 mmAP, and the computational latency on the GPU and ARM platforms are reduced to 43.7% and 0.29%, respectively. Compared with the state-of-the-art lightweight object detection model, MNet V2 + SSDLite, the accuracy of our model increases by 3.5 mmAP while the inferencing time stays nearly the same. On the PASCAL VOC2007 dataset, the accuracy of our model increases by 5.2 mAP compared to the state-of-the-art lightweight algorithm based on knowledge distillation. Therefore, in terms of accuracy, parameter count, and real-time performance, our algorithm has better performance than lightweight algorithms based on knowledge distillation or depthwise separable convolution.																	1861-8200	1861-8219															10.1007/s11554-020-01027-1		OCT 2020											
J								A comparison of multi-objective optimization algorithms for weight setting problems in traffic engineering	NATURAL COMPUTING										Traffic engineering; Intra-domain routing; Link-state routing protocols; Multiobjective evolutionary algorithms; NSGA-II	GENETIC ALGORITHM	Traffic engineering approaches are increasingly important in network management to allow an optimized configuration and resource allocation. In link-state routing, setting appropriate weights to the links is an important and challenging optimization task. Different approaches have been put forward towards this aim, including evolutionary algorithms (EAs). This work addresses the evaluation of a single and two multi-objective EAs, in two tasks related to weight setting optimization towards optimal intra-domain routing, knowing the network topology and aggregated traffic demands and seeking to minimize network congestion. In both tasks, the optimization considers scenarios where there is a dynamic alteration in the network, with (1) changes in the traffic demand matrices, and (2) link failures. The methods will simultaneously optimize for both conditions, the normal and the altered one, following a preventive TE approach. Since this leads to a bi-objective function, the use of multi-objective EAs, such as SPEA2 and NSGA-II, came naturally; those are compared to a single-objective EA previously proposed by the authors. The results show a remarkable performance and scalability of NSGA-II in the proposed tasks presenting itself as the most promising option for TE.																	1567-7818	1572-9796															10.1007/s11047-020-09807-1		OCT 2020											
J								A new Arabic handwritten character recognition deep learning system (AHCR-DLS)	NEURAL COMPUTING & APPLICATIONS										Arabic handwritten character recognition; Classification; Convolutional neural network; Data augmentation; Deep learning; Optical character recognition; Optimizers	ONLINE	Optical character recognition for the English text may be considered one of the most important research topics, whether, printed or handwritten. Although excellent results have been reached in the English text, there is a lack of this type of research in the Arabic text. This is because of the nature of the Arabic alphabet, and the multiplicity of forms of the same letter. Arabic handwritten character recognition (AHCR) systems involve several issues, and challenges from finding a suitable, and public Arabic handwritten text dataset phase to recognition, and classification phase passing through segmentation, and feature extraction phases. The paper objectives are: Firstly, a large, and complex Arabic handwritten characters' dataset (HMBD) is presented for training, testing, and validation phases, as well as, discussing its collection, preparation, cleaning, and preprocessing. Secondly, we introduce a deep learning (DL) system with two convolutional neural network (CNN) architectures (named HMB1 and HMB2); with the appliance of optimization, regularization, and dropout techniques. This system can serve as a baseline for future research on handwritten Arabic text. Different performance metrics were calculated such as accuracy, recall, precision, and F1. 16 experiments were applied to the described system using HMBD, and another two datasets: CMATER, and AIA9k. Experiments' results were captured and compared to study the effects of weight initializers, optimizers, data augmentation, and regularization on overfitting, and accuracy. He Uniform weight initializer and AdaDelta optimizer reported the highest accuracies. Data augmentation showed an improvement in the accuracies. HMB1 reported testing accuracy of 98.4% with 865,840 records using augmentation on HMBD. CMATER and AIA9k datasets were used for validating the generalization. Data augmentation was applied, and the best results were 100%, and 99.0% for testing accuracies, respectively. A cross-over validation between the described architectures, and a previous state-of-the-art architecture, and dataset was performed in two phases. First, the previous control architecture cannot generalize for the presented dataset in the current study. Second, the study described architectures generalize for the control dataset, with higher accuracies (97.3%, and 96.8% for HMB1, and HMB2, respectively), than the reported accuracy in the selected control study.																	0941-0643	1433-3058															10.1007/s00521-020-05397-2		OCT 2020											
J								Privacy-preserving image multi-classification deep learning model in robot system of industrial IoT	NEURAL COMPUTING & APPLICATIONS										Privacy-preserving; Deep learning; Industrial Internet of Things (IIoT); Secure calculation	SECURITY; PROTOCOLS	Deep learning in robot systems is a popular application that can learn and train the results per requirements, but that collects sensitive information in the training process, easily causing leakage of users' private information. To date, privacy-preserving deep learning models in robot systems have been sparsely researched. To solve the privacy leakage problem of deep learning in robot systems and fill the gap in robotics deep learning privacy research, in this paper a novel privacy-preserving image multi-classification deep-learning (PIDL) model in robot systems is presented. In PIDL, two schemes are proposed that adopt two groups of encrypted activation and cost functions-sigmoid plus cross-entropy function (PIDLSC) and softmax plus log-likelihood function (PIDLSL)-with secure calculation protocols, which are applied in a fog control center (FCC) with a non-colluding honest server by homomorphic encryption to improve the training efficiency, solve the encryption computation questions, and protect data and model privacy in robot systems. Security analysis and performance evaluation demonstrate that the proposed schemes realize security, correctness, and efficiency with low communication and computational costs.																	0941-0643	1433-3058															10.1007/s00521-020-05426-0		OCT 2020											
J								ARIMA models for predicting the end of COVID-19 pandemic and the risk of second rebound	NEURAL COMPUTING & APPLICATIONS										COVID-19 pandemic; Infection control; SARIMA; ARIMA models; Prediction; Second rebound; AIC		Globally, many research works are going on to study the infectious nature of COVID-19 and every day we learn something new about it through the flooding of the huge data that are accumulating hourly rather than daily which instantly opens hot research avenues for artificial intelligence researchers. However, the public's concern by now is to find answers for two questions; (1) When this COVID-19 pandemic will be over? and (2) After coming to its end, will COVID-19 return again in what is known as a second rebound of the pandemic? In this work, we developed a predictive model that can estimate the expected period that the virus can be stopped and the risk of the second rebound of COVID-19 pandemic. Therefore, we have considered the SARIMA model to predict the spread of the virus on several selected countries and used it for predicting the COVID-19 pandemic life cycle and its end. The study can be applied to predict the same for other countries as the nature of the virus is the same everywhere. The proposed model investigates the statistical estimation of the slowdown period of the pandemic which is extracted based on the concept of normal distribution. The advantages of this study are that it can help governments to act and make sound decisions and plan for future so that the anxiety of the people can be minimized and prepare the mentality of people for the next phases of the pandemic. Based on the experimental results and simulation, the most striking finding is that the proposed algorithm shows the expected COVID-19 infections for the top countries of the highest number of confirmed cases will be manifested between Dec-2020 and Apr-2021. Moreover, our study forecasts that there may be a second rebound of the pandemic in a year time if the currently taken precautions are eased completely. We have to consider the uncertain nature of the current COVID-19 pandemic and the growing inter-connected and complex world, that are ultimately demanding flexibility, robustness and resilience to cope with the unexpected future events and scenarios.																	0941-0643	1433-3058															10.1007/s00521-020-05434-0		OCT 2020											
J								Molten steel temperature prediction using a hybrid model based on information interaction-enhanced cuckoo search	NEURAL COMPUTING & APPLICATIONS										Hybrid modeling; Cuckoo search; Artificial neural networks; Molten steel temperature; Ladle furnace	PARTICLE SWARM OPTIMIZATION; LADLE FURNACE; PARAMETER-ESTIMATION; ALGORITHM; SYSTEM; IDENTIFICATION; DESIGN	This article presents a hybrid model for predicting the temperature of molten steel in a ladle furnace (LF). Unique to the proposed hybrid prediction model is that its neural network-based empirical part is trained in an indirect way since the target outputs of this part are unavailable. A modified cuckoo search (CS) algorithm is used to optimize the parameters in the empirical part. The search of each individual in the traditional CS is normally performed independently, which may limit the algorithm's search capability. To address this, a modified CS, information interaction-enhanced CS (IICS), is proposed in this article to enhance the interaction of search information between individuals and thereby the search capability of the algorithm. The performance of the proposed IICS algorithm is first verified by testing on two benchmark sets (including 16 classical benchmark functions and 29 CEC 2017 benchmark functions) and then used in optimizing the parameters in the empirical part of the proposed hybrid prediction model. The proposed hybrid model is applied to actual production data from a 300 t LF at Baoshan Iron & Steel Co. Ltd, one of China's most famous integrated iron and steel enterprises, and the results show that the proposed hybrid prediction model is effective with comparatively high accuracy.																	0941-0643	1433-3058															10.1007/s00521-020-05413-5		OCT 2020											
J								Fault detection of continuous glucose measurements based on modified k-medoids clustering algorithm	NEURAL COMPUTING & APPLICATIONS										Type 1 diabetes; Continuous glucose monitoring; k-medoids clustering; Abnormality detection	CLOSED-LOOP CONTROL; ARTIFICIAL PANCREAS; FUNCTIONAL REDUNDANCY; DENOISING METHOD; ERROR-DETECTION; NOISE-LEVEL; TIME; SYSTEMS; MEAL	As continuous glucose monitoring (CGM) systems provide critical feedback information of blood glucose concentration to the artificial pancreas for patients with type 1 diabetes (T1D), faults in CGM may seriously affect the computation of insulin infusion rates which can lead to fatal consequences accompany with hypoglycemia or hyperglycemia. In the present work, the k-medoids clustering algorithm is modified by calculating cluster number with a Bayesian Information Criterion (BIC)-based cost function and the SAC (SSE-ASW Criterion) evaluation coefficient which considers both SSE (Sum of Square due to Error) and ASW (Average Silhouette Width) criteria. Then, the modified k-medoids clustering algorithm is proposed to detect sensor failures online with CGM measurements. Different from the qualitative model-based methods and quantitative model-based methods, sufficient clean data are the only requirement of the proposed method. During online monitoring, the new glycemic variability is then tracked against predefined confidence limits during training period to indicate abnormality. The feasibility of the proposed method is successfully assessed using CGM data collected from the UVa/Padova metabolic simulator.																	0941-0643	1433-3058															10.1007/s00521-020-05432-2		OCT 2020											
J								A novel bat algorithm with dynamic membrane structure for optimization problems	APPLIED INTELLIGENCE										Dynamic membrane structure; Parallel membrane framework; Bat algorithm; Optimization problems	P-SYSTEMS; SELECTION; SEARCH	To improve the optimization efficiency for different optimization problems and take advantage of the dynamic membrane computing framework, this paper proposes an improved bat algorithm, namely, Dynamic Membrane-driven Bat Algorithm (DMBA). The dynamic construction of the DMBA algorithm aims at enhancing population diversity by balancing the exploration-exploitation tradeoff. Unlike the static membrane algorithms, the membranes in DMBA will be dynamically evolved by using merging and separation rules which help in maintaining the diversity of the population. The experimental results on a set of well-known benchmark functions including CEC 2005, CEC 2011, and CEC 2017 clearly prove the effectiveness of the proposed DMBA algorithm in terms of maintaining the diversity and exploitation capabilities compared to that of the others. It is shown that the proposed DMBA algorithm is superior to recent variants of the bat algorithm and other well-known algorithms in terms of solution accuracy and convergence speed.																	0924-669X	1573-7497															10.1007/s10489-020-01898-8		OCT 2020											
J								Infrared image super-resolution reconstruction by using generative adversarial network with an attention mechanism	APPLIED INTELLIGENCE										Infrared images; Super-resolution reconstruction; Attention mechanism; Generative adversarial network		Due to the limitations of infrared imaging principles and imaging systems, many problems are typically encountered with collected infrared images, such as low resolution, insufficient detail information, and blurred edges. In response to these problems, a method of infrared image super-resolution reconstruction that uses recursive attention and is based on a generative adversarial network is proposed. First, according to the characteristics of low-resolution infrared images such as uniform pixel distributions, low contrast, and poor perceived quality, a deep generator structure with a recursive-attention network is designed in this article. The recursive-attention module is used to extract high-frequency information from the feature maps, suppress useless information, and enhance the expressiveness of the features, which facilitates the reconstruction of texture details of infrared images. Then, to better distinguish the reconstructed images from the original high-resolution images, we designed a discriminator that was composed of a deep convolutional neural network. In addition, targeted improvements were made to the content loss function of GAN. We used the pre-trained VGG-19 network features before activation to calculate the perceptual loss, which helps recover the texture details of the infrared images. The experimental results on infrared image datasets demonstrated that the reconstruction performance of the proposed method is higher than those of several typical methods, and it realizes higher image visual quality.																	0924-669X	1573-7497															10.1007/s10489-020-01987-8		OCT 2020											
J								Forecasting COVID-19 outbreak progression using hybrid polynomial-Bayesian ridge regression model	APPLIED INTELLIGENCE										COVID-19 pandemic; Bayesian ridge regression; Prediction; Mathematical modeling	TRANSMISSION DYNAMICS	In 2020, Coronavirus Disease 2019 (COVID-19), caused by the SARS-CoV-2 (Severe Acute Respiratory Syndrome Corona Virus 2) Coronavirus, unforeseen pandemic put humanity at big risk and health professionals are facing several kinds of problem due to rapid growth of confirmed cases. That is why some prediction methods are required to estimate the magnitude of infected cases and masses of studies on distinct methods of forecasting are represented so far. In this study, we proposed a hybrid machine learning model that is not only predicted with good accuracy but also takes care of uncertainty of predictions. The model is formulated using Bayesian Ridge Regression hybridized with an n-degree Polynomial and uses probabilistic distribution to estimate the value of the dependent variable instead of using traditional methods. This is a completely mathematical model in which we have successfully incorporated with prior knowledge and posterior distribution enables us to incorporate more upcoming data without storing previous data. Also, L-2 (Ridge) Regularization is used to overcome the problem of overfitting. To justify our results, we have presented case studies of three countries, -the United States, Italy, and Spain. In each of the cases, we fitted the model and estimate the number of possible causes for the upcoming weeks. Our forecast in this study is based on the public datasets provided by John Hopkins University available until 11th May 2020. We are concluding with further evolution and scope of the proposed model.																	0924-669X	1573-7497															10.1007/s10489-020-01942-7		OCT 2020											
J								Chameleon algorithm based on mutual k-nearest neighbors	APPLIED INTELLIGENCE										Clustering analysis; Mutual k-nearest neighbors; Chameleon algorithm; Modularity	CLUSTERING METHOD; CLASSIFICATION	Clustering is a typical unsupervised data analysis method, which divides a given data set without label information into multiple clusters. The data on each cluster has a great deal of association, which can be used as the preprocessing stage of other algorithms or for further association analysis. Therefore, clustering plays an important role in a wide range of fields. Chameleon is a clustering algorithm that combines the relative interconnectivity and relative closeness to find clusters of arbitrary shape with high quality. However, the graph-partitioning technology hMETIS algorithm used in the algorithm is difficult to operate and easy to cause uncertainty of results. In addition, the final number of clusters need to be specified by user as a parameter to stop merging, which is difficult to determine without prior information. Aiming at these shortcomings, Chameleon algorithm based on mutual k-nearest neighbors (MChameleon) is proposed. Firstly, the idea of mutual k-nearest neighbors is introduced to directly generate sub-clusters, which omits the process of partitioning graph. Then, the concept of MC modularity is introduced, which is used to objectively identify the final clustering results. By experiments on artificial data sets and UCI data sets, we compared MChameleon with the original Chameleon algorithm, the improved AChameleon algorithm and the classic K-Means, DBSCAN, BIRCH algorithm in accuracy. Experimental results on data sets show that Chameleon algorithm based on mutual k-nearest neighbors has great advantages and is feasible.																	0924-669X	1573-7497															10.1007/s10489-020-01926-7		OCT 2020											
J								An integrated methodology to control the risk of cardiovascular disease in patients with hypertension and type 1 diabetes	COMPUTATIONAL INTELLIGENCE										cardiovascular disease screening; genetic algorithm; heart disease; Markov decision processes; risk estimation	CANCER SCREENING-PROGRAM; GENETIC ALGORITHM; OPTIMIZATION; IMPACT; DEATH	Today, air pollution, smoking, use of fatty acids and ready-made foods, and so on, have exacerbated heart disease. Therefore, controlling the risk of such diseases can prevent or reduce their incidence. The present study aimed at developing an integrated methodology including Markov decision processes (MDP) and genetic algorithm (GA) to control the risk of cardiovascular disease in patients with hypertension and type 1 diabetes. First, the efficiency of GA is evaluated against Grey Wolf optimization (GWO) algorithm, and then, the superiority of GA is revealed. Next, the MDP is employed to estimate the risk of cardiovascular disease. For this purpose, model inputs are first determined using a validated micro-simulation model for screening cardiovascular disease developed at Tehran University of Medical Sciences, Iran by GA. The model input factors are then defined accordingly and using these inputs, three risk estimation models are identified. The results of these models support WHO guidelines that provide medicine with a high discount to patients with high expected LYs. To develop the MDP methodology, policies should be adopted that work well despite the difference between the risk model and the actual risk. Finally, a sensitivity analysis is conducted to study the behavior of the total medication cost against the changes of parameters.																	0824-7935	1467-8640															10.1111/coin.12418		OCT 2020											
J								Sentiment analysis of tweets using a unified convolutional neural network-long short-term memory network model	COMPUTATIONAL INTELLIGENCE										convolutional neural networks; deep learning; long short-term memory; sentiment analysis; text mining; Twitter data analysis	MACHINE	Sentiment analysis focuses on identifying and classifying the sentiments expressed in text messages and reviews. Social networks like Twitter, Facebook, and Instagram generate heaps of data filled with sentiments, and the analysis of such data is very fruitful when trying to improve the quality of both products and services alike. Classic machine learning techniques have a limited capability to efficiently analyze such large amounts of data and produce precise results; they are thus supported by deep learning models to achieve higher accuracy. This study proposes a combination of convolutional neural network and long short-term memory (CNN-LSTM) deep network for performing sentiment analysis on Twitter datasets. The performance of the proposed model is analyzed with machine learning classifiers, including the support vector classifier, random forest (RF), stochastic gradient descent (SGD), logistic regression, a voting classifier (VC) of RF and SGD, and state-of-the-art classifier models. Furthermore, two feature extraction methods (term frequency-inverse document frequency and word2vec) are also investigated to determine their impact on prediction accuracy. Three datasets (US airline sentiments, women's e-commerce clothing reviews, and hate speech) are utilized to evaluate the performance of the proposed model. Experiment results demonstrate that the CNN-LSTM achieves higher accuracy than those of other classifiers.																	0824-7935	1467-8640															10.1111/coin.12415		OCT 2020											
J								Evolutionary Fuzzy-based gravitational search algorithm for query optimization in crowdsourcing system to minimize cost and latency	COMPUTATIONAL INTELLIGENCE										cost; crowdsourcing; evolutionary fuzzy&#8208; based gravitational search algorithm; latency; query processing; top k&#8208; query		Crowdsourcing is an environment where a group of users collaborates together to exchange information and to find answers for complex problems (queries). Query optimization is the task of selecting the best query strategy with less cost associated with it. The crowdsourcing cost can be determined by selecting the best plan from the set of options available and the best plan considerably reduce the cost for the inquiry configuration. As one of the center tasks in information recovery, the investigation of top-k queries with crowdsourcing, to be specific group empowered top k inquiries is depicted. This issue is defined with three key variables, latency, money related expense, and nature of answers. The fundamental point is to plan a novel system that limits financial cost when the latency is compelled. In this article, we used a heuristic search algorithm named as Evolutionary Fuzzy-based Gravitational Search algorithm (EFGSA) that produces an optimal query feature selection results with minimizing cost and latency. EFGSA-based crowdsourcing framework gives a better balance between latency and cost while generating query plans. The performance analysis of proposed EFSGA for optimal query plan is evaluated in terms of running time, accuracy, monetary cost, and so on. From the experimental results, the proposed method achieved better results than other methods in our cost and latency model.																	0824-7935	1467-8640															10.1111/coin.12382		OCT 2020											
J								Integration of recurrent convolutional neural network and optimal encryption scheme for intrusion detection with secure data storage in the cloud	COMPUTATIONAL INTELLIGENCE										cloud; intrusion detection; secure data storage and elliptical curve cryptography; text document	SEMI-TENSOR PRODUCT; DETECTION SYSTEM; ALGORITHM; FRAMEWORK	Data communication security is growing day after day with the proliferation of cloud computing. It is primarily because of the few security constraints and challenges occurring in the cloud environment during data transmission. Existing research has shown that the intrusion detection system (IDS) centered on the cloud is more complicated. In this article, we address the above issues by proposing an attention-based recurrent convolutional neural network (RCNN). This proposed RCNN is used to detect whether the text data are intrusion or nonintrusion. The nonintrusion text information is then used for further processing and encrypted using a two-way encryption scheme. We introduce the elliptical curve cryptography (ECC) approach to increase the security-level performance of nonintrusion data. Moreover, the integration of ECC with the modified flower pollination algorithm (MFP-ECC) creates the two-way encryption scheme, and it is used to produce an optimal private key. The encrypted data are then stored in a cloud environment by steganography and the data with the sensitive information are replaced by some other text, thus providing security to the data at rest. The proposed MFP-ECC approach shows maximum breaking time results and can also withstand different classical attacks when compared with other methods. As a result, the proposed intrusion detection and secure data storage mechanism is highly secured and it is never affected by any kinds of conspiracy attacks.																	0824-7935	1467-8640															10.1111/coin.12408		OCT 2020											
J								Artificial intelligence in medicine and the disclosure of risks	AI & SOCIETY										Artificial intelligence; Medical disclosure; Risks; Informed consent; COVID-19	BLACK-BOX; ADVERSARIAL ATTACKS; HEALTH-CARE; BIG DATA; ANALYTICS; MANAGE; BIAS	This paper focuses on the use of 'black box' AI in medicine and asks whether the physician needs to disclose to patients that even the best AI comes with the risks of cyberattacks, systematic bias, and a particular type of mismatch between AI's implicit assumptions and an individual patient's background situation. Pace current clinical practice, I argue that, under certain circumstances, these risks do need to be disclosed. Otherwise, the physician either vitiates a patient's informed consent or violates a more general obligation to warn him about potentially harmful consequences. To support this view, I argue, first, that the already widely accepted conditions in the evaluation of risks, i.e. the 'nature' and 'likelihood' of risks, speak in favour of disclosure and, second, that principled objections against the disclosure of these risks do not withstand scrutiny. Moreover, I also explain that these risks are exacerbated by pandemics like the COVID-19 crisis, which further emphasises their significance.																	0951-5666	1435-5655															10.1007/s00146-020-01085-w		OCT 2020											
J								An emerging AI mainstream: deepening our comparisons of AI frameworks through rhetorical analysis	AI & SOCIETY										Human-centered; Abstraction; Authorship; History		Comparing frameworks for AI development allows us to see trends and reflect on how we are conceptualizing, interacting with, and imagining futures for AI. Recent scholarship comparing a range of AI frameworks has often focused methodologically on consensus, which has led to problems in evaluating potentially ambiguous values. We contribute to this scholarship using a rhetorical perspective attuned to how frameworks shape people's actions. This perspective allows us to develop the concept of an "AI mainstream" through an analysis of five of the highest-profile frameworks, including Asimov's Three Laws. We identify four features of this emerging AI mainstream shared by most/all of the frameworks: human-centered design focus, abstraction-oriented ethical reasoning, privileged authorship, and ahistorical regulatory justifications. Notably, each of these features permeates each framework, rather than being limited to a single principle. We then evaluate these shared features and offer scholarly alternatives to complement and improve them.																	0951-5666	1435-5655															10.1007/s00146-020-01073-0		OCT 2020											
J								Predicting breast cancer survivability based on machine learning and features selection algorithms: a comparative study	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										BI-RADS; Breast cancer (BC); Classification; Feature selection; Machine learning algorithms; WBC; WDBC; WPBC	GENETIC ALGORITHM; NEURAL-NETWORK; DIAGNOSIS; CLASSIFICATION; PROGNOSIS; INFORMATION; RECURRENCE; SYSTEM	Breast cancer (BC) is considered the most common cause of cancer deaths in women. This study aims to identify BC early based on machine learning algorithms and features selection methods. The overall methodology of this work was modified based on knowledge data discovery (KDD) process, which include four datasets, preprocessing phase (data cleaning, data splitting to training and testing sets), processing phase (feature selection, k-folds validation, and classification) and finally model evaluation. This paper presents a comparison between different classifiers such as decision tree (DT), random forest (RF), logistic regression (LR), Naive Bayes (NB), K-nearest neighbor (KNN), and support vector machine (SVM). Four different breast cancer datasets (Wisconsin prognosis breast cancer (WPBC), Wisconsin diagnosis breast cancer (WDBC), Wisconsin Breast Cancer (WBC), and Mammographic Mass Dataset (MM-Dataset) based on BI-RADS findings) are conducted in the experiments. The proposed models were evaluated by utilizing classification accuracy and confusion matrix. The experimental results indicate that the classification based on RF technique with the Genetic Algorithm (GA) as a feature selection method is better than the other classifiers with an accuracy value 96.82% using WBC dataset. In WDBC dataset, the results indicate that the classification utilizing C-SVM technique with the applied kernel function RBF (Radial Basis Function) is superior to the other classifiers with an accuracy value 99.04%. In WPBC dataset, the results indicate that the classification using RF technique with recursive feature elimination (RFE) as a feature selection method is better than the other classifiers with an accuracy value 74.13%. In MM-Dataset, the results indicate that the classification using DT technique is better than the other classifiers with an accuracy value 83.74%. The findings indicate that the proposed models are effective by comparing with others existing models.																	1868-5137	1868-5145															10.1007/s12652-020-02590-y		OCT 2020											
J								Ridge regression algorithm based non-invasive anaemia screening using conjunctiva images	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Artificial intelligence; Computer-aided analysis; Feature extraction; Image processing; Machine learning; Medical diagnostic imaging		Anaemia is one of the most prevalent nutritional deficiency disorders in the world that affects 1.62 billion people of all age groups. Its effects are more significant in the preschool-age children and pregnant women. The objective of this work is to develop a noninvasive method for identifying the anaemic status of a person by estimating their haemoglobin (Hb) level. Data collected from 135 participants is used for developing this model in which 80% of them (108 participants) were classified as a training group and the rest (27 participants) were grouped into a test group and their data is used for testing the model that's based on the Ridge Regression algorithm. Haemoglobin level of a person is predicted from their digital image of the lower palpebral conjunctiva and basic details like age, sex, height, weight and BMI. These predicted values are closer to the values measured by the standard invasive methods and the Pearson correlation coefficients between the measured haemoglobin value and the predicted haemoglobin value are 0.722 and 0.705 for training and testing respectively. This model is trained to perform well with any smartphone in almost any non-ideal lighting condition without the usage of any external hardware. A web application and mobile application both called 'Chromanalysis' were developed and made available to anyone for screening their anaemic condition with their conjunctiva image and other basic details. This application will help users to assess their haemoglobin levels frequently without undergoing invasive procedures.																	1868-5137	1868-5145															10.1007/s12652-020-02618-3		OCT 2020											
J								Accurate detection of myocardial infarction using non linear features with ECG signals	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Myocardial infarction; Computer aided diagnostic system; Electrocardiogram; Pan Thompkins algorithm; Classifiers	COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL NEURAL-NETWORK; CORONARY-ARTERY-DISEASE; AUTOMATED DETECTION; APPROXIMATE ENTROPY; CLASSIFICATION; DECOMPOSITION; QUANTIFICATION; IDENTIFICATION; LOCALIZATION	Interrupted blood flow to regions of the heart causes damage to heart muscles, resulting in myocardial infarction (MI). MI is a major source of death worldwide. Accurate and timely detection of MI facilitates initiation of emergency revascularization in acute MI and early secondary prevention therapy in established MI. In both acute and ambulatory settings, the electrocardiogram (ECG) is a standard data type for diagnosis. ECG abnormalities associated with MI can be subtle, and may escape detection upon clinical reading. Experience and training are required to visually extract salient information present in the ECG signals. This process of characterization is manually intensive, and prone to intra-and inter-observer-variability. The clinical problem can be posed as one of diagnostic classification of MI versus no MI on the ECG, which is amenable to computational solutions. Computer Aided Diagnosis (CAD) systems are designed to be automated, rapid, efficient, and ultimately cost-effective systems that can be employed to detect ECG abnormalities associated with MI. In this work, ECGs from 200 subjects were analyzed (52 normal and 148 MI). The proposed methodology involves pre-processing of signals and subsequent detection of R peaks using the Pan-Tompkins algorithm. Nonlinear features were extracted. The extracted features were ranked based on Student's t-test and input to k-Nearest Neighbor (KNN), Support Vector Machine (SVM), Probabilistic Neural Network (PNN), and Decision Tree (DT) classifiers for distinguishing normal versus MI classes. This method yielded the highest accuracy 97.96%, sensitivity 98.89%, and specificity 93.80% using the SVM classifier.																	1868-5137	1868-5145															10.1007/s12652-020-02536-4		OCT 2020											
J								Ensemble learning based on random super-reduct and resampling	ARTIFICIAL INTELLIGENCE REVIEW										Ensemble learning; Rough sets; Random super-reduct; Approximate decision entropy; Resampling; Multi-modal perturbation	NEURAL-NETWORK ENSEMBLES; CLASSIFIER ENSEMBLES; KNOWLEDGE GRANULATION; FEATURE-SELECTION; ROTATION FOREST; DECISION TREES; ROUGH ENTROPY; DIVERSITY; UNCERTAINTY	Ensemble learning has been widely used for improving the performance of base classifiers. Diversity among base classifiers is considered as a key issue in ensemble learning. Recently, to promote the diversity of base classifiers, ensemble methods through multimodal perturbation have been proposed. These methods simultaneously use two or more perturbation techniques when generating base classifiers. In this paper, from the perspective of multi-modal perturbation, we propose an ensemble approach (called 'E_RSRR') based on random super-reduct and resampling. To generate a set of accurate and diverse base classifiers, E_RSRR adopts a new multi-modal perturbation strategy. This strategy combines two perturbation techniques together, that is, resampling and random super-reduct. First, it perturbs the sample space via the resampling technique; Second, it perturbs the feature space via the random super-reduct technique, which is a combination of RSS (random subspace selection) technique and ADEFS (approximate decision entropy-based feature selection) method in rough sets. Experimental results show that E_RSRR can provide competitive solutions for ensemble learning.																	0269-2821	1573-7462															10.1007/s10462-020-09922-6		OCT 2020											
J								Wrapper scan chain design algorithm for testing of embedded cores based on chaotic dragonfly algorithm	EVOLUTIONARY INTELLIGENCE										SoC testing; Wrapper scan chain design; Chaotic map; Dragonfly algorithm	PARTICLE SWARM OPTIMIZATION; NETWORK; CHIP	As embedded pre-designed and pre-validated cores in system-on-chip (SoC) designs have increased usage, the wrapper scan chain design (WSCD) for the embedded cores is one of the fundamental ways to reduce the SoC test time. In this paper, a chaotic dragonfly algorithm (CDA) for WSCD is proposed to minimize the test time of embedded cores by balancing the packaged scan chains (WSCs).Since the WSCD problem is non-continuous, we improve the dragonfly algorithm (DA) with integer coding to make it suitable for the WSCD problem. In order to improve population diversity and prevent falling into local optimum state, we introduce chaotic strategy into DA. Furthermore, a repaired operator that considers the specific knowledge is added to the DA. Since the CDA is a swarm intelligence method, it is expected to effectively solve the NP-hard problem. The experimental results on ITC'02 SoC benchmark show that the proposed algorithm can improve the balanced results and shorten the test time compared with the existing algorithms.																	1864-5909	1864-5917															10.1007/s12065-020-00513-6		OCT 2020											
J								Progressive Multi-granularity Analysis for Video Prediction	INTERNATIONAL JOURNAL OF COMPUTER VISION										Video prediction; Multiple granularity analysis		Video prediction is challenging as real-world motion dynamics are usually multi-modally distributed. Existing stochastic methods commonly formulate random noise input with simple prior distribution, which is insufficient to model highly complex motion dynamics. This work proposes a progressive multiple granularity analysis framework to tackle the above difficulty. Firstly, to achieve coarse alignment, the input sequence is matched to prototype motion dynamics in the training set, based on self-supervised auto-encoder learning via motion/appearance disentanglement. Secondly, motion dynamics is transferred from the matched prototype sequence to input sequence via adaptively learned kernel, and the predicted frames are further refined through a motion-aware prediction model. Extensive qualitative and quantitative experiments on three widely used video prediction datasets demonstrate that: (1) the proposed framework essentially decomposes the hard task into a series of more approachable sub-tasks where a better solution is easier to be sought and (2) our proposed method performs favorably against state-of-the-art prediction methods.																	0920-5691	1573-1405															10.1007/s11263-020-01389-w		OCT 2020											
J								Intelligent automation of dental material analysis using robotic arm with Jerk optimized trajectory	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Smart dental laboratory; Total laboratory automation; Motion planning; Pareto optimization; Industrial robotics	BOND STRENGTH; MOBILE ROBOTS; SYSTEM; ALGORITHM; DESIGN; FIND	Many types of biomaterial analysis require numerous repetition of the same operations. We suggest applying the principles of Total Laboratory Automation (TLA) for analysis of dental tissues in in-vitro conditions. We propose an innovative robotic platform with ABB high precision industrial robotic arm. We programmed the robot to achieve 3000 cycles of submerging for analysis of the stability and thermal wear of dental adhesive materials. We address the problem of robot trajectory planning to achieve smooth and precise trajectory while minimizing jerk. We generate different variants of trajectory using natural cubic splines and adopt the NSGA II multiobjective evolutionary algorithm to find a Pareto-optimal set of robot arm trajectories. The results demonstrate the applicability of the developed robotic platform for in-vitro experiments with dental materials. The platform is suitable for small or medium size dental laboratories.																	1868-5137	1868-5145															10.1007/s12652-020-02605-8		OCT 2020											
J								Prescribed performance fuzzy back-stepping control of a flexible air-breathing hypersonic vehicle subject to input constraints	JOURNAL OF INTELLIGENT MANUFACTURING										Flexible air-breathing hypersonic vehicle; Adaptive fuzzy control; Input constraints; Prescribed performance	NONLINEAR-SYSTEMS; ADAPTIVE-CONTROL; TRACKING CONTROL; AIRCRAFT; DESIGN	The design of prescribed performance fuzzy back-stepping tracking control for a flexible air-breathing hypersonic vehicle (FAHV) with actuator constraints is discussed. Fuzzy logic systems (FLSs) are applied to approximate the lumped uncertainty of each subsystem of the FAHV model. Every FLS contains only one adaptive parameter that needs to be updated online with a minimal-learning-parameter scheme. The sliding mode differentiator is introduced to obtain the derivatives of the virtual control laws, which avoid the explosion of the differentiation term in traditional back-stepping control. To further improve the control performance, a prescribed performance function characterizing the error convergence rate, maximum overshoot and steady-state error is utilized for the output error transformation. In particular, novel auxiliary systems are explored to handle input saturation. Fuzzy backstep control has obvious advantages in system robustness, control accuracy and highly real-time. Finally, reference trajectory tracking simulations show the effectiveness of the proposed method regarding air-breathing hypersonic vehicle control applications.																	0956-5515	1572-8145															10.1007/s10845-020-01656-0		OCT 2020											
J								A weighted fuzzy C-means clustering method with density peak for anomaly detection in IoT-enabled manufacturing process	JOURNAL OF INTELLIGENT MANUFACTURING										Anomaly detection; Internet of Things; Weighted fuzzy C-means; Clustering; Feature reduction	FAULT-DETECTION; FAST SEARCH; MANAGEMENT; SYSTEM; FIND	Accurate anomaly detection is the premise of production process control and normal execution of production plan. The implementation of Internet of Things (IoT) provides data foundation and guarantee for real-time perception and detection of production state. Taking abundant IoT data as support, a density peak (DP)-weighted fuzzy C-means (WFCM) based clustering method is proposed to detect abnormal situations in production process. Firstly, a features correlation and redundancy measure method based on mutual information (MI) and conditional MI is proposed, unsupervised feature reduction is completed based on the principle of maximum correlation-minimum redundancy. Secondly, a DP-WFCM based clustering model is established to identify clusters with fewer samples to detect production anomalies. DP is used to obtain the initial clustering centers to solve the problem that FCM is sensitive to the initial centers and the clusters number needs to be determined manually in advance. MI-based similarities are introduced as weight coefficients to guide the clustering process, which improves convergence speed and clustering quality. Finally, a real case from an IoT enabled machining workshop is carried out to verify the accuracy and effectiveness of the proposed method in anomaly detection of manufacturing process.																	0956-5515	1572-8145															10.1007/s10845-020-01690-y		OCT 2020											
J								Forecasting Monthly Tourism Demand Using Enhanced Backpropagation Neural Network	NEURAL PROCESSING LETTERS										Tourism demand; Time series forecasting; Backpropagation neural network; Improved chaotic particle swarm optimization	PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION ALGORITHM; SUPPORT VECTOR REGRESSION; TIME-SERIES; FOREIGN TOURIST; ARRIVALS; MODELS	The accurate forecasting of monthly tourism demand can improve tourism policies and planning. However, the complex nonlinear characteristics of monthly tourism demand complicate forecasting. This study proposes a novel approach named ICPSO-BPNN that combines improved chaotic particle swarm optimization (ICPSO) with backpropagation neural network (BPNN) to forecast monthly tourism demand. ICPSO with chaotic initialization and two search strategies, sigmoid-like inertia weight, and linear acceleration coefficients is utilized to search for the appropriate initial connection weights and thresholds necessary to improve the performance of BPNN. Two comparative real-life examples and one extended example are adopted to verify the superiority of the proposed ICPSO-BPNN. Results show ICPSO-BPNN outperforms that of the basic BPNN, autoregressive integrated moving average model, support vector regression, and other popular existing models.																	1370-4621	1573-773X															10.1007/s11063-020-10363-z		OCT 2020											
J								Learning to rank by using multivariate adaptive regression splines and conic multivariate adaptive regression splines	COMPUTATIONAL INTELLIGENCE										artificial neural networks; conic multivariate adaptive regression splines; multivariate adaptive regression spline; random forest; support vector machines; web search query	CMARS	Learning to rankis a supervised learning problem that aims to construct a ranking model for the given data. The most common application of learning to rank is to rank a set of documents against a query. In this work, we focus onpoint-wise learning to rank, where the model learns the ranking values. Multivariate adaptive regression splines (MARS) and conic multivariate adaptive regression splines (CMARS) are supervised learning techniques that have been proven to provide successful results on various prediction problems. In this article, we investigate the effectiveness of MARS and CMARS for point-wise learning to rank problem. The prediction performance is analyzed in comparison to three well-known supervised learning methods, artificial neural network (ANN), support vector machine, and random forest for two datasets under a variety of metrics including accuracy, stability, and robustness. The experimental results show that MARS and ANN are effective methods for learning to rank problem and provide promising results.																	0824-7935	1467-8640															10.1111/coin.12413		OCT 2020											
J								Z-uncertain probabilistic linguistic variables and its application in emergency decision making for treatment of COVID-19 patients	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										aggregation operators; COVID-19; emergency decision making; TOPSIS; Z-uncertain probabilistic linguistic variable	TERM SETS; AGGREGATION OPERATORS; INTERACTIVE PROCEDURE; DISTANCE OPERATOR; MODEL; INFORMATION; CONSENSUS	Probabilistic linguistic term sets (PLTSs) have many applications in the field of group decision making (GDM) because it includes both linguistic evaluation and probabilistic distribution when expressing preference information. However, the difference of information credibility in PLTSs is ignored, resulting in an inaccurate representation of decision information and unreasonable probability calculation. In this paper, we first consider the credibility of the information and propose the concept ofZ-uncertain probabilistic linguistic variables (Z-UPLVs). Subsequently, the operational rules, normalization, distance and similarity measures, and comparison method ofZ-UPLVs are introduced. Then, a probability calculation method based on credibility, an extended TOPSIS method, and some operators are proposed, which can be applied to emergency decision making in theZ-uncertain probabilistic linguistic (Z-UPL) environment. Finally, an emergency decision-making case of COVID-19 patients and comparative analysis illustrate the necessity and effectiveness of this method.																	0884-8173	1098-111X															10.1002/int.22303		OCT 2020											
J								Land-use dynamic discovery based on heterogeneous mobility sources	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										land labelling; online social networks; supervised learning; urban computing; urban mobility		Nowadays, cities are the most relevant type of human settlement and their population has been endlessly growing for decades. At the same time, we are witnessing an explosion of digital data that capture many different aspects and details of city life. This allows detecting human mobility patterns in urban areas with more detail than ever before. In this context, based on the fusion of mobility data from different and heterogeneous sources, such as public transport, transport-network connectivity and Online Social Networks, this study puts forward a novel approach to uncover the actual land use of a city. Unlike previous solutions, our work avoids atime-invariantapproach and it considers the temporal factor based on the assumption that urban areas are not used by citizens all the time in the same manner. We have tested our solution in two different cities showing high accuracy rates.																	0884-8173	1098-111X															10.1002/int.22307		OCT 2020											
J								Detecting voids in 3D printing using melt pool time series data	JOURNAL OF INTELLIGENT MANUFACTURING										Process monitoring; Classification; Time-series	POWDER	Powder Bed Fusion (PBF) has emerged as an important process in the additive manufacture of metals. However, PBF is sensitive to process parameters and careful management is required to ensure the high quality of parts produced. In PBF, a laser or electron beam is used to fuse powder to the part. It is recognised that the temperature of the melt pool is an important signal representing the health of the process. In this paper, Machine Learning (ML) methods on time-series data are used to monitor melt pool temperature to detect anomalies. In line with other ML research on time-series classification, Dynamic Time Warping andk-Nearest Neighbour classifiers are used. The presented process is effective in detecting voids in PBF. A strategy is then proposed to speed up classification time, an important consideration given the volume of data involved.																	0956-5515	1572-8145															10.1007/s10845-020-01694-8		OCT 2020											
J								Feature selection based bee swarm meta-heuristic approach for combinatorial optimisation problems: a case-study on MaxSAT	MEMETIC COMPUTING										Hybrid meta-heuristic; A priori knowledge; Feature selection; Size reduction; MaxSAT; Bee swarm optimisation		Background Meta-heuristics are high-level methods widely used in different fields of applications. To enhance their performance, they are often combined to concepts borrowed from machine learning and statistics in order to improve the quality of solutions and/or reduce the response time. Aim In this paper, we investigate the use of feature selection to speed-up the search process of Bee Swarm Optimisation (BSO) meta-heuristic in solving the MaxSAT problem.The general idea is to extract a subset of the most relevant features that describe an instance of a problem in order to reduce its size. Proposed approach We propose to translate a MaxSAT instance into a dataset following one of several representations proposed in this study, and then apply a FS technique to select the most relevant variables or clauses. Two data organizations are proposed depending on whether we want to remove variables or clauses. In addition, two data encodings can be used: binary encoding if we are only interested by the presence or not of a variable in a clause, and ternary encoding if we consider the information that it appears as a positive or negative literal. Moreover, we experiment two feature evaluation approaches: subset evaluation approach which returns the optimal subset, and individual evaluation which ranks the features and lets the user choose the number of features to remove. All possible combinations of data organization, data encoding and features evaluation approach lead to eight (08) variants of the hybrid algorithm, named FS-BSO. Results BSO and all the variants of FS-BSO have been applied to several instances of different benchmarks. The analysis of experimental results showed that in terms of solution quality, BSO gives the best results. However, FS-BSO algorithms achieve very good results and are statistically equivalent to BSO for some instances. In terms of execution time, all hybrid variants of FS-BSO are faster. In addition, results showed that removing clauses is slightly more advantageous in terms of solution quality whereas removing variables gives better execution times. Concerning data encoding, the results did not show any difference between the binary and ternary encodings. Conclusion In this paper, we investigated the possibility to speed-up BSO meta-heuristic in solving an instance of the MaxSAT problem by extracting a priori knowledge. Feature selection has been used as a preprocessing technique in order to reduce the instance size by selecting a subset of the most relevant vaiables/clauses. Results showed that there is a strong link between the reduction rate and solution quality, and that FS-BSO offers a better quality-time trade off.																	1865-9284	1865-9292															10.1007/s12293-020-00310-9		OCT 2020											
J								Soft computing-based edge-enhanced dominant peak and discrete Tchebichef extraction for image segmentation and classification using DCML-IC	SOFT COMPUTING										Soft computing; Magnetic resonance imaging; Computed tomography; Adaptive anisotropic diffusion; Histogram dominant peak valley; Discrete Tchebichef moment	GENE	Texture analysis is a very predominant scope in the area of computer vision and associated fields. In this work, edge-enhanced dominant valley and discrete Tchebichef (EDV-DT) method is presented to eradicate noise and segment image into number of partitions with higher accuracy and lesser time. In EDV-DT method, an edge-enhancing anisotropic diffusion filtering technique is used to perform the preprocessing for MRI, CT and texture features. The adaptive anisotropic diffusion creates scale space and reduces the image noise without removing the texture image content (i.e., edges, lines) that is found to be essential for texture image segmentation. Followed by preprocessing, histogram dominant peak valley segmentation technique is applied to segment the localization of region of interest. Valleys in histogram for the preprocessed images help in segmenting the texture image into equal-sized texture regions. Finally, with the segmented images, discrete Tchebichef moment feature extraction is applied to extract relevant features from the segmented texture image for reducing the dimensionality. This in turn helps in improving the feature extraction rate. Further a deep convolution multinomial logarithmic-based image classification (DCML-IC) model is presented for predicting results via positive and negative fact classification. The proposed system provides the better prediction of accuracy and the prediction of time to compare the other existing methods.																	1432-7643	1433-7479															10.1007/s00500-020-05306-8		OCT 2020											
J								Scalable network estimation with L-0 penalty	STATISTICAL ANALYSIS AND DATA MINING										L-0 penalty; genomics; network; scalable	INVERSE COVARIANCE ESTIMATION; VARIABLE SELECTION; SPARSE; LASSO; REGRESSION; APOPTOSIS; BLU	With the advent of high-throughput sequencing, an efficient computing strategy is required to deal with large genomic data sets. The challenge of estimating a large precision matrix has garnered substantial research attention for its direct application to discriminant analyses and graphical models. Most existing methods either use a lasso-type penalty that may lead to biased estimators or are computationally intensive, which prevents their applications to very large graphs. We propose using an L-0 penalty to estimate an ultra-large precision matrix (scalnetL0). We apply scalnetL0 to RNA-seq data from breast cancer patients represented in The Cancer Genome Atlas and find improved accuracy of classifications for survival times. The estimated precision matrix provides information about a large-scale co-expression network in breast cancer. Simulation studies demonstrate that scalnetL0 provides more accurate and efficient estimators, yielding shorter CPU time and less Frobenius loss on sparse learning for large-scale precision matrix estimation.																	1932-1864	1932-1872															10.1002/sam.11483		OCT 2020											
J								Transfer discriminative dictionary learning with label consistency for classification of EEG signals of epilepsy	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Dictionary learning; Transfer learning; Label consistency; EEG signal classification; Epilepsy		EEG signal classification play an important role in recognition of epilepsy. Recently, dictionary learning algorithms have shown the effectiveness in this field. When designing dictionaries, due to highly non-stationary of EEG signals, and collecting signals existing in different stimulus and drug modes, training and testing scenarios may be different. Thus, the performance of classical dictionary learning algorithms is unsatisfactory. In this paper, a transfer discriminative dictionary learning with label consistency (called TDDLLC) algorithm is proposed for EEG signal classification. Since each EEG signal can be represented as a linear combination of dictionary atoms, and some atoms are dataset independent, two dictionaries are learned simultaneously in source domain (SD) and target domain (TD) respectively where the discrepancy between two dictionaries is minimized. Meanwhile, utilizing the label information of samples in SD and a small number of labeled samples in TD, these dictionaries are learned with the aim of achieving discriminative abilities. To avoid the NP-hard problem, l(1)-norm regularization term is used in TDDLLC, and objective function is solved by block-coordinate descent method. Extensive experiments have been performed on Bonn dataset and show the validity of the TDDLLC algorithm.																	1868-5137	1868-5145															10.1007/s12652-020-02620-9		OCT 2020											
J								Task scheduling optimization strategy using improved ant colony optimization algorithm in cloud computing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cloud computing; Task scheduling optimization; Improved ant colony algorithm; Load balancing; Penalty coefficient; Cloudsim	PARTICLE SWARM OPTIMIZATION	In order to solve the problems of unbalanced load, slow convergence speed and low utilization of virtual machine resources existing in the previous task scheduling optimization strategies, this paper proposes a task scheduling optimization strategy using improved ant colony optimization algorithm in cloud computing. Firstly, based on the principle of cloud computing task scheduling, a scheduling model using improved ant colony algorithm is proposed to avoid the optimization strategy falling into local optimization. Then, task scheduling satisfaction function is constructed by combining the three objectives of the shortest waiting time, the degree of resource load balance and the cost of task completion to search the optimal solution of task scheduling. Finally, the reward and punishment coefficient is introduced to optimize the pheromone updating rules of ant colony algorithm, which speeds up the solution speed. Besides, we use dynamic update of volatility coefficient to optimize overall performance of this strategy, and introduce virtual machine load weight coefficient in the process of local pheromone updating, so as to ensure the load balance of virtual machine. The feasibility of our algorithm is analyzed and demonstrated by experiments with Cloudsim. The experimental results show that the proposed algorithm has the fastest convergence speed, the shortest completion time, the most balanced load and the highest utilization rate of virtual machine resources compared with other methods. Therefore, our proposed task scheduling optimization strategy has the best performance.																	1868-5137	1868-5145															10.1007/s12652-020-02614-7		OCT 2020											
J								A Decidable Class of Security Protocols for Both Reachability and Equivalence Properties	JOURNAL OF AUTOMATED REASONING										Security protocols; Verification; Privacy properties	TOOL	We identify a new decidable class of security protocols, both for reachability and equivalence properties. Our result holds for an unbounded number of sessions and for protocols with nonces. It covers all standard cryptographic primitives. Our class sets up three main assumptions. (i) Protocols need to be "simple", meaning that an attacker can precisely identify from which participant and which session a message originates from. We also consider protocols with no else branches (only positive test). (ii) Protocols should be type-compliant, which is intuitively guaranteed as soon as two encrypted messages of the protocol cannot be confused. (iii) Finally, we define the notion of a dependency graph, which, given a protocol, characterises how actions depend on the other ones (both sequential dependencies and data dependencies are taken into account). Whenever the graph is acyclic, then the protocol falls into our class. We show that many protocols of the literature belong to our decidable class, including for example some of the protocols embedded in the biometric passport.																	0168-7433	1573-0670															10.1007/s10817-020-09582-9		OCT 2020											
J								The Multiplicative-Additive Lambek Calculus with Subexponential and Bracket Modalities	JOURNAL OF LOGIC LANGUAGE AND INFORMATION										Lambek calculus; Categorial grammars; Subexponential modalities; Bracket modalities; Undecidability; cut elimination	DECISION-PROBLEMS; ONE DIVISION; GRAMMARS; POWER	We give a proof-theoretic and algorithmic complexity analysis for systems introduced by Morrill to serve as the core of the CatLog categorial grammar parser. We consider two recent versions of Morrill's calculi, and focus on their fragments including multiplicative (Lambek) connectives, additive conjunction and disjunction, brackets and bracket modalities, and the ! subexponential modality. For both systems, we resolve issues connected with the cut rule and provide necessary modifications, after which we prove admissibility of cut (cut elimination theorem). We also prove algorithmic undecidability for both calculi, and show that categorial grammars based on them can generate arbitrary recursively enumerable languages.																	0925-8531	1572-9583															10.1007/s10849-020-09320-9		OCT 2020											
J								Improved coral reefs optimization with adaptive beta-hill climbing for feature selection	NEURAL COMPUTING & APPLICATIONS										Meta-heuristic; Feature selection; UCI; Coral reefs optimization; Adaptive beta-hill climbing; Hybrid optimization	GENETIC ALGORITHM	For any classification problem, the dimension of the feature vector used for classification has great importance. This is because, in a high-dimensional feature vector, it is found that some are non-informative or even redundant as they do not contribute to the learning process of the classifier. Rather, they may be the reason for low classification accuracy and high training time of the learning model. To address this issue, researchers apply various feature selection (FS) methods as found in the literature. In recent years, meta-heuristic algorithms have been proven to be effective in solving FS problems. The Coral Reefs Optimizer (CRO) which is a cellular type evolutionary algorithms has good tuning between its exploration and exploitation ability. This has motivated us to present an improved version of CRO with the inclusion of adaptive beta-hill climbing to increase the exploitation ability of CRO. The proposed method is assessed on 18 standard UCI-datasets by means of three distinct classifiers, KNN, Random Forest and Naive Bayes classifiers. It is also analyzed with 10 state-of-the-art meta-heuristics FS procedure, and the outputs show an excellent performance of the proposed FS method reaching better results than the previous methods considered here for comparison. The source code of this work is publicly available at https://github.com/ahmed-shameem/Projects.																	0941-0643	1433-3058															10.1007/s00521-020-05409-1		OCT 2020											
J								Random-based networks with dropout for embedded systems	NEURAL COMPUTING & APPLICATIONS										Internet of Things; Random-based neural networks; Embedded systems	EXTREME LEARNING-MACHINE; ENSEMBLE; IMPLEMENTATION; OPTIMIZATION; EFFICIENT; DESIGN	Random-based learning paradigms exhibit efficient training algorithms and remarkable generalization performances. However, the computational cost of the training procedure scales with the cube of the number of hidden neurons. The paper presents a novel training procedure for random-based neural networks, which combines ensemble techniques and dropout regularization. This limits the computational complexity of the training phase without affecting classification performance significantly; the method best fits Internet of Things (IoT) applications. In the training algorithm, one first generates a pool of random neurons; then, an ensemble of independent sub-networks (each including a fraction of the original pool) is trained; finally, the sub-networks are integrated into one classifier. The experimental validation compared the proposed approach with state-of-the-art solutions, by taking into account both generalization performance and computational complexity. To verify the effectiveness in IoT applications, the training procedures were deployed on a pair of commercially available embedded devices. The results showed that the proposed approach overall improved accuracy, with a minor degradation in performance in a few cases. When considering embedded implementations as compared with conventional architectures, the speedup of the proposed method scored up to 20x in IoT devices.																	0941-0643	1433-3058															10.1007/s00521-020-05414-4		OCT 2020											
J								In-depth analysis of SVM kernel learning and its components	NEURAL COMPUTING & APPLICATIONS										SVM; Kernel learning; Genetic programming; Automatic machine learning	SUPPORT VECTOR MACHINES	The performance of support vector machines in nonlinearly separable classification problems strongly relies on the kernel function. Toward an automatic machine learning approach for this technique, many research outputs have been produced dealing with the challenge of automatic learning of good-performing kernels for support vector machines. However, these works have been carried out without a thorough analysis of the set of components that influence the behavior of support vector machines and their interaction with the kernel. These components are related in an intricate way and it is difficult to provide a comprehensible analysis of their joint effect. In this paper, we try to fill this gap introducing the necessary steps in order to understand these interactions and provide clues for the research community to know where to place the emphasis. First of all, we identify all the factors that affect the final performance of support vector machines in relation to the elicitation of kernels. Next, we analyze the factors independently or in pairs and study the influence each component has on the final classification performance, providing recommendations and insights into the kernel setting for support vector machines.																	0941-0643	1433-3058															10.1007/s00521-020-05419-z		OCT 2020											
J								A convolutional oculomotor representation to model parkinsonian fixational patterns from magnified videos	PATTERN ANALYSIS AND APPLICATIONS										Parkinson&#8217; s disease; Ocular fixation; Oculomotor patterns; Motion magnification; CNN features	OCULAR TREMOR; DISEASE PROGRESSION; TASK-FORCE; DIAGNOSIS	Oculomotor alterations are a promising biomarker to detect and characterize Parkinson's disease (PD), even in prodromal stages. Nowadays, however, only global and simplified gaze trajectories are used to approximate the complex interactions between neuromotor commands and ocular muscles. Besides, the acquisition of such signals often requires sophisticated calibration and invasive settings. This work presents a novel imaging biomarker for PD assessment that models ocular fixational movements, recorded with conventional cameras. Firstly, a video acceleration magnification is performed to enhance small relevant fixation patterns on standard gaze video recordings. Hence, from each video are extracted a set of spatio-temporal slices, which thereafter are represented as convolutional feature maps, recovered as the first-layer responses of pre-trained CNN architectures. The feature maps are then efficiently encoded by means of covariance matrices to train a support vector machine and perform the disease classification. From a set of 130 recordings of 13 PD patients and 13 age-matched controls, the proposed approach achieved an average accuracy of 95.4% and an AUC of 0.984, following a leave-one-patient-out cross-validation scheme. The proposed imaging-based descriptor properly captures known disease tremor patterns, since PD classification performance is outstanding when augmented motion frequencies were fixed within tremor-related ranges. These results suggest a successful PD characterization from fixational eye motion patterns using ordinary videos.																	1433-7541	1433-755X															10.1007/s10044-020-00922-4		OCT 2020											
J								Imitation Game: Threshold or Watershed?	MINDS AND MACHINES										Turing test; Artificial intelligence; Philosophy of mind; Linguistics	LOGIC	Showing remarkable insight into the relationship between language and thought, Alan Turing in 1950 proposed the Imitation Game as a proxy for the question "Can machines think?" and its meaning and practicality have been debated hotly ever since. The Imitation Game has come under criticism within the Computer Science and Artificial Intelligence communities with leading scientists proposing alternatives, revisions, or even that the Game be abandoned entirely. Yet Turing's imagined conversational fragments between human and machine are rich with complex instances of inference of implied information, reasoning from generalizations, and meta-reasoning, challenges AI practitioners have wrestled with since at least 1980 and continue to study. We argue that the very fact the Imitation Game is so difficult may be the very reason it shouldn't be changed or abandoned. The semi-decidability of the game at this point hints at the possibility of a hard limit to the powers of technology.																	0924-6495	1572-8641															10.1007/s11023-020-09544-5		OCT 2020											
J								Local-CycleGAN: a general end-to-end network for visual enhancement in complex deep-water environment	APPLIED INTELLIGENCE										Local auxiliary discriminator; Quality-monitor loss function; Cycle-consistency generative adversarial network; Image enhancement; Turbid deep-water environment		Underwater image analysis is crucial for many applications such as seafloor survey, biological and environment monitoring, underwater vehicle navigation, inspection and maintenance of underwater infrastructure etc. However, due to light absorption and scattering, the images acquired underwater are always blurry and distorted in color. Most existing image enhancement algorithms typically focus on a few features of the imaging environments, and enhanced results depend on the characteristics of original images. In this study, a local cycle-consistent generative adversarial network is proposed to enhance images acquired in a complex deep-water environment. The proposed network uses a combination of a local discriminator and a global discriminator. Additionally, quality-monitor loss is adopted to evaluate the effect of the generated images. Experimental results show that the local cycle-consistent generative adversarial network is robust and can be generalized for many different image enhancement tasks in different types of complex deep-water environment with varied turbidity.																	0924-669X	1573-7497															10.1007/s10489-020-01931-w		OCT 2020											
J								Study on Statistical Outlier Detection and Labelling	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Outlier detection; control loop quality; statistical analysis; robust estimation; heavy tails	ROBUST; REJECTION; CRITERION	Outliers accompany control engineers in their real life activity. Industrial reality is much richer than elementary linear, quadratic, Gaussian assumptions. Outliers appear due to various and varying, often unknown, reasons. They meet research interest in statistical and regression analysis and in data mining. There are a lot of interesting algorithms and approaches to outlier detection, labelling, filtering and finally interpretation. Unfortunately, their impact on control systems has not been found sufficient attention in research. Their influence is frequently unnoticed, ignored or not mentioned. This work focuses on the subject of outlier detection and labelling in the context of control system performance analysis. Selected statistical data-driven approaches are analyzed, as they can be easily implemented with limited a priori knowledge. The study consists of a simulation study followed by the analysis of real control data. Different generation mechanisms are simulated, like overlapping Gaussian processes, symmetric and asymmetric, artificially shifted points and fat-tailed distributions. Simulation observations are confronted with industrial control loops datasets. The work concludes with a practical procedure, which should help practitioners in dealing with outliers in control engineering temporal data.																	1476-8186	1751-8520															10.1007/s11633-020-1243-2		OCT 2020											
J								Saliency Detection via Manifold Ranking Based on Robust Foreground	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Saliency detection; manifold ranking; boundary connectivity; convex hull; robust foreground	VISUAL SALIENCY; TOP-DOWN	The graph-based manifold ranking saliency detection only relies on the boundary background to extract foreground seeds, resulting in a poor saliency detection result, so a method that obtains robust foreground for manifold ranking is proposed in this paper. First, boundary connectivity is used to select the boundary background for manifold ranking to get a preliminary saliency map, and a foreground region is acquired by a binary segmentation of the map. Second, the feature points of the original image and the filtered image are obtained by using color boosting Harris corners to generate two different convex hulls. Calculating the intersection of these two convex hulls, a final convex hull is found. Finally, the foreground region and the final convex hull are combined to extract robust foreground seeds for manifold ranking and getting final saliency map. Experimental results on two public image datasets show that the proposed method gains improved performance compared with some other classic methods in three evaluation indicators: precision-recall curve, F-measure and mean absolute error.																	1476-8186	1751-8520															10.1007/s11633-020-1246-z		OCT 2020											
J								A Position Synchronization Controller for Co-ordinated Links (COOL) Dual Robot Arm Based on Integral Sliding Mode: Design and Experimental Validation	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Integral sliding mode control; position synchronization; dual-arm robotic manipulator; chattering; robust control	MULTIPLE MOTION AXES; UNCERTAIN KINEMATICS; SYSTEMS; MANIPULATORS; TRACKING	In this study, a simple position synchronization control algorithm based on an integral sliding mode is developed for dual-arm robotic manipulator systems. A first-order sliding surface is designed using cross-coupling error in order to ensure position synchronization of dual-arm manipulators. The design objective of the proposed controller is to ensure stability as well as to synchronize the movement of both arms while maintaining the trajectory as desired. The integral sliding mode eliminates the reaching phase and guarantees robustness throughout the whole operating period. Additionally, a low pass filter is used to smoothen the discontinuous element and minimize unwanted chattering. Lyapunov stability theory is utilized to prove the asymptotic stability of the controlled system. Simulation studies are performed to validate the proposed controller's effectiveness. Also, to investigate the possibility of realizing the proposed dynamic control method in practical applications, experiments are conducted on a 14DoF coordinated links (COOL) dual-arm robotic manipulator system. Experimental evidence indicates adequate efficiency in trajectory tracking and guarantees robustness in the presence of parametric uncertainty and external disturbance.																	1476-8186	1751-8520															10.1007/s11633-020-1242-3		OCT 2020											
J								The emergence of explainability of intelligent systems: Delivering explainable and personalized recommendations for energy efficiency	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										energy efficiency; explainable recommendation system; Internet of things; recommendation systems; rule-based recommendation; user habits		The recent advances in artificial intelligence namely in machine learning and deep learning, have boosted the performance of intelligent systems in several ways. This gave rise to human expectations, but also created the need for a deeper understanding of how intelligent systems think and decide. The concept of explainability appeared, in the extent of explaining the internal system mechanics in human terms. Recommendation systems are intelligent systems that support human decision making, and as such, they have to be explainable to increase user trust and improve the acceptance of recommendations. In this study, we focus on a context-aware recommendation system for energy efficiency and develop a mechanism for explainable and persuasive recommendations, which are personalized to user preferences and habits. The persuasive facts either emphasize on the economical saving prospects (Econ) or on a positive ecological impact (Eco) and explanations provide the reason for recommending an energy saving action. Based on a study conducted using a Telegram bot, different scenarios have been validated with actual data and human feedback. Current results show a total increase of 19% on the recommendation acceptance ratio when both economical and ecological persuasive facts are employed. This revolutionary approach on recommendation systems, demonstrates how intelligent recommendations can effectively encourage energy saving behavior.																	0884-8173	1098-111X															10.1002/int.22314		OCT 2020											
J								A learning-based resource provisioning approach in the fog computing environment	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE										Resource Provisioning; iot Applications; fog Computing; neural Network; hidden Markov Model	NEURAL-NETWORKS; EDGE; INTERNET; THINGS; SIMULATION; TOOLKIT; MODELS	With the recent advancements in distributed computing technologies, the fog computing model has emerged to provide resource capabilities at the edge of the network for executing IoT applications. However, due to the rapid growth of IoT applications and variability their workload over time, achieving an efficient resource provisioning solution to deal with time-varying workloads as one of the challenging tasks in resource management scope to be considered. In this work, we propose a learning-based resource provisioning approach for managing time-varying workloads of IoT applications in the fog network. Our proposed approach utilises the nonlinear autoregressive (NAR) neural network as prediction method and hidden Markov model (HMM) as a decision-maker to identify scaling decisions to provision the fog resources for serving of workloads of IoT applications. The effectiveness of our proposed solution is evaluated using extension experiments under real-world datasets, and the obtained results from iFogSim toolkit demonstrated that it yields a reduction of the delay and cost and improves resource energy consumption compared with existing baseline mechanisms.																	0952-813X	1362-3079															10.1080/0952813X.2020.1818294		OCT 2020											
J								Learning credible DNNs via incorporating prior knowledge and model local explanation	KNOWLEDGE AND INFORMATION SYSTEMS										Deep neural network; Credibility; Prior knowledge; Generalization; Fairness; Adversarial		Recent studies have shown that state-of-the-art DNNs are not always credible, despite their impressive performance on the hold-out test set of a variety of tasks. These models tend to exploit dataset shortcuts to make predictions, rather than learn the underlying task. The non-credibility could lead to low generalization, adversarial vulnerability, as well as algorithmic discrimination of the DNN models. In this paper, we propose CREX in order to develop more credible DNNs. The high-level idea of CREX is to encourage DNN models to focus more on evidences that actually matter for the task at hand and to avoid overfitting to data-dependent shortcuts. Specifically, in the DNN training process, CREX directly regularizes the local explanation with expert rationales,i.e., a subset of features highlighted by domain experts as justifications for predictions, to enforce the alignment between local explanations and rationales. Even when rationales are not available, CREX still could be useful by requiring the generated explanations to be sparse. In addition, CREX is widely applicable to different network architectures, including CNN, LSTM and attention model. Experimental results on several text classification datasets demonstrate that CREX could increase the credibility of DNNs. Comprehensive analysis further shows three meaningful improvements of CREX: (1) it significantly increases DNN accuracy on new and previously unseen data beyond test set, (2) it enhances fairness of DNNs in terms of equality of opportunity metric and reduce models' discrimination toward certain demographic group, and (3) it promotes the robustness of DNN models with respect to adversarial attack. These experimental results highlight the advantages of the increased credibility by CREX.																	0219-1377	0219-3116															10.1007/s10115-020-01517-5		OCT 2020											
J								Two-branch fusion network with attention map for crowd counting	NEUROCOMPUTING										Crowd counting; Attention map; Dynamic weighting strategy		Predicting the number and distribution of people in a crowded image is challenging work, due to the scale variations and complex background. In this work, we propose a two-branch fusion model with attention map to deal with the above two problems. Compared with previous works, our method designs a network focusing on fusing density maps which generated from different branches, instead of fusing features which captured from different scales. Two paralleled branches are followed with first ten layers of VGG16 model to extract different scales features from input image. And a dynamic weighting strategy is used to fuse the density maps generated from the different branches to get the final high quality density map. In addition, our model adopts attention mechanism to modify the density map of each branch. Our method has been evaluated on different datasets (ShanghaiTech, WorldExpo'10, UCF-QRNF and UCF_CC_50). The results present that our model has lower error than many other methods on these four datasets. The source code is available at https://github.com/jiezishu737/two_branches_code. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						1	8		10.1016/j.neucom.2020.06.034													
J								More trainable inception-ResNet for face recognition	NEUROCOMPUTING										Deep learning; Convolutional neural network; Face recognition; Inception-ResNet network; Activation function		In recent years, applications of face recognition have increased significantly. Despite the successful application of deep convolutional neural network (DCNN), training such networks is still a challenging task that needs a lot of experience and carefully tuning. Based on the Inception-ResNet network, we propose a novel method to mitigate the difficulty of training such deep convolutional neural network and improve its performance simultaneously. The residual scaling factor used in the Inception-ResNet module is a manually set fixed value. We believe that changing the value to a trainable parameter and initializing it to a small value can improve the stability of the model training. We further adopted a small trick of alternating the ReLU activation function with the Leaky ReLU and PReLU. The proposed model slightly increased the number of training parameters but improved training stability and performance significantly. Extensive experiments are conducted on VGGFace2, MS1MV2, IJBB and LFW datasets. The results show that the proposed trainable residual scaling factor (TRSF) and PReLU can promote the accuracy notably while stabilizing training process. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						9	19		10.1016/j.neucom.2020.05.022													
J								Adaptive Attention-Aware Network for unsupervised person re-identification	NEUROCOMPUTING										Unsupervised person re-identification; Adaptive Attention-Aware Network; Style-transfer; Hard negative mining		Person re-identification (Re-ID) has attracted more attention in computer vision tasks recently and achieved high accuracy in some public available datasets in a supervised manner. The performance drops significantly when datasets are unlabeled, which limits the scalability of Re-ID algorithms in practical applications. Despite some unsupervised methods are proposed to address the scalability problem of Re-ID, it's hard to learn discriminative feature representations due to the lack of pairwise labels in different camera views. To overcome this problem, we propose an end-to-end network named Adaptive Attention-Aware Network for unsupervised person re-identification. Specifically, we propose a novel adaptive attention-aware module that could be easily embedded into Re-ID architecture. The proposed module focuses on learning strong expressive relationship among channels of feature maps, and alleviating the key problems of Re-ID, e.g., occlusion and local deformation. In addition, we extract the camera-invariant features by adopting camera-style transfer feature learning since matching pairs in Re-ID suffers from appearance changes under different camera views. Besides, unsupervised hard negative mining is introduced to learn large intra-person appearance variance and discriminate high inter-person appearance similarity in an unlabeled target dataset with an auxiliary labeled dataset. Comprehensive experiments on three public available Re-ID datasets demonstrate that our method can achieve the state-of-the-art results of unsupervised Re-ID and is competitive with supervised learning. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						20	31		10.1016/j.neucom.2020.05.094													
J								Adaptive and azimuth-aware fusion network of multimodal local features for 3D object detection	NEUROCOMPUTING										3D object detection; Point cloud; Multimodal fusion; Ground plane fitting		This paper focuses on the construction of strong local features and the effective fusion of image and LiDAR data for 3D object detection. We adopt different modalities of LiDAR data to generate rich features and present an adaptive and azimuth-aware network to aggregate local features from image, bird's eye view maps and point cloud. Our network mainly consists of three subnetworks: ground plane estimation network, region proposal network and adaptive fusion network. The ground plane estimation network extracts features of point cloud and predicts the parameters of a plane which are used for generating abundant 3D anchors. The region proposal network generates features of image and bird's eye view maps to output region proposals. To integrate heterogeneous image and point cloud features, the adaptive fusion network explicitly adjusts the intensity of multiple local features and achieves the orientation consistency between image and LiDAR data by introducing an azimuth-aware fusion module. Experiments are conducted on KITTI dataset and the results validate the advantages of our aggregation of multimodal local features and the adaptive fusion network. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 21	2020	411						32	44		10.1016/j.neucom.2020.05.086													
J								Learning ordered pooling weights in image classification	NEUROCOMPUTING										Pooling; Ordered weighted aggregation; Image classification; Bag-of-words; Mid-level features; Convolutional neural networks; Global pooling		Spatial pooling is an important step in computer vision systems like Convolutional Neural Networks or the Bag-of-Words method. The spatial pooling purpose is to combine neighbouring descriptors to obtain a single descriptor for a given region (local or global). The resultant combined vector must be as discriminant as possible, in other words, must contain relevant information, while removing irrelevant and confusing details. Maximum and average are the most common aggregation functions used in the pooling step. To improve the aggregation of relevant information without degrading their discriminative power for image classification, we introduce a simple but effective scheme based on Ordered Weighted Average (OWA) aggregation operators. We present a method to learn the weights of the OWA aggregation oper-ator in a Bag-of-Words framework and in Convolutional Neural Networks, and provide an extensive evaluation showing that OWA based pooling outperforms classical aggregation operators. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						45	53		10.1016/j.neucom.2020.06.028													
J								Kernel-target alignment based non-linear metric learning	NEUROCOMPUTING										Metric learning; Learning framework; Random Fourier Approximation; Kernel-target alignment	FRAMEWORK	Distance metric learning aims to learn a measure of the pairwise distance between data instances, which is essential for various machine learning algorithms and applications. However, existing linear metric learning methods based on linear transformations fail to capture nonlinear relationships between instances, while most existing kernel-based metric learning algorithms may ignore the correlation between the kernel function and the target learning task during model selection, which results in a suboptimal selection of kernels. To address the aforementioned issues, we propose a method named Kernel Alignment based Metric Learning with Random Fourier Approximation (KAML(RFA)). Specifically, on one hand, we utilize the random Fourier features to approximate the shift-invariant kernel function for distance metric learning. On the other hand, we attempt to maximize the degree of agreement between the kernel function and the target learning task. In this way, distance metric learning is performed in a discriminative feature space. Compared with those kernel metric learning algorithms whose kernel functions fall into a suboptimal, KAML(RFA) achieves the optimal kernel function for the target task and improves classification accuracy. We develop an efficient solution to solve the proposed optimization problem. Extensive experiments are conducted on several benchmark datasets including NUS-WIDE-LITE, USPS, MNIST, LETTER and 10 UCI datasets to verify the effectiveness of KAML(RFA) compared with state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						54	66		10.1016/j.neucom.2020.06.042													
J								Unseen image generating domain-free networks for generalized zero-shot learning	NEUROCOMPUTING										Generalized zero-shot learning; Unseen image generation; Extreme data bias; Data bias; Generative adversarial networks		In generalized zero-shot learning (GZSL), it is imperative to solve the bias problem due to extreme data imbalance between seen and unseen classes, i.e., unseen classes are misclassified as seen classes. We alleviate the bias problem by generating synthetic images of unseen classes. The most challenging part is that existing GAN methods are only focused on producing authentic seen images, so realistic unseen images cannot be generated. Specifically, we propose a novel zero-shot generative adversarial network (ZSGAN) which learns the relationship between images and attributes shared by seen and unseen classes. Unlike existing works that generate synthetic features of unseen classes, we can generate more generalizable realistic unseen images. For instance, generated unseen images can be used for zero-shot detection, segmentation, and image translation since images have spatial information. We also propose domain-free networks (DFN) that can effectively distinguish seen and unseen domains for input images. We evaluate our approaches on three challenging GZSL datasets, including CUB, FLO, and AWA2. We outperform the state-of-the-art methods and also empirically verify that our proposed method is a network-agnostic approach, i.e., the generated unseen images can improve performance regardless of the neural network type. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						67	77		10.1016/j.neucom.2020.05.043													
J								Gaussian-response correlation filter for robust visual object tracking	NEUROCOMPUTING										Object tracking; Correlation filter; Partial occlusion; Scale variation; Online learning	NETWORK	This paper presents a novel correlation filter-based tracking method for robust visual object tracking in the presence of partial occlusion, large-scale variation and model drift. To do this, first, we develop a correlation filter for predicting the target location based on the distribution of correlation response. In this formulation, the correlation response of the target image follows Gaussian distribution to estimate the target location efficiently. Second, the constraints are derived using kernel ridge regression to mitigate the target failure in object tracking. Third, we propose an adaptive scale estimation method to detect the target scale changes during the tracking. In addition, two feature integration is elaborately designed to improve the discriminative strength of the correlation filter. Finally, extensive experimental results on OTB2013, OTB2015, TempleColor128 and UAV123 datasets demonstrate that the proposed method performs favourably against several state-of-the-art methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						78	90		10.1016/j.neucom.2020.06.016													
J								Density-adaptive kernel based efficient reranking approaches for person reidentification	NEUROCOMPUTING										Person reidentification; Reranking; Density-adaptive kernel; k-INN; k-RNN	INFORMATION; HISTOGRAMS; FEATURES	Person reidentification (ReID) refers to the task of verifying the identity of a pedestrian observed from nonoverlapping views in a surveillance camera network. It has recently been validated that reranking can achieve remarkable performance improvements in person ReID systems. However, current reranking approaches either require feedback from users or suffer from burdensome computational costs. In this paper, we propose to exploit a density-adaptive smooth kernel technique to achieve efficient and effective reranking. Specifically, we adopt a smooth kernel function to formulate the neighbor relationships among data samples with a density-adaptive parameter. Based on this new formulation, we present two simple yet effective reranking methods, termed inverse density-adaptive kernel based reranking (inv-DAKR) and bidirectional density-adaptive kernel based reranking (bi-DAKR), in which the local density information in the vicinity of each gallery sample is elegantly exploited. Moreover, we extend the proposed inv-DAKR and bi-DAKR methods to incorporate the available extra probe samples and demonstrate that when and why these extra probe samples are able to improve the local neighborhood and thus further refine the ranking results. Extensive experiments are conducted on six benchmark datasets, including: PRID450s, VIPeR, CUHK03, GRID, Market-1501 and Mars. The experimental results demonstrate that our proposals are effective and efficient. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						91	111		10.1016/j.neucom.2020.05.096													
J								Detection of cervical cancer cells based on strong feature CNN-SVM network	NEUROCOMPUTING										Cancer cell detection; Strong features; CNN-SVM; Sample amplification	QUANTITATIVE-ANALYSIS; CLASSIFICATION; SEGMENTATION; DIAGNOSIS	Traditional screening of cervical cells largely depends on the experience of pathologists, which also has the problem of low accuracy and poor efficiency. Medical image processing combining deep learning and machine learning shows its superiority in the field of cell classification. A new framework based on strong feature Convolutional Neural Networks (CNN)-Support Vector Machine (SVM) model was proposed to accurately classify the cervical cells. A method fusing the strong features extracted by Gray-Level Co-occurrence Matrix (GLCM) and Gabor with abstract features from the hidden layers of CNN was conducted, meanwhile the fused ones were input into the SVM for classification. An effective dataset amplification method was designed to improve the robustness of the model. The proposed method was evaluated on two independent datasets with the metrics of accuracy (Acc), sensitivity (Sn), and specificity (Sp). Our approach outperformed than the state-of-the-art models with the Acc, Sn, and Sp of 99.3, 98.9, 99.4 for 2-class detection in the mass, respectively. The results indicated that the strong feature CNN-SVM model could be applied in cell classification for the early screening of cervical cancer. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						112	127		10.1016/j.neucom.2020.06.006													
J								Temporal learning of bottom-up connections via spatially nonspecific top-down inputs	NEUROCOMPUTING										Computational model; Learning; Spike-time-dependent-plasticity; Brain rhythms; Recurrent networks	CLASSICAL RECEPTIVE-FIELD; BRAIN NETWORKS; VISUAL-CORTEX; FEEDBACK; INHIBITION; FEEDFORWARD; ATTENTION; V1; V2	In the brain, high-order and low-order areas are connected via bottom-up connections (from low-order to high-order areas) and top-down connections (from high-order to low-order areas). While bottom-up signals are thought to be critical in generating perception, functions of top-down signals have not been clearly delineated. One popular theory is that top-down inputs modify the activity of specific cell assemblies to modulate responses to bottom-up inputs. However, a different line of studies proposes that not all top-down inputs are specifically delivered. As the leading theories cannot account for nonspecific top down inputs, we seek potential functions of nonspecific top-down signals using network models in our study. Our simulation results suggest that top-down inputs can regulate low-order area responses by providing temporal information even without spatial specificity. Specifically, the temporal information in nonspecific top-down inputs can weaken the undesired bottom-up connections, contributing to bottom-up connections' learning. Further, we found that cortical rhythms (synchronous oscillatory neural responses) are critical in the proposed learning process of bottom-up connections in our model. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						128	138		10.1016/j.neucom.2020.06.030													
J								Att-MoE: Attention-based Mixture of Experts for nuclear and cytoplasmic segmentation Att-MoE: Attention-based Mixture of Experts for nuclear and cytoplasmic segmentation	NEUROCOMPUTING										Fluorescent histology image segmentation; Cell segmentation; Mixture of Experts; Attention gate	RESOLUTION; NETWORKS; CONTOUR	Cell segmentation is a critical step in histology images analysis. Recently, Convolutional Neural Network (CNN) has shown outstanding performance for various segmentation problems, however, the segmentation of histology images remains challenging due to the tight arrangement of cells and their weak boundaries. This paper proposes a novel architecture called Attention-based Mixture of Experts (Att-MoE) for nuclear and cytoplasmic segmentation in fluorescent histology images, which integrates multiple Expert networks using a single Gating network. Expert networks complement each other to accomplish sub-tasks under the direction of the Gating network, which enforces the adaptive use of multiple networks to complete the segmentation task. The Att-MoE also introduces attention gates and residual blocks in the Expert networks to improve segmentation accuracy. The attention gate is used to emphasize useful features and suppress irrelevant features for segmentation in a self-adaptive manner. On the other hand, residual blocks are employed to enhance gradient flow in training and improve the stability and segmentation accuracy of the network. Experiments on fluorescent histology images of mouse liver show that Att-MoE is superior to recent segmentation methods and has the potential for cancer diagnosis based on histology images. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						139	148		10.1016/j.neucom.2020.06.017													
J								An extension of the type-1 and singleton fuzzy logic system trained by scaled conjugate gradient methods for multiclass classification problems	NEUROCOMPUTING										Fuzzy logic system; Multiclass classification; Scaled conjugate gradient; Hessian-free		This paper proposes an extension of the type-1 and singleton fuzzy logic system for dealing with multi-class classification problems. The proposed extension enables a fuzzy classifier to generate more than one output, thereby avoiding the use of binary decomposition strategies when multiclass classification problems are considered. Additionally, with the goal of improving classifier performance, the scaled conjugate gradient training method was applied, as well as its modified version using the differential operator R {center dot}. The effectiveness of the proposed extension was evaluated using data from the UCI Machine Learning Repository based on well-established classification metrics. The numerical results reveal a significant reduction in computational complexity when using the proposed extension compared to the traditional decomposition strategy, as well as improved convergence speed when using the scaled conjugate gradient training method. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						149	163		10.1016/j.neucom.2020.05.052													
J								Dual reference age synthesis	NEUROCOMPUTING										Age synthesis; Dual reference; ''Soft" age information; Conditional generative adversarial network	FACE; PERCEPTION; TEXTURES; SHAPE	Age synthesis methods typically take a single image as input and use a specific number to control the age of the generated image. In this paper, we propose a novel framework taking two images as inputs, named dual-reference age synthesis (DRAS), which approaches the task differently; instead of using ''hard" age information, i.e. a fixed number, our model determines the target age in a ''soft" way, by employing a second reference image. Specifically, the proposed framework consists of an identity agent, an age agent and a generative adversarial network. It takes two images as input - an identity reference and an age reference - and outputs a new image that shares corresponding features with each. Experimental results on two benchmark datasets (UTKFace and CACD) demonstrate the appealing performance and flexibility of the proposed framework. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						164	177		10.1016/j.neucom.2020.06.023													
J								Domain adaptation based on domain-invariant and class-distinguishable feature learning using multiple adversarial networks	NEUROCOMPUTING										Transfer learning; Domain adaptation; Domain adversarial learning; Sample adversarial learning	KERNEL	Adversarial networks have been used to learn transferable representations in many domain adaptation methods. However, there is no theoretical guarantee that two distributions are identical, even if the discriminator is fully confused. Therefore, a more elaborate domain adversarial method to better align distributions is desirable. In this paper, we propose two groups of multiple adversarial networks for domain-invariant and class-distinguishable feature learning: i) class-wise domain adversarial networks based on sample locations and ii) sample adversarial networks. We analyze the impact of the sample's intra-class distribution on transfer learning and reveal that the distance between a sample and its cluster center affects the role of that sample in transfer learning. Domain adversarial learning is conducted separately on samples located near the cluster center (central samples) and samples located far away from cluster center (non-central samples) in order to align the distributions of the source domain and target domain better. However, separate domain adversarial learning on central and non-central samples ignores the relationship between them, because all these samples belong to the same class. We therefore propose a method called sample adversarial learning to convert the distribution of non-central samples to the distribution of central samples. In this way, the relationship between central samples and non central samples is rebuilt. Sample adversarial learning solves the problem that arises in the sperate domain adversarial learning. Sample adversarial learning also enables us to obtain a class distinguishable feature representation because of the reduction in intra-class distance. Experimental results show that our method extracts more transferable and class-distinguishable features than existing methods and achieves start-of-the-art results on several datasets. The significant contribution of this paper is to show how separate domain adversarial learning based on sample locations and sample adversarial learning together enhance positive transfer by maximally matching the multimodal structures underlying the data distributions across domains. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						178	192		10.1016/j.neucom.2020.06.044													
J								N3-CPL: Neuroplasticity-based neuromorphic network cell proliferation learning	NEUROCOMPUTING										SNN; ANN; Novel structure; Network proliferation; Neuromorphic network cell; Neuroplasticity	SPIKING NEURAL-NETWORKS; CLASSIFICATION; PLASTICITY; PREDICTION	In general, Spiking Neural Networks (SNNs) have a network structure with special methods applied to neuron models and information transmission to mimic humans biologically. However, the existing SNN structures have two problems, such as fixed existing Artificial Neural Network structures and difficulty in learning due to lack of spike information during information transfer. Recently, many approaches of learning SNNs have been proposed in order to alleviate those two drawbacks. However, it is very difficult to overcome the drawbacks only by the learning method without the fundamental solution for the structure. In order to solve the problem of structure and learning method, we propose a novel flexible network construction method using neurogenesis-based cell proliferation concept and Triple SimultaneousSpike Timing Dependent Plasticity (TS-STDP) which is improved learning method through neuroplasticity-based spike timing. We build the network flexibly and automatically by employing the concept that not only one neuron exists in the neural network, but also that various cells proliferate and transform from stem cells to function. In addition, TS-STDP is designed by considering the correlation of signal response among several neurons to solve the lack of information due to spike sparsity, which is a disadvantage of STDP. In the experimental section, we demonstrate and analyze our method using Mixed National Institute of Standards and Technology image data. Our method is 2.7x better in memory efficiency and 1.7x better in computational efficiency than the existing method. In particular, the research that automatically constructs the network structure is the first to my knowledge. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						193	205		10.1016/j.neucom.2020.06.012													
J								A TD3-based multi-agent deep reinforcement learning method in mixed cooperation-competition environment	NEUROCOMPUTING										Reinforcement learning; Overestimation error; Dual-critic; MADDPG; MATD3		We explored the problem about function approximation error and complex mission adaptability in multi agent deep reinforcement learning. This paper proposes a new multi-agent deep reinforcement learning algorithm framework named multi-agent time delayed deep deterministic policy gradient. Our work reduces the overestimation error of neural network approximation and variance of estimation result using dual-centered critic, group target network smoothing and delayed policy updating. According to experiment results, it improves the ability to adapt complex missions eventually. Then, we discuss that there is an inevitable overestimation issue about existing multi-agent algorithms about approximating real action-value equations with neural network. We also explain the approximate error of equations in the multi-agent deep deterministic policy gradient algorithm mathematically and experimentally. Finally, the application of our algorithm in the mixed cooperative competition experimental environment further demonstrates the effectiveness and generalization of our algorithm, especially improving the group's ability of adapting complex missions and completing more difficult missions. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						206	215		10.1016/j.neucom.2020.05.097													
J								DCSR: Deep clustering under similarity and reconstruction constraints	NEUROCOMPUTING										Clustering; Adaptive siamese loss; Reconstruction loss	FAST SEARCH; ENSEMBLE; NETWORK; FIND	Clustering is a difficult but crucial task in pattern recognition and machine learning. Inherently, clustering methods are always subject to the uncertainty of similarities between samples. To weaken the impact of such uncertainty, we develop Deep Clustering with both Adaptive Siamese Loss (ASL) and ReConstruction Loss (RCL) to adaptively consider the similarities and stabilize the clustering process. Technically, ASL is focus on mapping the samples from the data space to the same representations or the orthogonal representations, and RCL provides a priori knowledge to stabilize the clustering process. Benefiting from such artful modelling, DCSR is in a position to endow deep networks to stably learn one-hot representations, yielding an end-to-end mechanism for clustering and representation learning. Extensive experiments demonstrate that our model achieves state-of-the-art performance on popular datasets, including image, audio, and text. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						216	228		10.1016/j.neucom.2020.06.013													
J								TEAN: Timeliness enhanced attention network for session-based recommendation	NEUROCOMPUTING										Recommender systems; Attention model; Temporal information; Neural network; Session learning		Session-based recommendation task attracts more researchers' attention in recent years. However, previous approaches suffer from limited timeliness since they overlook dynamic features of items and temporal semantic information, which results in inappropriate prediction. In this study, we propose an attention-based model named Timeliness Enhanced Attention Network (TEAN). It first extracts features of user and item from static and dynamic perspectives and then employs temporal semantic information by a time-cross mechanism. Our model is capable of ranking items based on timeliness enhanced features. Besides, we apply a pre-training method based on word2vec to learn embedding vector for users, items and temporal semantic information in an elegant way. Experiments on three datasets of different domains demonstrate that our approach improves performance opposed to other methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						229	238		10.1016/j.neucom.2020.06.063													
J								State estimation for a class of artificial neural networks subject to mixed attacks: A set-membership method	NEUROCOMPUTING										Set-membership state estimation; Artificial neural networks; Time delays; Mixed attacks	TIME-DELAY SYSTEMS; SENSOR NETWORKS; MULTIAGENT SYSTEMS; SYNCHRONIZATION; STABILITY; DESIGN	This article deals with the set-membership state estimation problem for a class of artificial neural networks subject to time-delays and mixed malicious attacks. Both Denial-of-Service (DoS) and deception attacks are taken into consideration. The objective of the addressed problem is to design the state estimation algorithm for the artificial neural networks under investigation in spite of the existence of the malicious mixed attacks. By means of the set-membership approach in combination with certain convex optimization algorithm, the sufficient condition is established for the existence of the desired state estimator in terms of the solvability of a recursive matrix inequality. The resulting state estimation error is confined within certain pre-specified ellipsoidal region. An optimization problem is then formulated with the purpose of seeking the filtering parameters guaranteeing the locally optimal performance. Finally, the developed theoretical results are verified via an illustrative numerical example. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						239	246		10.1016/j.neucom.2020.06.020													
J								Recurrent convolutional networks for session-based recommendations	NEUROCOMPUTING										Session-based recommendation; Recommender systems; Deep learning; Recurrent neural networks; Recurrent convolutional neural networks; Convolutional neural networks	SYSTEMS	Traditional recommender systems help users find items of interest by modeling long-term user profiles, which consist of items the users interacted with in the past. In many real-life applications, however, informative user profiles are not available. Instead, the system recommends by relying on the current user activities within an ongoing session, leading to the emergence of session-based recommendation methods. Among techniques used in such situations, recurrent neural networks (RNNs) present a natural choice thanks to their ability to model the order of session events and capture long-term dependencies. Recently, methods based on convolutional neural networks (CNNs) have also shown their potential in modeling session data, especially in extracting complex local patterns that are predictive of the user target. In this work, we propose a recurrent convolutional architecture that takes the advantages of both complex local features extracted by CNNs and long-term dependencies learned by RNNs from session sequences. Our model has two main layers: the lower layer consists of convolutional filters applied over consecutive session event embeddings, and the upper layer is a gated recurrent unit (GRU) RNN that takes as input the CNN's output. This hybrid approach provides a flexible and unified network architecture for modeling various important features of session sequences. Experiments conducted on three benchmark datasets demonstrate the superiority of the proposed model over pure RNNs and CNNs models as well as state-of-the-art session-based recommendation methods. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						247	258		10.1016/j.neucom.2020.06.077													
J								Underdetermined blind separation of source using l(p)-norm diversity measures	NEUROCOMPUTING										Underdetermined mixture; Blind separation of source; l(p)-norm diversity measures; Source number estimation; Source reconstruction	IDENTIFICATION; DECONVOLUTION; DECOMPOSITION; FACTORIZATION; MIXTURES	Blind separation of sources (BSS) is to recover the source signals from the observed mixture signals with no knowledge on the mixing channel. Recently, there has been more and more attention to underdetermined BSS. In the study of underdetermined BSS, it is a challenging problem to separate the source signals efficiently while without knowing the number of sources. On the one hand, the number of sources is unknown in practice. On the other hand, most traditional blind separation algorithms encounter highly computational complexity leading to poor separation performance. To remedy the shortcomings of traditional algorithms, in this paper, a novel algorithm based on p-norm-like (l((0< p <= 1))) diversity measures is proposed to solve the underdetermined BSS problem. First of all, we propose an improved information theory criteria method to detect the number of sources in the underdetermined case. Meanwhile, we use a fourth-order tensor blind identification method for the estimation of the mixing matrix. In the stage of source signal reconstruction, we develop an (l((0< p <= 1)))-norm diversity measure for better source signal reconstruction and the computational complexity is reduced significantly. Simulation results and experimental measurements demonstrate that the proposed algorithm can obtain better separation performance and achieve fast running speed. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						259	267		10.1016/j.neucom.2020.06.029													
J								Attentive feature integration network for detecting salient objects in images	NEUROCOMPUTING										Salient object detection; Saliency detection; Channel-wise attention; Deep supervision; Multi-level feature integration	VISUAL-ATTENTION; MODEL	Benefiting from the development of convolutional neural networks, salient object detection has yielded a qualitative leap in performance. In recent years, most of deep learning based methods utilize multi-level features and obtain inferred saliency map in a coarse-to-fine manner. However, how to learn and represent powerful features is still a challenge. In this paper, we propose a novel FCN-like approach named attentive feature integration network (AFINet) for pixel-wise salient object detection, which results saliency maps with explicit boundary and uniform highlighted regions. Specifically, it adopts feature enhancement module (FEM) to extract rich and enhanced features from backbone net. A feature discrimination module (FDM) is designed to utilize the predicted saliency map generated by deeper layer to help shallower layer learn useful and discriminative attentive features. Moreover, we introduce the saliency information from deeper layer to the shallower one in saliency prediction module (SPM), which helps shallow side outputs accurately locate salient regions. In addition, we design a saliency fusion module (SFM) to integrate different side outputs for utilizing multi-level features. Finally, a fully connected CRF scheme can be optimally incorporated for obtaining saliency results with a higher accuracy. Both qualitative and quantitative comparisons and evaluations conducted on five publicly benchmark datasets demonstrate that our proposed approach compares favorably against 17 state-of-the-art approaches. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						268	281		10.1016/j.neucom.2020.05.083													
J								State estimation for discrete-time high-order neural networks with time-varying delays	NEUROCOMPUTING										Discrete-time high-order neural networks; State observer; Global exponential stability; Moore-Penrose inverse; Time-varying delays	GLOBAL EXPONENTIAL STABILITY; PERIODIC-SOLUTION; EXISTENCE; OBSERVER; SYSTEMS; DESIGN	This paper focuses on state estimation problem for discrete-time high-order neural networks with time varying delays. First, the delay-dependent global exponential stability criterion of the error system is derived. Then, the state observer is designed by using the generalized inverse theory of matrices. Last, two numerical examples are given to illustrate the validity of the theoretical results. The method proposed in this paper has two advantages: (i) it is directly based on the definitions of global exponential stability and Moore-Penrose inverse of matrix, which avoids the construction of Lyapunov-Krasovskii functional; (ii) the obtained stability criteria contain only several simple matrix inequalities, which are easier to solve. More valuable, this paper fills in the gaps in designing state observers for discrete-time high-order neural network models. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						282	290		10.1016/j.neucom.2020.06.047													
J								Real-time phonocardiogram anomaly detection by adaptive 1D Convolutional Neural Networks	NEUROCOMPUTING										Phonocardiogram classification; Convolutional Neural Networks; Real-time heart sound monitoring	STRUCTURAL DAMAGE DETECTION; DEEP; SEGMENTATION; RECOGNITION; WIRELESS	The heart sound signals (Phonocardiogram - PCG) enable the earliest monitoring to detect a potential cardiovascular pathology and have recently become a crucial tool as a diagnostic test in outpatient monitoring to assess heart hemodynamic status. The need for an automated and accurate anomaly detection method for PCG has thus become imminent. To determine the state-of-the-art PCG classification algorithm, 48 international teams competed in the PhysioNet (CinC) Challenge in 2016 over the largest benchmark dataset with 3126 records with the classification outputs, normal (N), abnormal (A) and unsure - too noisy (U). In this study, our aim is to push this frontier further; however, we focus deliberately on the anomaly detection problem while assuming a reasonably high Signal-to-Noise Ratio (SNR) on the records. By using 1D Convolutional Neural Networks trained with a novel data purification approach, we aim to achieve the highest detection performance and real-time processing ability with significantly lower delay and computational complexity. The experimental results over the high-quality subset of the same benchmark dataset show that the proposed approach achieves both objectives. Furthermore, our findings reveal the fact that further improvements indeed require a personalized (patient-specific) approach to avoid major drawbacks of a global PCG classification approach. (C) 2020 The Authors. Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 21	2020	411						291	301		10.1016/j.neucom.2020.05.063													
J								Joint extraction of entities and relations using graph convolution over pruned dependency trees	NEUROCOMPUTING										Joint extraction of entities and relations; Graph convolutional Network; Dependency tree		We present a novel end-to-end deep neural network model based on graph convolutional networks for simultaneous joint extraction of entities and relations among them. Our model captures context and syntactic information from sentence by stacking a graph convolutional layer over bidirectional sequential LSTM layers. We sequentially concatenate the subject, object and sentence representations for obtaining the directionality of relations. Besides, in order to address long entity-distances problem, we further apply a path-centric pruning procedure to input trees in order to preserve useful information while maximally removing irrelevant words. Experiments are conducted on NYT dataset, and the proposed model achieves the state-of-the-art results on entity and relation extraction task. Our source code is available on Github: https://github.com/michael-hon/LSTM-GCN-ER. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						302	312		10.1016/j.neucom.2020.06.061													
J								Gated hierarchical multi-task learning network for judicial decision prediction	NEUROCOMPUTING										Judicial decision prediction; Multi-task learning; Gated hierarchical encoder; Dependencies auto-learning predictor	QUANTITATIVE-ANALYSIS; NEURAL-NETWORKS	Judicial Decision Prediction (JDP) aims to predict legal judgments given the fact description of a criminal case. It consists of multiple subtasks, e.g., law article prediction, charge prediction, and term of penalty prediction. Generally, a fact description contains in-depth semantic information. Besides, there exist complex dependencies among subtasks. For instance, law article prediction could guide charge prediction and term of penalty prediction. Nonetheless, the majority of previous approaches usually capture indepth semantic information of fact description inadequately or neglect the dependencies among sub tasks. In this paper, we propose a novel gated hierarchical multi-task learning network, named GHEDAP, to jointly model multiple subtasks in JDP. Specifically, GHE-DAP combines a Gated Hierarchical Encoder (GHE) to extract in-depth semantic information of fact description from multiple perspectives, and a Dependencies Auto-learning Predictor (DAP) to learn the dependencies among subtasks dynamically. We evaluate our model on several representative subtasks, and the experimental results demonstrate that our model outperforms state-of-art baselines consistently and significantly for JDP. (c) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 21	2020	411						313	326		10.1016/j.neucom.2020.05.018													
J								Design of a self-organizing reciprocal modular neural network for nonlinear system modeling	NEUROCOMPUTING										Reciprocal modular neural network; Inter-module connection; Self-organization; Nonlinear system modeling	BRAIN; OPTIMIZATION; ARCHITECTURE; COMPLEXITY; ALGORITHM; INTEGRATION	Aiming to improve the model's generalization performance for nonlinear system modeling, a self organizing reciprocal modular neural network (SORMNN) is proposed in the present study, which imitates the modular structure with inter-module connections observed in human brains. The inter module connections in SORMNN are built by inputting the output of each subnetwork to other subnetworks. All subnetworks work in parallel to process the allocated features, and the structure of each subnetwork is designed to be self-organized by using a growing and pruning algorithm based on the contribution of hidden neurons. An improved Levenberg-Marquardt (LM) algorithm using a sliding window is conducted to update the parameters of SORMNN, which makes SORMNN available for solving online problems. To validate the effectiveness of the proposed model, SORMNN is tested on chaotic benchmark time series prediction, four UCI benchmark problems and a practical problem for biochemical oxygen demand prediction in wastewater treatment process. Experimental results demonstrate that SORMNN exhibits both a higher training accuracy and a better generalization ability for nonlinear system modeling than other modular neural networks, and the inter-module connections have a positive effect on the superior performance of the proposed model and can make the network structure compact. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						327	339		10.1016/j.neucom.2020.06.056													
J								Attention mechanism-based CNN for facial expression recognition	NEUROCOMPUTING										Facial Expression Recognition; Convolutional Neural Network; Attention Mechanism; Local Binary Patten; Image Classification	CLASSIFICATION	Facial expression recognition is a hot research topic and can be applied in many computer vision fields, such as human-computer interaction, affective computing and so on. In this paper, we propose a novel end-to-end network with attention mechanism for automatic facial expression recognition. The new network architecture consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The LBP features extract image texture information and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the neural network pay more attention to useful features. We combine LBP features and attention mechanism to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both RGB images and depth images with a Microsoft Kinect sensor. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						340	350		10.1016/j.neucom.2020.06.014													
J								Smoothed LSTM-AE: A spatio-temporal deep model for multiple time-series missing imputation	NEUROCOMPUTING										Time-series; Missing data; Long short-term memory; Auto-encoder		Missing values widely exist in time-series data owing to sensor or communication failure. It is indispensable to impute the missing data for equipment state monitoring and advanced data analysis. In this study, we propose a deep spatiotemporal time-series missing data imputation model, called LSTM-AEs, to enhance the imputation performance and handle multiple missing patterns. Generally, it is practically challenging to determine when, which, and how many sensors fail. Most previous algorithms cannot handle multiple-sensor missing data owing to insufficient attributes. As different missing patterns require different models and may appear simultaneously, it is inadvisable to employ a large number of models for handling all these patterns. A deep auto-encoder (DAE) can eliminate the diversity of missing patterns by restoring the information from the sensor data. The proposed model combines DAE and LSTM for extracting spatio-temporal features to estimate missing values in multiple time series. Moreover, a smoothing regularization term is added into the combined model, leading to a more stable estimation. Experiments are conducted on three types of sensor data: the Tennessee Eastman process simulation data, gas turbine data from the offshore oil Corporation, and power plant simulation data. The results demonstrate that the proposed technique is effective for different missing patterns and provides more accurate predictions than the existing techniques. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						351	363		10.1016/j.neucom.2020.05.033													
J								Novel up-scale feature aggregation for object detection in aerial images	NEUROCOMPUTING										Object detection; Aerial images; Feature aggregation; Up-sampling	NETWORK	Object detection is a pivotal task for many unmanned aerial vehicle (UAV) applications. Compared to general scenes, the objects in aerial images are typically much smaller. For this reason, most general object detectors suffer from two critical challenges while dealing with aerial images: 1) The widely exploited Feature Pyramid Network works by integrating high-level features to lower levels progressively. However, this manner does not transfer equivalent information from each level of backbone network to the generated features, and the shared detection head faces an unbalanced sources of information flow, damaging the detection accuracy. 2) Up-sampling is commonly used to expand feature resolution for feature fusion or feature aggregation. However, existing up-sampling methods are ineffective to reconstruct high resolution feature maps. To address these two challenges, two works are proposed: 1) An up-scale feature aggregation framework that fully utilizes multi-scale complementary information, and 2) a novel up-sampling method that further improve detection accuracy. These two proposals are integrated into an end-to-end single-stage object detector namely HawkNet. Extensive experiments are conducted on VisDrone-DET2018, UAVDT and DIOR datasets. Compared to the RetinaNet baseline, our HawkNet achieves absolute gains of 6.0%, 1.2% and 5.9% in average precision (AP) on VisDrone-DET2018, UAVDT and DIOR datasets, respectively. For a 800 x 1333 input on the UAVDT dataset, HawkNet with ResNet50 backbone surpasses existing methods for single-scale inference and achieves the best performance (37.4 AP), while operating at 10.6 frames per second on a single Nvidia GTX 1080Ti GPU. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						364	374		10.1016/j.neucom.2020.06.011													
J								A composite learning method for multi-ship collision avoidance based on reinforcement learning and inverse control	NEUROCOMPUTING										Ship collision avoidance; Asynchronous advantage actor-critic; Long short-term memory neural network; Inverse control	UNMANNED SURFACE VEHICLE; NEURAL-NETWORKS; DECISION-SUPPORT; NAVIGATION; SYSTEM; MODELS	Model-free reinforcement learning methods have potentials in ship collision avoidance under unknown environments. To defect the low efficiency problem of the model-free reinforcement learning, a composite learning method is proposed based on an asynchronous advantage actor-critic (A3C) algorithm, a long short-term memory neural network (LSTM) and Q-learning. The proposed method uses Q-learning for adaptive decisions between a LSTM inverse model-based controller and the model-free A3C policy. Multi-ship collision avoidance simulations are conducted to verify the effectiveness of the model-free A3C method, the proposed inverse model-based method and the composite learning method. The simulation results indicate that the proposed composite learning based ship collision avoidance method outperforms the A3C learning method and a traditional optimization-based method. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						375	392		10.1016/j.neucom.2020.05.089													
J								Content-aware rate control scheme for HEVC based on static and dynamic saliency detection	NEUROCOMPUTING										HEVC; Content-aware; Static saliency; Dynamic saliency; Rate control		High efficiency video coding (HEVC) greatly outperforms previous standards H.264/AVC in terms of coding bit rate and video quality. However, it does not take into account the human visual system (HVS), that people pay more attention to specific areas and moving objects. In this paper, we present a content-aware rate control scheme for HEVC based on static and dynamic saliency detection. The proposed strategy mainly consists of three techniques, static saliency detection, dynamic saliency detection, and adaptive bit rate allocation. Firstly, we train a deep convolution network (DCN) model to extract the static saliency map by highlighting semantically salient regions. Compared to traditional texture-based or color-based region of interest (ROI) extraction techniques, our models are more in line with the HVS. Secondly, we develop a moving object segmentation technique to automatically extract the dynamic salient regions for each frame. Furthermore, according to the fusion saliency map, a coding tree unit (CTU) level bit control technique is exploited to realize flexible and adaptive bit rate allocation. As a result, the quality of salient regions is improved by allocating more bits, while allocating fewer bits to the non-salient regions. We verified the proposed method on both the JCT-VC recommended data set and eye-tracking data set. Experiment results show that the PSNR of salient regions can improve by an average of 1.85 dB without adding bit rate burden, which significantly improves the visual experience. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						393	405		10.1016/j.neucom.2020.06.003													
J								Synchronizing non-identical time-varying delayed neural network systems via iterative learning control	NEUROCOMPUTING										Synchronization; Delayed neural network system; Iterative learning control; Adaptive control	EXPONENTIAL SYNCHRONIZATION; MULTIAGENT SYSTEMS; NONLINEAR-SYSTEMS; ARRAY; DESIGN	In this paper, we proposed an iterative learning control (ILC) update rule to synchronize an array of nonidentical time-varying delayed neural network systems in a repetitive environment. Under the identical initial conditions, we employed a distributed D-type ILC update rule that guaranteed synchronization by choosing the appropriate inner coupling matrix. Besides, to accommodate non-identical initial conditions, we proposed another adaptive ILC update rule that also could synchronize the systems. Two numerical simulations are presented to illustrate the effectiveness of the theoretical results. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						406	415		10.1016/j.neucom.2020.05.053													
J								Multi-attention guided feature fusion network for salient object detection	NEUROCOMPUTING										Salient object detection; Feature fusion; Channel-wise attention; Position attention	VISUAL-ATTENTION	Though with the rapid development of deep learning, salient object detection methods have achieved increasingly better performance, how to get effective feature representation to predict more accurate sal-iency maps is still a burning problem we need to consider. To overcome this situation, most previous works tend to focus on skip-based architecture to integrate hierarchical information of different scales and layers. However, a simple concatenation of high-level features and low-level features is not all-powerful because cluttered and noisy information can cause negative consequences. Concerning the issue mentioned above, we propose a Multi-Attention guided Feature-fusion network (MAF) which can allevi-ate the problem from two aspects. For one thing, we use a novel Channel-wise Attention Block (CAB) to in charge of message passing layer by layer from a global view, which utilizes the semantic cues in the higher convolutional block to instruct the feature selection in the lower block. For another, a Position Attention Block (PAB) also works on integrated features to model pixel relationships and capture rich contextual dependencies. Under the guidance of multi-attention, discriminative features are selected to conduct a new end-to-end densely supervised encoder-decoder network which detects salient objects more uniformly and precisely. As the experimental results on five benchmark datasets show, our meth-ods perform favorably against other state-of-the-art approaches. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						416	427		10.1016/j.neucom.2020.06.021													
J								A quality enhancement framework with noise distribution characteristics for high efficiency video coding	NEUROCOMPUTING										High efficiency video coding; Quality enhancement; Convolutional neural network	SPARSE REPRESENTATION; DEBLOCKING; ARTIFACTS; NETWORK	Video coding effectively reduces the amount of video data while unavoidably producing compression noise. Compression noise can cause significant artifacts in compressed video, such as blocking, ringing, and blurring, which seriously affects the visual quality of videos and the value of videos for content analysis. In compressed video quality enhancement, few methods based on deep learning fully consider the relationship between video content and compression noise or the possibility of uniting the encoder or the decoder to enhance the quality of compressed video. In an approach different from existing methods, we propose a video quality enhancement framework based on the distribution characteristics of compression noise. The proposed framework consists of two parts: at the encoder, we propose a convolutional neural network (CNN)-based in-loop filtering network combined with noise distribution (IFN-ND) characteristics for the I frame instead of high efficiency video coding (HEVC) standard in-loop filters; at the decoder, we propose a CNN-based quality enhancement network combined with the noise distribution characteristics (PQEN-ND) for the P frames. The noise characteristics are extracted from the code stream to further improve the performance of the proposed networks. The experiments show that the proposed method can significantly improve the quality of HEVC compressed video, achieving an average 12.84% reduction in the BD rate and up to a 1.0476 dB increase in the peak signal-to-noise ratio (PSNR). (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						428	441		10.1016/j.neucom.2020.06.048													
J								Neural-network estimators based fault-tolerant tracking control for AUV via ADP with rudders faults and ocean current disturbance	NEUROCOMPUTING										Neural-network estimators (NNEs); Rudders faults; Autonomous underwater vehicle (AUV); Adaptive dynamic programming (ADP); Uniformly ultimately bounded (UUB)	AUTONOMOUS UNDERWATER VEHICLE; TRAJECTORY-TRACKING; CONTINUOUS-TIME; THRUSTER; SYSTEMS; RECONSTRUCTION; SPACECRAFT	This paper investigates fault-tolerant tracking control problem for autonomous underwater vehicle (AUV) with rudders faults and ocean current disturbance. The adaptive dynamic programming (ADP) method is adopted to transform the fault-tolerant tracking control problem into an optimal control problem. Two neural-network estimators (NNEs) are designed to estimate rudders faults and ocean current disturbance respectively. The estimated rudders faults and the estimated ocean current disturbance are utilized to construct the performance index function. By using policy iteration (PI), critic neural network and action neural network are constructed to solve the Hamilton-Jacobi-Bellman (HJB) equation. The error tracking system of AUV is guaranteed to be uniformly ultimately bounded (UUB) based on the Lyapunov stability theorem. Simulation results are given to verify the effectiveness of the control scheme proposed in this paper. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						442	454		10.1016/j.neucom.2020.06.026													
J								DWS-MKL: Depth-width-scaling multiple kernel learning for data classification	NEUROCOMPUTING										Deep learning; Multiple kernel learning; Depth-width-scaling; Span bound		Deep learning technologies have been rapidly developing recently. They have shown excellent performances in many fields. However, deep learning networks have weak adaptability to small sample sizes.Usually, deep learning networks require tens of thousands of samples to avoid overfitting. In con trast, the kernel method can deal with small sample sizes. In this paper, we use only dozens of samples to train a successful classifier. Deep multiple kernel learning (DMKL) has emerged in recent years. It combines the ideas of deep learning and multiple kernel learning. Unfortunately, the DMKL network with a fixed structure cannot adapt to data of different dimensions and sizes. Therefore, in this paper, we propose a novel depth-width-scaling multiple kernel learning (DWS-MKL) algorithm. It has the ability to adjust the architecture according to the input data. We optimize the estimation of leave-one-out error by using the span bound instead of the dual objective function. Finally, we choose a large number of data sets from the UCI benchmark data sets for classification tasks. We also evaluate DWS-MKL on the MNIST data set. The experimental results show that different frameworks have different performances on the same dataset. Our DWS-MKL algorithm obtains better classification results than the state-of-the-art kernel learning algorithms, as determined by a thorough comparison. The encouraging results demonstrate that our method has the potential to improve generalization performance of the model. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						455	467		10.1016/j.neucom.2020.06.039													
J								Adversarial-learning-based image-to-image transformation: A survey	NEUROCOMPUTING										Generative adversarial network; Adversarial learning; Image-to-image transformation	NETWORKS; SUPERRESOLUTION; REMOVAL	Recently, the generative adversarial network (GAN) has attracted wide attention for various computer vision tasks. GAN provides a novel concept for image-to-image transformation by means of adversarial learning. In recent years, numerous adversarial-learning-based methods have been proposed, and impressive results have been achieved. Related reviews have mainly focused on the basic GAN model and its general variants; in contrast, this survey aims to provide an overview of adversarial-learningbased methods by focusing on the image-to-image transformation scenario. First, a brief review of basic GAN is presented; next, the related approaches are roughly divided into adversarial style transfer and adversarial image restoration, e.g., super-resolution, image inpainting, and de-raining. The network architectures of generative models and loss functions are introduced and discussed in detail. Finally, we conclude the survey with an analysis of the trends and challenges. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						468	486		10.1016/j.neucom.2020.06.067													
J								Multi-group formation tracking control via impulsive strategy	NEUROCOMPUTING										Formation control; Multi-agent systems; Exponential stability; Impulsive control; Time-delay	SYSTEMS; CONSENSUS; NETWORKS	This paper addresses multi-group formation tracking (MGFT) control problems for second-order nonlin-ear multi-agent systems (MASs) with multiple leaders via distributed impulsive control methods. The objective is to design formation tracking protocols such that agents divide into multiple subgroups with following different leaders while maintaining desired sub-formation configurations. Distributed impul-sive control protocols are proposed for MGFT control of second-order nonlinear MASs without and with the input delay. In these protocols, information exchanges among agents are only transmitted at impul-sive instants. Based on the Lyapunov stability theory, some sufficient conditions are established to ensure that MASs are globally exponentially stable with and without the input delay, respectively. Examples are given to show the effectiveness of our theoretical results. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						487	497		10.1016/j.neucom.2020.06.046													
J								Impulsive mu-stabilization and mu-synchronization for delayed network systems with any time-varying delays	NEUROCOMPUTING										mu-stabilization; mu-synchronization; Neural network; Chaotic system; Time-varying delay; Impulsive delay inequality	GLOBAL EXPONENTIAL STABILITY; CELLULAR NEURAL-NETWORKS; DIFFERENTIAL-SYSTEMS; INEQUALITY	This paper investigates impulsive mu-stabilization and mu-synchronization for dynamical systems with any time-varying delays. A novel impulsive delay inequality is obtained from impulsive control point of view, which can uniformly deal with any bounded and unbounded time-varying delays, and moreover relaxes the restriction on differentiability of the delays. A criterion is derived to ensure global mu-stability of the addressed neural networks via impulsive control. This inequality is subsequently applied to secure communication systems, and synchronization conditions are presented for global mu-synchronization of coupled chaotic communication systems with any transmission delay and control impulses. The feasibility of the analytical results is finally illustrated by three examples. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						498	509		10.1016/j.neucom.2020.06.022													
J								Infrared head pose estimation with multi-scales feature fusion on the IRHP database for human attention recognition	NEUROCOMPUTING										Head pose estimation; Convolutional neural network; Feature fusion; Attention recognition; Infrared image	VISIBLE IMAGE FUSION; REGRESSION	Head pose estimation (HPE) has been widely applied in human attention recognition, robot vision and assistant driving. Infrared (IR) images bear unique advantages of being still effective under visible scenarios, which are resistance to illumination changing and strong penetration. However, the lack of public IR database hinders the research progress in the low illumination environment. In this paper, we establish a first-of-its-kind infrared head pose (IRHP) database and propose a novel convolutional neural network architecture IRHP-Net on the IRHP database. The IRHP database contains 145 kinds of IR head pose images of subjects, and benchmark evaluations are conducted on our database by the facial features based standard HPE classification methods to prove the usability and effectiveness of IRHP database. To extract the adaptive features for the IR images, a novel multi-scale feature fusion descriptor is developed in the proposed IRHP-Net model. Quantitative assessments of the proposed method on the IRHP images demonstrate the significant improvements over the traditional methods. The new proposed IRHP-Net model can be utilized in human attention recognition and intelligent driving assistant system. (c) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 21	2020	411						510	520		10.1016/j.neucom.2020.06.066													
J								Forecasting and simulation of cutting force in virtual surgery based on particle filtering	APPLIED INTELLIGENCE										Virtual surgery; Haptic interaction; Cutting force simulation; Artificial intelligence; Particle filtering	TIME; EQUIPMENT; CUTS	An accurate and realistic force feedback is very important in determining the realism of virtual surgery. In order to improve the accuracy of force simulation in cutting procedures, we proposed a novel method for forecasting and simulating the cutting force based on a particle filtering (PF) technique. Since the probability density function (PDF) is represented by particles, it is able to estimate accurately the interaction force between the surgical tool and soft tissue during cutting processes. The root mean square error (RMSE) of the PF-based method ranges from 0.0014 to 0.0034, and the mean absolute error (MAE) is less than 0.0399. Comparison of the experiment results with other methods demonstrated that the PF-based method can achieve a higher accuracy with different cutting speeds and angles. The application of the PF-based method to a virtual liver cutting procedure confirmed the effectiveness and accuracy of this method.																	0924-669X	1573-7497															10.1007/s10489-020-01910-1		OCT 2020											
J								The hybridization of ACO plus GA and RVNS algorithm for solving the time-dependent traveling salesman problem	EVOLUTIONARY INTELLIGENCE										TDTSP; GA; ACO; RVND	VEHICLE-ROUTING PROBLEM; FORMULATIONS; SEARCH	The time-dependent traveling salesman problem is a class of combinatorial optimization problems. Naturally, metaheuristic is a suitable approach to solve the problem with large sizes in short computation time. Previously, several metaheuristics have been proposed for solving the problem. These algorithms might have a strong search intensification, and their diversification mechanisms may not be sufficient. Due to the random nature, population-based algorithms improve on the chance of finding a globally. In this paper, we propose a population-based algorithm that combines an ant colony algorithm (ACO), genetic algorithm (GA), and neighborhood descent with random neighborhood ordering (RVND). In the algorithm, the ACO and GA are used to explore the promising solution areas that are yet to refined while the RVND exploits them with the hope of improving a solution. Therefore, our metaheuristic algorithm balances between exploration and exploitation. Extensive numerical experiments and comparisons with the state-of-the-art metaheuristic algorithms in the literature show that the proposed algorithm reaches better solutions in many cases.																	1864-5909	1864-5917															10.1007/s12065-020-00510-9		OCT 2020											
J								Learning an end-to-end spatial grasp generation and refinement algorithm from simulation	MACHINE VISION AND APPLICATIONS										Robot learning; 3d deep learning; Object grasping; Robot vision		Novel object grasping is an important technology for robot manipulation in unstructured environments. For most of current works, a grasp sampling process is required to obtain grasp candidates, combined with a local feature extractor using deep learning. However, this pipeline is time-cost, especially when grasp points are sparse such as at the edge of a bowl. To tackle this problem, our algorithm takes the whole sparse point clouds as the input and requires no sampling or search process. Our work is combined with two steps. The first step is to predict poses, categories and scores (qualities) based on a SPH3D-GCN network. The second step is an iterative grasp pose refinement, which is to refine the best grasp generated in the first step. The whole weight sizes for these two steps are only about 0.81M and 0.52M, which takes about 73 ms for a whole prediction process including an iterative grasp pose refinement using a GeForce 840M GPU. Moreover, to generate training data of multi-object scene, a single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) combined with thin structures grasp planning are generated. Our experiment shows our work gets 76.67% success rate and 94.44% completion rate, which performs better than current state-of-the-art works.																	0932-8092	1432-1769				OCT 20	2020	32	1							10	10.1007/s00138-020-01127-9													
J								Design of a supply chain network for determining the optimal number of items at the inventory groups based on ABC analysis: a comparison of exact and meta-heuristic methods	NEURAL COMPUTING & APPLICATIONS										ABC analysis; Bi-objective optimization; Three-level supply chain; Heuristic and meta-heuristic methods	CLASSIFICATION; MODEL; SYSTEM; HEALTH	One of the most applicable techniques in the inventory management field is inventory classification based on ABC analysis, a well-known method to set the items in a different group, according to their importance and values. In this paper, a bi-objective mathematical model is proposed to improve the inventory grouping based on ABC analysis. The first objective function maximizes the total net profit of the items in the central stock, and the second objective function maximizes the total net profit of items in different wards. The proposed model simultaneously optimizes the service level, the number of inventory groups, and the number of assigned items. To solve the model in small and large dimensions, two exact methods (LP-metric and epsilon-constraint) and two meta-heuristic methods (NSGA-II and MOPSO) are used. Then, to compare those methods in terms of efficiency, the statistical analysis besides the AHP and VIKOR techniques is implemented. The results show the superiority of the epsilon-constraint among the exact methods and MOPSO among meta-heuristic methods. Finally, the proposed model has been implemented in two sets of numerical examples to demonstrate its applicability.																	0941-0643	1433-3058															10.1007/s00521-020-05428-y		OCT 2020											
J								Copy-move forgery detection technique based on discrete cosine transform blocks features	NEURAL COMPUTING & APPLICATIONS										Cope-move forgery; Digital images; Discrete cosine transforms; Forgery detection	DOUBLE JPEG COMPRESSION; DCT	With the increasing number of software applications that allow altering digital images and their ease of use, they weaken the credibility of an image. This problem, together with the ease of distributing information through the Internet (blogs, social networks, etc.), has led to a tendency for information to be accepted as true without its veracity being questioned. Image counterfeiting has become a major threat to the credibility of the information. To deal with this threat, forensic image analysis is aimed at detecting and locating image forgeries using multiple clues that allows it to determine the veracity or otherwise of an image. In this paper, we present a method for the authentication of images. The proposed method performs detection of copy-move alterations within an image, using the discrete cosine transform. The characteristics obtained from these coefficients allow us to obtain transfer vectors, which are grouped together. Through the use of a tolerance threshold, it is possible to determine whether there are regions copied and pasted within the analysed image. The results obtained from the experiments reported in this paper demonstrate the effectiveness of the proposed method. For the evaluation of the proposed methods, experiments were carried out with public databases of falsified images that are widely used in the literature.																	0941-0643	1433-3058															10.1007/s00521-020-05433-1		OCT 2020											
J								From artificial neural networks to deep learning for music generation: history, concepts and trends	NEURAL COMPUTING & APPLICATIONS										Artificial neural networks; Deep learning; Music; Generation; Tutorial; Concepts; History; Trends		The current wave of deep learning (the hyper-vitamined return of artificial neural networks) applies not only to traditional statistical machine learning tasks: prediction and classification (e.g., for weather prediction and pattern recognition), but has already conquered other areas, such as translation. A growing area of application is the generation of creative content, notably the case of music, the topic of this article. The motivation is in using the capacity of modern deep learning techniques to automatically learn musical styles from arbitrary musical corpora and then to generate musical samples from the estimated distribution, with some degree of control over the generation. This article provides a tutorial on music generation based on deep learning techniques. After a short introduction to the topic illustrated by a recent example, the article analyzes some early works from the late 1980s using artificial neural networks for music generation and how their pioneering contributions foreshadowed current techniques. Then, we introduce some conceptual framework to analyze various concepts and dimensions involved. Various examples of recent systems are introduced and analyzed to illustrate the variety of concerns and of techniques.																	0941-0643	1433-3058															10.1007/s00521-020-05399-0		OCT 2020											
J								Classification of operation cases in electric arc welding wachine by using deep convolutional neural networks	NEURAL COMPUTING & APPLICATIONS										Welding; Deep convolutional neural network; Graphical image; Pre-trained; Alexnet; Googlenet; Squeezenet; Resnet18	OPTIMIZATION; PREDICTION; PARAMETERS; GEOMETRY; BEAD	Electric arc welding machines are widely used in industry in metal technology. In parallel with the advancement of technology for the development and automation of electric arc welding machines, it is necessary to conduct scientific studies on the determination of optimal operation cases and control for optimal welding process. In this study, operating zones were classified and determined according to the measured welding current graph during the 5-s operation of the MAG electric arc welding machine. Five deep convolutional neural networks were used for this purpose. Four of these deep learning methods are pre-trained models. We used the concept of "ransfer learning" to use pre-trained models. According to the results we obtained from five different models, we were able to estimate the operating range of the electric arc welding machine, with 93.5% accuracy with the designed model and 95-100% accuracy with pre-trained models.																	0941-0643	1433-3058															10.1007/s00521-020-05436-y		OCT 2020											
J								Latent Timbre Synthesis Audio-based variational auto-encoders for music composition and sound design applications	NEURAL COMPUTING & APPLICATIONS										Audio synthesis; Neural networks; Signal processing; Computer assisted music composition		We present the Latent Timbre Synthesis, a new audio synthesis method using deep learning. The synthesis method allows composers and sound designers to interpolate and extrapolate between the timbre of multiple sounds using the latent space of audio frames. We provide the details of two Variational Autoencoder architectures for the Latent Timbre Synthesis and compare their advantages and drawbacks. The implementation includes a fully working application with a graphical user interface, calledinterpolate_two, which enables practitioners to generate timbres between two audio excerpts of their selection using interpolation and extrapolation in the latent space of audio frames. Our implementation is open source, and we aim to improve the accessibility of this technology by providing a guide for users with any technical background. Our study includes a qualitative analysis where nine composers evaluated the Latent Timbre Synthesis and theinterpolate_twoapplication within their practices.																	0941-0643	1433-3058															10.1007/s00521-020-05424-2		OCT 2020											
J								Systematic Homonym Detection and Replacement Based on Contextual Word Embedding	NEURAL PROCESSING LETTERS										Homonym detection; Contextual word embedding; Word-clustering based document embedding; Spherical k-means clustering; ELMo	AUTHOR NAME DISAMBIGUATION; ERROR-DETECTION; DOMAIN	Homonyms are words that share their spelling but differ in meaning and are a common feature in most languages. Homonyms are a source of noise i most text analyses and are difficult to detect; numerous studies have been conducted in this regard. However, extant methods typically detect homonyms using a rule-based or statistical-based approach, which requires an answer set, with little regard to the semantic meaning of the word. Therefore, we propose a novel approach for the detection of homonyms based on contextual word embedding that allows a word to be understood based on the context in which it appears. In this study, we extracted all contextual word embedding vectors of individual words and clustered those vectors using a spherical k-means clustering to detect pairs of homonyms. In addition, we developed a homonym replacement method to increase the performance of a document embedding technique, based on the word vector value. We replaced the embedding vectors of homonyms with a representative vector based on the respective meaning using the proposed homonym detection method. Experimental results indicate that the proposed method effectively detects homonyms and significantly improves the performance of document embedding.																	1370-4621	1573-773X															10.1007/s11063-020-10376-8		OCT 2020											
J								A new approach for the vanishing gradient problem on sigmoid activation	PROGRESS IN ARTIFICIAL INTELLIGENCE										Vanishing gradient problem; Sigmoid function; Feedforward neural networks; Backpropagation algorithm		The vanishing gradient problem (VGP) is an important issue at training time on multilayer neural networks using the backpropagation algorithm. This problem is worse when sigmoid transfer functions are used, in a network with many hidden layers. However, the sigmoid function is very important in several architectures such as recurrent neural networks and autoencoders, where the VGP might also appear. In this article, we propose a modification of the backpropagation algorithm for the sigmoid neurons training. It consists of adding a small constant to the calculation of the sigmoid's derivative so that the proposed training direction differs slightly from the gradient while keeping the original sigmoid function in the network. This approach suggests that the derivative's modification produces the same accuracy in fewer training steps on most datasets. Moreover, due to VGP, the original derivative does not converge using sigmoid functions on more than five hidden layers. However, the modification allows backpropagation to train two extra hidden layers in feedforward neural networks.																	2192-6352	2192-6360															10.1007/s13748-020-00218-y		OCT 2020											
J								Simulation based study on parameter variation of Si(0.9)Ge(0.1)junction-lessSELBOX FinFETfor high-performance application	COMPUTATIONAL INTELLIGENCE										DIBL; JLFinFET; SELBOX; SOI and UTB; SS	STRAINED SI; SUBSTRATE; GE	In this article, we present a high-performance SiGe junctionless FinFET (JLFinFET) on insulator by selective growth of buried oxide (SELBOX) layer device with better electrostatics. The mole fractionx = 0.1, 0.2, 0.3, 0.4, 0.5, and 0.7 with fin width 10 nm and gate length of 20 nm are considered for simulation using technology computer aided design (TCAD) Sentaurus device. With Si(0.9)Ge(0.1)JLFinFET on insulator by SELBOX layer, nearly an ideal subthreshold swing of 61.51 mV/decade and enhanced on-current, off-current has been achieved. Evaluation of on-off current ratio, DIBL, SS for different parameters, such as doping concentration (10(15)-10(19)/cm(3)), channel length (10-40 nm), temperature (200-700 degrees K) on JLJFinFET on insulator by SELBOX layer are presented. Three-dimensional device simulation using the TCAD software tool Sentaurus Device is used to simulate and the results are compared with a SELBOX JLFinFET.																	0824-7935	1467-8640															10.1111/coin.12416		OCT 2020											
J								Mining specific and representative information by the attribute-oriented induction method	EXPERT SYSTEMS										attribute-oriented induction; concept hierarchy; cost; data mining; noise	KNOWLEDGE DISCOVERY; REDUCTION; DATABASES	Attribute-oriented induction (AOI) is a data analysis technique based on induction. The traditional AOI algorithm requires a threshold given by users to determine the number of output tuples. However, it is not easy to set an appropriate tuple threshold, and there is usually noise contained in a dataset. The traditional AOI algorithm can only generate a summary output of a fixed size, but it cannot guarantee that all generalized tuples have sufficient specificity and representativeness. In this article, a new AOI method is proposed to make up for the shortcomings. We introduce the concept of cost to measure the loss of accuracy due to attribute ascension. We also propose two algorithms based on the hierarchical clustering method. By setting cost constraints on each generalized tuple, our method can generate accurate output while eliminating noise, and help users get more informative and clearer results.																	0266-4720	1468-0394														e12643	10.1111/exsy.12643		OCT 2020											
J								A novel distance measure for intuitionistic fuzzy sets with diverse applications	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										COVID-19; distance measure; face mask selection; intuitionistic fuzzy sets; medical diagnosis; multi-attributes decision making; pattern recognition	SIMILARITY MEASURES	Distance function is a canonical quantitative tool to measure the similarity or difference between two intuitionistic fuzzy sets (IFSs). In spite of having a vast range of such tools, one fails to distinguish accurately the IFSs with higher hesitancy. In view of that, we introduce a distance function for IFSs and validate the axiomatic definition of it. Boundedness and nonlinear characteristics of the proposed distance measure are corroborated. Moreover, its efficacy is not restricted to highly uncertain IFSs only, but it is equally effective in other cases, which is testified via some numerical examples. We establish the veracity of the prescribed distance by comparing it with reported results through some illustrative examples. In light of recent COVID-19 pandemic, selection of a proper antivirus face mask has become a daunting task, which is addressed via the introduced distance measure as a multi-attribute decision-making problem. We further extend the applicability of the proposed distance in the areas of pattern recognition and medical diagnosis.																	0884-8173	1098-111X															10.1002/int.22312		OCT 2020											
J								A hybrid ARIMA-LSTM model optimized by BP in the forecast of outpatient visits	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Hybrid forecasting model; Neural networks; ARIMA; LSTM; BP; Outpatient visits		Effective hospital outpatient forecasting is an important prerequisite for modern hospitals to implement intelligent management of medical resources. As outpatient visits flow may be complex and diverse volatility, we propose a hybrid Autoregressive Integrated Moving Average (ARIMA)-Long Short Term Memory (LSTM) model, which hybridizes the ARIMA model and LSTM model to obtain the linear tendency and nonlinear tendency correspondingly. Instead of the traditional methods that artificially assume the linear components and nonlinear components should be linearly added, we propose employing backpropagation neural networks (BP) to imitate the real relationship between them. The proposed hybrid model is applied to real data analysis and experimental analysis to justify its performance against single ARIMA model, single LSTM model and the hybrid ARIMA-LSTM model based on the traditional method. Compared with competitors, the proposed hybrid model produced the lowest RMSE, MAE and MAPE. It achieves more accurate and stable prediction. Therefore, the proposed model can be a promising alternative in outpatient visit predictive problems.																	1868-5137	1868-5145															10.1007/s12652-020-02602-x		OCT 2020											
J								Effects of video type, display technique, and ambient illumination on visual and physiological performance	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Video type; Display technique; Ambient illumination; Visual fatigue; Presence	BENDING CURVATURE; HEART-RATE; 3D; LEGIBILITY; EXPERIENCE; SICKNESS; FATIGUE; COMFORT; IMPACT; LIGHT	With the promotion of technology, 3D displays not only offer high-end video and sound qualities, but also provide larger-than-life viewing experiences. Twenty-five participants were recruited to investigate the effect of video type (horror, action, and comedy), display technique (2D, 3D), and ambient illumination (a dark room, 1500 lux) on saccade length, number of fixations, Simulator Sickness Questionnaire (SSQ), iGroup Presence Questionnaire (IPQ), and change of heart rate. The results showed that video type was significant on SSQ and IPQ, where horror videos showed the greatest effects on SSQ and IPQ. In addition, display technique was significant on number of fixations, SSQ, IPQ, and change of heart rate, where the 3D technique resulted in a higher number of fixations, SSQ, IPQ, and change of heart rate. Furthermore, ambient illumination was significant on number of fixations, IPQ, and change of heart rate, where a dark room led to a higher number of fixations, IPQ, and change of heart rate. The main contribution of this study is that it offers suggestions for choosing the appropriate video type, display technique, and ambient illumination when watching 3D movies-namely, for 3D film manufacturers, using horror videos in a dark environment brings greater realness and presence, but also results in higher visual fatigue and change of heart rate.																	1868-5137	1868-5145															10.1007/s12652-020-02609-4		OCT 2020											
J								A novel violation detection method of live video using fuzzy support vector machine	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Violation video detection; Multi-modal features; FSVM; Noise immunity	SKIN-COLOR; MIXTURE MODEL; CLASSIFICATION; IMAGE	In order to prevent the illegal videos from being posted on the Internet and causing adverse effects, video sites need to manually review each newly released video. The manual review is time-consuming and labor-intensive, and is prone to omissions. Against this background, this article intends to propose a method for automatically detecting illegal content in videos. Automatic video detection can greatly reduce the work of auditors and improve detection efficiency. This study proposes a multi-modal fusion feature violation video detection method using fuzzy support vector machine (FSVM). First, extract multiple modal features of live video, including still image features, motion features, and audio features. Secondly, FSVM is used to classify the feature data of various modalities to obtain the classification results under different modalities. Finally, the classification results in different modes are merged to obtain the final decision result. The innovation of this study is that the introduction of multiple modal features enriches the sample information, making the sample information more comprehensive. Which is easy to distinguish. The classifier FSVM is based on the traditional SVM to assign a degree of membership to each sample, thereby reducing the impact of isolated points and noise on the optimal decision surface. Experiments show that this study improves the detection efficiency of illegal videos and can meet the requirements of practical applications.																	1868-5137	1868-5145															10.1007/s12652-020-02613-8		OCT 2020											
J								Addressing the New Item problem in video recommender systems by incorporation of visual features with restricted Boltzmann machines	EXPERT SYSTEMS										cold start; multimedia; new item; recommender systems; visually aware	OF-THE-ART; COLD-START; MATRIX FACTORIZATION; FRAMEWORK	Over the past years, the research of video recommender systems (RSs) has been mainly focussed on the development of novel algorithms. Although beneficial, still any algorithm may fail to recommend video items that the system has no form of data associated to them (New Item Cold Start). This problem occurs when a new item is added to the catalogue of the system and no data are available for that item. In content-based RSs, the video items are typically represented by semantic attributes, when generating recommendations. These attributes require a group of experts or users for annotation, and still, the generated recommendations might not capture a complete picture of the users' preferences, for example, the visual tastes of users on video style. This article addresses this problem by proposing recommendation based on novel visual features that do not require human annotation and can represent visual aspects of video items. We have designed a novel evaluation methodology considering three realistic scenarios, that is, (a) extreme cold start, (b) moderate cold start and (c) warm-start scenario. We have conducted a set of comprehensive experiments, and our results have shown the superior performance of recommendations based on visual features, in all of the evaluation scenarios.																	0266-4720	1468-0394														e12645	10.1111/exsy.12645		OCT 2020											
J								One-dimensional convolutional neural networks for high-resolution range profile recognition via adaptively feature recalibrating and automatically channel pruning	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										channel attention; channel pruning; convolution neural networks; global best leading artificial bee colony; high-resolution range profile	HRRP TARGET RECOGNITION	High-resolution range profile (HRRP) has obtained intensive attention in radar target recognition and convolutional neural networks (CNNs) are among predominant approaches to deal with HRRP recognition problems. However, most CNNs are designed by the rule-of-thumb and suffer from much more computational complexity. Aiming at enhancing the channels of one-dimensional CNN (1D-CNN) for extracting efficient structural information oftargets form HRRP and reducing the computation complexity, we propose a novel framework for HRRP-based target recognition based on 1D-CNN with channel attention and channel pruning. By introducing an aggregation-perception-recalibration (APR) block for channel attention to the 1D-CNN backbone, channels in each 1D convolutional layer can adaptively learn to recalibrate the extracted features for enhancing the structural information captured from HRRP. To avoid rule-of-thumb design and reduce the computation complexity of 1D-CNN, we proposed a new method incorporated withthe global best leading artificial bee colony (GBL-ABC) to prune the original network based on the lottery ticket hypothesis in an automatic and heuristic manner. The extensive experimental results on the measured data illustrate that the proposed algorithm achievesthe superiorrecognition rate by combing APR and GBL-ABC simultaneously.																	0884-8173	1098-111X															10.1002/int.22302		OCT 2020											
J								Multi-task gradient descent for multi-task learning	MEMETIC COMPUTING										Multi-task gradient descent; Knowledge transfer; Multi-task learning; Multi-label learning	LABEL; CLASSIFICATION	Multi-Task Learning (MTL) aims to simultaneously solve a group of related learning tasks by leveraging the salutary knowledge memes contained in the multiple tasks to improve the generalization performance. Many prevalent approaches focus on designing a sophisticated cost function, which integrates all the learning tasks and explores the task-task relationship in a predefined manner. Different from previous approaches, in this paper, we propose a novel Multi-task Gradient Descent (MGD) framework, which improves the generalization performance of multiple tasks through knowledge transfer. The uniqueness of MGD lies in assuming individual task-specific learning objectives at the start, but with the cost functionsimplicitlychanging during the course of parameter optimization based on task-task relationships. Specifically, MGD optimizes the individual cost function of each task using a reformative gradient descent iteration, where relations to other tasks are facilitated through effectively transferring parameter values (serving as the computational representations of memes) from other tasks. Theoretical analysis shows that the proposed framework is convergent under any appropriate transfer mechanism. Compared with existing MTL approaches, MGD provides a novel easy-to-implement framework for MTL, which can mitigate negative transfer in the learning procedure by asymmetric transfer. The proposed MGD has been compared with both classical and state-of-the-art approaches on multiple MTL datasets. The competitive experimental results validate the effectiveness of the proposed algorithm.																	1865-9284	1865-9292															10.1007/s12293-020-00316-3		OCT 2020											
J								Output Layer Multiplication for Class Imbalance Problem in Convolutional Neural Networks	NEURAL PROCESSING LETTERS										Convolutional neural networks; Imbalance learning; Output layer multiplication	SAMPLING APPROACH	Convolutional neural networks (CNNs) have demonstrated remarkable performance in the field of computer vision. However, they are prone to suffer from the class imbalance problem, in which the number of some classes is significantly higher or lower than that of other classes. Commonly, there are two main strategies to handle the problem, including dataset-level methods via resampling and algorithmic-level methods by modifying the existing learning frameworks. However, most of these methods need extra data resampling or elaborate algorithm design. In this work we provide an effective but extremely simple approach to tackle the imbalance problem in CNNs with cross-entropy loss. Specifically, we multiply a coefficient alpha >1 to output of the last layer in a CNN model. With this modification, the final loss function can dynamically adjust the contributions of examples from different classes during the imbalanced training procedure. Because of its simplicity, the proposed method can be easily applied in the off-the-shelf models with little change. To prove the effectiveness on imbalance problem, we design three experiments on classification tasks of increasing complexity. The experimental results show that our approach could improve the convergence rate in the training stage and/or increase accuracy for test.																	1370-4621	1573-773X															10.1007/s11063-020-10366-w		OCT 2020											
J								Exploring Implicit and Explicit Geometrical Structure of Data for Deep Embedded Clustering	NEURAL PROCESSING LETTERS										Deep neural networks; Stacked autoencoder; Manifold constraint; Clustering		Clustering is an essential data analysis technique and has been studied extensively over the last decades. Previous studies have shown that data representation and data structure information are two critical factors for improving clustering performance, and it forms two important lines of research. The first line of research attempts to learn representative features, especially utilizing the deep neural networks, for handling clustering problems. The second concerns exploiting the geometric structure information within data for clustering. Although both of them have achieved promising performance in lots of clustering tasks, few efforts have been dedicated to combine them in a unified deep clustering framework, which is the research gap we aim to bridge in this work. In this paper, we propose a novel approach, Manifold regularized Deep Embedded Clustering (MDEC), to deal with the aforementioned challenge. It simultaneously models data generating distribution, cluster assignment consistency, as well as geometric structure of data in a unified framework. The proposed method can be optimized by performing mini-batch stochastic gradient descent and back-propagation. We evaluate MDEC on three real-world datasets (USPS, REUTERS-10K, and MNIST), where experimental results demonstrate that our model outperforms baseline models and obtains the state-of-the-art performance.																	1370-4621	1573-773X															10.1007/s11063-020-10375-9		OCT 2020											
J								A multi-task pipeline with specialized streams for classification and segmentation of infection manifestations in COVID-19 scans	PEERJ COMPUTER SCIENCE										COVID-19; Deeplab; Medical imaging; Pneumonia; Transfer learning; Multimodal learning	FEATURES	We are concerned with the challenge of coronavirus disease (COVID-19) detection in chest X-ray and Computed Tomography (CT) scans, and the classification and segmentation of related infection manifestations. Even though it is arguably not an established diagnostic tool, using machine learning-based analysis of COVID-19 medical scans has shown the potential to provide a preliminary digital second opinion. This can help in managing the current pandemic, and thus has been attracting significant research attention. In this research, we propose a multi-task pipeline that takes advantage of the growing advances in deep neural network models. In the first stage, we fine-tuned an Inception-v3 deep model for COVID-19 recognition using multi-modal learning, that is, using X-ray and CT scans. In addition to outperforming other deep models on the same task in the recent literature, with an attained accuracy of 99.4%, we also present comparative analysis for multi-modal learning against learning from X-ray scans alone. The second and the third stages of the proposed pipeline complement one another in dealing with different types of infection manifestations. The former features a convolutional neural network architecture for recognizing three types of manifestations, while the latter transfers learning from another knowledge domain, namely, pulmonary nodule segmentation in CT scans, to produce binary masks for segmenting the regions corresponding to these manifestations. Our proposed pipeline also features specialized streams in which multiple deep models are trained separately to segment specific types of infection manifestations, and we show the significant impact that this framework has on various performance metrics. We evaluate the proposed models on widely adopted datasets, and we demonstrate an increase of approximately 2.5% and 4.5% for dice coefficient and mean intersection-over-union (mIoU), respectively, while achieving 60% reduction in computational time, compared to the recent literature.																	2376-5992					OCT 19	2020									e303	10.7717/peerj-cs.303													
J								A part-based spatial and temporal aggregation method for dynamic scene recognition	NEURAL COMPUTING & APPLICATIONS										Dynamic scene recognition; Feature aggregation; Deep neural networks; Part-based models		Existing methods for dynamic scene recognition mostly use global features extracted from the entire video frame or a video segment. In this paper, a part-based method is proposed to aggregate local features from video frames. A pre-trained Fast R-CNN model is used to extract local convolutional features from the regions of interest of training images. These features are clustered to locate representative parts. A set cover problem is then formulated to select the discriminative parts, which are further refined by fine-tuning the Fast R-CNN model. Local features from a video segment are extracted at different layers of the fine-tuned Fast R-CNN model and aggregated both spatially and temporally. Extensive experimental results show that the proposed method is very competitive with state-of-the-art approaches.																	0941-0643	1433-3058															10.1007/s00521-020-05415-3		OCT 2020											
J								Circle-based Group Recommendation in Social Networks	SOFT COMPUTING										Group recommender systems; Genetic algorithm; Social factors; Status; Circles	OF-THE-ART; SYSTEMS	A large amount of data available on Web has proven to be an immense resource for innovative recommender system (RS) techniques and concepts. The traditional recommender system intended to provide recommendations for a single user. However, in certain domains the recommendation is required for a group of users. As to provide better recommendations for a group of users, we leverage the concept ofcirclesin a network. In this work, we use the genetic algorithm (GA)K_Meansclustering algorithm to generate social circles in a network. Then, we compute thestatusof each user in these overlapping circles. Finally, a circle-based group recommendation approach is used to generate the final group recommendation. The results obtained on theEpinionsdataset validate the eminence of the proposed model over traditional approaches of group recommendation.																	1432-7643	1433-7479															10.1007/s00500-020-05356-y		OCT 2020											
J								A topic-based hierarchical publish/subscribe messaging middleware for COVID-19 detection in X-ray image and its metadata	SOFT COMPUTING										Capsule networks; Topic-based hierarchical publish; subscribe; COVID-19 detection; Hybrid intelligence; X-ray images; Medical data management	BIG-DATA; CORONAVIRUS; HEALTH; WUHAN	Putting real-time medical data processing applications into practice comes with some challenges such as scalability and performance. Processing medical images from different collaborators is an example of such applications, in which chest X-ray data are processed to extract knowledge. It is not easy to process data and get the required information in real time using central processing techniques when data get very large in size. In this paper, real-time data are filtered and forwarded to the right processing node by using the proposed topic-based hierarchical publish/subscribe messaging middleware in the distributed scalable network of collaborating computation nodes instead of classical approaches of centralized computation. This enables processing streaming medical data in near real time and makes a warning system possible. End users have the capability of filtering/searching. The returned search results can be images (COVID-19 or non-COVID-19) and their meta-data are gender and age. Here, COVID-19 is detected using a novel capsule network-based model from chest X-ray images. This middleware allows for a smaller search space as well as shorter times for obtaining search results.																	1432-7643	1433-7479															10.1007/s00500-020-05387-5		OCT 2020											
J								Efficient energy consumption system using heuristic renewable demand energy optimization in smart city	COMPUTATIONAL INTELLIGENCE										energy storage system; IoT; renewable energy; smart city	MANAGEMENT; ALGORITHMS; BUILDINGS; CITIES; CLOUD	The rapid growth of urban development in recent years required reliable as well as realistic smart solutions to transport, system infrastructure, environmental conditions, and quality of life in smart cities. Furthermore, several innovative and comprehensive applications for smart cities are accessible through the Internet of Things that plays a significant role in reducing the utilization of energy requirements and other environmental effects. Based on the demands in reducing energy consumption, this article designed and developed a combined heat and power design based on the renewable energy system and energy storage system, which helps to minimize the utilization of energy consumption in smart cities. In these concerns, a standardized heuristic renewable demand energy optimization in the smart city (HRDEOSC) architecture is presented, where the smart area domain is distributed into a wide area network. In comparison with the overall domestic energy consumption of electricity and transport, the energy demand for desalination processes is very small and it has been achieved by HRDEOSC. Here, the designed computational model demonstrate that the developed system contributes significantly to our challenges and proved to be an economical approach for the development of the smart structural design which helps to reduce the energy consumption of smart cities.																	0824-7935	1467-8640															10.1111/coin.12412		OCT 2020											
J								Identification and eradication of attacker node in a mobile ad-hoc network environment using prediction model on delay factor	EVOLVING SYSTEMS										MANET; Prediction model; Delay; Malicious factor	TRUST MANAGEMENT; BLACKHOLE ATTACK; ALGORITHMS; SECURITY; MANETS	Mobile ad-hoc network (MANET) is a theoretical and experimental approach for achieving the applications to the best using VANETs. Given the mobility of nodes in the mobile ad-hoc networks, it is hard to depict the nature of the network or the structure of the network. With static nodes, it is easy to monitor a network. In a mobile environment, any node can come and join the network based on the distance covered by the entire network. A node that enters the region joins the network, while one that moves away leaves it and ceases participating in network communication. The routing table is updated, based on the movement of the nodes. Owing to the factors above, security fails to live up to expectations. Identifying a vulnerable node is a difficult proposition. This paper offers a prediction model based on the delay factor, which impacts the performance of the node and its network. The experimental results determine the malicious node. A malicious node is disconnected from the network.																	1868-6478	1868-6486															10.1007/s12530-020-09358-x		OCT 2020											
J								Detecting Ordinal Subcascades	NEURAL PROCESSING LETTERS										Ordinal classification; Classifier cascades; Error bounds; Subsets; Supersets	ORGANIZING MAPS; CLASSIFICATION; SELECTION; LEUKEMIA; CANCER; CELLS	Ordinal classifier cascades are constrained by a hypothesised order of the semantic class labels of a dataset. This order determines the overall structure of the decision regions in feature space. Assuming the correct order on these class labels will allow a high generalisation performance, while an incorrect one will lead to diminished results. In this way ordinal classifier systems can facilitate explorative data analysis allowing to screen for potential candidate orders of the class labels. Previously, we have shown that screening is possible for total orders of all class labels. However, as datasets might comprise samples of ordinal as well as non-ordinal classes, the assumption of a total ordering might be not appropriate. An analysis of subsets of classes is required to detect such hidden ordinal substructures. In this work, we devise a novel screening procedure for exhaustive evaluations of all order permutations of all subsets of classes by bounding the number of enumerations we have to examine. Experiments with multi-class data from diverse applications revealed ordinal substructures that generate new and support known relations.																	1370-4621	1573-773X															10.1007/s11063-020-10362-0		OCT 2020											
J								Conflict resolution using game theory and rough sets	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										conflict analysis; game-theoretic rough sets; multicriteria decision making; Nash equilibrium	MODEL	Conflicts occur naturally in the real world at all levels of society, individually, in groups or society as a whole. Almost all the existing conflict resolution models are unilateral in their decision-making process. They do not consider the actions of the involved parties simultaneously. Therefore, in this paper, we aim to design a novel conflict resolution model based on game-theoretic rough sets by constructing a game between all the concerned parties (players), computing the payoff of different strategies and classifying them following equilibrium rules. The proposed model yields more realistic and accurate results as it explores all possibilities and is flexible in determining different threshold values relative to the complexities of real-life problems. Three real-life conflict situations are solved with the proposed model, and a comprehensive analysis is done to validate the effectiveness of the proposed approach.																	0884-8173	1098-111X															10.1002/int.22298		OCT 2020											
J								A multi-level AI-based scheduler to increase adaptiveness in time-constrained mobile communication environments	NATURAL COMPUTING										Real-time scheduling; AI planner; Mobile computing; Multi-level architecture	BROADCAST; DISSEMINATION; ALGORITHMS	Scheduling is one of the classic problems in real-time adaptive systems. Due to the complex nature of these applications, the implementation of some sort of run-time intelligence is required, in order to build intelligent systems capable of operating adequately in dynamic environments. The incorporation of artificial intelligence planning techniques in a real-time scenario allows a timely reaction to external and internal events. In this work, a layered architecture integrating real-time scheduling at the bottom level and artificial intelligence planning techniques at the top level has been designed, to implement a multi-level scheduler with the capability to perform effectively in this kind of situation. This multi-level scheduler has been implemented and evaluated in a simulated information access system destined to broadcast information to mobile users in a time-constrained communication environment, modeling mobile users' realistic information access patterns. Results show that the incorporation of artificial intelligence planning improves the overall performance, adaptiveness, and responsiveness with respect to the non-AI-based scheduler version of the system.																	1567-7818	1572-9796															10.1007/s11047-020-09813-3		OCT 2020											
J								An effective method using clustering-based adaptive decomposition and editing-based diversified oversamping for multi-class imbalanced datasets	APPLIED INTELLIGENCE										Multi-class imbalance; Overlapping problem; Clustering; Oversampling	VS-ONE STRATEGY; CLASSIFICATION; SELECTION; DISTANCE	For multi-class imbalanced classification tasks that occur in many real-world applications, the class imbalance, which is caused by the case that some classes are not as frequent as other classes, and class overlap, which is caused by the case that some classes contains a similar number of data, are the major challenges. Both of them make the classification task complicated. The decomposition-based strategy is an effective way to improve the performance of multi-class imbalanced classification tasks. However, current studies based on this strategy have failed to solve the problems of class imbalance and overlapping simultaneously. Therefore, we propose an effective method , namely clustering-based adaptive decomposition and editing-based diversified oversamping procedure(CluAD-EdiDO), to solve the above problems in this paper. The proposed CluAD-EdiDO consists of two key components: the clustering-based adaptive decomposition and the editing-based diversified oversampling technique. The former is applied to group similar data samples of the data set into clusters(i.e., "sub-problems"). The latter is applied independently in different clusters to combat the imbalance and overlap, reducing the impact of the majority classes in overlapping region and oversampling the minority classes appropriately. Furthermore, a diversified ensemble learning framework is adopted to select the best classification algorithm for different sub-problems. Extensive experiments on 17 real-world datasets demonstrate that our method outperforms for multi-class imbalanced datasets.																	0924-669X	1573-7497															10.1007/s10489-020-01883-1		OCT 2020											
J								Exploiting multi-attention network with contextual influence for point-of-interest recommendation	APPLIED INTELLIGENCE										Point-of-interest; Recommendation system; Attention network; Collaborative filtering; Contextual information	MATRIX FACTORIZATION	Point-of-Interest (POI) recommendation has become an important service on Location-Based Social Networks (LBSNs). In order to improve the performance of recommendation, besides the check-in data generated in LBSNs, researchers are striving to exploit various auxiliary information such as social relation among users and geographical influence among neighbourhood POIs. However, existing works cannot effectively study the diverse degrees of influence from user's friends, neither are they able to capture the feature impacts of POIs in the preference modelling process. To overcome these challenges, by making use of aMulti-AttentionNetwork to learn theContextual influence of both users and POIs, this paper presents a model named MANC for POI recommendation. The MANC model consists of two parts: a user-friend module and a POI neighbourhood module. Unlike existing works which treat the influences from different friends of a user equally, the user-friend module in MANC applies an attention-based memory component to generate specific relation vectors which can differentiate the influence from the aspect of interest, and applies a friend-level attention network to adaptively capture the preferences of users. For the POI contextual information, the POI neighbourhood module in MANC applies a feature-level attention network to capture the latent features of neighbourhood POIs, and applies a POI-level attention network to capture the geographical influence among POIs. Extensive experiments are carried out, and it is shown that the MANC model achieves better performance than other state-of-the-art methods.																	0924-669X	1573-7497															10.1007/s10489-020-01868-0		OCT 2020											
J								FB-GSA: A fuzzy bi-level programming based gravitational search algorithm for unconstrained optimization	APPLIED INTELLIGENCE										Nature-inspired computing; Exploration and exploitation; Chaotic gravitational search algorithm; Local search; Polak-ribire-polyak-3 method; Fuzzy bi-level programming	CONJUGATE-GRADIENT METHOD	The Gravitational Search Algorithm (GSA) which is a prominent nature-inspired computing technique outperforms in the exploration stage, but its performance degrades in the exploitation stage. A fuzzy bi-level programming based gravitational search algorithm (FB-GSA) is proposed in this study. The basic concept to create FB-GSA is the iterative fuzzy decision-making operation. FB-GSA accompanies the algorithms such as Chaotic Gravitational Search Algorithm (CGSA), and the proposed local search using spectral Polak-Ribire-Polyak-3 (spectral PRP-3) method. Initially, the adaptive parameters, for the fuzzy decision-making process, are determined. Then, the controlled operation of constituent algorithms is executed using fuzzy Bi-level logic, which leads to an optimal solution. Experimental evaluation of FB-GSA is performed using several unimodal and multi-modal benchmark functions. Experimental results illustrate that FB-GSA outperforms other state-of-art works for most benchmarks. The simulation results for FB-GSA also presents a significant improvement in the convergence speed. The fuzzy-based adaptive control employed in FB-GSA makes it devoid of premature convergence.																	0924-669X	1573-7497															10.1007/s10489-020-01884-0		OCT 2020											
J								Cluster-based information retrieval using pattern mining	APPLIED INTELLIGENCE										Information retrieval; Data mining; Cluster-based approaches; Frequent and high-utility pattern mining	MAXSAT PROBLEM; FREQUENT; RANKING; MODEL	This paper addresses the problem of responding to user queries by fetching the most relevant object from a clustered set of objects. It addresses the common drawbacks of cluster-based approaches and targets fast, high-quality information retrieval. For this purpose, a novel cluster-based information retrieval approach is proposed, named Cluster-based Retrieval using Pattern Mining (CRPM). This approach integrates various clustering and pattern mining algorithms. First, it generates clusters of objects that contain similar objects. Three clustering algorithms based on k-means, DBSCAN (Density-based spatial clustering of applications with noise), and Spectral are suggested to minimize the number of shared terms among the clusters of objects. Second, frequent and high-utility pattern mining algorithms are performed on each cluster to extract the pattern bases. Third, the clusters of objects are ranked for every query. In this context, two ranking strategies are proposed: i) Score Pattern Computing (SPC), which calculates a score representing the similarity between a user query and a cluster; and ii) Weighted Terms in Clusters (WTC), which calculates a weight for every term and uses the relevant terms to compute the score between a user query and each cluster. Irrelevant information derived from the pattern bases is also used to deal with unexpected user queries. To evaluate the proposed approach, extensive experiments were carried out on two use cases: the documents and tweets corpus. The results showed that the designed approach outperformed traditional and cluster-based information retrieval approaches in terms of the quality of the returned objects while being very competitive in terms of runtime.																	0924-669X	1573-7497															10.1007/s10489-020-01922-x		OCT 2020											
J								Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray images using fine-tuned deep neural networks	APPLIED INTELLIGENCE										COVID-19; Classification; Deep learning; Transfer learning; Pneumonia; Chest X-ray (CXR); Imbalanced learning		The novel coronavirus 2019 (COVID-19) is a respiratory syndrome that resembles pneumonia. The current diagnostic procedure of COVID-19 follows reverse-transcriptase polymerase chain reaction (RT-PCR) based approach which however is less sensitive to identify the virus at the initial stage. Hence, a more robust and alternate diagnosis technique is desirable. Recently, with the release of publicly available datasets of corona positive patients comprising of computed tomography (CT) and chest X-ray (CXR) imaging; scientists, researchers and healthcare experts are contributing for faster and automated diagnosis of COVID-19 by identifying pulmonary infections using deep learning approaches to achieve better cure and treatment. These datasets have limited samples concerned with the positive COVID-19 cases, which raise the challenge for unbiased learning. Following from this context, this article presents the random oversampling and weighted class loss function approach for unbiased fine-tuned learning (transfer learning) in various state-of-the-art deep learning approaches such as baseline ResNet, Inception-v3, Inception ResNet-v2, DenseNet169, and NASNetLarge to perform binary classification (as normal and COVID-19 cases) and also multi-class classification (as COVID-19, pneumonia, and normal case) of posteroanterior CXR images. Accuracy, precision, recall, loss, and area under the curve (AUC) are utilized to evaluate the performance of the models. Considering the experimental results, the performance of each model is scenario dependent; however, NASNetLarge displayed better scores in contrast to other architectures, which is further compared with other recently proposed approaches. This article also added the visual explanation to illustrate the basis of model classification and perception of COVID-19 in CXR images.																	0924-669X	1573-7497															10.1007/s10489-020-01900-3		OCT 2020											
J								A new graph-based extractive text summarization using keywords or topic modeling	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Text summarization; Extractive summarization; Graph-based; Topic-based; Similarity measure		In graph-based extractive text summarization techniques, the weight assigned to the edges of the graph is the crucial parameter for the sentence ranking. The weights associated with the edges are based on the similarity between sentences (nodes). Most of the graph-based techniques use the common words based similarity measure to assign the weight. In this paper, we propose a new graph-based summarization technique, which, besides taking into account the similarity among the individual sentences, also considers the similarity between the sentences and the overall (input) document. While assigning the weight among the edges of the graph, we consider two attributes. The first attribute is the similarity among the nodes, which forms the edges of the graph. The second attribute is the weight given to a component that represents how much the particular edge is similar to the topics of the overall document for which we incorporate the topic modeling. Along with these modifications, we use the semantic measure to find the similarity among the nodes. The evaluation results of the proposed method demonstrate a significant improvement of the summary quality over the existing text summarization techniques.																	1868-5137	1868-5145															10.1007/s12652-020-02591-x		OCT 2020											
J								Multi-criteria decision support systems based on linguistic intuitionistic cubic fuzzy aggregation operators	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Linguistic intuitionistic cubic fuzzy variable; Linguistic intuitionistic cubic fuzzy weighted averaging and geometric operators; Multi-criteria decision-making	MAKING PROBLEMS; AVERAGING OPERATOR; OWA OPERATORS; CONSENSUS; METHODOLOGY; NUMBERS; MODEL; SETS	This article is an advanced approach to linguistic intuitionistic fuzzy variable through application of cubic set theory. For instance, we establish the idea of the linguistic intuitionistic cubic fuzzy variable (LICFV) theory and define several operations for LICFV; also establish a series of weighted aggregation operators under linguistic intuitionistic cubic fuzzy information, so called linguistic intuitionistic cubic fuzzy weighted averaging (LICFWA) operator, linguistic intuitionistic cubic fuzzy order weighted averaging (LICFOWA) operator, linguistic intuitionistic cubic fuzzy weighted geometric (LICFWG) operator, linguistic intuitionistic cubic fuzzy order weighted geometric (LICFOWG) operator, linguistic intuitionistic cubic fuzzy hybrid averaging (LICFHA) operator, and linguistic intuitionistic cubic fuzzy hybrid geometric (LICFHG) operator; and further study their fundamental properties and showed the relationship among these aggregation operators. In order to demonstrate the feasibility and practicality of the mentioned new technique, we develop multi-criteria decision-making algorithm under linguistic intuitionistic cubic fuzzy environment. Further, the proposed method applied to mobile phone selection, consider numerical application of mobile phone. Comparing the proposed techniques with other pre-existing aggregation operators, we concluded that the proposed technique is better, reliable, and effective.																	1868-5137	1868-5145															10.1007/s12652-020-02563-1		OCT 2020											
J								The necessary of constructing preventive health intervention policy under the trend of deep aging in China	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Public safety; Aging population; Preventive health; Hospital care	LONG-TERM-CARE; POPULATION; COMMUNICATION; DISPARITIES; CHALLENGES; FRAMEWORK; CHILDREN; NEEDS	China has developed into an aging population since 2000, following the global pattern of population aging. China has been ideally placed because of its excellent aging characteristics, which involve an ample proportion of the older population, speedy growth, and rapid expansion of the most past and unequal aging distribution. The aging demographic rises against the increasing burden of disease, high disability rate, and a low level of social involvement. The issue has been resolved by introducing the Low Fertility Economic State Aging Model (LFESAM) to shape unequal aging distribution based on health care perspectives. In the conventional health care model, the sustainable provision of treatment has primarily been loaded, which results in an unequal distribution of aging. LFESAM has multiple advantages when compared with traditional health care systems as a result of rapid advances and helps to distribute the aging population in a distributed manner. In its first stage of growth, the Chinese Government is responsible for introducing the intelligent health care service and the necessity of constructing preventive health intervention policies under the trend of deep aging in china.																	1868-5137	1868-5145															10.1007/s12652-020-02594-8		OCT 2020											
J								Ensemble convolutional neural networks with weighted majority for wafer bin map pattern classification	JOURNAL OF INTELLIGENT MANUFACTURING										Wafer bin map; Deep learning; Convolutional neural network; Ensemble classification; Weighted majority; Semiconductor manufacturing	DEFECT PATTERNS; RECOGNITION; MODEL; IDENTIFICATION; ENCODER; SYSTEM; YIELD	Wafer bin maps (WBM) provides crucial information regarding process abnormalities and facilitate the diagnosis of low-yield problems in semiconductor manufacturing. Most studies of WBM classification and analysis apply a statistical-based method or machine learning method operating on raw wafer data and extracted features. With increasing WBM pattern diversity and complexity, the useful features for effective WBM recognition are highly dependent on domain knowledge. This study proposes an ensemble convolutional neural network (ECNN) framework for WBM pattern classification, in which a weighted majority function is adopted to select higher weights for the base classifiers that have higher predictive performance. An industrial WBM dataset (namely, WM-811K) from a wafer fabrication process was used to demonstrate the effectiveness of the proposed ECNN framework. The proposed ECNN has superior performance in terms of precision, recall, F1 and other conventional machine learning classifiers such as linear regression, random forest, gradient boosting machine, and artificial neural network. The experimental results show that the proposed ECNN framework is able to identify common WBM defect patterns effectively.																	0956-5515	1572-8145															10.1007/s10845-020-01687-7		OCT 2020											
J								A post-quantum secure communication system for cloud manufacturing safety	JOURNAL OF INTELLIGENT MANUFACTURING										Cloud manufacturing; Intelligent manufacturing; Post-quantum algorithms; Secure scheme	PUBLIC-KEY ENCRYPTION; BREAKING RSA; ALGORITHM; EXPONENTIATION; PROTOCOL; PLATFORM; ATTACK	In recent years, as one of the new advanced manufacturing modes, cloud manufacturing has been received wide attentions around the world. The technology of cloud manufacturing intergrades the services-oriented techniques as well as manufacturing processes based on cloud computing. With the aid of the cloud computing platforms, the manufacturing services are provided in manufacturing clouds. However, one of the key challenges of cloud manufacturing is the security and safety of information transmission. Traditional network security architectures are based on RSA and elliptic curve cryptographic systems, which is claimed to be broken on quantum computers. We exploit the countermeasures of post-quantum algorithms to protect cloud manufacturing against quantum computer attacks. We propose a post-quantum secure scheme for cloud manufacturing. First, in order to retain confidentiality in cloud manufacturing, we propose a post-quantum asymmetric-key encryption scheme to encrypt the message with the generated session key. Second, in order to retain authentication security in cloud manufacturing, we propose a post-quantum public-key signature generation scheme. Third, based on the encryption scheme and signature generation scheme, we propose a post-quantum secure communication system for cloud manufacturing. We implement our design on cloud-based environment and the comparison with related designs show that our design is suitable for protecting communication in cloud manufacturing. Besides, the post-quantum secure communication system can be extended to other applications of intelligent manufacturing.																	0956-5515	1572-8145															10.1007/s10845-020-01682-y		OCT 2020											
J								Block-Based Refitting in l(12) Sparse Regularization	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Block sparsity; Total variation; Bias correction; Refitting	ITERATIVE REGULARIZATION; MODEL SELECTION; REGRESSION; IMAGES; SCALE	In many linear regression problems, including ill-posed inverse problems in image restoration, the data exhibit some sparse structures that can be used to regularize the inversion. To this end, a classical path is to usel l(12) block-based regularization. While efficient at retrieving the inherent sparsity patterns of the data-the support-the estimated solutions are known to suffer from a systematical bias. We propose a general framework for removing this artifact by refitting the solution toward the data while preserving key features of its structure such as the support. This is done through the use of refitting block penalties that only act on the support of the estimated solution. Based on an analysis of related works in the literature, we introduce a new penalty that is well suited for refitting purposes. We also present a new algorithm to obtain the refitted solution along with the original (biased) solution for any convex refitting block penalty. Experiments illustrate the good behavior of the proposed block penalty for refitting solutions of total variation and total generalized variation models.																	0924-9907	1573-7683															10.1007/s10851-020-00993-2		OCT 2020											
J								Periodically intermittent control for finite-time synchronization of delayed quaternion-valued neural networks	NEURAL COMPUTING & APPLICATIONS										Finite-time synchronization; Quaternion-valued neural networks; Periodically intermittent control; Settling time	FUNCTION PROJECTIVE SYNCHRONIZATION; COMPLEX DYNAMICAL NETWORKS; EXPONENTIAL SYNCHRONIZATION; ADAPTIVE SYNCHRONIZATION; NONLINEAR-SYSTEMS; VARYING DELAYS; MIXED DELAYS; STABILIZATION; STABILITY	In this paper, the finite-time synchronization between two delayed quaternion-valued neural networks (QVNNs) via the periodically intermittent feedback control is studied. Firstly, the finite-time synchronization problem is presented for the first time via the periodically intermittent control approach. Secondly, the upper bounds of the settling time for finite-time synchronization are estimated. Thirdly, a kind of novel controller, state feedback controller, which contains an integral term and delayed term, is proposed. Through these, the problem of finite-time synchronization has been solved very well. Finally, several new conditions ensuring finite-time synchronization of two delayed QVNNs are derived by establishing a new differential inequality and constructing a Lyapunov function. In the end, two numerical examples with simulations show the effectiveness of the derived results and the developed method.																	0941-0643	1433-3058															10.1007/s00521-020-05417-1		OCT 2020											
J								Applying BERT to analyze investor sentiment in stock market	NEURAL COMPUTING & APPLICATIONS										Bert model; Investor sentiment; Online reviews; Cross-sectional regression	PREDICTION; RETURNS; MODEL; RISK	This paper is an analysis of investor sentiment in the stock market based on the bidirectional encoder representations from transformers (BERT) model. First, we extracted the sentiment value from online information published by stock investor, using the Bert model. Second, these sentiment values were weighted by attention for computing the investor sentiment indicator. Finally, the relationship between investor sentiment and stock yield was analyzed through a two-step cross-sectional regression validation model. The experiments found that investor sentiment in online reviews had a significant impact on stock yield. The experiments show that the Bert model used in this paper can achieve an accuracy of 97.35% for the analysis of investor sentiment, which is better than both LSTM and SVM methods.																	0941-0643	1433-3058															10.1007/s00521-020-05411-7		OCT 2020											
J								DCARN: Deep Context Aware Recurrent Neural Network for Semantic Segmentation of Large Scale Unstructured 3D Point Cloud	NEURAL PROCESSING LETTERS										3D point clouds; Residual learning; Semantic segmentation; Mean shift clustering; Density-based spatial clustering of applications with noise (DBSCAN); Hierarchical density-based spatial clustering of applications with noise (HDBSCAN); Long short term memory; Edge conditioned convolution	CLASSIFICATION; RECONSTRUCTION	Semantic segmentation of large unstructured 3D point clouds is important problem for 3D object recognition which in turn is essential to solving more complex tasks such as scene understanding. The problem is highly challenging owing to large scale of data, varying point density and localization errors of 3D points. Nevertheless, with recent successes of deep neural network architectures to solve complex 2D perceptual problems, several researchers have shown interest to translate the developed 2D networks to 3D point cloud segmentation by a prior voxelization step for an explicit neighborhood representation. However, such a 3D grid representation loses the fine details and inherent structure due to quantization artifacts. For this purpose, this paper proposes an approach to performing semantic segmentation of 3D point clouds by exploiting the idea of super-point based graph construction. The proposed architecture is composed of two cascaded modules including a light-weight representation learning module which uses unsupervised geometric grouping to partition the large-scale unstructured 3D point cloud and a deep context aware sequential network based on long short memory units and graph convolutions with embedding residual learning for semantic segmentation. The proposed model is evaluated on two standard benchmark datasets and achieves competitive performance with the existing state-of-the-art datasets. The code and the obtained results have been made public at. https://github.com/ saba155/DCARN.																	1370-4621	1573-773X															10.1007/s11063-020-10368-8		OCT 2020											
J								Improving security using SVM-based anomaly detection: issues and challenges	SOFT COMPUTING										SVM; Multiclass SVM; Anomaly intrusion detection; Feature selection; Security; PCA	INTRUSION DETECTION SYSTEM; SUPPORT VECTOR MACHINES; FEATURE-SELECTION; DECISION TREE; ALGORITHM; HYBRID; INTERNET; ATTACKS; CLASSIFIER; NETWORKS	Security is one of the main requirements of the current computer systems, and recently it gains much importance as the number and severity of malicious attacks increase dramatically. Anomaly detection is one of the main branches of the intrusion detection systems which enables to recognize the newer variants of the security attacks. This paper focuses on the anomaly detection schemes (ADS), which have applied support vector machine (SVM) for detecting intrusions and security attacks. For this purpose, it first presents the required concepts about the SVM classifier and intrusion detection systems. It then classifies the ADS approaches and discusses the various machine learning and artificial intelligence techniques that have been applied in combination with the SVM classifier to detect anomalies. Besides, it specifies the primary capabilities, possible limitations, or advantages of the ADS approaches. Furthermore, a comparison of the studied ADS schemes is provided to illuminate their various technical details.																	1432-7643	1433-7479															10.1007/s00500-020-05373-x		OCT 2020											
J								Human motion tracking and positioning for augmented reality	JOURNAL OF REAL-TIME IMAGE PROCESSING										AR; Feature extraction and matching; Tracking and localization; KLT algorithm	SYSTEM	AR (Augmented reality) is a research hotspot in the current computer application field. AR technology enhances people's understanding and experience of the real environment by adding virtual objects to real scenes to integrate virtual objects with the real environment. Aiming at the weak processing power of intelligent terminals and the characteristics of limited hardware resources, this paper proposes a more effective human motion feature extraction and descriptor algorithm. The feature point detection and positioning method suitable for intelligent terminals is proposed in a targeted manner, which solves the problem of mismatching of similar structures. In addition, this paper proposes an AR-oriented recursive tracking algorithm for human motion. The positional relationship of the current frame is calculated from the position of the previous frame. A combination of ORB (Oriented fast and Rotated Brief) feature descriptors and KLT (Kanade-Lucas-Tomasi) algorithm is adopted. The ORB feature descriptor matched by the first frame image and the reference image is tracked by the KLT tracking algorithm, and the feature descriptor of the previous frame is tracked in the current frame, thereby eliminating the phenomenon of virtual object jitter. The experimental results show that the recursive tracking scheme has better performance in time and precision than the detection tracking scheme.																	1861-8200	1861-8219															10.1007/s11554-020-01030-6		OCT 2020											
J								A comparative study of feature selection methods for binary text streams classification	EVOLVING SYSTEMS										Text streams; Feature drift; Feature selection; Evolving regularization; Binary classification; Concept drift	STATISTICAL COMPARISONS; RECURRING CONTEXTS; CONCEPT DRIFT; CLASSIFIERS; ENSEMBLE	Text streams are a continuous flow of high-dimensional text, transmitted at high-volume and high-velocities. They are expected to be classified in real-time, which is challenging due to the high dimensionality of feature space. Applying feature selection algorithms is one solution to reduce text streams feature space and improve the learning process. However, since text streams are potentially unbounded, it is expected a change in their probabilistic distribution over time, the so-called Concept Drift. The concept drift impacts the feature selection process due to the feature drift when the relevance of features is also subject to changes over time. This paper presents a comparative study of six feature selection methods for binary text streams classification, even in the presence of feature drift. We also propose the Online Feature Selection with Evolving Regularization (OFSER) algorithm, a modified version of the Online Feature Selection (OFS) algorithm, which uses evolving regularization to dynamically penalize model complexity, reducing feature drift impacts on the feature selection process. We conducted the experimental analysis on eleven real-world, commonly used datasets for text classification. The OFSER algorithm showed F1-scores up to 12.92% higher than other algorithms in some cases. The results using Iman and Davenport and Bergmann-Hommel's tests show that OFSER algorithm is statistically superior to Information Gain and Extremal Feature Selection algorithms in terms of improving the base classifier predictive power.																	1868-6478	1868-6486															10.1007/s12530-020-09357-y		OCT 2020											
J								Optimal integration of multi-type DG in RDS based on novel voltage stability index with future load growth	EVOLVING SYSTEMS										Distributed generation; Radial distribution system; Siting and sizing; Optimal integration; Composite load model; Load growth	OPTIMAL PLACEMENT; DISTRIBUTION-SYSTEMS; DISTRIBUTED GENERATION; OPTIMIZATION ALGORITHM; OPTIMAL ALLOCATION; NETWORK; UNITS; SIZE; FLOW	In this article, a novel voltage stability index is proposed for the optimal placement and an analytical as well as particle swarm optimization method is implemented for optimal sizing of different types of distributed generation (DG) in a radial distribution system. The three types of DG considered are Type I, Type II and Type IV model. The methods account for changes in long-term system load profile in the planning phase to enhance power system performance. The load model chosen is composite. The optimal power factor and the cost of the DG are also considered. The efficiency of the proposed technique is tested and validated on IEEE 33-bus and 69-bus systems. The significant savings in annual energy loss, reduction in system power losses with upgraded voltage profile is observed for Type IV DG at optimal PF over other types. The results attained are further compared to other analytical and nature-inspired methods to exemplify the dominance of the proposed methodology. The statistical analysis has also been carried out for both bus systems without and with considering all types of DG.																	1868-6478	1868-6486															10.1007/s12530-020-09356-z		OCT 2020											
J								Absolute phase unwrapping with SVM for fringe-projection profilometry	IET IMAGE PROCESSING										support vector machines; surface topography measurement; learning (artificial intelligence); radial basis function networks; image capture; absolute phase unwrapping; fringe-projection profilometry; phase-based profilometry; support vector machine; learning-based method; wrapped phase; radial basis function kernel SVM; temporal unwrapping; complex quality-guided methods	SHAPE MEASUREMENT; SAR DATA; ALGORITHM; ACCURATE; MAPS	Phase unwrapping is a fundamental task in phase-based profilometry. Existing spatial and temporal approaches are facing challenges such as error propagation and low efficiency. In this study, the authors propose a learning-based method that uses a support vector machine (SVM) to perform phase unwrapping, where the problem is solved as a classification task. To be specific, seven elements, extracted from the captured patterns and the wrapped phase, form the input feature vector and the fringe order is the output class. Besides, a radial basis function kernel SVM is adopted as the model. The proposed method is conducted independently for every pixel, and does not suffer from error propagation in the spatial unwrapping. Moreover, it needs fewer patterns than temporal unwrapping since only one phase map is required. Simulation and experimental results demonstrate that the proposed scheme produces precise depth maps, which are comparable with the complex quality-guided methods but at a much faster speed.																	1751-9659	1751-9667				OCT 16	2020	14	12					2645	2651		10.1049/iet-ipr.2019.1611													
J								Geometry and context guided refinement for stereo matching	IET IMAGE PROCESSING										image resolution; learning (artificial intelligence); iterative methods; image matching; stereo image processing; geometry; context guided refinement; existing end-to-end stereo matching networks; disparity matching phase; triangulation principle; domain differences; disparity refinement phase; refine; concatenated coarse disparity; fine disparity; unseen domain; stereo matching network; unseen scenes; context-guided refinement network; fine matching module; GCGR-Net learns; pixels; high resolution dense disparity; possible matching pixel pairs; geometry information; upsampling module obtains context information; lower resolution disparity; final disparity map; iterative refinement model; fine-tuning		The disparity refinement phase of existing end-to-end stereo matching networks refines the disparity by learning the mapping from the concatenated coarse disparity and corresponding features to fine disparity. It depends on the scenarios' characteristics, such as the distribution of disparity and semantic categories contained in the domain, which makes the network fail to work on unseen domain. In this paper, we propose a geometry and context guided refinement network (GCGR-Net) containing a Fine Matching module and an Upsampling module. GCGR-Net learns to utilize pixels' relationship to get high resolution dense disparity, which is independent of the data's content. The Fine Matching module performs a minimum range search based on the relationship between the possible matching pixel pairs, i.e. the called geometry information, to recover the internal structure of the object. The Upsampling module obtains context information, the relationship between central pixel and the pixels in its neighborhood, to upsample the lower resolution disparity. The final disparity map is obtained step by step through an iterative refinement model. Experiment results show that our method not only has good performance in the training scenarios, but also outperforms previous methods on the unseen domain without fine-tuning.																	1751-9659	1751-9667				OCT 16	2020	14	12					2652	2659		10.1049/iet-ipr.2019.1636													
J								Energy minimisation-based multi-class multi-instance geometric primitives extraction from 3D point clouds	IET IMAGE PROCESSING										iterative methods; minimisation; feature extraction; computer vision; computational geometry; power aware computing; three-dimensional point clouds; 3D vision-based intelligent applications; energy minimisation; 3D point cloud; multiclass multiinstance geometric primitives extraction		Geometric primitives contained in three-dimensional (3D) point clouds can provide the meaningful and concise abstraction of 3D data, which plays a vital role in improving 3D vision-based intelligent applications. However, how to efficiently and robustly extract multiple geometric primitives from point clouds is still a challenge, especially when multiple instances of multiple classes of geometric primitives are present. In this study, a novel energy minimisation-based algorithm for multi-class multi-instance geometric primitives extraction from the 3D point cloud is proposed. First, an improved sampling strategy is proposed to generate model hypotheses. Then, an improved strategy to establish the neighbourhood is proposed to help construct and optimise an energy function for points labelling. After that, hypotheses and parameters of models are refined. Iterate this process until the energy does not decrease. Finally, models of multi-class multi-instance geometric primitives are simultaneously and robustly extracted from the 3D point cloud. In comparison with the state-of-the-art methods, it can automatically determine the classes and numbers of geometric primitives in the 3D point cloud. Experimental results with synthetic and real data validate the proposed algorithm.																	1751-9659	1751-9667				OCT 16	2020	14	12					2660	2667		10.1049/iet-ipr.2019.1625													
J								New multi-view human motion capture framework	IET IMAGE PROCESSING										image motion analysis; image capture; image reconstruction; image colour analysis; multiview human motion capture framework; human pose estimation; multiview camera system; real-time images capturing; robust 3D key points; 2D key points; human body; 3D point cloud; novel SMPL-based method; SMPL model; human motion capture; multiview colour images	DEFORMATION	Estimating human pose and shape without markers is a challenging problem. This study proposes a multiple-view markerless human motion capture framework. Firstly, a multi-view camera system is built for capturing real-time images of moving humans on multiple views. Secondly, by employing the OpenPose method, the authors calculate robust 3D key points from 2D key points of the human body, which are estimated from the multi-view images. And dense 3D point cloud is reconstructed from images. Thirdly, they propose a novel SMPL-based method to represent human motion by fitting the SMPL model to 3D key points and 3D point clouds. In order to achieve a more accurate human pose, a penalty term is utilised to solve the problem of error accumulation in the process of human motion capture. In addition, they present a dense mesh template-based SMPL that can be deformed to point cloud to recover a real human body shape. Finally, they map multi-view colour images onto the human mesh model to acquire rendered mesh. The experimental results show that the proposed method improves the accuracy of human pose and realises the 3D human body model more realistic.																	1751-9659	1751-9667				OCT 16	2020	14	12					2668	2674		10.1049/iet-ipr.2019.1606													
J								Individual retrieval based on oral cavity point cloud data and correntropy-based registration algorithm	IET IMAGE PROCESSING										medical image processing; image registration; image matching; oral cavity point cloud data; individual retrieval method; three-dimensional oral cavity data; registration accuracy; retrieval rate; rigid registration algorithm; matched point cloud data; accurate retrieval; retrieval three-dimensional model algorithm; different model data		In this study, the authors present a novel individual retrieval method based on oral cavity point cloud data and correntropy-based registration algorithm. Since the three-dimensional oral cavity data contains a large amount of noise and outliers, it may lead to a decrease in registration accuracy, which affects the accuracy of retrieval rate. Therefore, the authors introduce the correntropy into the rigid registration algorithm to solve this problem. Then, they filter the matched point cloud data and then use the mean squared error to judge the individual differences of the model data. Finally, the accurate retrieval of the oral cavity data is realised. Experimental results demonstrate the proposed retrieval three-dimensional model algorithm can be successfully searched under different model data, which can help forensics use the characteristics of biological individuals to accurately search and identify, and improve recognition efficiency.																	1751-9659	1751-9667				OCT 16	2020	14	12					2675	2681		10.1049/iet-ipr.2019.1420													
J								DenseUNet: densely connected UNet for electron microscopy image segmentation	IET IMAGE PROCESSING										image segmentation; encoding; diseases; medical image processing; convolutional neural nets; electron microscopy; EM image segmentation; DenseUNet; electron microscopy image segmentation; computer-aided diagnosis; specific pathogens; disease; convolutional neural network-based methods; CNN-based methods; parameter efficient method; weighted loss; ISBI 2012 EM dataset; smart design; encoder-decoder architecture variants	CROWD EVACUATION; NETWORKS; MODEL	Electron microscopy (EM) image segmentation plays an important role in computer-aided diagnosis of specific pathogens or disease. However, EM image segmentation is a laborious task and needs to impose experts knowledge, which can take up valuable time from research. Convolutional neural network (CNN)-based methods have been proposed for EM image segmentation and achieved considerable progress. Among those CNN-based methods, UNet is regarded as the state-of-the-art method. However, the UNet usually has millions of parameters to increase training difficulty and is limited by the issue of vanishing gradients. To address those problems, the authors present a novel highly parameter efficient method called DenseUNet, which is inspired by the approach that takes particular advantage of recent advances in both UNet and DenseNet. In addition, they successfully apply the weighted loss, which enables us to boost the performance of segmentation. They conduct several comparative experiments on the ISBI 2012 EM dataset. The experimental results show that their method can achieve state-of-the-art results on EM image segmentation without any further post-processing module or pre-training. Moreover, due to smart design of the model, their approach has much less parameters than currently published encoder-decoder architecture variants for this dataset.																	1751-9659	1751-9667				OCT 16	2020	14	12					2682	2689		10.1049/iet-ipr.2019.1527													
J								Coarse-to-fine 3D road model registration for traffic video augmentation	IET IMAGE PROCESSING										solid modelling; geographic information systems; image registration; pose estimation; iterative methods; Geographic Information Systems; traffic elements; point-to-line correspondence establishment; viewpoint registration; 3D graphic engine; traffic scene; viewpoints; augmented videos; coarse-to-fine 3D road model registration; traffic video augmentation; nonperspective; line correspondences; traffic scenarios; coarse-to-fine 3D road registration method; iterative closest point algorithm; feature correspondences; framework including road registration; traffic videos; road information	POSE ESTIMATION; LINE CORRESPONDENCES; SEARCH; ROBUST	This study addresses the problem of non-perspective pose estimation from line correspondences in the traffic scenarios. A coarse-to-fine 3D road registration method is proposed for this problem in two stages. Firstly, the iterative closest point algorithm is exploited to estimate the pose coarsely. An objective function is then established to incorporate the feature correspondences for refining the coarse pose. Besides, the framework including road registration is employed for traffic video augmentation. The framework begins with the inputs of traffic videos, road information from Geographic Information Systems and 3D models of traffic elements (e.g. vehicles, pedestrians). Subsequently, 3D road model generation and point-to-line correspondence establishment are achieved in the preprossessing stage. After road and viewpoint registration, the 3D graphic engine is employed to simulate the traffic scene with the road, viewpoints and traffic elements. The augmented videos are generated by fusing the original frames and newly projected traffic elements. The authors demonstrate the superiority of the proposed registration method by the comparison to state-of-the-arts in both quantitative and qualitative experiments. In addition, the frames of the augmented videos validate the proposed method in the application.																	1751-9659	1751-9667				OCT 16	2020	14	12					2690	2700		10.1049/iet-ipr.2019.1036													
J								Method for automatic railway track surface defect classification and evaluation using a laser-based 3D model	IET IMAGE PROCESSING										flaw detection; image classification; artificial intelligence; rails; mechanical engineering computing; railways; maintenance engineering; automatic optical inspection; railway engineering; feature extraction; pattern classification; wheels; rail measurement data; automatic railway track surface defect classification; laser-based 3D model; physical surface defects; wheels; laser-based optical inspection technologies; 2D profile measurement; rail maintenance; artificial intelligence algorithms; geometrical feature extraction; multiclass classifiers	VISION INSPECTION	Inspection of physical surface defects is a significant concern in many industrial areas. In railway systems, this process mainly includes the detection and classification of defects in rails and wheels, for which laser-based optical inspection technologies have gradually been applied in the form of 2D profile measurement, benefiting from its high precision and robustness to surface conditions. However, defect classification and evaluation after the initial detection works still rely heavily on human inspectors to make maintenance suggestions. The linear nature of rails makes it possible to increase the dimension of rail measurement data from 2D to 3D by aligning 2D profiles along the rail, from which more comprehensive diagnosis information becomes available. In combination with appropriate artificial intelligence algorithms, this approach can potentially replace human-dominated defect classification and evaluation work. This study presents a 3D model-based railway track surface defect classification and evaluation method. A set of geometrical features are extracted from the 3D model of track surface defects to describe a distinguishable pattern for each category of defect. Multi-class classifiers are then tested and have shown promising results on a group of artificial track surface defects, giving a systemic solution for 3D model-based automatic track surface defect inspection.																	1751-9659	1751-9667				OCT 16	2020	14	12					2701	2710		10.1049/iet-ipr.2019.1616													
J								360 degrees video compression based on sphere-rotated frame prediction	IET IMAGE PROCESSING										motion estimation; data compression; video coding; 360 degrees video compression; sphere-rotated frame prediction; hybrid coding framework; serious shape deformation; ERP; motion estimation; reference frame; inserted frame; shape deformation; video characters; standard high efficiency video coding		360 degrees video is very popular due to its 360 degrees views of a scene. Although 360 degrees videos are also compressed by a hybrid coding framework like 2D video, its high resolution and serious shape deformation affect coding efficiency. In equirectangular projection (ERP) format of 360 degrees videos, if an object moves from equator regions to pole regions or vice versa, large deformation will be introduced and motion estimation cannot find the best-matched part. To solve the above problem, the authors propose to generate a better reference frame for the current to be encoded frame. First, they project the frame prior to the current one from ERP to the sphere and rotate it at an appropriate angle depending on motion vectors. Subsequently, they insert this generated frame to the rear of the reference queue and let the encoder work as usual. The advantage is that the inserted frame has a more similar shape deformation as the current frame, which greatly helps motion estimation and makes full use of 360 degrees video characters. Their method is simple and friendly compatible with the existing compression standard. Experiments prove that their method achieves 1.57% Bjontegaard Delta (BD)-gain compared with standard high efficiency video coding.																	1751-9659	1751-9667				OCT 16	2020	14	12					2711	2718		10.1049/iet-ipr.2019.1663													
J								MapReduce framework based big data clustering using fractional integrated sparse fuzzy C means algorithm	IET IMAGE PROCESSING										Big Data; particle swarm optimisation; pattern clustering; data mining; learning (artificial intelligence); fuzzy set theory; pattern classification; data analysis; parallel processing; MapReduce framework; big data clustering; big data analytics; massive data; clustering algorithms; map function; particle swarm optimisation-based whale optimisation algorithm; FrSparse FCM-based MRF; Skin data; localisation data; fractional sparse fuzzy C-means algorithm	OPTIMIZATION ALGORITHM; COLONY APPROACH; SELECTION	Big data analytics gain significant interest over the traditional data-processing methodologies that engage in extracting the hidden patterns and correlations from the massive data, termed as big data. With the aim of relieving the computational complexity the clustering method plays a significant role. With the knowledge of the clustering algorithms, the big data arriving from the distributed sources is processed using the MapReduce framework (MRF). The MRF possesses two functions, namely, map function and reduce function, such that the map function is based on the proposed Fractional Sparse Fuzzy C-Means (FrSparse FCM) algorithm and reduce function is based on particle swarm optimisation-based whale optimisation algorithm (P-Whale). Initially, the optimal centroids are computed using the proposed algorithm in the mapper phase that is optimally tuned in the reducer phase, and it is clear that the proposed FrSparse FCM-based MRF ensures the parallel processing of the big data. Experimentation is performed using the Skin data set and the localisation data set taken from the UCI machine learning repository, and the analysis is progressed using the metrics, such as accuracy and DB Index. The analysis proves that the proposed method acquired a maximum accuracy of 90.6012% and a minimum DB Index of 5.33.																	1751-9659	1751-9667				OCT 16	2020	14	12					2719	2727		10.1049/iet-ipr.2019.0899													
J								Automatic labelling of brain tissues in MR images through spatial indexes based hybrid atlas forest	IET IMAGE PROCESSING										medical image processing; biomedical MRI; image registration; brain; biological tissues; multiatlas-based methods; magnetic resonance images; correct label propagation; labelling information; single atlas; automatic labelling method; spatial index based hybrid atlas forest; brain tissues; MR images; target image; hybrid atlas forest model; image space; image registration	SEGMENTATION; HIPPOCAMPUS; FUSION	The multi-atlas-based methods are widely applied in the automatic labelling in magnetic resonance (MR) images. However, most multi-atlas-based methods require that all atlases be registered to the target image accurately to have a correct label propagation. In this study, the authors introduce the term spatial indexes and construct a hybrid atlas forest model to gather the labelling information from all atlases without propagating labels from every single atlas. Furthermore, a new automatic labelling method using the hybrid atlas forest model based on spatial indexes is proposed. In the proposed framework, an atlas is chosen arbitrarily as a reference image and the spatial indexes are constructed on this image space. Then, the samples are selected from all atlases in the dataset based on the spatial indexes to construct a samples pool. Finally, the hybrid atlas forest model will be trained on the samples pool and used to predict the labelling of the target. Experiments are conducted on two public datasets to evaluate the effectiveness of the proposed method. The experimental results show that the proposed method reduces the requirement of strong dependence on precise registration and improve the accuracy of labelling.																	1751-9659	1751-9667				OCT 16	2020	14	12					2728	2736		10.1049/iet-ipr.2018.6073													
J								Bayesian multilevel random-effects model for estimating noise in image sensors	IET IMAGE PROCESSING										probability; Bayes methods; image sensors; Bayesian multilevel random-effects model; image sensors; sensor noise sources; single image; multiple images; Bayesian approach; Bayesian probabilistic model; different reflectance; image sensing model; complex model; fully probabilistic model; Bayesian modelling framework; noise parameters; model predictions; imaging process	CALIBRATION; CCD	Sensor noise sources cause differences in the signal recorded across pixels in a single image and across multiple images. This study presents a Bayesian approach to decomposing and characterising the sensor noise sources involved in imaging with digital cameras. A Bayesian probabilistic model based on the (theoretical) model for noise sources in image sensing is fitted to a set of a time-series of images with different reflectance and wavelengths under controlled lighting conditions. The image sensing model is a complex model, with several interacting components dependent on reflectance and wavelength. The properties of the Bayesian approach of defining conditional dependencies among parameters in a fully probabilistic model, propagating all sources of uncertainty in inference, makes the Bayesian modelling framework more attractive and powerful than classical methods for approaching the image sensing model. A feasible correspondence of noise parameters to their expected theoretical behaviours and well-calibrated posterior predictive distributions with a small root mean square error for model predictions have been achieved in this study, thus showing that the proposed model accurately approximates the image sensing model. The Bayesian approach could be extended to formulate further components aimed at identifying even more specific parameters of the imaging process.																	1751-9659	1751-9667				OCT 16	2020	14	12					2737	2745		10.1049/iet-ipr.2018.5926													
J								3D reconstruction of spine image from 2D MRI slices along one axis	IET IMAGE PROCESSING										interpolation; image reconstruction; biomedical MRI; medical image processing; spine image; MRI; magnetic resonance imaging; three-dimensional image; reasonable slice gap; orthogonal axis	INTERVERTEBRAL DISC SEGMENTATION; QUALITY ASSESSMENT; INTERPOLATION	Magnetic resonance imaging (MRI) is a very effective method for identifying any abnormality in the structure and physiology of the spine. However, MRI is time consuming as well as costly. In this work, the authors propose an algorithm which can reduce the time of MRI and thus the cost, with minimal compromise on accuracy. They reconstruct a three-dimensional (3D) image of the spine from a sequence of 2D MRI slices along any one axis with reasonable slice gap. In order to preserve the image at the edges properly, they regenerate the 3D image by using a combination of bicubic and bilinear interpolation along the orthogonal axis. From the reconstructed 3D, they use a simple geometric method to slice out any possible location along any axis and get the information in that region. They have tested their algorithm on real data, and found that their algorithm reduces the time by 80%, with high internal data preservation accuracy of about 96%.																	1751-9659	1751-9667				OCT 16	2020	14	12					2746	2755		10.1049/iet-ipr.2019.0800													
J								Simultaneous filter tuning and calibration of the camera and inertial measurement unit camera for a vision inertial navigation system	IET IMAGE PROCESSING										cameras; Global Positioning System; genetic algorithms; calibration; Kalman filters; inertial navigation; nonlinear filters; units (measurement); image sensors; mean square error methods; minimisation; image filtering; root mean square error minimisation; adjusted vision inertial navigation system; visual odometry; unscented Kalman filter parameters; MO-GA; AVINS; INS; VINS; inertial measurement unit camera calibration; UKF; multiobjective genetic algorithm	KALMAN FILTER; LOCALIZATION; STATE	In this study, a novel approach based on multi-objective genetic algorithm (MO-GA) is used for simultaneous tuning the unscented Kalman Filter (UKF) parameters and camera and inertial measurement unit camera calibration in a vision inertial navigation system (VINS). This system consists of visual odometry and inertial navigation system (INS) which integrates with a UKF. In order to obtain simultaneous tuning and calibration of the parameters and variables, the MO-GA minimises the root mean square error of the position and velocity of the vehicle on a selected trajectory of the benchmark data set. Then, the tuned parameters and calibrated variables are placed in the VINS and an adjusted VINS (AVINS) is obtained. For investigating the AVINS, the mentioned system is compared with INS only, VINS based on calibration data of the benchmark data set, and GPS/INS as Real Data on the identical trajectory. Furthermore, in order to evaluate the results of the proposed approach, the AVINS is examined in the second trajectory. The results indicate the proper performance of the presented approach in the simultaneous tuning the filter parameters and calibrating the variables of sensors that are used in the uncalibrated VINS.																	1751-9659	1751-9667				OCT 16	2020	14	12					2756	2767		10.1049/iet-ipr.2019.0007													
J								Adaptive colour-guided non-local means algorithm for compound noise reduction of depth maps	IET IMAGE PROCESSING										image reconstruction; image restoration; image denoising; image texture; image colour analysis; image filtering; stereo image processing; image representation; adaptive filters; adaptive colour-guided nonlocal means algorithm; compound noise reduction; object positioning information; compound noise; subsequent filter design; adaptive colour-guided nonlocal mean filter; nonhole pixels; restored depth map edges; interactive visual applications; RGB-D data representation; active illumination shadows; colour image; hole-artifact removal; virtual view synthesis; 3D scene reconstruction	IMAGE-ENHANCEMENT; MODEL; COMPLETION; RESOLUTION; FILTER	Depth maps are used to describe object positioning information in three-dimensional (3D) space, and they are crucial for RGB-D data representation, which is useful for numerous interactive visual applications. In practice, depth maps are often contaminated by compound noise, including intrinsic noise and missing regions owing to active illumination shadows. As existing noise models cannot describe the above-mentioned compound noise effectively, the subsequent filter design is a challenging task. In this study, an adaptive colour-guided non-local mean (NLM) filter is proposed to address such compound noise. First, the authors classify the depth map into hole and non-hole pixels. Then, the proposed filter is designed on the basis of the NLM framework, where the colour image is used as a guide prior for hole-artifact removal. Finally, the authors use a shock filter to effectively address the non-regularisation of the restored depth map edges and remove the remaining noise. Experiments show that the proposed filter qualitatively and quantitatively outperforms existing colour-guided and unguided filters. Moreover, the authors verify the superiority of the proposed filter through virtual view synthesis and 3D scene reconstruction applications.																	1751-9659	1751-9667				OCT 16	2020	14	12					2768	2779		10.1049/iet-ipr.2019.0074													
J								Multi-metric domain adaptation for unsupervised transfer learning	IET IMAGE PROCESSING										unsupervised learning; pattern classification; unlabelled target domain; labelled source domain; global transfer perspectives; local transfer perspectives; multimetric domain adaptation; MMDA; unsupervised transfer learning; marginal class distances; cross-domain adaptability; cross-domain manifold structures; global adaptation methods; local adaptation methods; unsupervised domain adaptation	FRAMEWORK; REGULARIZATION	Unsupervised domain adaptation aims to learn a classifier for the unlabelled target domain by leveraging knowledge from a labelled source domain. This study presents a novel domain adaptation framework from global and local transfer perspectives, referred to as multi-metric domain adaptation (MMDA) for unsupervised transfer learning. At the global level, MMDA minimises the marginal and within-class distances and maximises the between-class distance between domains while maintaining the features of the source domain to improve the cross-domain adaptability. At the local level, MMDA exploits both in- and cross-domain manifold structures embedded in data samples to increase the discriminative ability. The authors learn a coupled transformation that projects the source and target domain data onto respective subspace where the statistical and geometrical divergences are reduced simultaneously. They formulate global and local adaptation methods in an optimisation problem and derive an analytic solution to the objective function. Extensive experiments demonstrate that MMDA shows improvements in classification accuracy compared with several existing state-of-the-art methods.																	1751-9659	1751-9667				OCT 16	2020	14	12					2780	2790		10.1049/iet-ipr.2019.1434													
J								Improved MR image denoising via low- rank approximation and Laplacian-of-Gaussian edge detector	IET IMAGE PROCESSING										edge detection; image denoising; approximation theory; Laplacian-of-Gaussian edge detector; favorable denoising performance; low rank approximation methods; subtle edge texture; image visual quality; novel MR image denoising approach; low rank approximation model; clear MR image	SHRINKAGE; SPARSE; DOMAIN; NOISE	The low rank approximation for MR image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In spite of the great success of existing low rank approximation methods, these tend to lose the subtle edge texture when removing noise. It could degrade the image visual quality and affect the final clinical diagnosis. In this paper, a novel MR image denoising approach is proposed based on low rank approximation model and the Laplacian-of-Gaussian edge detector. In the proposed approach, a similarity evaluation scheme for noisy patch is employed to avoid the effect of the noise in the patch matching, and the details of the edge texture are preserved by the Laplacian-of-Gaussian edge detector. Experimental results show that the proposed approach is efficient and superior to some of the existing approaches in both objective criterion and visual fidelity. The proposed method can retrieve a clear MR image from the noisy one, with the detail of the edge texture, which could be very important in the clinical diagnosis.																	1751-9659	1751-9667				OCT 16	2020	14	12					2791	2798		10.1049/iet-ipr.2019.1648													
J								Image copy-move forgery detection using sparse recovery and keypoint matching	IET IMAGE PROCESSING										feature extraction; filtering theory; image representation; image forensics; image matching; image segmentation; object detection; image colour analysis; image copy-move; keypoint; image forensics; authenticity; criminal investigations; intelligence services; medical documentations; CMF detection algorithm; sparse recovery algorithm; suspicious segments; colour information; image segments; identified segments; similar ones; matched ones; morphology scheme; forged region; forged images; forgery detection capabilities; state-of-the-art schemes; scaled forgeries; sparse recovery step; CMF detection techniques		Copy-move forgery (CMF) detection is one of the most practical problems in image forensics. The authenticity of the image becomes more crucial when the images are used in the criminal investigations, intelligence services, and medical documentations. In this study, the authors suggest a CMF detection algorithm. At first they they suggest to use a sparse recovery algorithm to identify the suspicious segments. To incorporate the colour information of the image segments, they propose to compare the histograms of the identified segments to detect the similar ones. The keypoints of those parts are obtained and the matched ones are located. In the last step, they suggest a morphology scheme to extract the forged region. They have evaluated the proposed method in the detection of various forged images. The simulation results reveal the forgery detection capabilities of the suggested algorithm compared to the other state-of-the-art schemes. The proposed method has superiority over its counterparts in detecting the scaled forgeries. Moreover, the sparse recovery step enables the proposed algorithm to remove the genuine repeated patterns of the image, while the other CMF detection techniques wrongly consider those parts as a forgery. Furthermore, the proposed scheme is on-average faster than the other schemes.																	1751-9659	1751-9667				OCT 16	2020	14	12					2799	2807		10.1049/iet-ipr.2018.6246													
J								Classification of magnetic resonance images for brain tumour detection	IET IMAGE PROCESSING										support vector machines; medical image processing; image segmentation; tumours; biomedical MRI; multilayer perceptrons; feature extraction; image classification; learning (artificial intelligence); brain; low-level information; linear filter; higher-level image features; handcrafted feature extraction; segmentation-based localised region; MRI datasets; magnetic resonance image; automatic lesion recognition method; multistage image segmentation method; automated brain tumour detection; multilayer perceptron classifiers; support vector machine; Fisher vector; disparity map	SEGMENTATION; REFINEMENT; ALGORITHM	Image segmentation of magnetic resonance image (MRI) is a crucial process for visualisation and examination of abnormal tissues, especially during clinical analysis. Complexity and variations of the tumour structure magnify the challenges in the automated detection of a brain tumour in MRIs. This study presents an automatic lesion recognition method in the MRI followed by classification. In the proposed multistage image segmentation method, the intent region initialisation is performed using low-level information by the keypoint descriptors. A set of the linear filter is used to transform low-level information into higher-level image features. The set of features and filter training data are accomplished to track the tumour region. The authors adopt a possibilistic model for region growing, and disparity map for the refinement process to grave consist boundary. Further, the features are extracted using the Fisher vector and autoencoder. A set of handcrafted features is also extracted using a segmentation-based localised region to train and test the support vector machine and multilayer perceptron classifiers. The experiments that are performed using five MRI datasets confirm the superiority of proposal as that of the state-of-the-art methods. It reports 94.5 and 91.76%, average accuracy of segmentation and classification, respectively.																	1751-9659	1751-9667				OCT 16	2020	14	12					2808	2818		10.1049/iet-ipr.2019.1631													
J								Underwater sonar image classification using generative adversarial network and convolutional neural network	IET IMAGE PROCESSING										image classification; sonar imaging; convolutional neural nets; generative adversarial network; convolutional neural network; improved CNN; underwater sonar image classification; conditional Wasserstein GAN-gradient penalty	RECOGNITION	This study presents a generative adversarial network (GAN) called conditional Wasserstein GAN-gradient penalty (CWGAN-GP)&DenseNet and ResNet, and a convolutional neural network (CNN) called improved CNN to complete underwater sonar image classification. Specifically, to solve the problem of insufficient underwater sonar image data, the CWGAN-GP&DR is developed to expand underwater sonar image data set. Besides, to improve the analysis and utilisation of the feature map and reduce the misclassification rate of categories with similar probabilities, improved CNN is proposed to complete the final underwater sonar image classification. Finally, compared with other methods, the CWGAN-GP&DR generate better underwater sonar images and effectively expand the underwater sonar image data set. Moreover, compared with the original data set and other expanded data set, the highest accuracy rate of 85.00% can be obtained on the CWGAN-GP&DR expanded data set by CNN. Furthermore, CNN, CNN-bais and improved CNN are used to perform classification experiments on each data set, and the accuracy of the improved CNN is the highest on all data sets and reached the highest accuracy of 87.71% on CWGAN-GP&DR expanded data set. The experimental results demonstrate that the proposed method can effectively improve the performance of underwater sonar image classification.																	1751-9659	1751-9667				OCT 16	2020	14	12					2819	2825		10.1049/iet-ipr.2019.1735													
J								Quantitative analysis of cell morphology based on the contourlet transform	IET IMAGE PROCESSING										image segmentation; image classification; medical image processing; wavelet transforms; support vector machines; cellular biophysics; feature extraction; image representation; statistical analysis; quantitative analysis; cellular morphology analysis; biological processes; graft rejection; lymphocyte boundary deformation; clinical rejection diagnosis; contourlet transform-based method; cell boundary variation; edge-to-centroid distance signals; multidirectional decomposition; direction filter; statistical parameters; cell dynamic boundaries; cell images; image feature representation; wavelet transform; Laplacian pyramid; support vector machine; cell deformation classification	SHAPE CHANGES; IMAGE; TOOLS; KEY	Cellular morphology analysis has been widely used to detect abnormalities in biological processes. Clinicians have observed that lymphocytes become highly deformable under special conditions, particularly when graft rejection occurs. The characterisation of lymphocyte boundary deformation provides important quantitative parameters to assist clinical rejection diagnosis. To evaluate the dynamic features of the boundaries of target lymphocyte when a graft rejection occurs, a contourlet transform-based method is proposed to extract the characteristics of cell boundary variation. First, the lymphocyte is segmented and tracked to obtain their edge-to-centroid distance signals. Subsequently, a contourlet transform is performed on these signals, during which the edge-to-centroid distance signals of the lymphocyte is decomposed at multiple scales using the Laplacian pyramid; a multi-directional decomposition is then performed using a direction filter to merge the singularities distributed along the same direction and obtain the contourlet transform coefficients. Finally, statistical parameters of the cell dynamic boundaries are calculated, then fed into the support vector machine for classification of the cell deformation. Our findings demonstrate that contourlet transform has better performance in representing image features such as cell boundaries than wavelet transform for its prosperities of multi-scale and multi-directional decomposition for cell images.																	1751-9659	1751-9667				OCT 16	2020	14	12					2826	2832		10.1049/iet-ipr.2019.0909													
J								Fast multi-spectral image super-resolution via sparse representation	IET IMAGE PROCESSING										feature extraction; image resolution; image reconstruction; image representation; geophysical image processing; remote sensing; fast multispectral image super-resolution; sparse reconstruction; single image super-resolution; patch-based sparsity; coupled trained overcomplete dictionary; multicore single image SR technique; LR multispectral images; patch-wise sparse representation; morphological component analysis driven feature extraction; remote sensing images	RECONSTRUCTION; RECOVERY	Sparse reconstruction is used to solve the inverse problem of single image super-resolution (SR) as a patch-based sparsity promoting regularisation problem. A coupled trained overcomplete dictionary from high-resolution (HR) and low-resolution (LR) image patches containing significant features is proposed using sparse representation to produce HR patches from their LR counterparts. In this study, the authors develop a multi-core single image SR technique for LR multi-spectral images based on patch-wise sparse representation coupled with morphological component analysis driven feature extraction. Simulations are carried out to evaluate the proposed method using real remote sensing images of a few Indian satellites, RESOURCESAT-2 and CARTOSAT-2, as well as other satellites, such as QuickBird etc. Results are also compared with other existing SR methods to establish the superiority of the proposed method in terms of both objective metrics and visual analysis.																	1751-9659	1751-9667				OCT 16	2020	14	12					2833	2844		10.1049/iet-ipr.2019.0714													
J								Subpixel image registration regularised by L-1 and L-2 norms	IET IMAGE PROCESSING										image registration; medical image processing; brain; iterative methods; nonrigid registration models; rigid registration models; subpixel image registration framework; fundus image registration data; nonrigid subpixel image registration models; rigid subpixel image registration models; transformation function; compact support radial basis functions; nonrigid registration model; rigid transformation parameters; rigid registration model; subpixel image registration problem	ALGORITHM	In this study, the authors propose a subpixel image registration framework that detects and matches feature points. Rigid and nonrigid registration models are employed to solve the problem of subpixel image registration problem. A rigid registration model based on the l(2) norm is proposed to regularise the rotation coefficients using the indicator function to estimate the rigid transformation parameters. The latter estimation simplified is made easy by the reduction in the rigid transformation from two dimensions to one dimension. Furthermore, a non-rigid registration model based on the l(1) and l(2) norms is proposed to estimate the elastic coefficients of the compact support radial basis functions. Due to the linear representation of the transformation function, the rigid and nonrigid subpixel image registration models can be solved efficiently using the fast iterative shrinkage-thresholding algorithm. Experiments on a demosaicing data set, the ocean of remote sensing data set, a brain data set and the fundus image registration data set show that the proposed rigid and non-rigid registration models can accurately perform subpixel image registration.																	1751-9659	1751-9667				OCT 16	2020	14	12					2845	2854		10.1049/iet-ipr.2019.1384													
J								SiameseCCR: a novel method for one-shot and few-shot Chinese CAPTCHA recognition using deep Siamese network	IET IMAGE PROCESSING										image representation; image classification; security of data; data mining; object detection; feature extraction; neural nets; learning (artificial intelligence); one-shot; deep Siamese network; Chinese characters; residual convolutional neural network branches; small-scale Chinese CAPTCHA dataset; known characters; Chinese CAPTCHA recognition model		The research of CAPTCHA recognition is helpful to discover the security vulnerabilities in time and improve its safety. In comparison with digits and English letters, Chinese characters have many more categories which lead to the requirement of a large amount of training data. Therefore, this study proposes a novel method for one-shot and few-shot Chinese CAPTCHA recognition, using the deep Siamese network, based on the idea of template matching. In this method, the residual convolutional neural network branches are used for feature extraction of CAPTCHAs, a fully-connected layer is used for calculating the similarity of features, and a hard negative mining algorithm is designed to promote convergence. Experiments are done on a self-built small-scale Chinese CAPTCHA dataset. The results show that this proposed method can achieve higher accuracy on the known characters than traditional methods. For the brand-new characters, only one template is required to recognise them and the accuracy is close to known characters. To summarise, it is able to build a Chinese CAPTCHA recognition model with high accuracy and extensibility by using a small-scale dataset.																	1751-9659	1751-9667				OCT 16	2020	14	12					2855	2859		10.1049/iet-ipr.2019.0618													
J								Deep learning algorithm for breast masses classification in mammograms	IET IMAGE PROCESSING										mammography; neural nets; image classification; cancer; learning (artificial intelligence); medical image processing; max-pooling; fully connected layers; pre-trained nets; medical image processing techniques; kNN classifier; Mammographic Image Analysis Society; internally collected dataset; CNN model; deep learning algorithm; breast masses classification; breast cancer; Computer-Aided Detection system; convolutional neural network; mammogram images; automatic classification	NEURAL-NETWORKS; SYSTEM	A mammogram is an image of a breast used to detect and diagnose breast cancer. This paper emphases a Computer-Aided Detection system based on convolutional neural network (CNN) that uses the concept of deep learning to classify the mammogram images into benign, malignant and normal. The proposed CNN model consists of eight convolutional, four max-pooling and two fully connected layers and achieved better results compared to the pre-trained nets, AlexNet and VGG16. The proposed model demonstrates the feasibility of using CNNs on medical image processing techniques for the classification of breast masses. The results are also compared with the state-of-the-art machine learning algorithm like kNN classifier. Experimentation is done with three datasets. Among them, two are publicly available, Mammographic Image Analysis Society (MIAS), digital database for screening mammography (DDSM) and an internally collected dataset. The proposed model achieved accuracies of 92.54, 96.47 and 95 and the Area under the ROC curve (AUC) score of 0.85, 0.96 and 0.94 for MIAS, DDSM and the internally collected dataset respectively. Furthermore, the images of the three datasets are merged to build one large set and used to fine tune the proposed CNN model and produced accuracy of 98.32 and AUC of 0.98.																	1751-9659	1751-9667				OCT 16	2020	14	12					2860	2868		10.1049/iet-ipr.2020.0070													
J								Adaptive switching interpolation filter for restoring impulse corrupted digital images	IET IMAGE PROCESSING										computational geometry; median filters; adaptive filters; image denoising; image enhancement; image representation; extrapolation; image restoration; impulse noise; interpolation; impulse corrupted digital images; adaptive switching interpolation filter; interpolation scheme; Shepard's inverse distance; Simpson's natural neighbour interpolation techniques; uncorrupted pixels; natural neighbour-based techniques; interpolation methods; natural intensity variations; image enhancement factor; comparative filters; salt &amp; pepper impulse noise	MEDIAN FILTER; NOISE-REDUCTION; SALT; REMOVAL; EFFICIENT; DENSITY; RESTORATION; ALGORITHM; SUPPRESSION	The study introduces an adaptive switching interpolation filter (ASIF) for restoring images contaminated with salt & pepper impulse noise. The new method restores noisy pixels by applying a new interpolation scheme that combines Shepard's inverse distance weighting and Simpson's natural neighbour interpolation techniques. The new interpolation scheme is designed based on the percentage of the overlapping area and the distance between the sites created by noisy pixels with the sites of uncorrupted pixels in the Voronoi tessellation. Since natural neighbour-based techniques do not support extrapolation, the proposed algorithm performs Shepard's inverse distance weighting-based restoration when the noisy pixels fall outside the convex hull formed by uncorrupted pixels. As the proposed method combines the advantages of Simpson's natural neighbour and Shepard's inverse distance weighting interpolation methods, it better preserves the natural intensity variations in images and provides smoother approximation than other methods used in the comparative study. Visual and quantitative experimental analysis performed on various images with peak signal to noise ratio, mean structural similarity index measure, image enhancement factor, and feature-similarity index measure demarcates the improved capability of ASIF over other comparative filters.																	1751-9659	1751-9667				OCT 16	2020	14	12					2869	2878		10.1049/iet-ipr.2019.1445													
J								Target segmentation of industrial smoke image based on LBP Silhouettes coefficient variant (LBPSCV) algorithm	IET IMAGE PROCESSING										backpropagation; image colour analysis; smoke; image segmentation; air pollution control; neural nets; feature extraction; image texture; image classification; computer vision; environmental science computing; multicolour smoke; target segmentation; industrial smoke image; LBPSCV; computer vision technology; colour information; industrial production; air quality; industrial smoke emissions; natural wind speed; targeted smoke; texture information; local contrast information; extracted texture features; smoke emission monitoring videos; segmented industrial smoke images; local binary pattern silhouette coefficient variant	AIR-POLLUTION	The use of computer vision technology to analyse the characteristics of smoke such as Ringelmann blackness coefficient and colour information can directly and efficiently reflect the situation of smoke emissions in industrial production, which has great significance in improving air quality. As many factors stand in the way, including the amount and speed of industrial smoke emissions, natural wind speed, illumination etc., an accurate and complete detection of the targeted smoke in images becomes a difficult issue in this field. In this study, a local binary pattern Silhouettes coefficient variant (LBPSCV) is proposed to segment industrial smoke images. The variant of Silhouettes coefficient was used as the weight when calculating the local binary pattern (LBP) feature vector in the LBPSCV. The algorithm overcame the shortcoming that the texture information described by LBP lacks local contrast information, making the extracted texture features more easily to be distinguished between smoke and non-smoke images. Smoke emission monitoring videos with different characteristics have been used in experiments, such as smoke emission videos with low light, multiple chimney exhaust, multi-colour smoke etc. The results show that the proposed method has higher detection accuracy and a lower false-positive rate.																	1751-9659	1751-9667				OCT 16	2020	14	12					2879	2889		10.1049/iet-ipr.2019.1315													
J								Novel approach for automatic mid-diastole frame detection in 2D echocardiography sequences for performing planimetry of the mitral valve orifice	IET IMAGE PROCESSING										diseases; medical image processing; Hough transforms; principal component analysis; echocardiography; image sequences; 2D echocardiography sequences; planimetry; mitral valve orifice area; mitral valve stenosis severity; manual method; ROI; circular Hough transform; dimension reduction method; local linear; isometric mapping; kernel principal component analysis; linear PCA algorithms; distance curve; MS patients; LLE method; average frame difference; automatic mid-diastole frame detection; k-means algorithms; 2D space; local linear embedding; Euclidean distance	END-SYSTOLE; NEIGHBORS; NUMBER	The mitral valve orifice area is a reliable measure for evaluating mitral valve stenosis (MS) severity, which is obtained by the planimetry of the mid-diastole frame in the echocardiography sequences. Since the manual method for determining this frame is time-consuming and user-dependent, a novel automatic method has been proposed in this study. First, the region of interest (ROI) containing the mitral valve orifice region is detected using circular Hough transform and k-means algorithms. Then, the dimension reduction method is applied to the ROI of each frame to map it into a point in a 2D space. The performance of the local linear embedding (LLE), isometric mapping, kernel principal component analysis (PCA), and linear PCA algorithms has been evaluated in this study. Finally, a distance curve is obtained by calculating the Euclidean distance between consecutive points in 2D space, and the mid-diastole frame is determined by interpreting this curve. The proposed algorithm was validated using 2D echocardiography of the 20 MS patients. Finally, the LLE method showed the best result, and the average frame difference for 20 cases using the proposed method compared with the gold standard (the echo-cardiologist opinion) was 1.40.																	1751-9659	1751-9667				OCT 16	2020	14	12					2890	2900		10.1049/iet-ipr.2019.1757													
J								Method of multi-region tumour segmentation in brain MRI images using grid-based segmentation and weighted bee swarm optimisation	IET IMAGE PROCESSING										medical image processing; image segmentation; biomedical MRI; brain; tumours; optimisation; swarm intelligence; pattern clustering; sensitivity analysis; multiregion tumour segmentation; grid-based segmentation; weighted bee swarm optimisation; medical diagnostics; brain tumour identification; brain tumour classification; magnetic resonance imaging; computerised digital image processing techniques; decision-making time; grid-based technique; image information; image analysis; segmentation parameters; informative regions; tumour region; brain MRI image segmentation; weighted bee swarm intelligence; brain tumour segmentation; K-means clustering; cerebrospinal fluid; grey matter; white matter; sensitivity analysis; specificity analysis	SHARPENING ENHANCEMENT	Multi-region segmentation plays a major role in numerous medical diagnostics especially brain tumour identification and classification in Magnetic Resonance Imaging (MRI). Brain tumour segmentation is used in medical field for early diagnostics and detection of tumour. The main goal of this work is to improve the performance of detection by using grid based techniques with Weighted Bee Swarm Intelligence and K-means clustering. This technique is more effective due to hybrid combination of segmentation and optimisation as it seems to possess specific tasks of image information and detection to obtain a detailed and accurate image analysis. Grid based segmentation balance overall computation time and reduces complexity. Weighted Bee Swarm Optimisation is used to optimise segmentation parameters to get maximum performance. The various informative regions such as cerebrospinal fluid, grey matter, white matter are segmented by using proposed algorithm which will be most useful to study and characterise the tumour. The experimental outcomes show that the proposed strategy enhances performance measures in terms of sensitivity and specificity analysis. The performance of this technique is also improved by a factor of 1.5%.																	1751-9659	1751-9667				OCT 16	2020	14	12					2901	2910		10.1049/iet-ipr.2019.1234													
J								Row-level algorithm to improve real-time performance of glass tube defect detection in the production phase	IET IMAGE PROCESSING										quality control; production engineering computing; automatic optical inspection; pipes; edge detection; pharmaceuticals; vibrations; production batches; row-level algorithm; real-time performance; glass tube defect detection; production phase; pharmaceutical applications; high-quality defect detection; inspection systems; image processing; real-time inspection; production rate; pharmaceutical market; production process; imperfect cylindrical shape; detection techniques; processing time; defect detection phase; glass tube inspection; row level; perfect tube circular shape; threshold algorithm; defect size detection	INSPECTION; VISION	In the case of the glass tube for pharmaceutical applications, high-quality defect detection is made via inspection systems based on image processing. Such processing must be fast enough to guarantee real-time inspection and to meet the increasing rate and quality required by the market. Defect detection is complex due to specific problems of the production process: vibration, rotation and irregularity of the tube. All these aspects prevent the efficient use of known techniques. The authors present an algorithm that decreases the processing time of the defect detection phase. The algorithm is based on a moving average filter working at row level, that allows to minimize the effects of rotation, vibration, and irregularity of the tube. Luminosity variations due to the tube curvature are cut by the filter and a threshold algorithm can be applied. They made the evaluation considering different solutions taken from literature. The algorithm outperforms, in processing time, all these solutions with increased accuracy. Experimental measures show that the algorithm achieves a throughput gain of 2.6 times with respect to Canny. They develop also a methodology to get the best values for the algorithm parameters directly at the factory, during the change of production batches.																	1751-9659	1751-9667				OCT 16	2020	14	12					2911	2921		10.1049/iet-ipr.2019.1506													
J								Super-resolution image reconstruction using molecular docking	IET IMAGE PROCESSING										image reconstruction; diseases; image enhancement; molecular biophysics; genetic algorithms; proteins; learning (artificial intelligence); drugs; image resolution; medical image processing; super-resolution image reconstruction; molecular docking; drug designing process; disease-causing protein molecule; docking process; learning-based single image super-resolution reconstruction; high resolution patch; structured-spatiogram based measure; similarity criterion; image enhancement; image qualities; LSI-SRR	SIMILARITY; ALGORITHM	Molecular-docking is an essential tool in the drug designing process, where a small molecule ligand (drug) binds with disease-causing protein molecule to prevent its further activity. Docking process helps in predicting the most appropriate configuration and the optimal interaction energy between the interacting molecules (ligand and protein) to form a stable complex. Based on this idea, a new learning-based single image super-resolution reconstruction (LSI-SRR) method is proposed here. Estimation of a high resolution (HR) patch is achieved by optimising the interaction energy between the input low resolution patch and its corresponding candidate patches appropriately chosen from the training image dataset via Genetic algorithm. Structured-spatiogram based measure; a new and competent similarity criterion is proposed to select potentially efficient training images which encompass better statistical and structural co-relation with the input image. The proposed method is tested on synthetic and real-time images at different magnification factors. Performance analysis of the proposed work is compared with some of the representative state-of-the-art LSI-SRR methods. Experimental results demonstrate that the proposed method produces HR images with enhanced image details, minimal artefacts and most importantly enables an efficient trade-off between the image qualities to speed than the competing methods.																	1751-9659	1751-9667				OCT 16	2020	14	12					2922	2936		10.1049/iet-ipr.2019.0491													
J								Distributed ImageJ(Fiji): a framework for parallel image processing	IET IMAGE PROCESSING										medical image processing; image processing; pattern clustering; application program interfaces; existing 3D-Object-Counter plugin; designed cluster-based system; test images; Tagged Image File Format; single machine-based results; image processing time; parallel image processing; open-source application; developer API; specific image processing tasks; distributed systems; single machines; medical images; ImageJ plugins; existing plugins; combined results	SEGMENTATION	ImageJ is an open-source application widely used for image processing. It has developer API that can be used to implement new plugins for specific image processing tasks. However, ImageJ wasn't designed to work on distributed systems. Currently, it is still being used on single machines to process large medical images, which takes several hours to complete. In this article, we present the approaches to make several essential and widely used ImageJ plugins to work in a cluster. As the cluster nodes parallelly run the existing plugins for image processing, they write the results on a shared drive. But one of the main challenges is, merging those results with high accuracy. Several ImageJ plugins were developed to distribute tasks and generate combined results efficiently. The existing 3D-Object-Counter plugin was used for testing the designed system. The experimental results on the test images of 3D objects stored in Tagged Image File Format(TIFF) show faster processing time with high accuracy and similarity compared to the single machine-based results. The image processing time depends on the number of nodes in the cluster. So, we present a mathematical model that determines the cluster size automatically for optimizing the overall image processing time.																	1751-9659	1751-9667				OCT 16	2020	14	12					2937	2947		10.1049/iet-ipr.2019.0150													
J								A point-based redesign algorithm for designing geometrically complex surfaces. A case study: Miralles's croissant paradox	IET IMAGE PROCESSING										geometry; genetic algorithms; splines (mathematics); computational geometry; representation error; realistic representation; genetic morphogenesis; point-based redesign algorithm; geometrically complex surfaces; Miralles's croissant paradox; complex geometry; complex curved geometry; evolutionary morphogenetic processes; point-based genetic algorithm; unstructured point clouds; implemented algorithm; Coyote optimisation algorithm	OPTIMIZATION; TESTS	This study explores the use of point clouds for both representation and genetic morphogenesis of complex geometry. The accurate representation of existing objects of complex curved geometry, which are subsequently geometrically modified by evolutionary morphogenetic processes, is analysed. To this end, as a method of representation and generation of complex geometries, a point-based genetic algorithm and the use of large unstructured point clouds are proposed. A study of convergence and diversity of the implemented algorithm is detailed, as well as a comparison with the Coyote optimisation algorithm in terms of representation error demonstrating its efficiency. Some commonly used three-dimensional formats in architecture, such as NURBS and polygon meshes, are analysed, and compared against point clouds. This study also includes an evaluation regarding whether the use of point clouds is a more suitable format for realistic representation, rationalisation and genetic morphogenesis.																	1751-9659	1751-9667				OCT 16	2020	14	12					2948	2956		10.1049/iet-ipr.2020.0223													
J								A new goodness of fit test in the presence of uncertain parameters	COMPLEX & INTELLIGENT SYSTEMS										Neutrosophy; Neutrosophic numbers; Reliability; Weibull distribution; Classical statistics	LITHIUM-ION BATTERIES; ANDERSON-DARLING TEST; PROGNOSTICS; SOC	The Weibull distribution has been widely used in the areas of quality and reliability. The Anderson-Darling test has been popularly used either the data in hand follow the Weibull distribution or not. The existing Anderson-Darling test under classical statistics is applied when all the observations in quality and reliability work are determined, precised, and exact. In the areas of reliability and quality, the data may indeterminate, in-interval and fuzzy. In this case, the existing Anderson-Darling test cannot be applied for testing the assumption of the Weibull distribution. In this paper, we present the Anderson-Darling test under neutrosophic statistics. We present the methodology to fit the neutrosophic Weibull distribution on the data. We discuss the testing procedure with the help of reliability data. We present the comparisons of the proposed test with the existing Anderson-Darling the goodness of fit test under classical statistics. From the comparison, it is concluded that the proposed test is more informative than the existing Anderson-Darling test under an indeterminate environment. In addition, the proposed test gives information about the measure of indeterminacy.																	2199-4536	2198-6053															10.1007/s40747-020-00214-8		OCT 2020											
J								Applying catastrophe progression method to evaluate the service quality of cold chain logistics	COMPLEX & INTELLIGENT SYSTEMS										Fresh ecommerce; LSQ; Cold chain logistics; Catastrophe progression method; Complexity; Evaluation model	COMPREHENSIVE EVALUATION; DECISION-MAKING; PERFORMANCE; MODEL; MANAGEMENT; COMPANIES	Logistics service quality (LSQ) is one of the key influential factors in the success of an ecommerce business. In view of the complexity of the topic, this paper proposes a novel model for fresh ecommerce cold chain LSQ evaluation based on the catastrophe progression method. In the proposed methodology, first an index system for evaluating the fresh ecommerce cold chain LSQ is established from the perspective of service recipients. Then, the comprehensive weight of each evaluation index is determined using a combination weighting approach based on maximizing deviations and fuzzy set theory. The priority weights and the ranking of the indices are determined using the catastrophe progression method. Finally, the model is applied in a case study of two representative enterprises. The study demonstrates the validity and practical applicability of the proposed model. Also, based on the evaluation results and findings, some improvement suggestions are made for improving the cold chain LSQ of similar kinds of fresh ecommerce companies.																	2199-4536	2198-6053															10.1007/s40747-020-00202-y		OCT 2020											
J								Secure image classification with deep neural networks for IoT applications	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Internet-of-Things; Image classification; Convolutional neural network; Lattice-based homomorphic scheme; Secure multiparty computation	FULLY HOMOMORPHIC ENCRYPTION; PRIVACY; INTERNET; AUTHENTICATION; FRAMEWORK; QUERY	The Internet-of-Things (IoT) are used everywhere in our daily lives. IoT applications provide us with many useful functionalities such as preventing fires, detecting and tracking objects, controlling and reporting the changes in/outside the environments, and capturing images/videos in our homes, roads, and offices. For example, the images data gathered through the smart sensors of autonomous vehicles can serve in various applications such as traffic monitoring, prediction of road conditions, and classification of objects. Image classification with deep neural networks (DNNs) on the cloud is such a machine learning task and has great market potentials for IoT applications. Nevertheless, the deployment of these "smart" IoT devices and applications can raise the risks of security issues. It still suffers from the challenges of relieving IoT devices from excessive computation burdens, such as data encryption, feature extraction, and image classification. In this paper, we propose and implement an indistinguishability-chosen plaintext attack secure image classification framework with DNN for IoT Applications. The framework performs a secure image classification on the cloud without the IoT device's constant interaction. We propose and implement a real number computation mechanism and a divide-and-conquer mechanism for the secure evaluation of linear functions in DNNs, as well as a set of unified ideal protocols for the evaluation of non-linear functions in DNNs. The information about the image contents, the private DNNs model parameters and the intermediate results is strictly concealed by the conjunctive use of the lattice-based homomorphic scheme and 2-PC secure computation techniques. A pre-trained deep convolutional neural network model, i.e., Visual Geometry Group (VGG-16), is used to extract the deep features of an image. The comprehensive experimental results show that our framework is efficient and accurate. In addition, we evaluate the security of our framework by performing the white-box membership inference attack which is believed to be the most powerful attack on DNNs models. The failure of the attack indicates that our framework is practical secure.																	1868-5137	1868-5145															10.1007/s12652-020-02565-z		OCT 2020											
J								Multi-objective long-short term memory recurrent neural networks for speech enhancement	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Speech enhancement; LSTM; DNN; ASR; RNN; Intelligibility; Speech quality	TIME-FREQUENCY MASKING; PHASE ESTIMATION; NOISE; INTELLIGIBILITY; ALGORITHM; FRAMEWORK; QUALITY	Speech-in-noise perception is an important research problem in many real-world multimedia applications. The noise-reduction methods contributed significantly; however rely on a priori information about the noise signals. Deep learning approaches are developed for enhancing the speech signals in nonstationary noisy backgrounds and their benefits are evaluated for the perceived speech quality and intelligibility. In this paper, a multi-objective speech enhancement based on the Long-Short Term Memory (LSTM) recurrent neural network (RNN) is proposed to simultaneously estimate the magnitude and phase spectra of clean speech. During training, the noisy phase spectrum is incorporated as a target and the unstructured phase spectrum is transformed to its derivative that has an identical structure to corresponding magnitude spectrum. Critical Band Importance Functions (CBIFs) are used in training process to further improve the network performance. The results verified that the proposed multi-objective LSTM (MO-LSTM) successfully outscored the standard magnitude-aware LSTM (MA-LSTM), magnitude-aware DNN (MA-DNN), phase-aware DNN (PA-DNN), magnitude-aware GNN (MA-GNN) and magnitude-aware CNN (MA-CNN). Moreover, the proposed speech enhancement considerably improved the speech quality, intelligibility, noise-reduction and automatic speech recognition in changing noisy backgrounds, which is confirmed by the ANalysis Of VAriance (ANOVA) statistical analysis.																	1868-5137	1868-5145															10.1007/s12652-020-02598-4		OCT 2020											
J								A object detection and tracking method for security in intelligence of unmanned surface vehicles	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Unmanned surface vehicles; Environmental perception; Security in intelligence; Object detection; Object tracking; Field experiment verification	TARGET TRACKING	Unmanned surface vehicle is increasingly becoming a research hotspot, which can be used in a variety of civil and military missions. However, compared with the relative maturity of other technologies, the sensing technology of unmanned surface vehicles is relatively weak. Taking "WAM-V-USV" as the research platform, this paper is mainly focus on the detection and tracking methods of moving objects with unmanned surface vehicles. This paper introduces the environment sensing system of unmanned vehicle, water surface image preprocessing, water antenna detection based on SVM, and the method of water surface object detection and tracking based on improved YOLOV3. The simulation results show that the proposed method can effectively improve the accuracy of moving object detection and tracking. Through the practical application in the Songhua River and the US Unmanned Surface Vehicles Open, it is proved that the algorithm has a good detection and tracking effect and meets the real-time requirements. Practice has proved that the object detection and tracking method based on deep learning greatly improves the perception ability and self-security of the unmanned surface vehicles.																	1868-5137	1868-5145															10.1007/s12652-020-02573-z		OCT 2020											
J								An end-to-end fault diagnostics method based on convolutional neural network for rotating machinery with multiple case studies	JOURNAL OF INTELLIGENT MANUFACTURING										Fault diagnostics; Rotating machinery; Vibration signals; Convolutional neural network	WAVELET PACKET TRANSFORM; INSTANTANEOUS FREQUENCY; FEATURE-EXTRACTION; SYSTEM; SIGNAL; REPRESENTATION; DECOMPOSITION; RECOGNITION; FEATURES; VECTOR	The fault diagnostics of rotating components are crucial for most mechanical systems since the rotating components faults are the main form of failures of many mechanical systems. In traditional diagnostics approaches, extracting features from raw input is an important prerequisite and normally requires manual extraction based on signal processing techniques. This suffers of some drawbacks such as the strong dependence on domain expertise, the high sensitivity to different mechanical systems, the poor flexibility and generalization ability, and the limitations of mining new features, etc. In this paper, we proposed an end-to-end fault diagnostics model based on a convolutional neural network for rotating machinery using vibration signals. The model learns features directly from the one-dimensional raw vibration signals without any manual feature extraction. To fully validate its effectiveness and robustness, the proposed model is tested on four datasets, including two public ones and two datasets of our own, covering the applications of ball screw, bearing and gearbox. The method of manual, signal processing based feature extraction combined with a classifier is also explored for comparison. The results show that the manually extracted features are sensitive to the various applications, thus needing fine-tuning, while the proposed framework has a good robustness for rotating machinery fault diagnostics with high accuracies for all the four applications, without any application-specific manual fine-tuning.																	0956-5515	1572-8145															10.1007/s10845-020-01671-1		OCT 2020											
J								Multi-scale fractal residual network for image super-resolution	APPLIED INTELLIGENCE										Image super-resolution; Residual learning; Multi-scale feature fusion; Fractal network	INTERPOLATION	Recent studies have shown that the use of deep convolutional neural networks (CNNs) can improve the performance of single image super-resolution reconstruction (SISR) methods. However, the existing CNN-based SISR model ignores the multi-scale features and shallow and deep features of the image, resulting in relatively low image reconstruction performance. To address these issues, this paper proposes a new multi-scale fractal residual network (MSFRN) for image super-resolution. On the basis of residual learning, a multi-scale fractal residual block (MSFRB) is designed. This block uses convolution kernels of different sizes to extract image multi-scale features and uses multiple paths to extract and fuse image features of different depths. Then, the shallow features extracted at the shallow feature extraction stage and the local features output by all MSFRBs are used to perform global hierarchical feature fusion. Finally, through sub-pixel convolution, the fused global features are used to reconstruct high-resolution images from low-resolution images. The experimental results on the five standard benchmark datasets show that MSFRN improved subjective visual effects and objective image quality evaluation indicators, and is superior to other state-of-the-art SISR methods.																	0924-669X	1573-7497															10.1007/s10489-020-01909-8		OCT 2020											
J								Neural attention model for recommendation based on factorization machines	APPLIED INTELLIGENCE										Recommendation systems; Factorization machines; Attention weight; Feature interactions	ALGORITHM; NETWORKS; SYSTEMS	In recommendation systems, it is of vital importance to comprehensively consider various aspects of information to make accurate recommendations for users. When the low-order feature interactions between items are insufficient, it is necessary to mine information to learn higher-order feature interactions. In addition, to distinguish the different importance levels of feature interactions, larger weights should be assigned to features with larger contributions to predictions, and smaller weights to those with smaller contributions. Therefore, this paper proposes a neural attention model for recommendation (NAM), which deepens factorization machines (FMs) by adding an attention mechanism and fully connected layers. Through the attention mechanism, NAM can learn the different importance levels of low-order feature interactions. By adding fully connected layers on top of the attention component, NAM can model high-order feature interactions in a nonlinear way. Experiments on two real-world datasets demonstrate that NAM has excellent performance and is superior to FM and other state-of-the-art models. The results demonstrate the effectiveness of the proposed model and the potential of using neural networks for prediction under sparse data.																	0924-669X	1573-7497															10.1007/s10489-020-01921-y		OCT 2020											
J								Generalization of GCD matrices	EVOLUTIONARY INTELLIGENCE										Greatest common divisor matrix; Descartes direct-product; Meet semilattice; Meet matrices; Generalized Euler's phi-function; Mobius inversion	GREATEST COMMON DIVISOR; DETERMINANTS; COMPUTATION; BOUNDS	Special matrices are widely used in information society. The gcd-matrices have be conducted to study over Descartes direct-product of some finite positive integer sets. If Descartes direct-product S = S-1 x S-2 x ... x S-n with n finite positive integer sets as direct product terms, then S is finite too. Without loss of generality, set S = {d(1), d(2),.., d(t)}, and for all a = (a(1), a(2), ..., a(n)), b = (b(1), b(2), ..., b(n)) is an element of S, the general greatest common factor is defined as gcd(a, b) = Pi(n)(i=1) gcd(a(i), b(i)). And create a square matrix < S > = (s(ij))(txt) = (gcd(d(i), d(j)))(txt) possessed the general greatest common factors gcd(d(i), d(j)) as arrays s(ij) = gcd(d(i), d(j)). We have researched upper bound and lower bound of the determinant det < S > of the t x t gcd-matrix < S >, and compute the determinant's value under special or specific conditions in the article. At last, some well results about the gcd-matrix has been extend from Descartes direct-product of some finite positive integer sets to general direct product of the posets.																	1864-5909	1864-5917															10.1007/s12065-020-00504-7		OCT 2020											
J								High-speed real-time augmented reality tracking algorithm model of camera based on mixed feature points	JOURNAL OF REAL-TIME IMAGE PROCESSING										Mixed feature points; Augmented reality; New tracking model; Real-time estimation; Detection operator	INTERNET	At this stage of augmented reality, simple feature descriptions are mainly used in camera real-time motion tracking, but this is prone to the problem of unstable camera motion tracking. Aiming at the balance between real-time performance and stability, a new method model of real-time camera motion tracking based on mixed features was proposed. By comprehensively using feature points and feature lines as scene features, feature extraction, optimization, and fusion are used to construct hybrid features, and the hybrid features are unified for real-time camera parameter estimation. An image feature optimization method based on scene structure analysis is proposed to meet the computing constraints of mobile terminals. An iterative feature line-screening method is proposed to calculate a stable feature line set, and based on the scene feature composition and feature geometry, a hybrid feature is adaptively constructed to improve the tracking stability of the camera. Based on improved SIFT feature matching target detection and tracking algorithm, a hybrid feature point detection operator detection algorithm is used to achieve rapid feature point extraction, and the speed of descriptor generation is reduced by reducing the feature descriptor vector dimension. The experimental results prove that the proposed target detection and tracking algorithm has good real-time and robustness, and improves the success rate of target detection and tracking.																	1861-8200	1861-8219															10.1007/s11554-020-01032-4		OCT 2020											
J								A new hybrid model to foretell thermal power efficiency from energy performance certificates at residential dwellings applying a Gaussian process regression	NEURAL COMPUTING & APPLICATIONS										Energy performance certificate (EPC); Gaussian process regression (GPR); Differential evolution (DE); Residential buildings	DIFFERENTIAL EVOLUTION; NEURAL-NETWORKS; PREDICTION; CONSUMPTION; OPTIMIZATION; SIMULATION; ALGORITHM; PROJECT; DEMAND	An energy performance certificate (EPC) provides information on the energy performance of an energy system. The objective of this research aimed at obtaining a predictive model for early detection of thermal power efficiency (TPE) for energy conversion and preservation in buildings. This article expounds a sound and solid nonparametric Bayesian technique known as Gaussian process regression (GPR) approach, based on a set of data collected from different dwellings in an oceanic climate. Firstly, this model introduces the relevance of each predictive variable on energy performance in residential buildings. The second result refers to the statement that we can predict successfully the TPE by using this model. A coefficient of determination equal to 0.9687 was thus established in order to predict the TPE from the observed data, using the GPR approach in combination with the differential evolution (DE) optimiser. The concordance between experimental observed data and the predicted data from the best-proposed novel hybrid DE/GPR-relied model demonstrated here the adequate efficiency of this innovative approach.																	0941-0643	1433-3058															10.1007/s00521-020-05427-z		OCT 2020											
J								Optimization model and algorithm to locate rescue bases and allocate rescue vessels in remote oceans	SOFT COMPUTING										Maritime search and rescue; Base; Site selection; Vessel; Optimization	TEMPORAL ACCESSIBILITY MODEL; MARITIME SEARCH; NANSHA ISLANDS; ABILITY	By improving the efficiency of the long-range maritime search and rescue (LRMSAR), this paper uses the independence of GIS and optimization algorithm to establish calculation module respectively. Firstly, the GIS is used to project the geographic coordinates of past merchant vessels and alternative islands where the maritime search and rescue (SAR) base can be built. Secondly, the K-means clustering algorithm is used to obtain the location of the SAR dynamic duty points. Then, the obtained coordinate data of the alternative islands and the SAR dynamic duty points are input to the optimization algorithm module. Based on the traditional plant growth simulation algorithm, a multi-objective plant growth simulation algorithm is designed by adding the key technologies of fast non-dominated sorting, dominant strength, crowding distance, elite strategy, and partially ordered set. The optimal scheme considering the position of the SAR dynamic duty points, the allocation of SAR vessels and the location of SAR bases is obtained. Finally, taking the construction of SAR base in Spratly Islands of the South China Sea and the allocation of SAR ships as an example, the better results are obtained. To verify the effectiveness of the model and the algorithm in this study, different scales calculating examples were selected for comparison. The calculation results show that the improved algorithm is better in terms of optimization result, solution distribution and adaptability. The research shows that combining the location of SAR bases, the allocation of SAR resources and the spatial analysis function of the GIS for comprehensive optimization can effectively make up for the deficiencies of previous studies and obtain a better optimization scheme. The research results of this study can provide new analysis methods and optimization scheme for the location of SAR bases and the allocation of SAR vessels in remote oceans.																	1432-7643	1433-7479															10.1007/s00500-020-05378-6		OCT 2020											
J								An integrated and discriminative approach for group decision-making with probabilistic linguistic information	SOFT COMPUTING										CRITIC method; Discriminative weights; Gini index; Group decision-making; Maclaurin symmetric mean	EINSTEIN AGGREGATION OPERATORS; TERM SETS; MEAN OPERATORS; SELECTION; WEIGHTS	Group decision-making (GDM) is a complex process. The diversity, discrimination, and inevitable uncertainty due to human intervention characterize such problems that add to this complexity. To circumvent this challenge, there is an urge for an appropriate knowledge representation and decision-making approaches. The present paper is concerned with a prescriptive approach to GDM that can aid a group of decision-makers (DMs) to arrive at a decision. To this end, the recent concept of probabilistic linguistic term set is utilized. The discrimination among the alternatives, as in the real world, are mimicked using an integrated framework that adopts CRITIC and variance methods for attribute weight calculation, Gini index for calculating the weights of DMs, Maclaurin symmetric mean for aggregating preferences, and weighted distance-based approximation for prioritization of alternatives. A real-world problem on electric bike selection illustrates the usefulness of the proposed work. Finally, comparative analysis with extant methods demonstrates the technical results, and it is inferred that the proposed work is (i)highly consistent(from Spearman correlation) and (ii) producesbroad rank values(from standard deviation) that could be efficiently discriminated for rational decision-making and backup management during critical situations.																	1432-7643	1433-7479															10.1007/s00500-020-05361-1		OCT 2020											
J								On bipolar fuzzy soft topology with decision-making	SOFT COMPUTING										Bipolar fuzzy soft set; BFS-topology; BFS-base; Decision-making	SET-THEORY	In this paper, we bring out the idea of bipolar fuzzy soft topology (BFS-topology) based on bipolar fuzzy soft set (BFS-set). BFS-topology is the generalization of the crisp topology. We discuss certain properties of BFS-topology including, BFS-closure, BFS-interior, BFS-exterior and BFS-frontier by utilizing BFS-points. We study the concept of BFS-subspace, BFS-neighbourhoods and BFS-base for BFS-topology with the help of detailed examples. Furthermore, we use BFS-topology in decision-making by applying an algorithm to deal with unpredictability.																	1432-7643	1433-7479															10.1007/s00500-020-05342-4		OCT 2020											
J								Snapshot hyperspectral imaging using wide dilation networks	MACHINE VISION AND APPLICATIONS										Hyperspectral imaging; Deep learning; Convolutional neural networks	QUALITY	Hyperspectral (HS) cameras record the spectrum at multiple wavelengths for each pixel in an image, and are used, e.g., for quality control and agricultural remote sensing. We introduce a fast, cost-efficient and mobile method of taking HS images using a regular digital camera equipped with a passive diffraction grating filter, using machine learning for constructing the HS image. The grating distorts the image by effectively mapping the spectral information into spatial dislocations, which we convert into a HS image by a convolutional neural network utilizing novel wide dilation convolutions that accurately model optical properties of diffraction. We demonstrate high-quality HS reconstruction using a model trained on only 271 pairs of diffraction grating and ground truth HS images.																	0932-8092	1432-1769				OCT 16	2020	32	1							9	10.1007/s00138-020-01136-8													
J								SAT-based and CP-based declarative approaches for Top-Rank-K closed frequent itemset mining	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										Boolean satisfiability; constraint programming; data mining; Top-Kfrequent patterns		Top-Rank-KFrequent Itemset (or Pattern) Mining (FPM) is an important data mining task, where user decides on the number of top frequency ranks of patterns (itemsets) they want to mine from a transactional data set. This problem does not require the minimum support threshold parameter that is typically used in FPM problems. Rather, the algorithms solving the Top-Rank-KFPM problem are fed withK, the number of frequency ranks of itemsets required, to compute the threshold internally. This paper presents two declarative approaches to tackle the Top-Rank-KClosed FPM problem. The first approach is Boolean Satisfiability-based (SAT-based) where we propose an effective encoding for the problem along with an efficient algorithm employing this encoding. The second approach is CP-based, that is, utilizes Constraint Programming technique, where a simple CP model is exploited in an innovative manner to mine the Top-Rank-KClosed FPM itemsets from transactional data sets. Both approaches are evaluated experimentally against other declarative and imperative algorithms. The proposed SAT-based approach significantly outperformsIM, another SAT-based approach, and outperforms the proposed CP-approach for sparse and moderate data sets, whereas the latter excels on dense data sets. An extensive study has been conducted to assess the proposed approaches in terms of their feasibility, performance factors, and practicality of use.																	0884-8173	1098-111X															10.1002/int.22294		OCT 2020											
J								A Comparative Analysis of Machine Learning classifiers for Dysphonia-based classification of Parkinson's Disease	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Parkinson's disease; Machine learning; Deep learning; Feature selection; Dimensionality reduction	SOCIETY-SPONSORED REVISION; SCALE MDS-UPDRS; FEATURE-SELECTION; ALGORITHMS; DIAGNOSIS; PERFORMANCE; PATTERNS; RANKING	Parkinson's Disease is the second most common neurogenerative disease that affects the nervous system. There is no permanent cure for this disease, so, its early diagnosis is important to improve the quality of living of Parkinson patients. The distortion of the voice is one of the first symptoms to appear in Parkinson patients. Therefore, comparison and classification plays an important role. In this paper, a comparison of various classification techniques is done to show the potential of each classifier. The various classification techniques include SVM (Linear, RBF, Polynomial), DT, RF, LR, KNN, NB, MLP, AdaBoost, and XGBoost. Three different types of feature selection techniques are also explored to reduce the dimensionality of the dataset without affecting the accuracy much. The three different feature selection techniques include mRMR, GA, and PCA. The potential of voice features in classification process is also shown.																	2364-415X	2364-4168															10.1007/s41060-020-00234-0		OCT 2020											
J								Field-synchronized Digital Twin framework for production scheduling with uncertainty	JOURNAL OF INTELLIGENT MANUFACTURING										Digital Twin; Equipment health; Fault detection; Simheuristics; Robust scheduling; PHM; FSSP	FLOW-SHOP; GENETIC ALGORITHM; SIMHEURISTIC ALGORITHM; OPTIMIZATION; TARDINESS; HEURISTICS; SIMULATION	Research on scheduling problems is an evergreen challenge for industrial engineers. The growth of digital technologies opens the possibility to collect and analyze great amount of field data in real-time, representing a precious opportunity for an improved scheduling activity. Thus, scheduling under uncertain scenarios may benefit from the possibility to grasp the current operating conditions of the industrial equipment in real-time and take them into account when elaborating the best production schedules. To this end, the article proposes a proof-of-concept of a simheuristics framework for robust scheduling applied to a Flow Shop Scheduling Problem. The framework is composed of genetic algorithms for schedule optimization and discrete event simulation and is synchronized with the field through a Digital Twin (DT) that employs an Equipment Prognostics and Health Management (EPHM) module. The contribution of the EPHM module inside the DT-based framework is the real time computation of the failure probability of the equipment, with data-driven statistical models that take sensor data from the field as input. The viability of the framework is demonstrated in a flow shop application in a laboratory environment.																	0956-5515	1572-8145															10.1007/s10845-020-01685-9		OCT 2020											
J								Heuristic techniques for modelling machine spinning processes	JOURNAL OF INTELLIGENT MANUFACTURING										Machine spinning; Response surface designs; Case based reasoning; Potential function method; Madaline	OPTIMIZATION; DESIGN	In spite of many efforts made a complete model of machine spinning processes, due to its complexity, multidimensionality of the decision space and the present state of knowledge, is unachievable. The paper addresses the issues of constructing a local process model to enable the search for a locally optimal course of the process, within a short time and with the cost as low as possible. Comparison was made between the theoretically well-grounded response surface designs method with a few approaches to the model construction based on intuitively understood heuristic bases justified by their successful practical applications. In order to determine a set of Pareto-optimal solutions for a discrete decision space, the durations of process execution were generated through a virtual simulation. In order to outline and justify the adopted solutions a comprehensive example of the practical construction of the machine spinning process model was presented, including its various versions. The results obtained were validated and evaluated. The main utilitarian conclusion is the indication whereby basing on a partial experiment plan it is possible, thanks to simple heuristic methods, to obtain Pareto-optimal solutions which are close to those obtained when the full experiment plan is carried out.																	0956-5515	1572-8145															10.1007/s10845-020-01683-x		OCT 2020											
J								Decision rule mining for machining method chains based on rough set theory	JOURNAL OF INTELLIGENT MANUFACTURING										Machining method; Process planning; Rule mining; Rough set theory; Derivation rules	TOOL	Decision rules for machining method chains mined from historical machining documents can help technologists quickly design new machining method chains. However, the main factor that limits the practical application of existing rough set models is that the boundary regions are too large. Therefore, a decomposition-reorganization method (DRM) is proposed to mine rules for machining method chains. First, binary coding is used to decompose the existing machining method chains, and the decision rules for a single machining method are mined based on rough set reduction. Then, machining method chains are obtained by reorganizing the machining methods in accordance with the decision rules. DRM can eliminate the boundary regions without human intervention and recommend machining method chains for all features whose parameters have appeared in historical machining documents. Finally, three types of shell parts are used to verify the effectiveness of DRM.																	0956-5515	1572-8145															10.1007/s10845-020-01692-w		OCT 2020											
J								Semantic ranking structure preserving for cross-modal retrieval	APPLIED INTELLIGENCE										Cross-modal retrieval; Common space learning; Graph convolutional; Semantic structure preserving		Cross-modal retrieval not only needs to eliminate the heterogeneity of modalities, but also needs to constrain the return order of retrieval results. Accordingly, we propose a novel common representation space learning method, called Semantic Ranking Structure Preserving (SRSP) for Cross-modal Retrieval in this paper. First, the dependency relationship between labels is used to minimize the discriminative loss of multi-modal data and mine potential relationships between samples to get richer semantic information in the common space. Second, we constrain the correlation ranking of representations in common space, so as to break the modal gap and promote the multi-modal correlation learning. The comprehensive experimental comparison results show that our algorithm substantially enhances the performance and consistently outperforms very recent algorithms in terms of widely used cross-modal benchmark datasets.																	0924-669X	1573-7497															10.1007/s10489-020-01930-x		OCT 2020											
J								Trainable activation function with differentiable negative side and adaptable rectified point	APPLIED INTELLIGENCE										Activation functions; Self-normalizing neural networks; Parameterized learning; Rectified point	IMAGE SUPERRESOLUTION	Activation function is one of the keys for Artificial Neural Network in learning complex mapping function. A recently proposed activation function called Scaled Exponential Linear Unit (SELU) has a unique characteristic in the ability to automatically normalize its output toward predefined mean and variance. In this paper, we introduce Parametric Scaled Exponential Linear Unit (PSELU), a modification of SELU where the parameters are adaptively learned during the training phase via backpropagation algorithm. We then add further modifications with the aim of having a stronger gradient in the negative part and produce more negative output from our proposed method. Our proposed method is evaluated using various artificial neural network models on diverse image classification tasks. In addition, we also measure the performance of our proposed method in comparison with some other popular activation functions. The evaluation results in this paper present some empirical proof of improvement in term of network generalization performance. Moreover, our experiments strengthen our initial hypothesis regarding the advantages obtained from using our proposed method. Finally, the behavior of the trained parameters along with the training phase dynamic is observed in order to better understand the increased performance of our proposed method																	0924-669X	1573-7497															10.1007/s10489-020-01885-z		OCT 2020											
J								Cloud theory-based simulated annealing for a single-machine past sequence setup scheduling with scenario-dependent processing times	COMPLEX & INTELLIGENT SYSTEMS										Machine scheduling; Setup times; Scenario-dependent processing times; Cloud theory-based simulated annealing	OPTIMIZATION	Recently, the setup times or costs have become an important research topic. The main reason is huge economic savings can be achieved when setup times are explicitly included in scheduling decisions in various real-world industrial environments. On the other hand, many real systems commonly face various uncertainties, such as working environment changes, machine breakages, a worker becomes unstable, etc. In such an environment, job-processing times should not be fixed numbers. Motivated by these situations, this article introduces a single-machine scheduling problem with sequence-dependent setup times and scenario-dependent processing times where the objective function is the total completion time. The robust version of this problem without setup times has been shown to be NP hard. To tackle this problem, a lower bound and a dominance rule are derived in a branch-and-bound method for finding an optimal solution. As for determining approximate solutions, five neighborhood schemes are proposed and embedded in the cloud theory-based simulated annealing. Finally, the performances of all proposed algorithms are determined and compared.																	2199-4536	2198-6053															10.1007/s40747-020-00196-7		OCT 2020											
J								An adaptive defense mechanism to prevent advanced persistent threats	CONNECTION SCIENCE										Advanced persistent threats; moving target defense; risk assessment; Bayesian network; Markov game		The expansion of information technology infrastructure is encountered with Advanced Persistent Threats (APTs), which can launch data destruction, disclosure, modification, and/or Denial of Service attacks by drawing upon vulnerabilities of software and hardware. Moving Target Defense (MTD) is a promising risk mitigation technique that replies to APTs via implementing randomisation and dynamic strategies on compromised assets. However, some MTD techniques adopt the blind random mutation, which causes greater performance overhead and worse defense utility. In this paper, we formulate the cyber-attack and defense as a dynamic partially observable Markov process based on dynamic Bayesian inference. Then we develop an Inference-Based Adaptive Attack Tolerance (IBAAT) system , which includes two stages. In the first stage, a forward-backward algorithm with a time window is employed to perform a security risk assessment. To select the defense strategy, in the second stage, the attack and defense process is modelled as a two-player general-sum Markov game and the optimal defense strategy is acquired by quantitative analysis based on the first stage. The evaluation shows that the proposed algorithm has about 10% security utility improvement compared to the state-of-the-art.																	0954-0091	1360-0494															10.1080/09540091.2020.1832960		OCT 2020											
J								An insect inspired approach for optimization of tasks scheduling in computational grids	EVOLUTIONARY INTELLIGENCE										Computational grids; Grid computing; Grid scheduling; Task optimization	ALGORITHM; EVOLUTION; SHOP	The article suggests a novel optimization algorithm named Lepidoptera butterfly approach (LBA) that is inspired from the behavior of insects, American butterflies and their counterparts. This algorithm keenly observes the behavior of the Lepidoptera insects and tries to find an optimal solution through a larger solution space. The proposed algorithm LBA mimics the behavioral aspects of these insects. The insects (butterflies) migrate more often from one land to another in search of food particles and reproduction of offsprings. If they find the food particles and climate of the new land suitable, these insects often reproduce their offsprings in this new land. Hence, the suggested approach classifies the network of grids into two subnetworks (or two different lands) and thereby, generates two sub-populations. The algorithm then considers each individual subnetwork and their subpopulations. In our case, these are the jobs that contribute to each subnetwork and the offsprings that are reproduced are called as tasks. Our algorithm finds the best tasks and best jobs in every subnetwork and finally combines them and try to allocate the tasks/jobs to resources considering the constraints like cost and make-span time. However, this scheduling of tasks is considered as an NP-Complete problem. The algorithm is tested using 30 runs for simulation under these two constraints. This article makes a comparison with different existing optimization techniques like GA, TLBO, etc. The results signifies that our proposed approach of LBA performs better as compared to others. This inspires the authors to study the performance behavior of this approach in optimizing the scheduling problem in a computational grid environment under the constraints like time and cost.																	1864-5909	1864-5917															10.1007/s12065-020-00508-3		OCT 2020											
J								Visualizing the Intellectual Structure of the Fuzzy Linguistic Knowledge Domain: A Bibliometric Analysis	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Bibliometrics; Fuzzy linguistic; Computing with words; Linguistic variable; CiteSpace	GROUP DECISION-MAKING; TERM SETS; AGGREGATION OPERATORS; SCIENTIFIC-RESEARCH; MAPPING SOFTWARE; EMERGING TRENDS; INFORMATION; MODEL; CITATION; SYSTEMS	Ever since the 1970s when the idea of fuzzy linguistic variable was introduced by L. Zadeh, it has been heatedly discussed and widely used in engineering, information science, and many other research fields. With the rapid development and use, thousands of papers have been published on fuzzy linguistic, detailing both theoretical development and application-oriented studies, being a very important area in the Computational Intelligence field. Considering this massive document material over the past decades, the main purpose of this study is to explore the knowledge structure and citation landscape in this field based on scientometrics and bibliometrics. The document data used in this study are obtained through a topic search from Web of Science, including 4350 original research and review articles. The intellectual structure of fuzzy linguistic knowledge domain is analyzed, such as countries and territories, research institutions, and authors. The bibliographic landscape is analyzed, identifying research themes and current research hotspots through document co-citation analysis and citation burst detection methods. The research results of this article remarkably benefit to our understanding of the fuzzy linguistic knowledge domain.																	1562-2479	2199-3211															10.1007/s40815-020-00959-x		OCT 2020											
J								Vehicle energy system active defense: A health assessment of lithium-ion batteries	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										active defense; health assessment; lithium-ion battery	STATE-OF-HEALTH; INCREMENTAL CAPACITY ANALYSIS; GAUSSIAN PROCESS REGRESSION; REMAINING USEFUL LIFE; ELECTRIC VEHICLES; KALMAN FILTER; ONLINE STATE; CHARGE; MODEL; PARAMETER	With the wide application of lithium-ion battery in various fields, the security and reliability of lithium-ion battery have attracted great attention. Under the mode of continuous development of Internet of vehicles technology, vehicles will be connected with each other in the future, and the hackers will attack the energy system of the vehicle. However, health assessment of lithium-ion battery can timely grasp the running state and health of the power battery system, so as to realize active defense against hacker security attacks. This paper proposes a health assessment method for lithium-ion batteries using incremental capacity analysis and weighted Kalman filter algorithm. In view of the problem that ordinary Kalman filtering algorithm produces poor filtering results when the actual measurement noise error is large, this paper proposes a weighted Kalman filtering algorithm based on ordinary Kalman filtering. Incremental capacity analysis was performed on the charge and discharge data of lithium-ion batteries, and health characteristics were extracted to construct a Gaussian nonlinear feature association mapping model for the health characteristics of lithium-ion batteries. Combined with the battery SOH double-exponential decay model, the weighted Kalman filter algorithm was used to evaluate the health of lithium-ion batteries. Four lithium-ion battery data sets provided by NASA were used to simulate and verify the health assessment method proposed in this paper. The verification results show that the health assessment method based on weighted Kalman filter proposed in this paper has better assessment accuracy than the common Kalman filter method with an average percentage error of 0.61%. The average percentage error of the assessment results for different types of batteries was less than 0.9%. The health assessment method has high accuracy and is suitable for different types of batteries.																	0884-8173	1098-111X															10.1002/int.22309		OCT 2020											
J								An improved real-coded genetic algorithm with random walk based mutation for solving combined heat and power economic dispatch	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Combined heat and power (CHP); economic dispatch; real-coded genetic algorithm; random walk; complex optimization problem	CUCKOO SEARCH ALGORITHM; PARTICLE SWARM OPTIMIZATION	Combined heat and power economic dispatch (CHPED) is an energy management problem that minimizes the operation cost of power and heat generation while a vast variety of operational constraints of the system should be met. The CHPED is a complicated, non-convex and non-linear problem. In this study, a new real-coded genetic algorithm with random walk-based mutation (RCGA-CRWM) is under study, which is effective in solving large-scale CHPED problem with minimum operation cost. In the presented optimization method, a simple approach is introduced to combine the positive features of different probabilistic distributions for the step size of random walk. Using the presented approach, while the genetic algorithm is speeded up, the premature convergence is also avoided. After verifying the performance of the presented method on the benchmark functions, two large-scale and two medium-scale case studies are used for determining the algorithm strength in solving the CHPED problem. Despite the fact that the complexity of the CHPED rises dramatically by increasing its dimensionality, the algorithm has solved the problems accurately. The application of RCGA-CRWM method improves the results of the CHPED problem in terms of both operation cost and convergence speed in comparison with other optimization methods.																	1868-5137	1868-5145															10.1007/s12652-020-02589-5		OCT 2020											
J								Aitac: an identity-based traceable anonymous communication model	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Identity-based encryption; Bilinear map; Privacy protection; Identifications; Anonymous communications		In the big data background, data privacy becomes more and more important when data leakage and other security events occur more frequently. As one of the key means of privacy protection, anonymous communication attracts large attention. Aiming at the problems such as low efficiency of message forwarding, high communication delay and abusing of anonymity, this paper presents an identity-based traceable anonymous communication model by adding a preprocessing phase, modifying the ciphertext structure and increasing the controllability of anonymity. Firstly, a new identity-based signature algorithm is proposed, and its security is proved via existential unforgeability against chosen-message attacks (EU-CMA). The signature algorithm is further applied to the anonymous communication model to implement the controllability of revocable anonymity. Secondly, by adding a preprocessing Setup phase, the operations of identifications distribution and user authentication are launched before the anonymous communication phase starts, and this practice significantly improves the efficiency of the anonymous communication model. Finally, by adding the hash value of the message and the user identification as the message authentication code, we design a new ciphertext structure, which can efficiently guarantee the integrity of the ciphertext. Performance analysis and simulation results show that the proposed anonymous communication model has high message forwarding efficiency and better security and controllability of anonymity.																	1868-5137	1868-5145															10.1007/s12652-020-02604-9		OCT 2020											
J								Multi-station test scheduling optimization method for industrial robot servo system	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Industrial robot; Servo system; Performance testing; Scheduling model; Scheduling optimization	KNAPSACK-PROBLEM; ALGORITHM	This study examined the test scheduling optimization problem of industrial robot servo system (IRSS) samples with unequal numbers of different types of test items on the multiple IRSS comprehensive test platforms with the same function. In order to improve IRSS performance test efficiency, a multi-station test scheduling optimization method, which combines IRSS sample-level scheduling and test item-level scheduling, was proposed. First, the IRSS sample-level scheduling was carried out, and a model was established with reference to the identical parallel machine problem (IPMP). The optimal result of IRSS sample-level multi-station scheduling was obtained by solving the model. Second, based on the result of IRSS sample-level multi-station scheduling, and taking the ideal optimal test completion time of IRSS multi-station scheduling as the target, the test items at the stations were reallocated to obtain the optimal scheduling result. Finally, an application example was used to verify the efficiency of the proposed method, and the experiment result showed that the proposed method can effectively fulfill the optimal allocation of different IRSS test items of multiple IRSS samples on multiple IRSS comprehensive test platforms. The test time was 247 min shorter than the conventional sequential parallel test and only one min longer than the ideal optimal test completion time.																	1868-5137	1868-5145															10.1007/s12652-020-02577-9		OCT 2020											
J								Uncertain distance-based outlier detection with arbitrarily shaped data objects	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Nearest neighbors; Outlier detection; Uncertain data; Unsupervised learning	ALGORITHMS	Enabling information systems to face anomalies in the presence of uncertainty is a compelling and challenging task. In this work the problem of unsupervised outlier detection in large collections of data objects modeled by means of arbitrary multidimensional probability density functions is considered. We present a novel definition ofuncertain distance-based outlierunder the attribute level uncertainty model, according to which an uncertain object is an object that always exists but its actual value is modeled by a multivariate pdf. According to this definition an uncertain object is declared to be an outlier on the basis of the expected number of its neighbors in the dataset. To the best of our knowledge this is the first work that considers the unsupervised outlier detection problem on data objects modeled by means of arbitrarily shaped multidimensional distribution functions. We present the UDBOD algorithm which efficiently detects the outliers in an input uncertain dataset by taking advantages of three optimized phases, that are parameter estimation, candidate selection, and the candidate filtering. An experimental campaign is presented, including a sensitivity analysis, a study of the effectiveness of the technique, a comparison with related algorithms, also in presence of high dimensional data, and a discussion about the behavior of our technique in real case scenarios.																	0925-9902	1573-7675															10.1007/s10844-020-00624-7		OCT 2020											
J								Image Reconstruction by Minimizing Curvatures on Image Surface	JOURNAL OF MATHEMATICAL IMAGING AND VISION										Image reconstruction; Image surface; Differential geometry; Curvature regularization; Mean curvature; Gaussian curvature	AUGMENTED LAGRANGIAN METHOD; EULERS ELASTICA; VARIATIONAL APPROACH; GAUSSIAN CURVATURE; NOISE REMOVAL; SEGMENTATION; MODEL; CONVEX; TV; RESTORATION	The curvature regularities are well-known for providing strong priors in the continuity of edges, which have been applied to a wide range of applications in image processing and computer vision. However, these models are usually non-convex, non-smooth, and highly nonlinear, the first-order optimality condition of which are high-order partial differential equations. Thus, numerical computation is extremely challenging. In this paper, we estimate the discrete mean curvature and Gaussian curvature on the local 3 x 3 stencil, based on the fundamental forms in differential geometry. By minimizing certain functions of curvatures over the image surface, it yields a kind of weighted image surface minimization problem, which can be efficiently solved by the alternating direction method of multipliers. Numerical experiments on image restoration and inpainting are implemented to demonstrate the effectiveness and superiority of the proposed curvature-based model compared to state-of-the-art variational approches.																	0924-9907	1573-7683															10.1007/s10851-020-00992-3		OCT 2020											
J								Deep representation-based packetized predictive compensation for networked nonlinear systems	NEURAL COMPUTING & APPLICATIONS										Deep representation; Networked control systems; Data packet dropouts; Stabilization	SPARSE; ROBUST; DELAY	The design of networked nonlinear control system is a very challenging problem due to the coupling of the system uncertainties (e.g., model accuracy, noise, nonlinearity) and network effects (e.g., packet dropouts, time delay). In this paper, a deep representation-based predictive compensation method is proposed for networked nonlinear systems with packet-dropouts in the feedback and forward channel. Different from the existing compensation methods based on open-loop prediction, the proposed method is based on feedback compensation and does not require a nominal system model, so that it can avoid the coupling of system uncertainties and network effects as well as the occupation of network bandwidth. Specifically, a deep sequence to sequence learning scheme is firstly employed to encode the correlations of state and control sequences into deep feature representations. Furthermore, within the embedding space spanned by the learned features, according to the state-control sequence of each sampling step, a prediction of the next control command is generated as compensation for packet dropout. The stability of the overall system is rigorously proved by the Lyapunov theory, which reveals that the control errors for the networked control systems with packet dropouts asymptotic converge to a small neighborhood of the origin. We further evaluate the performance of the proposed strategy on a wheeled mobile robots simulation platform, and the experimental results demonstrate that our method can achieve high compensation accuracy and robustness concerning packet dropouts, even in the case of the maximum continuous packet dropouts specified by the network communication protocol.																	0941-0643	1433-3058															10.1007/s00521-020-05346-z		OCT 2020											
J								From text to graph: a general transition-based AMR parsing using neural network	NEURAL COMPUTING & APPLICATIONS										Semantic analysis; AMR parsing; Two-stack-based transition algorithm; Neural network		Semantic understanding is an essential research issue for many applications, such as social network analysis, collective intelligence and content computing, which tells the inner meaning of language form. Recently, Meaning Representation (AMR) is attracted by many researchers for its semantic representation ability on an entire sentence. However, due to the non-projectivity and reentrancy properties of AMR graphs, they lose some important semantic information in parsing from sentences. In this paper, we propose a general AMR parsing model which utilizes a two-stack-based transition algorithm for both Chinese and English datasets. It can incrementally parse sentences to AMR graphs in linear time. Experimental results demonstrate that it is superior in recovering reentrancy and handling arcs while is competitive with other transition-based neural network models on both English and Chinese datasets.																	0941-0643	1433-3058															10.1007/s00521-020-05378-5		OCT 2020											
J								Spatiotemporal dynamic of a coupled neutral-type neural network with time delay and diffusion	NEURAL COMPUTING & APPLICATIONS										Neutral-type; Turing instability; Oscillation; Stability; Reaction diffusion	HOPF-BIFURCATION; PERIODIC-SOLUTIONS; SYNCHRONIZATION; STABILITY; MODEL	In this paper, a delayed neutral-type neural network with diffusion is considered. Three spatiotemporal dynamic problems of such network, i.e., stability, Turing instability and oscillation, are addressed in detail. It is found that the diffusion may lead to Turing instability, and the time delay may result in oscillation. Then, a novel computing method is proposed to investigate the oscillation properties. Finally, numerical results not only verify the obtained results but also show the diffusion coefficients have a great effect on the appearance of pattern. There are six spatiotemporal patterns when diffusion varying.																	0941-0643	1433-3058															10.1007/s00521-020-05404-6		OCT 2020											
J								The Mode-Fisher pooling for time complexity optimization in deep convolutional neural networks	NEURAL COMPUTING & APPLICATIONS										Convolutional neural networks CNNs; Mode-Fisher pooling; Energy	ILLUMINANT ESTIMATION; IMAGE FEATURES; COLOR	In this paper, we aim to improve the performance, time complexity and energy efficiency of deep convolutional neural networks (CNNs) by combining hardware and specialization techniques. Since the pooling step represents a process that contributes significantly to CNNs performance improvement, we propose theMode-Fisher poolingmethod. This form of pooling can potentially offer a very promising results in terms of improving feature extraction performance. The proposed method reduces significantly the data movement in the CNN and save up to 10% of total energy, without any performance penalty.																	0941-0643	1433-3058															10.1007/s00521-020-05406-4		OCT 2020											
J								Applications of metaheuristic algorithms for optimal operation of cascaded hydropower plants	NEURAL COMPUTING & APPLICATIONS										Cuckoo search algorithm; Cascaded reservoir system; Total power energy; Hydropower plants	CUCKOO SEARCH ALGORITHM; SYSTEM; EVOLUTIONARY	In this paper, two optimal operation plans of a cascaded reservoir system with four hydropower plants are studied for reaching the highest power energy of all the power plants. In the first plan, called local optimization plan, optimal water discharge of each upstream hydropower plant is determined first and the optimal discharge is then used as input data for determining optimal water discharge of other downstream hydropower plants. In the second plan, called global optimization plan, optimal water discharge of all hydropower plants is simultaneously determined. For reaching the highest total power energy of the system, nine methods consisting of moth swarm algorithm, Harris hawks optimization, cuckoo search algorithm (CSA), snap drift cuckoo search algorithm (SD-CSA), stochastic fractal search algorithm, parasitism predation algorithm, marine predator algorithm, tunicate swarm algorithm, and the proposed improved cuckoo search algorithm (ICSA) are implemented. Among the methods, the proposed ICSA is first developed by improving the exploitation phase of CSA. The comparisons of power energy from each hydropower plant for the two plans indicate that local optimization plan is more useful for upstream plants but for downstream plants, whereas global optimization plan is more useful for downstream plants. For the purpose of reaching the highest total power energy for the whole system, the global optimization plan is more effective because it reaches higher power energy than local optimization plan. For investigating the improvement of the proposed method over CSA and SD-CSA, the three methods are run for seven benchmark functions and for the global optimization plan with different population sizes and different iteration numbers. As a result, it is recommended that global optimization plan should be applied for all hydropower plants in cascaded systems and downstream plants with higher power energy can share benefit to upstream ones. In addition, one of the most effective methods that should be recommended for implementing global optimization plan is the proposed ICSA.																	0941-0643	1433-3058															10.1007/s00521-020-05418-0		OCT 2020											
J								Selective information passing for MR/CT image segmentation	NEURAL COMPUTING & APPLICATIONS										Medical image segmentation; Convolutional neural network; Attention-focused module		Automated medical image segmentation plays an important role in many clinical applications, which however is a very challenging task, due to complex background texture, lack of clear boundary and significant shape and texture variation between images. Many researchers proposed an encoder-decoder architecture with skip connections to combine low-level feature maps from the encoder path with high-level feature maps from the decoder path for automatically segmenting medical images. The skip connections have been shown to be effective in recovering fine-grained details of the target objects and may facilitate the gradient back-propagation. However, not all the feature maps transmitted by those connections contribute positively to the network performance. In this paper, to adaptively select useful information to pass through those skip connections, we propose a novel 3D network with self-supervised function, named selective information passing network. We evaluate our proposed model on the MICCAI Prostate MR Image Segmentation 2012 Grant Challenge dataset, TCIA Pancreas CT-82 and MICCAI 2017 Liver Tumor Segmentation Challenge dataset. The experimental results across these datasets show that our model achieved improved segmentation results and outperformed other state-of-the-art methods. The source code of this work is available at https://github.com/ahukui/SIPNet.																	0941-0643	1433-3058															10.1007/s00521-020-05407-3		OCT 2020											
J								A novel fuzzy approach for segmenting medical images	SOFT COMPUTING										Gaussian kernel; Interval Type 2 fuzzy set; Hamacher T-conorm; Fuzzy clustering; Biomedical imaging	KRILL HERD ALGORITHM; SEGMENTATION; OPERATORS; SETS	In various medical imaging studies, the segmentation of the medical image is a crucial step. Due to the inherent behavior of the images, the computerized tomography (CT) scan/magnetic resonance imaging (MRI) images are not clear. As the medical images are captured using electronic devices, these images are ambiguous and unclear. This ambiguity in the images is due to factors related to noise and the environment while capturing images. A fuzzy set is a valuable method to deal with data uncertainty. In this paper, a novel clustering approach based upon a fuzzy concept is proposed, which enhances the vague MRI/CT scan image before segmentation. Initially, the image noise is minimized by processing eight immediate neighborhood pixels around each pixel in an image. After noise processing, upper and lower membership levels of the image are computed. Hamacher T-conorm is used as an aggregation operator to construct a new membership function using upper and lower membership levels. The enhanced image, created using the new membership function, is then segmented using Gaussian kernel-based fuzzy c means clustering. The experiment is performed on MRI/CT scan brain tumor images. Real data experiments demonstrate that the proposed algorithm has better performance when compared with existing methods both quantitatively and qualitatively. It is observed that even in the presence of noise, the proposed method exhibits better efficiency.																	1432-7643	1433-7479															10.1007/s00500-020-05386-6		OCT 2020											
J								Hierarchical stroke mesh: a new progressive matching method for detecting multi-scale road network changes using OpenStreetMap	SOFT COMPUTING										OSM; Progressive matching; Hierarchical stroke mesh (HSM); Hierarchical partition; Multi-scale matching constraint rules		Spatial feature matching is the key to detecting incremental changes in spatial data and extracting the updated information. The accuracy of spatial feature matching can depend on the structural organization of the data being compared; inconsistent data structures make comparison more difficult. OpenStreetMap (OSM) road network data, for example, is updated frequently to the point of being unstable, making the matching process used in information extraction susceptible to interference. To use OSM for comparison with other road data sources, this problem must be addressed. This paper proposes a new multi-scale dynamic matching algorithm based on a hierarchical stroke mesh (HSM) to detect matches between OSM data and professional surveying and mapping data and to update the change information. By improving the integrity and continuity of the stroke generation method and its algorithm for evaluating the importance of information, the algorithm proposed in this paper identifies the spatial hierarchy contained in the road network and abstracts the road network. The result is the HSM. The algorithm is based on multi-scale matching constraint rules designed from coarse to fine in terms of both resolution and granularity. It is used to detect one-to-one or one-to-many mapping relationships among different mesh levels (mesh, mesh boundary segment, and mesh inner segment). This allows progressive iterative matching between the older survey data and the newer OSM data. The results show that the HSM algorithm proposed in this paper can detect incremental changes between the two vector data sources quickly and accurately. Compared with others, this algorithm can effectively improve matching accuracy while sacrificing little performance.																	1432-7643	1433-7479															10.1007/s00500-020-05371-z		OCT 2020											
J								Group competition-cooperation optimization algorithm	APPLIED INTELLIGENCE										Deep evolution; Competition model; Cooperation model; Feature transformation	EVOLUTIONARY	In order to solve complex practical problems, the model of deep learning can not be limited to models such as deep neural networks. To deepen the learning model, we must actively explore various depth models. Based on this, we propose a deep evolutionary algorithm, that is group competition cooperation optimization (GCCO) algorithm. Unlike the deep learning, in the GCCO algorithm, depth is mainly reflected in multi-step iterations, feature transformation, and models are complex enough. Firstly, the bio-group model is introduced to simulate the behavior that the animals hunt for the food. Secondly, according to the rules of mutual benefit and survival of the fittest in nature, the competition model and cooperation model are introduced. Furthermore, in the individual mobility strategy, the wanderers adopt stochastic movement strategy based on feature transformation to avoid local optimization. The followers adopt the variable step size region replication method to balance the convergence speed and optimization precision. Finally, the GCCO algorithm and the other three comparison algorithms are used to test the performance of the algorithm on ten optimization functions. At the same time, in the actual problem of setting up the Shanghai gas station the to improve the timely rate, GCCO algorithm achieves better performance than the other three algorithms. Moreover, Compared to the Global Search, the GCCO algorithm takes less time to achieve similar effects to the Global Search.																	0924-669X	1573-7497															10.1007/s10489-020-01913-y		OCT 2020											
J								Preprocessing methods for near-infrared spectrum calibration	JOURNAL OF CHEMOMETRICS										NIR calibration; partial least square regression; performance evaluation; preprocessing; Savitzky-Golay (SG) smoothing	PARTIAL LEAST-SQUARES; ORTHOGONAL SIGNAL CORRECTION; NIR SPECTROSCOPY DATA; MULTIVARIATE CALIBRATION; MOISTURE-CONTENT; REFLECTANCE SPECTROSCOPY; FTIR SPECTROSCOPY; SOIL PROPERTIES; TRANSFORM; MODELS	Spectrum preprocessing is an essential component in the near-infrared (NIR) calibration. However, it has mostly been configured arbitrarily in the literature and calibration applications. In this paper, a systematic evaluation framework was proposed to quantify the effect of preprocessing, where repeated cross-validation and evaluation are involved. As many as 108 preprocessing schemes were gathered from the literature and were tested on 26 different NIR calibration problems. Using the evaluation framework, appropriate schemes can be found for several datasets, reducing the root mean square error of prediction (RMSEP) by 50%-60% compared with using the raw spectrum. However, the influence of preprocessing is highly data-dependent, and no universal solution could be found. Taking the effectiveness and correlation into consideration, Savitzky-Golay (SG), SG1D, and SG1D + vector normalization (VN)(/standard normal variate [SNV]) are worth testing first. Nevertheless, the heterogeneity at both the dataset level and sample level demonstrated the necessity of a complete evaluation. Our scripts are available at .																	0886-9383	1099-128X														e3306	10.1002/cem.3306		OCT 2020											
J								Empirical study of sentiment analysis tools and techniques on societal topics	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS										Sentiment analysis; Societal topics; Publicly available sentiment analysis tools; Machine learning techniques	CLASSIFICATION; TWITTER	A surge in public opinions mining against various societal topics using publicly available off-the-shelf sentiment analysis tools is evident in recent times. Since sentiment analysis is a domain-dependent problem, and the majority of the tools are built for customer reviews, the suitability of using such existing off-the-the-shelf tools for a societal topic is subject to investigation. None of the existing studies has thoroughly investigated on societal issues. This paper systematically evaluates the performance of 10 popularly used off-the-shelf tools and 17 state-of-the-art machine learning techniques and investigates their strengths and weaknesses using various societal and non-societal topics.																	0925-9902	1573-7675															10.1007/s10844-020-00616-7		OCT 2020											
J								Multi-block data analysis for online monitoring of anaerobic co-digestion process	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Anaerobic digestion; Online monitoring; Multi-block analysis; SO-PLS; SO-CovSel	NEAR-INFRARED SPECTROSCOPY; VOLATILE FATTY-ACIDS; VARIABLE SELECTION; BIOGAS PRODUCTION; WASTE-WATER; PLS; PREDICTION; EXTENSION; MODELS; SYSTEM	Anaerobic digestion is a chemical process whose purpose is to maximize biogas production whilst concomitantly treating organic waste mostly through co-digestion due to the variety of substrates. To avoid failures, the process requires the monitoring of several parameters and / or inhibitors. The existing strategies and methods used in the process monitoring still lack sensitivity and robustness, when taken individually. The current study investigated the use of sequential and orthogonalized partial least squares (SO-PLS) regression to relate these parameters to several blocks of data coming for near infrared spectroscopy, chemical routine analysis and kinetics of biogas production. The models produced were able to extract relevant information from each block's data and discard redundancies. Moreover, to meet biogas plant operators' requirements, variable selection was performed on the infrared blocks using a recent method: SO-CovSel. SO-CovSel is a method resulting from coupling SO-PLS and Covariance Selection (CovSel) method. The method has been demonstrated to be suitable for multi-response calibration purposes with infr ared calibration. It has provided good predictions and an interesting interpretation of wavelengths involved in the monitoring of the relevant parameters of stability in anaerobic co-digestion.																	0169-7439	1873-3239				OCT 15	2020	205								104120	10.1016/j.chemolab.2020.104120													
J								Comparison of PLSR, MCR-ALS and Kernel-PLSR for the quantification of allergenic fragrance compounds in complex cosmetic products based on nonlinear 2D GC-IMS data	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS											MULTIVARIATE CURVE RESOLUTION; ION-MOBILITY SPECTROMETRY; VOLATILE ORGANIC-COMPOUNDS; GAS-CHROMATOGRAPHY; QUANTITATIVE-ANALYSIS; UNIFORM DESIGN; IDENTIFICATION; HYDROCARBONS; EXPLOSIVES; SPECTRA																		0169-7439	1873-3239				OCT 15	2020	205								104128	10.1016/j.chemolab.2020.104128													
J								Maximal structure generation of superstructure for semantic triple generated by DEVS ontology in the process industry	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Superstructure; P-Graph; DEVS Ontology; Process industry	P-GRAPH; SPARQL QUERIES; SIMULATION; DESIGN; REPRESENTATION; SYSTEMS	In the process industry, a large number of multi-source heterogeneous data are generated. Ontology combined with resource description framework (RDF) is a great way to describe multi-source heterogeneous data. Due to the characteristics of free extension, no model limitations and few constraints in the calculation process, semantic data have been increasingly used in industrial systems. However, semantic data have not been fully utilized to realize automatic modeling. Lots of time and experience from knowledge workers is still required in the feedstock scheduling. Therefore, this article presents a method of constructing the RDF triple graph data based on the discrete event system specification ontology. Based on the advantage of graph data, the procedure of superstructure generation is greatly simplified by the proposed RDFMSG (maximal structure generation based on resource description framework data) algorithm. In the RDFMSG algorithm, the original structure is no longer pruned and then reorganized; the superstructure can be generated by the traversing RDF data set only once. The effectiveness and efficiency of the proposed methodology are verified through three cases. In addition, the representation of the discrete event system specification ontology can achieve good performance. Furthermore, the combination explosion caused by set operation can be greatly reduced, indicating that the strategy of the RDFMSG plays an important role in the solution structure generation algorithm and the accelerated branch and bound algorithm.																	0169-7439	1873-3239				OCT 15	2020	205								104119	10.1016/j.chemolab.2020.104119													
J								Multivariate image fusion: A pipeline for hyperspectral data enhancement	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Hyperspectral; Data fusion; Pansharpening; Super resolution	SUPERRESOLUTION	Hyperspectral cameras provide high spectral resolution data, but their usual low spatial resolution when compared to color (RGB) instruments is still a limitation for more detailed studies. This article presents a simple yet powerful method for fusing co-registered high spatial and low spectral resolution image data - e.g. RGB - with low spatial and high spectral resolution data - Hyperspectral. The proposed method exploits the overlap in observed phenomena by the two cameras to create a model through least square projections. This yields two images: 1) A high-resolution image spatially correlated with the input RGB image but with more spectral information than just the 3 RGB bands. 2) A low-resolution image showing the spectral information what is spatially uncorrelated with the RGB image. We show results for semi-artificial benchmark datasets and a real-world application. Performance metrics indicate the method is well suited for data enhancement.																	0169-7439	1873-3239				OCT 15	2020	205								104097	10.1016/j.chemolab.2020.104097													
J								Multi-models in predicting RNA solvent accessibility exhibit the contribution from none-sequential attributes and providing a globally stable modeling strategy	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Solvent accessibility; RNA structure; Machine learning methods; Attribute selection; Multi-models; Multi-attributes	SECONDARY STRUCTURE	Recently, multiple researches of solvent accessibility on protein are well established. However, research on solvent accessibility of RNA faces a few challenges such as instability and diversity of RNA tertiary structure. Nowadays, no study has examined the predicting performance from different datasets built from multi-models and multi-attributes, but it is an important part of measuring the overall performance of modeling. Therefore, we performed a comprehensive comparison for predicting RNA solvent accessibility based on two datasets. 15,923 (12,229 + 3694) samples and 512(336 + 176) attributes were generated for attribute selection, finally 336 models were built for predicting. 12 modeling methods and 2 attribute selection methods were used for modeling and evaluating. This work provided a strategy for getting stable expectation when predicting RNA solvent accessibility. These results would be useful in further experimental or computational design for RNA solvent accessibility predicting and we hope this work could help the related researches which need a workflow for stable prediction.																	0169-7439	1873-3239				OCT 15	2020	205								104100	10.1016/j.chemolab.2020.104100													
J								MBA-GUI: A chemometric graphical user interface for multi-block data visualisation, regression, classification, variable selection and automated pre-processing	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Data fusion; Multi-sensor; Chemometrics; Graphical user interface	DATA-FUSION; DISCRIMINANT-ANALYSIS; SO-PLS; SPECTROSCOPY; EXTENSION; QUALITY; TRENDS; FOOD	In recent years, due to advances in sensor technology, multi-modal measurement of process and products properties has become easier. However, multi-modal measurements are only of use if the data from adding new sensors is worthwhile, especially in the case of industrial applications where financial justification is needed for new sensor purchase and integration, and if the multi-modal data generated can be properly utilised. Several multi-block methods have been developed to do this; however, their use is largely limited to chemometricians, and non-experts have little experience with such methods. To deal with this, we present the first version of a MATLAB-based graphical user interface (GUI) for multi-block data analysis (MBA), capable of performing data visualisation, regression, classification and variable selection for up to 4 different sensors. The MBA-GUI can also be used to implement a recent technique called sequential pre-processing through orthogonalization (SPORT). Data sets are supplied to demonstrate how to use the MBA-GUI. In summary, the developed GUI makes the implementation of multi-block data analysis easier, so that it could be used also by practitioners with no programming skills or unfamiliar with the MATLAB environment. The fully functional GUI can be downloaded from (https://github.com/puneetmishra2/Multi-block.git) and can be either installed to run in the MATLAB environment or as a standalone executable program. The GUI can also be used for analysis of a single block of data (standard chemometrics).																	0169-7439	1873-3239				OCT 15	2020	205								104139	10.1016/j.chemolab.2020.104139													
J								Quality relevant over-complete independent component analysis based monitoring for non-linear and non-Gaussian batch process	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Batch process; Fault monitoring; Affinity propagation algorithm; Over-complete independent component analysis; Partial least squares	PARTIAL LEAST-SQUARES; FAULT-DETECTION; MIXTURE MODEL; DIAGNOSIS; INFORMATION; PHASE; PROJECTION; STRATEGY	A large number of multivariate statistical methods have been applied to process monitoring, but conventional methods only extract limited feature information that often cannot effectively monitor the quality related changes of production characteristics in batch processes. In order to improve the effect of the process monitoring, this paper proposes a batch process monitoring method based on Multistage Over-complete Independent Component Analysis (OICA) algorithm. Firstly, the Affinity Propagation algorithm (AP) is used to divide the batch production process. Secondly, the extra quality information extracted by Partial Least Squares (PLS) algorithm is input into OICA algorithm. Finally, a monitoring model is established for process monitoring in each sub-stage. The effectiveness of the proposed method has been verified by comparing with the conventional methods in the fed-batch penicillin fermentation process.																	0169-7439	1873-3239				OCT 15	2020	205								104140	10.1016/j.chemolab.2020.104140													
J								Comparison of multi-response estimation methods	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Model-comparison; Multi-response; Simrel; Estimation; Estimation error; Meta modelling; Envelope estimation	LEAST-SQUARES REGRESSION; PREDICTION METHODS; COMPONENTS	Prediction performance does not always reflect the estimation behaviour of a method. High error in estimation may necessarily not result in high prediction error, but can lead to an unreliable prediction if test data lie in a slightly different subspace than the training data. In addition, high estimation error often leads to unstable estimates, and consequently, the estimated effect of predictors on the response can not have a valid interpretation. Many research fields show more interest in the effect of predictor variables than actual prediction performance. This study compares some newly-developed (envelope) and well-established (PCR, PLS) estimation methods using simulated data with specifically designed properties such as Multicollinearity in the predictor variables, the correlation between multiple responses and the position of principal components corresponding to predictors that are relevant for the response. This study aims to give some insights into these methods and help the researchers to understand and use them for further study. Here we have, not surprisingly, found that no single method is superior to others, but each has its strength for some specific nature of data. In addition, the newly developed envelope method has shown impressive results in finding relevant information from data using significantly fewer components than the other methods.																	0169-7439	1873-3239				OCT 15	2020	205								104093	10.1016/j.chemolab.2020.104093													
J								A molecular generative model of ADAM10 inhibitors by using GRU-based deep neural network and transfer learning	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS										Deep learning; Recurrent neural network; Molecular design; Virtual screening; ADAM10; Inhibitor	DISCOVERY; CLEAVAGE; DESIGN	Recurrent neural network (RNN) is one of the most representative architectures in deep learning and widely adopted in many research fields especially in natural language processing. In this work, a gated-recurrent-unit (GRU)-based deep neural network combined with transfer learning was successfully employed to establish a molecular generative model of ADAM10 inhibitors. The results showed that the GRU-based generative model can learn accurately the SMILES grammars of the molecules and be capable of generating novel potential ADAM10 inhibitors. In comparison with traditional ligand-based methods, the GRU-based generative model requires only the SMILES information of the chemical ligands and can generate efficiently a large set of potential novel structures. These unique advantages make it extremely useful in de novo drug design and large-scale virtual screening researches.																	0169-7439	1873-3239				OCT 15	2020	205								104122	10.1016/j.chemolab.2020.104122													
J								Effective algorithms for single-machine learning-effect scheduling to minimize completion-time-based criteria with release dates	EXPERT SYSTEMS WITH APPLICATIONS										Learning effect; Single-machine scheduling; Discrete differential evolution; Asymptotic analysis; Branch and bound	PERMUTATION FLOW-SHOP	Multi-variety and small-batch productions are usually undertaken by skilled workers instead of an automatic assembly line because of economic cost consideration. In the production process, a worker's familiarity to an operation influences the length of task execution time. An interesting phenomenon called learning effect has become a trending research topic. This study investigates a learning effect scheduling model on a single machine system, in which the learning effect is position-dependent and each task is released at different dates. Two optimal criteria are individually discussed: one is total k-power completion time, and the other is maximum lateness. Both problems are NP-hard, therefore, effective algorithms are provided to handle different scale problems within an appropriate CPU time. The heuristic algorithms, namely, shortest processing time available and earliest due date available, are introduced to achieve feasible schedules for large-scale instances, and their asymptotic optimality is proven given that the problem scale tends to infinity. The two heuristics can thus serve as optimal algorithms in mass production. For small-scale instances, a branch and bound algorithm is presented to achieve the optimal solution, where a release-date-based branching rule and preemption-based lower bounds eliminate as many invalid nodes as possible. For medium-scale instances, an evolutionary-based metaheuristic algorithm, namely, discrete differential evolution, is utilized to seek high-quality solutions, in which the initial population and crossover operator are well-designed to enhance its performance. A number of random experiments demonstrate the superiority of the proposed algorithms. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113445	10.1016/j.eswa.2020.113445													
J								Fusing Transformed Deep and Shallow features (FTDS) for image-based facial expression recognition	EXPERT SYSTEMS WITH APPLICATIONS										Facial expression; PML Representation; Deep features; Hand-crafted features; Cross-databases		In this paper, we propose combining between the transformed hand-crafted and deep features using PCA to recognize the six-basic facial expressions from static images. To evaluate our approach, we use three popular databases (CK+, CASIA and MMI). We introduce the use of the Pyramid Multi Level (PML) face representation for facial expression recognition. The hand-crafted features are obtained with such representations. Initially, we determine the optimal level of the PML features of three hand-crafted descriptors (HOG, LPQ and BSIF) using CK+, CASIA and MMI databases. After the optimal level of the PML is found for each descriptor, we combine them together with the transformed final VGG-face layers (FC6 and FC7) in order to get a compact image descriptor. In within-database experiments, our approach achieved higher accuracy than the state-of-art methods on both the CK+ and CASIA databases, and competitive result on the MMI database. Likewise, our approach outperformed the static methods in all six experiments of cross-databases. (C) 2020 Published by Elsevier Ltd.																	0957-4174	1873-6793				OCT 15	2020	156								113459	10.1016/j.eswa.2020.113459													
J								Evaluating the environmental protection strategy of a printed circuit board manufacturer using a T-w fuzzy importance performance analysis with Google Trends	EXPERT SYSTEMS WITH APPLICATIONS										Printed circuit board; Environmental protection; Fuzzy importance-performance analysis; Google Trends	SUSTAINABLE TOURISM; ATTRIBUTES; MANAGEMENT; KOREA	Printed circuit boards (PCBs) are very important materials in consumer electronic products. The process of making PCBs usually uses chemicals, and large quantities of water are needed. PCB manufacturers are devoted to improving the process in order to conform to environmental protection rules and regulations. However, evaluating the performance of environmental protection strategies by quantitative methods is very difficult. Therefore, this study attempts to evaluate the environmental protection strategy of a PCB manufacturer using the novel weakest t-norm (T-w) fuzzy importance-performance analysis with Google Trends (TFIPA-Google). The TFIPA-Google methodology obtain advantages of T-w operations, IPA, and Google Trends, which can handle uncertainty based on a fuzzy matrix of IPA, reduce fuzzy accumulation using the T-w operators, and analyze social media viewpoints using Google Trends. This empirical example based on the TFIPA-Google method shows that the recovered waste material management system should be a priority for PCB manufacturers. Moreover, the TFIPA-Google method can provide more creditable information, based on T-w operations and volume of Google Trends for decision-makers, than a conventional importance-performance analysis (IPA) model. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113483	10.1016/j.eswa.2020.113483													
J								Model checking intelligent avionics systems for test cases generation using multi-agent systems	EXPERT SYSTEMS WITH APPLICATIONS										Model checking; Test cases generation; Avionics; Multi-agent systems; Interpreted systems; Commitments; MCMAS	COMMUNICATIVE COMMITMENTS; VERIFICATION; LOGIC	The paper contributes by introducing a novel, formal and operational approach that addresses the open challenging issues of modeling, verifying, and testing intelligent critical avionics systems. We advance the state-of-the-art by unifying the three challenges and considering the intelligence, autonomy, and accountability of the components as first citizen concepts. The proposed methodology is effectively applied to a real, practical and complex case study of intelligent avionics systems, namely the landing gear system and uses multi-agent systems to model each main component in the system as an intelligent agent. We also introduce the formalism of extended interpreted systems that supports intelligence, autonomy, communication, input and output actions, predicate conditions and post-conditions. The paper adopts the computation tree logic of conditional commitments to model communication among autonomous agents and trace its progress. The symbolic model checker of this logic is used to run the verification of the system model, encoded in an extended input language, against coverage criteria and properties. Furthermore, we introduce a new testing methodology that: 1) Follows a test-driven development approach; 2) performs unit testing, component testing, and system testing in each increment; and 3) uses model checking to generate automatically counterexamples and witness traces interpreted into concrete test suites that achieve new coverage criteria. The experimental results showed the efficiency and scalability of the developed approach against a transformation-based technique. Finally, the computational complexity of the developed approach is analysed. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113458	10.1016/j.eswa.2020.113458													
J								Parsimonious fuzzy time series modelling	EXPERT SYSTEMS WITH APPLICATIONS										Parsimonious fuzzy time series; Hyper-parameter optimization; Genetic algorithm; Forecasting	PREDICTING TEMPERATURE SETTINGS; FORECASTING ENROLLMENTS; NEURAL-NETWORKS; C-MEANS; INDEX; INTERVALS; OPTIMIZATION; LENGTHS; FCM	This paper proposes a novel modelling structure to ensure the parsimony of fuzzy time series (FTS) models while retaining certain level of out-of-sample accuracy. A parsimonious FTS model requires multiple optimizations of hyper-parameters such as time lags and partitioning which consists of the number of fuzzy sets, the partitioning type and the membership functions. In the vast literature of fuzzy time series, hyper-parameter optimization is usually ignored. In addition to that, optimization process for the hyper-parameters is also not presented properly. In this study, a parsimonious FTS modelling approach is introduced by using genetic algorithm (GA). Three major innovations are proposed: (1) Hyper-parameters of FTS structure are optimized to eliminate subjective preferences with the help of GA. Some of those parameters are never optimized or simply ignored in the past research. (2) The set of hyper-parameters is optimized subject to highest accuracy in validation set data and model's complexity. (3) For achieving sparsification and accuracy simultaneously at reasonable computation time, a two-stage GA optimization is run to search for higher accuracy and lower complexity consecutively. Empirical studies are conducted on two types of datasets. Prices of liquid bulk cargo carriers (i.e. tanker) and secondhand ship have been predicted using the proposed approach. Potential benchmarks as well as a simple Nave forecast have been compared to the proposed model for validation based on mean absolute scaled error and root mean squared error. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113447	10.1016/j.eswa.2020.113447													
J								DECAF: Deep Case-based Policy Inference for knowledge transfer in Reinforcement Learning	EXPERT SYSTEMS WITH APPLICATIONS										Deep Reinforcement Learning; Case-based Reasoning; Transfer Learning; Knowledge discovery; Knowledge management; Neural networks	SYSTEM; CBR	Having the ability to solve increasingly complex problems using Reinforcement Learning (RL) has prompted researchers to start developing a greater interest in systematic approaches to retain and reuse knowledge over a variety of tasks. With Case-based Reasoning (CBR) there exists a general methodology that provides a framework for knowledge transfer which has been underrepresented in the RL literature so far. We formulate a terminology for the CBR framework targeted towards RL researchers with the goal of facilitating communication between the respective research communities. Based on this framework, we propose the Deep Case-based Policy Inference (DECAF) algorithm to accelerate learning by building a library of cases and reusing them if they are similar to a new task when training a new policy. DECAF guides the training by dynamically selecting and blending policies according to their usefulness for the current target task, reusing previously learned policies for a more effective exploration but still enabling the adaptation to particularities of the new task. We show an empirical evaluation in the Atari game playing domain depicting the benefits of our algorithm with regards to sample efficiency, robustness against negative transfer, and performance increase when compared to state-of-the-art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113420	10.1016/j.eswa.2020.113420													
J								A novel data clustering algorithm based on gravity center methodology	EXPERT SYSTEMS WITH APPLICATIONS										Algorithm; Cluster analysis; Euclidean distance; Gravity center; Partitional clustering		The concept of clustering is to separate clusters based on the similarity which is greater within cluster than among clusters. The similarity consists of two principles, namely, connectivity and cohesion. However, in partitional clustering, while some algorithms such as K-means and K-medians divides the dataset points according to the first principle (connectivity) based on centroid clusters without any regard to the second principle (cohesion), some others like K-medoids partially consider cohesion in addition to connectivity. This prevents to discover clusters with convex shape and results are affected negatively by outliers. In this paper a new Gravity Center Clustering (GCC) algorithm is proposed which depends on critical distance (lambda) to define threshold among clusters. The algorithm falls under partition clustering and is based on gravity center which is a point within cluster that verifies both the connectivity and cohesion in determining the similarity of each point in the dataset. Therefore, the proposed algorithm deals with any shape of data better than K-means, K-medians and K-medoids. Furthermore, GCC algorithm does not need any parameters beforehand to perform clustering but can help user improving the control over clustering results and deal with overlapping and outliers providing two coefficients and an indicator. In this study, 22 experiments are conducted using different types of synthetic, and real healthcare datasets. The results show that the proposed algorithm satisfies the concept of clustering and provides great flexibility to get the optimal solution especially since clustering is considered as an optimization problem. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113435	10.1016/j.eswa.2020.113435													
J								Aggregation of preference relations to enhance the ranking quality of collaborative filtering based group recommender system	EXPERT SYSTEMS WITH APPLICATIONS										Preference relation; Group recommendation; Collaborative filtering; Graph aggregation	TRUST	The recommendation of suitable products/items for a group of users has always been a difficult task. Most of the recommender systems are designed for individual use only. However, there are many scenarios where the recommendations are intended to serve a group of users. Each member of the group has their own set of preferences, and it is challenging to satisfy each member of the group with the recommended list. It has also been observed in recent studies that mere aggregation of preferences (e.g., ratings) does not provide good group recommendations. The quality of the group recommendation depends on two essential things: the ranking quality and the aggregation strategy. The first one confirms that the higher preferred items always appear first in the list, and the second one confirms the agreement among users of the group towards the recommendation list. Hence, this study proposes a method that uses the preference relation based matrix factorization technique to obtain the predicted preference (e.g., ratings) and then uses graph aggregation strategy to aggregate the preferences of the group members. We applied collective rationality during graph aggregation to maintain consistency in preferences among group members. Three benchmark datasets were used to evaluate and compare the proposed model with other baselines in terms of ranking quality of the group recommendation. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113476	10.1016/j.eswa.2020.113476													
J								Refining understanding of corporate failure through a topological data analysis mapping of Altman's Z-score model	EXPERT SYSTEMS WITH APPLICATIONS										Credit scoring; Topological data analysis; Data visualization; Bankruptcy prediction	FINANCIAL RATIOS; PREDICTION	Corporate failure resonates widely, leaving practitioners searching for understanding of default risk. Managers seek to steer away from trouble, credit providers to avoid risky loans and investors to mitigate losses. Applying Topological Data Analysis tools, this paper explores whether failing firms from the United States organise neatly along the five predictors of default proposed by the Z-score models. Each firm is represented as a point in a five-dimensional point cloud, each dimension being one of the five predictors. Visualising that cloud using Ball Mapper reveals failing firms are not always located in similar regions of the point cloud, that is they are not concentrated in an easily split out area of the space. As new modelling approaches vie to better predict firm failure, often using black boxes to deliver potentially over-fitting models, a timely reminder is sounded on the importance of evidencing the identification process. Value is added to the understanding of where in the parameter space failure occurs, and how firms might act to move away from financial distress. Further, lenders may find opportunity amongst subsets of firms that are traditionally considered to be in danger of bankruptcy, but which the Ball Mapper plots developed herein clarify actually sit in characteristic spaces where failure has not occurred. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 15	2020	156								113475	10.1016/j.eswa.2020.113475													
J								Financial portfolio optimization with online deep reinforcement learning and restricted stacked autoencoder-DeepBreath	EXPERT SYSTEMS WITH APPLICATIONS										Portfolio management; Deep reinforcement learning; Restricted stacked autoencoder; Online leaning; Settlement risk; Blockchain	STOCK; PREDICTION; ECONOMICS; MARKETS	The process of continuously reallocating funds into financial assets, aiming to increase the expected return of investment and minimizing the risk, is known as portfolio management. In this paper, a portfolio management framework is developed based on a deep reinforcement learning framework called DeepBreath. The DeepBreath methodology combines a restricted stacked autoencoder and a convolutional neural network (CNN) into an integrated framework. The restricted stacked autoencoder is employed in order to conduct dimensionality reduction and features selection, thus ensuring that only the most informative abstract features are retained. The CNN is used to learn and enforce the investment policy which consists of reallocating the various assets in order to increase the expected return on investment. The framework consists of both offline and online learning strategies: the former is required to train the CNN while the latter handles concept drifts i.e. a change in the data distribution resulting from unforeseen circumstances. These are based on passive concept drift detection and online stochastic batching. Settlement risk may occur as a result of a delay in between the acquisition of an asset and its payment failing to deliver the terms of a contract. In order to tackle this challenging issue, a blockchain is employed. Finally, the performance of the DeepBreath framework is tested with four test sets over three distinct investment periods. The results show that the return of investment achieved by our approach outperforms current expert investment strategies while minimizing the market risk. Crown Copyright (C) 2020 Published by Elsevier Ltd.																	0957-4174	1873-6793				OCT 15	2020	156								113456	10.1016/j.eswa.2020.113456													
J								Training feedforward neural network via multiobjective optimization model using non-smooth L-1/2 regularization	NEUROCOMPUTING										Multiobjective optimization; NSGAII; Learning algorithm; L-1/2 regularization; Neural network	ALGORITHMS; SELECTION	The paper presents a new approach to optimize the Multilayer Perceptron Neural Network (MLPNN), to deal with the generalization problem. As known, most supervised learning algorithms aim to minimize the training error. However, the mentioned methods, based only on error minimizing, may generate a solution with an insufficient generalization performance. This present work proposes a multiobjective modelling problem involving two objectives: accuracy and complexity since the learning problem is multiobjective by nature. The learning task is carried on by minimizing both objectives simultaneously, according to Pareto domination concept, using NSGAII (Non-dominated Sorting Genetic Algorithm II) as a solver. This method leads us to a set of solutions called Pareto front, being the optimal solutions set, the adequate MLPNN need to be extracted. We show empirically that the proposed method is capable of reducing the neural networks topology and improved generalization performance, in addition to a good classification rate compared to different methods. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						1	11		10.1016/j.neucom.2020.05.066													
J								3D face reconstruction from mugshots: Application to arbitrary view face recognition	NEUROCOMPUTING										Mugshot; 3D face reconstruction; Arbitrary view face recognition	ROBUST; DATABASE; MODEL; SHAPE	Mugshots while routinely acquired by law enforcement agencies are under utilized by automated face recognition systems. In this paper, we propose a regression based approach to reconstruct textured full 3D face models from multi-view mugshot images. Using landmarks from the input frontal and profile mugshots of a subject, our method reconstructs his \ her 3D face shape via either linear or nonlinear regressors. The texture of the mugshot images is mapped to the reconstructed 3D face shape via an efficient seamless texture recovery scheme. Compared with existing 3D face reconstruction methods, the proposed method more effectively utilizes the three-view mugshot face images collected during booking. The reconstructed 3D faces are used to generate realistic multi-view face images to enlarge the gallery and facilitate arbitrary view face recognition. Evaluation experiments have been done on BFM and Bosphorus databases in terms of reconstruction accuracy, and on Multi-PIE and Color FERET databases in terms of recognition accuracy. The results show that the proposed method can reduce the 3D face reconstruction error of the best competitive method from 2.31 mm to 1.88 mm, and improve the recognition accuracy of state-of-the-art deep learning based face matchers by as much as similar to 4% on Multi-PIE and similar to 2% on Color FERET despite the high baseline set by them. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						12	27		10.1016/j.neucom.2020.05.076													
J								Synchronized stationary distribution and synchronization of stochastic coupled networks with Markovian switching via periodically intermittent control	NEUROCOMPUTING										Synchronized stationary distribution; Periodically intermittent control; Graph theory; Coupled Chua's circuits; Markovian switching	MULTI-GROUP MODELS; PREDATOR-PREY SYSTEM; NEURAL-NETWORKS; EXPONENTIAL SYNCHRONIZATION; DISPERSAL; STABILITY	This paper investigates the synchronized stationary distribution of stochastic coupled networks with Markovian switching (CNMS) and the exponential synchronization of CNMS. Except for the Lyapunov method, the periodically intermittent control strategy and the technique of graph theory are applied to the study of synchronized stationary distribution and exponential synchronization. Some sufficient conditions to achieve synchronized stationary distribution and exponential synchronization are presented. The results show that the existing domain of synchronized stationary distribution is affected by control rate and the realization of exponential synchronization is also influenced by intensity of control, control rate. In addition, the theoretical results are applied to stochastic coupled oscillators and coupled Chua's circuits with Markovian switching. Finally, two examples with numerical simulations are provided to illustrate the effectiveness of the results developed. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						28	40		10.1016/j.neucom.2020.05.051													
J								Using hybrid normalization technique and state transition algorithm to VIKOR method for influence maximization problem	NEUROCOMPUTING										Influence maximization; Normalization technique; Multiple criteria decision making; State transition algorithm	COMMUNITY DETECTION; DECISION-MAKING; MCDM METHODS; CENTRALITY; SELECTION; ECONOMICS	Influence maximization problem is the procedure of attempting to identify a group of K nodes in a social network in order to maximize the dissemination of influence under certain influence models. Based on state transition algorithm (STA) and a multiple criteria decision making (MCDM) method called Vise Kriterijumska Optimizacija I Kompromisno Resenje (VIKOR), a novel hybrid approach has been proposed to cope with the influence maximization problem in this paper. Firstly, an intelligent optimization paradigm called STA is introduced to obtain the most appropriate weights that are used to integrate the criteria of each alternative in the VIKOR method. Then, a hybrid normalization technique has been presented to allow the process of aggregating criterion with numerical and comparable data properly in this method. Several typical networks have been used to testify the effectiveness of proposed method and technique. Compared with other approaches, experimental results show that our approach can solve the influence maximization problem more effectively. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						41	50		10.1016/j.neucom.2020.05.084													
J								Improved adaptive NN backstepping control design for a perturbed PVTOL aircraft	NEUROCOMPUTING										Neural network; Backstepping; PVTOL aircraft	STABILIZATION	This paper proposes an improved flight control scheme for a perturbed planar vertical take-off and landing (PVTOL) aircraft based on backstepping and neural networks. In this approach, three neural networks are applied to deal with the external disturbances of the aircraft system. Instead of using sigma-modification to design the adaptive laws, gradient descent algorithm is adopted to train the weight parameters of neural networks such that high function approximation precision can be achieved. By resorting to Lyapunov stability criterion, it can be proved that the reference signals are tracked by the aircraft's outputs with small errors. In the end, simulation results are used to illustrate the superiority of the our approach compared with traditional direct adaptive neural network backstepping control technique. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						51	60		10.1016/j.neucom.2020.05.065													
J								Speeded-up Convolution Neural Network for classification tasks using multiscale 2-dimensional decomposition	NEUROCOMPUTING										Image classification; Modular finetuning; Multiscale compression; Weight decomposition		In this paper, we propose a strategy for network simplification and acceleration. First, we propose to generate a suitable resized image using multiscale patching in the first convolutional layer, which can then be used for the rest of the network. We use p convolutional filters that operate on patches of size m x n, and we first select all the possible non-superposed m x n patches from the available images. If the number of such patches is not sufficient, the remaining ones are collected using scales a x b or c x d such that ab = cd = mn or a = 2 m or b = 2n. Patches generated from the former condition are directly extracted from the images, while the downsampled results are used in the latter case. We also introduce a 2-dimensional decomposition for patch compression, by stacking all the available image patches along the columns and applying a 2D PCA decomposition. Finally, a layer weight decomposition technique followed by module-based finetuning is adopted, for a new fast module-based CNN model. Extensive evaluations using public data sets like MNIST, Pascal VOC, and WebCASIA, and with different state-of-the art CNN architectures like Open-Face, VGG and DarkNet verify that our proposed model is able to accelerate the training process and even to provide higher classification accuracies for small-sized datasets. We obtain 8% increase in Top-1 and Top-5 recognition rates, and 5% increase in F1 score over general interpolation-based resizing. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						61	70		10.1016/j.neucom.2020.05.068													
J								DONE: Enhancing network embedding via greedy vertex domination	NEUROCOMPUTING										Network embedding; Deep learning; Greedy algorithm; Dominating vertices; Community detection	APPROXIMATION; SET	In this paper, we present DONE, a novel framework for learning networks representations, which fundamentally supports numerous network analytic tasks such as node classification, clustering, and visualization. Most existing network embedding methods are unable to efficiently scale for large networks and usually suffer from performance issues. In addition, these methods cannot efficiently leverage the vertex labels that are usually very scarce in real-world networks. Our framework provides a powerful way to generate representations for network vertices without relying on user-defined heuristics for manual feature extraction. We present a deep autoencoder model to generate low-dimensional feature representations by learning network reconstruction and semi-supervised classification tasks. We propose a novel greedy algorithm based on vertex domination and centrality concepts to simplify networks while preserving network topology and community structure, namely GreedyNet. In addition, we propose a novel sampling approach to estimate the labels of unlabeled vertices and adopt it to learn superior embedding. Using network dominating vertices, our approach enhances the generalization and scalability of network embedding through simplifying the underlying network. To the best of our knowledge, we are the first to propose the idea of using network dominating vertices to enhance network embedding. The experimental results show that our method outperforms the state-of-the-art methods. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						71	82		10.1016/j.neucom.2020.05.055													
J								A new emotion model of associative memory neural network based on memristor	NEUROCOMPUTING										Memristor; Emotion model; Associative memory; Memristor-based neural networks	DESIGN	Implementing associative memory experiments with nanoscale memristors is an interesting subject, which can allow robots to mimic human thinking. This paper is concerned with a new emotion model of memristor-based neural network and its circuit implementation. The model has three inputs and two outputs, which can feel happy when it receives good news or feel sad when it receives bad news. Unknown news can be recognized through associative memory, which simulates human emotions. Associative learning and three kinds of forgetting process together make up the full-function emotion model. In addition, the Ag/AgInSbTe/Ta-based model closely related to the actual physical properties of memristors is used to design synaptic structures. The circuits of memristor-based neural networks are also simplified. Furthermore, the new emotion model is able to adjust the changing rate of emotion. The process reflects the fact that humans learn the same thing faster at the second time, compared with the first time. Finally, PSPICE is used to simulate all the circuits of the emotion model. The presented emotion model in this paper offers more possibilities for designing intelligent machines. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						83	92		10.1016/j.neucom.2020.05.002													
J								Interaction of neuronal and network mechanisms on firing propagation in a feedforward network	NEUROCOMPUTING										Feedforward network; Neuronal diversity; Spiking propagation; Izhikevich neuron	SPIKING; DIVERSITY; CORTEX; MODEL; PATTERNS; CELLS; RATES	The mammalian brain has enormously complex neuronal diversity and a highly modular structure. The propagation of information in the modular brain network can be modeled by a feedforward network (FFN). Although studies in this area have yielded many important results, neuronal diversity has rarely been considered. In the current work, we investigate the complex interactions between the intrinsic properties of neurons and the FFN structure in the propagation of spiking activity. Here, four typical types of cortical neurons reproduced by the Izhikevich neuron model are introduced. A homogeneous FFN composed of a single type of excitatory neuron (regular spiking, mixed model, or tonic bursting) can propagate spiking activity. However, an FFN with fast spiking neurons does not propagate spiking activity. By modifying the network structure and synaptic weights, the spiking propagation of the homogeneous FFNs can vary from synchronous transmission (with a high firing rate) to asynchronous transmission (with a low firing rate). Among the homogeneous FFNs, both the firing rate and the synchrony of the FFN with tonic bursting neurons are the highest, but those of the FFN with regular spiking neurons is lowest, even when implementing the same FFN structure. For the FFN with mixed neuronal types, interestingly, the spiking propagation is very sensitive to the composition of the four types of neurons. By introducing fast spiking neurons into the homogeneous FFN composed of excitatory neurons, spiking propagation can be modified from synchronous to asynchronous. Similarly, changing the proportion of any of the types of neuron affects the spiking propagation, even for very small changes. The underlying mechanism of these observed results has also been discussed. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						93	102		10.1016/j.neucom.2020.05.088													
J								Deep memory network with Bi-LSTM for personalized context-aware citation recommendation	NEUROCOMPUTING										Context-aware citation recommendation; Memory network; Bi-LSTM; Personalized author; Citation relationship		The explosive growth of data leads researchers to waste time and energy to search for papers they need. Context-aware citation recommendation aims to solve this problem by analyzing a citation context and provides a list of recommended papers. In this paper, we propose a context-aware citation recommendation model based on end to end memory network. The model learns the representations of papers and citation contexts respectively based on bidirectional long short-term memory (Bi-LSTM). In particular, we jointly integrate author information and citation relationship in the distributed vector representations of citation contexts and papers. Then calculates the continuous relevance between them based on a computational multilayers memory network. We also conduct experiments on three real-world datasets to evaluate the performance of our model. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						103	113		10.1016/j.neucom.2020.05.047													
J								A multi-layer fuzzy model based on fuzzy-rule clustering for prediction tasks	NEUROCOMPUTING										Multi-layer fuzzy model; Fuzzy-rule clustering; Modified fuzzy rules; Exact matching strategy; Relative error support vector machine	INFERENCE SYSTEM; NEURAL-NETWORK; IDENTIFICATION; ALGORITHM; ANFIS; OPTIMIZATION; PERFORMANCE; MACHINE	Fuzzy systems are widely used for solving complex and non-linear problems that cannot be addressed using precise mathematical models. Their performance, however, is critically affected by how they are constructed as well as their fuzzy rule base. Inspired by neural networks that apply a multi-layer structure to improve their performance, we propose a multi-layer fuzzy model with modified fuzzy rules to improve the approximation ability of fuzzy systems without losing efficiency. In practical applications, the fuzzy rule base extracted from numerical data is often incomplete, which makes a fuzzy system less robust. To address this problem, a non-linear function is used as the consequent of each fuzzy rule based on fuzzy-rule clustering to enhance the approximation ability of the fuzzy rule base. In addition, exact matching of fuzzy rules is employed based on the fuzzy rule's antecedent for prediction. By doing so, only one rule will be triggered in each layer, which is very efficient. Experimental results from two simulated functions and three practical applications confirm that our proposed multi-layer fuzzy model can outperform other well-established fuzzy models in terms of accuracy and robustness without sacrificing efficiency. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						114	124		10.1016/j.neucom.2020.04.031													
J								An incrementally cascaded broad learning framework to facial landmark tracking	NEUROCOMPUTING										Facial landmark tracking; Face alignment; Cascade regression; Incremental learning	FACE ALIGNMENT; NETWORK	Facial landmark tracking often adopts static models to generically fit per frame of video. This is considered inappropriate since such models ignore the informative correlation between previous and current frames. Moreover, most of these methods fail to balance the speed and accuracy for video-based facial landmark tracking simultaneously. In this paper, we propose an efficient online framework for video-based face alignment, named Incrementally Cascaded Broad Learning framework (ICBL). ICBL aims to continuously enhance the prediction capability of tracking model for sequential data. It is capable of learning the spatial appearance on specific-person statistics from continuous facial frames and using such knowledge to incrementally tune a cascade of regressors in parallel. To achieve this goal, we approximate the facial shape space by sampling from a dynamic distribution which is continuously updated by person-specific statistics from the tracked facial frames. This dramatically facilitates cascade regression to incrementally update all cascade-regressors in parallel, thus allowing a fast update of the whole model. Furthermore, we successfully incorporate both the linear and non-linear mappings into our parallel cascade framework and introduce Broad Learning (BL) algorithm as a solution for them simultaneously. Experimental results on the most popular and large-scale benchmark for facial landmark tracking show highly competitive performance of proposed ICBL in comparisons with the state-of-the-arts. The code of our ICBL framework has been available from https://github.com/CaifengLiu/Facial-landmark-tracking-by-ICBL. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						125	137		10.1016/j.neucom.2020.05.025													
J								Detecting community structure and structural hole spanner simultaneously by using graph convolutional network based Auto-Encoder	NEUROCOMPUTING										Community detection; Structural hole spanner; Auto-encoder; Graph convolutional neural network; Deep learning		Both Community and Structural Hole (SH) Spanner Detection are significant research tasks in social network analysis. Due to the close topological relevance between communities and structure hole spanners, the two tasks can work out synchronously, but most studies address the two tasks independently. In recent years, deep learning has been applied in the field of community detection. However, so far no deep learning model can solve both community and SH detection at the same framework. In this paper, we first analyze why a previous model named Harmony Modularity (HAM) can working for joint community and SH spanners detection task, which is the only one previous work that solve two task synchronously. Then we discuss the deficiency of HAM. For purpose of overcoming the shortcoming of HAM, we propose a deep learning model for finding both communities and structural holes simultaneously. Because the main framework used in our model is graph convolutional neural network based Auto-Encoder, we shorten it for ComSHAE. Specifically, ComSHAE learn the eigenvectors of weighted Spectral Ratio-Cut Partitioning and the nonlinear representation of adjacent matrix. We infer the community assignments and top-k SH spanners from eigenvectors. Extensive experimental results on synthetic and real networks show that our model outperform the baseline HAM and some state-of-the-art methods. When compare ComSHAE with HAM on synthetic data, ComSHAE shows great effects but HAM can not work. We use Normalized Mutual Information (NMI) to measure performance on detecting communites. ComSHAE shows abort 0.05 NMI improvement than HAM on real data and abort 0.63 NMI improvement on synthetic data. We measure the cross-community transmission capacity through structural hole influence index (SHII). The SH spanners found by ComSHAE shows at lest 0.03 SHII improvement compared with SH detection methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						138	150		10.1016/j.neucom.2020.05.039													
J								On synchronization of competitive memristor-based neural networks by nonlinear control	NEUROCOMPUTING										Neural networks (NNs); Synchronization; Delay-product function; Legendre polynomials (LPs); Quadratic function	STABILITY ANALYSIS; EXPONENTIAL STABILITY; ASYMPTOTIC STABILITY; SYSTEMS; DELAYS; INEQUALITY; DISCRETE; CRITERIA	This paper probes into the synchronization of delayed competitive memristor-based neural networks (CMNNs). Firstly, a new loosened integral inequality is advanced to decrease the estimation difference of auxiliary function-based integral inequalities (AFBIs). Next, by utilizing Legendre polynomials and appropriate loose variables, a delay-product function (DPF) is advanced to employ extra freedom and more information on system states. Then, by proposing nonlinear controller and Lyapunov-Krasovskii functional (LKF) based on above DPF, two delay-dependent principles are offered to accomplish the global synchronization by making use of Chen et al.'s integral inequalities and quadratic combination technique. Finally, an example is supplied to reveal the effectiveness of the presented results. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						151	160		10.1016/j.neucom.2020.05.061													
J								Nonlinear feature selection on attributed networks	NEUROCOMPUTING										Feature selection; Graph convolution networks; Attributed networks		The acceleratinnsional nodal attributes in various data mining tasks highlights the significance of feature selection on the networked data. Due to the lack of class labels of nodes, many feature selection methods are proposed in semi-supervised or unsupervised manners in various scenarios instead of supervised ones. More often than not, features and (pseudo) labels are correlated in a nonlinear way that is more intricate than linearity. In these circumstances, the vast majority of existing linear algorithms could not work well since they select features according to how well the feature can linearly explain the variance of labels. Moreover, although some methods focus on nonlinear feature selection, with the neglect of the link relations between data, they are difficult to be applied to attributed networks directly. In this paper, we investigate how to achieve nonlinear feature selection on attributed networks with the help of both labeled and unlabeled data. Methodologically, we first propose a novel semi-supervised nonlinear framework FS-GCN based on graph convolutional networks (GCNs) to select high-quality features, which can elaborately catch the nonlinear dependency between nodal attributes and class labels. To verify the importance of nonlinearity precisely, we further explore the possibility of totally removing the label information so that a variant of FS-GCN is proposed in the unsupervised form, referred to as UFS-GCN. Besides, experimental results on several real-world datasets validate the superiority of FS-GCN as well as UFS-GCN in terms of the quality of selected features, suggesting their robustness in the condition of extremely low even zero label ratio. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						161	173		10.1016/j.neucom.2020.05.077													
J								Adversarial open set domain adaptation via progressive selection of transferable target samples	NEUROCOMPUTING										Open set domain adaptation; Adversarial learning; Progressive selection		In recent years, many Unsupervised Domain Adaptation (UDA) methods have been proposed to tackle the domain shift problem. Most existing UDA methods are derived for Close Set Domain Adaptation (CSDA) in which source and target domains are assumed to share the same label space. However, target domain may contain unknown class different from the known ones in the source domain in practice, i.e., Open Set Domain Adaptation (OSDA). Due to the presence of unknown class, aligning the whole distribution of the source and target domain for OSDA as in the previous methods will lead to negative transfer. Existing methods developed for OSDA attempt to assign smaller weights to target samples of unknown class. Despite promising performance achieved by existing methods, the samples of the unknown class are still used for distribution alignment, which makes the model suffer from the risk of negative transfer. Instead of reweighting, this paper presents a novel method namely Thresholded Domain Adversarial Network (ThDAN), which progressively selects transferable target samples for distribution alignment. Based on the fact that samples from the known classes must be more transferable than target samples of the unknown one, we derive a criterion to quantify the transferability by constructing classifiers to categorize known classes and to discriminate unknown class. In ThDAN, an adaptive threshold is calculated by averaging transferability scores of source domain samples to select target samples for training. The threshold is tweaked progressively during the training process so that more and more target samples from the known classes can be correctly selected for adversarial training. Extensive experiments show that the proposed method outperforms state-of-the-art domain adaptation and open set recognition approaches on benchmarks. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						174	184		10.1016/j.neucom.2020.05.032													
J								A support vector regression model hybridized with chaotic krill herd algorithm and empirical mode decomposition for regression task	NEUROCOMPUTING										Support vector regression (SVR); Empirical mode decomposition (EMD); Krill herd (KH) algorithm; Tent chaotic mapping function	OPTIMIZATION	This work presents a hybrid model that combines support vector regression (SVR), empirical mode decomposition (EMD), the krill herd (KH) algorithm and a chaotic mapping function. EMD is used to decompose input time series data into components with several intrinsic mode functions (IMFs) and one residual, to capture the trends in the input data. SVR is used to forecast separately IMFs and the residual owing to its effectiveness in solving nonlinear regression and time series problems. The KH algorithm is used to select the parameters in the SVR models. The Tent chaotic mapping function is hybridized with the KH algorithm to prevent premature convergence and increase the accuracy of the whole model. Two real-world datasets from the New South Wales (NSW, Australia) market and the New York Independent System Operator (NYISO, USA) are used to demonstrate the performance of the proposed EMD-SVRCKH model. The experimental results reveal that the proposed model provides competitive advantages over other models and offers greater forecasting accuracy. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						185	201		10.1016/j.neucom.2020.05.075													
J								DNF: A differential network flow method to identify rewiring drivers for gene regulatory networks	NEUROCOMPUTING										Differential network analysis; Network flow; Information entropy; Network topology; Neuronal differentiation	REVEALS; CELLS; APP	Differential network analysis has become an important approach in identifying driver genes in development and disease. However, most studies capture only local features of the underlying gene-regulatory network topology. These approaches are vulnerable to noise and other changes which mask driver-gene activity. Therefore, methods are urgently needed which can separate the impact of true regulatory elements from stochastic changes and downstream effects. We propose the differential network flow (DNF) method to identify key regulators of progression in development or disease. Given the network representation of consecutive biological states, DNF quantifies the essentiality of each node by differences in the distribution of network flow, which are capable of capturing comprehensive topological differences from local to global feature domains. DNF achieves more accurate driver-gene identification than other state-of-the-art methods when applied to four human datasets from The Cancer Genome Atlas and three single-cell RNA-seq datasets of murine neural and hematopoietic differentiation. Furthermore, we predict key regulators of crosstalk between separate networks underlying both neuronal differentiation and the progression of neurodegenerative disease, among which App is predicted as a driver gene of neural stem cell differentiation. Our method is a new approach for quantifying the essentiality of genes across networks of different biological states. (C) 2020 The Author(s). Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						202	210		10.1016/j.neucom.2020.05.028													
J								Multidimensional relation learning for hyperspectral image classification	NEUROCOMPUTING										Hyperspectral image classification; Spatial relation learning; Spectral relation learning; Category relation learning; Multidimensional relation learning	SPECTRAL-SPATIAL CLASSIFICATION	Classification is a fundamental technique in hyperspectral image understanding field, which is to give each pixel a specific semantic label based on its characteristics automatically. Recently, even though convolutional neural network (CNN) based methods have been applied to hyperspectral image classification, their performances are not in accordance with our expectation. The reason is that, most of the existing methods can not exploit the intrinsic characteristics of different pixels in hyperspectral image effectively, they often ignore the inherent relationships among different spatial pixels, different spectral bands and different category dependencies. Specifically, the relationships among different spatial pixels mean that the similarities of attribute and location information among different pixels. The relationships among different spectral bands mean that the different contributions of them to the final classification. The relationships among different categories mainly mean that the severe sample imbalance problem in hyperspectral image classification task. To address the aforementioned problems, a deep convolutional network based multidimensional relation learning method is proposed in this paper. Firstly, we propose a weighted gaussian mask based spatial relation learning module to alleviate the spatial diffusion issue. Besides, we propose a channel attention alike spectral relation learning module to alleviate the interferences from noisy and redundant bands. Additionally, we propose an integrated decision based category relation learning module to alleviate the ill-conditioned classifying issue from imbalanced samples. Finally, we test the proposed method on four public and challenging datasets, and the experimental results validate the effectiveness and robustness of our method. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						211	219		10.1016/j.neucom.2020.05.034													
J								EEG signal processing with separable convolutional neural network for automatic scoring of sleeping stage	NEUROCOMPUTING										Convolutional neural networks; Deep learning; EEG; Signal processing; Sleep scoring	EPILEPTIC SEIZURES; IDENTIFICATION; SYSTEM; ADULTS; DEPTH	Nowadays, among the Deep Learning works, there is a tendency to develop networks with millions of trainable parameters. However, this tendency has two main drawbacks: overfitting and resource consumption due to the low-quality features extracted by those networks. This paper presents a study focused on the scoring of sleeping EEG signals to measure if the increase of the pressure on the features due to a reduction of the number though different techniques results in a benefit. The work also studies the convenience of increasing the number of input signals in order to allow the network to extract better features. Additionally, it might be highlighted that the presented model achieves comparable results to the state-of-the-art with 1000 times less trainable and the presented model uses the whole dataset instead of the simplified versions in the published literature. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						220	228		10.1016/j.neucom.2020.05.085													
J								A dense connection based network for real-time object tracking	NEUROCOMPUTING										Cascade; Deep learning; Tracking; Dense connection	VISUAL TRACKING	With the development of deep learning, the performance of many computer vision tasks has been greatly improved. For visual tracking, deep learning methods mainly focus on extracting better features or designing end-to-end trackers. However, during tracking specific targets most of the existing trackers based on deep learning are less discriminative and time-consuming. In this paper, a cascade based tracking algorithm is proposed to promote the robustness of the tracker and reduce time consumption. First, we propose a novel deep network for feature extraction. Since some pruning strategies are applied, the speed of the feature extraction stage can be more than 50 frames per second. Then, a cascade tracker named DCCT is presented to improve the performance and enhance the robustness by utilizing both texture and semantic features. Similar to the cascade classifier, the proposed DCCT tracker consists of several weaker trackers. Each weak tracker rejects some false candidates of the tracked object, and the final tracking results are obtained by synthesizing these weak trackers. Intensive experiments are conducted in some public datasets and the results have demonstrated the effectiveness of the proposed framework. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						229	236		10.1016/j.neucom.2020.06.019													
J								Artificial intelligence within the interplay between natural and artificial computation: Advances in data science, trends and applications	NEUROCOMPUTING										Artificial intelligence (AI); Machine learning; Deep learning; Reinforcement learning; Evolutionary computation; Ontologies; Artificial neural networks (ANNs); Big data; Robotics; Neuroscience; Human-machine interaction; Virtual reality; Emotion recognition; Computational neuroethology; Autism; Dyslexia; Alzheimer; Parkinson; Glaucoma; AI for social well-being	BIG DATA; CLASSIFICATION; RECOGNITION; INFORMATION; CHALLENGES; TUTORIAL; SOFTWARE; MACHINE; FUSION	Artificial intelligence and all its supporting tools, e.g. machine and deep learning in computational intelligence-based systems, are rebuilding our society (economy, education, life-style, etc.) and promising a new era for the social welfare state. In this paper we summarize recent advances in data science and artificial intelligence within the interplay between natural and artificial computation. A review of recent works published in the latter field and the state the art are summarized in a comprehensive and self- contained way to provide a baseline framework for the international community in artificial intelligence. Moreover, this paper aims to provide a complete analysis and some relevant discussions of the current trends and insights within several theoretical and application fields covered in the essay, from theoretical models in artificial intelligence and machine learning to the most prospective applications in robotics, neuroscience, brain computer interfaces, medicine and society, in general. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						237	270		10.1016/j.neucom.2020.05.078													
J								A Trajectory-based Attention Model for Sequential Impurity Detection	NEUROCOMPUTING										Impurity detection; Siamese fusion network; Trajectory-based attention model; Sequential region proposal classification	NETWORKS	Impurity detection involves detecting small impurities in the liquid inside an opaque glass bottle with complex textures by looking through the bottleneck. Sometimes experts have to observe continuous frames to determine the existence of an impurity. In recent years, region-based convolutional neural networks have gained incremental successes in common object detection tasks. However, sequential impurity detections present more challenging issues than detecting targets in a single frame, because consecutive motions and appearance changes of impurities cannot be captured using those common object detectors. In this paper, we propose a simple and controllable ensemble architecture to alleviate this problem. Specifically, a siamese fusion network is used to generate impurity proposals, then an attention model based on visual features and trajectories is proposed to localize a unique region proposal in each frame, finally, a sequential region proposal classifier using a long-term recurrent convolutional network is applied to refine impurity detection performances. The proposed method achieves 79.81% mAP on IML-DET datasets, outperforming a comparable state-of-the-art Mask R-CNN model. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						271	283		10.1016/j.neucom.2020.06.008													
J								Joint model for residual life estimation based on Long-Short Term Memory network	NEUROCOMPUTING										Deep learning; Prognosis; Multi-sensor data fusion; Supervised joint training; Condition monitoring; Long-short-term memory network	REMAINING USEFUL LIFE; DATA FUSION; PROGNOSTICS; PREDICTION; LSTM; MACHINERY; SYSTEMS; TOOL	With the rapid development of industrial internet of things, multi-sensor technology has been widely used in system condition monitoring and residual useful life (RUL) estimation, which plays a crucial role in preventing catastrophic failures and reducing maintenance losses. However, current prognosis using multi-sensor data faces the following challenges: (i) Manual feature selection and extraction and exploration of degradation failure mechanism for a complex domain require a substantial amount of human labor and expertise from the practitioner, which is seldom available. (ii) Data fusion and prognosis are usually divided into two separate steps, resulting in the lack of intrinsic relationship between the two tasks. (iii) The end-to-end prediction methods directly based on deep learning behave like the black-box and provide no information for degradation progression. To overcome these drawbacks, a prediction framework comprising two deep learning models is proposed in this paper. Through the proposed supervised joint training scheme, the framework not only provides a continuous visualization progression of system degradation but also ensures that the generated fusion signal effectively performs in RUL prediction. As a framework application, a joint model of RUL estimation based on an ordinary long short-term memory network is designed. In the experiment section, a simulation study is firstly performed to show its RUL prediction performance. Then, a case study is conducted using two public experimental data sets (the aircraft turbofan engine data and the milling). Furthermore, the advantage of the proposed joint model is validated by carrying out a comparison with other methods based on the same experimental data sets. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						284	294		10.1016/j.neucom.2020.06.052													
J								Stability analysis for delayed neural networks based on the augmented Lyapunov-Krasovskii functional with delay-product-type and multiple integral terms	NEUROCOMPUTING										Delayed neural networks; Lyapunov-Krasovskii functional; Auxiliary function-based multiple integral inequality; Stability analysis	TIME-VARYING DELAYS; DISCRETE; SYSTEMS; CRITERIA; IDENTIFICATION; INEQUALITY; HIERARCHY	This paper studies the stability problem for neural networks with time-varying delay. A novel Lyapunov-Krasovskii functional (LKF) is constructed that contains a delay-product-type (DPT) functional and a multiple-integral-type (MIT) functional. Therein, the DPT functional covers some existing ones as its special cases. In order to estimate the derivative of the MIT functional, an auxiliary function-based multiple integral inequality (AFMII) is presented, which can treat some existing results as its special cases. Based on these ingredients, a novel stability condition is obtained for neural networks with time-varying delay. A numerical example is given to illustrate the advantages of the stability condition. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						295	303		10.1016/j.neucom.2020.05.045													
J								Human action recognition using convolutional LSTM and fully-connected LSTM with different attentions	NEUROCOMPUTING										Human action recognition; Convolutional LSTM; Fully-connected LSTM; Spatial-temporal attention; Principle components analysis; Feature fusion	SPATIAL-TEMPORAL ATTENTION; NEURAL-NETWORKS	This paper aims to address the human action recognition issue by using convolutional long short-term memory networks (Conv-LSTM) and fully-connected LSTM (FC-LSTM) with different attentions. To this end, the spatial-temporal dual-attention network (STDAN), which is mainly composed of feature extraction, attention and fusion modules, is designed. Different from the features of high-level fully-connected layer mostly used in previous work, the features of convolution and fully-connected layers of convolutional neural network (CNN) are both extracted in STDAN, which can enrich the initial level of video representation. Besides, the Conv-LSTM and FC-LSTM are employed to handle the long-duration sequential features with different temporal context information. To reinforce the spatial-temporal attention ability, a temporal attention module (TAM) and a joint spatial-temporal attention module (JSTAM) are implemented. Through the principle components analysis (PCA) and features fusion, the potential of STDAN is effectively explored and weighted. Finally, the experimental results show that the proposed STDAN has better recognition performance than existing state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						304	316		10.1016/j.neucom.2020.06.032													
J								Randomized multi-label subproblems concatenation via error correcting output codes	NEUROCOMPUTING										Multi-label classification; Error correcting output codes; Imbalance problem; Diversity	CLASSIFICATION; DESIGN; ECOC	In this paper, we study the error correcting output codes for multi-label classification problems. Imbalance problem is very common in multi-label task and it has not been effectively solved yet. In previous works, base classifiers are learned from the same pool of training data which may lead to similar classifiers, especially when a large amount of labels exist. To tackle these challenges, we propose a novel model called Randomized Multi-Label Subproblems Concatenation via Error Correcting Output Codes (RMSC). In order to reduce the imbalance problem and enhance the diversity between base classifiers, in our model, the original multi-label problem is transformed into an ensemble of many multi-label sub-problems and the one-vs-all encoding strategy is conducted on these sub-problems and finally corresponding coding matrices are concatenated into a whole coding matrix. Moreover, we provide a proof of enhanced diversity in our model, together with some discussions about the parameter determination and time complexity. Extensive experimental results on various kinds of data sets well demonstrate that the proposed model consistently outperforms the state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						317	327		10.1016/j.neucom.2020.06.035													
J								Exploration of glottal characteristics and the vocal folds behavior for the speech under emotion	NEUROCOMPUTING										Physiological characteristics; Glottal features; Emotion analysis; Vocal folds; Vibration behavior	2-MASS MODEL; AIR-FLOW; VOICE; RECOGNITION; CLASSIFICATION; STRESS; CORDS	We preliminarily explore physiological characteristics of the vocal folds when the subject is under different emotional modes. Glottal variations from speech production representing the vocal folds behavior will be mainly discussed. We believe that emotion of the human subject has specific impact on the behavior of the vocal folds, which may result in the variations in glottal flow. This paper investigates the physiological characteristics of the vocal folds through variation in the glottal flow under different emotions. A modified algorithm, Pitch Synchronous Iterative Adaptive Inverse Filtering using Average Magnitude Difference Function based on Empirical Mode Decomposition (AMDFEMD-PSIAIF), is proposed to estimate the glottal flow. Glottal flow is discussed and measured by parameters representing the variations in the vibration behavior of the vocal folds. The physical parameters characterizing the muscle tension and viscosity of the vocal folds are estimated using a speech production model, and a fitting method using the glottal flow is proposed. Through an evaluation on a dataset containing over 1200 voice signals, the glottal and physical parameters are measured to verify the variation mode in vocal folds vibration. We obtain the true positive rate and the average sensitivity of each 9 parameter in 6 different emotional modes. Experimental results show that vocal folds present obvious physical changes when under different emotional modes. The CT muscle of the vocal folds is contracting for fear, happy, angry and surprise mode. The TA is relaxing for happy, angry and sad, while contracting when the speaker is under surprise. Fear and surprise make the surface of the vocal folds sticker, while viscosity reduction occurs when the speaker is experiencing sadness. Therefore, the vibration mechanism and physiological properties of the vocal folds corresponding to emotion modes are preliminarily explored. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						328	341		10.1016/j.neucom.2020.06.010													
J								Neural fuzzy approximation enhanced autonomous tracking control of the wheel-legged robot under uncertain physical interaction	NEUROCOMPUTING										Wheel-legged robot; Autonomous tracking control; Model predictive control; Neural fuzzy approximation	4-WHEEL-INDEPENDENT-DRIVE ELECTRIC VEHICLES; LATERAL MOTION CONTROL; NETWORK	The accuracy of trajectory tracking and stable operation with heavy load are the main challenges of parallel mechanism for wheel-legged robots, especially in complex road conditions. To guarantee the tracking performance in an uncertain environment, the disturbances, including the internal-robot friction and external-robot and environment interaction forces, should be considered in the robot's dynamical system. In this article, a neural fuzzy-based model predictive tracking scheme (NFMPC) for reliable tracking control is proposed to the developed four wheel-legged robot, and the fuzzy neural network approximation is applied to estimate the unknown physical interaction and external dynamics of the robot system. Meanwhile, the advanced parallel mechanism of the four wheel-legged robot (BIT-NAZA) is introduced. Finally, co-simulation and experiment results using the BIT-NAZA robot derived from the proposed hybrid control strategy indicate that the methodology can achieve satisfactory tracking performance in terms of accuracy and stability. This research can provide theoretical and engineering guidance for lateral stability of intelligent robots under unknown disturbances and uncertain nonlinearities, and facilitate the control performance of the wheel-legged robot in a practical system. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						342	353		10.1016/j.neucom.2020.05.091													
J								Micro-attention for micro-expression recognition	NEUROCOMPUTING										Micro expression recognition; Deep learning; Attention mechanism; Transfer learning	CATEGORIZATION	Micro-expression, for its high objectivity in emotion detection, has emerged to be a promising modality in affective computing. Recently, deep learning methods have been successfully introduced into the micro-expression recognition area. Whilst the higher recognition accuracy achieved, substantial challenges in micro-expression recognition remain. The existence of micro expression in small-local areas on face and limited size of available databases still constrain the recognition accuracy on such emotional facial behavior. In this work, to tackle such challenges, we propose a novel attention mechanism called micro-attention cooperating with residual network. Micro-attention enables the network to learn to focus on facial areas of interest covering different action units. Moreover, coping with small datasets, the micro-attention is designed without adding noticeable parameters while a simple yet efficient transfer learning approach is together utilized to alleviate the overfitting risk. With extensive experimental evaluations on three benchmarks (CASMEII, SAMM and SMIC) and post-hoc feature visualizations, we demonstrate the effectiveness of the proposed micro-attention and push the boundary of automatic recognition of micro-expression. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						354	362		10.1016/j.neucom.2020.06.005													
J								NLDN: Non-local dehazing network for dense haze removal	NEUROCOMPUTING										Non-local dehazing; Deep learning; Image restoration		Single image dehazing is one of the most challenging and important tasks in computer vision and image processing. In this paper, we propose a Non-local Dehazing Network (NLDN), which learns the mapping between hazy images and haze-free images. Our network architecture consists three components: the first is full point-wise convolutional part, which extracts Non-local statistical regularities; the second is feature combination part, which learns the spatial relation of statistical regularities; the third is reconstruction part, which recovers the haze-free image by the features extracted from the second part. By using these three components, we obtain a high quality dehazing result. Experimental results show that our method performs favorably against other state-of-the-art methods on both synthetic dataset and real-world images. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						363	373		10.1016/j.neucom.2020.06.041													
J								Deep learning for EEG-based biometric recognition	NEUROCOMPUTING										Biometrics; Electroencephalography; Deep learning; Convolutional neural networks; Recurrent neural networks	PERMANENCE; SIGNALS	The exploitation of brain signals for biometric recognition purposes has received significant attention from the scientific community in the last decade, with most of the efforts so far devoted to the quest for discriminative information within electroencephalography (EEG) recordings. Yet, currently-achievable recognition rates are still not comparable with those granted by more-commonly-used biometric characteristics, posing an issue for the practical deployment of EEG-based recognition in reallife applications. Within this regard, the present study investigates the effectiveness of deep learning techniques in extracting distinctive features from EEG signals. Both convolutional and recurrent neural networks, as well as their combinations, are employed as strategies to derive personal identifiers from the collected EEG data. In order to assess the robustness of the considered techniques, an extensive set of experimental tests is conducted under very challenging conditions, trying to determine whether it is feasible to identify subjects through their brain signals regardless the performed mental task, and comparing acquisitions collected at a temporal distance greater than one year. The obtained results suggest that the proposed networks are actually able to exploit the dynamic temporal behavior of EEG signals to achieve high-level accuracy for brain-based biometric recognition. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						374	386		10.1016/j.neucom.2020.06.009													
J								Short-term traffic speed forecasting based on graph attention temporal convolutional networks	NEUROCOMPUTING										Traffic forecasting; Deep learning; Graph attention network; Temporal convolutional network	FLOW PREDICTION; DEMAND	Accurate and timely traffic forecasting is significant for intelligent transportation management. However, existing approaches model the temporal and spatial features of traffic flow inadequately. To address these limitations, a novel deep learning traffic forecasting framework based on graph attention network (GAT) and temporal convolutional network (TCN) is presented in this paper, termed as graph attention temporal convolutional networks (GATCN). More specifically, GATCN deal with the spatial features by GAT, and the temporal features by TCN. The layer fused by GAT and TCN enables the proposed model to learn the spatio-temporal characteristics that lie in traffic flow, while considering exogenous factors. In addition, nodes in the graph can capture the information of their neighborhoods by stacking multiple layers. Precision and robustness of the proposed method have been evaluated through testing on the real-world dataset. Results show that the proposed model outperforms other baselines. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						387	393		10.1016/j.neucom.2020.06.001													
J								Deep multi-metric learning for text-independent speaker verification	NEUROCOMPUTING										Speaker verification; N-pair loss; Angular loss; triplet loss; SENet		Text-independent speaker verification is an important artificial intelligence problem that has a wide spectrum of applications, such as criminal investigation, payment certification, and interest-based customer services. The purpose of text-independent speaker verification is to determine whether two given uncontrolled utterances originate from the same speaker or not. Extracting speech features for each speaker using deep neural networks is a promising direction to explore and a straightforward solution is to train the discriminative feature extraction network by using a metric learning loss function. However, a single loss function often has certain limitations. Thus, we use deep multi-metric learning to address the problem and introduce three different losses for this problem, i.e., triplet loss, n-pair loss and angular loss. The three loss functions work in a cooperative way to train a feature extraction network equipped with Residual connections and squeeze-and-excitation attention. We conduct experiments on the large-scale VoxCeleb2 dataset, which contains over a million utterances from over 6,000 speakers, and the proposed deep neural network obtains an equal error rate of 3.48%, which is a very competitive result. Codes for both training and testing and pretrained models are available at https://github.com/Greatjiweix/DmmltiSV, which is the first publicly available code repository for large-scale text- independent speaker verification with performance on par with the state-of-the-art systems. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						394	400		10.1016/j.neucom.2020.06.045													
J								Distribution agnostic Bayesian matching pursuit based on the exponential embedded family	NEUROCOMPUTING										Compressed sensing; Sparse signal reconstruction; Exponentially embedded family; Dominant support selection; Minimum mean squared error	SIGNAL RECOVERY; RECONSTRUCTION	Compressed sensing (CS) is an emerging field that allows to recover high-dimensional sparse signal from a few compressed measurements. Classical CS algorithms using the Bayesian framework generally impose a sparseness-promoting prior on the signal, which may not characterize the real signals with diversity. Moreover, estimating the parameters involved in the prior is challenging especially for non-i. i.d. signals. In this paper, we propose an efficient prior-agnostic Bayesian matching pursuit for sparse signal recovery, which avoids the risk of imposing mismatched prior on the signals and enjoys lower complexity than Bayesian approaches due to the elimination of prior parameter estimation. Specifically, we utilize the noise model and the reduced exponential embedded family (EEF) to obtain an approximate likelihood of interest, and then find the most dominant supports with maximum approximate likelihoods in a greedy manner to give an approximate minimum mean squared error (MMSE) estimate for the sparse signal. Experiment results demonstrate that our method achieves lower normalized mean squared error (NMSE) while higher efficiency compared to the state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						401	409		10.1016/j.neucom.2020.06.007													
J								Cooperative control for swarming systems based on reinforcement learning in unknown dynamic environment	NEUROCOMPUTING										Swarming system; Cooperative control; Reinforcement learning; Neural networks; Dynamic threat	MULTIAGENT SYSTEMS; FLOCKING; ALGORITHM; ROBOT; ADP	This paper discussed the cooperative control problem for swarming systems in unknown dynamic environment. The swarm agents are required to move in a completely distributed manner with the reference trajectory determined by a virtual dynamic leader. In addition to keeping an appropriate distance from neighboring agents, each agent needs to avoid collision with dynamic threats in unknown environment. All of these complex requirements are integrated and designed as the performance index function for each agent. Then, the cooperative learning behavior of swarming system is realized by applying the reinforcement learning theory. Neural networks are used to model the control scheme and trained to minimize the performance index. The online updating rules of the neural networks are achieved based on the gradient descent algorithm. Finally, two simulation experiments are performed to verify the effectiveness of the cooperative control scheme and the environmental adaptability of the swarm agents. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						410	418		10.1016/j.neucom.2020.06.038													
J								CTEA: Context and Topic Enhanced Entity Alignment for knowledge graphs	NEUROCOMPUTING										Knowledge graph embedding; Entity alignment; Entity contexts; Topic model		We study the problem of finding entities referring to the same real world object in multilingual knowledge graphs(KGs), i.e., entity alignment for multilingual KGs. Recently, embedding-based entity alignment methods get extended attention in this area. Most of them firstly embed the entities in low dimensional vectors space via relation structure of entities, and then align entities via these learned embeddings combined with some entity similarity function. Even achieved promising performances, these methods are defective in utilizing entity contexts and entity topic information. In this paper, we propose a novel entity alignment framework CTEA (Context and Topic Enhanced Entity Alignment), which integrates entity context information and entity topic information to help alignment. This framework learns entity topic distributions from their attributes with a specially designed topic model BTM4EA, and the learned entity topic distributions are used to filter some weakly correlated entities for each entity to be aligned. Meanwhile, we embed KGs to low dimensional vectors space via translation-based KG embedding model and mine context information from these vectors with an attention attached Convolutional Neural Network(CNN). The entity embeddings, entity contexts and entity topics are combined to get the final alignment results. Extended experiments reveal that our method achieves promising performances in most cases. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						419	431		10.1016/j.neucom.2020.06.054													
J								Abstractive social media text summarization using selective reinforced Seq2Seq attention model	NEUROCOMPUTING										Social media text summarization; Sequence-to-sequence; Reinforcement learning		The Abstractive text summarization aims to generate a brief version of a given sentence while attempting to express its main meaning. Although some models based on the sequence-to-sequence framework have achieved remarkable results recently, there are still many problems that cannot be ignored. In this paper, we propose a selective reinforced sequence-to-sequence (i.e. Seq2Seq) attention model for abstractive social media text summarization. We add a selective gate after the encoder module for better filtering out invalid information. Specifically, we combine the cross-entropy and reinforcement learning policy for optimizing the ROUGE score directly. Evaluations on a famous social media dataset (i.e. LCSTS) demonstrate that our model outperforms most of famous baseline models, and the proposed model is 2.6%, 2.1% and 2.5% higher than the basic Seq2Seq attention model on the F1 score of ROUGE-1, ROUGE-2, and ROUGE-L, respectively. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						432	440		10.1016/j.neucom.2020.04.137													
J								Sentiment key frame extraction in user-generated micro-videos via low-rank and sparse representation	NEUROCOMPUTING										Video analytics; Video emotion recognition; Key frame extraction; Video summarization; Sparse representation; Low-rank representation		It is a prevailing trend that the user-generated content (UGC) on social media is shifting toward mobile video and micro content. Sentiment analysis and emotion recognition extract the opinions expressed in UGC and are important to understand the fast-growing mobile micro-videos. Although extensive research efforts have been devoted to it, most of the existing studies pre-processed the video before extracting sentiment features, pre-sampling as an example. Due to the rather unstructured nature of user-generated videos and the sparsely expressed emotions, sampling before sentiment analysis can remove visual contents important to understand the video. In this paper, a novel unsupervised sentiment key frame extraction (SKFE) model based on low-rank and sparse representation is proposed. Sparsity is the important characteristic distinct to a video frame. The low-rank constraint is helpful to improve the robustness to noise and outliers. The 1 2 , 1 -norm sparsity is adopted to improve the robustness via different indexes running through the feature dimensions and among the video frames. To better characterize the relationship between the local features and alleviate the sensitiveness of sparse coding, a regularization term based on the Laplacian matrix is introduced to preserve the consistency of sparse codes for similar local features. The experimental results on publicly available datasets demonstrate the effectiveness of the proposed SKFE model. (C) 2020 Elsevier B.V. All rights reserved.																	0925-2312	1872-8286				OCT 14	2020	410						441	453		10.1016/j.neucom.2020.05.026													
J								Semantic segmentation with hybrid pyramid pooling and stacked pyramid structure	NEUROCOMPUTING										Semantic segmentation; Channel-wise feature; Hybrid pyramid pooling; Stacked pyramid structure; Sampling density		Convolution filters play important roles in improving the abstraction ability of segmentation networks due to its method of fusing features from all input channels. Such a method pays little attention to protecting the channel-wise features which is important in preserving the detail features in the final result. Though a few works has discussed this problem, the function of channel-wise features is still not sufficiently exploited. For investigating the beneficial effect of channel-wise feature on improving details representation ability, we design a Hybrid Pyramid Pooling (HPP) structure to explicitly exploit the channel-wise features. Through utilizing different scales of depthwise dilated convolution, segmentation networks can fully utilize the superiority of channel-wise features to improve the details representation ability. For deeply developing the advantages of the channel-wisely calculated features by HPP, we design another Stacked Pyramid Structure (SPS), which contains stacked pyramid pooling structures. The SPS distributes sufficient sampling points in each finely divided sampling area, and fuses features from a large range of receptive fields to produce rich feature representation. Finally, the combination of HPP and SPS can not only maintains both the advantages of features calculated from a particular channel and all input channels, but also provides sufficiently enriched receptive fields for depicting details in the final result. (C) 2020 Published by Elsevier B.V.																	0925-2312	1872-8286				OCT 14	2020	410						454	467		10.1016/j.neucom.2020.04.126													
J								An evaluation of machine learning techniques to predict the outcome of children treated for Hodgkin-Lymphoma on the AHOD0031 trial	APPLIED ARTIFICIAL INTELLIGENCE											REGULARIZATION PATHS; SURVIVAL; MODELS	In this manuscript, we analyze a data set containing information on children with Hodgkin Lymphoma (HL) enrolled on a clinical trial. Treatments received and survival status were collected together with other covariates such as demographics and clinical measurements. Our main task is to explore the potential of machine learning (ML) algorithms in a survival analysis context in order to improve over the Cox Proportional Hazard (CoxPH) model. We discuss the weaknesses of the CoxPH model we would like to improve upon and then we introduce multiple algorithms, from well-established ones to state-of-the-art models, that solve these issues. We then compare every model according to the concordance index and the Brier score. Finally, we produce a series of recommendations, based on our experience, for practitioners that would like to benefit from the recent advances in artificial intelligence.																	0883-9514	1087-6545															10.1080/08839514.2020.1815151		OCT 2020											
J								Multilayer weighted integrated self-learning algorithm for automatic diagnosis of epileptic electroencephalogram signals	COMPUTATIONAL INTELLIGENCE										automatic epilepsy diagnosis; EEG; machine learning; semi-supervised learning	SEIZURE DETECTION; PATTERN; ENERGY	Epilepsy is a common mental disorder that affects about 70 million people worldwide. Epileptic electroencephalogram (EEG) signal, an important means to judge epileptic seizure, needs neurologists' prior knowledge to mark manually. This marking method is time-consuming and laborious. Currently, the existing automated diagnosis methods have achieved good results on one benchmark EEG dataset, most of which can achieve accuracy of more than 0.95. However, the method has limitations on the dataset, and the accuracy of the diagnosis results on another new dataset drops sharply to nearly 0.5. Aiming at the existing EEG signal diagnosis lacks stability and generalization ability, this paper proposed a multilayer-weighted integrated self-learning algorithm for different classifiers. For this algorithm, weighted voting was first conducted on the the diagnostic results by different classifiers to obtain a result, which was weighted again to produce the final diagnostic results. This algorithm improves the problem that the traditional self-learning algorithm is greatly affected by data noise, which shows a strong stability in different data sets and in clinical epileptic EEG signal data detection, so as to reduce the workload of neurologists and provide support and assistance for the diagnosis and treatment of epilepsy. The experiment result shows that the algorithm can improve the stability and reliability of EEG automatic diagnosis of epilepsy. The accuracy and AUC area of its classification in two different public data sets and clinical data can reach 0.80 to 0.95.																	0824-7935	1467-8640															10.1111/coin.12414		OCT 2020											
J								Interval Type-2 Fuzzy Cognitive Map-Based Flight Control System for Quadcopters	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Interval type-2 fuzzy sets; Quadcopters; Fuzzy Cognitive Map; Flight control system	TRAJECTORY TRACKING; ATTITUDE-CONTROL; NEURAL-NETWORKS; QUADROTOR; PSO	In this paper, we propose a novel Interval Type-2 (IT2) Fuzzy Cognitive Map (FCM)-based flight control system to solve the altitude, attitude and position control problems of quadcopters. The proposed IT2-FCM encompasses all concepts related to drone for a satisfactory path-tracking and stabilizing control performance. The degree of mutual influences of the concepts is designed with opinions of three experts that take account the dynamics of drone and rules governing proportional integral derivative (PID) controllers. To model the inter-uncertainty of the experts' opinions, IT2 fuzzy logic systems are utilized as they are powerful tools to model high level of uncertainties. Thus, the proposed IT2-FCM has a qualitative representation as it merges the advantages of IT2 fuzzy logic systems and FCMs. We present comparative simulations results in presence of uncertainties where the superiority of the proposed IT2-FCM-based flight control system is shown in comparison with its type-1 fuzzy counterpart.																	1562-2479	2199-3211															10.1007/s40815-020-00940-8		OCT 2020											
J								A Parallel Fuzzy Algorithm for Real-Time Medical Image Enhancement	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Filter design; Medical image processing; Fuzzy logic; Noise reduction	IMPULSE NOISE-REDUCTION; PEER GROUPS; CT IMAGES; REMOVAL; FILTER	Medical images may be corrupted by noise. This noise affects the image quality and can obscure important information required for accurate diagnosis. Effectively apply filtering techniques can facilitate diagnosis or reduce radiation exposure. In this paper, we introduce a parallel method designed to reduce mixed Gaussian-impulse noise from digital images. The method uses fuzzy logic and the fuzzy peer group concept. Implementations of the method on multi-core interface using the open multi-processing (OpenMP) and on graphics processing units (GPUs) using CUDA are presented. Efficiency is measured in terms of execution time and in terms of MAE, PSNR and SSIM over medical images from the mini-MIAS database and over computed radiography (CR) images generated at different exposure levels. These images have been contaminated with impulsive and/or Gaussian noise. Experiments show that the proposed method obtains good performance in terms of the above mentioned objective quality measures. After applying multi-core and GPUs optimization strategies, the observed time shows that the new filter allows to remove mixed Gaussian-impulse noise in real-time.																	1562-2479	2199-3211															10.1007/s40815-020-00953-3		OCT 2020											
J								Admissibility and Admissibilization of Singular Polynomial Fuzzy Systems with Time-Varying Delay	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Polynomial fuzzy controller; Singular polynomial fuzzy systems; Sum-of-squares (SOS); Time-varying delay	H-INFINITY CONTROL; STABILIZATION CRITERIA; STABILITY	This paper addresses the admissibility analysis and the polynomial fuzzy controller design for a class of singular polynomial fuzzy systems with time-varying delay. Firstly, according to Lyapunov stability theory, a sufficient condition is obtained by means of sum-of-squares (SOS) to ensure that the closed-loop singular polynomial fuzzy system is admissible. Secondly, by the help of the two equivalent sets, SOS-based admissibility conditions are proposed to avoid solving the equality conditions and the polynomial fuzzy controller is designed. Finally, three examples validate the usefulness and superiority of the proposed design procedure compared with existing results.																	1562-2479	2199-3211															10.1007/s40815-020-00965-z		OCT 2020											
J								Adaptive Leader-Follower Formation for Unmanned Surface Vehicles Subject to Output Constraints	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Leader-follower formation; LOS guidance law; Adaptive fuzzy control; Bioinspired neurodynamics	NEURAL-NETWORK CONTROL; PRESCRIBED PERFORMANCE; TRACKING; VESSELS; SHIP	This paper addresses the leader-follower formation control strategy for unmanned surface vehicles with model uncertainties. First, to achieve the desired formation configuration, the line-of-sight (LOS) scheme is incorporated in the guidance design. The constraints of LOS range and angle are required to meet the connectivity maintenance and collision avoidance. Tan-type time-varying Barrier Lyapunov function (BLF) is applied to address the output constraints. Next, in the formation control design, bioinspired models are combined with backstepping techniques to achieve less calculation. Adaptive fuzzy control approach is developed to deal with the uncertainties of marine vessels due to their superior approximation capability. Finally, the uniform ultimate boundedness of all signals can be guaranteed via stability analysis. Simulation examples are carried out to demonstrate the feasibility of the theoretical results.																	1562-2479	2199-3211															10.1007/s40815-020-00958-y		OCT 2020											
J								Practical Moving Target Detection in Maritime Environments Using Fuzzy Multi-sensor Data Fusion	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy multi-sensor data fusion; Unmanned surface vehicles (USVs); Maritime navigation; Automatic Identification System (AIS)	PROBABILISTIC DATA ASSOCIATION; MULTIPLE MANEUVERING TARGETS; TRACKING; ALGORITHM; CLUTTER	As autonomous ships become the future trend for maritime transportation, it is of importance to develop intelligent autonomous navigation systems to ensure the navigation safety of ships. Among the three core components (sensing, planning and control modules) of the system, an accurate detection of target ships' navigation information is critical. Within a typical maritime environment, the existence of sensor noises as well as the influences generated by varying environment conditions largely limit the reliability of using a single sensor for environment awareness. It is therefore vital to use multiple sensors together with a multi-sensor data fusion technology to improve the detection performance. In this paper, a fuzzy logic-based multi-sensor data fusion algorithm for moving target ships detection has been proposed and designed using both AIS and radar information. A two-stage fuzzy logic association method has been particularly developed and integrated with Kalman filtering to achieve a computationally efficient performance. The effectiveness of the proposed algorithm has been tested and validated in simulations where multiple target ships are transiting with complex movements.																	1562-2479	2199-3211															10.1007/s40815-020-00963-1		OCT 2020											
J								Adaptive Interval Type-2 Fuzzy Fixed-time Control for Underwater Walking Robot with Error Constraints and Actuator Faults Using Prescribed Performance Terminal Sliding-mode Surfaces	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Underwater walking robot; Interval type-2 fuzzy logic system; Error constraint; Fixed-time control; Fault-tolerant control	TRAJECTORY TRACKING CONTROL; FOLLOWER FORMATION CONTROL; FINITE-TIME; VEHICLES; SYSTEMS; DESIGN; STABILIZATION; FILTER	Underwater walking robot (UWR) is a kind of autonomous underwater vehicles which can walk underwater. In this work, the fixed-time tracking control problem of UWR with external disturbances, error constraints, and actuator faults is investigated. An interval type-2 fuzzy neural network approximator is designed to tackle nonlinear uncertainties, and a novel prescribed performance terminal sliding-mode surface is proposed to handle error constraints. Furthermore, two fault-tolerant controllers are given, where one is nonsingular and the other has higher steady-state precision. According to Lyapunov theory, the proposed controllers can guarantee that system states will converge to the expected values in a fixed time. Simulation results demonstrate the effectiveness of the proposed control strategies.																	1562-2479	2199-3211															10.1007/s40815-020-00949-z		OCT 2020											
J								Fuzzy State Observer-Based Cooperative Path-Following Control of Autonomous Underwater Vehicles with Unknown Dynamics and Ocean Disturbances	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Synchronized guidance; Fuzzy state observer; Prediction; Cooperative path-following control; Autonomous underwater vehicles	MARINE SURFACE VEHICLES; TRAJECTORY TRACKING; MULTIAGENT SYSTEMS; UNCERTAINTY; ROBOTS; CURVE	This article considers the cooperative path-following control problem for a cluster of networked autonomous underwater vehicles (AUVs) suffering from unknown dynamics and ocean disturbances. By virtue of light-of-sight guidance and undirected graph, a synchronized guidance approach is created for underactuated AUVs, where multiple geometry curves are taken into account and information exchanges-related path variables are utilized, and thereby enabling AUVs to be synchronized and stabilized into a desired formation pattern. Within the distributed surge and yaw controller design, the unknown dynamics and the ocean disturbances are lumped together by using a linear state transformation. And a prediction-based fuzzy state observer (PFSO) is devised for estimating the unmeasured lumped states, where prediction errors are used to update fuzzy weights. Through the Lyapunov analysis, it is proven that surge and yaw-tracking errors and state observation errors are uniformly ultimately bounded. Simulation verifications are deployed to illustrate the efficacy and superiority of the designed method.																	1562-2479	2199-3211															10.1007/s40815-020-00943-5		OCT 2020											
J								Further Developments on Application of Dynamic Fuzzy Cognitive Map Concept for Digital Business Models	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Fuzzy cognitive map; Business models; Digital transformation; Differential Hebbian learning	TRANSFORMATION; INNOVATION	Business systems are considered as complex systems and consist of several sub-models such as procurement market, supply process, assembly, distribution and sales market. In these systems, it is important to analyze strength and weakness of each sub-model over other parts in order to obtain information for enhancing the business system performance. To fulfill this aim, in this paper we utilize differential Hebbian learning-based dynamic fuzzy cognitive map techniques to examine the effect of expert's knowledge as a sort of digital transformation source as well as impact of each sub-model of business system over other sub-models. Finally, the proposed method is illustrated numerically.																	1562-2479	2199-3211															10.1007/s40815-020-00955-1		OCT 2020											
J								Aggregating Intuitionistic Fuzzy Preference Relations with Symmetrical Intuitionistic Fuzzy Bonferroni Mean Operators in Group Decision Making	INTERNATIONAL JOURNAL OF FUZZY SYSTEMS										Symmetrical intuitionistic fuzzy Bonferroni mean operator; Group decision making; Acceptable group multiplicative consistency; Intuitionistic fuzzy preference relation	MULTIPLICATIVE CONSISTENCY; CONSENSUS	As a useful aggregation technique, the Bonferroni mean can capture the interrelationship between input arguments and has been a hot research topic, especially, in intuitionistic fuzzy environment. In this paper, it is pointed out by an example that the existing intuitionistic fuzzy Bonferroni mean (IFBM) operators fail to satisfy the need in group decision making with intuitionistic fuzzy preference relations (IFPRs). Then, symmetrical intuitionistic fuzzy Bonferroni mean (SIFBM) operator and weighted SIFBM operator are developed to settle the above issue and some desirable properties of them are provided. Furthermore, an acceptable group multiplicative consistency of the IFPRs is introduced and a novel algorithm is established to jointly and stepwisely reach the acceptable group multiplicative consistency and consensus of IFPRs in group decision making. Finally, numerical examples are given to illustrate the effectiveness of the proposed method and comparisons with the existing methods are made to demonstrate the advantages of the proposed method.																	1562-2479	2199-3211															10.1007/s40815-020-00960-4		OCT 2020											
J								Solution of an imperfect-quality EOQ model with backorder under fuzzy lock leadership game approach	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										backlogging; game and leadership theory; imperfect item; inventory; triangular lock fuzzy set	GROUP DECISION-MAKING; COMPETITION; MOTIVATION; SELECTION; ENTROPY; TALENT; SETS	This paper considers an economic order quantity (EOQ) inventory model for items with imperfect quality and shortage backordering under several styles of managerial leadership via lock fuzzy game theoretic approach. The decision maker (DM) controls several cost components by playing as Player 1 on the one side and the consumers who may accept/reject those items (unwilling to buy those commodities) stands as Player 2 on the other side. First of all, we develop a profit maximization backlogging EOQ model where the imperfect items are screened out batchwise. Because of the fuzzy flexibility of the model parameters we also develop a fuzzy mathematical model by considering the demand, all cost parameters, and other input parameters of the inventory system as triangular lock fuzzy numbers. Then we develop a 3 x 3 matrix game by applying a five-stage leadership theory employing several key vectors in the model itself. The problem has been solved for crisp, general fuzzy models of several leadership styles also. Numerical results show that for a cooperative game, inventory profit function reaches its maximum rather than the noncooperative game by the use of proper keys. Finally, comparative study, sensitivity analysis, and graphical illustrations are made to justify the new approach.																	0884-8173	1098-111X															10.1002/int.22305		OCT 2020											
J								A decision support framework for security resource allocation under ambiguity	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS										ambiguity; decision making under uncertainty; D-S theory; game theory; public security; security game	STACKELBERG GAME; MODEL; IMPRECISE	There has been increasing interest in using Stackelberg game (known as a security game) to allocate limited security resources against different attacker types with a specific probability distribution. However, real problems of this kind often face ambiguous information, such as imprecise, unreliable and absent payoffs, and ambiguous assignments of these payoffs. To this end, based on decision theory and the Dempster-Shafer theory of evidence, this paper proposes a novel framework that can handle these common types of ambiguity. More specifically, this paper deploys the underlying principles of existing rules from decision theory, as a way to characterise different attitudes to ambiguity, during the transformation of ambiguous payoffs into point-valued payoffs. Hence, our framework holds some good properties: (i) it subsumes traditional security games without ambiguous payoffs, (ii) a uniform margin of error will not affect the results and (iii) the influence of complete ignorance can be minimised. Also, our framework is evaluated by using nine different transformation rules, under various conditions and constraints, against 73,000 randomly generated games (a first comprehensive empirical evaluation to date). The evaluation reveals the benefits of each transformation rule and confirms that different rules can model individuals' different attitudes to ambiguity.																	0884-8173	1098-111X															10.1002/int.22288		OCT 2020											
J								A novel framework based on wavelet transform and principal component for face recognition under varying illumination	APPLIED INTELLIGENCE										Face recognition; Varying illumination; Wavelet transform; Principal component; Neural network	NETWORK; NORMALIZATION; DECOMPOSITION; CLASSIFIER; REDUCTION; ALGORITHM	One of the most primitive problems in face recognition is illumination variation, which is of significance for image processing and pattern recognition. Existing studies concentrate on the wavelet transform (WT) without elaborately considering high-frequency information and most do not efficiently tackle a computation explosion of facial dimensions in classification. Therefore, a novel framework based on wavelet transform and principal component is proposed to improve the accuracy under illumination variation in this paper. In the proposed framework, low-frequency sub-band (LFSB) and high-frequency sub-band (HFSB) images from wavelet transform are simultaneously enhanced and denoised, unlike previous studies that usually cause loss of details due to less consideration of HFSB. For LFSB image, a multiple scale Retinex-based steering kernel is designed to enhance more details, and then an adaptive strategy of gamma correction is developed to automatically expand gray-dynamic range. For HFSB image, a non-local mean filtering is established to suppress the noise and subsequently, more image details are preserved by local of mean of local variance. Moreover, the principal component technique based Fisherface and virtual auxiliary sample strategy is developed in order to overcome the computation explosion of facial dimensions, in which a sample strategy with interpolation mechanism is employed to avoid the complicated singularity and Fisherface analysis is further applied to extract features and dimensionality reduction. In addition, the particle swarm optimization-neural network (PSO-NN) is employed to perform classification in the framework. Experimental results prove that the proposed framework can effectively obtain the robust visual effect under varying illumination and significantly improve the recognition performance in comparison to existing methods.																	0924-669X	1573-7497															10.1007/s10489-020-01924-9		OCT 2020											
J								Attentive evolutionary generative adversarial network	APPLIED INTELLIGENCE										Generative adversarial network; Attention mechanism; Evolutionary algorithm; Image generation		Generative adversarial network (GAN) is an effective method to learn generative models from real data. But there are some drawbacks such as instability, mode collapse and low computational efficiency in the existing GANs. In this paper, attentive evolutionary generative adversarial network (AEGAN) model is proposed in order to improve these disadvantages of GANs. The modified evolutionary algorithm is designed for the AEGAN. In the AEGAN the generator evolves continuously to resist the discriminator by three independent mutations at every batch and only the well-performing offspring (i.e.,the generators) can be preserved at next batch. Furthermore, a normalized self-attention (SA) mechanism is embedded in the discriminator and generator of AEGAN to adaptively assign weights according to the importance of features. We propose careful regulation of the generators evolution and an effective weight assignment to improve diversity and long-range dependence. We also propose a superior training algorithm for AEGAN. With the algorithm, the AEGAN overcomes the shortcomings of traditional GANs brought by single loss function and deep convolution and it greatly improves the training stability and statistical efficiency. Extensive image synthesis experiments on CIFAR-10, CelebA and LSUN datasets are presented to validate the performance of AEGAN. Experimental results and comparisons with other GANs show that the proposed model is superior to the existing models.																	0924-669X	1573-7497															10.1007/s10489-020-01917-8		OCT 2020											
J								Two levels approach based on multifactorial optimization to solve the clustered shortest path tree problem	EVOLUTIONARY INTELLIGENCE										Multifactorial evolutionary algorithm; Clustered shortest-path tree problem; Evolutionary algorithms; Genetic algorithm; Multifactorial optimization	EVOLUTIONARY MULTITASKING; ALGORITHM; NETWORKS	The Clustered Shortest-Path Tree Problem (CluSPT) has a great meaning in theoretical research as well as a wide range of applications in everyday life, especially in the field of network optimization. Being able to solve the CluSPT will path the way for improving practical systems such as agricultural irrigation and product distribution. Multifactorial Evolutionary Algorithm (MFEA) is a variant of Evolutionary Algorithm (EA) aiming at simultaneously solving multiple factorial tasks which can be diverse in types, dimensionalities and search spaces. The applications of MFEA have yet to be fully exploited, but the realm has recently attracted much interest from the research community, especially those who are working on evolutionary multitasking. Considering these characteristics, this paper describes a new approach using the MFEA for solving the CluSPT. The MFEA has two tasks: the first is solving the CluSPT problem and the second is solving a new problem which is decomposed from the CluSPT problem. The goal of the first task is finding the fittest solution as possible for the CluSPT while the goal of the second task is determining the best tree (w.r.t. cost minimization) which envelops all vertices of the problem. This paper also introduces mutation, crossover and population initialization operators for a proposed MFEA to solve the CluSPT. Each of these operators deals with individuals in two phases, one of which ensures that the resulted individual is a spanning tree and the other phase ensures that each of its clustered sub-graphs is also a spanning tree. As the MFEA had to deal with these two tasks, a decoding method was also created to allow communication between the tasks. To assess the effectiveness of the proposed algorithm and methods, the authors implemented them on both Euclidean and Non-Euclidean instances. Experiment results show that the proposed MFEA outperformed the existing MFEA algorithms on two-thirds instances with average improvement value of 47%. Besides, this paper analysis the convergence trends of each task in generations and the affectation of the number of vertices in the largest cluster on the obtained results by using both the Spearman's rank correlation coefficient and scatter graphs.																	1864-5909	1864-5917															10.1007/s12065-020-00501-w		OCT 2020											
J								A knowledge discovery and visualisation method for unearthing emotional states from physiological data	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Knowledge discovery; Knowledge visualisation; Decision trees; Physiological data; Logic rules; Interpretable machine learning; Wearables; Sensors; Affective computing; Plethysmography; Galvanic skin response	HEART-RATE; SYSTEMS	In this paper we propose a knowledge discovery and visualisation method for unearthing emotional states from physiological data typically available from wearable devices. In addition we investigate the viability of using a limited set of wearable sensors to extract decision tree rules which are representative of physiological changes taking place during emotional changes. Our method utilised a fusion of pre-processing and classification techniques using decision trees to discover logic rules relating to the valence and arousal emotional dimensions. This approach normalised the signal data in a manner that enabled accurate classification and generated logic rules for knowledge discovery. Furthermore, the use of three target classes for the emotional dimensions was effective at denoising the data and further enhancing classification and useful rule extraction. There are three key contributions in this work, firstly an exploration and validation of our knowledge discovery methodology, secondly successful extraction of high accuracy rules derived from physiological data and thirdly knowledge discovery and visualisation of relationships within-participant physiological data that can be inferred relating to emotions. Additionally, this work may be utilised in areas such as the medical sciences where interpretable rules are required for knowledge discovery.																	1868-8071	1868-808X															10.1007/s13042-020-01205-4		OCT 2020											
J								Matrix-based incremental updating approximations in multigranulation rough set under two-dimensional variation	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Multigranulation rough set; Approximation; Matrix; Incremental; Two-dimensional variation		Multigranulation rough set model (MGRS) uses multiple equivalence relations on the universe to calculate the approximations, which can solve problem in mutigranulation spaces. In practical applications, information systems often dynamically update due to the variation of objects, attributes or attribute values. Incremental approach is an effective method to calculate approximations for dynamically updated information system. However, existing incremental updating approximations in MGRS mainly focus on single-dimensional variation of objects, attributes or attribute values respectively, without considering multi-dimensional variation of objects, attributes and attribute values. In this paper, we propose matrix-based incremental updating approximations in multigranulation rough set under two-dimensional variation of objects, attributes and attribute values. One is the simultaneous variation of objects and attributes (VOA). The other is the simultaneous variation of objects and attribute values (VOV). First, we give the incremental approaches to update the relevant matrices for the dynamically updated information system due to VOA and VOV. Second, based on the updated matrices, we propose two matrix-based incremental algorithms to update approximations. Finally, examples and experimental results demonstrate the effectiveness of the proposed algorithms for incremental updating approximations in multigranulation rough set under two-dimensional variation.																	1868-8071	1868-808X															10.1007/s13042-020-01219-y		OCT 2020											
