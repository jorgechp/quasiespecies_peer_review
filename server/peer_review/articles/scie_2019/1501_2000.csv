PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J								Major-Minor Long Short-Term Memory for Word-Level Language Model	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Feature extraction; Semantics; Correlation; Natural language processing; Data models; Task analysis; Training; Language model (LM); long short-term memory (LSTM); natural language processing (NLP); shortcut connections		Language model (LM) plays an important role in natural language processing (NLP) systems, such as machine translation, speech recognition, learning token embeddings, natural language generation, and text classification. Recently, the multilayer long short-term memory (LSTM) models have been demonstrated to achieve promising performance on word-level language modeling. For each LSTM layer, larger hidden size usually means more diverse semantic features, which enables the LM to perform better. However, we have observed that when a certain LSTM layer reaches a sufficiently large scale, the promotion of overall effect will slow down, as its hidden size increases. In this article, we analyze that an important factor leading to this phenomenon is the high correlation between the newly extended hidden states and the original hidden states, which hinders diverse feature expression of the LSTM. As a result, when the scale is large enough, simply lengthening the LSTM hidden states will cost tremendous extra parameters but has little effect. We propose a simple yet effective improvement on each LSTM layer consisting of a large-scale Major LSTM and a small-scale Minor LSTM to break the high correlation between the two parts of hidden states, which we call Major-Minor LSTMs (MMLSTMs). In experiments, we demonstrate the LM with MMLSTMs surpasses the existing state-of-the-art model on Penn Treebank (PTB) and WikiText-2 (WT2) data sets and outperforms the baseline by 3.3 points in perplexity on WikiText-103 data set without increasing model parameter counts.																	2162-237X	2162-2388				OCT	2020	31	10					3932	3946		10.1109/TNNLS.2019.2947563													
J								Online Topology Learning by a Gaussian Membership-Based Self-Organizing Incremental Neural Network	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neural networks; Topology; Network topology; Approximation algorithms; Prediction algorithms; Learning systems; Data mining; Data streams; Gaussian membership; incremental learning; neural network; topology learning	VECTOR QUANTIZATION; ALGORITHM; POWER	In order to extract useful information from data streams, incremental learning has been introduced in more and more data mining algorithms. For instance, a self-organizing incremental neural network (SOINN) has been proposed to extract a topological structure that consists of one or more neural networks to closely reflect the data distribution of data streams. However, SOINN has the tradeoff between deleting previously learned nodes and inserting new nodes, i.e., the stability-plasticity dilemma. Therefore, it is not guaranteed that the topological structure obtained by the SOINN will closely represent data distribution. For solving the stability-plasticity dilemma, we propose a Gaussian membership-based SOINN (Gm-SOINN). Unlike other SOINN-based methods that allow only one node to be identified as a "winner" (the nearest node), the Gm-SOINN uses a Gaussian membership to indicate to which degree the node is a winner. Hence, the Gm-SOINN avoids the topological structure that cannot represent the data distribution because previously learned nodes overly deleted or noisy nodes inserted. In addition, an evolving Gaussian mixture model is integrated into the Gm-SOINN to estimate the density distribution of nodes, thereby avoiding the wrong connection between two nodes. Experiments involving both artificial and real-world data sets indicate that our proposed Gm-SOINN achieves better performance than other topology learning methods.																	2162-237X	2162-2388				OCT	2020	31	10					3947	3961		10.1109/TNNLS.2019.2947658													
J								Sample Balancing for Deep Learning-Based Visual Recognition	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Training; Visualization; Semantics; Deep learning; Measurement; Task analysis; Image recognition; Deep learning; image classification; sample reweighting; sample selection; self-paced learning	ALGORITHMS; FEATURES; OUTLIERS	Sample balancing includes sample selection and sample reweighting. Sample selection aims to remove some bad samples that may lead to bad local optima. Sample reweighting aims to assign optimal weights to samples to improve performance. In this article, we integrate a sample selection method based on self-paced learning into deep learning frameworks and study the influence of different sample selection strategies on training deep networks. In addition, most of the existing sample reweighting methods mainly take per-class sample number as a metric, which does not fully consider sample qualities. To improve the performance, we propose a novel metric based on the multiview semantic encoders to reweight the samples more appropriately. Then, we propose an optimization mechanism to embed sample weights into loss functions of deep networks, which can be trained in end-to-end manners. We conduct experiments on the CIFAR data set and the ImageNet data set. The experimental results demonstrate that our proposed sample balancing method can improve the performances of deep learning methods in several visual recognition tasks.																	2162-237X	2162-2388				OCT	2020	31	10					3962	3976		10.1109/TNNLS.2019.2947789													
J								GrAMME: Semisupervised Learning Using Multilayered Graph Attention Models	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Data models; Task analysis; Semisupervised learning; Computer architecture; Deep learning; Benchmark testing; Attention; deep learning; multilayered graphs; network embeddings; semisupervised learning	COMMUNITY DETECTION	Modern data analysis pipelines are becoming increasingly complex due to the presence of multiview information sources. While graphs are effective in modeling complex relationships, in many scenarios, a single graph is rarely sufficient to succinctly represent all interactions, and hence, multilayered graphs have become popular. Though this leads to richer representations, extending solutions from the single-graph case is not straightforward. Consequently, there is a strong need for novel solutions to solve classical problems, such as node classification, in the multilayered case. In this article, we consider the problem of semisupervised learning with multilayered graphs. Though deep network embeddings, e.g., DeepWalk, are widely adopted for community discovery, we argue that feature learning with random node attributes, using graph neural networks, can be more effective. To this end, we propose to use attention models for effective feature learning and develop two novel architectures, GrAMME-SG and GrAMME-Fusion, that exploit the interlayer dependences for building multilayered graph embeddings. Using empirical studies on several benchmark data sets, we evaluate the proposed approaches and demonstrate significant performance improvements in comparison with the state-of-the-art network embedding strategies. The results also show that using simple random features is an effective choice, even in cases where explicit node attributes are not available.																	2162-237X	2162-2388				OCT	2020	31	10					3977	3988		10.1109/TNNLS.2019.2948797													
J								Property-Constrained Dual Learning for Video Summarization	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Generators; Task analysis; Recurrent neural networks; Machine learning; Training; Semantics; Learning systems; Dual learning; property model; recurrent neural network (RNN); video summarization	ALGORITHMS	Video summarization is the technique to condense large-scale videos into summaries composed of key-frames or key-shots so that the viewers can browse the video content efficiently. Recently, supervised approaches have achieved great success by taking advantages of recurrent neural networks (RNNs). Most of them focus on generating summaries by maximizing the overlap between the generated summary and the ground truth. However, they neglect the most critical principle, i.e., whether the viewer can infer the original video content from the summary. As a result, existing approaches cannot preserve the summary quality well and usually demand large amounts of training data to reduce overfitting. In our view, video summarization has two tasks, i.e., generating summaries from videos and inferring the original content from summaries. Motivated by this, we propose a dual learning framework by integrating the summary generation (primal task) and video reconstruction (dual task) together, which targets to reward the summary generator under the assistance of the video reconstructor. Moreover, to provide more guidance to the summary generator, two property models are developed to measure the representativeness and diversity of the generated summary. Practically, experiments on four popular data sets (SumMe, TVsum, OVP, and YouTube) have demonstrated that our approach, with compact RNNs as the summary generator, using less training data, and even in the unsupervised setting, can get comparable performance with those supervised ones adopting more complex summary generators and trained on more annotated data.																	2162-237X	2162-2388				OCT	2020	31	10					3989	4000		10.1109/TNNLS.2019.2951680													
J								Model-Based Event-Triggered Tracking Control of Underactuated Surface Vessels With Minimum Learning Parameters	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adaptation models; Computational modeling; Artificial neural networks; Navigation; Complexity theory; Uncertainty; Explosions; Adaptive neural control; dynamic surface control (DSC); minimum learning parameters (MLPs); model-based event-triggered control (ETC); underactuated surface vessel (USV)	PATH-FOLLOWING CONTROL; NONLINEAR-SYSTEMS; GLOBAL TRACKING; SHIPS; STABILIZATION; COMPENSATION; VEHICLES	This article studies the model-based event-triggered control (ETC) for the tracking activity of the underactuated surface vessel (USV). Following this ideology, the continuous acquisition of states is no longer needed, and the communication traffic is reduced in the channel of sensor to controller. The control laws are fabricated in the frame of an adaptive model, which is renewed with the states of the original system whenever the triggering condition is violated. In the scheme, both internal and external uncertainties are approximated by the neural networks (NNs). To decrease the computing complexity, the minimum learning parameters (MLPs) are involved both in the adaptive model and the derived controller. The adaptive laws of only two MLPs are devised, and their updating only happens at triggering instants. Using the MLPs, an adaptive triggering condition is further derived. To avoid the "Zeno" phenomenon in small tracking errors, a dead-zone operator is designed for the triggering condition. Furthermore, we incorporate the dynamic surface control (DSC) into the controller design, such that the jumping of virtual control laws at triggering instants is smoothed and the problem of "complexity explosion" is circumvented. Through the techniques of the impulsive dynamic system and the direct Lyapunov function, the parameter setting for the DSC is derived to guarantee the semiglobal uniformly ultimate boundedness (SGUUB) of all the error signals in the closed-loop system. Finally, the effectiveness of the proposed scheme is validated through the simulation.																	2162-237X	2162-2388				OCT	2020	31	10					4001	4014		10.1109/TNNLS.2019.2951709													
J								Neural-Network-Based Adaptive Event-triggered Control for Spacecraft Attitude Tracking	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Space vehicles; Attitude control; Artificial neural networks; Quaternions; Adaptive systems; Quantization (signal); Uncertainty; Adaptive control; attitude control; event-triggered control (ETC); neural networks (NNs); spacecraft	NONLINEAR-SYSTEMS; STABILIZATION	The problem of attitude tracking control for spacecraft with limited communication rate is addressed in this article. To reduce the communication burden, an adaptive event-triggered control scheme is proposed. In the control scheme, only the sampling states at the event-triggering instants are sent to the control module, which can considerably decrease the data transmission rate. To address the inertia uncertainties and external disturbances, a radial basis function neural network (NN) is introduced. The bound of the uncertainties and disturbances is estimated for the proposed control scheme, which can simplify the NN and reduce the computation. Since the event-triggered error signal is discontinuous due to the event-triggered mechanism, the closed-loop system is formulated as an impulsive dynamical system to obtain the stability properties of the system. Finally, simulation results are given to demonstrate the effectiveness of the proposed control scheme.																	2162-237X	2162-2388				OCT	2020	31	10					4015	4024		10.1109/TNNLS.2019.2951732													
J								Convergence Analysis of Saturated Iterative Learning Control Systems With Locally Lipschitz Nonlinearities	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convergence; Trajectory; Heuristic algorithms; Iterative learning control; Nonlinear dynamical systems; Composite energy function (CEF); input saturation; iterative learning control (ILC); locally Lipschitz nonlinearity; robustness; system relative degree	TRAJECTORY TRACKING; FRAMEWORK; NETWORKS	In this article, the robust trajectory tracking problem of iterative learning control (ILC) for uncertain nonlinear systems is considered, and the effects from locally Lipschitz nonlinearities, input saturations, and nonzero system relative degrees are treated. A saturated ILC algorithm is given, with the convergence analysis exploited using a composite energy function-based approach. It is shown that the tracking error can be guaranteed to converge both pointwisely and uniformly. Furthermore, the input updating signal can be ensured to eventually satisfy the input saturation requirements with increasing iterations. Two examples are given to demonstrate the validity of saturated ILC for systems with the relative degree of one, input saturation, and locally Lipschitz nonlinearity.																	2162-237X	2162-2388				OCT	2020	31	10					4025	4035		10.1109/TNNLS.2019.2951752													
J								Realizing Data Features by Deep Nets	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neural networks; Machine learning; Manifolds; Computer vision; Sparse matrices; Learning systems; Approximation rates; covering numbers; data feature; deep neural networks (deep nets); neural networks	NEURAL-NETWORKS; SMOOTH FUNCTIONS; LOWER BOUNDS; APPROXIMATION; SHALLOW; REPRESENTATION; POLYNOMIALS; LIMITATIONS; COMPLEXITY; MANIFOLDS	This article considers the power of deep neural networks (deep nets) in realizing data features. Based on refined covering number estimates, we find that, to realize data features such as the locality, rotation invariance, and manifold structure, deep nets essentially improve the performances of shallow neural networks (shallow nets) without requiring additional capacity costs. Conversely, to realize some data features, such as the smoothness, we show that deep nets perform similar as shallow nets, provided the depth is not extremely large. Both sides show the advantages and limitations of deep nets in realizing data features and demonstrate that deep nets are not always better than shallow nets.																	2162-237X	2162-2388				OCT	2020	31	10					4036	4048		10.1109/TNNLS.2019.2951788													
J								A Network Framework for Small-Sample Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neural networks; Training; Training data; Task analysis; Data models; Deep learning; Semisupervised learning; Expression learning network; generative network; restricted Boltzmann machine (RBM); small-sample learning	ALGORITHMS	Small-sample learning involves training a neural network on a small-sample data set. An expansion of the training set is a common way to improve the performance of neural networks in small-sample learning tasks. However, improper constraints in expanding training data will reduce the performance of the neural networks. In this article, we present certain conditions for incorporation of additional training data. According to these conditions, we propose a neural network framework for self-training using self-generated data called small-sample learning network (SSLN). The SSLN consists of two parts: the expression learning network and the sample recall generative network, both of which are constructed based on restricted Boltzmann machine (RBM). We show that this SSLN can converge as well as the RBM. Moreover, the experiment results on MNIST Digit, SVHN, CIFAR10, and STL-10 data sets reveal the superiority of the SSLN over other models.																	2162-237X	2162-2388				OCT	2020	31	10					4049	4062		10.1109/TNNLS.2019.2951803													
J								Quasi-Synchronization and Bifurcation Results on Fractional-Order Quaternion-Valued Neural Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Artificial neural networks; Bifurcation; Quaternions; Delay effects; Synchronization; Hopf bifurcation; hub structure; quasi-synchronization; quaternion-valued neural networks (QVNNs); time delay	DISSIPATIVITY ANALYSIS; STABILITY; STABILIZATION; SYSTEMS	In this article, the quasi-synchronization and Hopf bifurcation issues are investigated for the fractional-order quaternion-valued neural networks (QVNNs) with time delay in the presence of parameter mismatches. On the basis of noncommutativity property of quaternion multiplication results, the quaternion network has been split as four real-valued networks. A synchronization theorem for fractional-order QVNNs is derived by employing suitable Lyapunov functional candidate; furthermore, the bifurcation behavior of the hub-structured fractional-order QVNNs with time delay has been investigated. Finally, two numerical examples are provided to demonstrate the effectiveness of the theoretical results.																	2162-237X	2162-2388				OCT	2020	31	10					4063	4072		10.1109/TNNLS.2019.2951846													
J								Information Losses in Neural Classifiers From Sampling	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neural networks; Machine learning; Training; Random variables; Training data; Probability distribution; Learning systems; Deep learning; information theory; large deviations theory; mutual information; statistical learning theory		This article considers the subject of information losses arising from the finite data sets used in the training of neural classifiers. It proves a relationship between such losses as the product of the expected total variation of the estimated neural model with the information about the feature space contained in the hidden representation of that model. It then bounds this expected total variation as a function of the size of randomly sampled data sets in a fairly general setting, and without bringing in any additional dependence on model complexity. It ultimately obtains bounds on information losses that are less sensitive to input compression and in general much smaller than existing bounds. This article then uses these bounds to explain some recent experimental findings of information compression in neural networks that cannot be explained by previous work. Finally, this article shows that not only are these bounds much smaller than existing ones, but they also correspond well with experiments.																	2162-237X	2162-2388				OCT	2020	31	10					4073	4083		10.1109/TNNLS.2019.2952029													
J								Adaptive Neural Output-Feedback Controller Design of Switched Nonlower Triangular Nonlinear Systems With Time Delays	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Switches; Adaptive systems; Nonlinear systems; Delay effects; Backstepping; Stability analysis; Adaptive control; average dwell time (ADT); neural networks (NNs); nonlower triangular form; switched nonlinear systems; time delays	H-INFINITY CONTROL; FUZZY CONTROL; STABILIZATION; STABILITY; TRACKING	In this article, we study the issue of adaptive neural output-feedback controller design for a class of uncertain switched time-delay nonlinear systems with nonlower triangular structure. The prominent contribution of this article is that the delay-dependent stability criterion of nonswitched nonlinear systems is successfully extended to that of switched nonlower triangular nonlinear systems. The design algorithm is listed as follows. First, a switched state observer is designed such that the error dynamic system can be generated. Second, neural networks, adaptive backstepping technique, and variable separation method are, respectively, applied to construct a common controller for all subsystems, in which the Lyapunov-Krasovskii functionals are deliberately constructed such that the average dwell-time scheme can be employed to guarantee the stability and performance of the closed-loop system, despite the existence of time delays. Third, the stability analysis process confirms in detail that all the variables of the closed-loop system are semiglobally uniformly ultimately bounded. Finally, simulation study is given to show the validity of the proposed control approach.																	2162-237X	2162-2388				OCT	2020	31	10					4084	4093		10.1109/TNNLS.2019.2952108													
J								An Active Repetitive Learning Control Method for Lateral Suspension Systems of High-Speed Trains	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Vibrations; Suspensions (mechanical systems); Vehicle dynamics; Aerodynamics; Actuators; Active suspension; high-speed trains (HSTs); lateral vibration; periodicity; repetitive learning control (RLC)	H-INFINITY CONTROL; VEHICLES	This article presents a novel perspective to improve the ride quality of high-speed trains (HSTs), namely, by virtue of the periodicity of lateral dynamics to suppress the lateral vibration of HST. To resolve the contradiction between the complex HST model and the effective controller design, a simplified three-degrees-of-freedom (3-DOF) quarter-vehicle model is first employed for controller design, while a 17-DOF full-vehicle model is built for efficiency verification, where periodic and random track irregularities are considered, respectively. An active repetitive learning control (RLC) method is proposed to achieve the periodic tracking control, where the learning convergence is proved rigorously in a Lyapunov way. The configuration of RLC-based lateral suspensions is economical in the sense that only four actuators and six sensors are needed. It is verified by simulation that, compared with the dynamic matrix controller, the proposed RLC controller has greatly reduced the lateral vibration of a vehicle body, especially the lateral acceleration in the frequency range of (0, 3] Hz to which human body is strongly sensitive.																	2162-237X	2162-2388				OCT	2020	31	10					4094	4103		10.1109/TNNLS.2019.2952175													
J								Event-Triggered Exponential Synchronization for Complex-Valued Memristive Neural Networks With Time-Varying Delays	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Synchronization; Delays; Biological neural networks; Memristors; Information exchange; Asymptotic stability; Complex-valued memristive neural networks; event-triggered mechanism; exponential synchronization; Zeno behavior	STABILIZATION; STABILITY; CONSENSUS; SYSTEMS	This article solves the event-triggered exponential synchronization problem for a class of complex-valued memristive neural networks with time-varying delays. The drive-response complex-valued memristive neural networks are translated into two real-valued memristive neural networks through the method of separating the complex-valued memristive neural networks into real and imaginary parts. In order to reduce the information exchange frequency between the sensor and the controller, a novel event-triggered mechanism with the event-triggering functions is introduced in wireless communication networks. Some sufficient conditions are established to achieve the event-triggered exponential synchronization for drive-response complex-valued memristive neural networks with time-varying delays. In addition, to guarantee that the Zeno behavior cannot occur, a positive lower bound for the interevent times is explicitly derived. Finally, numerical simulations are provided to illustrate the effectiveness and superiority of the obtained theoretical results.																	2162-237X	2162-2388				OCT	2020	31	10					4104	4116		10.1109/TNNLS.2019.2952186													
J								Conditional Generative Denoising Autoencoder	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Noise reduction; Supervised learning; Training; Unsupervised learning; Decoding; Data models; Markov processes; Artificial neural networks; image denoising; image sampling; multilayer perceptron; unsupervised learning	LANGEVIN	We present a generative denoising autoencoder model that has an embedded data classifier in its architecture in order to take advantage of class-based discriminating features and produce better data samples. The proposed model is a conditional generative model and is sampled with a Markov chain Monte Carlo (MCMC) process according to a label that denotes the desired (or undesired) class or classes. In this sense, any chosen predefined class or characteristic may have a positive or negative effect on the image generation process, meaning that it can be instructed to be present or absent from the generated sample. We argue that allowing discriminative information in the form of feature detectors to be present in the latent representation of the autoencoder can be generally beneficial. This technique is an alternative approach to variational autoencoders (VAEs) that enforce a prior on the latent distribution. We further claim that supervised learning may be generally able to serve unsupervised learning through an interaction between the two paradigms. However, the extreme majority of research done on the interaction of the two learning regimes has the goal of using unsupervised learning to improve supervised learning. In this article, we explore the two learning paradigms' interaction in the opposite direction.																	2162-237X	2162-2388				OCT	2020	31	10					4117	4129		10.1109/TNNLS.2019.2952203													
J								Mixed H-2/H-infinity State Estimation for Discrete-Time Switched Complex Networks With Random Coupling Strengths Through Redundant Channels	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Complex networks; mixed H-2/H-infinity performance; random coupling strengths; redundant channels; state estimation; stochastic stability with probability 1	DYNAMICAL NETWORKS; SENSOR NETWORKS; GLOBAL SYNCHRONIZATION; ROBUST SYNCHRONIZATION; NEURAL-NETWORKS; SYSTEMS	This article investigates the mixed H-2/H-infinity state estimation problem for a class of discrete-time switched complex networks with random coupling strengths through redundant communication channels. A sequence of random variables satisfying certain probability distributions is employed to describe the stochasticity of the coupling strengths. A redundant-channel-based data transmission mechanism is adopted to enhance the reliability of the transmission channel from the sensor to the estimator. The purpose of the addressed problem is to design a state estimator for each node, such that the error dynamics achieves both the stochastic stability (with probability 1) and the prespecified mixed H-2/H-infinity performance requirement. By using the switched system theory, an extensive stochastic analysis is carried out to derive the sufficient conditions ensuring the stochastic stability as well as the mixed H-2/H-infinity performance index. The desired state estimator is also parameterized by resorting to the solutions to certain convex optimization problems. A numerical example is provided to illustrate the validity of the proposed estimation scheme.																	2162-237X	2162-2388				OCT	2020	31	10					4130	4142		10.1109/TNNLS.2019.2952249													
J								CHIP: Channel-Wise Disentangled Interpretation of Deep Convolutional Neural Networks	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Visualization; Logic gates; Predictive models; Data models; Knowledge engineering; Task analysis; Perturbation methods; Channel-wise disentanglement; model interpretability; network perturbation; visual interpretation		With the increasing popularity of deep convolutional neural networks (DCNNs), in addition to achieving high accuracy, it becomes increasingly important to explain how DCNNs make their decisions. In this article, we propose a CHannel-wise disentangled InterPretation (CHIP) model for visual interpretations of DCNN predictions. The proposed model distills the class-discriminative importance of channels in DCNN by utilizing sparse regularization. We first introduce network perturbation to learn the CHIP model. The proposed model is capable to not only distill the global perspective knowledge from networks but also present class-discriminative visual interpretations for the predictions of networks. It is noteworthy that the CHIP model is able to interpret different layers of networks without retraining. By combining the distilled interpretation knowledge at different layers, we further propose the Refined CHIP visual interpretation that is both high-resolution and class-discriminative. Based on qualitative and quantitative experiments on different data sets and networks, the proposed model provides promising visual interpretations for network predictions in an image classification task compared with the existing visual interpretation methods. The proposed model also outperforms the related approaches in the ILSVRC 2015 weakly supervised localization task.																	2162-237X	2162-2388				OCT	2020	31	10					4143	4156		10.1109/TNNLS.2019.2952322													
J								Relaxed Stability Criteria for Neural Networks With Time-Varying Delay Using Extended Secondary Delay Partitioning and Equivalent Reciprocal Convex Combination Techniques	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Delays; Asymptotic stability; Artificial neural networks; Linear matrix inequalities; Stability criteria; Automation; Equivalent reciprocal convex combination; extended secondary delay partitioning; global asymptotic stability; neural networks (NNs); time-varying delay	GLOBAL ASYMPTOTIC STABILITY; SYSTEMS; SYNCHRONIZATION	This article investigates global asymptotic stability for neural networks (NNs) with time-varying delay, which is differentiable and uniformly bounded, and the delay derivative exists and is upper-bounded. First, we propose the extended secondary delay partitioning technique to construct the novel Lyapunov-Krasovskii functional, where both single-integral and double-integral state variables are considered, while the single-integral ones are only solved by the traditional secondary delay partitioning. Second, a novel free-weight matrix equality (FWME) is presented to resolve the reciprocal convex combination problem equivalently and directly without Schur complement, which eliminates the need of positive definite matrices, and is less conservative and restrictive compared with various improved reciprocal convex inequalities. Furthermore, by the present extended secondary delay partitioning, equivalent reciprocal convex combination technique, and Bessel-Legendre inequality, two different relaxed sufficient conditions ensuring global asymptotic stability for NNs are obtained, for time-varying delays, respectively, with unknown and known lower bounds of the delay derivative. Finally, two examples are given to illustrate the superiority and effectiveness of the presented method.																	2162-237X	2162-2388				OCT	2020	31	10					4157	4169		10.1109/TNNLS.2019.2952410													
J								Accurate Tensor Completion via Adaptive Low-Rank Representation	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Tensors; Adaptation models; Data models; Bayes methods; Learning systems; Computer science; Australia; Adaptive low-rank representation; automatic tensor rank determination; tensor completion	SPARSITY; FACTORIZATION	Low-rank representation-based approaches that assume low-rank tensors and exploit their low-rank structure with appropriate prior models have underpinned much of the recent progress in tensor completion. However, real tensor data only approximately comply with the low-rank requirement in most cases, viz., the tensor consists of low-rank (e.g., principle part) as well as non-low-rank (e.g., details) structures, which limit the completion accuracy of these approaches. To address this problem, we propose an adaptive low-rank representation model for tensor completion that represents low-rank and non-low-rank structures of a latent tensor separately in a Bayesian framework. Specifically, we reformulate the CANDECOMP/PARAFAC (CP) tensor rank and develop a sparsity-induced prior for the low-rank structure that can be used to determine tensor rank automatically. Then, the non-low-rank structure is modeled using a mixture of Gaussians prior that is shown to be sufficiently flexible and powerful to inform the completion process for a variety of real tensor data. With these two priors, we develop a Bayesian minimum mean-squared error estimate framework for inference. The developed framework can capture the important distinctions between low-rank and non-low-rank structures, thereby enabling more accurate model, and ultimately, completion. For various applications, compared with the state-of-the-art methods, the proposed model yields more accurate completion results.																	2162-237X	2162-2388				OCT	2020	31	10					4170	4184		10.1109/TNNLS.2019.2952427													
J								Leader-Follower Bipartite Output Synchronization on Signed Digraphs Under Adversarial Factors via Data-Based Reinforcement Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Adversarial inputs; bipartite output synchronization; heterogeneous multiagent systems (MASs); reinforcement learning (RL); resilient H-infinity controller; signed digraphs	MULTIAGENT SYSTEMS; CONTAINMENT CONTROL; FEEDBACK CONTROL; CONSENSUS	The optimal solution to the leader-follower bipartite output synchronization problem is proposed for heterogeneous multiagent systems (MASs) over signed digraphs in the presence of adversarial inputs in this article. For the MASs, the dynamics and dimensions of the followers are different. Distributed observers are first designed to estimate the leader's two-way state and output over signed digraphs. Then, the leader-follower bipartite output synchronization problem on signed graphs is translated into a conventional output distributed leader-follower problem over nonnegative graphs after the state transformation by using the information of followers and observers. The effect of adversarial inputs in sensors or actuators of agents is mitigated by designing the resilient H-infinity controller. A data-based reinforcement learning (RL) algorithm is proposed to obtain the optimal control law, which implies that the dynamics of the followers is not required. Finally, a simulation example is given to verify the effectiveness of the proposed algorithm.																	2162-237X	2162-2388				OCT	2020	31	10					4185	4195		10.1109/TNNLS.2019.2952611													
J								Event-Triggered Adaptive Neural Network Control for Nonstrict-Feedback Nonlinear Time-Delay Systems With Unknown Control Directions	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Delays; Adaptive systems; Nonlinear systems; Backstepping; Artificial neural networks; Ear; Event-triggered; input delay; neural network; nonstrict feedback; unknown control directions	TRACKING CONTROL; VARYING INPUT; COMPENSATION; STABILITY; STATE	In this article, the event-triggered-based adaptive neural network control problem is studied for a class of nonlinear time-delay systems with nonstrict-feedback structures and unknown control directions. First, a compensation system is introduced to handle the input delay and an observer is also designed to estimate the unmeasurable states. Then, by employing the neural networks and the variable separation approach, the adaptive backstepping method is applied to control the nonlinear systems with nonstrict-feedback structures. By codesigning the adaptive controller and the triggering mechanism, the input-to-state stability (ISS) assumption with respect to the measurement error is removed. Finally, it is shown that the proposed event-triggered adaptive controller can ensure the semiglobal boundedness of all the states in the closed-loop systems.																	2162-237X	2162-2388				OCT	2020	31	10					4196	4205		10.1109/TNNLS.2019.2952709													
J								A Model for R(t) Elements and R(t)-Based Spike-Timing-Dependent Plasticity With Basic Circuit Examples	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Resistance; Synapses; Memristors; Neurons; Integrated circuit modeling; Action potentials; Time-varying systems; Memristor; spike-timing-dependent plasticity (STDP); spiking neural network; synapse	MEMRISTOR DEVICE; SPICE MODEL; NETWORK; NEURONS; SYNAPSE; POTENTIATION; COINCIDENCE; NUMBER	Spike-timing-dependent plasticity (STDP) is a fundamental synaptic learning rule observed in biology that leads to numerous behavioral and cognitive outcomes. Emulating STDP in electronic spiking neural networks with high-density memristive synapses is, therefore, of significant interest. While one popular method involves pulse-shaping the spiking neuron output voltages, an alternative approach is outlined in this article. The proposed STDP implementation uses time-varying dynamic resistance [R(t)] elements to achieve local synaptic learning from spike-pair STDP, spike triplet STDP, and firing rates. The R(t) elements are connected to each neuron circuit, thereby maintaining synaptic density and leveraging voltage division as a means of altering synaptic weight (memristor voltage). Example R(t) elements with their corresponding behaviors are demonstrated through simulation. A three-input-two-output network using single-memristor synaptic connections and R(t) elements is also simulated. Network-level effects, such as nonspecific synaptic plasticity, are discussed. Finally, spatiotemporal pattern recognition (STPR) using R(t) elements is demonstrated in simulation.																	2162-237X	2162-2388				OCT	2020	31	10					4206	4216		10.1109/TNNLS.2019.2952768													
J								An Adaptive Deep Belief Network With Sparse Restricted Boltzmann Machines	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Neurons; Adaptation models; Adaptive learning; Training; Robustness; Convergence; Modeling; Adaptive-sparse restricted Boltzmann machine (RBM); convergence analysis; deep belief network (DBN); partial least square (PLS)-based regression fine-tuning; robust structure	FEEDFORWARD NEURAL-NETWORKS; LEARNING ALGORITHM; CLASSIFICATION; IDENTIFICATION; REPRESENTATION	Deep belief network (DBN) is an efficient learning model for unknown data representation, especially nonlinear systems. However, it is extremely hard to design a satisfactory DBN with a robust structure because of traditional dense representation. In addition, backpropagation algorithm-based fine-tuning tends to yield poor performance since its ease of being trapped into local optima. In this article, we propose a novel DBN model based on adaptive sparse restricted Boltzmann machines (AS-RBM) and partial least square (PLS) regression fine-tuning, abbreviated as ARP-DBN, to obtain a more robust and accurate model than the existing ones. First, the adaptive learning step size is designed to accelerate an RBM training process, and two regularization terms are introduced into such a process to realize sparse representation. Second, initial weight derived from AS-RBM is further optimized via layer-by-layer PLS modeling starting from the output layer to input one. Third, we present the convergence and stability analysis of the proposed method. Finally, our approach is tested on Mackey-Glass time-series prediction, 2-D function approximation, and unknown system identification. Simulation results demonstrate that it has higher learning accuracy and faster learning speed. It can be used to build a more robust model than the existing ones.																	2162-237X	2162-2388				OCT	2020	31	10					4217	4228		10.1109/TNNLS.2019.2952864													
J								Communication-Efficient Federated Deep Learning With Layerwise Asynchronous Model Update and Temporally Weighted Aggregation	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Servers; Data models; Training; Data privacy; Distributed databases; Deep learning; Sun; Aggregation; asynchronous learning; deep neural network (DNN); federated learning; temporally weighted aggregation		Federated learning obtains a central model on the server by aggregating models trained locally on clients. As a result, federated learning does not require clients to upload their data to the server, thereby preserving the data privacy of the clients. One challenge in federated learning is to reduce the client-server communication since the end devices typically have very limited communication bandwidth. This article presents an enhanced federated learning technique by proposing an asynchronous learning strategy on the clients and a temporally weighted aggregation of the local models on the server. In the asynchronous learning strategy, different layers of the deep neural networks (DNNs) are categorized into shallow and deep layers, and the parameters of the deep layers are updated less frequently than those of the shallow layers. Furthermore, a temporally weighted aggregation strategy is introduced on the server to make use of the previously trained local models, thereby enhancing the accuracy and convergence of the central model. The proposed algorithm is empirically on two data sets with different DNNs. Our results demonstrate that the proposed asynchronous federated deep learning outperforms the baseline algorithm both in terms of communication cost and model accuracy.																	2162-237X	2162-2388				OCT	2020	31	10					4229	4238		10.1109/TNNLS.2019.2953131													
J								The Cubic Dynamic Uncertain Causality Graph: A Methodology for Temporal Process Modeling and Diagnostic Logic Inference	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Cognition; Hidden Markov models; Fault diagnosis; Inference algorithms; Computational modeling; Data models; Complex systems; Dynamic negative feedback loop; dynamics and uncertainties; fault diagnosis; probabilistic reasoning; temporal causality modeling	ROOT CAUSE DIAGNOSIS; KNOWLEDGE REPRESENTATION; NETWORKS; STABILIZATION; OSCILLATIONS; SYSTEMS; EVENTS	To meet the demand for dynamic and highly reliable real-time fault diagnosis for complex systems, we extend the dynamic uncertain causality graph (DUCG) by proposing novel temporal causality modeling and reasoning methods. A new methodology, the Cubic DUCG, is therefore developed. It exploits an efficient scheme for compactly representing and accurately reasoning about the dynamic causalities in the system fault-spreading process. The Cubic DUCG is characterized by: 1) continuous generation of a causality graph that allows for causal connections penetrating among any number of time slices and discards the restrictive assumptions (about the underlying graph structure) upon which the existing research commonly relies; 2) a modeling scheme of complex causalities that includes dynamic negative feedback loops in a natural and intuitive manner; 3) a rigorous and reliable inference algorithm based on complete causalities that reflect real-time fault situations rather than on the cumulative aggregation of static time slices; and 4) some solutions to causality simplification and reduction, graphical transformation, and logical reasoning, for the sake of reducing the reasoning complexity. A series of fault diagnosis experiments on a nuclear power plant simulator verifies the accuracy, robustness, and efficiency of the proposed methodology.																	2162-237X	2162-2388				OCT	2020	31	10					4239	4253		10.1109/TNNLS.2019.2953177													
J								Decentralized Event-Triggered Adaptive Control of Discrete-Time Nonzero-Sum Games Over Wireless Sensor-Actuator Networks With Input Constraints	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Games; Sensors; Actuators; Wireless sensor networks; Wireless communication; Protocols; Optimal control; Adaptive dynamic programming (ADP); decentralized event-triggered control (DETC); interevent times; nonzero-sum (NZS) game; wireless sensor-actuator network (WSAN)	CONTROL-SYSTEMS	This article studies an event-triggered communication and adaptive dynamic programming (ADP) co-design control method for the multiplayer nonzero-sum (NZS) games of a class of nonlinear discrete-time wireless sensor-actuator network (WSAN) systems subject to input constraints. By virtue of the ADP algorithm, the critic and actor networks are established to attain the approximate Nash equilibrium point solution in the context of the constrained control mechanism. Simultaneously, as the sensors and actuators are physically distributed, a decentralized event-triggered communication protocol is presented, accompanied by a dead-zone operation which avoids the unnecessary events. By predefining the triggering thresholds and compensation values, a novel adaptive triggering condition is derived to guarantee the stability of the event-based closed-loop control system. Then resorting to the Lyapunov theory, the system states and the critic/actor network weight estimation errors are proven to be ultimately bounded. Moreover, an explicit analysis on the nontriviality of the interevent times is also provided. Finally, two numerical examples are conducted to validate the effectiveness of the proposed method.																	2162-237X	2162-2388				OCT	2020	31	10					4254	4266		10.1109/TNNLS.2019.2953613													
J								Continual Learning of Recurrent Neural Networks by Locally Aligning Distributed Representations	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Training; Predictive models; Computational modeling; Backpropagation; Computer architecture; Predictive coding; Brain modeling; Continual learning; generative models; learning algorithms; predictive coding; recurrent neural networks (RNNs)	BACKPROPAGATION; MODELS	Temporal models based on recurrent neural networks have proven to be quite powerful in a wide variety of applications, including language modeling and speech processing. However, training these models often relies on backpropagation through time (BPTT), which entails unfolding the network over many time steps, making the process of conducting credit assignment considerably more challenging. Furthermore, the nature of backpropagation itself does not permit the use of nondifferentiable activation functions and is inherently sequential, making parallelization of the underlying training process difficult. Here, we propose the parallel temporal neural coding network (P-TNCN), a biologically inspired model trained by the learning algorithm we call local representation alignment. It aims to resolve the difficulties and problems that plague recurrent networks trained by BPTT. The architecture requires neither unrolling in time nor the derivatives of its internal activation functions. We compare our model and learning procedure with other BPTT alternatives (which also tend to be computationally expensive), including real-time recurrent learning, echo state networks, and unbiased online recurrent optimization. We show that it outperforms these on-sequence modeling benchmarks such as Bouncing MNIST, a new benchmark we denote as Bouncing NotMNIST, and Penn Treebank. Notably, our approach can, in some instances, outperform full BPTT as well as variants such as sparse attentive backtracking. Significantly, the hidden unit correction phase of P-TNCN allows it to adapt to new data sets even if its synaptic weights are held fixed (zero-shot adaptation) and facilitates retention of prior generative knowledge when faced with a task sequence. We present results that show the P-TNCN's ability to conduct zero-shot adaptation and online continual sequence modeling.																	2162-237X	2162-2388				OCT	2020	31	10					4267	4278		10.1109/TNNLS.2019.2953622													
J								An Event-Triggering Approach to Recursive Filtering for Complex Networks With State Saturations and Random Coupling Strengths	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Couplings; Petroleum; Complex networks; Upper bound; Covariance matrices; State estimation; Neural networks; Complex networks (CNs); event-triggering; random coupling strengths; recursive filtering; state saturations	SENSOR NETWORKS; SYSTEMS; INFORMATION; DESIGN; DELAYS	In this article, the recursive filtering problem is investigated for a class of time-varying complex networks with state saturations and random coupling strengths under an event-triggering transmission mechanism. The coupled strengths among nodes are characterized by a set of random variables obeying the uniform distribution. The event-triggering scheme is employed to mitigate the network data transmission burden. The purpose of the problem addressed is to design a recursive filter such that in the presence of the state saturations, event-triggering communication mechanism, and random coupling strengths, certain locally optimized upper bound is guaranteed on the filtering error covariance. By using the stochastic analysis technique, an upper bound on the filtering error covariance is first derived via the solution to a set of matrix difference equations. Next, the obtained upper bound is minimized by properly parameterizing the filter parameters. Subsequently, the boundedness issue of the filtering error covariance is studied. Finally, two numerical simulation examples are provided to illustrate the effectiveness of the proposed algorithm.																	2162-237X	2162-2388				OCT	2020	31	10					4279	4289		10.1109/TNNLS.2019.2953649													
J								SRSC: Selective, Robust, and Supervised Constrained Feature Representation for Image Classification	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Training; Task analysis; Learning systems; Computational modeling; Optimization; Support vector machines; Principal component analysis; Feature learning; feature selection; least squares; subspace learning	LEAST-SQUARES REGRESSION; FACE RECOGNITION; DICTIONARY; ILLUMINATION; EIGENFACES	Feature representation learning, an emerging topic in recent years, has achieved great progress. Powerful learned features can lead to excellent classification accuracy. In this article, a selective and robust feature representation framework with a supervised constraint (SRSC) is presented. SRSC seeks a selective, robust, and discriminative subspace by transforming the original feature space into the category space. Particularly, we add a selective constraint to the transformation matrix (or classifier parameter) that can select discriminative dimensions of the input samples. Moreover, a supervised regularization is tailored to further enhance the discriminability of the subspace. To relax the hard zero-one label matrix in the category space, an additional error term is also incorporated into the framework, which can lead to a more robust transformation matrix. SRSC is formulated as a constrained least square learning (feature transforming) problem. For the SRSC problem, an inexact augmented Lagrange multiplier method (ALM) is utilized to solve it. Extensive experiments on several benchmark data sets adequately demonstrate the effectiveness and superiority of the proposed method. The proposed SRSC approach has achieved better performances than the compared counterpart methods.																	2162-237X	2162-2388				OCT	2020	31	10					4290	4302		10.1109/TNNLS.2019.2953675													
J								Discriminative Local Sparse Representation by Robust Adaptive Dictionary Pair Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Dictionaries; Encoding; Sun; Robustness; Computer science; Training; Learning systems; Image recognition; image representation; locality-adaptive discriminative sparse representation (SR); robust projective dictionary pair learning (DPL)	FACE RECOGNITION; LOW-RANK; K-SVD; IMAGE	In this article, we propose a structured robust adaptive dictionary pair learning (RA-DPL) framework for the discriminative sparse representation (SR) learning. To achieve powerful representation ability of the available samples, the setting of RA-DPL seamlessly integrates the robust projective DPL, locality-adaptive SRs, and discriminative coding coefficients learning into a unified learning framework. Specifically, RA-DPL improves existing projective DPL in four perspectives. First, it applies a sparse l(2,1)-norm-based metric to encode the reconstruction error to deliver the robust projective dictionary pairs, and the l(2,1)-norm has the potential to minimize the error. Second, it imposes the robust l(2,1)-norm clearly on the analysis dictionary to ensure the sparse property of the coding coefficients rather than using the costly l(0)/l(1)-norm. As such, the robustness of the data representation and the efficiency of the learning process are jointly considered to guarantee the efficacy of our RA-DPL. Third, RA-DPL conceives a structured reconstruction weight learning paradigm to preserve the local structures of the coding coefficients within each class clearly in an adaptive manner, which encourages to produce the locality preserving representations. Fourth, it also considers improving the discriminating ability of coding coefficients and dictionary by incorporating a discriminating function, which can ensure high intraclass compactness and interclass separation in the code space. Extensive experiments show that our RA-DPL can obtain superior performance over other state of the arts.																	2162-237X	2162-2388				OCT	2020	31	10					4303	4317		10.1109/TNNLS.2019.2954545													
J								Adaptive Hashing With Sparse Matrix Factorization	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Binary codes; Sparse matrices; Learning systems; Quantization (signal); Tuning; Adaptation models; Hash functions; Binary code; hashing; image retrieval; matrix factorization; sparse learning	ROBUST	Hashing offers a desirable and effective solution for efficiently retrieving the nearest neighbors from large-scale data because of its low storage and computation costs. One of the most appealing techniques for hashing learning is matrix factorization. However, most hashing methods focus only on building the mapping relationships between the Euclidean and Hamming spaces and, unfortunately, underestimate the naturally sparse structures of the data. In addition, parameter tuning is always a challenging and head-scratching problem for sparse hashing learning. To address these problems, in this article, we propose a novel hashing method termed adaptively sparse matrix factorization hashing (SMFH), which exploits sparse matrix factorization to explore the parsimonious structures of the data. Moreover, SMFH adopts an orthogonal transformation to minimize the quantization loss while deriving the binary codes. The most distinguished property of SMFH is that it is adaptive and parameter-free, that is, SMFH can automatically generate sparse representations and does not require human involvement to tune the regularization parameters for the sparse models. Empirical studies on four publicly available benchmark data sets show that the proposed method can achieve promising performance and is competitive with a variety of state-of-the-art hashing methods.																	2162-237X	2162-2388				OCT	2020	31	10					4318	4329		10.1109/TNNLS.2019.2954856													
J								Reinforcement Learning-Based Optimal Stabilization for Unknown Nonlinear Systems Subject to Inputs With Uncertain Constraints	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Nonlinear systems; Optimal control; Artificial neural networks; Actuators; Observers; Feedforward systems; Adaptive dynamic programming (ADP); neural networks (NNs); optimal control; reinforcement learning (RL); uncertain input constraints; unknown nonlinear systems	ZERO-SUM GAMES; DECENTRALIZED TRACKING CONTROL; ADAPTIVE OPTIMAL-CONTROL; FAULT-TOLERANT CONTROL; NEURAL-NETWORK CONTROL; DISCRETE-TIME-SYSTEMS; POLICY ITERATION; ALGORITHMS; CONTROLLER; EQUATION	This article presents a novel reinforcement learning strategy that addresses an optimal stabilizing problem for unknown nonlinear systems subject to uncertain input constraints. The control algorithm is composed of two parts, i.e., online learning optimal control for the nominal system and feedforward neural networks (NNs) compensation for handling uncertain input constraints, which are considered as the saturation nonlinearities. Integrating the input-output data and recurrent NN, a Luenberger observer is established to approximate the unknown system dynamics. For nominal systems without input constraints, the online learning optimal control policy is derived by solving Hamilton-Jacobi-Bellman equation via a critic NN alone. By transforming the uncertain input constraints to saturation nonlinearities, the uncertain input constraints can be compensated by employing a feedforward NN compensator. The convergence of the closed-loop system is guaranteed to be uniformly ultimately bounded by using the Lyapunov stability analysis. Finally, the effectiveness of the developed stabilization scheme is illustrated by simulation studies.																	2162-237X	2162-2388				OCT	2020	31	10					4330	4340		10.1109/TNNLS.2019.2954983													
J								Neural-Network-Based Adaptive Resilient Dynamic Surface Control Against Unknown Deception Attacks of Uncertain Nonlinear Time-Delay Cyberphysical Systems	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Control design; Adaptive systems; Actuators; Delays; Delay effects; Robot sensing systems; Adaptive resilient control; dynamic surface control; lower triangular nonlinear systems; unknown deception attacks; unknown time delays	CYBER-PHYSICAL SYSTEMS; TRACKING CONTROL; SENSOR; STABILIZATION; DESIGN	A neural-network-based dynamic surface design strategy against sensor and actuator deception attacks is presented to design a delay-independent adaptive resilient control scheme of uncertain nonlinear time-delay cyberphysical systems in the lower triangular form. It is assumed that all nonlinearities, time-varying delays, and sensor and actuator attacks are unknown. In the concerned problem, since the state information measured by sensors is compromised by additional attack signals, the exact state variables are not available for feedback. Thus, a memoryless adaptive resilient control design using compromised state variables is developed by employing the neural-network-based function approximation technique and designing the attack compensator. The resulting control scheme ensures the robust stabilization in the presence of unknown deception attacks and time-varying delays. It is shown from the Lyapunov stability analysis that all closed-loop signals are uniformly ultimately bounded and the stabilization errors converge to an adjustable neighborhood of the origin.																	2162-237X	2162-2388				OCT	2020	31	10					4341	4353		10.1109/TNNLS.2019.2955132													
J								A Deterministic Annealing Neural Network Algorithm for the Minimum Concave Cost Transportation Problem	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Transportation; Annealing; Optimization; Biological neural networks; Computational modeling; Linear programming; Annealing scheme; barrier function; combinatorial optimization; Lagrange multipliers; minimum concave cost transportation; neural network	QUADRATIC-PROGRAMMING PROBLEMS; FLOW	In this article, a deterministic annealing neural network algorithm is proposed to solve the minimum concave cost transportation problem. Specifically, the algorithm is derived from two neural network models and Lagrange-barrier functions. The Lagrange function is used to handle linear equality constraints, and the barrier function is used to force the solution to move to the global or near-global optimal solution. In both neural network models, two descent directions are constructed, and an iterative procedure for the optimization of the neural network is proposed. As a result, two corresponding Lyapunov functions are naturally obtained from these two descent directions. Furthermore, the proposed neural network models are proved to be completely stable and converge to the stable equilibrium state, therefore, the proposed algorithm converges. At last, the computer simulations on several test problems are made, and the results indicate that the proposed algorithm always generates global or near-global optimal solutions.																	2162-237X	2162-2388				OCT	2020	31	10					4354	4366		10.1109/TNNLS.2019.2955137													
J								Asynchronous Distributed Learning From Constraints	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Knowledge engineering; Distributed databases; Optimization; Task analysis; Learning systems; Bridges; Neural networks; Artificial neural networks; distributed algorithms; optimization; semisupervised learning		In this brief, the extension of the framework of Learning from Constraints (LfC) to a distributed setting where multiple parties, connected over the network, contribute to the learning process is studied. LfC relies on the generic notion of "constraint" to inject knowledge into the learning problem, and, due to its generality, it deals with possibly nonconvex constraints, enforced either in a hard or soft way. Motivated by recent progresses in the field of distributed and constrained nonconvex optimization, we apply the (distributed) asynchronous method of multipliers (ASYMM) to LfC. The study shows that such a method allows us to support scenarios where selected constraints (i.e., knowledge), data, and outcomes of the learning process can be locally stored in each computational node without being shared with the rest of the network, opening the road to further investigations into privacy-preserving LfC. Constraints act as a bridge between what is shared over the net and what is private to each node, and no central authority is required. We demonstrate the applicability of these ideas in two distributed real-world settings in the context of digit recognition and document classification.																	2162-237X	2162-2388				OCT	2020	31	10					4367	4373		10.1109/TNNLS.2019.2947740													
J								Qualitative Measurements of Policy Discrepancy for Return-Based Deep Q-Network	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Reinforcement learning; Learning systems; Trajectory; Task analysis; Research and development; Games; Neural networks; Deep Q-network (DQN); policy discrepancy; reinforcement learning; return-based algorithm		The deep Q-network (DQN) and return-based reinforcement learning are two promising algorithms proposed in recent years. The DQN brings advances to complex sequential decision problems, while return-based algorithms have advantages in making use of sample trajectories. In this brief, we propose a general framework to combine the DQN and most of the return-based reinforcement learning algorithms, named R-DQN. We show that the performance of the traditional DQN can be significantly improved by introducing return-based algorithms. In order to further improve the R-DQN, we design a strategy with two measurements to qualitatively measure the policy discrepancy. We conduct experiments on several representative tasks from the OpenAI Gym and Atari games. The state-of-the-art performance achieved by our method with this proposed strategy validates its effectiveness.																	2162-237X	2162-2388				OCT	2020	31	10					4374	4380		10.1109/TNNLS.2019.2948892													
J								A Dynamic Event-Triggered Approach to Recursive Filtering for Complex Networks With Switching Topologies Subject to Random Sensor Failures	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Topology; Switches; Heuristic algorithms; Markov processes; Complex networks; Dynamic scheduling; Complex networks (CNs); dynamic event-triggered mechanisms (ETMs); recursive filtering; sensor failures; switching topologies	STATE ESTIMATION; SYSTEMS; SYNCHRONIZATION; STABILITY; DESIGN	This article deals with the recursive filtering issue for a class of nonlinear complex networks (CNs) with switching topologies, random sensor failures and dynamic event-triggered mechanisms. A Markov chain is utilized to characterize the switching behavior of the network topology. The phenomenon of sensor failures occurs in a random way governed by a set of stochastic variables obeying certain probability distributions. In order to save communication cost, a dynamic event-triggered transmission protocol is introduced into the transmission channel from the sensors to the recursive filters. The objective of the addressed problem is to design a set of dynamic event-triggered filters for the underlying CN with a certain guaranteed upper bound (on the filtering error covariance) that is then locally minimized. By employing the induction method, an upper bound is first obtained on the filtering error covariance and subsequently minimized by properly designing the filter parameters. Finally, a simulation example is provided to demonstrate the effectiveness of the proposed filtering scheme.																	2162-237X	2162-2388				OCT	2020	31	10					4381	4388		10.1109/TNNLS.2019.2951948													
J								LS-SVR as a Bayesian RBF Network	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Bayes methods; Kernel; Support vector machines; Computational modeling; Radial basis function networks; Standards; Bayesian modeling; least squares support vector regression (LS-SVR); radial basis function (RBF) networks	SUPPORT VECTOR MACHINES; GAUSSIAN-PROCESSES; REGRESSION; FRAMEWORK	We show theoretical similarities between the least squares support vector regression (LS-SVR) model with a radial basis functions (RBFs) kernel and maximum a posteriori (MAP) inference on Bayesian RBF networks with a specific Gaussian prior on the regression weights. Although previous articles have pointed out similar expressions between those learning approaches, we explicitly and formally state the existing correspondences. We empirically demonstrate our result by performing computational experiments with standard regression benchmarks. Our findings open a range of possibilities to improve LS-SVR by borrowing strength from well-established developments in Bayesian methodology.																	2162-237X	2162-2388				OCT	2020	31	10					4389	4393		10.1109/TNNLS.2019.2952000													
J								Stochastic Gradient Descent for Nonconvex Learning Without Bounded Gradient Assumptions	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS										Convergence; Training; Stochastic processes; Optimization; Loss measurement; Nickel; Learning systems; Learning theory; nonconvex optimization; Polyak-Lojasiewicz condition; stochastic gradient descent (SGD)		Stochastic gradient descent (SGD) is a popular and efficient method with wide applications in training deep neural nets and other nonconvex models. While the behavior of SGD is well understood in the convex learning setting, the existing theoretical results for SGD applied to nonconvex objective functions are far from mature. For example, existing results require to impose a nontrivial assumption on the uniform boundedness of gradients for all iterates encountered in the learning process, which is hard to verify in practical implementations. In this article, we establish a rigorous theoretical foundation for SGD in nonconvex learning by showing that this boundedness assumption can be removed without affecting convergence rates, and relaxing the standard smoothness assumption to Holder continuity of gradients. In particular, we establish sufficient conditions for almost sure convergence as well as optimal convergence rates for SGD applied to both general nonconvex and gradient-dominated objective functions. A linear convergence is further derived in the case with zero variances.																	2162-237X	2162-2388				OCT	2020	31	10					4394	4400		10.1109/TNNLS.2019.2952219													
J								Energy efficient scheduler of aperiodic jobs for real-time embedded systems	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Real-time systems; energy efficiency; aperiodic jobs; scheduling; dynamic voltage scaling; low-power systems; embedded systems	TASKS	Energy consumption has become a key metric for evaluating how good an embedded system is, alongside more performance metrics like respecting operation deadlines and speed of execution. Schedulability improvement is no longer the only metric by which optimality is judged. In fact, energy efficiency is becoming a preferred choice with a fundamental objective to optimize the system's lifetime. In this work, we propose an optimal energy efficient scheduling algorithm for aperiodic real-time jobs to reduce CPU energy consumption. Specifically, we apply the concept of real-time process scheduling to a dynamic voltage and frequency scaling (DVFS) technique. We address a variant of earliest deadline first (EDF) scheduling algorithm called energy saving-dynamic voltage and frequency scaling (ES-DVFS) algorithm that is suited to unpredictable future energy production and irregular job arrivals. We prove that ES-DVFS cannot attain a total value greater thanC/000000, where 000000 is the minimum speed of any job andCis the available energy capacity. We also investigate the implications of having in advance, information about the largest job size and the minimum speed used for the competitive factor of ES-DVFS. We show that such advance knowledge makes possible the design of semi-on-line algorithm, ES-DVFS**, that achieved a constant competitive factor of 0.5 which is proved as an optimal competitive factor. The experimental study demonstrates that substantial energy savings and highest percentage of feasible job sets can be obtained through our solution that combines EDF and DVFS optimally under the given aperiodic jobs and energy models.																	1476-8186	1751-8520				OCT	2020	17	5					733	743		10.1007/s11633-016-0993-3													
J								A novel self-adaptive Circuit design technique based on evolvable hardware	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Circuit design; self-adaptive design; redundant fault tolerance technique; evolvable hardware (EHW); evolutionary algorithms (EA)	GENETIC ALGORITHM	Since traditional fault tolerance methods of electronic systems are based on redundant fault tolerance technique, and their structures are fixed when circuits are designed, the self-adaptive ability is limited. In order to solve these problems, a novel circuit self-adaptive design technique based on evolvable hardware (EHW) is proposed. It features robustness, self-organization and self-adaption. It can be adapted to a complex environment through dynamic configuration of the circuit. In this paper, the proposed technique simulated. The consumption of hardware resources and the number of convergence iterations researched. The effectiveness and superiority of the proposed technique are verified. The designed circuit has the ability of resistible redundant-state interference (RRSI). The proposed technique has a broad application prospect, and it has great significance.																	1476-8186	1751-8520				OCT	2020	17	5					744	751		10.1007/s11633-016-1000-8													
J								A study on performance and reliability of urethral valve driven by ultrasonic-vaporized steam	INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING										Urethral valve; ultrasonic; opening; closing performance; driving performance; reliability	SMA ACTUATORS; MODEL	The aim of this study is to investigate the performance and reliability of urethral valve driven by ultrasonic-vaporized steam. The performance model of urethral valve is established to analyze the driving and opening/closing performances of urethral valve. The reliability model of urethral valve is obtained, and the reliability simulation algorithm is proposed to calculate the reliability index of urethral valve. The numerical simulation and experimental results show that urethral valve has a good opening/closing performance, the driving performance can be improved by increasing ultrasonic intensity, radiation area and ultrasonic frequency, and the corrosion and aging of driving bags are the weak links of urethral valve.																	1476-8186	1751-8520				OCT	2020	17	5					752	762		10.1007/s11633-016-1026-y													
J								Deep learning-based edge caching for multi-cluster heterogeneous networks	NEURAL COMPUTING & APPLICATIONS										DNN; HetNets; Joint optimization; User cluster; Content placement	FRAMEWORK; DELIVERY	In this work, we consider a time and space evolution cache refreshing in multi-cluster heterogeneous networks. We consider a two-step content placement probability optimization. At the initial complete cache refreshing optimization, the joint optimization of the activated base station density and the content placement probability is considered. And we transform this optimization problem into a GP problem. At the following partial cache refreshing optimization, we take the time-space evolution into consideration and derive a convex optimization problem subjected to the cache capacity constraint and the backhaul limit constraint. We exploit the redundant information in different content popularity using the deep neural network to avoid the repeated calculation because of the change in content popularity distribution at different time slots. Trained DNN can provide online response to content placement in a multi-cluster HetNet model instantaneously. Numerical results demonstrate the great approximation to the optimum and generalization ability.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15317	15328		10.1007/s00521-019-04040-z													
J								A framework involving MEC: imaging satellites mission planning	NEURAL COMPUTING & APPLICATIONS										Mission planning; Framework; Imaging satellite; Mobile edge computing		Satellite will play an important role in many important industries and exist as a carrier of information transmission in the era of Internet of Things. Massive data can be used in planning and scheduling processes A general data-driven framework-imaging satellite mission planning framework (ISMPF) for solving imaging mission planning problems is proposed. ISMPF mainly includes three parts: task assignment, planning and scheduling and task execution. The framework gives a general solution to the problem of satellite mission planning. The two core parts of the planning and scheduling module are machine learning algorithms and planning and scheduling algorithms, which greatly affect the quality of the results. Machine learning algorithm is mainly used to quickly obtain feasible initial solution. This idea can be used to quickly analyze and model the imaging satellite observation mission planning, imaging satellite measurement and control, data downlink mission planning problems. It has a strong generality and is suitable for most situations of imaging satellites. In order to verify the validity of ISMPF, we designed test examples for measurement and control, data downlink missions. Experimental verification demonstrates the effectiveness of our proposed framework.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15329	15340		10.1007/s00521-019-04047-6													
J								An IoT-based E-business model of intelligent vegetable greenhouses and its key operations management issues	NEURAL COMPUTING & APPLICATIONS										Intelligent vegetable greenhouses; Internet of things; E-business model; IoT-based e-business platforms; Industry and value chains; Operations management	WIRELESS SENSOR NETWORK; THINGS IOT; INTERNET; FRAMEWORK; RADIO	The widespread popularization of Internet has brought about various Internet-based business models as well as well-known Internet giants such as Facebook, Google, Amazon, and Alibaba. Similarly, the application of internet of things (IoT) is fermenting IoT-based business models in various fields. In our work, we present an IoT-based e-business model of intelligent vegetable greenhouses with details on the basic process and key nodes of the e-business model. Information, capital and logistics flows are recognized in the industry chain consisting of ingredient suppliers, IoT-equipped greenhouses, IoT-based e-business platforms, payment and delivery service providers, and end consumers. The value chain is also analyzed according to Michael Porter's value chain model, which is helpful for greenhouses to focus on main activities in the business model. Moreover, we recognize key operation issues including big-data-driven pricing, planting structure and time optimization, water and fertilizer integrated control, plant light supplement, and order-driven picking and packing. The characteristics brought about by IoT techniques to these operation issues are analyzed, and corresponding mathematical models are formulated, which may attract more efforts in the future.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15341	15356		10.1007/s00521-019-04123-x													
J								Study on supply chain strategy based on cost income model and multi-access edge computing under the background of the Internet of Things	NEURAL COMPUTING & APPLICATIONS										Multi-access edge computing; Internet of Things; Fresh agricultural product; Cost effectiveness of cold-chain logistics	INTEGRATION; SYSTEMS	With the application of the Internet of Things, the cold-chain logistics efficiency of fresh agricultural product remarkably is improved, but the operating costs inevitably rise. Thus, the main bodies of circulation at various levels need to decide whether adopt the Internet of Things or not according to the cost-benefit situation. The significant boundary value closely related to the revenue decision of cold-chain logistics of fresh agricultural product was figured out by particularly analyzing the impact of the adoption of the Internet of Things on upstream and downstream wholesale prices, retail price, and order quantity decision based on the costs and revenues of the upstream and downstream of the supply chain before and after the adoption of the Internet of Things, and it was found that the overall profit boundary values of wholesaler, retailer, and supply chain are the same; the increment of retail price and retailers' revenues is larger than that of wholesalers' revenues, and the ascensional range of retail price is larger than that of wholesale price; the cost boundary value of order quantity in supply chain has little to do with the quality of agricultural products, but is affected by the time of circulation, and transportation and warehouse cost; the lower the cost of the Internet of Things is, the larger the impact on order quantity is. The correctness of the research results was proved by means of illustrative example. This paper provides a scientific basis for investment in the Internet of Things by enterprises engaged in cold-chain operation of fresh agricultural products.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15357	15368		10.1007/s00521-019-04125-9													
J								A novel edge-enabled SLAM solution using projected depth image information	NEURAL COMPUTING & APPLICATIONS										Mobile robots; Edge computing; Simultaneous localization and mapping; Extended Kalman filter; Inertial navigation; Depth sensor; Edge layer	SIMULTANEOUS LOCALIZATION; NETWORK	Environmental mapping is the key step for mobile robots to perform tasks independently and perfectly. In recent years, visual SLAM, laser-based SLAM and simultaneous localization and mapping (SLAM) have aroused the interest of many people. Unfortunately, those technologies are not widely used, limited by the computational complexity, data processing and very low and predictable latency. This paper had mainly completed the following work and edge-enabled computing-based edge computing (Shi and Dustdar in Computer 49(5):78-81,2016) is used as a solution to accelerate calculation. First of all, this research design works with inertial unit mobile robotic navigation systems, and all sensors are connected in edge layers in the framework of edge computing and explore the accelerometer, electronic compass, and gyroscope data. The accelerometer data are integrated using the Kalman filter data fusion algorithm to filter the random drift error caused by the gyroscope and the electronic compass. The state of the machine is determined by calculation of the corresponding attitude angle and position information. Second, a low-cost distance sensor is used to detect the depth and upload to the other fog node for computation. Next, the 3D point coordinate information is projected onto the two-dimensional coordinate extraction feature point to establish the feature map. Third, the extended Kalman filter SLAM is used to achieve simultaneous positioning and mapping. Finally, the method is validated in the experiment, proving that the method is feasible. The main improvement in this article is as follows: First, the multi-sensor data fusion algorithm is used to reduce the positioning error. Second, we use low-cost distance sensors to measure the depth of the model environment and reduce the cost. Third, we would take advantage of translating the three-dimensional depth information into a flat two-dimensional projection information to reduce the calculation of load and computing time. Fourth, our computation is distributed in different layers and focuses on edge-enabled platform to decrease the latency and redundancy.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15369	15381		10.1007/s00521-019-04156-2													
J								Partial offloading strategy for mobile edge computing considering mixed overhead of time and energy	NEURAL COMPUTING & APPLICATIONS										Full granularity; Partial offloading; Mixed overhead; Mobile edge computing	CLOUD; COMMUNICATION; 5G	Mobile edge computing (MEC) utilizes wireless access network to provide powerful computing resources for mobile users to improve the user experience, which mainly includes two aspects: time and energy consumption. Time refers to the latency consumed to process user tasks, while energy consumption refers to the total energy consumed in processing tasks. In this paper, the time and energy consumption in user experience are weighted as a mixed overhead and then optimized jointly. We formulate a mixed overhead of time and energy (MOTE) minimization problem, which is a nonlinear programming problem. In order to solve this problem, the block coordinate descent method to deal with each variable step by step is adopted. We further analyze the minimum value of delay parameters in the model, and examine two special cases: 1-offloading and 0-offloading. In 1-offloading, all the task data is offloaded to MEC server, and no data offloaded in 0-offloading. The necessary and sufficient conditions for the existence of two special cases are also deduced. Besides, the multi-user situation is also discussed. In the performance evaluation, we compare MOTE with other offloading schemes, such as exhaustive strategy and Monte Carlo simulation method-based strategy to evaluate the optimality. The simulation results show that MOTE always achieves the minimal overhead compared to other algorithms.																	0941-0643	1433-3058				OCT	2020	32	19			SI		15383	15397		10.1007/s00521-019-04401-8													
J								Comparison of offline and real-time human activity recognition results using machine learning techniques	NEURAL COMPUTING & APPLICATIONS										Activity recognition; Android application; Feature extraction; Machine learning	TRIAXIAL ACCELEROMETER; HUMAN MOVEMENT; CLASSIFICATION; IMPLEMENTATION; ALGORITHM; PATTERN	Today's human activity recognition is an important part of healthcare and ambient-assisted living where accelerometer and gyroscope sensors provide the raw data about physical activities and functional abilities of an observed person. Previous studies have shown that activity recognition can be seen as a machine learning chain with its particular data preprocessing technique. In recent past, several scientists measured rather high recognition accuracies on public databases or in laboratory environment but their solutions have not been tested in real environment. The goal of this paper is to examine the efficiency of previously used machine learning methods in real time by an Android-based, self-learning, activity recognition application which has been designed especially to this study according to the latest theoretical results (with the most relevant feature extraction and machine learning algorithms). Before real-time tests, we investigated the design considerations and application possibilities of different shallow and deep methods. The final outcome shows recognition rate difference between the "online" and "offline" cases. In the article we present some reasons for the difference and their possible solutions.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15673	15686		10.1007/s00521-018-3437-x													
J								Automatic computer vision-based detection and quantitative analysis of indicative parameters for grading of diabetic retinopathy	NEURAL COMPUTING & APPLICATIONS										Fundus images; Diabetic retinopathy; Optic disc; Bright lesions; Red lesions; Mathematical morphology; Classification; Grading	OPTIC DISC	Diabetic retinopathy (DR) is one of the complications of diabetes affecting the eyes. If not treated at an early stage, then it can cause permanent blindness. The present work proposes a method for automatic detection of pathologies that are indicative parameters for DR and use them strategically in a framework to grade the severity of the disease. The bright lesions are highlighted using a normalization process followed by anisotropic diffusion and intensity threshold for detection of lesions which makes the algorithm robust to correctly reject false positives. SVM-based classifier is used to reject false positives using 10 distinct feature types. Red lesions are accurately detected from a shade-corrected green channel image, followed by morphological flood filling and regional minima operations. The rejection of false positives using geometrical features makes the system less complex and computationally efficient. A comprehensive quantitative analysis to grade the severity of the disease has resulted in an average sensitivity of 92.85 and 86.03% on DIARETDB1 and MESSIDOR databases, respectively.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15687	15697		10.1007/s00521-018-3443-z													
J								Neural networks fusion for temperature forecasting	NEURAL COMPUTING & APPLICATIONS										Score fusion; Modeling; Temperature prediction; Artificial neural networks	PREDICTION; MODEL	Weather conditions have a direct relationship with energy consumption, touristic activities, and farm tasks. By means of the fusion of artificial neural networks, this work presents a system with a general method that obtains an accurate temperature prediction. The objective is temperature, but the method is easily scalable to obtain any other meteorological parameter; this is one strength of the model. This research carries out a temperature prediction modeling that contributes to obtain better results with different applications as energy generation or in other different fields such as tourism or farming. The database contains data of 5 years from stations located in Gran Canaria at Gran Canaria Airport and in Tenerife at Tenerife Sur Airport. Data are collected hourly, what means more than 100,000 samples. This quantity of samples gives sturdiness to the study. With this method, our best result in terms of mean absolute error and using data from meteorological stations in Canary Islands is 0.41 degrees C.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15699	15710		10.1007/s00521-018-3450-0													
J								Comparison of SFS and mRMR for oximetry feature selection in obstructive sleep apnea detection	NEURAL COMPUTING & APPLICATIONS										Classification; Feature section; mRMR; SFS; Sleep apnea; SpO2	OXYGEN-SATURATION; ELECTROCARDIOGRAM; CLASSIFICATION; OPTIMALITY; ENTROPY	Obstructive sleep apnea is a disorder characterized by pauses in respiration during sleep. Due to this disturbance in breathing, there is a decrease in the oxygen saturation (SpO2) level. Thus, SpO2 can be used as a source of information for the automatic detection of apnea. Several solutions exist in the literature where different features are used. To find a better discriminant capacity, a subset of few features that obtains higher accuracy with the proper classifier is needed. To face this challenge, this work compares two different feature selection methods. The first one is a filter method named minimum redundancy maximum relevance, and the other one is called sequential forward search. These methods are tested with different classifiers. Two public datasets with 8 and 25 subjects are used to test and compare the performances of the different feature selection methods. A set of features for each classifier is obtained, and the results are compared with the previous work. The results found in this work show a good performance with respect to the state of the art and present a good option for apnea screening with low resources.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15711	15731		10.1007/s00521-018-3455-8													
J								Writer identification approach by holistic graphometric features using off-line handwritten words	NEURAL COMPUTING & APPLICATIONS										Based-handwriting recognition; Word holistic analysis; Graphometric features; Off-line system; Biometric identification		The biometric identification is an important topic with applications in different fields. Among the different modalities, based-handwriting biometric is a very useful and extended modality, and the most known one is the signature. The use of handwritten texts is researched presenting a biometric system for identifying writers from their handwritten words. A set of feature-based graphometric information has been extracted from off-line handwritten words to implement an automatic biometric approach. Given the handwritten nature of the information and its great variability, a feature selection based on principal component analysis and neural network classifier has been proposed. A fusion block based on neural networks has been added in order to reduce the effect of the data variability due to an increase and stabilization of the accuracy. A dataset composed of 100 writers have been used for the experiments. A holdout cross-validation was applied and the accuracy reached between 99.80% and 100%.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15733	15746		10.1007/s00521-018-3461-x													
J								Towards robust voice pathology detection Investigation of supervised deep learning, gradient boosting, and anomaly detection approaches across four databases	NEURAL COMPUTING & APPLICATIONS										Voice pathology detection; Deep learning; Gradient boosting; Anomaly detection	FREQUENCY CEPSTRAL COEFFICIENTS; PERCEPTUAL EVALUATION; QUALITY; MACHINE	Automatic objective non-invasive detection of pathological voice based on computerized analysis of acoustic signals can play an important role in early diagnosis, progression tracking, and even effective treatment of pathological voices. In search towards such a robust voice pathology detection system, we investigated three distinct classifiers within supervised learning and anomaly detection paradigms. We conducted a set of experiments using a variety of input data such as raw waveforms, spectrograms, mel-frequency cepstral coefficients (MFCC), and conventional acoustic (dysphonic) features (AF). In comparison with previously published works, this article is the first to utilize combination of four different databases comprising normophonic and pathological recordings of sustained phonation of the vowel /a/ unrestricted to a subset of vocal pathologies. Furthermore, to our best knowledge, this article is the first to explore gradient-boosted trees and deep learning for this application. The following best classification performances measured by F1 score on dedicated test set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621) using MFCC, and Isolation Forest (0.610) using AF. Even though these results are of exploratory character, conducted experiments do show promising potential of gradient boosting and deep learning methods to robustly detect voice pathologies.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15747	15757		10.1007/s00521-018-3464-7													
J								On the analysis of speech and disfluencies for automatic detection of Mild Cognitive Impairment	NEURAL COMPUTING & APPLICATIONS										Mild Cognitive Impairment; Automatic Speech Analysis; Deep Learning; Convolutional Neural Networks; Nonlinear features; Disfluencies	ALZHEIMERS-DISEASE	Alzheimer's disease is characterized by a progressive and irreversible cognitive deterioration. In a previous stage, the so-called Mild Cognitive Impairment or cognitive loss appears. Nevertheless, this previous stage does not seem sufficiently severe to interfere in independent abilities of daily life, so it is usually diagnosed inappropriately. Thus, its detection is a crucial challenge to be addressed by medical specialists. This paper presents a novel proposal for such early diagnosis based on automatic analysis of speech and disfluencies, and Deep Learning methodologies. The proposed tools could be useful for supporting Mild Cognitive Impairment diagnosis. The Deep Learning approach includes Convolutional Neural Networks and nonlinear multifeature modeling. Additionally, an automatic hybrid methodology is used in order to select the most relevant features by means of nonparametric Mann-Whitney U test and Support Vector Machine Attribute evaluation.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15761	15769		10.1007/s00521-018-3494-1													
J								Control structure for a car-like robot using artificial neural networks and genetic algorithms	NEURAL COMPUTING & APPLICATIONS										Neuroevolution; Artificial neural network; Genetic algorithm; Control strategy; Non-holonomic wheeled robot; Car-like robot	NAVIGATION; AVOIDANCE	The idea of improving human's life quality by making life more comfortable and easy is nowadays possible using current technologies and techniques to solve complex daily problems. The presented idea in this work proposes a control strategy for autonomous robotic systems, specifically car-like robots. The main objective of this work is the development of a reactive navigation controller by means of obstacles avoidance and position control to reach a desired position in an unknown environment. This research goal was achieved by the integration of potential fields and neuroevolution controllers. The neuro-evolutionary controller was designed using the (NEAT) algorithm "Neuroevolution of Augmented Topologies" and trained using a designed training environment. The methodology used allowed the vehicle to reach a certain level of autonomy, obtaining a stable controller that includes kinematic and dynamic considerations. The obtained results showed significant improvements compared to the comparison work.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15771	15784		10.1007/s00521-018-3514-1													
J								Evaluation and analysis of ear recognition models: performance, complexity and resource requirements	NEURAL COMPUTING & APPLICATIONS										Ear recognition; Covariate analysis; Convolutional neural networks; Feature extraction	FACE RECOGNITION; INVARIANT; FEATURES; ILLUMINATION; ADAPTATION	Ear recognition technology has long been dominated by (local) descriptor-based techniques due to their formidable recognition performance and robustness to various sources of image variability. While deep-learning-based techniques have started to appear in this field only recently, they have already shown potential for further boosting the performance of ear recognition technology and dethroning descriptor-based methods as the current state of the art. However, while recognition performance is often the key factor when selecting recognition models for biometric technology, it is equally important that the behavior of the models is understood and their sensitivity to different covariates is known and well explored. Other factors, such as the train- and test-time complexity or resource requirements, are also paramount and need to be consider when designing recognition systems. To explore these issues, we present in this paper a comprehensive analysis of several descriptor- and deep-learning-based techniques for ear recognition. Our goal is to discover weak points of contemporary techniques, study the characteristics of the existing technology and identify open problems worth exploring in the future. We conduct our analysis through identification experiments on the challenging Annotated Web Ears (AWE) dataset and report our findings. The results of our analysis show that the presence of accessories and high degrees of head movement significantly impacts the identification performance of all types of recognition models, whereas mild degrees of the listed factors and other covariates such as gender and ethnicity impact the identification performance only to a limited extent. From a test-time-complexity point of view, the results suggest that lightweight deep models can be equally fast as descriptor-based methods given appropriate computing hardware, but require significantly more resources during training, where descriptor-based methods have a clear advantage. As an additional contribution, we also introduce a novel dataset of ear images, called AWE Extended (AWEx), which we collected from the web for the training of the deep models used in our experiments. AWEx contains 4104 images of 346 subjects and represents one of the largest and most challenging (publicly available) datasets of unconstrained ear images at the disposal of the research community.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15785	15800		10.1007/s00521-018-3530-1													
J								Monitoring ALS from speech articulation kinematics	NEURAL COMPUTING & APPLICATIONS										Amyotrophic lateral sclerosis; Neuromotor diseases; Kullback-Leibler divergence; Speech articulation	AMYOTROPHIC-LATERAL-SCLEROSIS; MOVEMENTS; MODEL	Patients affected by amyotrophic lateral sclerosis (ALS) show specific dysarthria in their speech resulting in specific marks which could be used to detect early symptoms and monitor the evolution of the disease in time. Classically articulation marks have been mainly based on static premises. Articulation kinematics from acoustic correlates may help in producing measurements depending on the dynamic behaviour of speech. Specifically, distribution functions from the absolute kinematic velocity estimated on a simplified articulation model can be used in establishing distances based on information theory concepts between running speech segments from patients and controls. As an example, several cases of ALS were studied longitudinally using this methodology. The study shows that the performance of dynamic articulation quality correlates may be sensitive and robust in tracking illness progress. Conclusions foresee the use of speech as a valuable monitoring methodology for ALS timely neurodegenerative progression.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15801	15812		10.1007/s00521-018-3538-6													
J								Design of sEMG-based clench force estimator in FPGA using artificial neural networks	NEURAL COMPUTING & APPLICATIONS										Artificial neural network; Biomedical electronics; Biomedical equipment; Biomedical signal processing; Field programmable gate arrays; Prosthesis	SURFACE ELECTROMYOGRAPHY; LIMB LOSS; EMG; IMPLEMENTATION; GASTROCNEMIUS; REDUNDANCY; MUSCLES; WALKING; SOLEUS; MODEL	Hands are the main environmental manipulator for the human being. After losing a hand, the only alternative for the victim is to use a prosthesis. Despite the progress of science, the modern prosthesis has the same age-old problem of accurate force estimation. Among different kinds of force, clench force is the most important one. Because of this importance, this paper presents a hardware system that has been designed and implemented to estimate the desired clench force using surface Electromyography signals recorded from lower-arm muscles. The implementation includes a two-layer artificial neural network with a surface electromyography integrator. The neural network was trained with the Levenberg-Marquardt back propagation algorithm and was implemented in a field programmable gate array using an off-chip training method. The results from 10 datasets, recorded from five subjects, show that the hardware model is very accurate, with an average mean square error of 0.003. This suggests that the proposed design can mimic the behavior of clench force that a real limb does, and therefore this intelligent system could be a useful tool for any application related to prostheses.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15813	15823		10.1007/s00521-018-3600-4													
J								Comparing different solutions for forecasting the energy production of a wind farm	NEURAL COMPUTING & APPLICATIONS										Support vector machine; Artificial neural network; Adaptive neuro-fuzzy inference system; Eolic energy	SPEED; PREDICTION; MODEL; IMPLEMENTATION	The production of different renewable and non-renewable energies sources can be coordinated efficiently to avoid costly overproduction. For that, it is important to develop models for accurate energy production forecasting. The energy production of wind farms is extremely dependent on the meteorological conditions. In this paper, computational intelligence techniques were used to predict the production of energy in a wind farm. This study is held on publicly accessible climacteric and energy data for a wind farm in Galicia, Spain, with 24 turbines of 9 different models. Data preprocessing was performed in order to delete outliers caused by the maintenance and technical problems. Models of the following types were developed: artificial neural networks, support vector machines and adaptive neuro-fuzzy inference system models. Furthermore, the persistence method was used as a time series forecast baseline model. Overall, the developed computational intelligence models perform better than the baseline model, being adaptive neuro-fuzzy inference system the model with the best results: a ~ 5% performance improvement over the baseline model.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15825	15833		10.1007/s00521-018-3628-5													
J								A global monitoring system for electricity consumption and production of household roof-top PV systems in Madeira	NEURAL COMPUTING & APPLICATIONS										Roof-top PV system; Prediction; Artificial neural network; Monitoring system	FEASIBILITY ANALYSIS; MODELS	This paper describes recent work on the development of a wireless-based remote monitoring system for household energy consumption and generation in Madeira Island, Portugal. It contains three different main sections: (1) a monitoring system for consumed and produced energy of residencies equipped with photovoltaic (PV) systems, (2) developing a tool to predict the electricity production, (3) and proposing a solution to detect the PV system malfunctions. With the later tool, the user (owner) or the energy management system can monitor its own PV system and make an efficient schedule use of electricity at the consumption side. In addition, currently, the owners of PV systems are notified about a failure in the system only when they receive the bill, whereas using the proposed method conveniently would notify owners prior to bill issue. The artificial neural network was employed as a tool together with the hardware-based monitoring system which allows a daily analysis of the performance of the system. The comparison of the predicted value of the produced electricity with the actual production for each day shows the validity of the method.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15835	15844		10.1007/s00521-018-3832-3													
J								Automatic lung segmentation in low-dose chest CT scans using convolutional deep and wide network (CDWN)	NEURAL COMPUTING & APPLICATIONS										Automatic lung segmentation; Convolutional neural network; Deep learning; Image processing and analysis; Medical imaging	IMAGE; INFORMATION	Computed tomography (CT) imaging is the preferred imaging modality for diagnosing lung-related complaints. Automatic lung segmentation is the most common prerequisite to develop a computerized diagnosis system for analyzing chest CT images. In this paper, a convolutional deep and wide network (CDWN) is proposed to segment lung region from the chest CT scan for further medical diagnosis. Earlier lung segmentation techniques depend on handcrafted features, and their performance relies on the features considered for segmentation. The proposed model automatically segments the lung from complete CT scan in two laps: (1) learning the required filters to extract hierarchical feature representations at convolutional layers, (2) dense prediction with spatial features through learnable deconvolutional layers. The model has been trained and evaluated with low-dose chest CT scan images on LIDC-IDRI database. The proposed CDWN reaches the average Dice coefficient of 0.95 and accuracy of 98% in segmenting the lung regions from 20 test images and maintains consistent results for all test images. The experimental results confirm that the proposed approach achieves a superior performance compared to other state-of-the-art methods for lung segmentation.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15845	15855		10.1007/s00521-018-3877-3													
J								A deep convolutional neural network model for automated identification of abnormal EEG signals	NEURAL COMPUTING & APPLICATIONS										Convolutional neural network; Abnormal EEG; EEG classification; Deep learning	SEIZURE PREDICTION; EPILEPTIC SEIZURES; COMPONENT ANALYSIS; CLASSIFICATION; RECOGNITION	Electroencephalogram (EEG) is widely used to monitor the brain activities. The manual examination of these signals by experts is strenuous and time consuming. Hence, machine learning techniques can be used to improve the accuracy of detection. Nowadays, deep learning methodologies have been used in medical field to diagnose the health conditions precisely and aid the clinicians. In this study, a new deep one-dimensional convolutional neural network (1D CNN) model is proposed for the automatic recognition of normal and abnormal EEG signals. The proposed model is a complete end-to-end structure which classifies the EEG signals without requiring any feature extraction. In this study, we have used the EEG signals from temporal to occipital (T5-O1) single channel obtained from Temple University Hospital EEG Abnormal Corpus (v2.0.0) EEG dataset to develop the 1D CNN model. Our developed model has yielded the classification error rate of 20.66% in classifying the normal and abnormal EEG signals.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15857	15868		10.1007/s00521-018-3889-z													
J								Detection of shockable ventricular arrhythmia using optimal orthogonal wavelet filters	NEURAL COMPUTING & APPLICATIONS										Electrocardiogram ECG; Shockable rhythms; Non-shockable rhythms; Biorthogonal filter bank; Stopband energy; SVM	CONVOLUTIONAL NEURAL-NETWORK; TRANSFORM-BASED FEATURES; CARDIOVASCULAR-DISEASE; FIBRILLATION DETECTION; ECG SIGNALS; DESIGN; TACHYCARDIA; DIAGNOSIS; BANK; ALGORITHMS	Sudden cardiac death (SCD) is caused by lethal arrhythmia. Ventricular fibrillation (VF) and ventricular tachycardia (VT) are amenable to defibrillation or electrical shock therapy ("shockable" arrhythmia) that can abolish the VF/VT and restore normal electrical and mechanical heart function. The challenge is to differentiate between shockable and non-shockable arrhythmia during the emergency response to SCD. When it comes to saving the life, accurate electrocardiogram (ECG) diagnosis and fast delivery of appropriate treatment is imperative. Automated systems to differentiate shockable from non-shockable arrhythmia have been developed to overcome the difficulty, and possible errors due to the manual inspection. In the present work, we have devised an efficient, effective and robust automated system to detect shockable and non-shockable arrhythmia using an optimal wavelet-based features extracted from ECG epochs of 2 s durations. We employed optimal two-channel frequency selective orthogonal wavelet filter bank to diagnose shockable ventricular arrhythmia. The optimization was carried out by minimizing the stop band ripple energy of the wavelet filter. The optimal orthogonal wavelet filter has been designed using a semi-definite programming (SDP) formulation without the use of any parameterization. The SDP solution gave us the desired optimal orthogonal wavelet filter bank with minimum stop band energy and the desired degree of regularity for the given length of filter. Fuzzy entropy and Renyi entropy features were extracted from the 2-s ECG epochs. These extracted features were then fed into the classifiers for discrimination of shockable arrhythmia rhythms and non-shockable arrhythmia rhythms. The best results were obtained from support vector machine. Accuracy of 97.8%, sensitivity of 93.42%, and specificity of 98.35% were obtained using a tenfold cross validation scheme. The developed automated system is accurate and robust; therefore, it can be integrated in automated external defibrillators that can be deployed for hospitals as well as out-of-hospital emergency resuscitation of SCD.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15869	15884		10.1007/s00521-019-04061-8													
J								Enhanced vascular and osseous information fusion: disagreement of quantitative and qualitative analysis	NEURAL COMPUTING & APPLICATIONS										Osseous; Vascular; Aneurysms; Fusion; DSA; Hessian matrix	VISIBLE IMAGE FUSION	The computer-aided algorithms are becoming indispensable in the field of digital subtraction angiography for better subsequent clinician diagnosis and feature extraction. These tools find widespread application for localization and highlighting potential malfunctioned sites and abnormal vascular pathology. For this purpose, an enhancement filter function based on Hessian matrix is often employed which produces a response close to ideal enhancement function in the literature. However, while predicting the abnormal pathology, both vessel and osseous details are elementary to patient diagnosis and treatment. In this manuscript, with an aim to parallelize the visualization of enhanced vessel details and osseous information for quick diagnosis, an image fusion algorithm is proposed based on the pre-enhancement of source images which generates highly pleasant visual results free from noise and ghostly artefacts outperforming the ten other image fusion techniques. Besides, this study presents a potential research challenge of disagreement between objective and subjective evaluation of fused image.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15885	15895		10.1007/s00521-019-04259-w													
J								A reliable framework for accurate brain image examination and treatment planning based on early diagnosis support for clinicians	NEURAL COMPUTING & APPLICATIONS										Brain MRI; Tumor examination; Customized examination framework; Assessment; Clinical diagnosis	STROKE LESION SEGMENTATION; MR-IMAGES; OPTIMIZATION; ENTROPY; TUMOR; CLASSIFICATION; ALGORITHM	The human brain is considered to be the anatomical seat of intelligence, comprehensively supervising conscious and autonomous functions responsible for monitoring and control operations. Although neural homeostasis can be disrupted, early signs of disease should be recognized to save the patient from permanent disability and even a preventable death. The record of World Health Organization (WHO) lists various brain diseases, such as aneurism, stroke and tumor, which affect humans irrespective of their age, sex and province, all of which affect diagnosis, prognosis and treatment options. Since clinically significant diagnosis of brain abnormality is generally performed using dedicated imaging procedures and also under the supervision of an experienced radiologist, more accurate tools can make this process even more precise. The usual protocol involves a radiologist who records the three-dimensional (3D) image which provides initial insight on the type of brain disease, followed by doctor examination of the 3D/2D image that determines the treatment plan. This article proposes a tool and associated procedure to examine a clinical brain image with improved accuracy in order to provide early insight on ideal treatment procedure. In summary, this tool gives the treatment team unprecedented assessment capability before an operation by integrating all the possible image processing procedures to enhance the result in brain image analysis.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15897	15908		10.1007/s00521-019-04369-5													
J								Prediction analytics of myocardial infarction through model-driven deep deterministic learning	NEURAL COMPUTING & APPLICATIONS										Deep learning; Deep deterministic learning; Electrocardiography; Myocardial infarction; Prediction analysis; Artificial neural network	CONVOLUTIONAL NEURAL-NETWORK; AUTOMATED DETECTION; WAVELET TRANSFORM; ECG; CLASSIFICATION; RECOGNITION; QUALITY	Electrocardiography is the primary diagnostic tool for measuring the malfunction of different heart activities in the form of various cardiac diseases. Some cardiac diseases require special attention due to the urgency and risk factors involved. Myocardial infarction (MI) is one of the cardiac diseases that require robust identification. Early prediction in MI cases without prior history remains to be an ongoing challenge. This article delivers a major novel contribution in the context of predictive classification of flattened T-wave MI cases. Therefore, a novel model-driven deep deterministic learning (MDDDL) approach is proposed. In MDDDL, two different data sets are used for the execution of operational activities in terms of flattened T-wave predictive classification. The first data set is the publicly available Physikalisch-Technische Bundesanstalt (PTB), and the second data set is exclusively obtained from the University of Malaya Medical Centre (UMMC). Firstly, the systematic behaviour of MDDDL is defined in terms of pattern recognition of extracted features between T-wave alternans and flattened T-wave subjects, and then both data sets are merged considering data fusion approach and pre-defined conditions. Afterwards, the empirical approach is adopted in MDDDL evaluation in relation to global acceptance and state-of-the-art comparison. Finally, some qualitative improvements, such as inclusion of a backtracking factor for rapid prediction of flattened anomalies and increasing the number of features along with enhancement of fusion processes to reduce complexity, are required by the MDDDL and should be covered in future works.																	0941-0643	1433-3058				OCT	2020	32	20			SI		15909	15928		10.1007/s00521-019-04400-9													
J								Dynamic Reorganization of the Cortical Functional Brain Network in Affective Processing and Cognitive Reappraisal	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Emotion regulation; EEG; functional MRI; multimodal imaging; functional connectivity; cognitive dynamics	EMOTION REGULATION; PREFRONTAL CORTEX; CIRCUMPLEX MODEL; CONNECTIVITY; GRAPH; SYNCHRONIZATION; COMPLEXITY; FRACTALITY; DIAGNOSIS; ATTENTION	Emotion and affect play crucial roles in human life that can be disrupted by diseases. Functional brain networks need to dynamically reorganize within short time periods in order to efficiently process and respond to affective stimuli. Documenting these large-scale spatiotemporal dynamics on the same timescale they arise, however, presents a large technical challenge. In this study, the dynamic reorganization of the cortical functional brain network during an affective processing and emotion regulation task is documented using an advanced multi-model electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) technique. Sliding time window correlation and k-means clustering are employed to explore the functional brain connectivity (FC) dynamics during the unaltered perception of neutral (moderate valence, low arousal) and negative (low valence, high arousal) stimuli and cognitive reappraisal of negative stimuli. Betweenness centralities are computed to identify central hubs within each complex network. Results from 20 healthy subjects indicate that the cortical mechanism for cognitive reappraisal follows a 'top-down' pattern that occurs across four brain network states that arise at different time instants (0-170ms, 170-370ms, 380-620ms, and 620-1000ms). Specifically, the dorsolateral prefrontal cortex (DLPFC) is identified as a central hub to promote the connectivity structures of various affective states and consequent regulatory efforts. This finding advances our current understanding of the cortical response networks of reappraisal-based emotion regulation by documenting the recruitment process of four functional brain sub-networks, each seemingly associated with different cognitive processes, and reveals the dynamic reorganization of functional brain networks during emotion regulation.																	0129-0657	1793-6462				OCT	2020	30	10							2050051	10.1142/S0129065720500513													
J								A Methodology to Differentiate Parkinson's Disease and Aging Speech Based on Glottal Flow Acoustic Analysis	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Parkinson's disease; phonation distortion; aging speech; speech neuromechanics; Jensen-Shannon divergence; support vector machines	FUNCTIONAL NEUROANATOMY; NEURAL-CONTROL; WAVE-FORM; VOCALIZATION; ROBUST; CLASSIFICATION	Speech is controlled by axial neuromotor systems, therefore, it is highly sensitive to the effects of neurodegenerative illnesses such as Parkinson's Disease (PD). Patients suffering from PD present important alterations in speech, which are manifested in phonation, articulation, prosody, and fluency. These alterations may be evaluated using statistical methods on features obtained from glottal, spectral, cepstral, or fractal descriptions of speech. This work introduces an evaluation paradigm based on Information Theory (IT) to differentiate the effects of PD and aging on glottal amplitude distributions. The study is conducted on a database including 48 PD patients (24 males, 24 females), 48 age-matched healthy controls (HC, 24 males, 24 females), and 48 mid- age normative subjects (NS, 24 males, 24 females). It may be concluded from the study that Hierarchical Clustering (HiCl) methods produce a clear separation between the phonation of PD patients from NS subjects (accuracy of 89.6% for both male and female subsets), but the separation between PD patients and HC subjects is less efficient (accuracy of 75.0% for the male subset and 70.8% for the female subset). Conversely, using feature selection and Support Vector Machine (SVM) classification, the differentiation between PD and HC is substantially improved (accuracy of 94.8% for the male subset and 92.8% for the female subset). This improvement was mainly boosted by feature selection, at a cost of information and generalization losses. The results point to the possibility that speech deterioration may affect HC phonation with aging, reducing its difference to PD phonation.																	0129-0657	1793-6462				OCT	2020	30	10							2050058	10.1142/S0129065720500586													
J								A Basal Ganglia Computational Model to Explain the Paradoxical Sensorial Improvement in the Presence of Huntington's Disease	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Basal ganglia; spiking neural networks; computational model; Huntington's disease; dopamine	VITRO SLICE PREPARATION; ACTION SELECTION; INTEGRATIVE PROPERTIES; MOUSE MODELS; NEURONS; PROJECTION; STRIATUM; CLASSIFICATION; MECHANISMS; DOPAMINE	The basal ganglia (BG) represent a critical center of the nervous system for sensorial discrimination. Although it is known that Huntington's disease (HD) affects this brain area, it still remains unclear how HD patients achieve paradoxical improvement in sensorial discrimination tasks. This paper presents a computational model of the BG including the main nuclei and the typical firing properties of their neurons. The BG model has been embedded within an auditory signal detection task. We have emulated the effect that the altered levels of dopamine and the degree of HD affectation have in information processing at different layers of the BG, and how these aspects shape transient and steady states differently throughout the selection task. By extracting the independent components of the BG activity at different populations, it is evidenced that early and medium stages of HD affectation may enhance transient activity in the striatum and the substantia nigra pars reticulata. These results represent a possible explanation for the paradoxical improvement that HD patients present in discrimination task performance. Thus, this paper provides a novel understanding on how the fast dynamics of the BG network at different layers interact and enable transient states to emerge throughout the successive neuron populations.																	0129-0657	1793-6462				OCT	2020	30	10							2050057	10.1142/S0129065720500574													
J								Improved Activity Recognition Combining Inertial Motion Sensors and Electroencephalogram Signals	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Neuroethology; activity recognition; EEG; inertial measurement	EEG; TRACKING; ACCURACY; SYSTEM; FIELD	Human activity recognition and neural activity analysis are the basis for human computational neureoethology research dealing with the simultaneous analysis of behavioral ethogram descriptions and neural activity measurements. Wireless electroencephalography (EEG) and wireless inertial measurement units (IMU) allow the realization of experimental data recording with improved ecological validity where the subjects can be carrying out natural activities while data recording is minimally invasive. Specifically, we aim to show that EEG and IMU data fusion allows improved human activity recognition in a natural setting. We have defined an experimental protocol composed of natural sitting, standing and walking activities, and we have recruited subjects in two sites: in-house (N = 4) and out-house (N = 12) populations with different demographics. Experimental protocol data capture was carried out with validated commercial systems. Classifier model training and validation were carried out with scikit-learn open source machine learning python package. EEG features consist of the amplitude of the standard EEG frequency bands. Inertial features were the instantaneous position of the body tracked points after a moving average smoothing to remove noise. We carry out three validation processes: a 10-fold cross-validation process per experimental protocol repetition, (b) the inference of the ethograms, and (c) the transfer learning from each experimental protocol repetition to the remaining repetitions. The in-house accuracy results were lower and much more variable than the out-house sessions results. In general, random forest was the best performing classifier model. Best cross-validation results, ethogram accuracy, and transfer learning were achieved from the fusion of EEG and IMUs data. Transfer learning behaved poorly compared to classification on the same protocol repetition, but it has accuracy still greater than 0.75 on average for the out-house data sessions. Transfer leaning accuracy among repetitions of the same subject was above 0.88 on average. Ethogram prediction accuracy was above 0.96 on average. Therefore, we conclude that wireless EEG and IMUs allow for the definition of natural experimental designs with high ecological validity toward human computational neuroethology research. The fusion of both EEG and IMUs signals improves activity and ethogram recognition.																	0129-0657	1793-6462				OCT	2020	30	10							2050053	10.1142/S0129065720500537													
J								A Neural Network for Image Anomaly Detection with Deep Pyramidal Representations and Dynamic Routing	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Anomaly detection; novelty detection; deep learning; semi-supervised learning		Image anomaly detection is an application-driven problem where the aim is to identify novel samples, which differ significantly from the normal ones. We here propose Pyramidal Image Anomaly DEtector (PIADE), a deep reconstruction-based pyramidal approach, in which image features are extracted at different scale levels to better catch the peculiarities that could help to discriminate between normal and anomalous data. The features are dynamically routed to a reconstruction layer and anomalies can be identified by comparing the input image with its reconstruction. Unlike similar approaches, the comparison is done by using structural similarity and perceptual loss rather than trivial pixel-by-pixel comparison. The proposed method performed at par or better than the state-of-the-art methods when tested on publicly available datasets such as CIFAR10, COIL-100 and MVTec.																	0129-0657	1793-6462				OCT	2020	30	10							2050060	10.1142/S0129065720500604													
J								Nonlinear Spiking Neural P Systems	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS										Membrane computing; spiking neural P systems; nonlinear spiking neural P systems; universality; register machines	FAULT-DIAGNOSIS; POWER; ALGORITHM; RULES	This paper proposes a new variant of spiking neural P systems (in short, SNP systems), nonlinear spiking neural P systems (in short, NSNP systems). In NSNP systems, the state of each neuron is denoted by a real number, and a real configuration vector is used to characterize the state of the whole system. A new type of spiking rules, nonlinear spiking rules, is introduced to handle the neuron's firing, where the consumed and generated amounts of spikes are often expressed by the nonlinear functions of the state of the neuron. NSNP systems are a class of distributed parallel and nondeterministic computing systems. The computational power of NSNP systems is discussed. Specifically, it is proved that NSNP systems as number-generating/accepting devices are Turing-universal. Moreover, we establish two small universal NSNP systems for function computing and number generator, containing 117 neurons and 164 neurons, respectively.																	0129-0657	1793-6462				OCT	2020	30	10							2050008	10.1142/S0129065720500082													
J								Automated Categorization of Brain Tumor from MRI Using CNN features and SVM	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Convolutional neural network; Support vector machine; Brain tumor; Computational complexity	CLASSIFICATION; IMAGES; SEGMENTATION; NETWORKS	Automated tumor characterization has a prominent role in the computer-aided diagnosis (CAD) system for the human brain. Despite being a well-studied topic, CAD of brain tumors poses severe challenges in some specific aspects. One such challenging problem is the category-based classification of brain tumors among glioma, meningioma, and pituitary tumors using magnetic resonance imaging (MRI) images. The emergence of deep learning and machine learning algorithms have addressed image classification tasks with promising results. But an associated limitation with the medical image classification is the small sizes of medical image databases. This limitation, in turn, limits the availability of medical images for training deep neural networks. To mitigate this challenge, we adopt a combination of convolutional neural network (CNN) features with support vector machine (SVM) for classification of the medical images. The fully automated system is evaluated usingFigshareopen dataset containing MRI images for the three types of brain tumors. CNN is designed to extract features from brain MRI images. For enhanced performance, a multiclass SVM is used with CNN features. Testing and evaluation of the integrated system followed a fivefold cross-validation procedure. The proposed model attained an overall classification accuracy of 95.82%, better than the state-of-the-art method. Extensive experiments are performed on other MRI datasets for the brain to ascertain the improved performance of the proposed system. When the amount of available training data is small, the SVM classifier is observed to perform better than the softmax classifier for the CNN features. Compared to transfer learning-based classification, the adopted strategy of CNN-SVM has lesser computations and memory requirements.																	1868-5137	1868-5145															10.1007/s12652-020-02568-w		OCT 2020											
J								An intelligent navigational strategy for mobile robots in uncertain environments using smart cuckoo search algorithm	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cuckoo search; Path planning; Mobile robot; Obstacle avoidance; PSO; Khepera robot	NEURO-FUZZY CONTROLLER; LOGIC	This paper presents the implementation of smart cuckoo search (SCS) algorithm for intelligent path planning of mobile robots. A new fitness function is modeled and optimized by SCS algorithm to generate collision free optimal route for the mobile robots. The simulation results are illustrated to verify the ability of robot to deal with different environment conditions and reach to the target in all the time. Also the results obtained using SCS algorithm is compared with results of Adaptive Particle Swarm Optimization (APSO). It is noticed that SCS algorithm showed better results as compared to APSO. Finally the simulation platform results are validated with Khepera-IV mobile robot experimental results and it is revealed that proposed algorithm is valid and feasible in the mobile robot path planning problems.																	1868-5137	1868-5145															10.1007/s12652-020-02535-5		OCT 2020											
J								Prediction of mortality of premature neonates using neural network and logistic regression	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Neural networks; Logistic regression; Premature neonate; Mortality	RISK	Neonatal mortality is one of the important health indicators and mortality prediction is applied for auditing and benchmarking, comparing the outcomes in neonatal intensive care units (NICUs), controlling individual differences in populations in clinical trials and evaluating efficacy. In this research work, we aimed to establish and compare two models (neural network and logistic regression models) for prediction of mortality in premature neonates upon admission to the NICU. This modeling research was conducted based on the information of 1618 neonates for prediction of mortality risk until the 28th day of life. In total, 80% and 20% of the data were considered for training and testing of the designed models, respectively. Finally, we achieved to predict the probability of infant mortality based on the 5th minute after birth data. Modeling was performed with two methods; neural network [multi layer perceptron (MLP) with education of back-propagation (BP)] and logistic regression (binominal form in MATLAB R2016a). The results showed that the MLP (with 60 neurons in the hidden layer) had more acceptable indices compared to logistic regression. While both neural network and logistic regression were able to predict the neonatal mortality risk, the neural network is more effective than logistic regression model in performance comparison.																	1868-5137	1868-5145															10.1007/s12652-020-02562-2		OCT 2020											
J								Collaborating AI and human experts in the maintenance domain	AI & SOCIETY										Industry 4; 0; Maintenance; Decision support; Situation awareness; Collaboration; Augmented reality	DECISION-SUPPORT-SYSTEM; SITUATION AWARENESS; AUGMENTED REALITY; COGNITIVE FIT; MODELS; ERGONOMICS; INTUITION; KNOWLEDGE; WORK; RISK	Maintenance decision errors can result in very costly problems. The 4th industrial revolution has given new opportunities for the development of and use of intelligent decision support systems. With these technological advancements, key concerns focus on gaining a better understanding of the linkage between the technicians' knowledge and the intelligent decision support systems. The research reported in this study has two primary objectives. (1) To propose a theoretical model that links technicians' knowledge and intelligent decision support systems, and (2) to present a use case how to apply the theoretical model. The foundation of the new model builds upon two main streams of study in the decision support literature: "distribution" of knowledge among different agents, and "collaboration" of knowledge for reaching a shared goal. This study resulted in the identification of two main gaps: firstly, there must be a greater focus upon the technicians' knowledge; secondly, technicians need assistance to maintain their focus on the big picture. We used the cognitive fit theory, and the theory of distributed situation awareness to propose the new theoretical model called "distributed collaborative awareness model." The model considers both explicit and implicit knowledge and accommodates the dynamic challenges involved in operational level maintenance. As an application of this model, we identify and recommend some technological developments required in augmented reality based maintenance decision support.																	0951-5666	1435-5655															10.1007/s00146-020-01076-x		OCT 2020											
J								A systematic mapping study for ensemble classification methods in cardiovascular disease	ARTIFICIAL INTELLIGENCE REVIEW										Cardiovascular; Cardiology; Heart disease; Classification; Ensemble methods; Machine learning; Data mining	CORONARY-ARTERY-DISEASE; HEART-DISEASE; NEURAL-NETWORKS; KNOWLEDGE DISCOVERY; DIAGNOSIS; CLASSIFIERS; ELECTROCARDIOGRAM; PREDICTION; DIVERSITY; ALGORITHM	Ensemble methods overcome the limitations of single machine learning techniques by combining different techniques, and are employed in the quest to achieve a high level of accuracy. This approach has been investigated in various fields, one of them being that of bioinformatics. One of the most frequent applications of ensemble techniques involves research into cardiovascular diseases, which are considered the leading cause of death worldwide. The purpose of this research work is to identify the papers that investigate ensemble classification techniques applied to cardiology diseases, and to analyse them according to nine aspects: their publication venues, the medical tasks tackled, the empirical and research types adopted, the types of ensembles proposed, the single techniques used to construct the ensembles, the validation frameworks adopted to evaluate the proposed ensembles, the tools used to build the ensembles, and the optimization methods employed for the single techniques. This paper reports the carrying out of a systematic mapping study. An extensive automatic search in four digital libraries: IEEE Xplore, ACM Digital Library, PubMed, and Scopus, followed by a study selection process, resulted in the identification of 351 papers that were used to address our mapping questions. This study found that the papers selected had been published in a large number of different resources. The medical task addressed most frequently by the selected studies was diagnosis. In addition, the experiment-based empirical type and evaluation-based research type were the most dominant approaches adopted by the selected studies. Homogeneous ensembles were the ensemble type that was developed most often in literature, while decision trees, artificial neural networks and Bayesian classifiers were the single techniques used most frequently to develop ensemble classification methods. The weighted majority and majority voting rules were adopted to obtain the final decision of the ensembles developed. With regard to evaluation frameworks, the datasets obtained from the UCI and PhysioBank repositories were those used most often to evaluate the ensemble methods, while the k-fold cross-validation method was the most frequently-employed validation technique. Several tools with which to build ensemble classifiers were identified, and the type of software adopted with the greatest frequency was open source. Finally, only a few researchers took into account the optimization of the parameter settings of either single or meta ensemble classifiers. This mapping study attempts to provide a greater insight into the application of ensemble classification methods in cardiovascular diseases. The majority of the selected papers reported positive feedback as regards the ability of ensemble methods to perform better than single methods. Further analysis is required to aggregate the evidence reported in literature.																	0269-2821	1573-7462															10.1007/s10462-020-09914-6		OCT 2020											
J								Laplacian regularized low-rank sparse representation transfer learning	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Transfer learning; Representation matrix reconstruction; Regularization; Subspace learning	DOMAIN ADAPTATION; FUZZY SYSTEM; RECOGNITION	In unsupervised transfer learning, it is extremely valuable to effectively extract knowledge from the vast amount of untagged data that exists by utilizing tagged data from other similar databases. In general, the data in the real world often resides in the low-dimensional manifold embedded in the high-dimensional environment space. However, the current subspace transfer learning methods do not consider the nonlinear geometry structure inside the data, so the local similarity information between the data may be lost in the learning process. In order to improve this respect, we propose a new subspace transfer learning algorithm, namely Laplacian Regularized Low-Rank Sparse Representation Transfer Learning (LRLRSR-TL). After introducing the low-rank representation and sparse constraints, the method incorporates Laplacian regularization term to represent the global low-dimensional structure and capture the inherent nonlinear geometry information of the data. Experimental investigation conducted based on five different cross-domain visual image datasets shows that the proposed method has outstanding performance compared with several state-of-the-art transfer learning methods.																	1868-8071	1868-808X															10.1007/s13042-020-01203-6		OCT 2020											
J								An improved TODIM method based on the hesitant fuzzy psychological distance measure	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Hesitant fuzzy set; Psychological distance measure; TODIM; Decision making	ROUGH SET MODEL; SIMILARITY; IDENTIFICATION; ATTENTION	The distance measure plays an important role in the hesitant fuzzy theory. Experts always focus on the attributes aggregation of hesitant fuzzy information, ignoring the preference relationships between alternatives. Therefore, it is necessary to consider the competition effect between alternatives and develop a more suitable distance measure. Considering the background information of the connections and competitive relationships between different alternatives, the hesitant fuzzy psychological distance measure is proposed. Based on which, a novel similarity measure for hesitant fuzzy information is also developed. Next, an improved TODIM based on the hesitant fuzzy psychological distance measure is proposed for decision making problems. At last but not least, we apply the proposed improved TODIM to the application of the temporary rescue airport decision making problem of the Arctic Northwest Passage. The results demonstrate the advantages of the proposed method in decision making under the hesitant fuzzy environment.																	1868-8071	1868-808X															10.1007/s13042-020-01215-2		OCT 2020											
J								An Intelligent prediction model for UCG state based on dual-source LSTM	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS										Equivalent; LSTM; Prediction; Underground coal gasification	UNDERGROUND COAL-GASIFICATION; FIRE RISK PREVENTION; ALTERNATING INJECTION; NEURAL-NETWORKS; ENERGY; MEMORY; STRATEGY; OXYGEN; STEAM	Underground coal gasification (UCG) is a serious attempt to clean and efficient use of coal, but it has not been able to solve the problem of stable production. Predicting UCG can provide effective guidance for control, which effectively solves this problem. Existing UCG prediction models are not accurate, and most of them can only predict a single variable, and cannot adequately predict the UCG state. The paper proposes the concept of combustible gas equivalents that can characterize the concentration of mixed gas through stoichiometry and material balance equations. The equivalent gradient is introduced to characterize the trends in equivalent, and the UCG state discrimination standard is established to evaluate the UCG state. Eventually, a dual-source long short-term memory (LSTM) prediction model is proposed for predicting UCG state. The experimental results show that compared with Support Vector Machine (SVM) and Back Propagation Neural Network (BPNN) prediction model, the model can make a better prediction of equivalent value and the accuracy of predicting trends in equivalent reaches 90.99%.																	1868-8071	1868-808X															10.1007/s13042-020-01210-7		OCT 2020											
J								An effective adaptive adjustment method for service composition exception handling in cloud manufacturing	JOURNAL OF INTELLIGENT MANUFACTURING										Cloud manufacturing; Strict time constraints; Service-composition exception handling adaptive adjustment model; Service-composition exception handling adaptive adjustment algorithm (SCEHAA); Reconfiguration	ANT COLONY OPTIMIZATION; ALGORITHM; SELECTION; PLATFORM; QOS	With the increasing market features of globalization, service and customization, the way manufacturers conduct manufacturing business is changing. Under this background, Cloud Manufacturing (CMfg) emerges as a new networked manufacturing model. However, CMfg is immature in many aspects, especially in exception handling of service composition execution. Due to the complexity of the enterprise manufacturing process, there are a large number of unpredictable abnormal events in the dynamic open cloud manufacturing environment (such as user demand change, machine failure, etc.), so in order to ensure the smooth implementation of the service combination, it is indispensable to establish an effective service exception handling mechanism in CMfg. Moreover, when an exception occurs, in order to ensure the smooth execution of the downstream services after the exception point, the exception handling must satisfy the strict time constraints. To realize the exception-handing of service-composition with the strict deadline or strict time constraints, this paper proposes a service-composition exception adaptive adjustment model, considering the influences of the logistics transferring time and cost. And the occupied time of the cloud services and the valid replacement time range of the exception service are considered as the constraints in this model. In addition, the processing quality, the cost, and the quality of service are set as the optimal objectives. On the above basis, a service-composition exception handling adaptive adjustment (SCEHAA) algorithm based on the improved ant colony optimization algorithm (ACO) is proposed and applied to address the above model. Finally, to validate the performance of SCEHAA, a case study and the comparison experiment between SCEHAA and other algorithms (Particle Swarm Optimization and Artificial Bee Colony) are performed. The results show that the SCEHAA algorithm can perform the adaptive adjustment of the service-composition with strict time limit effectively, through the adaptive service execution path reconfiguration and has fast convergence effects.																	0956-5515	1572-8145															10.1007/s10845-020-01652-4		OCT 2020											
J								ROPDet: real-time anchor-free detector based on point set representation for rotating object	JOURNAL OF REAL-TIME IMAGE PROCESSING										Remote-sensing image; Object detection; Arbitrary direction; RoPoints	SALIENCY DETECTION; CO-SEGMENTATION	Remote-sensing object detection is a challenging task due to the difficulties of separating the objects with arbitrary direction from complex backgrounds. Though substantial progress has been made, there still exist challenges for object detection under the scenario of small scale, large aspect ratio, and dense distribution. Besides, the current mainstream approach falls under anchor-based multi-stage method, which has a serious shortcoming of slower inference speed. To conquer the aforementioned issues, this paper used RoPoints (points in rotation objects), a new better representation of objects as a set of sample points to perform object localization and classification. Then, we propose an anchor-free refined rotation detector:ROPDet based on RoPoints for more accurate and faster object detection. In our method, there is no need to predefine a large number anchors with different shapes. We only need to learn RoPoints for each object followed by converting to the corresponding bounding box, which greatly accelerates the inference process. Extensive experiments on two public remote-sensing datasets DOTA and HRSC-2016 demonstrate the competitive ability in terms of accuracy and inference speed.																	1861-8200	1861-8219															10.1007/s11554-020-01013-7		OCT 2020											
J								Artificial Intelligence, Values, and Alignment	MINDS AND MACHINES										Artificial intelligence; Machine learning; Value alignment; Moral philosophy; Political theory	FAIR	This paper looks at philosophical questions that arise in the context of AI alignment. It defends three propositions. First, normative and technical aspects of the AI alignment problem are interrelated, creating space for productive engagement between people working in both domains. Second, it is important to be clear about the goal of alignment. There are significant differences between AI that aligns with instructions, intentions, revealed preferences, ideal preferences, interests and values. A principle-based approach to AI alignment, which combines these elements in a systematic way, has considerable advantages in this context. Third, the central challenge for theorists is not to identify 'true' moral principles for AI; rather, it is to identify fair principles for alignment that receive reflective endorsement despite widespread variation in people's moral beliefs. The final part of the paper explores three ways in which fair principles for AI alignment could potentially be identified.																	0924-6495	1572-8641															10.1007/s11023-020-09539-2		OCT 2020											
J								Refocused Attention: Long Short-Term Rewards Guided Video Captioning	NEURAL PROCESSING LETTERS										Video captioning; Hierarchical attention; Reinforcement learning; Reward		The adaptive cooperation of visual model and language model is essential for video captioning. However, due to the lack of proper guidance for each time step in end-to-end training, the over-dependence of language model often results in the invalidation of attention-based visual model, which is called 'Attention Defocus' problem in this paper. Based on an important observation that the recognition precision of entity word can reflect the effectiveness of the visual model, we propose a novel strategy called refocused attention to optimize the training and cooperating of visual model and language model, using ingenious guidance at appropriate time step. The strategy consists of a short-term-reward guided local entity recognition and a long-term-reward guided global relation understanding, neither requires any external training data. Moreover, a framework with hierarchical visual representations and hierarchical attention is established to fully exploit the potential strength of the proposed learning strategy. Extensive experiments demonstrate that the ingenious guidance strategy together with the optimized structure outperform state-of-the-art video captioning methods with relative improvements 7.7% in BLEU-4 and 5.0% in CIDEr-D on MSVD dataset, even without multi-modal features.																	1370-4621	1573-773X				OCT	2020	52	2			SI		935	948		10.1007/s11063-019-10030-y													
J								An Abstract Painting Generation Method Based on Deep Generative Model	NEURAL PROCESSING LETTERS										Generative art; Depth generation model; Abstract painting CoCBs	ART	Computer technology provides new conditions and possibilities for art creation and research, and also expands the forms of artistic expression. Computer-created art has thus become one of the important forms of art. In this paper, we proposed a novel method of generating abstract paintings. We used the public painting dataset WikiArt and designed aK-Means algorithm that automatically finds the optimalKvalue to perform color segmentation on these images, and divide the picture into different color blocks. We proposed the concept of the collection of color block (CoCB), which records all color block information of the segmented image and serves as an intermediate vector for the generation of abstract painting. We extracted the CoCB as an empirical sample and used a learning model based on deep learning to automatically generate brand-new CoCBs. We then converted the CoCBs into an abstract painting, so that the generated abstract painting also followed certain aesthetic rules. Experiments showed that the resulting abstract painting have great visual impact, and some of them have been installed as decorations in public and private spaces, as well as art institutions. Also, some artists and designers have used the results in their work.																	1370-4621	1573-773X				OCT	2020	52	2			SI		949	960		10.1007/s11063-019-10063-3													
J								A Multi-modality Sensor System for Unmanned Surface Vehicle	NEURAL PROCESSING LETTERS										Multi-modality sensor; Unmanned Surface Vehicle; Object detection; Sensor calibration		The onboard multi-modality sensors significantly expand perception ability of Unmanned Surface Vehicle (USV). This paper aims to fully utilize various onboard sensors and enhance USV's object detection performance. We solve several unique challenges for application of USV multi-modality sensor system in the complex maritime environment. By utilizing deep learning networks, we achieved accurate object detection on water surface. We firstly propose a multi-modality sensor calibration method. The network fuses RGB images with multiple point clouds from various sensors. The well-calibrated image and point cloud are input to our deep object detection network, and conduct 3D detection through proposal generation network and object detection network. Meanwhile, we made a series of improvements to the system framework, which accelerate the detection procedures. We collected two datasets from the real-world offshore field and the simulation scenes respectively. The experiments on both datasets showed valid calibration results. On this basis, our object detection network achieves better accuracy than other methods. The performance of the proposed multi-modality sensor system meets the application requirement of our prototype USV platform.																	1370-4621	1573-773X				OCT	2020	52	2			SI		977	992		10.1007/s11063-019-09998-4													
J								Hierarchical Temporal Fusion of Multi-grained Attention Features for Video Question Answering	NEURAL PROCESSING LETTERS										Video question answering; Multi-grained representation; Temporal co-attention		This work aims to address the problem of video question answering (VideoQA) with a novel model and a new open-ended VideoQA dataset. VideoQA is a challenging field in visual information retrieval, which aims to generate the answer according to the video content and question. Ultimately, VideoQA is a video understanding task. Efficiently combining the multi-grained representations is the key factor in understanding a video. The existing works mostly focus on overall frame-level visual understanding to tackle the problem, which neglects finer-grained and temporal information inside the video, or just combines the multi-grained representations simply by concatenation or addition. Thus, we propose the multi-granularity temporal attention network that enables to search for the specific frames in a video that are holistically and locally related to the answer. We first learn the mutual attention representations of multi-grained visual content and question. Then the mutually attended features are combined hierarchically using a double layer LSTM to generate the answer. Furthermore, we illustrate several different multi-grained fusion configurations to prove the advancement of this hierarchical architecture. The effectiveness of our model is demonstrated on the large-scale video question answering dataset based on ActivityNet dataset.																	1370-4621	1573-773X				OCT	2020	52	2			SI		993	1003		10.1007/s11063-019-10003-1													
J								Construction of Retinal Vessel Segmentation Models Based on Convolutional Neural Network	NEURAL PROCESSING LETTERS										Retinal blood vessel; Segmentation; Convolutional neural networks (CNN); Modified CNN	BLOOD-VESSELS; IMAGES; ALGORITHM; TRACKING	Segmentation of retinal vessels in fundus images plays a very important role in diagnosing relevant diseases. In this paper, we have constructed automated segmentation models for the retinal vessel segmentation task based on convolutional neural networks. Since some typical deep convolutional neural networks need to be fed by high-resolution patches, small retinal patches should be interpolated to the specific resolution. The interpolated patches sometimes would introduce additional noises. Thus, we modify some typical deep architectures by inserting a set of convolutional layers. In this way, our models have the ability to adapt to different resolutions. Overall, five models are analyzed and compared in our studies including LeNet, M-AlexNet (modified AlexNet), M-ZF-Net (Modified ZF-Net), M-VGG (Modified VGG) and Deformable-ConvNet. Deformable-ConvNet captures the vascular structure and is used to do the retinal vessel segmentation task for the first time. We train the models from scratch and compare their ability to discriminate vessels/non-vessel pixels on two retinal fundus image datasets, DRIVE and STARE. Results are analyzed and compared in our studies. We obtain the highest accuracy of 0.9628/0.9690, lowest loss of 0.1045/0.0968, and highest AUC of 0.9764/0.9844 on DRIVE/STARE respectively. We also compare the CNN models with other segmentation methods. The results demonstrate the high effectiveness of the CNN-based approaches.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1005	1022		10.1007/s11063-019-10011-1													
J								Pairwise Generalization Network for Cross-Domain Image Recognition	NEURAL PROCESSING LETTERS										Cross-domain; Image recognition; Pairwise		In recent years, convolutional neural networks have received increasing attention from the computer vision and machine learning communities. Due to the differences in the distribution, tone and brightness of the training domain and test domain, researchers begin to focus on cross-domain image recognition. In this paper, we propose a Pairwise Generalization Network (PGN) for addressing the problem of cross-domain image recognition where Instance Normalization and Batch Normalization are added to enhance their abilities in the original domain and to expand to the new domain. Meanwhile, the Siamese architecture is utilized in the PGN to learn an embedding subspace that is discriminative, and map positive sample pairs aligned and negative sample pairs separated, which can work well even with only few labeled target data samples. We also add residual architecture and MMD loss for the PGN model to further improve its performance. Extensive experiments on two different public benchmarks show that our PGN solution significantly outperforms the state-of-the-art methods.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1023	1041		10.1007/s11063-019-10041-9													
J								Hierarchical Deep Neural Network for Image Captioning	NEURAL PROCESSING LETTERS										Regional semantic; Image captioning; Attention mechanism	MODEL	Automatically describing image content with natural language is a fundamental challenge for computer vision community. General methods used visual information to generate sentences directly. However, only depending on the visual information is not enough to generate the fine-grained descriptions for given images. In this paper, we exploit the fusion of visual information and high-level semantic information for image captioning. We propose a hierarchical deep neural network, which consists of the bottom layer and the top layer. The former extracts the visual and high-level semantic information from image and detected regions, respectively, while the latter integrates both of them with adaptive attention mechanism for the caption generation. The experimental results achieve the competing performances against the state-of-the-art methods on MSCOCO dataset.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1057	1067		10.1007/s11063-019-09997-5													
J								Bearing fault diagnostic using machine learning algorithms	PROGRESS IN ARTIFICIAL INTELLIGENCE										Bearing damage detection; Machine fault diagnostic; Vibration; Motor current signal; Machine learning algorithm; Neural networks; Genetic algorithm	ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; GENETIC ALGORITHM; DAMAGE DETECTION; VIBRATION; DEFECTS; SYSTEM	This study aims to enhance the condition monitoring of external ball bearings using the raw data provided by Paderborn University which provided sufficient data for motor current signal MCS. Three classes of bearings have been used: healthy bearings, bearings with an inner race defect, and bearings with outer race defect. Online data at different operating conditions, bearings, and faults extent of artificial and real damages have been chosen to provide the generalization and robustness of the model. After proper preprocessing to the raw data of vibration and MCS, time, frequency, and time-frequency domain features have been extracted. Then, optimal features have been selected using genetic algorithm. Artificial neural network with optimized structure using genetic algorithm has been implemented. A comparison between the performance of vibration and motor current signal has been presented. Moreover, our results are compared to previous work by using the same raw data. Results showed the potential of motor current signal in bearing fault diagnosis with high classification accuracy. Moreover, the results showed the possibility to provide a promised diagnostic model that can diagnose bearings of real faults with different fault severities using MCS.																	2192-6352	2192-6360															10.1007/s13748-020-00217-z		OCT 2020											
J								BMDA: applying biogeography-based optimization algorithm and Mexican hat wavelet to improve dragonfly algorithm	SOFT COMPUTING										Dragonfly algorithm; Biogeography-based optimization algorithm; Mexican hat wavelet	SEARCH ALGORITHM; PARTICLE SWARM; TABLES; TESTS	One of the methods for solving optimization problems is applying metaheuristic algorithms that find near to optimal solutions. Dragonfly algorithm is one of the metaheuristic algorithms which search problem space by the inspiration of hunting and emigration behavior of dragonflies in nature. However, it suffers from the premature convergence of the population to an undesirable point in the detection ability (global search). In this research, an improved dragonfly algorithm called BMDA (applying Biogeography-based algorithm, Mexican hat wavelet, and Dragonfly algorithm) is presented to resolve the premature convergence in high workloads by creating a mutation phase based on the combination of the biogeography-based optimization (BBO) migration process and the Mexican hat wavelet transform in dragonfly algorithm (DA). The algorithm was evaluated for the mean error in comparison with standard dragonfly algorithm (DA), Memory-based Hybrid Dragonfly Algorithm (MHDA), chaotic dragonfly algorithm version 9 (CDA9), Adaptive_DA algorithm, bat algorithm (BAT), particle swarm optimization algorithm (PSO), raven roosting optimization (RRO) and whale optimization algorithm (WOA) using the CEC2017 benchmark functions. The implementation results of the proposed BMDA algorithm applying different benchmark functions outweighed the DA-based algorithm, MHDA algorithm, CDA9 algorithm, Adaptive_DA algorithm, BAT algorithm, PSO algorithm, RRO, and WOA algorithms in terms of mean error.																	1432-7643	1433-7479				NOV	2020	24	21					15979	16004		10.1007/s00500-020-05340-6		OCT 2020											
J								Computational procedure for solving fuzzy equations	SOFT COMPUTING										Fuzzy arithmetics; Fuzzy equation; Extension principle (EP); Transmission average (TA)	THINKING	The classical methods for solving fuzzy equations are very limited because, often, there are no solutions or very strong conditions for the equations it is placed to have a solution. In addition, the solution's support obtained in these methods is large. All of this is due to the consideration of operations related to equations based on the principle of extension, which is due to the absence of ineffective members. These high points are our motive for achieving a new approach to solving fuzzy equations. We will solve the fuzzy equations, taking into account the fuzzy operations involved in the equation based on the transmission average by Abbasi et al. (J Intell Fuzzy Syst 29:851-861, 2015). In this paper, a computational procedure is proposed to solve the fuzzy equations that meets the defects of previous techniques, specially reluctant to question whether the answer is valid in the equation. The proposed approach is implemented on the fuzzy equations as AX + B = C, AX(2) + BX + C = D, AX(3) + BX2 = CX. At the end, it is shown that the solution of the proposed method in comparison with other methods of solving fuzzy equations are more realistic, that is, they have smaller support.																	1432-7643	1433-7479															10.1007/s00500-020-05330-8		OCT 2020											
J								A new emergency response of spherical intelligent fuzzy decision process to diagnose of COVID19	SOFT COMPUTING										Spherical fuzzy set; Intelligent decision support systems; Emergency decision making of COVID-19; Critical path problems	AGGREGATION OPERATORS; SETS; TOPSIS; WEIGHTS; PROJECT	The control of spreading of COVID-19 in emergency situation the entire world is a challenge, and therefore, the aim of this study was to propose a spherical intelligent fuzzy decision model for control and diagnosis of COVID-19. The emergency event is known to have aspects of short time and data, harmfulness, and ambiguity, and policy makers are often rationally bounded under uncertainty and threat. There are some classic approaches for representing and explaining the complexity and vagueness of the information. The effective tool to describe and reduce the uncertainty in data information is fuzzy set and their extension. Therefore, we used fuzzy logic to develop fuzzy mathematical model for control of transmission and spreading of COVID19. The fuzzy control of early transmission and spreading of coronavirus by fuzzy mathematical model will be very effective. The proposed research work is on fuzzy mathematical model of intelligent decision systems under the spherical fuzzy information. In the proposed work, we will develop a newly and generalized technique for COVID19 based on the technique for order of preference by similarity to ideal solution (TOPSIS) and complex proportional assessment (COPRAS) methods under spherical fuzzy environment. Finally, an illustrative the emergency situation of COVID-19 is given for demonstrating the effectiveness of the suggested method, along with a sensitivity analysis and comparative analysis, showing the feasibility and reliability of its results.																	1432-7643	1433-7479															10.1007/s00500-020-05287-8		OCT 2020											
J								Hybrid gradient simulated annealing algorithm for finding the global optimal of a nonlinear unconstrained optimization problem	SOFT COMPUTING										Nonlinear function; Unconstrained minimization; Hybrid algorithm; Global optima; Gradient method; Line search; Meta-heuristics; Simulated annealing; Numerical comparisons; Test problems	PARTICLE SWARM OPTIMIZATION; SEARCH; MINIMIZATION	A new hybrid gradient simulated annealing algorithm is introduced. The algorithm is designed to find the global minimizer of a nonlinear function of many variables. The function is assumed to be smooth. The algorithm uses the gradient method together with a line search to ensure convergence from a remote starting point. It is hybridized with a simulated annealing algorithm to ensure convergence to the global minimizer. The performance of the algorithm is demonstrated through extensive numerical experiments on some well-known test problems. Comparisons of the performance of the suggested algorithm and other meta-heuristics methods were reported. It validates the effectiveness of our approach and shows that the suggested algorithm is promising and merits to be implemented in practice.																	1432-7643	1433-7479															10.1007/s00500-020-05303-x		OCT 2020											
J								Double-hierarchy hesitant fuzzy linguistic term set-based decision framework for multi-attribute group decision-making	SOFT COMPUTING										Double-hierarchy hesitant fuzzy linguistic term set; Group decision making; Green supplier selection; Optimization model; VIKOR ranking method	COMPROMISE SOLUTION; MULTIMOORA METHOD; VIKOR METHOD; SELECTION; RESOURCES; OPERATORS; ENTROPY; AHP; CONSENSUS; MODEL	With massive growth in decision-making theory, representation of preference information plays an indispensable role. To rationally handle uncertainty, scholars presented different ideas of which hesitant fuzzy linguistic term set (HFLTS) is a good choice to represent hesitancy in decision makers' (DMs) preferences. The challenge with HFLTS is that it cannot be used for representing complex linguistic terms. To better circumvent this challenge, double-hierarchy HFLTS (DHHFLTS) is presented. Motivated by the power of DHHFLTS in expressing complex linguistic terms by using two linguistic hierarchies, a decision framework is proposed under the DHHFLTS context. Initially, the framework presents a new aggregation operator called simple double-hierarchy frequency match aggregation operator for sensible aggregation of DMs' preference information. Later, the mathematical programming model is extended under the DHHLTS context for rational estimation of attribute weight with partially known information. Also, the popular Vise Kriterijumska Optimizacija Kompromisno Resenje ranking method is extended under the DHHFLTS context for the selection of a suitable object from the set of objects. Finally, the proposed decision framework is validated for its practicality by demonstrating two numerical examples viz., green supplier selection problem and renewable energy source selection problem. Also, the strengths and weaknesses of the proposed framework are realized by comparison with other methods.																	1432-7643	1433-7479															10.1007/s00500-020-05328-2		OCT 2020											
J								Multi-objective learning backtracking search algorithm for economic emission dispatch problem	SOFT COMPUTING										Backtracking search algorithm; Environmental; economic dispatch; Multi-objective optimization	MULTITYPE DISTRIBUTED GENERATORS; OPTIMAL POWER-FLOW; GENETIC ALGORITHM; EVOLUTIONARY ALGORITHMS; OPTIMIZATION ALGORITHM; ALLOCATION; SYSTEMS; COST	The backtracking search algorithm (BSA) as a novel intelligent optimizer belongs to population-based evolutionary algorithms. In this paper, a multi-objective learning backtracking search algorithm (MOLBSA) is proposed to solve the environmental/economic dispatch (EED) problem. In this algorithm, we design two novel learning strategies: a leader-choosing strategy, which takes a sparse solution from an external archive as leader; a leader-guiding strategy, which updates individuals with the guidance of leader. These two learning strategies have outstanding performance in improving the uniformity and diversity of obtained Pareto front. The extreme solutions, compromise solution and three metrics obtained by MOLBSA are further compared with those of well-known multi-objective optimization algorithms in IEEE 30-bus 6-unit test system and 10-unit test system. Simulation results demonstrate the capability of MOLBSA in generating well-distributed and high-quality approximation of true Pareto front for the EED problem.																	1432-7643	1433-7479															10.1007/s00500-020-05312-w		OCT 2020											
J								A multi-period fuzzy mean-minimax risk portfolio model with investor's risk attitude	SOFT COMPUTING										Fuzzy portfolio selection; Risk attitude; l(infinity) downside risk; Diversification constraint; Multiple particle swarm optimization	LOWER PARTIAL MOMENT; SELECTION MODEL; OPTIMIZATION; ENTROPY; UTILITY	This paper deals with a multi-period portfolio selection problem considering investor's risk attitude in fuzzy environment. We regard the return rate of each risky asset as a fuzzy number and use the expected value and semi-absolute deviation to measure its return and risk, respectively. We adopt an l(infinity) downside risk function to measure the portfolio's risk, which is represented by the maximum individual risk. Moreover, we formulate a reasonable diversification constraint for the portfolio involving risk-free asset. Then, we propose a multi-period portfolio selection model with the objectives of maximizing the final expected wealth and minimizing the final cumulative risk. Furthermore, we design a multiple particle swarm optimization to solve it. Finally, we illustrate the effectiveness of the model and algorithm by using a real case.																	1432-7643	1433-7479															10.1007/s00500-020-05351-3		OCT 2020											
J								Personalised rating	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS										Trust and reputation; Social networks; Bribery and strategic behaviour; Computational social choice	REPUTATION	We introduce personalised rating, a network-based rating system where individuals, connected in a social network, decide whether or not to consume a service (e.g., a restaurant) based on the evaluations provided by their peers. We compare personalised rating with the more widely used objective rating where, instead, customers receive an aggregate evaluation of what everybody else has declared so far. We focus on the manipulability of such systems, allowing a malicious service provider (e.g., the restaurant owner) to transfer monetary incentive to the individuals in order to manipulate their rating and increase the overall profit. We study manipulation under various constraints, such as the proportion of individuals who evaluate the service and, in particular, how much the attacker knows of the underlying customers' network, showing the conditions under which the system is bribery-proof, i.e., no manipulation strategy yields a strictly positive expected gain to the service provider. We also look at manipulation strategies that are feasible in theory but might, in general, be infeasible in practice, deriving a number of algorithmic properties of manipulation under personalised rating. In particular we show that establishing the existence of a rewarding manipulation strategy for the attacker-and, notably, an optimal one-isNP-complete, even with full knowledge of the underlying network structure.																	1387-2532	1573-7454				OCT 1	2020	34	2							55	10.1007/s10458-020-09479-2													
J								A hybrid recurrent neural network-logistic chaos-based whale optimization framework for heart disease prediction withelectronic health records	COMPUTATIONAL INTELLIGENCE										electronic health records; heart disease prediction; logistic chaos; long short-term memory; recurrent neural network; wolf optimization algorithm	RISK; SYSTEM; ALGORITHM; RELIABILITY; FAILURE	Heart disease, known interchangeably as "Cardio Vascular Disease," blocks the blood vessels in the heart and causes heart attack, chest pain, and stroke. Heart disease is one of the leading causes of morbidity and mortality worldwide and it is one of the major causes of morbidity and mortality globally and a trending topic in clinical data analysis. Assessing risk factors related to heart disease is considered as an important step in diagnosing the disease at an early stage. Clinical data present in the form of electronic health records (EHR) can be extracted with the aid of machine learning (ML) algorithms to provide valuable decisions and predictions. ML approaches also play a vital role in early diagnosis and therapeutic monitoring of heart disease. Several research works have been carried out recently to predict heart disease. To this end, we propose a novel hybrid recurrent neural network (RNN)-logistic chaos-based whale optimization (LCBWO) structured hybrid framework for predicting heart disease within 5 years using EHR data. Meanwhile, in the hybrid model established multilayer bidirectional LSTM is used for feature selection, LCBWO algorithm for structural improvement and fast convergence, and LSTM for disease prediction. This research used 10 cross-validations to obtain generalized accuracy and error values. The findings and observations provided here are focused on the knowledge obtained from the EHR report. The results show that the proposed novel hybrid RNN-LCBWO framework achieves a higher accuracy of 98%, a specificity of 99%, precision of 96%,Mathews correlation coefficientof 91%, F-measure of 0.9892, an area under the curve value of 98%, and a prediction time of 9.23 seconds. The accurate predictions obtained from the comparative analysis shows the significant performance of our proposed framework.																	0824-7935	1467-8640															10.1111/coin.12405		OCT 2020											
J								Approximating Complex Pareto Fronts With Predefined Normal-Boundary Intersection Directions	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Shape; Mirrors; Evolutionary computation; Pareto optimization; Sociology; Decomposition; evolutionary many-objective optimization; irregular Pareto fronts (PFs); normal-boundary intersection (NBI) directions	MANY-OBJECTIVE OPTIMIZATION; NONDOMINATED SORTING APPROACH; EVOLUTIONARY ALGORITHM; PERFORMANCE; DESIGN; MOEA/D	Decomposition-based evolutionary algorithms using predefined reference points have shown good performance in many-objective optimization. Unfortunately, almost all experimental studies have focused on problems having regular Pareto fronts (PFs). Recently, it has been shown that the performance of such algorithms is deteriorated when facing irregular PFs, such as degenerate, discontinuous, inverted, strongly convex, and/or strongly concave fronts. The main issue is that the predefined reference points may not all intersect with the PF. Therefore, many researchers have proposed to update the reference points with the aim of adapting them to the discovered Pareto shape. Unfortunately, the adaptive update does not really solve the issue for two main reasons. On the one hand, there is a considerable difficulty to set the time and the frequency of updates. On the other hand, it is not easy to define how to update the search directions for an unknown PF shape. This article proposes to approximate irregular PFs using a set of predefined normal-boundary intersection (NBI) directions. The main motivation behind this article is that when using a set of well-distributed NBI directions, all these directions intersect with the PF regardless of its shape, except for the case of discontinuous and/or degenerate fronts. To handle the latter cases, a simple interaction mechanism between the decision maker (DM) and the algorithm is used. In fact, the DM is asked if the number of NBI directions needs to be increased in some stages of the evolutionary process. If so, the resolution of the NBI directions that intersect the PF is increased to properly cover discontinuous and/or degenerate PFs. Our experimental results on benchmark problems with regular and irregular PFs, having up to fifteen objectives, show the merits of our algorithm when compared to eight of the most representative state-of-the-art algorithms.																	1089-778X	1941-0026				OCT	2020	24	5					809	823		10.1109/TEVC.2019.2958921													
J								Multiobjective Multitasking Optimization Based on Incremental Learning	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Task analysis; Optimization; Knowledge transfer; Evolutionary computation; Heuristic algorithms; Problem-solving; Cloud computing; Evolutionary algorithms; incremental learning; knowledge transfer; multitask optimization	EVOLUTIONARY MULTITASKING; GENETIC ALGORITHM	Multiobjective multitasking optimization (MTO) is an emerging research topic in the field of evolutionary computation. In contrast to multiobjective optimization, MTO solves multiple optimization tasks simultaneously. MTO aims to improve the overall performance of multiple tasks through knowledge transfer among tasks. Recently, MTO has attracted the attention of many researchers, and several algorithms have been proposed in the literature. However, one of the crucial issues, finding useful knowledge, has been rarely studied. Keeping this in mind, this article proposes an MTO algorithm based on incremental learning (EMTIL). Specifically, the transferred solutions (the form of knowledge) will be selected by incremental classifiers, which are capable of finding valuable solutions for knowledge transfer. The training data are generated by the knowledge transfer at each generation. Furthermore, the search space of the tasks will be explored by the proposed mapping (among tasks) approach, which helps these tasks to escape from their local Pareto Fronts. Empirical studies have been conducted on 15 MTO problems to assess the effectiveness of EMTIL. The experimental results demonstrate that EMTIL works more effectively for MTO compared to the existing algorithms.																	1089-778X	1941-0026				OCT	2020	24	5					824	838		10.1109/TEVC.2019.2962747													
J								A New Hypervolume-Based Evolutionary Algorithm for Many-Objective Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Sociology; Optimization; Approximation algorithms; Monte Carlo methods; Tensors; Convergence; Evolutionary algorithms; hypervolume contribution approximation; many-objective optimization	SELECTION; PARETO; PERFORMANCE; MOEA/D	In this article, a new hypervolume-based evolutionary multiobjective optimization algorithm (EMOA), namely, R2HCA-EMOA (R2-based hypervolume contribution approximation EMOA), is proposed for many-objective optimization. The core idea of the algorithm is to use an R2 indicator variant to approximate the hypervolume contribution. The basic framework of the proposed algorithm is the same as SMS-EMOA. In order to make the algorithm computationally efficient, a utility tensor structure is introduced for the calculation of the R2 indicator variant. Moreover, a normalization mechanism is incorporated into R2HCA-EMOA to enhance the performance of the algorithm. Through experimental studies, R2HCA-EMOA is compared with three hypervolume-based EMOAs and several other state-of-the-art EMOAs on 5-, 10-, and 15-objective DTLZ, WFG problems, and their minus versions. Our results show that R2HCA-EMOA is more efficient than the other hypervolume-based EMOAs, and is superior to all the compared state-of-the-art EMOAs.																	1089-778X	1941-0026				OCT	2020	24	5					839	852		10.1109/TEVC.2020.2964705													
J								An Analysis of Quality Indicators Using Approximated Optimal Distributions in a 3-D Objective Space	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Convergence; Linear programming; Pareto optimization; Decision making; Benchmark testing; Indexes; Evolutionary multiobjective optimization (EMO); optimal distributions of objective vectors; quality indicators	NONDOMINATED SORTING APPROACH; GENETIC LOCAL SEARCH; EVOLUTIONARY ALGORITHMS; OPTIMIZATION; PERFORMANCE; IMPACT; SETS	Although quality indicators play a crucial role in benchmarking evolutionary multiobjective optimization algorithms, their properties are still unclear. One promising approach for understanding quality indicators is the use of the optimal distribution of objective vectors that optimizes each quality indicator. However, it is difficult to obtain the optimal distribution for each quality indicator, especially, when its theoretical property is unknown. Thus, optimal distributions for most quality indicators have not been well investigated. To address these issues, first, we propose a problem formulation of finding the optimal distribution for each quality indicator on an arbitrary Pareto front. Then, we approximate the optimal distributions for nine quality indicators using the proposed problem formulation. We analyze the nine quality indicators using their approximated optimal distributions on eight types of Pareto fronts of three-objective problems. Our analysis demonstrates that uniformly distributed objective vectors over the entire Pareto front are not optimal in many cases. Each quality indicator has its own optimal distribution for each Pareto front. We also examine the consistency among the nine quality indicators.																	1089-778X	1941-0026				OCT	2020	24	5					853	867		10.1109/TEVC.2020.2966014													
J								Evolutionary Large-Scale Multiobjective Optimization for Ratio Error Estimation of Voltage Transformers	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Voltage measurement; Optimization; Calibration; Substations; Estimation; Error analysis; Benchmark testing; Benchmark test suite; inequality constraint; large-scale multiobjective optimization; time-varying ratio error estimation (TREE); voltage transformer (VT)	ALGORITHM; CONVERGENCE; UNBALANCE; SELECTION; FASTER	Ratio error (RE) estimation of the voltage transformers (VTs) plays an important role in modern power delivery systems. Existing RE estimation methods mainly focus on periodical calibration but ignore the time-varying property. Consequently, it is difficult to efficiently estimate the state of the VTs in real time. To address this issue, we formulate a time-varying RE estimation (TREE) problem into a large-scale multiobjective optimization problem, where the multiple objectives and inequality constraints are formulated by statistical and physical rules extracted from the power delivery systems. Furthermore, a set of TREE problems from different substations is systematically formulated into a benchmark test suite for characterizing their different properties. The formulation of these TREE problems not only transfers an expensive RE estimation task to a relatively cheaper optimization problem but also promotes the research in large-scale multiobjective optimization by providing a real-world benchmark test suite with complex variable interactions and correlations to different objectives. To the best of our knowledge, this is the first time to formulate a real-world problem into a benchmark test suite for large-scale multiobjective optimization, and it is also the first work proposing to solve TREE problems via evolutionary multiobjective optimization.																	1089-778X	1941-0026				OCT	2020	24	5					868	881		10.1109/TEVC.2020.2967501													
J								Variable-Size Cooperative Coevolutionary Particle Swarm Optimization for Feature Selection on High-Dimensional Data	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Feature extraction; Computational efficiency; Search problems; Uncertainty; Particle swarm optimization; Convergence; Correlation; Cooperative coevolutionary (CC); feature selection (FS); particle swarm optimization (PSO); variable-population	FEATURE SUBSET-SELECTION; DIFFERENTIAL EVOLUTION; LOCAL SEARCH; CLASSIFICATION; ALGORITHM; MODEL	Evolutionary feature selection (FS) methods face the challenge of "curse of dimensionality" when dealing with high-dimensional data. Focusing on this challenge, this article studies a variable-size cooperative coevolutionary particle swarm optimization algorithm (VS-CCPSO) for FS. The proposed algorithm employs the idea of "divide and conquer" in cooperative coevolutionary approach, but several new developed problem-guided operators/strategies make it more suitable for FS problems. First, a space division strategy based on the feature importance is presented, which can classify relevant features into the same subspace with a low computational cost. Following that, an adaptive adjustment mechanism of subswarm size is developed to maintain an appropriate size for each subswarm, with the purpose of saving computational cost on evaluating particles. Moreover, a particle deletion strategy based on fitness-guided binary clustering, and a particle generation strategy based on feature importance and crossover both are designed to ensure the quality of particles in the subswarms. We apply VS-CCPSO to 12 typical datasets and compare it with six state-of-the-art methods. The experimental results show that VS-CCPSO has the capability of obtaining good feature subsets, suggesting its competitiveness for tackling FS problems with high dimensionality.																	1089-778X	1941-0026				OCT	2020	24	5					882	895		10.1109/TEVC.2020.2968743													
J								Combining Simple and Adaptive Monte Carlo Methods for Approximating Hypervolume	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Monte Carlo methods; Approximation algorithms; Approximation error; Optimization; Computational efficiency; Urban areas; Error probability; Approximation algorithms; hypervolume; multiobjective optimization	ALGORITHMS	The computation of hypervolume is a key issue in multiobjective optimization, particularly, multiobjective evolutionary optimization. However, it is NP-hard to compute the exact hypervolume value. Monte Carlo methods have been widely used for approximating the hypervolume. Observing that the basic Monte Carlo method and the fully polynomial-time randomized approximation scheme (FPRAS) suit different solution sets, we propose a combination of these two methods and show that it performs very well on a number of solution sets.																	1089-778X	1941-0026				OCT	2020	24	5					896	907		10.1109/TEVC.2020.2969965													
J								A Multifactorial Evolutionary Algorithm for Multitasking Under Interval Uncertainties	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Interval dominance relationship; interval multiobjective optimization (IMOOP); multifactorial evolution	OPTIMIZATION	Various real-world applications with interval uncertainty, such as the path planning of mobile robot, layout of radio frequency identification readers and solar desalination, can be formulated as an interval multiobjective optimization problem (IMOOP), which is usually transformed into one or a series of certain problems to solve by using evolutionary algorithms. However, a definite characteristic among them is that only a single optimization task can be catched up at a time. Inspired by the multifactorial evolutionary algorithm (MFEA), a novel interval MFEA (IMFEA) is proposed to solve IMOOPs simultaneously using a single population of evolving individuals. In the proposed method, the potential interdependency across related problems can be explored in the unified genotype space, and multitasks of multiobjective interval optimization problems are solved at once by promoting knowledge transfer for the greater synergistic search to improve the convergence speed and the quality of the optimal solution set. Specifically, an interval crowding distance based on shape evaluation is calculated to evaluate the interval solutions more comprehensively. In addition, an interval dominance relationship based on the evolutionary state of the population is designed to obtain the interval confidence level, which considers the difference of average convergence levels and the relative size of the potential possibility between individuals. Correspondingly, the strict transitivity proof of the presented dominance relationship is given. The efficacy of the associated evolutionary algorithm is validated on a series of benchmark test functions, as well as a real-world case of robot path planning with many terrains that provides insight into the performance of the method in the face of IMOOPs.																	1089-778X	1941-0026				OCT	2020	24	5					908	922		10.1109/TEVC.2020.2975381													
J								Boosting Data-Driven Evolutionary Algorithm With Localized Data Generation	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Optimization; Iron; Data models; Buildings; Boosting; Computational modeling; Adaptation models; Boosting strategy (BS); data-driven evolutionary algorithm (DDEA); expensive optimization problems (EOPs); localized data generation (LDG); surrogate	PARTICLE SWARM OPTIMIZATION; FITNESS APPROXIMATION; EXPECTED IMPROVEMENT; SURROGATE MODEL; NEURAL-NETWORKS; SYSTEMS; STRATEGY	By efficiently building and exploiting surrogates, data-driven evolutionary algorithms (DDEAs) can be very helpful in solving expensive and computationally intensive problems. However, they still often suffer from two difficulties. First, many existing methods for building a single ad hoc surrogate are suitable for some special problems but may not work well on some other problems. Second, the optimization accuracy of DDEAs deteriorates if available data are not enough for building accurate surrogates, which is common in expensive optimization problems. To this end, this article proposes a novel DDEA with two efficient components. First, a boosting strategy (BS) is proposed for self-aware model managements, which can iteratively build and combine surrogates to obtain suitable surrogate models for different problems. Second, a localized data generation (LDG) method is proposed to generate synthetic data to alleviate data shortage and increase data quantity, which is achieved by approximating fitness through data positions. By integrating the BS and the LDG, the BDDEA-LDG algorithm is able to improve model accuracy and data quantity at the same time automatically according to the problems at hand. Besides, a tradeoff is empirically considered to strike a better balance between the effectiveness of surrogates and the time cost for building them. The experimental results show that the proposed BDDEA-LDG algorithm can generally outperform both traditional methods without surrogates and other state-of-the-art DDEA son widely used benchmarks and an arterial traffic signal timing real-world optimization problem. Furthermore, the proposed BDDEA-LDG algorithm can use only about 2% computational budgets of traditional methods for producing competitive results.																	1089-778X	1941-0026				OCT	2020	24	5					923	937		10.1109/TEVC.2020.2979740													
J								A Constrained Multiobjective Evolutionary Algorithm With Detect-and-Escape Strategy	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Sociology; Statistics; Constraint handling; Optimization; Evolutionary computation; Urban areas; Constraint handling technique (CHT); MOEA; D; multiobjective optimization	MOEA/D	Overall constraint violation functions are commonly used in multiobjective evolutionary algorithms (MOEAs) for handling constraints. Constraints could cause these algorithms stuck in two stagnation states: 1) since the feasible region of a multiobjective optimization problem can consist of several disconnected feasible subregions, the search can be easily trapped in a feasible subregion which does not contain all the global Pareto optimal solutions and 2) an overall constraint violation function may have many nonzero minimal points, it can make the search stuck in an unfeasible area. To address these two issues, this article proposes a strategy to detect whether or not the search is stuck in these two stagnation states and then escape from them. Our proposed detect-and-escape strategy uses the feasible ratio and the change rate of overall constraint violation to detect stagnation, and adjusts the weight of the constraint violation for guiding the search to escape from stagnation states. We develop and implement a decomposition-based constrained MOEA with this strategy. Extensive experiments on a number of benchmark problems demonstrate the competitiveness of our proposed algorithm when compared to five other state-of-the-art constrained evolutionary algorithms.																	1089-778X	1941-0026				OCT	2020	24	5					938	947		10.1109/TEVC.2020.2981949													
J								Limit-Cycle-Based Mutant Multiobjective Pigeon-Inspired Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Convergence; Compass; Sociology; Heuristic algorithms; Pareto optimization; Limit-cycle-based mechanism; multiobjective pigeon-inspired optimization (PIO); mutant mechanism; theoretical analysis	PARTICLE SWARM OPTIMIZATION; NONDOMINATED SORTING APPROACH; EVOLUTIONARY ALGORITHMS; FEATURE-SELECTION	This article presents a limit-cycle-based mutant multiobjective pigeon-inspired optimization (PIO). In this algorithm, the limit-cycle-based mechanism is devised to consider the factors that affect the flight of pigeons to simplify the multiobjective PIO algorithm. The mutant mechanism is incorporated to strengthen the exploration capability in the evolutionary process. Additionally, the application of the dual repository makes the nondominated solutions stored and selected to guide the flight of pigeons. Attributed to the limit-cycle-based mutant mechanisms, this algorithm not only obtains the faster convergence speed and higher accuracy but also improves its population diversity. To confirm the universal application of this algorithm, theoretical analysis of the convergence is discussed in this article. Finally, comparative experiments of our proposed algorithm and other five multiobjective methods are conducted to verify the accuracy, efficiency, and convergence stability of the proposed algorithm.																	1089-778X	1941-0026				OCT	2020	24	5					948	959		10.1109/TEVC.2020.2983311													
J								Specializing Context-Free Grammars With a (1+1)-EA	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Grammar; Computational modeling; Optimization; Production; Sociology; Statistics; Evolutionary computation; Grammar design; grammatical evolution; run time analysis	EVOLUTION; MODEL	Context-free grammars are useful tools for modeling the solution space of problems that can be solved by optimization algorithms. For a given solution space, there exists an infinite number of grammars defining that space, and there are clues that changing the grammar may impact the effectiveness of the optimization. In this article, we investigate theoretically and experimentally the possibility of specializing a grammar in a problem, that is, of systematically improving the quality of the grammar for the given problem. To this end, we define the quality of a grammar for a problem in terms of the average fitness of the candidate solutions generated using that grammar. Theoretically, we demonstrate the following findings: 1) that a simple mutation operator employed in a (1 + 1)-EA setting can be used to specialize a grammar in a problem without changing the solution space defined by the grammar and 2) that three grammars of equal quality for a grammar-based version of the ONEMAX problem greatly vary in how they can be specialized with that (1 + 1)-EA, as the expected time required to obtain the same improvement in quality can vary exponentially among grammars. Then, experimentally, we validate the theoretical findings and extend them to other problems, grammars, and a more general version of the mutation operator.																	1089-778X	1941-0026				OCT	2020	24	5					960	973		10.1109/TEVC.2020.2983664													
J								Multiobjective Evolution Strategy for Dynamic Multiobjective Optimization	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION										Sociology; Pareto optimization; Convergence; Heuristic algorithms; Magnetic particles; Dynamic multiobjective optimization problem (DMOP); evolution strategy (ES); multiobjective evolutionary algorithm (MOEA); multiobjective optimization problem (MOP)	PREDICTION STRATEGY; GENETIC ALGORITHMS; ENVIRONMENTS; IMMIGRANTS; DIVERSITY; SEARCH; OPTIMA; MODEL	This article presents a novel evolution strategy-based evolutionary algorithm, named DMOES, which can efficiently and effectively solve multiobjective optimization problems in dynamic environments. First, an efficient self-adaptive precision controllable mutation operator is designed for individuals to explore and exploit the decision space. Second, the simulated isotropic magnetic particles niching can guide the individuals to keep uniform distance and extent to approximate the entire Pareto front automatically. Third, the nondominated solutions (NDS) guided immigration can facilitate the population convergence with two different strategies for the NDSs and the dominated solutions, respectively. As a result, our algorithm can track the new approximate Pareto set and approximate Pareto front as quickly as possible when the environment changes. In addition, DMOES can obtain a well-converged and well-diversified Pareto front with much less population size and far lower computational cost. The larger the number of individuals, the sharper the contour of the resulted approximate Pareto front will be. Finally, the proposed algorithm is evaluated by the FDA, dMOP, UDF, and ZJZ test suites. The experimental results have been demonstrated to provide a competitive and oftentimes better performance when compared against some chosen state-of-the-art dynamic multiobjective evolutionary algorithms.																	1089-778X	1941-0026				OCT	2020	24	5					974	988		10.1109/TEVC.2020.2985323													
J								Binarized Neural Architecture Search for Efficient Object Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION										Neural architecture search (NAS); Binarized network; Object recognition; Edge computing	MULTIARMED BANDIT	Traditional neural architecture search (NAS) has a significant impact in computer vision by automatically designing network architectures for various tasks. In this paper, binarized neural architecture search (BNAS), with a search space of binarized convolutions, is introduced to produce extremely compressed models to reduce huge computational cost on embedded devices for edge computing. The BNAS calculation is more challenging than NAS due to the learning inefficiency caused by optimization requirements and the huge architecture space, and the performance loss when handling the wild data in various computing applications. To address these issues, we introduce operation space reduction and channel sampling into BNAS to significantly reduce the cost of searching. This is accomplished through a performance-based strategy that is robust to wild data, which is further used to abandon less potential operations. Furthermore, we introduce the upper confidence bound to solve 1-bit BNAS. Two optimization methods for binarized neural networks are used to validate the effectiveness of our BNAS. Extensive experiments demonstrate that the proposed BNAS achieves a comparable performance to NAS on both CIFAR and ImageNet databases. An accuracy of 96.53% vs. 97.22% is achieved on the CIFAR-10 dataset, but with a significantly compressed model, and a 40% faster search than the state-of-the-art PC-DARTS. On the wild face recognition task, our binarized models achieve a performance similar to their corresponding full-precision models.																	0920-5691	1573-1405															10.1007/s11263-020-01379-y		OCT 2020											
J								HihO: accelerating artificial intelligence interpretability for medical imaging in IoT applications using hierarchical occlusion Opening the black box	NEURAL COMPUTING & APPLICATIONS										Explainable AI; Artificial intelligence; Deep learning; Internet of Things; Occlusion sensitivity		In the medical imaging domain, nonlinear warping has enabled pixel-by-pixel mapping of one image dataset to a reference dataset. This co-registration of data allows for robust, pixel-wise, statistical maps to be developed in the domain, leading to new insights regarding disease mechanisms. Deep learning technologies have given way to some impressive discoveries. In some applications, deep learning algorithms have surpassed the abilities of human image readers to classify data. As long as endpoints are clearly defined, and the input data volume is large enough, deep learning networks can often converge and reach prediction, classification and segmentation with success rates as high or higher than human operators. However, machine learning and deep learning algorithms are complex. Interpretability is not always a product of the classifications performed. Visualization techniques have been developed to add a layer of interpretability. The work presented here builds on a framework for augmenting statistical findings in medical imaging workflows with machine learning results. Utilizing the framework, visualization techniques for the machine learning portion are compared in an application, and a novel, lightweight technique for machine learning visualization is proposed as a means of increasing the portability of machine learning interpretability to Internet of Things applications. The novel visualization, hierarchical occlusion, can improve time to visualization by three orders of magnitude over a traditional occlusion sensitivity algorithm.																	0941-0643	1433-3058															10.1007/s00521-020-05379-4		OCT 2020											
J								3D Model Retrieval Using Bipartite Graph Matching Based on Attention	NEURAL PROCESSING LETTERS										3D model retrieval; Bipartite graph matching; Attention mechanism	CONVOLUTIONAL NEURAL-NETWORKS; OBJECT RETRIEVAL	In this paper, we propose an attention-based bipartite graph 3D model retrieval algorithm, where many-to-many matching method, the weighted bipartite graph matching, is employed for comparison between two 3D models. Considering the panoramic views can donate the spatial and structural information, in this work, we use panoramic views to represent each 3D model. Attention mechanism is used to generate the weight of all views of each model. And then, we construct a weighted bipartite graph with the views of those models and the weight of each view. According to the bipartite graph, the matching result is used to measure the similarity between two 3D models. We experiment our method on ModelNet, NTU and ETH datasets, and the experimental results and comparison with other methods show the effectiveness of our method.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1043	1055		10.1007/s11063-019-10155-0													
J								H-infinity State Estimation of Static Neural Networks with Mixed Delay	NEURAL PROCESSING LETTERS										Static neural networks; H-infinity state estimation; Leakage time-varying delay; Distributed delay; Linear matrix inequality	STABILITY ANALYSIS; LEAKAGE DELAY; SYNCHRONIZATION; SYSTEMS; STABILIZATION	This paper focuses on studying the H-infinity state estimation of static neural networks with mixed delay in which leakage time-varying delay and distributed delay are taken into account, simultaneously. By constructing several suitable Lyapunov-Krasovskii functionals and linear matrix inequality technique, the delay-independent and delay-dependent criteria are established in order that the error system is globally asymptotically stable with H-infinity performance, respectively. In addition, with the skills to construct Lyapunov-Krasovskii functionals, we obtain the results in which we constitutionally drop the differentiability requirement of transmission delays. Some numerical examples are given to show the effectiveness and advantages of the obtained results.																	1370-4621	1573-773X				OCT	2020	52	2			SI		1069	1087		10.1007/s11063-019-10171-0													
J								Improving Alzheimer's disease classification by performing data fusion with vascular dementia and stroke data	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE										Data fusion; machine learning; Alzheimer's disease; vascular dementia; stroke	MILD COGNITIVE IMPAIRMENT; FEATURE REPRESENTATION; EARLY-DIAGNOSIS; PREDICTION; STATE; BIOMARKERS; CRITERIA; RELIEFF	Improvement of prediction accuracy and early detection of the Alzheimer's disease is becoming increasingly important for managing its impact on lives of affected patients. Many machine learning approaches have been applied to support the diagnosis and prediction of this illness. In this paper we propose an approach for improving the Alzheimer's disease classification accuracy by using data fusion of several independent clinical datasets. Data fusion was performed twofold: 1) by enriching attributes of the base dataset with the attributes of the secondary dataset and 2) by enriching the examples set of the base dataset with the examples of the secondary dataset. In both cases the missing values (for newly added attributes and/or examples) were predicted by using linear regression for numeric and naive Bayes classifier for nominal attributes. We experimented on three data sources: on a dataset of Alzheimer's disease-impaired patients, on a dataset of patients with vascular dementia, and on a dataset of patients who have been affected by a stroke. We fused these datasets with different data fusion approaches and analysed the improvement in classification accuracy as well as the quality of the fused attributes. The experiments indicated that we obtained an increase of classification accuracy on the fused dataset compared with the accuracy obtained from individual dataset.																	0952-813X	1362-3079															10.1080/0952813X.2020.1818290		OCT 2020											
J								Exploiting Implicit Influence From Information Propagation for Social Recommendation	IEEE TRANSACTIONS ON CYBERNETICS										Recommender systems; Social networking (online); Matrix decomposition; Information technology; Australia; Cybernetics; Information systems; Computational intelligence; implicit user influence; information propagation; recommender systems; social networks	MATRIX FACTORIZATION; TRUST; NETWORK	Social recommender systems have attracted a lot of attention from academia and industry. On social media, users' ratings and reviews can be observed by all users, and have implicit influence on their future ratings. When these users make subsequent decisions about an item, they may be affected by existing ratings on the item. Thus, implicit influence propagates among the users who rated the same items, and it has significant impact on users' ratings. However, implicit influence propagation and its effect on recommendation rarely have been studied. In this article, we propose an information propagation-based social recommendation method (SoInp) and model the implicit user influence from the perspective of information propagation. The implicit influence is inferred from ratings on the same items. We investigate the concrete effect of implicit user influence in the propagation process and introduce it into recommender systems. Furthermore, we incorporate the implicit user influence and explicit trust information in the matrix factorization framework. To demonstrate the performance, we conduct comprehensive experiments on real-world datasets to compare the proposed method with the state-of-the-art models. The results indicate that SoInp makes notable improvements in rating prediction.																	2168-2267	2168-2275				OCT	2020	50	10					4186	4199		10.1109/TCYB.2019.2939390													
J								Quasi-Synchronization of Heterogeneous Networks With a Generalized Markovian Topology and Event-Triggered Communication	IEEE TRANSACTIONS ON CYBERNETICS										Switches; Synchronization; Heterogeneous networks; Network topology; Topology; Couplings; Stochastic processes; Event-triggered control; generalized Markovian topology; heterogeneous network; quasi-synchronization	DYNAMICAL NETWORKS; PINNING CONTROL; COMPLEX NETWORKS; BOUNDED SYNCHRONIZATION; OUTPUT SYNCHRONIZATION; MULTIAGENT SYSTEMS; NONIDENTICAL NODES; DIRECTED NETWORKS; NEURAL-NETWORKS; CONSENSUS	We consider the quasi-synchronization problem of a continuous time generalized Markovian switching heterogeneous network with time-varying connectivity, using pinned nodes that are event-triggered to reduce the frequency of controller updates and internode communications. We propose a pinning strategy algorithm to determine how many and which nodes should be pinned in the network. Based on the assumption that a network has limited control efficiency, we derive a criterion for stability, which relates the pinning feedback gains, the coupling strength, and the inner coupling matrix. By utilizing the stochastic Lyapunov stability analysis, we obtain sufficient conditions for exponential quasi-synchronization under our stochastic event-triggering mechanism, and a bound for the quasi-synchronization error. Numerical simulations are conducted to verify the effectiveness of the proposed control strategy.																	2168-2267	2168-2275				OCT	2020	50	10					4200	4213		10.1109/TCYB.2019.2891536													
J								Differentially Private Malicious Agent Avoidance in Multiagent Advising Learning	IEEE TRANSACTIONS ON CYBERNETICS										Privacy; Differential privacy; Base stations; Reinforcement learning; Multi-agent systems; Buildings; Routing; Agent advising; differential privacy; multiagent reinforcement learning (MARL)		Agent advising is one of the key approaches to improve agent learning performance by enabling agents to ask for advice between each other. Existing agent advising approaches have two limitations. The first limitation is that all the agents in a system are assumed to be friendly and cooperative. However, in the real world, malicious agents may exist and provide false advice to hinder the learning performance of other agents. The second limitation is that the analysis of communication overhead in these approaches is either overlooked or simplified. However, in communication-constrained environments, communication overhead has to be carefully considered. To overcome the two limitations, this paper proposes a novel differentially private agent advising approach. Our approach employs the Laplace mechanism to add noise on the rewards used by student agents to select teacher agents. By using the differential privacy technique, the proposed approach can reduce the impact of malicious agents without identifying them. Also, by adopting the privacy budget concept, the proposed approach can naturally control communication overhead. The experimental results demonstrate the effectiveness of the proposed approach.																	2168-2267	2168-2275				OCT	2020	50	10					4214	4227		10.1109/TCYB.2019.2906574													
J								A Bilevel Optimization Approach for Joint Offloading Decision and Resource Allocation in Cooperative Mobile Edge Computing	IEEE TRANSACTIONS ON CYBERNETICS										Task analysis; Servers; Resource management; Optimization; Delays; Mobile handsets; Interference; Ant colony system (ACS); bilevel optimization; computation resource allocation; mobile edge computing (MEC); offloading decision	ANT COLONY OPTIMIZATION; COMPUTATION	This paper studies a multiuser cooperative mobile edge computing offloading (called CoMECO) system in a multiuser interference environment, in which delay-sensitive tasks may be executed on local devices, cooperative devices, or the primary MEC server. In this system, we jointly optimize the offloading decision and computation resource allocation for minimizing the total energy consumption of all mobile users under the delay constraint. If this problem is solved directly, the offloading decision and computation resource allocation are generally generated separately at the same time. Note, however, that they are closely coupled. Therefore, under this condition, their dependency is not well considered, thus leading to poor performance. We transform this problem into a bilevel optimization problem, in which the offloading decision is generated in the upper level, and then the optimal allocation of computation resources is obtained in the lower level based on the given offloading decision. In this way, the dependency between the offloading decision and computation resource allocation can be fully taken into account. Subsequently, a bilevel optimization approach, called BiJOR, is proposed. In BiJOR, candidate modes are first pruned to reduce the number of infeasible offloading decisions. Afterward, the upper-level optimization problem is solved by ant colony system (ACS). Furthermore, a sorting strategy is incorporated into ACS to construct feasible offloading decisions with a higher probability and a local search operator is designed in ACS to accelerate the convergence. For the lower-level optimization problem, it is solved by the monotonic optimization method. In addition, BiJOR is extended to deal with a complex scenario with the channel selection. Extensive experiments are carried out to investigate the performance of BiJOR on two sets of instances with up to 400 mobile users. The experimental results demonstrate the effectiveness of BiJOR and the superiority of the CoMECO system.																	2168-2267	2168-2275				OCT	2020	50	10					4228	4241		10.1109/TCYB.2019.2916728													
J								Toward Flotation Process Operation-State Identification via Statistical Modeling of Biologically Inspired Gabor Filtering Responses	IEEE TRANSACTIONS ON CYBERNETICS										Biological system modeling; Transforms; Monitoring; Image segmentation; Image color analysis; Surface morphology; Biologically inspired Gabor wavelets (BIGWs); froth image; gamma distribution (Gamma D); Gaussian scale mixture model (GSMM); Laplace distribution (LD); local spline regression (LSR) classifier; operation-state monitoring	SPATIAL-FREQUENCY; IMAGE-ANALYSIS; CLASSIFICATION; RECOGNITION; LEVEL	This paper presents a froth image statistical modeling-based online flotation process operation-state identification method by introducing a biologically inspired Gabor wavelet transform in accordance with the physiological findings in the biological vision system. It derived the latent probabilistic density models of these biologically inspired Gabor filtering responses (GFRs) based on a versatile intermediate probability modeling frame, Gaussian scale mixture model. It has demonstrated that both the real and the imaginary representation of GFR obey a Laplace distribution. Accordingly, the amplitude representation of GFR obeys a Gamma distribution. Whereas the phase representation of GFR is an important yet frequently ignored aspect in Gabor-based signal analysis; it is demonstrated to be a periodic distribution and can be expressed by a von Mises-like distribution model. Successively, a local spline regression (LSR)-based classifier that the maps scattered statistical feature points of froth images directly to the operation-state labels smoothly is introduced for the operation-state recognition. Extensive confirmatory and comparative experiments on an industrial-scale bauxite flotation process demonstrate the effectiveness and superiority of the proposed method. Performance effects on different parameter settings, e.g., parameters of Gabor kernel and dimensionalities of multivariate statistical models, are further discussed.																	2168-2267	2168-2275				OCT	2020	50	10					4242	4255		10.1109/TCYB.2019.2909763													
J								Real-World ISAR Object Recognition Using Deep Multimodal Relation Learning	IEEE TRANSACTIONS ON CYBERNETICS										Convolution; Object recognition; Kernel; Image resolution; Feature extraction; Cybernetics; Convolutional neural networks; Attribute learning; deep learning; deformable; image matching; object recognition; radar; real-world environment; relation learning; statistic	NETWORKS	Real-world inverse synthetic aperture radar (ISAR) object recognition is a critical and challenging problem in computer vision tasks. In this article, an efficient real-world ISAR object recognition method is proposed, namely, real-world ISAR object recognition (RIOR), based on deep multimodal relation learning (DMRL). It cannot only handle the complex multimodal recognition problem efficiently but also exploit the relations among the features, attributes, labels, and classes with semantic knowledge: 1) an adaptive multimodal mechanism (AMM) is proposed in convolutional neural network (CNN) to substantially promote the CNN sampling and transformation capability and significantly raise the output feature map resolutions by keeping almost all of the information; 2) deep attribute relation graph learning (DARGL) is proposed to jointly estimate the large numbers of heterogeneous attributes and collaboratively explore the relations among the features, attributes, labels, and classes with common knowledge graphs; and 3) relational-regularized convolutional sparse learning (RCSL) is proposed to further achieve good translation invariance and improve the accuracy and speed of the entire system. Extensive qualitative and quantitative experiments are performed on two real-world ISAR datasets, demonstrating that RIOR outperforms the state-of-the-art methods while running quickly.																	2168-2267	2168-2275				OCT	2020	50	10					4256	4267		10.1109/TCYB.2019.2933224													
J								Bridging User Interest to Item Content for Recommender Systems: An Optimization Model	IEEE TRANSACTIONS ON CYBERNETICS										Feature extraction; Optimization; Sparse matrices; Motion pictures; Recommender systems; Estimation; Social networking (online); Content based; optimization; recommendation; relation learning; user preference		Recommender systems are currently utilized widely in e-commerce for product recommendations and within content delivery platforms. Previous studies usually use independent features to represent item content. As a result, the relationship hidden among the content features is overlooked. In fact, the reason that an item attracts a user may be attributed to only a few set of features. In addition, these features are often semantically coupled. In this paper, we present an optimization model for extracting the relationship hidden in content features by considering user preferences. The learned feature relationship matrix is then applied to address the cold-start recommendations and content-based recommendations. It could also easily be employed for the visualization of feature relation graphs. Our proposed method was examined on three public datasets: 1) hetrec-movielens-2k-v2; 2) book-crossing; and 3) Netflix. The experimental results demonstrated the effectiveness of our method in comparison to the state-of-the-art recommendation methods.																	2168-2267	2168-2275				OCT	2020	50	10					4268	4280		10.1109/TCYB.2019.2900159													
J								Exponential State Estimation for Memristor-Based Discrete-Time BAM Neural Networks With Additive Delay Components	IEEE TRANSACTIONS ON CYBERNETICS										Artificial neural networks; Delays; Neurons; Additives; Memristors; State estimation; Symmetric matrices; Additive time-varying delay; exponential state estimation; linear matrix inequality (LMI); Lyapunov-Krasovskii functional (LKF); memristor	VARYING DELAYS; STABILITY ANALYSIS; LEAKAGE	This paper focuses on the dynamical behavior for a class of memristor-based bidirectional associative memory neural networks (BAMNNs) with additive time-varying delays in discrete-time case. The necessity of the proposed problem is to design a proper state estimator such that the dynamics of the corresponding estimation error is exponentially stable with a prescribed decay rate. By constructing an appropriate Lyapunov-Krasovskii functional (LKF) and utilizing Cauchy-Schwartz-based summation inequality, the delay-dependent sufficient conditions for the existence of the desired estimator are derived in the absence of uncertainties which are further extended to available uncertain parameters of the prescribed memristor-based BAMNNs in terms of linear matrix inequalities (LMIs). By solving the proposed LMI conditions the estimation gain matrices are obtained. Finally, two numerical examples are presented to illustrate the effectiveness of the proposed results.																	2168-2267	2168-2275				OCT	2020	50	10					4281	4292		10.1109/TCYB.2019.2902864													
J								Discrete-Time Impulsive Adaptive Dynamic Programming	IEEE TRANSACTIONS ON CYBERNETICS										Optimal control; Performance analysis; Nonlinear systems; Dynamic programming; Heuristic algorithms; Indexes; Adaptive critic designs; adaptive dynamic programming (ADP); approximate dynamic programming; impulsive control; nonlinear systems; optimal control	OPTIMAL TRACKING CONTROL; ONLINE LEARNING CONTROL; PERIODIC-SOLUTIONS; NEURAL-NETWORKS; SYSTEMS; CONTROLLABILITY; ALGORITHMS; DESIGN	In this paper, a new iterative adaptive dynamic programming (ADP) algorithm is developed to solve optimal impulsive control problems for infinite horizon discrete-time nonlinear systems. Considering the constraint of the impulsive interval, in each iteration, the iterative impulsive value function under each possible impulsive interval is obtained, and then the iterative value function and iterative control law are achieved. A new convergence analysis method is developed which proves an iterative value function to converge to the optimum as the iteration index increases to infinity. The properties of the iterative control law are analyzed, and the detailed implementation of the optimal impulsive control law is presented. Finally, two simulation examples with comparisons are given to show the effectiveness of the developed method.																	2168-2267	2168-2275				OCT	2020	50	10					4293	4306		10.1109/TCYB.2019.2906694													
J								Stabilization of Nonautonomous Recurrent Neural Networks With Bounded and Unbounded Delays on Time Scales	IEEE TRANSACTIONS ON CYBERNETICS										Delays; Artificial neural networks; Stability criteria; Synchronization; Germanium; Recurrent neural networks; Halanay inequality; nonautonomous recurrent neural networks (NRNNs); stabilization; synchronization; time delay; time scale	GENERALIZED HALANAY INEQUALITIES; GLOBAL EXPONENTIAL STABILITY; ASYMPTOTIC STABILITY; OPTIMIZATION SUBJECT; LAGRANGE STABILITY; DISCRETE; SYNCHRONIZATION; SYSTEMS; MULTIPERIODICITY; DISSIPATIVITY	A class of nonautonomous recurrent neural networks (NRNNs) with time-varying delays is considered on time scales. Bounded delays and unbounded delays have been taken into consideration, respectively. First, a new generalized Halanay inequality on time scales is constructed by time-scale theory and some analytical techniques. Based on this inequality, the stabilization of NRNNs with bounded delays is discussed on time scales. The results are also applied to the synchronization of a class of drive-response NRNNs. Furthermore, the stabilization of NRNNs with unbounded delays is investigated. Especially, the stabilization of NRNNs with proportional delays is obtained without any variable transformation. The obtained generalized Halanay inequality on time scales develops and extends some existing ones in the literature. The stabilization criteria for the NRNNs with bounded or unbounded delays cover the results of continuous-time and discrete-time NRNNs and hold the results for the systems that involved on time interval as well. Some examples are given to demonstrate the validity of the results. An application to image encryption and decryption is addressed.																	2168-2267	2168-2275				OCT	2020	50	10					4307	4317		10.1109/TCYB.2019.2922207													
J								Contextual Correlation Preserving Multiview Featured Graph Clustering	IEEE TRANSACTIONS ON CYBERNETICS										Correlation; Context modeling; Optimization; Social networking (online); Computational modeling; Topology; Adaptation models; Attributed graph (AG); community detection; complex network; contextual correlation preserving multiview featured graph clustering (CCPMVFGC); contextual correlation; graph clustering; multiview features	COMMUNITY DETECTION; NETWORKS; TOOL	Graph clustering, which aims at discovering sets of related vertices in graph-structured data, plays a crucial role in various applications, such as social community detection and biological module discovery. With the huge increase in the volume of data in recent years, graph clustering is used in an increasing number of real-life scenarios. However, the classical and state-of-the-art methods, which consider only single-view features or a single vector concatenating features from different views and neglect the contextual correlation between pairwise features, are insufficient for the task, as features that characterize vertices in a graph are usually from multiple views and the contextual correlation between pairwise features may influence the cluster preference for vertices. To address this challenging problem, we introduce in this paper, a novel graph clustering model, dubbed contextual correlation preserving multiview featured graph clustering (CCPMVFGC) for discovering clusters in graphs with multiview vertex features. Unlike most of the aforementioned approaches, CCPMVFGC is capable of learning a shared latent space from multiview features as the cluster preference for each vertex and making use of this latent space to model the inter-relationship between pairwise vertices. CCPMVFGC uses an effective method to compute the degree of contextual correlation between pairwise vertex features and utilizes view-wise latent space representing the feature-cluster preference to model the computed correlation. Thus, the cluster preference learned by CCPMVFGC is jointly inferred by multiview features, view-wise correlations of pairwise features, and the graph topology. Accordingly, we propose a unified objective function for CCPMVFGC and develop an iterative strategy to solve the formulated optimization problem. We also provide the theoretical analysis of the proposed model, including convergence proof and computational complexity analysis. In our experiments, we extensively compare the proposed CCPMVFGC with both classical and state-of-the-art graph clustering methods on eight standard graph datasets (six multiview and two single-view datasets). The results show that CCPMVFGC achieves competitive performance on all eight datasets, which validates the effectiveness of the proposed model.																	2168-2267	2168-2275				OCT	2020	50	10					4318	4331		10.1109/TCYB.2019.2926431													
J								Solving Trajectory Optimization Problems in the Presence of Probabilistic Constraints	IEEE TRANSACTIONS ON CYBERNETICS										Planning; Probabilistic logic; Trajectory optimization; Optimal control; Prediction algorithms; Approximation function; chance-constrained; nonlinear programming; probabilistic constraints; trajectory optimization	MODEL-PREDICTIVE CONTROL; BUNDLE METHODS; APPROXIMATION; ROBUSTNESS; AVOIDANCE; STABILITY; COVERAGE; VEHICLES; SYSTEMS; SEARCH	The objective of this paper is to present an approximation-based strategy for solving the problem of nonlinear trajectory optimization with the consideration of probabilistic constraints. The proposed method defines a smooth and differentiable function to replace probabilistic constraints by the deterministic ones, thereby converting the chance-constrained trajectory optimization model into a parametric nonlinear programming model. In addition, it is proved that the approximation function and the corresponding approximation set will converge to that of the original problem. Furthermore, the optimal solution of the approximated model is ensured to converge to the optimal solution of the original problem. Numerical results, obtained from a new chance-constrained space vehicle trajectory optimization model and a 3-D unmanned vehicle trajectory smoothing problem, verify the feasibility and effectiveness of the proposed approach. Comparative studies were also carried out to show the proposed design can yield good performance and outperform other typical chance-constrained optimization techniques investigated in this paper.																	2168-2267	2168-2275				OCT	2020	50	10					4332	4345		10.1109/TCYB.2019.2895305													
J								Maneuvering Target Tracking With Event-Based Mixture Kalman Filter in Mobile Sensor Networks	IEEE TRANSACTIONS ON CYBERNETICS										Kalman filters; Target tracking; Robot sensing systems; Mutual information; Optimal control; State estimation; Event-trigger; mixture Kalman filter; mobile sensors; mutual information theory; state estimation	SYSTEMS	In this paper, the distributed remote state estimation problem for conditional dynamic linear systems in mobile sensor networks with an event-triggered mechanism is investigated. The distributed mixture Kalman filtering method is proposed to track the state of the maneuvering target, which uses particle filtering to estimate the nonlinear variables and apply Kalman filtering to estimate the linear variables. An event-based distributed filtering scheme is designed, which is an energy-efficient way to transmit data between sensors and estimators. In addition, by using the mutual information theory, an optimal control problem is formed to control the position of sensors so that the target tracking process can be achieved quickly. Finally, a simulation example about the maneuvering target tracking is provided to corroborate the effectiveness of the filtering method and the control performance for sensors.																	2168-2267	2168-2275				OCT	2020	50	10					4346	4357		10.1109/TCYB.2019.2901515													
J								Adjacent-Agent Dynamic Linearization-Based Iterative Learning Formation Control	IEEE TRANSACTIONS ON CYBERNETICS										Iterative methods; Uncertainty; Learning systems; Vehicle dynamics; Multi-agent systems; Task analysis; Adjacent-agent dynamic linearization; data-driven control approach; iterative learning formation control; nonlinear nonaffine multiagent systems (MASs)	SPACECRAFT FORMATION; TRACKING CONTROL; SYSTEMS; COORDINATION; NETWORKS; DESIGN	The dynamical relationship of the multiple agents' behavior in a networked system is explored and utilized to enhance the control performance of the multiagent formation in this paper. An adjacent-agent dynamic linearization is first presented for nonlinear and nonaffine multiagent systems (MASs) and a virtual linear difference model is built between two adjacent agents communicating with each other. Considering causality, the agents are assigned as parent and child, respectively. Communication is from parent to child. Taking the advantage of the repetitive characteristics of a large class of MASs, an adjacent-agent dynamic linearization-based iterative learning formation control (ADL-ILFC) is proposed for the child agent using 3-D control knowledge from iterations, time instants, and the parent agent. The ADL-ILFC is a data-driven method and does not depend on a first-principle physical model but the virtual linear difference model. The validity of the proposed approach is demonstrated through rigorous analysis and extensive simulations.																	2168-2267	2168-2275				OCT	2020	50	10					4358	4369		10.1109/TCYB.2019.2899654													
J								Stochastic Fixed Point Optimization Algorithm for Classifier Ensemble	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Convergence; Machine learning algorithms; Approximation algorithms; Classification algorithms; Convex functions; Machine learning; Classifier ensemble; convex stochastic optimization; fixed point; quasi-nonexpansive mapping; sparsity and diversity learning; stochastic fixed point optimization algorithm	APPROXIMATION ALGORITHMS; COMPOSITE OPTIMIZATION; SPARSITY	This paper considers a classifier ensemble problem with sparsity and diversity learning, which arises in the field of machine learning, and shows that the classifier ensemble problem can be formulated as a convex stochastic optimization problem over the fixed point set of a quasi-nonexpansive mapping. Specifically, for such a problem, this paper proposes an algorithm referred to as the stochastic fixed point optimization algorithm and performs a convergence analysis for three types of step size: 1) constant step size; 2) decreasing step size; and 3) a step size computed by line searches. In the case of a constant step size, the results indicate that a sufficiently small constant step size allows a solution to the problem to be approximated. In the case of a decreasing step size, conditions are shown under which the algorithm converges in probability to a solution. For the third case, a variation of the basic proposed algorithm also achieves convergence in probability to a solution. The high classification accuracies of the proposed algorithms are demonstrated through numerical comparisons with the conventional algorithm.																	2168-2267	2168-2275				OCT	2020	50	10					4370	4380		10.1109/TCYB.2019.2921369													
J								Fixed-Time Leader-Following Consensus for Multiple Wheeled Mobile Robots	IEEE TRANSACTIONS ON CYBERNETICS										Mobile robots; Protocols; Directed graphs; Observers; Manifolds; Nonlinear dynamical systems; Directed graphs; fixed-time consensus; formation control; leader-following consensus; wheeled mobile robots	MULTIAGENT SYSTEMS; COOPERATIVE CONTROL; TRACKING CONTROL; SUBJECT	This article deals with the problem of leader-following consensus for multiple wheeled mobile robots. Under a directed graph, a distributed observer is proposed for each follower to estimate the leader state in a fixed time. Based on the observer and a constructed nonlinear manifold, a novel protocol is designed such that the estimated leader state is tracked in a fixed time. Moreover, a switching protocol together with a linear manifold is proposed to ensure that fixed-time leader-following consensus is realized for any initial conditions without causing singularity issues. In contrast to alternative fixed-time consensus protocols in some existing results, the protocol proposed in this article is designed by constructing the nonlinear or linear manifold, which builds a new framework for fixed-time leader-following consensus. Furthermore, the obtained upper bound of settling time is explicitly linked with a single parameter in the protocol, which facilitates the adjustment of the bound under different performance requirements. Finally, the proposed protocol is applied to formation control of wheeled mobile robots.																	2168-2267	2168-2275				OCT	2020	50	10					4381	4392		10.1109/TCYB.2019.2955543													
J								Modal Regression-Based Atomic Representation for Robust Face Recognition and Reconstruction	IEEE TRANSACTIONS ON CYBERNETICS										Optimization; Face recognition; Data models; Cybernetics; Face; Laplace equations; Collaboration; Atomic representation (AR); face recognition (FR); modal regression (MR)	SPARSE REPRESENTATION; SELECTION	Representation-based classification (RC) methods, such as sparse RC, have shown great potential in face recognition (FR) in recent years. Most previous RC methods are based on the conventional regression models, such as lasso regression, ridge regression, or group lasso regression. These regression models essentially impose a predefined assumption on the distribution of the noise variable in the query sample, such as the Gaussian or Laplacian distribution. However, the complicated noises in practice may violate the assumptions and impede the performance of these RC methods. In this paper, we propose a modal regression (MR)-based atomic representation and classification (MRARC) framework to alleviate such limitations. MR is a robust regression framework which aims to reveal the relationship between the input and response variables by regressing toward the conditional mode function. Atomic representation is a general atomic norm regularized linear representation framework which includes many popular representation methods, such as sparse representation, collaborative representation, and low-rank representation as special cases. Unlike previous RC methods, the MRARC framework does not require the noise variable to follow any specific predefined distributions. This gives rise to the capability of MRARC in handling various complex noises in reality. Using MRARC as a general platform, we also develop four novel RC methods for unimodal and multimodal FR, respectively. In addition, we devise a general optimization algorithm for the unified MRARC framework based on the alternating direction method of multipliers and half-quadratic theory. The experiments on real-world data validate the efficacy of MRARC for robust FR and reconstruction.																	2168-2267	2168-2275				OCT	2020	50	10					4393	4405		10.1109/TCYB.2019.2903205													
J								Additive Integrals of q-Rung Orthopair Fuzzy Functions	IEEE TRANSACTIONS ON CYBERNETICS										q-rung orthopair fuzzy calculus (q-ROFC); q-rung orthopair fuzzy functions (q-ROFFs); q-rung orthopair fuzzy integrals (q-ROFIs); q-rung orthopair fuzzy sets (q-ROFSs)	PYTHAGOREAN MEMBERSHIP GRADES; CLASSIFIER FUSION; OPERATORS	The q-rung orthopair fuzzy set (q-ROFS) is a powerful tool to deal with uncertainty and ambiguity in real life. The theoretical basis for processing the continuous q-rung orthopair fuzzy information is q-rung orthopair fuzzy calculus (q-ROFC) and the main object is q-rung orthopair fuzzy functions (q-ROFFs). Recently, the authors proposed derivatives and differentials of q-ROFFs in the framework of q-ROFC. In this paper, we aim to further study the q-rung orthopair fuzzy integral (q-ROFI). It is the most important and fundamental part of the q-ROFC theoretical system with direct and powerful applications. Our contribution is the indefinite and definite integrals, and bridges the fuzzy calculus theoretical gap of the nonlinear q-ROFFs. In particular, we begin with the indefinite integral of q-ROFFs, which can be regarded as the anti-derivatives operations of our previous work. Some of their basic properties are discussed. Next, we give the accurate concept of definite integrals of q-ROFFs under additive operations, and obtain the explicit integral formula. Some properties of q-ROFIs, such as comparison, algebraic operations, and mean value theorem are analyzed. Finally, we generalize the q-ROFI to the case when membership and nonmembership functions are allowed to be correlated. After the theoretical results have been established, we present some numerical examples to demonstrate the rationality and effectiveness of integrating continuous q-rung orthopair fuzzy data with the q-ROFIs.																	2168-2267	2168-2275				OCT	2020	50	10					4406	4419		10.1109/TCYB.2019.2908657													
J								Multilayered Sampled-Data Iterative Learning Tracking for Discrete Systems With Cooperative-Antagonistic Interactions	IEEE TRANSACTIONS ON CYBERNETICS										Social networking (online); Laplace equations; Bandwidth; Economics; Iterative learning control; Training; Cooperative-antagonistic interactions; iterative learning control (ILC); multilayered systems; sampled-data learning control; signed graph	WAFER TEMPERATURE UNIFORMITY; MULTIAGENT SYSTEMS; TIME-SYSTEMS; NETWORKS; SYNCHRONIZATION; CONSENSUS; MODEL	The tracking for discrete systems is discussed by designing two kinds of multilayered iterative learning schemes with cooperative-antagonistic interactions in this paper. The definition of the signed graph is presented and iterative learning schemes are then designed to be multilayered and have cooperative-antagonistic interactions. Moreover, considering the limited bandwidth of information storage, the state information of these controllers is updated in light of previous learning iterations but not just dependent on the last iteration. Two simple criteria are addressed to discuss the tracking of discrete systems with multilayered and cooperative-antagonistic iterative schemes. The simulation results are shown to demonstrate the validity of the given criteria.																	2168-2267	2168-2275				OCT	2020	50	10					4420	4429		10.1109/TCYB.2019.2915664													
J								Cost-Aware Robust Control of Signed Networks by Using a Memetic Algorithm	IEEE TRANSACTIONS ON CYBERNETICS										Complex systems; Optimization; Memetics; Controllability; Approximation algorithms; Robust control; Knowledge engineering; Controllability; memetic algorithm (MA); minimum dominating set (MDS); signed networks; structural balance	DOMINATING SET; CONTROLLABILITY; OPTIMIZATION; ORGANIZATION; STRATEGY	The robust controllability (RC) of a complex system tries to select a set of dominating entities for the functional control of this entire system without uncertain disturbances, and the research on RC will help to understand the system's underlying functions. In this article, we introduce the control cost in signed networks and present a cost-aware robust control (CRC) problem in this scenario. The aim of CRC is to minimize the cost to control a set of dominating nodes and transform a set of unbalanced links into balanced ones, such that the signed network can be robustly controlled without uncertain unbalanced factors (like nodes and links). To solve this problem, we first model CRC as a constrained combination optimization problem, and then present a memetic algorithm with some problem-specific knowledge (like the neighbors of nodes, the constraints of CRC, and the fast computation of the cost under each optimization) to solve this problem on signed networks. The extensive experiments on both real social and biological networks assess that our algorithm outperforms several state-of-the-art RC algorithms.																	2168-2267	2168-2275				OCT	2020	50	10					4430	4443		10.1109/TCYB.2019.2932996													
J								Necessary and Sufficient Conditions on Pinning Stabilization for Stochastic Boolean Networks	IEEE TRANSACTIONS ON CYBERNETICS										Probabilistic logic; Stability analysis; Neurons; Control systems; Stochastic processes; Probability distribution; Cybernetics; Boolean network (BN); pinning control; semitensor product; stochastic disturbances	FEEDBACK STABILIZATION; CONTROLLABILITY; STABILITY; SYNCHRONIZATION; OBSERVABILITY	In this paper, the stabilization problem of the Boolean network (BN) with stochastic disturbances via pinning control has been investigated. The necessary and sufficient conditions are given for robust stabilization of a BN with stochastic disturbances. Then, pinning control is considered to stabilize a BN with stochastic disturbances. An algorithm is given to obtain a new stable system and the pinning control, including the pinned nodes, control design, and control adding, is also solved. Finding the minimal number of pinned nodes is further analyzed. The necessary and sufficient conditions are obtained for the solvability of pinning control, based on which some matrices sets are constructed which leads to the necessary and sufficient conditions of pinning t nodes. Furthermore, an algorithm is introduced to search the minimal number of pinned nodes and what exactly they are, which will reduce the computational burden. Examples are given to illustrate the efficiency of the obtained results.																	2168-2267	2168-2275				OCT	2020	50	10					4444	4453		10.1109/TCYB.2019.2931051													
J								Cooperative Coevolutionary Bare-Bones Particle Swarm Optimization With Function Independent Decomposition for Large-Scale Supply Chain Network Design With Uncertainties	IEEE TRANSACTIONS ON CYBERNETICS										Uncertainty; Maintenance engineering; Particle swarm optimization; Optimization; Encoding; Supply chains; Computer science; Bare-bones particle swarm optimization (BBPSO); cooperative coevolution (CC); large-scale supply chain network design under uncertainties (LUSCND)	MANAGEMENT; ALGORITHMS; MODEL	Supply chain network design (SCND) is a complicated constrained optimization problem that plays a significant role in the business management. This article extends the SCND model to a large-scale SCND with uncertainties (LUSCND), which is more practical but also more challenging. However, it is difficult for traditional approaches to obtain the feasible solutions in the large-scale search space within the limited time. This article proposes a cooperative coevolutionary bare-bones particle swarm optimization (CCBBPSO) with function independent decomposition (FID), called CCBBPSO-FID, for a multiperiod three-echelon LUSCND problem. For the large-scale issue, binary encoding of the original model is converted to integer encoding for dimensionality reduction, and a novel FID is designed to efficiently decompose the problem. For obtaining the feasible solutions, two repair methods are designed to repair the infeasible solutions that appear frequently in the LUSCND problem. A step translation method is proposed to deal with the variables out of bounds, and a labeled reposition operator with adaptive probabilities is designed to repair the infeasible solutions that violate the constraints. Experiments are conducted on 405 instances with three different scales. The results show that CCBBPSO-FID has an evident superiority over contestant algorithms.																	2168-2267	2168-2275				OCT	2020	50	10					4454	4468		10.1109/TCYB.2019.2937565													
J								Nonlocal Sparse Tensor Factorization for Semiblind Hyperspectral and Multispectral Image Fusion	IEEE TRANSACTIONS ON CYBERNETICS										Tensile stress; Matrix decomposition; Dictionaries; Spatial resolution; Hyperspectral imaging; Hyperspectral imaging; hyperspectral super-resolution; nonlocal spatial self-similarity; semiblind fusion; sparse tensor factorization		Combining a high-spatial-resolution multispectral image (HR-MSI) with a low-spatial-resolution hyperspectral image (LR-HSI) has become a common way to enhance the spatial resolution of the HSI. The existing state-of-the-art LR-HSI and HR-MSI fusion methods are mostly based on the matrix factorization, where the matrix data representation may be hard to fully make use of the inherent structures of 3-D HSI. We propose a nonlocal sparse tensor factorization approach, called the NLSTF_SMBF, for the semiblind fusion of HSI and MSI. The proposed method decomposes the HSI into smaller full-band patches (FBPs), which, in turn, are factored as dictionaries of the three HSI modes and a sparse core tensor. This decomposition allows to solve the fusion problem as estimating a sparse core tensor and three dictionaries for each FBP. Similar FBPs are clustered together, and they are assumed to share the same dictionaries to make use of the nonlocal self-similarities of the HSI. For each group, we learn the dictionaries from the observed HR-MSI and LR-HSI. The corresponding sparse core tensor of each FBP is computed via tensor sparse coding. Two distinctive features of NLSTF_SMBF are that: 1) it is blind with respect to the point spread function (PSF) of the hyperspectral sensor and 2) it copes with spatially variant PSFs. The experimental results provide the evidence of the advantages of the NLSTF_SMBF method over the existing state-of-the-art methods, namely, in semiblind scenarios.																	2168-2267	2168-2275				OCT	2020	50	10					4469	4480		10.1109/TCYB.2019.2951572													
J								Swarm Control for Self-Organized System With Fixed and Switching Topology	IEEE TRANSACTIONS ON CYBERNETICS										Topology; Switches; Dispersion; Maintenance engineering; Nonlinear dynamical systems; Asymptotic stability; Finite time; relation-invariable persistent formation (RIPF); self-organized system; swarm control; switching topology	LEADER-FOLLOWING CONSENSUS; STABILIZATION; VEHICLES; DESIGN	In this article, we propose the swarm control for a self-organized system with fixed and switching topology, which can realize aggregation, dispersion, or switching formation when swarm moves. The self-organized system can automatically construct the communication topology for intelligent units in swarm. Swarm control can realize aggregation and dispersion of intelligent units based on its communication topology when swarm moves. The proposed swarm control, in which distances between the related intelligent units are time varying, is different from traditional swarm consensus or swarm formation maintenance. To design swarm control, we define the normalization adjacency matrix and normalization degree matrix based on communication topology. The communication topology is automatically generated based on relation-invariable persistent formation. Depending on whether the communication topology changes or not, the swarm control can be classified as fixed topology and switching topology. Then, the swarm control with fixed and switching topology is designed and analyzed, respectively. The swarm control can realize stability asymptotically when topology is fixed and realize stability in finite time when topology is switched. The simulation results show that the proposed approaches are effective.																	2168-2267	2168-2275				OCT	2020	50	10					4481	4494		10.1109/TCYB.2019.2952913													
J								Robust Flexible Preserving Embedding	IEEE TRANSACTIONS ON CYBERNETICS										Manifolds; Principal component analysis; Feature extraction; Robustness; Optimization; Noise measurement; Sparse matrices; Feature extraction; flexible; nuclear norm; robust	DISCRIMINANT-ANALYSIS; IMAGE; REDUCTION; GRAPH	Neighborhood preserving embedding (NPE) has been proposed to encode overall geometry manifold embedding information. However, the class-special structure of the data is destroyed by noise or outliers existing in the data. To address this problem, in this article, we propose a novel embedding approach called robust flexible preserving embedding (RFPE). First, RFPE recovers the noisy data by low-rank learning and obtains clean data. Then, the clean data are used to learn the projection matrix. In this way, the projective learning is totally unaffected by noise or outliers. By encoding a flexible regularization term, RFPE can keep the property of the data points with a nonlinear manifold and be more flexible. RFPE searches the optimal projective subspace for feature extraction. In addition, we also extend the proposed RFPE to a kernel case and propose kernel RFPE (KRFPE). Extensive experiments on six public image databases show the superiority of the proposed methods over other state-of-the-art methods.																	2168-2267	2168-2275				OCT	2020	50	10					4495	4507		10.1109/TCYB.2019.2953922													
J								Fuzzy Knowledge-Based Prediction Through Weighted Rule Interpolation	IEEE TRANSACTIONS ON CYBERNETICS										Interpolation; Knowledge based systems; Prediction algorithms; Cognition; Fuzzy sets; Task analysis; Predictive models; Attribute weighting; intelligent prediction; knowledge interpolation; sparse knowledge	SYSTEMS	Fuzzy rule interpolation (FRI) facilitates approximate reasoning in fuzzy rule-based systems only with sparse knowledge available, remedying the limitation of conventional compositional rule of inference working with a dense rule base. Most of the existing FRI work assumes equal significance of the conditional attributes in the rules while performing interpolation. Recently, interesting techniques have been reported for achieving weighted interpolative reasoning. However, they are either particularly tailored to perform classification problems only or employ attribute weights that are obtained using additional information (rather than just the given rules), without integrating them with the associated FRI procedure. This paper presents a weighted rule interpolation scheme for performing prediction tasks by the use of fuzzy sparse knowledge only. The weights of rule conditional attributes are learned from a given rule base to discriminate the relative significance of each individual attribute and are integrated throughout the internal mechanism of the FRI process. This scheme is demonstrated using the popular scale and move transformation-based FRI for resolving prediction problems, systematically evaluated on 12 benchmark prediction tasks. The performance is compared with the relevant state-of-the-art FRI techniques, showing the efficacy of the proposed approach.																	2168-2267	2168-2275				OCT	2020	50	10					4508	4517		10.1109/TCYB.2018.2887340													
J								Predicting Citation Count of Scientists as a Link Prediction Problem	IEEE TRANSACTIONS ON CYBERNETICS										Measurement; Task analysis; Complex networks; Predictive models; Cybernetics; Bibliometrics; Citation count; complex networks; directed and weighted networks; dynamic networks; link prediction	COMMUNITY; IMPACT	The studies dealing with the problem of predicting scientific impacts in the scientific world mostly focus on predicting citation count of papers (PCCP). However, in the literature, only a little bit of research has been conducted on estimating the future influence of scientists individually. Estimating the impact of scientists individually is a worthwhile task for the following scientific research and cooperatives. From this point of view, a new supervised link prediction method is proposed to predict the citation count of scientists (PCCS). Many PCCP studies employ document-based attributes, such as titles, abstracts, and keywords of papers; institutions of scientists; impact factors of publishers; etc. and they do not take advantage of any topological features of complex networks formed with citations among papers. However, citation networks include valuable features for PCCP and PCCS. Therefore, we formulate the problem of PCCS as a link prediction problem in directed, weighted, and temporal citation networks. The proposed approach predicts not only links but also its weights. Our supervised link prediction method is tested on two citation networks in Experiment 1. The results of Experiment 1 confirm that our method achieves promising performances when considering prediction links with its weights are addressed for the first time in terms of link prediction in directed, weighted, and temporal networks. In Experiment 2, the performance of the proposed link prediction metric and five well-known link prediction metrics are compared in terms of prediction new links in complex networks. The results of Experiment 2 demonstrate that the proposed link prediction metric outperforms all baseline link prediction metrics.																	2168-2267	2168-2275				OCT	2020	50	10					4518	4529		10.1109/TCYB.2019.2900495													
J								Accelerated Guided Sampling for Multistructure Model Fitting	IEEE TRANSACTIONS ON CYBERNETICS										Correlation; Sorting; Data models; Computational modeling; Sampling methods; Acceleration; Estimation; Hypothesis generation; keypoint matching scores; multiple structures; residual sorting; robust model fitting	ROBUST; ALGORITHM; CONSENSUS	The performance of many robust model fitting techniques is largely dependent on the quality of the generated hypotheses. In this paper, we propose a novel guided sampling method, called accelerated guided sampling (AGS), to efficiently generate the accurate hypotheses for multistructure model fitting. Based on the observations that residual sorting can effectively reveal the data relationship (i.e., determine whether two data points belong to the same structure), and keypoint matching scores can be used to distinguish inliers from gross outliers, AGS effectively combines the benefits of residual sorting and keypoint matching scores to efficiently generate accurate hypotheses via information theoretic principles. Moreover, we reduce the computational cost of residual sorting in AGS by designing a new residual sorting strategy, which only sorts the top-ranked residuals of input data, rather than all input data. Experimental results demonstrate the effectiveness of the proposed method in computer vision tasks, such as homography matrix and fundamental matrix estimation.																	2168-2267	2168-2275				OCT	2020	50	10					4530	4543		10.1109/TCYB.2018.2889908													
J								Cooperative Mining in Blockchain Networks With Zero-Determinant Strategies	IEEE TRANSACTIONS ON CYBERNETICS										Blockchain; Games; Game theory; Optimization; Cybernetics; Bitcoin; Blockchain networks; cooperative mining; game theory; zero-determinant strategies (ZD strategies)	EVOLUTION; EXTORTION	In proof-of-work (PoW)-based blockchain networks, the miners contribute their distributed computation in solving a crypto-puzzle competition to win the reward. To secure stable profits, some miners organize mining pools and share the rewards from the pool in proportion to each miner's contribution. However, some miners may exhibit malicious behaviors which cause a waste of distributed computation resource, even posing a threat on the efficiency of blockchain networks. In this paper, we propose a new game-theoretic framework to incentivize miners mining honestly and help to bring about a higher total welfare of blockchain networks. We first formulate the mining process as a noncooperative iterated game. We then propose a mechanism in terms of zero-determinant strategies (ZD strategies) to encourage the cooperative mining and improve the efficiency of mining in PoW-based blockchain networks. In addition, we theoretically analyze the maximum system welfare of the target pool through the method of optimization. Numerical illustrations are also presented to support our theoretical results.																	2168-2267	2168-2275				OCT	2020	50	10					4544	4549		10.1109/TCYB.2019.2915253													
J								Cooperative Circumnavigation Control of Networked Microsatellites	IEEE TRANSACTIONS ON CYBERNETICS										Small satellites; Space vehicles; Planetary orbits; Laplace equations; Earth; Cooperative circumnavigation (CCN); formation control; networked microsatellites	AFFINE FORMATION CONTROL; SPACECRAFT FORMATION; TRACKING CONTROL	This paper addresses the trajectory analysis, mission design, and control law for multiple microsatellites to cooperatively circumnavigate a host spacecraft. This cooperative circumnavigation (CCN) problem is defined to drive a group of networked microsatellites to a predefined planar ellipse concerning a host spacecraft while maintaining a geometric formation configuration. We first design several potential functions to guide the microsatellites to the given planar elliptical orbit with a proper radius. Next, the affine Laplacian matrix is introduced to characterize the desired formation shape of microsatellites. Based on the potential functions and the Laplacian matrix, a CCN control law is finally proposed. Then, the simulation results of eight microsatellites with earth-orbiting mission scenarios are given, where the natural trajectory motion is incorporated which consumes nearly zero-fuel.																	2168-2267	2168-2275				OCT	2020	50	10					4550	4555		10.1109/TCYB.2019.2923119													
J								A consistently oriented basis for eigenanalysis	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Eigenvectors; Eigenvalues; Singular-value decomposition; Directional statistics		Repeated application of eigen-centric methods to an evolving dataset reveals that eigenvectors calculated by well-established computer implementations are not stable along an evolving sequence. This is because the sign of any one eigenvector may point along either the positive or negative direction of its associated eigenaxis, and for any one eigenfunction call, the sign does not matter when calculating a solution. This work reports a model-free algorithm that creates a consistently oriented basis of eigenvectors. The algorithm postprocesses any well-established eigen call and is therefore agnostic to the particular implementation of the latter. Once consistently oriented, directional statistics can be applied to the eigenvectors in order to track their motion and summarize their dispersion. When a consistently oriented eigensystem is applied to methods of machine learning, the time series of training weights becomes interpretable in the context of the machine-learning model. Ordinary linear regression is used to demonstrate such interpretability. A reference implementation of the algorithm reported herein has been written in Python and is freely available, both as source code and through the thucyd Python package.																	2364-415X	2364-4168				OCT	2020	10	4					301	319		10.1007/s41060-020-00227-z													
J								Fast multi-resolution segmentation for nonstationary Hawkes process using cumulants	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Hawkes process; Nonstationary; Segmentation; Cumulants		The stationarity is assumed in the vanilla Hawkes process, which reduces the model complexity but introduces a strong assumption. In this paper, we propose a fast multi-resolution segmentation algorithm to capture the time-varying characteristics of the nonstationary Hawkes process. The proposed algorithm is based on the first- and second-order cumulants. Except for the computation efficiency, the algorithm can provide a hierarchical view of the segmentation at different resolutions. We extensively investigate the impact of hyperparameters on the performance of this algorithm. To ease the choice of hyperparameter, we propose a refined Gaussian process-based segmentation algorithm, which is proved to be a robust method. The proposed algorithm is applied to a real vehicle collision dataset, and the outcome shows some interesting hierarchical dynamic time-varying characteristics.																	2364-415X	2364-4168				OCT	2020	10	4					321	330		10.1007/s41060-020-00223-3													
J								Streaming statistical models via Merge & Reduce	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Mergeable statistical models; Large data; Streaming; Distributed; Regression analysis	BAYESIAN-ANALYSIS; CORE-SETS	Merge & Reduce is a general algorithmic scheme in the theory of data structures. Its main purpose is to transform static data structures-that support only queries-into dynamic data structures-that allow insertions of new elements-with as little overhead as possible. This can be used to turn classic offline algorithms for summarizing and analyzing data into streaming algorithms. We transfer these ideas to the setting of statistical data analysis in streaming environments. Our approach is conceptually different from previous settings where Merge & Reduce has been employed. Instead of summarizing the data, we combine the Merge & Reduce framework directly with statistical models. This enables performing computationally demanding data analysis tasks on massive data sets. The computations are divided into small tractable batches whose size is independent of the total number of observations n. The results are combined in a structured way at the cost of a bounded O(log n) factor in their memory requirements. It is only necessary, though nontrivial, to choose an appropriate statistical model and design merge and reduce operations on a casewise basis for the specific type of model. We illustrate our Merge & Reduce schemes on simulated and real-world data employing (Bayesian) linear regression models, Gaussian mixture models and generalized linear models.																	2364-415X	2364-4168				OCT	2020	10	4					331	347		10.1007/s41060-020-00226-0													
J								Modeling infection methods of computer malware in the presence of vaccinations using epidemiological models: an analysis of real-world data	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Malware; Epidemiological model; Compartmental models; Vaccination	PROPAGATION; NETWORKS; SPREAD	Computer malware and biological pathogens often use similar infection mechanisms. For this reason, it has been suggested to model malware spread using epidemiological models developed to characterize the spread of biological pathogens. However, to date, most work examining the similarities between malware and pathogens using such methods was based on theoretical analysis and simulation. Here we extend the classical susceptible-infected-recovered epidemiological model to describe two of the most common infection methods used by malware. We fit the proposed model to malware collected between April 2017 and April 2018 from a major anti-malware vendor. We show that by fitting the proposed model it is possible to identify the method of transmission used by the malware, its rate of infection, and the number of machines which will be infected unless blocked by anti-virus software. In a large sample of malware infections, the Spearman correlation between the number of actual and predicted infected machines is rho = 0.84. Examining cases where an anti-malware "signature" was transmitted to susceptible computers by the anti-virus provider, we show that the time to remove the malware will be short and independent of the number of infected computers if fewer than approximately 60% of susceptible computers have been infected. If more computers were infected, the time to removal will be approximately 3.2 times greater and will depend on the fraction of infected computers. Our results show that the application of epidemiological models of infection to malware can provide anti-virus providers with information on malware spread and its potential damage. We further propose that similarities between computer malware and biological pathogens, the availability of data on the former, and the dearth of data on the latter, make malware an extremely useful model for testing interventions which could later be applied to improve medicine.																	2364-415X	2364-4168				OCT	2020	10	4					349	358		10.1007/s41060-020-00225-1													
J								An improved scheme for determining top-revenue itemsets for placement in retail businesses	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										High-utility itemset mining; Top-kmining; Retailing; Supermarkets; Product placement; Indexing	UTILITY PATTERNS; MANAGEMENT	Utility mining has been emerging as an important area in data mining. While existing works on utility mining for retail businesses have primarily focused on the problem of finding high-utility itemsets from transactional databases, they implicitly assume that each item occupies only one slot. Here, the slot size of a given item is the number of (integer) slots occupied by that item on the retail store shelves. However, in many real-world scenarios, the number of slots consumed by different items typically varies. Hence, this paper considers that a given item may physically occupy any fixed (integer) number of slots. Thus, we address the problem of efficiently determining the top-utility itemsets when a given number of slots is specified as input. The key contributions of our work are three fold. First, we present an efficient framework to determine the top-utility itemsets for different user-specified number of slots that need to be filled. Second, we propose a novel flexible and efficient index, designated as Slot Type Utility (STU) index, for facilitating quick retrieval of the top-utility itemsets for a given number of slots. Third, we conducted an extensive performance evaluation using both real and synthetic datasets to demonstrate the overall effectiveness of the STU index in quickly retrieving the top-utility itemsets by considering a placement scheme in terms of execution time and utility (net revenue) as compared to recent existing schemes.																	2364-415X	2364-4168				OCT	2020	10	4					359	375		10.1007/s41060-020-00221-5													
J								Automatic optimization of outlier detection ensembles using a limited number of outlier examples	INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS										Bagging; Outlier detection; Outlier detection ensemble; Semi-supervised outlier detection	ANOMALY DETECTION; ALGORITHMS	In data analysis, outliers are deviating and unexpected observations. Outlier detection is important, because outliers can contain critical and interesting information. We propose an approach for optimizing outlier detection ensembles using a limited number of outlier examples. In our work, a limited number of outlier examples are defined as from 1 to 10% of the available outliers. The optimized outlier detection ensembles consist of outlier detection algorithms, which provide an outlier score and utilize adjustable parameters. The automatic optimization determines the parameter values, which enhance the discrimination of inliers and outliers. This increases the efficiency of the outlier detection. Outliers are rare by definition, which makes the optimization with a few examples beneficial. Obtaining examples of outliers can be prohibitively challenging, and the outlier examples should be used efficiently.																	2364-415X	2364-4168				OCT	2020	10	4					377	394		10.1007/s41060-020-00222-4													
J								Semantic string operation for specializing AHC algorithm for text clustering	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE										String vector; Semantic similarity; String vector based AHC algorithm; Text clustering		This article proposes the modified AHC (Agglomerative Hierarchical Clustering) algorithm which clusters string vectors, instead of numerical vectors, as the approach to the text clustering. The results from applying the string vector based algorithms to the text clustering were successful in previous works and synergy effect between the text clustering and the word clustering is expected by combining them with each other; the two facts become motivations for this research. In this research, we define the operation on string vectors called semantic similarity, and modify the AHC algorithm by adopting the proposed similarity metric as the approach to the text clustering. The proposed AHC algorithm is empirically validated as the better approach in clustering texts in news articles and opinions. We need to define and characterize mathematically more operations on string vectors for modifying more advanced machine learning algorithms.																	1012-2443	1573-7470				OCT	2020	88	10					1083	1100		10.1007/s10472-019-09687-x													
J								State-of-the-Art Robotic Devices for Wrist Rehabilitation: Design and Control Aspects	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Wrist; Rehabilitation robotics; Exoskeletons; Medical treatment; Brushless DC motors; Actuation; control paradigm; mechanical design; rehabilitation robot; stroke; wrist orthosis	HYBRID IMPEDANCE CONTROL; AIDED NEUROREHABILITATION; EXOSKELETON; STROKE; ACTUATION; PERFORMANCE; MECHANISMS; MOVEMENTS; RICEWRIST; FEEDBACK	Robot-assisted physical therapy of the upper limb is becoming popular among the rehabilitation community. The wrist is the second most complicated joint in the upper limb after shoulder in terms of degrees of freedom. Several robotic devices have been developed during the past three decades for wrist joint rehabilitation. Intensive physical therapy and repetitive self-practice, with objective measurement of performance, could be provided by using these wrist rehabilitation robots at a low cost. There has been an increasing trend in the development of wrist rehabilitation robots to provide safe and customized therapy according to the disability level of patients. The mechanical design and control paradigms are two active fields of research undergoing rapid developments in the field of robot-assisted wrist rehabilitation. The mechanical design of these robots could be divided into the categories of end-effector based robots and wearable robotic orthoses. The control for these wrist rehabilitation robots could also be divided into the conventional trajectory tracking control mode and the assist-as-needed control mode for providing customized robotic assistance. This article presents a review of the mechanical design and control aspects of wrist rehabilitation robots. Experimental evaluations of these robots with healthy and neurologically impaired are also discussed along with the future directions of research in the design and control domains of wrist rehabilitation robots.																	2168-2291	2168-2305				OCT	2020	50	5					361	372		10.1109/THMS.2020.2976905													
J								Musculoskeletal Model for Path Generation and Modification of an Ankle Rehabilitation Robot	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Rehabilitation robotics; Ligaments; Joints; Bones; Springs; Ankle joint musculoskeletal modeling; optimization of muscle forces; parallel ankle rehabilitation robot; robot path generation and modification	TRAJECTORY GENERATION; MUSCLE-ACTIVITY; GAIT; ORTHOSIS; WALKING; DESIGN; SIMULATIONS; PERFORMANCE; KINEMATICS; FORCE	While newer designs and control approaches are being proposed for rehabilitation robots, vital information from the human musculoskeletal system should also be considered. Incorporating knowledge about joint biomechanics during the development of robot controllers can enhance the safety and performance of robot-aided treatments. In this article, the optimal path or trajectories of a parallel ankle rehabilitation robot were generated by minimizing joint reaction moments and the tension along ligaments and muscle-tendon units. The simulations showed that using optimized robot paths, user efforts could be reduced to 80%, thereby ensuring less strain on weaker or stiffer ligaments, etc. Additionally, to limit the moments applied by the robot in stiff or constrained directions, the intended robot path was modified to move the commanded position in the direction opposite to that of the position error. Such online modification of the robot path can lead to a reduction in forces applied by a robot to the subject. Simulation results and experimental findings with healthy subjects using an ankle rehabilitation robot prototype and subsequent statistical analysis further validated that path modification based on ankle joint biomechanics results in a reduction in undesired forces experienced by human users during treatment.																	2168-2291	2168-2305				OCT	2020	50	5					373	383		10.1109/THMS.2020.2989688													
J								Reciprocity and Its Neurological Correlates in Human-Agent Cooperation	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Task analysis; Games; Hospitals; Atmospheric measurements; Particle measurements; Spectroscopy; Psychology; Cooperation calibration; functional near-infrared spectroscopy (fNIRS); human-agent interaction; microworld; neuroergonomics	NEAR-INFRARED SPECTROSCOPY; FNIRS; ARTIFACTS; TRUST; NORM	Reciprocal cooperation is prevalent in human society. Understanding human reciprocal cooperation in human-agent interaction can help design human-agent systems that promote cooperation and joint performance. Studies have found that people reciprocate cooperative behavior when interacting with computer agents in social dilemma games. However, few studies have investigated human reciprocal cooperation with agents in complex dynamic environments. This article examines the behavioral and neurological patterns of reciprocal cooperation in a hospital management microworld experiment. The participants (n = 30) work with both high- and low-cooperation computer agents to share resources to cope with dynamic demands. Participants' resource sharing behaviors were recorded and their prefrontal cortex (PFC) activation was measured using functional near-infrared spectroscopy (fNIRS) technology. Similar to previous studies conducted with participants in the United States, results demonstrate that participants in China showed reciprocal cooperation behaviors with the agents. Specifically, participants share more resources and achieve higher performance when working with a high-cooperation agent than with a low-cooperation agent. A high activation level is detected in the right dorsolateral PFC when working with a high-cooperation agent. Other PFC activation patterns imply that cooperation could be unnecessarily mentally taxing in certain situations. These findings suggest that human cooperativeness in human-agent systems can be calibrated by an agent's cooperation behavior. System designers should design for appropriate cooperativeness and avoid the inefficient use of system resources. Neurological measures could be a useful tool to investigate the mental process in human-agent cooperation																	2168-2291	2168-2305				OCT	2020	50	5					384	394		10.1109/THMS.2020.2992224													
J								Physiological Synchrony Revealed by Delayed Coincidence Count: Application to a Cooperative Complex Environment	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Cooperation; delayed coincidence count; dyad; electrocardiogram (ECG); physiological synchrony	UNITARY EVENTS; LINKAGE	Synchrony at the physiological level is an objective measure that can be used to investigate cooperation between human agents. This physiological synchrony has been experimentally observed in different dyadic contexts through measures of the autonomous system such as cardiac measures. Various metrics are used to characterize synchrony between participants such as cross-correlation, weighted coherence, or cross recurrence quantification analysis and with a wide variety of paradigms. We propose the delayed coincidence count as a new method for assessing cardiac synchrony. Delayed coincidence count has already been used to characterize synchrony in firing neurons populations. While being straightforward and computationally light, this method has already been formally proven to be statistically robust. A complex dynamic microworld is designed with two difficulty levels and two cooperation conditions. A total of 40 participants, i.e., 20 teams, voluntarily has conducted the experiment. The delayed coincidence count method (with a coincidence threshold delta of 20 ms) reveals a significant synchrony (p < . 01) during the cooperative and high difficulty condition only, while the other methods did not. The results are interpreted in terms of interaction intensity in accordance with recent literature.																	2168-2291	2168-2305				OCT	2020	50	5					395	404		10.1109/THMS.2020.2986417													
J								A Multiviewpoint Outdoor Dataset for Human Action Recognition	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Cameras; YouTube; Australia; Drones; Surveillance; Nonlinear distortion; Human action recognition; kernelized rank pooling; multiviewpoint; video dataset		Advancements in deep neural networks have contributed to near-perfect results for many computer vision problems, such as object recognition, face recognition, and pose estimation. However, human action recognition is still far from human-level performance. Owing to the articulated nature of the human body, it is challenging to detect an action from multiple viewpoints, particularly from an aerial viewpoint. This is further compounded by a scarcity of datasets that cover multiple viewpoints of actions. To fill this gap and enable research in wider application areas, in this article we present a multiviewpoint outdoor action recognition dataset collected from YouTube and our own drone. The dataset consists of 20 dynamic human action classes, 2324 video clips, and 503 086 frames. All videos are cropped and resized to 720 x 720 without distorting the original aspect ratio of the human subjects in videos. This dataset should be useful to many research areas, including action recognition, surveillance, and situational awareness. We evaluate the dataset with a two-stream convolutional neural network architecture coupled with a recently proposed temporal pooling scheme called kernelized rank pooling that produces nonlinear feature subspace representations. The overall baseline action recognition accuracy is 74.0%.																	2168-2291	2168-2305				OCT	2020	50	5					405	413		10.1109/THMS.2020.2971958													
J								A Smartphone-Based Adaptive Recognition and Real-Time Monitoring System for Human Activities	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Data compression; deep learning (DL); hierarchical classification (HC); human activity recognition (HAR)		Human activity recognition (HAR) using smartphones provides significant healthcare guidance for telemedicine and long-term treatment. Machine learning and deep learning (DL) techniques are widely utilized for the scientific study of the statistical models of human behaviors. However, the performance of existing HAR platforms is limited by complex physical activity. In this article, we proposed an adaptive recognition and real-time monitoring system for human activities (Ada-HAR), which is expected to identify more human motions in dynamic situations. The Ada-HAR framework introduces an unsupervised online learning algorithm that is independent of the number of class constraints. Furthermore, the adopted hierarchical clustering and classification algorithms label and classify 12 activities (five dynamics, six statics, and a series of transitions) autonomously. Finally, practical experiments have been performed to validate the effectiveness and robustness of the proposed algorithms. Comparedwith the methods mentioned in the literature, the results show that the DL-based classifier obtains a higher recognition rate (95.15%, waist, and 92.20%, pocket). The decision-tree-based classifier is the fastest method for modal evolution. Finally, the Ada-HAR system can monitor human activity in real time, regardless of the direction of the smartphone.																	2168-2291	2168-2305				OCT	2020	50	5					414	423		10.1109/THMS.2020.2984181													
J								Finding a Secure Place: A Map-Based Crowdsourcing System for People With Autism	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Autism; Urban areas; Human computer interaction; Crowdsourcing; Interviews; Sociology; Statistics; Autism; crowdsourcing; human-computer interaction; maps; spatiality	CHILDREN	People with autism have idiosyncratic sensory experiences, which may impact on how they live the "spaces" of their everyday life. Starting from an investigation of their conception and experience of "secure places," we defined a series of user requirements for designing technology that supports their everyday movements in the urban environment. On the basis of such requirements, we developed an interactive system that leverages crowdsourcing mechanisms to map places that are perceived as secure by the population with autism.																	2168-2291	2168-2305				OCT	2020	50	5					424	433		10.1109/THMS.2020.2984743													
J								Agreement Study Using Gesture Description Analysis	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Gesture recognition; user centered design; human computer interaction; participatory design; agreement analysis; gesture descriptors		Choosing adequate gestures for touchless interfaces is a challenging task that has a direct impact on human-computer interaction. Such gestures are commonly determined by the designer, ad-hoc, rule-based, or agreement-based methods. Previous approaches to assess agreement grouped the gestures into equivalence classes and ignored the integral properties that are shared between them. In this article, we propose a generalized framework that inherently incorporates the gesture descriptors into the agreement analysis. In contrast to previous approaches, we represent gestures using binary description vectors and allow them to be partially similar. In this context, we introduce a new metric referred to as soft agreement rate (SAR) to measure the level of agreement and provide a mathematical justification for this metric. Furthermore, we perform computational experiments to study the behavior of SAR and demonstrate that existing agreement metrics are a special case of our approach. Our method is evaluated and tested through a guessability study conducted with a group of neurosurgeons. Nevertheless, our formulation can be applied to any other user-elicitation study. Results show that the level of agreement obtained by SAR is 2.64 times higher than the previous metrics. Finally, we show that our approach complements the existing agreement techniques by generating an artificial lexicon based on the most agreed properties.																	2168-2291	2168-2305				OCT	2020	50	5					434	443		10.1109/THMS.2020.2992216													
J								Human Threshold Model for Perceiving Changes in System Dynamics	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Haptic interfaces; Damping; System dynamics; Frequency response; Force; Manipulators; Difference threshold; frequency response function (FRF); haptics; just-noticeable difference (JND); mass-spring-damper systems; Weber's law	DISTANCE-TO-BREAK; MANUAL DISCRIMINATION; PERCEPTUAL ANALYSIS; HAPTIC PERCEPTION; TELEOPERATION; FORCE; STABILITY	Limitations of a haptic device can cause distortions of the force feedback it presents. Just-noticeable difference (JND) in system dynamics is important for creating transparent haptic interaction. Based on the previous work, this article presents a unified model that extends the existing JND rule. Our approach projects the JNDs in the mechanical properties of a second-order mass-spring-damper system onto the real and imaginary components of the system's frequency response function (FRF). We discuss the results of two experiments and show that the JNDs obtained for both the real and imaginary components can be expressed as the same fraction of, and thus are proportional to, the magnitude of the total system's FRF. Furthermore, the findings are generalized to cases where the system's dynamics order is different than two. What results is a unified model that accurately describes the threshold for changes in human perception of any linear system dynamics with only two dimensions: the real and imaginary axes in the complex plane.																	2168-2291	2168-2305				OCT	2020	50	5					444	453		10.1109/THMS.2020.2989383													
J								Estimating an LPV Model of Driver Neuromuscular Admittance Using Grip Force as Scheduling Variable	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Driving behavior; grip force; linear parameter-varying (LPV) models; neuromuscular admittance	IDENTIFICATION; ADAPTATION; STIFFNESS; DYNAMICS; BEHAVIOR; STRETCH; REFLEX; MUSCLE	Humans can rapidly change their low-frequency arm dynamics to resist forces or give way to them. Quantifying driver time-varying arm dynamics is important to develop steer-by-wire and haptic support systems. Conventional linear time-invariant (LTI) identification, and even time-varying techniques such as wavelets, fail to capture fast changing dynamics. Moreover, such techniques require perturbation signals on the steering wheel (SW), which may affect steering feel and control behavior. We propose a novel two-stepmethod to estimate time-varying driver admittance, using unobtrusive grip-force measurements of the hands on the wheel to schedule a linear parameter-varying (LPV) model that captures the full admittance range. A total of 18 subjects participated in two experiments in a simulator with an actuated SW. In a sensorimotor control experiment, we first establish the grip force and admittance relationship, requiring subjects to perform a boundary tracking task where perturbations on the wheel enabled local LTI identification. Six boundary widths is used to evoke admittance changes, after which a global LPV model is obtained through interpolation between the local models. Results show an inverse relationship between grip force and admittance and that the LPV model accurately captures the admittance settings (fit percentage> 90%). Second, a driving experiment is followed that aims to evoke differences in grip force and admittance in response to varying road widths, offering more realistic data to evaluate the LPV model predictions. Results show that the LPV model accurately describes adaptations in admittance to road width. Our method allows for online estimation of time-varying admittance during driving, without applying force perturbations.																	2168-2291	2168-2305				OCT	2020	50	5					454	464		10.1109/THMS.2020.2989685													
J								Hierarchical Eye-Tracking Data Analytics for Human Fatigue Detection at a Traffic Control Center	IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS										Fatigue; Interpolation; Data integrity; Noise measurement; Data mining; Tracking; Data analysis; Eye movement; hierarchical-based interpolation; human fatigue; traffic management	FIXATION; ALGORITHM; SACCADES; NETWORK; QUALITY	Eye-tracking-based human fatigue detection at traffic control centers suffers from an unavoidable problem of low-quality eye-tracking data caused by noisy and missing gaze points. In this article, the authors conducted pioneering work by investigating the effects of data quality on eye-tracking-based fatigue indicators and by proposing a hierarchical-based interpolation approach to extract the eye-tracking-based fatigue indicators from low-quality eye-tracking data. This approach adaptively classified the missing gaze points and hierarchically interpolated them based on the temporal-spatial characteristics of the gaze points. In addition, the definitions of applicable fixations and saccades for human fatigue detection is proposed. Two experiments are conducted to verify the effectiveness and efficiency of the method in extracting eye-tracking-based fatigue indicators and detecting human fatigue. The results indicate that most eye-tracking parameters are significantly affected by the quality of the eye-tracking data. In addition, the proposed approach can achieve much better performance than the classic velocity threshold identification algorithm (I-VT) and a state-of-the-art method (U'n'Eye) in parsing low-quality eye-tracking data. Specifically, the proposed method attained relatively stable eye-tracking-based fatigue indicators and reported the highest accuracy in human fatigue detection. These results are expected to facilitate the application of eye movement-based human fatigue detection in practice.																	2168-2291	2168-2305				OCT	2020	50	5					465	474		10.1109/THMS.2020.3016088													
J								Performance analysis of CE-OFDM-CPM Modulation using MIMO system over wireless channels	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Constant envelope OFDM; Maximum-likelihood sequence estimation; Peak-to-average power ratio; Multiple-input multiple-output OFDM		Orthogonal Frequency-Division Multiplexing (OFDM) is a multicarrier modulation that has expanded attractiveness and is used for wireless communication system. However one key weakness of OFDM signal is the high Peak-to-Average Power Ratio (PAPR). The high PAPR of OFDM signal cause nonlinear distortions by the power amplifier, which in turn affects negatively the OFDM transmission signal. These nonlinearities in amplifiers cause both Inter-Symbol Interference (ISI) and inter-carrier interference (ICI) in the system. A "power back-off" is required to prevent spectral broadening and performance degradation from inter-modulation distortion. To overcome this problem we propose Constant Envelope OFDM (CE-OFDM) which provides a good solution to the high PAPR issue in OFDM. OFDM signal is transformed, by way of Phase Modulation (PM), to a constant envelope signal, thereby alleviating the need for a power back-off and allowing for the most efficient power amplifier operation possible. In this paper the implementation of Maximum-Likelihood Sequence Estimation (MLSE) channel equalization in CE-OFDM-PM is proposed, a performance gain comparison and evaluation over fast fading channels well be presented and discussed. At the same time, Multiple-Input Multiple-Output (MIMO) system is found to provide better performance over wireless channels by providing communication links with substantial diversity and capacity. Likewise for MIMO system, simulation results are given in terms of BER (Bit Error Rate) to show the performance gain of the Alamouti code and of the proposed receiver. The simulation results show that the Minimum Mean Square Error (MMSE) is the best one to avoid ISI.																	1868-5137	1868-5145				OCT	2020	11	10			SI		3937	3945		10.1007/s12652-019-01628-0													
J								Acknowledgment scheme using cloud for node networks with energy-aware hybrid scheduling strategy	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Cloud acknowledgement scheme (CACKS); Cloud computing; Mobile ad hoc network; Scheduler; Energy consumption; Acknowledgement packets; Virtual machine		Cloud computing is attracting a lot of traffic on the Internet. Due to the distributed nature of the ad hoc networks, there is no clear path for the communication between nodes. Additionally, there is no centralized or master node to guide the rest of the nodes in the distributed networks. Since the networks are continually expanding, it is vital to mention that there is a substantial increase in the number of attacks. As such, we became interested to consider monitoring the wireless network using cloud. This way, we will be able to deal with varies attacks and to provide better guidance for the networks. In this paper, we propose a new approach for acknowledgement scheme, using a one hop cloud technology, called Cloud Acknowledgement Scheme. This approach strengthens the wireless network by introducing cloud as a monitoring tool as well as to act as a leader node. An efficient cloud provisioning needs a better scheduling scheme. Towards this end, this paper is proposing a new approach to support the short-lived nature of acknowledgment packets in an efficient manner. Our proposed approach constitutes of two developed algorithms that act as one. These scheduling algorithms help to accomplish the purpose of cloud acknowledgment scheme. It is also important and significant to consider the cloud's awareness of energy consumption to reduce the impact on the environment. Towards this end, monitoring energy consumption is achieved by assigning priorities on the given tasks and balancing the performance and the energy of the cloud. The proposed approach is demonstrated and proved as working models using simulations. The results suggest that our proposed approach has the potential to alternate other existing acknowledgement schemes.																	1868-5137	1868-5145				OCT	2020	11	10			SI		3947	3962		10.1007/s12652-019-01629-z													
J								FACO: a hybrid fuzzy ant colony optimization algorithm for virtual machine scheduling in high-performance cloud computing	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Ant colony optimization; Fuzzy logic; Cloud computing; Load balancing; Scheduling; Taguchi DOE	PLACEMENT	High-performance cloud computing has recently become the focus of much interest. Extensive research has shown that scheduling and load balancing are among the key aspects of performance optimization. The allocation of a set of requests into a set of computing resources, which is considered as an NP-hard problem, aims to distribute efficiently the load within the cloud architecture. To resolve this problem, the last decade has seen a growing trend towards using hybrid approaches to combine the advantages of different algorithms. In this paper, we propose a hybrid fuzzy ant colony optimization algorithm (FACO) for virtual machine scheduling to guarantee high-efficiency in a cloud environment. The proposed fuzzy module evaluates historical information to calculate the pheromone value and select a suitable server while keeping an optimal computing time. The experimental work presented in this study provides one of the first investigations into how to choose the optimal parameters of ant colony optimization algorithms using the Taguchi experimental design. We have simulated the proposed algorithm through the Cloud Analyst and CloudSim simulators by applying different cloud configurations to evaluate the performance of the proposed algorithm. Our findings highlight how response time and processing time are improved compared to the Round Robin algorithm, Throttled algorithm and Equally Spread Current Execution Load algorithm, especially in the case of a high number of nodes. FACO algorithm could be applied to define efficient cloud architecture adapted to high-performance applications.																	1868-5137	1868-5145				OCT	2020	11	10			SI		3975	3987		10.1007/s12652-019-01631-5													
J								Car telematics big data analytics for insurance and innovative mobility services	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobility; Big data analytics; Car insurance; Mobility services; Carpooling		Car telematics is a large and growing business sector aiming to collect mobility-related data (mainly private and commercial vehicles) and to develop services of various nature both for individual citizens and other companies. Such services and applications include information systems to support car insurances, info-mobility services, ad hoc studies for planning purposes, etc. In this work we report and discuss some of the key challenges that a car telematics pilot application is facing within the EU project "Track and Know". The paper introduces the overall context, the main business goals identified as potentially beneficial of big data solutions and the type of data sources that such applications can rely on (in particular, those available within the project for experimental studies), then discusses initial results of the solutions developed so far and ongoing lines of research. In particular, the discussion will focus on the most relevant applications identified for the project purposes, namely new services for car insurance, electric vehicles mobility and car- and ride-sharing.																	1868-5137	1868-5145				OCT	2020	11	10			SI		3989	3999		10.1007/s12652-019-01632-4													
J								Market revenue prediction and error analysis of products based on fuzzy logic and artificial intelligence algorithms	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Fuzzy algorithm; Neural network; Revenue prediction; Intelligent system		Neural networks can approximate the neuron information of all quantitative or qualitative nonlinear relationship, any complex is stored in the potential distribution in the network. It has strong robustness and fault tolerance, using the parallel distribution processing method, making quick lots of computing is possible. The mature prediction method in artificial intelligence, or the neural network method to forecast, this kind of algorithm has theoretical support to mature, reliable predictions of the information. In this paper, the authors analyze the market revenue prediction and error analysis of products based on fuzzy logic and artificial intelligence algorithms. The results of this paper can be concluded that the neural network algorithm has a high accuracy in predicting the future sales of the product, and the prediction error can be controlled within 4%. Through the establishment of the neural network model of future product sales forecast, we can predict the future product sales, can grasp the market direction, and make the enterprise get the maximum profit.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4011	4018		10.1007/s12652-019-01650-2													
J								Strengthen user authentication on mobile devices by using user's touch dynamics pattern	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Mobile computing; User authentication; Behavioural biometrics; Touch dynamics	SMARTPHONES; INFORMATION; SELECTION	Mobile devices, particularly the touch screen mobile devices, are increasingly used to store and access private and sensitive data or services, and this has led to an increased demand for more secure and usable security services, one of which is user authentication. Currently, mobile device authentication services mainly use a knowledge-based method, e.g. a PIN-based authentication method, and, in some cases, a fingerprint-based authentication method is also supported. The knowledge-based method is vulnerable to impersonation attacks, while the fingerprint-based method can be unreliable sometimes. To overcome these limitations and to make the authentication service more secure and reliable for touch screen mobile device users, we have investigated the use of touch dynamics biometrics as a mobile device authentication solution by designing, implementing and evaluating a touch dynamics authentication method. This paper describes the design, implementation, and evaluation of this method, the acquisition of raw touch dynamics data, the use of the raw data to obtain touch dynamics features, and the training of the features to build an authentication model for user identity verification. The evaluation results show that by integrating the touch dynamics authentication method into the PIN-based authentication method, the protection levels against impersonation attacks is greatly enhanced. For example, if a PIN is compromised, the success rate of an impersonation attempt is drastically reduced from 100% (if only a 4-digit PIN is used) to 9.9% (if both the PIN and the touch dynamics are used).																	1868-5137	1868-5145				OCT	2020	11	10			SI		4019	4039		10.1007/s12652-019-01654-y													
J								LWESM: learning with error based secure communication in mobile devices using fuzzy extractor	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Security; Privacy; Authentication; Learning with error; Ideal lattice	ANONYMOUS MUTUAL AUTHENTICATION; REMOTE USER AUTHENTICATION; CLIENT-SERVER ENVIRONMENT; ROAMING SERVICE; KEY EXCHANGE; SCHEME; PROTOCOL; INTERNET; NETWORK	Rapid-growth in wireless communication technologies and increasing demand smart devices are enabling users to access various services in remote areas. However, security and privacy are the two key attributes of wireless communication. To establish secure channel, various anonymous authentication schemes have been proposed based on classical number-theoretic hard assumptions ( discrete logarithm or factorization ) have been introduced in the last two or three decades. Due to Shor's algorithm, a scheme based on number-theoretic assumptions could be broken by post-quantum computers in polynomial time. Therefore, we have proposed learning with errors based anonymous authentication protocol using ideal in some lattice. The security proof of the proposed technique ensures provable-security in the random oracle under learning with errors problem in some lattice. Furthermore, an informal security discussion and performance analysis show that our LWESM protocol is efficient and could be used in various applications.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4089	4100		10.1007/s12652-019-01675-7													
J								Gold price forecasting research based on an improved online extreme learning machine algorithm	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Genetic algorithm; AIC criterion; Online learning machine; Gold price forecast	MODEL; NETWORKS; MARKET; CHINA	Accurate gold price prediction is highly essential for economic and currency markets. Thus, the intelligence prediction models need to be applied to price prediction. On the basis of long-term collected daily gold, the study proposes a novel genetic algorithm regularization online extreme learning machine (GA-ROSELM), to predict gold price data which collected from public websites. Akaike Information Criterion (AIC) is introduced to build the eight input combinations of variables based on the silver price of the previous day (Silver_D1), Standard & Poor. The 500 indexes (S&P_D1), the crude oil price (Crude_D1), and the gold price of the previous 3 days (Gold_D1, Gold_D2, Gold_D3). Eight optimal variable models are established, and the final input variables are determined according to the minimum AIC value. The proposed model (GA-ROSELM) solve the problem that OS-ELM model which is easy to generate singular matrices, meanwhile, experiments demonstrate this model performs better than ARIMA, SVM, BP, ELM and OS-ELM in the gold price prediction experiment. On the test set, the root means square error of this model (GA-ROSELM) prediction compared with five other models which decreased by 13.1%, 22.4%, 53.87%, 57.84% and 37.72% respectively. In summary, the results clearly confirm the effectiveness of the GA-ROSELM model.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4101	4111		10.1007/s12652-020-01682-z													
J								Type-2 single-valued neutrosophic sets and their applications in multi-criteria group decision making based on TOPSIS method	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Single-valued neutrosophic set; Type-2 single-valued neutrosophic number; Decision making; TOPSIS method	HAMACHER AGGREGATION OPERATORS; SIMILARITY MEASURE; FUZZY-SETS	Type-2 fuzzy set and type-2 intuitionistic fuzzy set are important tools for dealing with problems involving uncertainty and linguistic variables. However, it is sometimes difficult to model problems involving inconsistent data by using these approaches. In this paper, the concept of type-2 single-valued neutrosophic sets is defined in order to cope with this difficulty. Also, some distance measure methods for type-2 single-valued neutrosophic sets based on Hausdorff, Hamming and Euclidean distances are introduced and some properties of them are investigated. Furthermore, a multi-criteria group decision-making method is developed based on TOPSIS approach under the type-2 single-valued neutrosophic environment. Finally, an illustrative example is given in order to show the validity and process of the proposed method.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4113	4132		10.1007/s12652-020-01686-9													
J								Bayesian curved lane estimation for autonomous driving	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Autonomous driving; Embedded camera; Road marking; Multi-hyperbola; Bayesian framework	HOUGH TRANSFORM; SENSORS; NETWORK; MODEL	Several pieces of research during the last decade in intelligent perception are focused on the development of algorithms allowing vehicles to move efficiently in complex environments. Most of existing approaches suffer from either processing time which do not meet real-time requirements, or inefficient in real complex environment, which also does not meet the full availability constraint of such a critical function. To improve the existing solutions, an algorithm based on curved lane detection by using a Bayesian framework for the estimation of multi-hyperbola parameters is proposed to detect curved lane under challenging conditions. The general idea is to divide a captured image into several parts. The trajectory is modeled by a hyperbola over each part, whose parameters are estimated using the proposed hierarchical Bayesian model. Compared to the existing works in the state of the art, experimental results prove that our approach is more efficient and more precise in road marking detection.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4133	4143		10.1007/s12652-020-01688-7													
J								Detection and multi-class classification of falling in elderly people by deep belief network algorithms	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Fall detection; Feature selection; Deep belief network; Smartphone; Elderly people	WEARABLE SENSORS	According to the reports on aging population, the number of elderly people without a caregiver has increased. These people are always at high risks of adverse incidents such as increased blood pressure, a variety of stroke-leading health issues, as well as other accidents resulting in body instability and eventually hazardous falls. An uncontrolled fall can result in far worse situations than the original cause itself, if the unattended patient is not promptly transmitted to a treatment center. To reduce the adverse consequences of such unfortunate events, the demand for intelligent systems to prevent, detect, and report the incidents has significantly increased during the past decade. So far, many studies have been proposed considering different aspects of the fall detection problem, from simple applied systems to complex ones regarding the detection algorithm and feature extraction methods. In this paper, a framework for smart detection, identification and notification of elderly falls is introduced. Using a personal smartphone, the tri-axial acceleration of the person's movements is measured, and the related features are extracted following a pre-processing and timing the samples with a predefined window. The deep belief network (DBN) is used next for training and testing the system using two public datasets, with nine classes of fall and one class of daily activity. Simulation results on two generic datasets, TFall and MobiFall, show an accuracy of 97.56% sensitivity and 97.03% specificity, which is promising compared to nine other related studies.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4145	4165		10.1007/s12652-020-01690-z													
J								Design of 3.84 Tbps hybrid WDM-PDM based inter-satellite optical wireless communication (IsOWC) system using spectral efficient orthogonal modulation scheme	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Wavelength division multiplexing; Polarization division multiplexing; Orthogonal modulation scheme; Link range	PERFORMANCE ANALYSIS; LINK ISL; BANDWIDTH; FORMAT; DPSK; KEY	Inter satellite optical wireless communication (IsOWC) is an emerging transmission technology which is capable of transporting high-speed data between two satellites estranged in outer space and revolving in the same or different orbits. IsOWC links have been considered very crucial for the purpose of providing global coverage for information transmission throughout the world. This work reports the modeling and performance investigation of a novel hybrid wavelength division multiplexing-polarization division multiplexing based IsOWC transmission system incorporating an orthogonal modulation scheme combining carrier suppressed return to zero-differential quadrature phase shift keying-polarization shift keying formats to transmit three independent 40 Gbps data streams simultaneously at different signal parameters. The results show a successful transmission of 3.84 Tbps information over 58,000 km link range with acceptable Q Factor (> 6 dB) and BER (<= 10(-9)) using the proposed system. The performance comparison of the proposed system with existing work has also been discussed in this paper.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4167	4175		10.1007/s12652-020-01691-y													
J								An improved dynamic deployment technique based-on genetic algorithm (IDDT-GA) for maximizing coverage in wireless sensor networks	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Coverage; Deployment techniques; Genetic algorithm (GA); Whale optimization algorithm (WOA); Wireless sensor network (WSN); Quality of service (QoS)	CONNECTIVITY; OPTIMIZATION; ISSUES; WSNS	Recently, many researchers have paid attention to wireless sensor networks (WSNs) due to their ability to encourage the innovation of the IT industry. Although WSN provides dynamically scalable solutions with various smart applications, the growing need to maximize the area coverage with decreasing the percentage of deployed sensor nodes is still required. Random deployment is preferable for large areas that require a maximal number of nodes but result in coverage holes. As a result, mobile nodes are used to reduce coverage holes and maximize area coverage. The main objective of this study is to present an Improved Dynamic Deployment Technique based-on Genetic Algorithm (IDDT-GA) to maximize the area coverage with the lowest number of nodes as well as minimizing overlapping area between neighboring nodes. A two-point crossover novel is introduced to demonstrate the notation of variable-length encoding. Simulation results reveal that the superiority of the proposed IDDT-GA compared with other state-of-the-art techniques. IDDT-GA has better coverage rates with 9.69% and a minimum overlapping ratio with 35.43% compared to deployment based on Harmony Search (HS). Also, IDDT-GA has minimized the network cost by 13% and 7.44% than Immune Algorithm (IA) and Whale Optimization Algorithm (WOA) respectively. Besides, it confirms its stability with 83.04% compared to maximizing coverage with WOA.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4177	4194		10.1007/s12652-020-01698-5													
J								A situation-aware task model for adaptive real-time systems	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										Situation-awareness; Environmental situations; Task models; Real-time systems; Adaptive systems		Real-time systems are usually well-defined and operate based on a specific task model defined during system design. However, the system can interact with different objects from its environment at runtime and needs to guarantee its operational as well as timing behavior even in adverse environmental situations. Uncertainties in the system environment impose challenges on assuring the runtime behavior during system design. The system needs to adapt to different environmental situations which require the task model to consider the execution of adaptive tasks which can be activated in response to environmental events. We present an operational environment model that characterizes environmental situations of the real-time system and identifies the adaptive tasks needed to be activated at runtime. The adaptive tasks can be included and executed using a number of existing task models which allow non-deterministic task activation patterns. We present a situation-aware task model which efficiently maps the environmental events to (reduced) adaptive tasks. To demonstrate the applicability and usability of the proposed situation-aware task model, we perform the experimental analysis using two case studies: an automotive situation-aware task model, and an unmanned aerial vehicle situation-aware task model. The experimental results of our work show that the constructed situation-aware task model contains a maximum of nine vertices and 68 edges, provides an improvement in terms of scheduling overhead and in adaptation time (with respect to the considered existing task models).																	1868-5137	1868-5145				OCT	2020	11	10			SI		4249	4259		10.1007/s12652-020-01705-9													
J								RISA: routing scheme for Internet of Things using shuffled frog leaping optimization algorithm	JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING										IoT; Shuffled frog leaping algorithm (SFLA); Routing; Content-oriented communication	NETWORKS; ENERGY	Internet of Things (IoT) has emerged with the recent developments in different technologies such as smart sensors, radio frequency identifier (RFID), wireless networks and communication protocols with various applications. However, gathering large amounts of multimedia data from IoT applications cause traffic congestion. Congestion can affect network quality of service (QoS) parameters such as latency and packet delivery rate (PDR). On the other hand, providing appropriate packet routing scheme in IoT is an important issue. Hence, in this paper, we propose a routing scheme for IoT using shuffled frog leaping algorithm (SFLA). RISA uses SFLA to find a content-based path between the source and destination nodes. RISA can reduce energy consumption and improve the network lifetime using an appropriate data aggregation scheme. The simulation results of the proposed method in Matlab software show that the proposed method is able to optimize the power consumption, network lifetime, throughput, and PDR.																	1868-5137	1868-5145				OCT	2020	11	10			SI		4273	4283		10.1007/s12652-020-01708-6													
J								Distributivity between extended nullnorms and uninorms on fuzzy truth values	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Fuzzy truth values; Extended nullnorm; Extended uninorm; Distributive law	CONDITIONAL DISTRIBUTIVITY; AGGREGATION OPERATORS; ALGEBRA	This paper mainly investigates the distributive laws between extended nullnorms and uninorms on fuzzy truth values under the condition that the nullnorm is conditionally distributive over the uninorm. It presents the distributive laws between the extended nullnorm and t-conorm, and the left and right distributive laws between the extended generalized nullnorm and uninorm, where a generalized nullnorm is an operator from the class of aggregation operators with absorbing element that generalizes a nullnorm. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						1	13		10.1016/j.ijar.2020.06.006													
J								Toward a Dempster-Shafer theory of concepts	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Formal concept analysis; Dempster-Shafer theory; Epistemic logic	BELIEF FUNCTIONS; ROUGH	In this paper, we generalize the basic notions and results of Dempster-Shafer theory from predicates to formal concepts. Results include the representation of conceptual belief functions as inner measures of suitable probability functions, and a Dempster-Shafer rule of combination on belief functions on formal concepts. (C) 2020 The Author(s). Published by Elsevier Inc.																	0888-613X	1873-4731				OCT	2020	125						14	25		10.1016/j.ijar.2020.05.004													
J								Tractable inference in credal sentential decision diagrams	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Probabilistic graphical models; Imprecise probability; Credal sets; Probabilistic circuits; Sentential decision diagrams; Sum-product networks		Probabilistic sentential decision diagrams are logic circuits where the inputs of disjunctive gates are annotated by probability values. They allow for a compact representation of joint probability mass functions defined over sets of Boolean variables, that are also consistent with the logical constraints defined by the circuit. The probabilities in such a model are usually "learned" from a set of observations. This leads to overconfident and prior-dependent inferences when data are scarce, unreliable or conflicting. In this work, we develop the credal sentential decision diagrams, a generalisation of their probabilistic counterpart that allows for replacing the local probabilities with (so-called credal) sets of mass functions. These models induce a joint credal set over the set of Boolean variables, that sharply assigns probability zero to states inconsistent with the logical constraints. Three inference algorithms are derived for these models. These allow to compute: (i) the lower and upper probabilities of an observation for an arbitrary number of variables; (ii) the lower and upper conditional probabilities for the state of a single variable given an observation; (iii) whether or not all the probabilistic sentential decision diagrams compatible with the credal specification have the same most probable explanation of a given set of variables given an observation of the other variables. These inferences are tractable, as all the three algorithms, based on bottom-up traversal with local linear programming tasks on the disjunctive gates, can be solved in polynomial time with respect to the circuit size. The first algorithm is always exact, while the remaining two might induce a conservative (outer) approximation in the case of multiply connected circuits. A semantics for this approximation together with an auxiliary algorithm able to decide whether or not the result is exact is also provided together with a brute-force characterization of the exact inference in these cases. For a first empirical validation, we consider a simple application based on noisy seven-segment display images. The credal models are observed to properly distinguish between easy and hard-to detect instances and outperform other generative models not able to cope with logical constraints. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						26	48		10.1016/j.ijar.2020.06.005													
J								Modelling epistemic irrelevance with choice functions	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Choice functions; Coherence; Sets of desirable gambles; Natural extension; Conditioning; Epistemic irrelevance	INDEPENDENT NATURAL EXTENSION; CREDAL NETWORKS; SETS	We consider coherent choice functions under the recent axiomatisation proposed by De Bock and de Cooman that guarantees a representation in terms of binary preferences, and we discuss how to define conditioning in this framework. In a multivariate context, we propose a notion of marginalisation, and its inverse operation called weak (cylindrical) extension. We combine this with our definition of conditioning to define a notion of irrelevance, and we obtain the irrelevant natural extension in this framework: the least informative choice function that satisfies a given irrelevance assessment. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						49	72		10.1016/j.ijar.2020.06.010													
J								An axiomatic framework for influence diagram computation with partially ordered preferences	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Influencediagrams; Variableelimination; Preferences; Uncertainty; Utility; Optimization		This paper presents an axiomatic framework for influence diagram computation, which allows reasoning with partially ordered values of utility. We show how an algorithm based on sequential variable elimination can be used to compute the set of maximal values of expected utility (up to an equivalence relation). Formalisms subsumed by the framework include decision making under uncertainty based on multi-objective utility, or on interval-valued utilities, as well as a more qualitative decision theory based on order of magnitude probabilities and utilities. Consequently, we also introduce the order of magnitude influence diagram to model and solve partially specified sequential decision problems when only qualitative (or imprecise) information is available. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						73	117		10.1016/j.ijar.2020.06.011													
J								Observational nonidentifiability, generalized likelihood and free energy	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Generalized likelihood; Nonidentifiability; Free energy; Entropy optimization	PROBABILITY DENSITIES; MAXIMUM-ENTROPY; IDENTIFIABILITY; PARAMETERS; MODELS	We study the parameter estimation problem in mixture distributions with observational nonidentifiability: the full distribution (also containing hidden variables) is identifiable, but the marginal (observed) distribution is not. Hence global maxima of the marginal likelihood are (infinitely) degenerate and predictions of the marginal likelihood are not unique. We show how to generalize the marginal likelihood by introducing an effective temperature, and making it similar to the free energy. This generalization resolves the observational nonidentifiability, since its maximization leads to unique results that are better than a random selection of one degenerate maximum of the marginal likelihood or the averaging over many such maxima. The generalized likelihood inherits many features from the usual likelihood, e.g. it holds the conditionality principle, and its local maximum can be searched for via suitably modified expectation-maximization method. The maximization of the generalized likelihood relates to entropy optimization. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						118	138		10.1016/j.ijar.2020.06.009													
J								The Fuzzy Logic Programming language FASILL: Design and implementation	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Fuzzy Logic Programming; Similarity relation; Operational semantics; High level implementation techniques	UNIFICATION; PROLOG; TABULATION; ALGORITHMS; FRAMEWORK; SEMANTICS; XPATH	The FASILL programming language (acronym of "Fuzzy Aggregators and Similarity Into a Logic Language") combines a weak unification algorithm, based on similarity relations, along with a rich repertoire of fuzzy connectives and aggregators, whose truth functions can be defined on a complete lattice. In this work, we want to provide a unified view of the fundamental concepts and ideas that inspired its construction, jointly with the implementation techniques that made it possible. We detail the implementation of the operational semantics and we describe the overall structure of the FASILL system. The FASILL language is well-suited for a wide range of applications and, specifically, it can help the development of knowledge based systems where to deal with uncertainty is important. After ten years designing and implementing fuzzy logic systems, this work culminates and agglutinates the experience acquired in our research group on the development of this kind of modern programming languages. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						139	168		10.1016/j.ijar.2020.06.002													
J								BWM and MULTIMOORA-based multigranulation sequential three-way decision model for multi-attribute group decision-making problem	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										BWM; Cost-sensitive; Sequential three-way decisions; Multi-attribute group decision; Medical diagnosis	ROUGH SET; SELECTION	This paper proposes a sequential three-way decision-making approach based on BWM (best-worst method) and MULTIMOORA for multiple levels of granularity to deal with the multi-attribute group decision-making problems under uncertainty. First, using BWM to preprocess the attribute indicators of the decision problem, the relationship between the criteria important for decision problem is determined. Then, according to the importance of the determined level of granularity, from rough to clear, three-way decisions are made in sequence at each level. In this way, we obtain a lattice based three-way decision-making process. Also, in the process at each granularity, we consider the costs of both the decision process and the decision result. Thus, this paper builds a multigranulation sequential threeway decisions model with cost-sensitive. Next, based on the above-mentioned model, we propose a decision procedure and an algorithm for multi-attribute group decision making. It is worth noting that according to the research goals of the decision problem, MULTIMOORA is used to sort the classified alternatives. And a ranking result of the decision problem is given. Finally, the effectiveness and validity of the proposed model is verified by a multi-attribute group decision problem. The problem is the case of emergency diagnosis and treatment after a highway accident. And put forward reasonable suggestions for further development direction. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						169	186		10.1016/j.ijar.2020.07.003													
J								Heuristic-based feature selection for rough set approach	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Rough sets; Greedy heuristics; Decision rules; Feature selection; Discretisation; Stylometry	INCREMENTAL ATTRIBUTE REDUCTION; DYNAMIC-PROGRAMMING APPROACH; DECISION RULES; CLASSIFICATION; ALGORITHMS; OPTIMIZATION; FOUNDATIONS; INDUCTION; COVERAGE	The paper presents the proposed research methodology, dedicated to the application of greedy heuristics as a way of gathering information about available features. Discovered knowledge, represented in the form of generated decision rules, was employed to support feature selection and reduction process for induction of decision rules with classical rough set approach. Observations were executed over input data sets discretised by several methods. Experimental results show that elimination of less relevant attributes through the proposed methodology led to inferring rule sets with reduced cardinalities, while maintaining rule quality necessary for satisfactory classification. (C) 2020 The Author(s). Published by Elsevier Inc.																	0888-613X	1873-4731				OCT	2020	125						187	202		10.1016/j.ijar.2020.07.005													
J								Constructions of overlap functions on bounded lattices	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Overlap function; Lambda-Extension; Ordinal sum; Bounded lattice	TRIANGULAR NORMS; FUZZY IMPLICATIONS; DISTRIBUTIVE LAWS; INTERVAL OVERLAP; ORDINAL SUMS; UNINORMS; CLASSIFICATION; NULLNORMS; EQUATIONS; PROPERTY	In this paper, we present two methods for constructing new overlap functions on bounded lattices from given ones. At first, we introduce the notion of overlap functions on bounded lattices, which is a generalization of overlap functions on the real unit interval. Then we provide the Lambda-extension of an overlap function on a subinterval and give the necessary and sufficient conditions for the Lambda-extension to be an overlap function. Finally, we propose a definition of ordinal sum of finitely many overlap functions on subintervals of a bounded lattice, where the endpoints of the subintervals constitute a chain. Necessary and sufficient conditions for the ordinal sum yielding again an overlap function are provided. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						203	217		10.1016/j.ijar.2020.07.006													
J								The joy of Probabilistic Answer Set Programming: Semantics, complexity, expressivity, inference	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Logic programming; Answer Set Programming; Probabilistic programming; Credal sets; Computational complexity; Descriptive complexity	LOGIC PROGRAMS; BAYESIAN NETWORKS	Probabilistic Answer Set Programming (PASP) combines rules, facts, and independent probabilistic facts. We argue that a very useful modeling paradigm is obtained by adopting a particular semantics for PASP, where one associates a credal set with each consistent program. We examine the basic properties of PASP under this credal semantics, in particular presenting novel results on its complexity and its expressivity, and we introduce an inference algorithm to compute (upper) probabilities given a program. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						218	239		10.1016/j.ijar.2020.07.004													
J								On generating random Gaussian graphical models	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING										Concentration graph; Covariance graph; Positive definite matrix simulation; Undirected graphical model; Algorithm validation	WISHART DISTRIBUTIONS; COVARIANCE; SELECTION	Structure learning methods for covariance and concentration graphs are often validated on synthetic models, usually obtained by randomly generating: (i) an undirected graph, and (ii) a compatible symmetric positive definite (SPD) matrix. In order to ensure positive definiteness in (ii), a dominant diagonal is usually imposed. In this work we investigate different methods to generate random symmetric positive definite matrices with undirected graphical constraints. We show that if the graph is chordal it is possible to sample uniformly from the set of correlation matrices compatible with the graph, while for general undirected graphs we rely on a partial orthogonalization method. (C) 2020 Elsevier Inc. All rights reserved.																	0888-613X	1873-4731				OCT	2020	125						240	250		10.1016/j.ijar.2020.07.007													
J								A new hybrid financial time series prediction model	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Neural networks; Support vector machine; Genetic algorithm; Ensemble empirical mode decomposition; Financial time series	ARTIFICIAL NEURAL-NETWORKS; PETROLEUM RESERVOIR CHARACTERIZATION; STOCK-MARKET PREDICTION; SUPPORT VECTOR MACHINE; ENSEMBLE MODEL; DECOMPOSITION; SELECTION; ARIMA; PRICE; COMBINATION	Due to the characteristics of financial time series, such as being non-linear, non-stationary and noisy, with uncertain and hidden relationships, it is difficult to capture its non-stationary state and to accurately describe its moving tendency. This is also a consequence of using a single approach to artificial intelligence, and other techniques that have been conventionally used. Therefore, those participating in financial markets, along with researchers, have paid a great deal of attention to tackling this problem. Hence, several approaches have been developed to alleviate the influence of inherent characteristics. However, the noise characteristic can refer to the unavailability of information, which affects how financial markets behave, as well as captured prices in both the past and the future. Therefore, the prediction of stock prices and detecting their noise is considered a very challenging financial topic. This paper adopts a novel three-step hybrid intelligent prediction model that combines a collection of intelligent modelling techniques and a feature extraction algorithm. At first, ensemble empirical mode decomposition is applied to the original data, as to facilitate model fitting to them. Then neural network and support vector regression is proposed individually for modelling the extracted features. Finally, a weighted ensemble average using a genetic algorithm to optimise and determine the weight is proposed for establishing a unified prediction. Experimental results are presented which illustrate the excellent performance of the proposed approach, and that is significantly outperforming the existing models, in terms of error criteria such as MSE, RMSE and MAE.																	0952-1976	1873-6769				OCT	2020	95								103873	10.1016/j.engappai.2020.103873													
J								Multi-objective ensembles of echo state networks and extreme learning machines for streamflow series forecasting	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Streamflow; Time series forecasting; Extreme learning machine; Echo state network; Ensemble learning; Multi-objective optimization	OPTIMIZATION; MODEL; PERFORMANCE; PREDICTION	Streamflow series forecasting composes a fundamental step in planning electric energy production for hydroelectric plants. In Brazil, such plants produce almost 70% of the total energy. Therefore, it is of great importance to improve the quality of streamflow series forecasting by investigating state-of-the-art time series forecasting algorithms. To this end, this work proposes the development of ensembles of unorganized machines, namely Extreme Learning Machines (ELMs) and Echo State Networks (ESNs). Two primary contributions are proposed: (1) a new training logic for ESNs that enables the application of bootstrap aggregation (bagging); and (2) the employment of multi-objective optimization to select and adjust the weights of the ensemble's base models, taking into account the trade-off between bias and variance. Experiments are conducted on streamflow series data from five real-world Brazilian hydroelectric plants, namely those in Sobradinho, Serra da Mesa, Jirau, Furnas and Agua Vermelha. The statistical results for four different prediction horizons (1, 3, 6, and 12 months ahead) indicate that the ensembles of unorganized machines achieve better results than autoregressive (AR) models in terms of the Nash-Sutcliffe model efficiency coefficient (NSE), root mean squared error (RMSE), coefficient of determination (R-2), and RMSE-observations standard deviation ratio (RSR). In such results, the ensembles with ESNs and the multi-objective optimization design procedure achieve the best scores.																	0952-1976	1873-6769				OCT	2020	95								103910	10.1016/j.engappai.2020.103910													
J								Performing predefined tasks using the human-robot interaction on speech recognition for an industrial robot	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Deep neural networks; Intelligent robots; Human-robot interaction; Robotic vision; Turkish speech recognition	SYSTEM; FRAMEWORK; SELECTION	People who are not experts in robotics can easily implement complex robotic applications by using human- robot interaction (HRI). HRI systems require many complex operations such as robot control, image processing, natural speech recognition, and decision making. In this study, interactive control with an industrial robot was performed by using speech recognition software in the Turkish language. The collected voice data were converted to text data by using automatic speech recognition module based on deep neural networks (DNN). The proposed DNN (p-DNN) was compared to classic classification algorithms. Converted text data was improved in another module to select the process to be applied. According to selected process, position data were defined using image processing. The determined position information was sent to the robot using a fuzzy controller. The developed HRI system was implemented on a KUKA KR Agilus KR6 R900 sixx robot manipulator. The word accuracy rate of the p-DNN model was measured as 90.37%. The developed image processing module and fuzzy controller worked with minimal errors. The contribution of this study is that an industrial robot is easily programming using this software by people who are not experts in robotics and know Turkish.																	0952-1976	1873-6769				OCT	2020	95								103903	10.1016/j.engappai.2020.103903													
J								Predicting customer satisfaction based on online reviews and hybrid ensemble genetic programming algorithms	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										New product development; Social media; Online customer reviews; Machine learning; Genetic programming; Committee member selection	TIME-SERIES	Determination of the design attribute settings of a new product is essential for maximizing customer satisfaction. A model is necessary to illustrate the relation between the design attributes and dimensions of customer satisfaction such as product performance, affection and quality. The model is commonly developed based on customer survey data collected from questionnaires or interviews which require a long deployment time; hence the developed model cannot completely reflect the current marketplace. In this paper, a framework is proposed based on online reviews in which past and current customer opinions are included to develop the model. The proposed framework overcomes the limitation of the aforementioned approaches in which the developed models are not up-to-date. Indeed, the proposed framework develops models based on machine learning technologies, namely genetic programming, which has better generalization capabilities than classical approaches, and has higher transparency capabilities than implicit modelling approaches. To further enhance the prediction capability, committee member selection is proposed. The proposed selection method improves the currently used selection method which trains several models and only selects the best one. The proposed selection method generates a hybrid model which integrates the predictions of the generated models. Each prediction is weighted by how likely the prediction is agreed by others. The proposed framework is implemented on electric hair dryer design of which online reviews in amazon.com are used. Experimental results show that models with more accurate prediction capabilities can be generated by the proposed framework.																	0952-1976	1873-6769				OCT	2020	95								103902	10.1016/j.engappai.2020.103902													
J								A nucleus for Bayesian Partially Observable Markov Games: Joint observer and mechanism design	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Nucleus; Mechanism design; Observer design; Bayesian games; Partially observable Markov chains; Reinforcement Learning	DYNAMIC MECHANISM; CONVERGENCE ANALYSIS; NASH EQUILIBRIUM; FOLK THEOREM; INFORMATION; COLLUSION; INCENTIVES; STRATEGIES; AUCTIONS	An intelligent agent suggests an autonomous entity, which manages and learns actions to be taken towards achieving goals. The problem, reported as common knowledge in the literature in Artificial Intelligence (AI), is that it is a challenge to develop an approach able to compute efficient decisions that maximize the total reward of interacting agents upon an environment with unknown, incomplete, and uncertain information. To address these shortcomings, this paper provides a step forward: a nucleus for Bayesian Partially Observable Markov Games (BPOMGs) supported by an AI approach. Three fundamental topics conform the structure of the nucleus: game theory, learning and inference. First, we present a novel general Bayesian approach which is conceptualized for games that considered both, the incomplete information of the Bayesian model and the incomplete information over the states of the Markov system. In this new model, execution uncertainty is handled by using a Partially Observable Markov Game (POMG). Second, we extend the design theory, which now involves the mechanism design and the joint observer design (both unknown). The mechanism design results from the fact that agents act in their own individuals' self-interest, and to induce agents to not reveal their private information and create a particular outcome. The joint observer design goal is related to represent the fact that agents may not be interested to provide accurate information of their states. In addition, agents follow a model that employs a Reinforcement Learning (RL) approach for estimating the transition matrices (also unknown) at each time step. Hence, as our final contribution, is an extended model of POMGs by introducing a new variable and proposing an analytical solution to compute both the observer design and the mechanism design (the two unknown). The proposed extension makes the game theory problem computationally tractable. We derive relations to recover analytically the variables of interest for each agent, i.e. observation kernels, joint observers, mechanism, strategies, and distribution vectors. The usefulness and effectiveness of the proposed nucleus is validated in simulation on a game-theoretic analysis of the patrolling problem designing the mechanism, computing the observers, and employing an RL approach.																	0952-1976	1873-6769				OCT	2020	95								103876	10.1016/j.engappai.2020.103876													
J								A highly robust automatic 3D reconstruction system based on integrated optimization by point line features	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Jacobian matrix; Point line features; Graph optimization; 3D reconstruction	ROBOT NAVIGATION; TRACKING; CAMERA; SCALE; SLAM	Current reconstruction systems often face the challenge of drifting when reconstructing complex scenes. Recent 3D(three-dimensional) reconstruction systems have shown convincing results, but still suffer from the following problems: (1) When the current vision-based 3D reconstruction system uses a single camera , the small angle of view of the camera is likely to cause the reconstructed 3D model to be incomplete. (2) Some image frames have fewer image feature points and image blurring, which leads to a larger deviation of the estimated camera pose value. (3) The current mainstream line feature 3D reconstruction system causes linearization and limits the update efficiency due to the adoption of the filter frame. In order to solve the above problems, this paper proposes a highly robust automatic 3D reconstruction system based on integrated optimization by point line features. Firstly, a multi-depth camera collaborative scanning method is developed to obtain a relatively complete 3D model. Secondly, a more accurate camera pose initial value can be obtained in advance without the position estimation. Thirdly, a comprehensive optimization method based on point line feature is used, which can improve the accuracy of camera pose and the consistency and accuracy of map construction. Many experiments show that the system can solve the problems of small viewing angle, blurred image and low modeling efficiency. The proposed system can be applied to 3D reconstruction of various complex large scenes. The obtained high-precision 3D model can be widely applied in the fields of human-computer interaction, virtual reality, etc.																	0952-1976	1873-6769				OCT	2020	95								103879	10.1016/j.engappai.2020.103879													
J								A deep learning framework for text-independent writer identification	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Enhanced ResNet; Deep residual networks; Text-independent; Handwriting writer recognition		Handwriting Writer Identification (HWI) refers to the process of handwriting text image analysis to identify the authorship of the documents. It has yielded promising results in various applications, including digital forensics, criminal purposes, exploring the writer of historical documents, etc. The complexity of the text image, especially in images with various handwriting makes the writer identification difficult. In this work, we propose an end-to-end system that relies on a straightforward yet well-designed deep network and very efficient feature extraction, emphasizing feature engineering. Our system is an extended version of ResNet by conjugating deep residual networks and a new traditional yet high-quality handwriting descriptor towards handwriting analysis. Our descriptor analyzes the handwriting thickness as a preliminary and essential feature for human handwriting characteristics. Our approach can also provide text-independent writer identification that we do not need to have the same handwriting content for learning our model. The proposed approach is evaluated and achieved consistent results on four public and well-known datasets of IAM, Firemaker, CVL, and CERUG-EN. We empirically demonstrate that our conjugated network outperforms the original ResNet, and it can work well for real-world applications in which patches with few letters exist.																	0952-1976	1873-6769				OCT	2020	95								103912	10.1016/j.engappai.2020.103912													
J								Reinforcement learning for quadrupedal locomotion with design of continual-hierarchical curriculum	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Continual learning; Curriculum learning; Hierarchical learning; Reservoir computing; Fractal network	ROBOT; WALKING; ENERGY; FAMILY; POLICY; GAIT	End-to-end reinforcement learning is a promising approach to enable robots to acquire complicated skills. However, this requires numerous samples to be implemented successfully. The issue is that it is often difficult to collect the sufficient number of samples. To accelerate learning in the field of robotics, knowledge gathered from robotics engineering and previously learned tasks must be fully exploited. Specifically, we propose using a sample-efficient curriculum to establish quadrupedal robot control in which the walking and turning tasks are divided into two hierarchical layers, and a robot learns them incrementally from lower to upper layers. To develop such a curriculum, two core components are designed. First the fractal design of neural networks in reservoir computing is aimed at allocating the tasks to be learned to respective modules in fractal networks. This allows mitigating the problem of catastrophic forgetting in neural networks and achieves the capability of continuous learning. The second task includes hierarchical task decomposition according to robotics knowledge for controlling legged robots. Owing to the combination of these two components, the proposed curriculum enables a robot to tune the lower layer even when the upper layer is optimized. As a result of implementing the proposed design, we confirm that a quadrupedal robot in a dynamical simulator succeeds in learning skills hierarchically according to the given curriculum, starting from moving legs and finally, walking/turning, unlike the considered conventional curriculums that are unable to achieve such results.																	0952-1976	1873-6769				OCT	2020	95								103869	10.1016/j.engappai.2020.103869													
J								Background image-assisted divide-and-conquer reconstruction method for ECT	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Inverse imaging problem; Random vector functional link network; Nonnegative matrix factorization; Electrical capacitance tomography; Process monitoring method	NONNEGATIVE MATRIX FACTORIZATION; SPLIT-BREGMAN ITERATION; NEURAL-NETWORKS; REGULARIZATION; ALGORITHM; SPARSE; MODEL; DECONVOLUTION	Electrical capacitance tomography (ECT) is a potential image-based measurement technology for monitoring time-varying industrial processes, but its applicability is challenged by low-quality images. To address this conundrum, a two-stage reconstruction (TSR) method with more effective priors and optimizer is presented in this work. In the first stage, the random vector functional link network (RVFLN) is developed to calculate a data-dependent background image, and a new distributed computing method is developed to achieve efficient training. To decrease the expensive computation load in the RVFLN training, the regularized projective nonnegative matrix factorization (RPNMF) method is developed to diminish the size of the sample data. A new optimization problem (OP) is proposed to model the RPNMF problem, which is solved by a new optimizer efficiently. In the second stage, a new OP that achieves the confluence of the domain knowledge-based prior related to imaging objects and the measurement physics is built, and a new divide-and-conquer optimizer is devised to solve the OP. To reduce the difficulty of parameter adjustment, the background image is used to initialize the proposed computing algorithm, and such treatment not only achieves the simultaneous fusion of the domain knowledge-based prior and the data-dependent prior but also decreases the computational difficulty. Numerical results show that the TSR algorithm is not only robust but also can achieve high precision reconstruction in comparison with popular imaging techniques.																	0952-1976	1873-6769				OCT	2020	95								103906	10.1016/j.engappai.2020.103906													
J								An effective memetic algorithm for the generalized bike-sharing rebalancing problem	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Heuristics; Bike-sharing rebalancing; Memetic algorithm; Evolutionary local search	EVOLUTIONARY LOCAL SEARCH; STATIC REPOSITIONING PROBLEM; HEURISTIC ALGORITHM; RELOCATION PROBLEM; DELIVERY; PICKUP	The generalized bike-sharing rebalancing problem (BRP) entails driving a fleet of capacitated vehicles to rebalance bicycles among bike-sharing system stations at a minimum cost. To solve this NP-hard problem, we present a highly effective memetic algorithm that combines (i) a randomized greedy construction method for initial solution generation, (ii) a route-copy-based crossover operator for solution recombination, and (iii) an effective evolutionary local search for solution improvement integrating an adaptive randomized mutation procedure. Computational experiments on real-world benchmark instances indicate a remarkable performance of the proposed approach with an improvement in the best-known results (new upper bounds) in more than 46% of the cases. In terms of the computational efficiency, the proposed algorithm shows to be nearly two to six times faster when compared to the existing state-of-the-art heuristics. In addition to the generalized BRP, the algorithm can be easily adapted to solve the one-commodity pickup-and-delivery vehicle routing problem with distance constraints, as well as the multi-commodity many-to-many vehicle routing problem with simultaneous pickup and delivery.																	0952-1976	1873-6769				OCT	2020	95								103890	10.1016/j.engappai.2020.103890													
J								A lexicographic-based two-stage algorithm for vehicle routing problem with simultaneous pickup-delivery and time window	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Simultaneous pickup-delivery problem; Time window; Tabu search; Variable neighborhood search; Vehicle routing problem; Two-stage algorithm; Learning-based approach	PARTICLE SWARM OPTIMIZATION; LARGE NEIGHBORHOOD SEARCH; TABU SEARCH; LOCAL SEARCH; SCHEDULING PROBLEM; UP PROBLEM; LOCATION; HEURISTICS; TRAVEL	Vehicle routing problem with simultaneous pickup-delivery and time window (VRPSPDTW) is computationally challenging as it generalizes the classical and NP-hard vehicle routing problem. According to the state-of-the-art, VRPSPDTW usually has two hierarchical optimization objectives: a primary objective of minimizing the number of vehicles (NV) and a secondary objective of reducing the transportation distance (TD). Given the existing research and our trial results, we find that the optimization of TD is not necessarily a promotion for reducing NV. In this paper, an effective learning-based two-stage algorithm, which has never been studied before, is proposed to solve the VRPSPDTW. In the first stage, a modified variable neighborhood search with a learning-based objective function is proposed to minimize the primary objective with retaining the potential structures. In the second stage, a bi-structure based tabu search (BSTS) is designed to optimize the primary and secondary objectives further. The experimental results on 93 benchmark instances demonstrate that the proposed algorithm performs remarkably well both in terms of computational efficiency and solution quality. In particular, the proposed two-stage algorithm improve several best known solutions (either a better NV or a better TD when NV are the same) from the state-of-the-art. To our knowledge, this is the first learning-based two-stage algorithm for solving VRPSPDTW reaching such a performance. Finally, we empirically analyze several critical components of the algorithm to highlight their impacts on the performance of the proposed algorithm.																	0952-1976	1873-6769				OCT	2020	95								103901	10.1016/j.engappai.2020.103901													
J								A novel methodology to classify test cases using natural language processing and imbalanced learning	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Software testing; Artificial intelligence; Imbalanced classification; Natural language processing; Optimization; IFROWANN; Doc2Vec	TOPIC MODELS; DATA-SETS; SOFTWARE; CLASSIFICATION; PRIORITIZATION; SMOTE	Detecting the dependency between integration test cases plays a vital role in the area of software test optimization. Classifying test cases into two main classes - dependent and independent - can be employed for several test optimization purposes such as parallel test execution, test automation, test case selection and prioritization, and test suite reduction. This task can be seen as an imbalanced classification problem due to the test cases' distribution. Often the number of dependent and independent test cases is uneven, which is related to the testing level, testing environment and complexity of the system under test. In this study, we propose a novel methodology that consists of two main steps. Firstly, by using natural language processing we analyze the test cases' specifications and turn them into a numeric vector. Secondly, by using the obtained data vectors, we classify each test case into a dependent or an independent class. We carry out a supervised learning approach using different methods for handling imbalanced datasets. The feasibility and possible generalization of the proposed methodology is evaluated in two industrial projects at Bombardier Transportation, Sweden, which indicates promising results.																	0952-1976	1873-6769				OCT	2020	95								103878	10.1016/j.engappai.2020.103878													
J								Multi-modal recognition of worker activity for human-centered intelligent manufacturing	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Worker activity recognition; Multi-modal fusion; Deep learning; Intelligent manufacturing; Human-centered computing	NEURAL-NETWORKS	This study aims at sensing and understanding the worker's activity in a human-centered intelligent manufacturing system. We propose a novel multi-modal approach for worker activity recognition by leveraging information from different sensors and in different modalities. Specifically, a smart armband and a visual camera are applied to capture Inertial Measurement Unit (IMU) signals and videos, respectively. For the IMU signals, we design two novel feature transform mechanisms, in both frequency and spatial domains, to assemble the captured IMU signals as images, which allow using convolutional neural networks to learn the most discriminative features. Along with the above two modalities, we propose two other modalities for the video data, i.e., at the video frame and video clip levels. Each of the four modalities returns a probability distribution on activity prediction. Then, these probability distributions are fused to output the worker activity classification result. A worker activity dataset is established, which at present contains 6 common activities in assembly tasks, i.e., grab a tool/part, hammer a nail, use a power-screwdriver, rest arms, turn a screwdriver, and use a wrench. The developed multi-modal approach is evaluated on this dataset and achieves recognition accuracies as high as 97% and 100% in the leave-one-out and half-half experiments, respectively.																	0952-1976	1873-6769				OCT	2020	95								103868	10.1016/j.engappai.2020.103868													
J								Basic uncertain information soft set and its application to multi-criteria group decision making	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Soft set; Basic uncertain information; MAGDM; Jaccard similarity; Natural gas security	TYPE-2 FUZZY-SETS; SIMILARITY MEASURES; CRITERIA; AGGREGATION; MODEL	The purpose of this paper is to develop a novel type of soft set called basic uncertain information soft set (BUISS), which combines the notion of basic uncertain information and soft set theory. Since basic uncertain information can measure the quality of datum by using the degree of certainty, the developed BUISS provides a novel extension of soft set. In this paper, set operations and comparison law of basic uncertain information are also developed. Then, operations on BUISSs include set operations, 'AND' operation and 'OR' operation are defined. Besides, the Jaccard similarity between two BUISSs is introduced. The properties of the operations and similarity measure are studied. Theoretically, a multi-criteria group decision making (MAGDM) problem under basic uncertain information environment is analysed by using BUISSs. Two decision algorithms based on level BUISS and the aggregation of epsilon-approximate elements are proposed. Finally, an assessment of natural gas security in China is investigated to illustrate the feasibility and validity of the developed decision approaches.																	0952-1976	1873-6769				OCT	2020	95								103871	10.1016/j.engappai.2020.103871													
J								Sensor Defense In-Software (SDI): Practical software based detection of spoofing attacks on position sensors	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Sensor spoofing; Sensor fusion; Machine learning		Position sensors, such as the gyroscope, the magnetometer and the accelerometer, are found in a staggering variety of devices, from smartphones and UAVs to autonomous robots. Several works have shown how adversaries can mount spoofing attacks to remotely corrupt or even completely control the outputs of these sensors. With more and more critical applications relying on sensor readings to make important decisions, defending sensors from these attacks is of prime importance. In this work we present practical software based defenses against attacks on two common types of position sensors, specifically the gyroscope and the magnetometer. We first characterize the sensitivity of these sensors to acoustic and magnetic adversaries. Next, we present two software-only defenses: a machine learning-based single sensor defense, and a sensor fusion defense which makes use of the mathematical relationship between the two sensors. We performed a detailed theoretical analysis of our defenses, and implemented them on a variety of smartphones, as well as on a resource-constrained IoT sensor node. Our defenses do not require any hardware or OS-level modifications, making it possible to use them with existing hardware. Moreover, they provide a high detection accuracy, a short detection time and a reasonable power consumption.																	0952-1976	1873-6769				OCT	2020	95								103904	10.1016/j.engappai.2020.103904													
J								Policy-based reinforcement learning for time series anomaly detection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Time series anomaly detection; Reinforcement learning; Policy-based methods	OUTLIER DETECTION	Time series anomaly detection has become a crucial and challenging task driven by the rapid increase of streaming data with the arrival of the Internet of Things. Existing methods are either domain-specific or require strong assumptions that cannot be met in realistic datasets. Reinforcement learning (RL), as an incremental self-learning approach, could avoid the two issues well. However, the current investigation is far from comprehensive. In this paper, we propose a generic policy-based RL framework to address the time series anomaly detection problem. The policy-based time series anomaly detector (PTAD) is progressively learned from the interactions with time-series data in the absence of constraints. Experimental results show that it outperforms the value-based temporal anomaly detector and other state-of-the-art detection methods whether training and test datasets come from the same source or not. Furthermore, the tradeoff between precision and recall is well respected by the PTAD, which is beneficial to fulfill various industrial requirements.																	0952-1976	1873-6769				OCT	2020	95								103919	10.1016/j.engappai.2020.103919													
J								Policy-based reinforcement learning for time series anomaly detection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Time series anomaly detection; Reinforcement learning; Policy-based methods	OUTLIER DETECTION	Time series anomaly detection has become a crucial and challenging task driven by the rapid increase of streaming data with the arrival of the Internet of Things. Existing methods are either domain-specific or require strong assumptions that cannot be met in realistic datasets. Reinforcement learning (RL), as an incremental self-learning approach, could avoid the two issues well. However, the current investigation is far from comprehensive. In this paper, we propose a generic policy-based RL framework to address the time series anomaly detection problem. The policy-based time series anomaly detector (PTAD) is progressively learned from the interactions with time-series data in the absence of constraints. Experimental results show that it outperforms the value-based temporal anomaly detector and other state-of-the-art detection methods whether training and test datasets come from the same source or not. Furthermore, the tradeoff between precision and recall is well respected by the PTAD, which is beneficial to fulfill various industrial requirements.																	0952-1976	1873-6769				OCT	2020	95																						
J								Improved Population-Based Incremental Learning of Bayesian Networks with partly known structure and parallel computing	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Bayesian Networks; Structure learning; Evolutionary algorithm; Population-Based Incremental Learning; Parallel computing	ALGORITHM; MODELS	Bayesian Network is a frequently-used model for fault detection and diagnosis in industrial processes. In this article, some modifications are made to Population-Based Incremental Learning and the improved algorithm is applied to structure learning of Bayesian networks. A pre-training step with K2 algorithm is added to the Population-Based Incremental Learning process to obtain an initial probability vector. Then, an elitist strategy is introduced into this method, providing a better way to update the probability vector. Individuals generated in every iteration, and elites in history are utilized to update the vector. The nature of this method makes it possible to learn the bayesian network whose structure is partly known, for sometimes we can specify some parts of the structure with prior process knowledge. A benchmark network Alarm and an industrial process are provided for performance evaluation and comparisons. Furthermore, we parallelize the algorithm to make it more efficient to learn Bayesian Networks. The speed of Improved Population-Based Incremental Learning has been improved significantly after parallelization.																	0952-1976	1873-6769				OCT	2020	95								103920	10.1016/j.engappai.2020.103920													
J								A modified particle swarm optimization for multimodal multi-objective optimization	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE										Particle swarm optimization; Offering competition mechanism; Multimodal multi-objective; Dynamic neighborhood	GENETIC ALGORITHM; SELECTION; EMOA	As an effective evolutionary algorithm, particle swarm optimization (PSO) has been widely used to solve single or multi-objective optimization problems. However, the performance of PSO in solving multi-objective problems is unsatisfactory, so a variety of PSO has been proposed to enhance the performance of PSO on multiobjective optimization problems. In this paper, a modified particle swarm optimization (AMPSO) is proposed to solve the multimodal multi-objective problems. Firstly, a dynamic neighborhood-based learning strategy is introduced to replace the global learning strategy, which enhances the diversity of the population. Meanwhile, to enhance the performance of PSO, the offering competition mechanism is utilized. 11 multimodal multiobjective optimization functions are utilized to verify the feasibility and effectiveness of the proposed AMPSO. Experimental results and statistical analysis indicate that AMPSO has competitive performance compared with 5 state-of-the-art multimodal multi-objective algorithms.																	0952-1976	1873-6769				OCT	2020	95								103905	10.1016/j.engappai.2020.103905													
J								A Hierarchical Attention Model for Social Contextual Image Recommendation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Visualization; Social networking (online); Context modeling; Recommender systems; Data models; Task analysis; History; Recommender systems; social recommendation; image recommendation; hierarchical attention		Image based social networks are among the most popular social networking services in recent years. With a tremendous amount of images uploaded everyday, understanding users' preferences on user-generated images and making recommendations have become an urgent need. In fact, many hybrid models have been proposed to fuse various kinds of side information (e.g., image visual representation, social network) and user-item historical behavior for enhancing recommendation performance. However, due to the unique characteristics of the user generated images in social image platforms, the previous studies failed to capture the complex aspects that influence users' preferences in a unified framework. Moreover, most of these hybrid models relied on predefined weights in combining different kinds of information, which usually resulted in sub-optimal recommendation performance. To this end, in this paper, we develop a hierarchical attention model for social contextual image recommendation. In addition to basic latent user interest modeling in the popular matrix factorization based recommendation, we identify three key aspects (i.e., upload history, social influence, and owner admiration) that affect each user's latent preferences, where each aspect summarizes a contextual factor from the complex relationships between users and images. After that, we design a hierarchical attention network that naturally mirrors the hierarchical relationship (elements in each aspects level, and the aspect level) of users' latent interests with the identified key aspects. Specifically, by taking embeddings from state-of-the-art deep learning models that are tailored for each kind of data, the hierarchical attention network could learn to attend differently to more or less content. Finally, extensive experimental results on real-world datasets clearly show the superiority of our proposed model.																	1041-4347	1558-2191				OCT 1	2020	32	10					1854	1867		10.1109/TKDE.2019.2913394													
J								A Nodes' Evolution Diversity Inspired Method to Detect Anomalies in Dynamic Social Networks	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Social networking (online); Evolution (biology); Heuristic algorithms; Cultural differences; Prediction algorithms; Birds; Anomaly detection; Anomaly detection; dynamic social network; link prediction; particle swarm optimization	LINK PREDICTION; ALGORITHM	Recently dynamic social networks witnessed a massive surge in popularity, especially in the area of anomaly detection. Although the text-based methods have achieved impressive detection performances, their applications are limited to the social text provided by users. This research focuses on graph-based methods and proposes a universal method for generalized social networks. Different from the existing graph-based methods that summarize a number of structural features, the proposed nodes' evolution diversity inspired method (NEDM) detects anomalies in dynamic social networks from the perspective of diverse evolution mechanisms. More specifically, NEDM applies link prediction algorithms at the micro-level to fit evolution mechanisms followed by the behaviors of nodes, and designs indices to evaluate their fitting degrees in edge removal and generation processes. In addition, the behavior of a node is represented as a quantum superposition state where such behavior follows different evolution mechanisms with uncertain probabilities. We propose a quantum mechanism based particle swarm optimization algorithm (QMPSO) in NEDM. QMPSO determines the optimal observation states of the behaviors of different nodes, and maximally reflects the evolutional fluctuations in the evolution processes of social networks. As a result, NEDM can quantify the evolutional fluctuations in different periods, and detect anomalies in dynamic social networks. Comparing with art-of-the-state methods and real social data in extensive experiments on disparate real-world social networks, we verify the outstanding performance of NEDM in terms of both accuracy and universality.																	1041-4347	1558-2191				OCT 1	2020	32	10					1868	1880		10.1109/TKDE.2019.2912574													
J								Automatic Classification of Algorithm Citation Functions in Scientific Literature	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Feature extraction; Machine learning algorithms; Metadata; Clustering algorithms; Approximation algorithms; Machine learning; Computer science; Algorithm citation; ensemble machine learning; scholarly big data; algorithmic evolution	MEDIA	Computer sciences and related disciplines evolve around developing, evaluating, and applying algorithms. Typically, an algorithm is not developed from scratch, but uses and builds upon existing ones, which often are proposed and published in scholarly articles. The ability to capture this evolution relationship among these algorithms in scientific literature would not only allow us to understand how a particular algorithm is composed, but also shed light on large-scale analysis of algorithmic evolution through different temporal spans and thematic scales. We propose to capture such evolution relationship between two algorithms by investigating the knowledge represented in citation contexts, where authors explain how cited algorithms are used in their works. A set of heterogeneous ensemble machine-learning methods is proposed, where the combination of two base classifiers trained with heterogeneous feature types is used to automatically identify the algorithm usage relationship. The proposed heterogeneous ensemble methods achieve the best average F1 of 0.749 and 0.905 for fine-grained and binary algorithm citation function classification, respectively. The success of this study will allow us to generate a large-scale algorithm citation network from a collection of scholarly documents representing multiple time spans, venues, and fields of study. Such a network will be used as an instrument not only to answer critical questions in algorithm search, such as identifying the most influential and generalizable algorithms, but also to study the evolution of algorithmic development and trends over time.																	1041-4347	1558-2191				OCT 1	2020	32	10					1881	1896		10.1109/TKDE.2019.2913376													
J								BATON: Batch One-Hop Personalized PageRanks with Efficiency and Accuracy	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Personalized PageRanks; query performance; graph algorithms	COMPUTATION	Personalized PageRank (PPR) is a classic measure of the relevance among different nodes in a graph, and has been applied in numerous systems, such as Twitter's Who-To-Follow and Pinterest's Related Pins. Existing work on PPR has mainly focused on three general types of queries, namely, single-pair PPR, single-source PPR, and all-pair PPR. However, we observe that there are applications that rely on a new query type (referred to as batch one-hop PPR), which takes as input a set S of source nodes and, for each node s is an element of S and each of s's neighbor v, asks for the PPR value of v with respect to s. None of the existing PPR algorithms is able to efficiently process batch one-hop queries, due to the inherent differences between batch one-hop PPR and the three general query types. To address the limitations of existing algorithms, this paper presents Baton, an algorithm for batch one-hop PPR that offers both strong theoretical guarantees and practical efficiency. Baton leverages the characteristics of one-hop PPR to avoid unnecessary computation, and it incorporates advanced mechanisms to improve the cost-effectiveness of PPR derivations. Extensive experiments on benchmark datasets show that Baton is up to three orders of magnitude faster than the state of the art, while offering the same accuracy.																	1041-4347	1558-2191				OCT 1	2020	32	10					1897	1908		10.1109/TKDE.2019.2912606													
J								Cross-Domain Sentiment Encoding through Stochastic Word Embedding	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Training; Task analysis; Computational modeling; Stochastic processes; Standards; Buildings; Computer science; Cross domain; sentiment classification; word; document embedding; similarity matrix; stochastic neighbor embedding		Sentiment analysis is an important topic concerning identification of feelings, attitudes, emotions and opinions from text. To automate such analysis, a large amount of example text needs to be manually annotated for model training. This is laborious and expensive, but the cross-domain technique is a key solution to reducing the cost by reusing annotated reviews across domains. However, its success largely relies on the learning of a robust common representation space across domains. In the recent years, significant effort has been invested to improve the cross-domain representation learning by designing increasingly more complex and elaborate model inputs and architectures. We support that it is not necessary to increase design complexity as this inevitably consumes more time in model training. Instead, we propose to explore the word polarity and occurrence information through a simple mapping and encode such information more accurately whilst managing lower computational costs. The proposed approach is unique and takes advantage of the stochastic embedding technique to tackle cross-domain sentiment alignment. Its effectiveness is benchmarked with over ten data tasks constructed from two review corpora and it is compared against ten classical and state-of-the-art methods.																	1041-4347	1558-2191				OCT 1	2020	32	10					1909	1922		10.1109/TKDE.2019.2913379													
J								Efficient Learning with Exponentially-Many Conjunctive Precursors for Interpretable Spatial Event Forecasting	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Forecasting; Computational modeling; Predictive models; Numerical models; Kernel; Task analysis; Complexity theory; Conjunctive feature learning; spatial event forecasting; multi-task learning; hierarchical kernel learning		Forecasting spatial societal events in social media is significant and challenging. Most existing methods consider the frequencies of keywords or n-grams to be features, but have not explored the exponentially large space of the conjunctions of those features, such as keyword co-occurrence in messages, which can serve as crucial precursor rules. Due to the inherent exponential complexity of ensemble rule learning, existing work typically adopts greedy/heuristic strategies. This means that they cannot guarantee the solution's optimality, which would require a considerably more sophisticated model for spatial event forecasting, while still suffering from major challenges: 1) Exponentially-dimensional feature learning with distant supervision, 2) Numerical values of conjunctive features, and 3) Spatially heterogeneous conjunction patterns. To concurrently address all these challenges with a theoretical guarantee, we propose a novel spatial event forecasting model which learns numerical conjunctive features efficiently. Specifically, to consider their magnitude, traditional Boolean rules are innovatively generalized to deal with numerical conjunctive features with amenable computational properties. To handle the geographical similarity and heterogeneity in numerical conjunctive feature learning, we propose a new model that implements through a new bi-space hierarchical sparsity regularization for locations and features. Moreover, we propose a new algorithm to optimize the model parameters and prove that it enjoys theoretical guarantees for both the error bounds and time efficiency. Extensive experiments on multiple datasets demonstrate the effectiveness and efficiency of the proposed method.																	1041-4347	1558-2191				OCT 1	2020	32	10					1923	1935		10.1109/TKDE.2019.2912187													
J								Fraud Detection in Dynamic Interaction Network	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Hidden Markov models; Anomaly detection; Data models; Probabilistic logic; Correlation; Telecommunications; fraud detection; sequential schema; interaction schema; telecommunication network; probabilistic graphical model	LATENT DIRICHLET ALLOCATION; ANOMALY DETECTION	Fraud detection from massive user behaviors is often regarded as trying to find a needle in a haystack. In this paper, we suggest abnormal behavioral patterns can be better revealed if both sequential and interaction behaviors of users can be modeled simultaneously, which however has rarely been addressed in prior work. Along this line, we propose a COllective Sequence and INteraction (COSIN) model, in which the behavioral sequences and interactions between source and target users in a dynamic interaction network are modeled uniformly in a probabilistic graphical model. More specifically, the sequential schema is modeled with a hierarchical Hidden Markov Model, and meanwhile it is shifted to the interaction schema to generate the interaction counts through Poisson factorization. A hybrid Gibbs-Variational algorithm is then proposed for efficient parameter estimation of the COSIN model. We conduct extensive experiments on both synthetic and real-world telecom datasets in different scales, and the results show that the proposed model outperforms some competitive baseline methods and is scalable. A case is further presented to show the precious explainability of the model.																	1041-4347	1558-2191				OCT 1	2020	32	10					1936	1950		10.1109/TKDE.2019.2912817													
J								Joint Multi-View Hashing for Large-Scale Near-Duplicate Video Retrieval	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Near-duplicate video retrieval; joint multi-view hashing; one-step learning; video indexing	SEARCH; ALGORITHM	Multi-view hashing can well support large-scale near-duplicate video retrieval, due to its desirable advantages of mutual reinforcement of multiple features, low storage cost, and fast retrieval speed. However, there are still two limitations that impede its performance. First, existing methods only consider local structures in multiple features. They ignore the global structure that is important for near-duplicate video retrieval, and cannot fully exploit the dependence and complementarity of multiple features. Second, existing works always learn hashing functions bit by bit, which unfortunately increases the time complexity of hash function learning. In this paper, we propose a supervised hashing scheme, termed as joint multi-view hashing (JMVH), to address the aforementioned problems. It jointly preserves the global and local structures of multiple features while learning hashing functions efficiently. Specially, JMVH considers features of video as items, based on which an underlying Hamming space is learned by simultaneously preserving their local and global structures. In addition, a simple but efficient multi-bit hash function learning based on generalized eigenvalue decomposition is devised to learn multiple hash functions within a single step. It can significantly reduce the time complexity of conventional hash function learning processes that sequentially learn multiple hash functions bit by bit. The proposed JMVH is evaluated on two public databases: CC_WEB_VIDEO and UQ_VIDEO. Experimental results demonstrate that the proposed JMVH achieves more than a 5 percent improvement compared to several state-of-the-art methods which indicates the superior performance of JMVH.																	1041-4347	1558-2191				OCT 1	2020	32	10					1951	1965		10.1109/TKDE.2019.2913383													
J								OLAP over Probabilistic Data Cubes II: Parallel Materialization and Extended Aggregates	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Probabilistic databases; OLAP; data warehousing		On-Line Analytical Processing (OLAP) enables powerful analytics by quickly computing aggregate values of numerical measures over multiple hierarchical dimensions for massive datasets. However, many types of source data, e.g., from GPS, sensors, and other measurement devices, are intrinsically inaccurate (imprecise and/or uncertain) and thus OLAP cannot be readily applied. In this paper, we address the resulting data veracity problem in OLAP by proposing the concept of probabilistic data cubes. Such a cube is comprised of a set of probabilistic cuboids which summarize the aggregated values in the form of probability mass functions (pmfs in short) and thus offer insights into the underlying data quality and enable confidence-aware query evaluation and analysis. However, the probabilistic nature of data poses computational challenges, since a probabilistic database can have exponential number of possible worlds under the possible world semantics. Even worse, it is hard to share computations among different cuboids, as aggregation functions that are distributive for traditional data cubes, e.g., SUM, become holistic in probabilistic settings. In this paper, we propose a complete set of techniques for probabilistic data cubes, from cuboid aggregation, over cube materialization, to query evaluation. We study two types of aggregation: convolution and sketch-based, which take polynomial time complexities for aggregation and jointly enable efficient query processing. Also, our proposal is versatile in terms of: 1) its capability of supporting common aggregation functions, i.e., SUM, COUNT, MAX, and AVG; 2) its adaptivity to different materialization strategies, e.g., full versus partial materialization, with support of our devised cost models and parallelization framework; 3) its coverage of common OLAP operations, i.e., probabilistic slicing and dicing queries. Extensive experiments over real and synthetic datasets show that our techniques are effective and scalable.																	1041-4347	1558-2191				OCT 1	2020	32	10					1966	1981		10.1109/TKDE.2019.2913420													
J								On the Usefulness of SQL-Query-Similarity Measures to Find User Interests	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Feature extraction; Relational databases; Extraterrestrial measurements; Companies; Clustering algorithms; SQL log analysis; SQL query representations; similarity measures	ALGORITHM	In the sciences and elsewhere, the use of relational databases has become ubiquitous. An important challenge is finding hot spots of user interests. In principle, one can discover user interests by clustering the queries in the query log. Such a clustering requires a notion of query similarity. This, in turn, raises the question of what features of SQL queries are meaningful. We have studied the query representations proposed in the literature and corresponding similarity functions and have identified shortcomings of all of them. To overcome these limitations, we propose new similarity functions for SQL queries. They rely on the so-called access area of a query and, more specifically, on the overlap and the closeness of the access areas. We have carried out experiments systematically to compare the various similarity functions described in this article. The first series of experiments measures the quality of clustering and compares it to a ground truth. In the second series, we focus on the query log from the well-known SkyServer database. Here, a domain expert has interpreted various clusters by hand. We conclude that clusters obtained with our new measures of similarity seem to be good indicators of user interests.																	1041-4347	1558-2191				OCT 1	2020	32	10					1982	1999		10.1109/TKDE.2019.2913381													
J								Online Knowledge Level Tracking with Data-Driven Student Models and Collaborative Filtering	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Hidden Markov models; Predictive models; Data models; Task analysis; Adaptation models; Knowledge engineering; Production facilities; Student model; knowledge level estimation; machine learning; Gaussian processes	INTELLIGENT TUTORING SYSTEMS; PERFORMANCE; NETWORKS; SLIP	Intelligent Tutoring Systems are promising tools for delivering optimal and personalized learning experiences to students. A key component for their personalization is the student model, which infers the knowledge level of the students to balance the difficulty of the exercises. While important advances have been achieved, several challenges remain. In particular, the models should be able to track in real-time the evolution of the students' knowledge levels. These evolutions are likely to follow different profiles for each student, while measuring the exact knowledge level remains difficult given the limited and noisy information provided by the interactions. This paper introduces a novel model that addresses these challenges with three contributions: 1) the model relies on Gaussian Processes to track online the evolution of the student's knowledge level over time, 2) it uses collaborative filtering to rapidly provide long-term predictions by leveraging the information from previous users, and 3) it automatically generates abstract representations of knowledge components via automatic relevance determination of covariance matrices. The model is evaluated on three datasets, including real users. The results demonstrate that the model converges to accurate predictions in average four times faster than the compared methods.																	1041-4347	1558-2191				OCT 1	2020	32	10					2000	2013		10.1109/TKDE.2019.2912367													
J								Parameter-Free Weighted Multi-View Projected Clustering with Structured Graph Learning	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Clustering methods; Task analysis; Dimensionality reduction; Laplace equations; Visualization; Clustering algorithms; Biomedical optical imaging; Multi-view clustering; dimensionality reduction; structured graph learning	PROPAGATION; FRAMEWORK; SCALE	In many real-world applications, we are often confronted with high dimensional data which are represented by various heterogeneous views. How to cluster this kind of data is still a challenging problem due to the curse of dimensionality and effectively integration of different views. To address this problem, we propose two parameter-free weighted multi-view projected clustering methods which perform structured graph learning and dimensionality reduction simultaneously. We can use the obtained structured graph directly to extract the clustering indicators, without performing other discretization procedures as previous graph-based clustering methods have to do. Moreover, two parameter-free strategies are adopted to learn an optimal weight for each view automatically, without introducing a regularization parameter as previous methods do. Extensive experiments on several public datasets demonstrate that the proposed methods outperform other state-of-the-art approaches and can be used more practically.																	1041-4347	1558-2191				OCT 1	2020	32	10					2014	2025		10.1109/TKDE.2019.2913377													
J								SentiDiff: Combining Textual Information and Sentiment Diffusion Patterns for Twitter Sentiment Analysis	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Twitter; Sentiment analysis; Prediction algorithms; Fuses; Task analysis; Data mining; Noise measurement; Sentiment analysis; sentiment diffusion; social networks; feature fusion; graph analysis	SOCIAL NETWORKS	Twitter sentiment analysis has become a hot research topic in recent years. Most of existing solutions to Twitter sentiment analysis basically only consider textual information of Twitter messages, and struggle to perform well when facing short and ambiguous Twitter messages. Recent studies show that sentiment diffusion patterns on Twitter have close relationships with sentiment polarities of Twitter messages. Therefore, in this paper, we focus on how to fuse textual information of Twitter messages and sentiment diffusion patterns to obtain better performance of sentiment analysis on Twitter data. To this end, we first analyze sentiment diffusion by investigating a phenomenon called sentiment reversal, and find some interesting properties of sentiment reversals. Then, we consider the inter-relationships between textual information of Twitter messages and sentiment diffusion patterns, and propose an iterative algorithm called SentiDiff to predict sentiment polarities expressed in Twitter messages. To the best of our knowledge, this work is the first to utilize sentiment diffusion patterns to help improve Twitter sentiment analysis. Extensive experiments on real-world dataset demonstrate that compared with state-of-the-art textual information based sentiment analysis algorithms, our proposed algorithm yields PR-AUC improvements between 5.09 and 8.38 percent on Twitter sentiment classification tasks.																	1041-4347	1558-2191				OCT 1	2020	32	10					2026	2039		10.1109/TKDE.2019.2913641													
J								User Group Analytics Survey and Research Opportunities	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING										Data visualization; Motion pictures; Sociology; Statistics; Task analysis; Data analysis; Databases; User data; user group; user group analytics	EFFECTIVE COMMUNITY SEARCH; VISUAL ANALYTICS; DATA VISUALIZATION; DATA EXPLORATION; NAVIGATION; QUERY; COHORT; CONSTRUCTION; EXPLORER; PATTERNS	User data can be acquired from various domains and is characterized by a combination of demographics such as age and occupation, and user actions such as rating a movie or recording one's blood pressure. User data is appealing to analysts in their role as data scientists who seek to conduct large-scale population studies, and gain insights on various population segments. It is also appealing to users in their role as information consumers who use the social Web for routine tasks such as finding a book club or choosing a physical activity. User data analytics usually relies on identifying group-level behaviors such as "Asian women who publish regularly in databases". Group analytics addresses peculiarities of user data such as noise and sparsity to enable insights. In this survey, we discuss different approaches for each component of user group analytics, i.e., discovery, exploration, and visualization. We focus on related work which arises from combining those components. We also discuss challenges and future directions of having an all-in-one system, where all those components are combined. This survey has been presented in the form of two tutorials [1] , [2].																	1041-4347	1558-2191				OCT 1	2020	32	10					2040	2059		10.1109/TKDE.2019.2913651													
J								Low-level multiscale image segmentation and a benchmark for its evaluation	COMPUTER VISION AND IMAGE UNDERSTANDING										Image segmentation; Benchmark; Low-level vision	INTEGRATED EDGE	In this paper, we present a segmentation algorithm to detect low-level structure present in images. The algorithm is designed to partition a given image into regions, corresponding to image structures, regardless of their shapes, sizes, and levels of interior homogeneity. We model a region as a connected set of pixels that is surrounded by ramp edge discontinuities where the magnitude of these discontinuities is large compared to the variation inside the region. Each region is associated with a scale that depends upon the fraction of the strong and weak parts of its boundary. Traversing through the range of all possible scales, we obtain all regions present in the image. Regions strictly merge as the scale increases; hence a tree is formed where the root node corresponds to the whole image, nodes closer to the root along a path correspond to larger regions and those further from the root capture smaller regions representing embedded details. To evaluate the accuracy and precision of our algorithm, as well as to compare it to the existing algorithms, we present a new benchmark dataset for low-level image segmentation. We provide evaluation methods for both boundary-based and region-based performance of algorithms. We also annotate different parts of the images that are difficult to segment with the types of segmentation challenges they pose. This enables our benchmark to give an account of which algorithm fails where. We show that our proposed algorithm performs better than the widely used low-level segmentation algorithms on this benchmark.																	1077-3142	1090-235X				OCT	2020	199								103026	10.1016/j.cviu.2020.103026													
J								End-to-end deep learning-based fringe projection framework for 3D profiling of objects	COMPUTER VISION AND IMAGE UNDERSTANDING										3D reconstruction; Deep learning; Fringe projection; Active stereo; Phase unwrapping	FOURIER-TRANSFORM PROFILOMETRY; PHASE	Fringe projection techniques are widely used for precise three-dimensional depth profiling of objects. Existing signal processing-based fringe projection techniques measure the phase deformation of the projected fringe patterns with a sequence of operations, such as fringe denoising, fringe analysis for wrapped phase extraction, followed by phase unwrapping. However, the error induced in any of the stages leads to erroneous depth estimation. Furthermore, any aliasing in frequency domain fringe analysis and ill-posed nature of phase unwrapping limit the overall accuracy of the Fringe Projection Profilometry (FPP). To this end, unlike the traditional approaches, we propose a paradigm shift by introducing a novel end-to-end deep learningbased framework for FPP that does not need any frequency domain filtering and phase unwrapping. The proposed framework directly reconstructs the object's depth profile from the deformed fringe itself through a multi-resolution similarity assessment convolutional neural network. We compare the performance of the proposed framework with two widely used conventional approaches. The evaluations are performed for various challenging and important scenarios such as low fringe-frequency, depth profiles with high dynamic range and noisy fringes. The results demonstrate that the proposed framework achieves promising results in all these scenarios.																	1077-3142	1090-235X				OCT	2020	199								103023	10.1016/j.cviu.2020.103023													
J								Partial domain adaptation based on shared class oriented adversarial network	COMPUTER VISION AND IMAGE UNDERSTANDING										Knowledge transfer; Partial domain adaptation; Adversarial network; Weighted class sampling	KERNEL	Most existing domain adaptation methods assume that the label space of the source domain is the same as the label space of the target domain. However, this assumption is generally untenable due to the differences between the two domains. Therefore, a novel domain adaptation paradigm called Partial Domain Adaptation (PDA), which only assumes that the source label space is large enough to subsume the target label space has been proposed recently to relax such strict assumption. Previous partial domain adaptation methods mainly utilize weighting mechanisms to alleviate negative transfer caused by outlier classes samples. Though these methods have achieved high performance in PDA tasks, all the heterogeneous data is retained during the whole training process, which still contributes to negative transfer. In this work, we propose a shared class oriented adversarial network (SCOAN) for partial domain adaptation. Outlier samples are excluded from training process via weighting strategy to entirely circumvent negative transfer and positive transfer is performed by combining adversarial network and Maximum Mean Discrepancy (MMD) to bridge domain gap. Multi-classifier module is proposed to further improve the generalization ability of the network. Extensive experiments show that SCOAN achieves state-of-the-art results on several benchmark partial domain adaptation datasets.																	1077-3142	1090-235X				OCT	2020	199								103018	10.1016/j.cviu.2020.103018													
J								Refining high-frequencies for sharper super-resolution and deblurring	COMPUTER VISION AND IMAGE UNDERSTANDING										Image super-resolution; Video super-resolution; Video Deblurring; Dual motion warping with attention; 2-phase progressive-retrogressive training; High-frequency refinement network; HFR-Net	IMAGE SUPERRESOLUTION; VIDEO SUPERRESOLUTION; NETWORKS	A sub-problem of paramount importance in super-resolution is the generation of an upsampled image (or frame) that is 'sharp'. In deblurring, the core problem itself is of removing the blur, and it is equivalent to the problem of generating a 'sharper' version of the given image. This sharpness in the generated image comes by accurately predicting the high-frequency details (commonly referred to as fine-details) such as object edges. Thus high-frequency prediction is a vital sub-problem in super-resolution and a core problem in deblurring. To generate a sharp upsampled or deblurred image, this paper proposes a multi-stage neural network architecture 'HFR-Net' that works on the principle of 'explicit refinement and fusion of high-frequency details'. To implement this principle, HFR-Net is trained with a novel 2-phase progressive-retrogressive training method. In addition to the training method, this paper also introduces dual motion warping with attention. It is a technique that is specifically designed to handle videos that have different rates of motion. Results obtained from extensive experiments on multiple super-resolution and deblurring datasets reveal that the proposed approach gives better results than the current state-of-the-art techniques.																	1077-3142	1090-235X				OCT	2020	199								103034	10.1016/j.cviu.2020.103034													
J								Dynamic mode decomposition via dictionary learning for foreground modeling in videos	COMPUTER VISION AND IMAGE UNDERSTANDING										Dynamic mode decomposition; Nonlinear dynamical system; Dictionary learning; Object extraction; Background modeling; Foreground modeling	BACKGROUND SUBTRACTION; SPARSE; ALGORITHM	Accurate extraction of foregrounds in videos is one of the challenging problems in computer vision. In this study, we propose dynamic mode decomposition via dictionary learning (dl-DMD), which is applied to extract moving objects by separating the sequence of video frames into foreground and background information with a dictionary learned using block patches on the video frames. Dynamic mode decomposition (DMD) decomposes spatiotemporal data into spatial modes, each of whose temporal behavior is characterized by a single frequency and growth/decay rate and is applicable to split a video into foregrounds and the background when applying it to a video. And, in dl-DMD, DMD is applied on coefficient matrices estimated over a learned dictionary, which enables accurate estimation of dynamical information in videos. Due to this scheme, dl-DMD can analyze the dynamics of respective regions in a video based on estimated amplitudes and temporal evolution over patches. The results on synthetic data exhibit that dl-DMD outperforms the standard DMD and compressed DMD (cDMD) based methods. Also, the results of an empirical performance evaluation in the case of foreground extraction from videos using publicly available dataset demonstrates the effectiveness of the proposed dl-DMD algorithm and achieves a performance that is comparable to that of the state-of-the-art techniques in foreground extraction tasks.																	1077-3142	1090-235X				OCT	2020	199								103022	10.1016/j.cviu.2020.103022													
J								Task differentiation: Constructing robust branches for precise object detection	COMPUTER VISION AND IMAGE UNDERSTANDING										Task differentiation; Feature fusion; Object detection; SSD		Most prevailing object detection methods share networks and features between localization and classification components, which easily leads to sub-optimal learning for the two separate tasks. In this paper, we propose a conception of task differentiation and design specialized sub-networks for both localization and classification components based on SSD framework. A novel probability based localization method is introduced into the one-stage framework and combined with bounding box regression for precise object localization. Furthermore, a new feature fusion strategy, together with a global attention mechanism, is proposed to learn more robust features. Experimental results on PASCAL VOC and MS COCO data sets indicate that our method has impressive performance compared with other state-of-the-art object detection approaches.																	1077-3142	1090-235X				OCT	2020	199								103030	10.1016/j.cviu.2020.103030													
J								Residual network with detail perception loss for single image super-resolution	COMPUTER VISION AND IMAGE UNDERSTANDING										Detail perception loss; Multi-layer perceptron; Single image super-resolution		Recently, deep convolutional neural networks have demonstrated high-quality reconstruction for single image super-resolution. In this study, we present a network by using residual blocks with cascading simple blocks to improve the image resolution. Cascading simple blocks with a multi-layer perceptron are conducive to extract features and approximate a complex mapping with fewer parameters. Skip connections can help to alleviate the vanishing-gradient problem of deep networks. In addition, our network contains two pathways. One is to predict the high frequency information of the high resolution image and the other is to predict the low frequency information of the high resolution image. Then the information of two pathways is fused, and pixel-shuffle is used for upsampling. Moreover, to capture texture details of images, we introduce a novel loss function called detail perception loss, which is used to measure the difference of the wavelet coefficients from the reconstructed image and ground truth. By reducing detail perception loss, texture details of the reconstructed image are becoming more similar with texture details of ground truth. Extensive quantitative and qualitative experiments on four benchmark datasets show that our method achieves superior performance over typical single image super-resolution methods.																	1077-3142	1090-235X				OCT	2020	199								103007	10.1016/j.cviu.2020.103007													
J								Representation learning of image composition for aesthetic prediction	COMPUTER VISION AND IMAGE UNDERSTANDING										Photo quality assessment; Image quality assessment; Deep learning; Aesthetic; Representation learning		Photo quality assessment (PQA) aims at computationally and precisely evaluating the quality of images from the aspect of aesthetic. Image aesthetic is strongly correlated with composition. However, few existing works have taken composition into consideration. Besides, existing composition features are typically hand-crafted. In this paper, we propose a novel end-to-end framework for representation learning of image composition. Specially, we build a fully connected graph based on deep features in Convolutional Neural Networks (CNNs). In the graph, edge attributes i.e. similarities between deep features at different positions are used for representing image composition. Besides, we use global attributes of the graph to represent miscellaneous aesthetic aspects. Finally, we use a gate unit to combine both composition features and miscellaneous aesthetic features for aesthetic prediction. The whole network can be trained in an end-to-end manner. Experimental results show that the proposed techniques significantly improves the prediction precision of aesthetic and composition over various datasets. We have released our codes at: https://github.com/fei-hdu/ReLIC.																	1077-3142	1090-235X				OCT	2020	199								103024	10.1016/j.cviu.2020.103024													
J								FinnForest dataset: A forest landscape for visual SLAM	ROBOTICS AND AUTONOMOUS SYSTEMS										Forest; Dataset; SLAM; Visual odometry; Navigation; Localization; Mapping; Stereo; Autonomous driving; Mobile robotics; Field robotics; Computer vision	VISION	This paper presents a novel challenging dataset that offers a new landscape of testing material for mobile robotics, autonomous driving research, and forestry operation. In contrast to common urban structures, we explore an unregulated natural environment to exemplify sub-urban and forest environment. The sequences provide two-natured data where each place is visited in summer and winter conditions. The vehicle used for recording is equipped with a sensor rig that constitutes four RGB cameras, an Inertial Measurement Unit, and a Global Navigation Satellite System receiver. The sensors are synchronized based on non-drifting timestamps. The dataset provides trajectories of varying complexity both for the state of the art visual odometry approaches and visual simultaneous localization and mapping algorithms. The full dataset and toolkits are available for download at: http://urn.fi/urn:nbn:fi:att:9b8157a7-1e0f-47c2-bd4e-a19a7e952c0d. As an alternative, you can browse for the dataset using the article title at: http://etsin.fairdata.fi. (C) 2020 The Author(s). Published by Elsevier B.V.																	0921-8890	1872-793X				OCT	2020	132								103610	10.1016/j.robot.2020.103610													
J								On the consensus of nonlinear agents in unknown cluttered environments using random planning	ROBOTICS AND AUTONOMOUS SYSTEMS										Multi-agent consensus; Rapidly-exploring random trees; Probabilistic completeness; Rendezvous	MOBILE AUTONOMOUS AGENTS; MOTION; ALGORITHMS; NETWORKS	The consensus of multi-agent dynamic systems is a metaphor for many different tasks involving group agreement. However, ensuring consensus in real-world scenarios, with non-convex obstacles and kinodynamic motion constraints, proves to be a hard task, since it is quite difficult to model such a problem analytically. Therefore, this paper studies the problem of state agreement for Multi-Robot Systems (MRS) in unknown cluttered complex environments. Here, we propose and analyze a distributed consensus algorithm combined with a Rapidly-exploring Random Tree-based planner, which allows linear and nonlinear systems to reach a common target on their states inside bi- or three-dimensional spaces filled with static obstacles. We demonstrate that, with enough time, our planning strategy ensures probabilistic completeness convergence independently of the topological communication network employed, since some connectivity constraints are observed. Simulated results with linear and nonlinear models are provided, showing the effectiveness of our proposed method in comparison with the state-of-the-art literature for the specific case of position consensus (rendezvous) missions. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103607	10.1016/j.robot.2020.103607													
J								On planar self-folding magnetic chains: Comparison of Newton-Euler dynamics and internal energy optimisation	ROBOTICS AND AUTONOMOUS SYSTEMS										Magnetic self-folding chain; Self-assembly; Newton-Euler dynamics; Magnetic surgery	FRICTION COEFFICIENT; ALGORITHM; MOTION	Within the wide field of self-assembly, the self-folding chain has the unique capability to pass through narrow openings, too small for the assembled structure, yet consists in one connected body. This paper presents a novel analytical framework and corresponding experimental setup to quantify the results of a self-folding process using magnetic forces at the centimetre-scale, with the aim to put experimental results and prediction methods in the context of surgical anchoring and therapy. Two possibilities to predict the folding of a chain of magnetic components in 2D are compared and investigated in an experimental setup. Folding prediction by system Coulomb energy, neglecting folding dynamics, is compared with a simulation of the system dynamics using a novel approach for 2D folding chains, derived from the Newton-Euler equations. The presented algorithm is designed for the parallel computation architecture of modern computer systems to be easily applicable and to achieve an improved simulation speed. The experimental setup for the self-folding chain used to validate the simulation results consists of a chain of magnetic components where movement is limited to one plane and the chain is agitated by the magnetic forces between the chain components. The folding process of the experimental setup is validated for its stability and predictability under different deployment modes. Finally, the results are discussed in light of the folding prediction of longer chains. The implications of the presented findings for a 3D folding chain are discussed together with the challenges to apply the novel dynamics simulation algorithm to the 3D case. The work clearly demonstrates the potential for this novel approach for complex self-folding applications such as magnetic compression anastomosis and anchoring in minimally invasive surgery. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103601	10.1016/j.robot.2020.103601													
J								Range-based target localization and pursuit with autonomous vehicles: An approach using posterior CRLB and model predictive control	ROBOTICS AND AUTONOMOUS SYSTEMS										Range-based target localization; Target tracking; Target pursuit; MPC; Fisher information matrix; Posterior CRLB; Autonomous vehicle	OPTIMAL SENSOR PLACEMENT; MOTION ANALYSIS; ONLY MEASUREMENTS; TRACKING	We address the general problem of multiple target localization and pursuit using measurements of the ranges from the targets to a set of autonomous pursuing vehicles, referred to as trackers. We develop a general framework for targets with models exhibiting uncertainty in the initial state, process, and measurement noise. The main objective is to compute optimal motions for the trackers that maximize the range-based information available for target localization and at the same time yield good target pursuit performance. The solution proposed is rooted in an estimation-theoretical setting that involves the computation of an appropriately defined Bayesian Fisher Information Matrix (FIM). The inverse of the latter yields a posterior Cramer-Rao Lower Bound (CRLB) on the covariance of the targets' state estimation errors that can be possibly achieved with any estimator. Using the FIM, sufficient conditions on the trackers' motions are derived for the ideal relative geometry between the trackers and the targets for which the range information acquired is maximal. This allows for an intuitive understanding of the types of ideal tracker trajectories. To deal with realistic constraints on the trackers' motions and the requirement that the trackers pursue the targets, we then propose a model predictive control (MPC) framework for optimal tracker motion generation with a view to maximizing the predicted range information for target localization while taking explicitly into account the trackers' dynamics, strict constraints on the trackers' states and inputs, and prior knowledge about the targets' states. The efficacy of the MPC is assessed in simulation through the help of representative examples motivated by operational scenarios involving single and multiple targets and trackers. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103608	10.1016/j.robot.2020.103608													
J								Visual place recognition using directed acyclic graph association measures and mutual information-based feature selection	ROBOTICS AND AUTONOMOUS SYSTEMS										Visual place recognition; Localization; Deep convolutional neural networks; Mutual information-based feature selection; SeqSLAM	LOCALIZATION	Visual localization is a challenging problem, especially over the long run, since places can exhibit significant variation due to dynamic environmental and seasonal changes. To tackle this problem, we propose a visual place recognition method based on directed acyclic graph matching and feature maps extracted from deep convolutional neural networks (DCNN). Furthermore, in order to find the best subset of DCNN feature maps with minimal redundancy, we propose to form probability distributions on image representation features and leverage the Jensen-Shannon divergence to rank features. We evaluate the proposed approach on two challenging public datasets, namely the Bonn and the Freiburg datasets, and compare it to the state-of-the-art methods. For image representations, we evaluated the following DCNN architectures: AlexNet, OverFeat, ResNet18 and ResNet50. Due to the proposed graph structure, we are able to account for any kind of correlations in image sequences, and therefore dub our approach NOSeqSLAM. Algorithms with and without feature selection were evaluated based on precision-recall curves, area under the curve score, best recall at 100% precision score and running time, with NOSeqSLAM outperforming the counterpart approaches. Furthermore, by formulating the mutual information-based feature selection specifically for visual place recognition and by selecting the feature percentile with the best score, all the algorithms, and not just NOSeqSLAM, exhibited enhanced performance with the reduced feature set. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103598	10.1016/j.robot.2020.103598													
J								Collective navigation of a multi-robot system in an unknown environment	ROBOTICS AND AUTONOMOUS SYSTEMS										Swarm intelligence; Cooperative control; Autonomous systems; Collective navigation	OBSTACLE AVOIDANCE; ALGORITHMS; FLOCKING	The navigation of autonomous, mobile multi-robot systems in changing environments is a challenging problem investigated over the past years. Cooperative, multiple robots are employed for many different tasks to increase the efficiency and success of a mission. However, many of the existing collective path planning approaches do not guarantee a reliable escape in environments with complex, non-convex obstacles without any prior knowledge. In this study, we developed a navigation framework for multi-robot systems in unknown areas that solely exploit the sensing information and shared data among the agents. The key contribution of this paper is the simultaneous, collision-free motion planning for fully autonomous robots in a collective manner. Furthermore, our communication architecture enables the robots to find an appropriate path to a desired, joint target position, despite the limited sensing and communication range. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103604	10.1016/j.robot.2020.103604													
J								A novel path planning methodology for automated valet parking based on directional graph search and geometry curve	ROBOTICS AND AUTONOMOUS SYSTEMS										AVP; Path planning; Path coordination; Directional graph search; Geometry curve	CURVATURE	The paper presents a novel path planning methodology based on the directional graph search and the geometry curve for the Automated Valet Parking (AVP) system. The whole path planning methodology is divided into three parts including the global path planning, the path coordination strategy and the parking path planning. Firstly, the global path planning is triggered to find a path from the parking slot entrance to the rough location of the assigned parking spot. A novel directional Hybrid A* algorithm is proposed to generate the global path efficiently without redundant searches, such as the dead end. Afterwards, the path coordination strategy gives a transitional path to connect the end node of the global path to the parking planning start node. The transitional path is composed of geometry curves including arcs and line segments based on the optimal parking start node. Finally, the parking path planning generates a parking path to guide the vehicle from parking start node to the parking space. A modified C-type vertical parking path planning algorithm is utilized to generate the parking path, offering flexibility for choosing the parking start node. Simulation results based on Matlab and PreScan show that it takes less time for the proposed path planning algorithm to generate a feasible path for the AVP system compared with the general planning algorithm. The novel AVP path planning algorithm also has the potential for practical use. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103606	10.1016/j.robot.2020.103606													
J								Estimation of body direction based on gait for service robot applications	ROBOTICS AND AUTONOMOUS SYSTEMS										Service robots; Human-robot interaction; Pedestrian tracking; Kalman filter; Laser range sensor	WALKING; TRACKING; HEAD	Recently, there have been several studies on the research and development of service robots, such as reception or waiter robots for facilities and companion robots for support of baggage transportation or guidance in public spaces. Several experimental results in real environments have been reported. To realize socially acceptable human-robot interaction for service robots, human recognition, including not only position but also body direction, around the robot is important. Using an RGB-D camera, it is possible to detect the posture of a person. However, because the viewing angle of the camera is narrow, it is difficult to recognize the environment around the robot with a single device. This study proposes the estimation of the body direction based on the gait, that is, not only the position and velocity, but also the state of the legs (stance or swing phase), using laser range sensors installed at shin height. We verify the effectiveness of the proposed method for several patterns of movement, which are seen when a person interacts with the service robot and evaluate measurement accuracy. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103603	10.1016/j.robot.2020.103603													
J								A Robust Stereo Feature-aided Semi-direct SLAM System	ROBOTICS AND AUTONOMOUS SYSTEMS										Visual SLAM; Hybrid method; Image brightness rectification	VISUAL ODOMETRY	In autonomous driving, many intelligent perception technologies have been put in use. However, visual SLAM still has problems with robustness, which limits its application, although it has been developed for a long time. We propose a feature-aided semi-direct approach to combine the direct and indirect methods in visual SLAM to allow robust localization under various situations, including large-baseline motion, textureless environment, and great illumination changes. In our approach, we first calculate inter-frame pose estimation by feature matching. Then we use the direct alignment and a multi-scale pyramid, which employs the previous coarse estimation as a priori, to obtain a more precise result. To get more accurate photometric parameters, we combine the online photometric calibration method with visual odometry. Furthermore, we replace the Shi-Tomasi corner with the ORB feature, which is more robust to illumination. For extreme brightness change, we employ the dark channel prior to weaken the halation and maintain the consistency of the image. To evaluate our approach, we build a full stereo visual SLAM system. Experiments on the publicly available dataset and our mobile robot dataset indicate that our approach improves the accuracy and robustness of the SLAM system. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103597	10.1016/j.robot.2020.103597													
J								A novel odor source localization system based on particle filtering and information entropy	ROBOTICS AND AUTONOMOUS SYSTEMS										Source localization; Particle filtering; Information entropy; Pseudo source filtering; Artificial potential field	SOURCE-TERM ESTIMATION; SOURCE DECLARATION; STRATEGY	So far, gas leakage caused by natural or human factors has led to serious consequences in terms of social security. Previous strategies for locating the odor sources appear to be either defective or incomplete. For enhancing the success rate and rapidity, this paper aims to present a novel and complete strategy in search of lurking gas sources. Particle filtering and information entropy are both employed to track the plume information. To improve the tracking efficiency in this process, a novel objective function is designed by considering the entropy gains of the suspected targets as well as the repeated exploration scores. Considering the pseudo sourced caused by obstacles, a statistics-based source determine algorithm is proposed to confirm the source's authenticity, while the artificial potential field method is subsequently applied to eliminate the distractions introduced by the pseudo sources. Simulations and on-site tests are both carried out while results showed that the proposed scheme is competent to complete sources localization task in the scene that contains randomly distributed obstacles and pseudo source. (C) 2020 Elsevier B.V. All rights reserved.																	0921-8890	1872-793X				OCT	2020	132								103619	10.1016/j.robot.2020.103619													
J								Optimization of Correlated and Conflicting Responses of ECM Process Using Flower Pollination Algorithm	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Electrochemical Machining; Flower Pollination Algorithm; Metaheuristic Algorithm; Optimization	PROCESS PARAMETERS; MULTIOBJECTIVE OPTIMIZATION; MODELS	The electrochemical machining (ECM) process has been investigated in this article to achieve the desired process performances by optimizing the machining parameters using the flower pollination algorithm (FPA). Two major process performances namely: material removal rate (MRR) and surface roughness (Ra), which are correlated and conflicting in nature, are optimized with respect to the key process parameters. The regression equations developed by using experimental data are used as objective functions in the flower pollination algorithm. Objectives are set to find the optimal set of process parameters to fulfil a single objective as well as multiple objectives. The performance of the algorithm is checked in terms of accuracy, convergence speed, number of optimized populations, and computational time. The mean values of functional evaluations for MRR and Ra obtained are close to their respective optimal results, which ensures the quality of the convergence. It is further seen that FPA can predict the true overall parametric trends as it does not require keeping any parameter as constant during the analysis.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					1	15		10.4018/IJAMC.2020100101													
J								An Overview of Mutation Strategies in Particle Swarm Optimization	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Local Minima; Optimization; Premature Convergence	ALGORITHM; SEARCH	The Particle swarm optimization (PSO) algorithm is a population-based intelligent stochastic search technique encouraged from the intrinsic manner of bee swarm seeking for their food source. With flexibility for numerical experimentation, the PSO algorithm has been mostly used to resolve diverse kind of optimization problems. The PSO algorithm is frequently captured in local optima meanwhile handling the complex real-world problems. Many authors improved the standard PSO algorithm with different mutation strategies but an exhausted comprehensive overview about mutation strategies is still lacking. This article aims to furnish a concise and comprehensive study of problems and challenges that prevent the performance of the PSO algorithm. It has tried to provide guidelines for the researchers who are active in the area of the PSO algorithm and its mutation strategies. The objective of this study is divided into two sections: primarily to display the improvement of the PSO algorithm with mutation strategies that may enhance the performance of the standard PSO algorithm to great extent and secondly, to motivate researchers and developers to use the PSO algorithm to solve the complex real-world problems. This study presents a comprehensive survey of the various PSO algorithms based on mutation strategies. It is anticipated that this survey would be helpful to study the PSO algorithm in detail for researchers.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					16	37		10.4018/IJAMC.2020100102													
J								Short Term Hydro-Thermal Scheduling Using Backtracking Search Algorithm	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Backtracking Search Algorithm; Cascaded Reservoir; Evolutionary Programming; Hydrothermal Scheduling; Particle Swarm Optimization; Simulated Annealing; Valve Point Loading Effect	PARTICLE SWARM OPTIMIZATION; CODED GENETIC ALGORITHM; DIFFERENTIAL EVOLUTION; SYSTEMS	In this article, a new optimization technique, the backtracking search algorithm (BSA), is proposed to solve the hydrothermal scheduling problem. The BSA has mainly unique five steps: (i) Initialization; (ii) Selection - I; (iii) Mutation; (iv) Crossover; and (v) Selection - II; which have been applied to minimize fuel cost of the hydro-thermal scheduling problem. The BSA is very fast, robust, reliable optimization technique and gives an accurate, optimized result. Mutation and crossover are very effective steps of the BSA, which help to determine the better optimum value of the objective function. Here, four hydro and three thermal power generating units are considered. Performance of each committed generating units (hydro and thermal) are also analyzed using a new proposed algorithm, the BSA. A multi-reservoir cascaded hydroelectric with a nonlinear relationship between water discharge rate and power generation is considered. The valve point loading effect is also considered with a fuel cost function. The proposed optimum fuel cost obtained from the BSA shows the better result as compared to other techniques like particle swarm optimization (PSO), teaching learning-based optimization (TLBO), quasi-oppositional teaching learning-based optimization (QOTLBO), real-coded genetic algorithm (RCGA), mixed-integer linear programming (MILP) and krill herd algorithm (KHA), etc.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					38	63		10.4018/IJAMC.2020100103													
J								Elephant Herding Optimization for Multi-Level Image Thresholding	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Elephant Herding Optimization; Entropy; Image Segmentation; Multi-Level Thresholding; Nature Inspired Optimization	ALGORITHM; SEGMENTATION; ENTROPY	Multilevel thresholding plays a significant role in the arena of image segmentation. The main issue of multilevel image thresholding is to select the optimal combination of threshold value at different level. However, this problem has become challenging with the higher number of levels, because computational complexity is increased exponentially as the increase of number of threshold. To address this problem, this paper has proposed elephant herding optimization (EHO) based multilevel image thresholding technique for image segmentation. The EHO method has been inspired by the herding behaviour of elephant group in nature. Two well-known objective functions such as 'Kapur's entropy' and 'between-class variance method' have been used to determine the optimized threshold values for segmentation of different objects from an image. The performance of the proposed algorithm has been verified using a set of different test images taken from a well-known benchmark dataset named Berkeley Segmentation Dataset (BSDS). For comparative analysis, the results have been compared with three popular algorithms, e.g. cuckoo search (CS), artificial bee colony (ABC) and particle swarm optimization (PSO). It has been observed that the performance of the proposed EHO based image segmentation technique is efficient and promising with respect to the others in terms of the values of optimized thresholds, objective functions, peak signal-to-noise ratio (PSNR), structure similarity index (SSIM) and feature similarity index (FSIM). The algorithm also shows better convergence profile than the other methods discussed.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					64	90		10.4018/IJAMC.2020100104													
J								A New Multi-Objective Firework Algorithm to Solve the Multimodal Planning Network Problem	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Explosion Amplitude; Explosion Sparks; Firework Algorithm; Guiding Sparks; Multimodal Transport; Multi-Objective Optimization; Network Planning; Pareto-Dominance		This article introduces a new approach called multi-objective firework algorithm (MFWA). The proposed approach allows for solving the multimodal transportation network problem (MTNP). The main goal is to develop a decision system that optimizes and determines the planning network of the multimodal transportation (PNMT) problem. The optimization involves reaching the efficient transport mode and multimodal path, in order to move from one country to another while satisfying the set of objectives. Moreover, the firework algorithm has distinct advantages in solving complex optimization problems and in obtaining a solution by a distributed and oriented research system. This approach presents a search way, which is different from the swarm intelligence-based stochastic search technique. For each firework, the process starts by exploding a firework in the sky. The search space is filled with a shower of sparks to get diversity solutions. This new approach proves their efficacy in solving the multi-objective problem, which is shown by the experimental results.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					91	113		10.4018/IJAMC.2020100105													
J								A Novel Multi-Objective Competitive Swarm Optimization Algorithm	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Competitive Swarm Optimizer; Evolutionary Algorithms; Multi-Objective Optimization; Non-Dominating Sorting; Pareto Front; Particle Swarm Optimization; Particle Swarm Optimizer; Swarm Intelligence	EVOLUTIONARY ALGORITHMS	In this article, a new algorithm, namely the multi-objective competitive swarm optimizer (MOCSO), is introduced to handle multi-objective problems. The algorithm has been principally motivated from the competitive swarm optimizer (CSO) and the NSGA-II algorithm. In MOCSO, a pair wise competitive scenario is presented to achieve the dominance relationship between two particles in the population. In each pair wise competition, the particle that dominates the other particle is considered the winner and the other is consigned as the loser. The loser particles learn from the respective winner particles in each individual competition. The inspired CSO algorithm does not use any memory to remember the global best or personal best particles, hence, MOCSO does not need any external archive to store elite particles. The experimental results and statistical tests confirm the superiority of MOCSO over several state-of-the-art multi-objective algorithms in solving benchmark problems.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					114	129		10.4018/IJAMC.2020100106													
J								Three-Step Metaheuristic for the Multiple Objective Multiple Traveling Salesmen Problem	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Center of Mass; Metaheuristic; Multiple Objective; Multiple Salesmen; Neighborhood Search; TSP Solver	GENETIC ALGORITHM	In this article, the multiple objective multiple Traveling Salesman Problem is considered. m salesmen have to visit n cities to perform some tasks each taking a given processing time. Two objectives are considered: balance the working loads of different salesmen and minimize their total traveled distance. To solve this NP-hard problem, a 3-phase metaheuristic was developed. In the first 2 phases, the principle of center of mass and a neighborhood search technique are used to assign the n cities to the m salesmen. In the third phase, a TSP solver was used to generate an optimal tour to every salesman using its assigned cities in phase 2. The metaheuristic was tested using TSP benchmarks of different sizes. The obtained results showed almost optimal load balancing for all tested instances and optimal tours in term of total traveled distances. A conducted comparison study showed that the proposed metaheuristic outperforms a recently published clustering algorithm for the workload objective.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					130	148		10.4018/IJAMC.2020100107													
J								Advanced Applications on Bilingual Document Analysis and Processing Systems	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										BDAPS; BE-HDCS; Bilingual Documents; Configuration Modes; Document Category; Document Classification; English-Hindi Pair; Image Analysis; Natural Language Processing	HINDI; HANDWRITTEN; RECOGNITION; MACHINE; BANGLA; FUZZY; IDENTIFICATION; ENGLISH; TEXTS; MODEL	Today, rapid digitization requires efficient bilingual non-image and image document classification systems. Although many bilingual NLP and image-based systems provide solutions for real-world problems, they primarily focus on text extraction, identification, and recognition tasks with limited document types. This article discusses a journey of these systems and provides an overview of their methods, feature extraction techniques, document sets, classifiers, and accuracy for English-Hindi and other language pairs. The gaps found lead toward the idea of a generic and integrated bilingual English-Hindi document classification system, which classifies heterogeneous documents using a dual class feeder and two character corpora. Its non-image and image modules include pre- and post-processing stages and pre-and post-segmentation stages to classify documents into predefined classes. This article discusses many real-life applications on societal and commercial issues. The analytical results show important findings of existing and proposed systems.C																	1947-8283	1947-8291				OCT-DEC	2020	11	4					149	193		10.4018/IJAMC.2020100108													
J								State Estimation of Power Using the Whale Optimization Algorithm	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										Biogeography-Based Optimization; Evolutionary Programming; State Estimation; Steady State Power; Weighted Least Squares State Estimation; Whale Optimization Algorithm	SYSTEM	In power systems, the process of attaining a better prediction from a set of variables from state variables is called state estimation (SE). These variables consist of magnitudes of bus voltage and the corresponding angles of all the buses. Because of the non-linearity and intricacy of ever-developing power systems, it has become important to apply upgraded techniques for the dissolution and supervision in practical environments. The discussed analysis evaluates the appositeness of a new metaheuristic technique called the whale optimization algorithm (WOA) which is a population-based algorithm, to reduce the measurement errors so as to gauge the optimal point of the power system when some susceptible values are inadequate. WOA displays admirable attainment in global optimization. It employs a bubble-net hunting approach and it mimics the social behaviour of humpback whales to get the best candidate solution. The approach is tested on IEEE-14, IEEE-30, and IEEE-57 bus test systems and the potency is validated by comparison with the biogeography based optimization algorithm (BBO).																	1947-8283	1947-8291				OCT-DEC	2020	11	4					194	213		10.4018/IJAMC.2020100109													
J								Hybrid Cuckoo Search Approach for Course Time-Table Generation Problem	INTERNATIONAL JOURNAL OF APPLIED METAHEURISTIC COMPUTING										ANOVA; Combinatorial Optimization; Constraint Satisfaction Problem; Course Timetable; Cuckoo Search; Global Search; Hill Climbing; Local Search	ALGORITHM	Course time-table generation (CTTG) is a combinatorial optimization problem which largely fits into the family of scheduling problems. It attempts to schedule a number of subjects to particular time slots in an order to satisfy multiple numbers of constraints. A solution of CTTG generates a weekly schedule for each course satisfying several constraints regarding the order of classes, preference of teachers, and other institutional constraints. Automated generation of the course timetable is a problem of optimization that requires satisfying maximum constraints and can be solved with a search-based optimization technique. This article proposes a novel hybrid Cuckoo search approach for solving the Course Time-Table Generation (CTTG) problem for high schools affiliated to the West Bengal Board of Secondary Education (WBBSE), India. The authors investigate the performance of local search Hill climbing against the population-based basic Cuckoo search algorithm on the problem. Thereafter they propose a hybrid Cuckoo search technique that improves the performance significantly showed by ANOVA.																	1947-8283	1947-8291				OCT-DEC	2020	11	4					214	230		10.4018/IJAMC.2020100110													
J								Landslide displacement interval prediction using lower upper bound estimation method with pre-trained random vector functional link network initialization	NEURAL NETWORKS										Prediction interval; Lower upper bound estimation; Random vector functional link network; Population initialization; Landslide displacement prediction	EXTREME LEARNING-MACHINE; 3 GORGES RESERVOIR; NEURAL-NETWORK; DEFORMATION; RAINFALL; WATER; MODEL; AREA; LOAD	Interval prediction is an efficient approach to quantifying the uncertainties associated with landslide evolution. In this paper, a novel method, termed lower upper bound estimation (LUBE), of constructing prediction intervals (PIs) based on neural networks (NNs) is applied and extended to landslide displacement prediction. A random vector functional link network (RVFLN) is adopted as the NN used in the improved LUBE. A hybrid evolutionary algorithm, termed PSOGSA, that combines particle swarm optimization (PSO) and gravitational search algorithm (GSA) is utilized to train LUBE. The loss function of LUBE is redesigned by considering the quality of PI centre, which allows for a more comprehensive evaluation of PIs. The population initialization in the training process of LUBE is implemented by transferring the weights of a series of pre-trained RVFLNs. The performance of the improved LUBE method is validated by considering a comprehensive set of cases using seven benchmark datasets. In addition, a hybrid method that integrates ensemble empirical mode decomposition (EEMD) with the improved LUBE is proposed for the special case of landslide displacement prediction. Six real-world reservoir-induced landslides are considered to validate the capability and merit of the proposed hybrid method. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						286	296		10.1016/j.neunet.2020.07.020													
J								Discretely-constrained deep network for weakly supervised segmentation	NEURAL NETWORKS										Weakly-supervised learning; Segmentation; Discrete optimization; Convolutional neural networks	FULLY CONVOLUTIONAL NETWORKS; ATLAS; MRI	An efficient strategy for weakly-supervised segmentation is to impose constraints or regularization priors on target regions. Recent efforts have focused on incorporating such constraints in the training of convolutional neural networks (CNN), however this has so far been done within a continuous optimization framework. Yet, various segmentation constraints and regularization priors can be modeled and optimized more efficiently in a discrete formulation. This paper proposes a method, based on the alternating direction method of multipliers (ADMM) algorithm, to train a CNN with discrete constraints and regularization priors. This method is applied to the segmentation of medical images with weak annotations, where both size constraints and boundary length regularization are enforced. Experiments on two benchmark datasets for medical image segmentation show our method to provide significant improvements compared to existing approaches in terms of segmentation accuracy, constraint satisfaction and convergence speed. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						297	308		10.1016/j.neunet.2020.07.011													
J								Investigating object compositionality in Generative Adversarial Networks	NEURAL NETWORKS										Generative Adversarial Networks; Objects; Compositionality; Generative modeling; Instance segmentation; Representation learning		Deep generative models seek to recover the process with which the observed data was generated. They may be used to synthesize new samples or to subsequently extract representations. Successful approaches in the domain of images are driven by several core inductive biases. However, a bias to account for the compositional way in which humans structure a visual scene in terms of objects has frequently been overlooked. In this work, we investigate object compositionality as an inductive bias for Generative Adversarial Networks (GANs). We present a minimal modification of a standard generator to incorporate this inductive bias and find that it reliably learns to generate images as compositions of objects. Using this general design as a backbone, we then propose two useful extensions to incorporate dependencies among objects and background. We extensively evaluate our approach on several multi-object image datasets and highlight the merits of incorporating structure for representation learning purposes. In particular, we find that our structured GANs are better at generating multi-object images that are more faithful to the reference distribution. More so, we demonstrate how, by leveraging the structure of the learned generative process, one can 'invert' the learned generative model to perform unsupervised instance segmentation. On the challenging CLEVR dataset, it is shown how our approach is able to improve over other recent purely unsupervised object-centric approaches to image generation. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						309	325		10.1016/j.neunet.2020.07.007													
J								An approach for combining ethical principles with public opinion to guide public policy	ARTIFICIAL INTELLIGENCE										Moral machine; Machine ethics		We propose a framework for incorporating public opinion into policy making in situations where values are in conflict. This framework advocates creating vignettes representing value choices, eliciting the public's opinion on these choices, and using machine learning to extract principles that can serve as succinct statements of the policies implied by these choices and rules to guide the behavior of autonomous systems. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103349	10.1016/j.artint.2020.103349													
J								Designing normative theories for ethical and legal reasoning: LOGIKEY framework, methodology, and tool support	ARTIFICIAL INTELLIGENCE										Trustworthy and responsible AI; Knowledge representation and reasoning; Automated theorem proving; Model finding; Normative reasoning; Normative systems; Ethical issues; Semantical embedding; Higher-order logic	MACHINE MORALITY; DEONTIC LOGIC; SYSTEMS	A framework and methodology-termed LOGIKEY-for the design and engineering of ethical reasoners, normative theories and deontic logics is presented. The overall motivation is the development of suitable means for the control and governance of intelligent autonomous systems. LOGIKEY's unifying formal framework is based on semantical embeddings of deontic logics, logic combinations and ethico-legal domain theories in expressive classic higher-order logic (HOL). This meta-logical approach enables the provision of powerful tool support in LOGIKEY: off-the-shelf theorem provers and model finders for HOL are assisting the LOGIKEY designer of ethical intelligent agents to flexibly experiment with underlying logics and their combinations, with ethico-legal domain theories, and with concrete examples-all at the same time. Continuous improvements of these off-the-shelf provers, without further ado, leverage the reasoning performance in LOGIKEY. Case studies, in which the LOGIKEY framework and methodology has been applied and tested, give evidence that HOL's undecidability often does not hinder efficient experimentation. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103348	10.1016/j.artint.2020.103348													
J								DEL-based epistemic planning: Decidability and complexity	ARTIFICIAL INTELLIGENCE										Epistemic planning; Dynamic epistemic logic; Automated planning; Decision problems; Complexity theory; Automata theory		Epistemic planning can be used for decision making in multi-agent systems with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we present a systematic overview of known complexity and decidability results for epistemic planning based on DEL, as well as provide some new results and improved proofs of existing results based on reductions between the problems. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103304	10.1016/j.artint.2020.103304													
J								Old techniques in new ways: Clause weighting, unit propagation and hybridization for maximum satisfiability	ARTIFICIAL INTELLIGENCE										Maximum satisfiability; Industrial instances; Local search; Clause weighting; Unit propagation; Hybridization	LOCAL SEARCH; MAXSAT; ALGORITHM	Maximum Satisfiability (MaxSAT) is a basic and important constraint optimization problem. When dealing with both hard and soft constraints, the MaxSAT problem is referred to as Partial MaxSAT, which has been used to effectively solve many combinatorial optimization problems in real world. The local search method and the SAT-based method are two popular methods for Partial MaxSAT. Nevertheless, local search algorithms have been dominated by SAT-based algorithms on industrial benchmarks. This work develops an effective local search algorithm for industrial benchmarks, which for the first time is competitive with SAT-based algorithms on industrial MaxSAT benchmarks. We propose a local search algorithm, called SATLike, which exploits the structure of Partial MaxSAT by a novel clause weighting scheme. Then we improve SATLike by integrating a unit propagation based decimation algorithm to generate initial solutions, leading to an improved algorithm, called SATLike 2.0. We also refine SATLike 2.0 and obtain SATLike 3.0. Furthermore, we apply SATLike 3.0 to improve two SAT-based solvers, leading to two hybrid MaxSAT solvers that push the state of the art in MaxSAT solving. Experiments on benchmarks from the MaxSAT Evaluations 2017 and 2018 show that SATLike significantly outperforms previous local search solvers on all the benchmarks. More importantly, SATLike 3.0 has better performance than state-of-the-art SAT-based solvers on unweighted industrial benchmarks. The two hybridized solvers obtain significant improvements on both unweighted and weighted benchmarks. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103354	10.1016/j.artint.2020.103354													
J								Probabilistic reasoning about epistemic action narratives	ARTIFICIAL INTELLIGENCE										Reasoning about actions; Epistemic reasoning; Narrative reasoning; Probabilistic reasoning; Conditional actions; Imperfect sensing	NOISY SENSORS; LOGIC; LANGUAGE	We propose the action language EPEC - Epistemic Probabilistic Event Calculus - that supports probabilistic, epistemic reasoning about narratives of action occurrences and environmentally triggered events, and in particular facilitates reasoning about future belief-conditioned actions and their consequences in domains that include both perfect and imperfect sensing actions. To provide a declarative semantics for sensing and belief conditioned actions in a probabilistic, narrative setting we introduce the novel concept of an epistemic reduct. We then formally compare our language with two established frameworks for probabilistic reasoning about action - the action language PAL by Baral et al., and the extension of the situation calculus to reason about noisy sensors and effectors by Bacchus et al. In both cases we prove a correspondence with EPEC for a class of domains representable in both frameworks. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103352	10.1016/j.artint.2020.103352													
J								Automated temporal equilibrium analysis: Verification and synthesis of multi-player games	ARTIFICIAL INTELLIGENCE										Multi-agent systems; Temporal logic; Nash equilibrium; Bisimulation invariance; Rational verification; Model checking; Synthesis	REACTIVE MODULES; PARITY GAMES; TIME	In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of individual objectives. Typically, those objectives are expressed as temporal logic formulae which the relevant agent desires to see satisfied. Unfortunately, rational verification is computationally complex, and requires specialised techniques in order to obtain practically useable implementations. In this paper, we present such a technique. This technique relies on a reduction of the rational verification problem to the solution of a collection of parity games. Our approach has been implemented in the Equilibrium Verification Environment (EVE) system. The EVE system takes as input a model of a concurrent/multi-agent system represented using the Simple Reactive Modules Language (SRML), where agent goals are represented as Linear Temporal Logic (LTL) formulae, together with a claim about the equilibrium behaviour of the system, also expressed as an LTL formula. EVE can then check whether the LTL claim holds on some (or every) computation of the system that could arise through agents choosing Nash equilibrium strategies; it can also check whether a system has a Nash equilibrium, and synthesise individual strategies for players in the multi-player game. After presenting our basic framework, we describe our new technique and prove its correctness. We then describe our implementation in the EVE system, and present experimental results which show that EVE performs favourably in comparison to other existing tools that support rational verification. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103353	10.1016/j.artint.2020.103353													
J								A technical survey on statistical modelling and design methods for crowdsourcing quality control	ARTIFICIAL INTELLIGENCE										Crowdsourcing; Quality control; Statistical modelling and inference; Mechanism design	FIELD EXPERIMENT; SYSTEMS; GAMIFICATION; FEEDBACK	Online crowdsourcing provides a scalable and inexpensive means to collect knowledge (e.g. labels) about various types of data items (e.g. text, audio, video). However, it is also known to result in large variance in the quality of recorded responses which often cannot be directly used for training machine learning systems. To resolve this issue, a lot of work has been conducted to control the response quality such that low-quality responses cannot adversely affect the performance of the machine learning systems. Such work is referred to as the quality control for crowdsourcing. Past quality control research can be divided into two major branches: quality control mechanism design and statistical models. The first branch focuses on designing measures, thresholds, interfaces and workflows for payment, gamification, question assignment and other mechanisms that influence workers' behaviour. The second branch focuses on developing statistical models to perform effective aggregation of responses to infer correct responses. The two branches are connected as statistical models (i) provide parameter estimates to support the measure and threshold calculation, and (ii) encode modelling assumptions used to derive (theoretical) performance guarantees for the mechanisms. There are surveys regarding each branch but they lack technical details about the other branch. Our survey is the first to bridge the two branches by providing technical details on how they work together under frameworks that systematically unify crowdsourcing aspects modelled by both of them to determine the response quality. We are also the first to provide taxonomies of quality control papers based on the proposed frameworks. Finally, we specify the current limitations and the corresponding future directions for the quality control research. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103351	10.1016/j.artint.2020.103351													
J								Evaluation of the moral permissibility of action plans	ARTIFICIAL INTELLIGENCE										Automatic planning; Plan evaluation; Machine ethics		Research in classical planning so far has been mainly concerned with generating a satisficing or an optimal plan. However, if such systems are used to make decisions that are relevant to humans, one should also consider the ethical consequences generated plans can have. Traditionally, ethical principles are formulated in an action-based manner, allowing to judge the execution of one action. We show how such a judgment can be generalized to plans. Further, we study the computational complexity of making ethical judgment about plans. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103350	10.1016/j.artint.2020.103350													
J								Memetic algorithms outperform evolutionary algorithms in multimodal optimisation	ARTIFICIAL INTELLIGENCE										Search heuristics; Hybridisation; Evolutionary algorithms; Black-box optimisation; Memetic algorithms; Time complexity	LOCAL SEARCH ALGORITHM; ROYAL ROAD FUNCTIONS; CROSSOVER; OPERATORS; MUTATION	Memetic algorithms integrate local search into an evolutionary algorithm to combine the advantages of rapid exploitation and global optimisation. We provide a rigorous runtime analysis of memetic algorithms on the Hurdle problem, a landscape class of tunable difficulty with a "big valley structure", a characteristic feature of many hard combinatorial optimisation problems. A parameter called hurdle width describes the length of fitness valleys that need to be overcome. We show that the expected runtime of plain evolutionary algorithms like the (1+1) EA increases steeply with the hurdle width, yielding superpolynomial times to find the optimum, whereas a simple memetic algorithm, (1+1) MA, only needs polynomial expected time. Surprisingly, while increasing the hurdle width makes the problem harder for evolutionary algorithms, it becomes easier for memetic algorithms. We further give the first rigorous proof that crossover can decrease the expected runtime in memetic algorithms. A (2+1) MA using mutation, crossover and local search outperforms any other combination of these operators. Our results demonstrate the power of memetic algorithms for problems with big valley structures and the benefits of hybridising multiple search operators. (C) 2020 Elsevier B.V. All rights reserved.																	0004-3702	1872-7921				OCT	2020	287								103345	10.1016/j.artint.2020.103345													
J								Analytical and fast Fiber Orientation Distribution reconstruction in 3D-Polarized Light Imaging	MEDICAL IMAGE ANALYSIS										Fiber orientation distribution; 3D-PLI; Polarized light imaging; Diffusion MRI	STRUCTURE TENSOR ANALYSIS; DIFFUSION MRI; MICROSCOPY	Three dimensional Polarized Light Imaging (3D-PLI) is an optical technique which allows mapping the spatial fiber architecture of fibrous postmortem tissues, at sub-millimeter resolutions. Here, we propose an analytical and fast approach to compute the fiber orientation distribution (FOD) from high-resolution vector data provided by 3D-PLI. The FOD is modeled as a sum of K orientations/Diracs on the unit sphere, described on a spherical harmonics basis and analytically computed using the spherical Fourier transform. Experiments are performed on rich synthetic data which simulate the geometry of the neuronal fibers and on human brain data. Results indicate the analytical FOD is computationally efficient and very fast, and has high angular precision and angular resolution. Furthermore, investigations on the right occipital lobe illustrate that our strategy of FOD computation enables the bridging of spatial scales from microscopic 3D-PLI information to macroor mesoscopic dimensions of diffusion Magnetic Resonance Imaging (MRI), while being a means to evaluate prospective resolution limits for diffusion MRI to reconstruct region-specific white matter tracts. These results demonstrate the interest and great potential of our analytical approach. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101760	10.1016/j.media.2020.101760													
J								Local rotation invariance in 3D CNNs	MEDICAL IMAGE ANALYSIS										Local rotation invariance; Convolutional neural network; Steerable filters; 3D Texture	TEXTURE CLASSIFICATION	Locally Rotation Invariant (LRI) image analysis was shown to be fundamental in many applications and in particular in medical imaging where local structures of tissues occur at arbitrary rotations. LRI constituted the cornerstone of several breakthroughs in texture analysis, including Local Binary Patterns (LBP), Maximum Response 8 (MR8) and steerable filterbanks. Whereas globally rotation invariant Convolutional Neural Networks (CNN) were recently proposed, LRI was very little investigated in the context of deep learning. LRI designs allow learning filters accounting for all orientations, which enables a drastic reduction of trainable parameters and training data when compared to standard 3D CNNs. In this paper, we propose and compare several methods to obtain LRI CNNs with directional sensitivity. Two methods use orientation channels (responses to rotated kernels), either by explicitly rotating the kernels or using steer able filters. These orientation channels constitute a locally rotation equivariant representation of the data. Local pooling across orientations yields LRI image analysis. Steerable filters are used to achieve a fine and efficient sampling of 3D rotations as well as a reduction of trainable parameters and operations, thanks to a parametric representations involving solid Spherical Harmonics (SH),which are products of SH with associated learned radial profiles. Finally, we investigate a third strategy to obtain LRI based on rotational invariants calculated from responses to a learned set of solid SHs. The proposed methods are evaluated and compared to standard CNNs on 3D datasets including synthetic textured volumes composed of rotated patterns, and pulmonary nodule classification in CT. The results show the importance of LRI image analysis while resulting in a drastic reduction of trainable parameters, outperforming standard 3D CNNs trained with rotational data augmentation. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101756	10.1016/j.media.2020.101756													
J								Handling confounding variables in statistical shape analysis - application to cardiac remodelling	MEDICAL IMAGE ANALYSIS										Confounder correction; Statistical shape analysis; Computational anatomy; Cardiac remodelling	MODELS; SEGMENTATION; GEOMETRY; OBESITY; HEART	Statistical shape analysis is a powerful tool to assess organ morphologies and find shape changes associated to a particular disease. However, imbalance in confounding factors, such as demographics might invalidate the analysis if not taken into consideration. Despite the methodological advances in the field, providing new methods that are able to capture complex and regional shape differences, the relationship between non-imaging information and shape variability has been overlooked. We present a linear statistical shape analysis framework that finds shape differences unassociated to a controlled set of confounding variables. It includes two confounding correction methods: confounding deflation and adjustment. We applied our framework to a cardiac magnetic resonance imaging dataset, consisting of the cardiac ventricles of 89 triathletes and 77 controls, to identify cardiac remodelling due to the practice of endurance exercise. To test robustness to confounders, subsets of this dataset were generated by randomly removing controls with low body mass index, thus introducing imbalance. The analysis of the whole dataset indicates an increase of ventricular volumes and myocardial mass in athletes, which is consistent with the clinical literature. However, when confounders are not taken into consideration no increase of myocardial mass is found. Using the downsampled datasets, we find that confounder adjustment methods are needed to find the real remodelling patterns in imbalanced datasets. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101792	10.1016/j.media.2020.101792													
J								Spatio-temporal visual attention modelling of standard biometry plane-finding navigation	MEDICAL IMAGE ANALYSIS										Fetal ultrasound; Gaze tracking; Multi-task learning; Saliency prediction; Standard plane detection	FETAL ULTRASOUND; LOCALIZATION	We present a novel multi-task neural network called Temporal SonoEyeNet (TSEN) with a primary task to describe the visual navigation process of sonographers by learning to generate visual attention maps of ultrasound images around standard biometry planes of the fetal abdomen, head (trans-ventricular plane) and femur. TSEN has three components: a feature extractor, a temporal attention module (TAM), and an auxiliary video classification module (VCM). A soft dynamic time warping (sDTW) loss function is used to improve visual attention modelling. Variants of the model are trained on a dataset of 280 video clips, each containing one of the three biometry planes and lasting 3-7 seconds, with corresponding real-time recorded gaze tracking data of an experienced sonographer. We report the performances of the different variants of TSEN for visual attention prediction at standard biometry plane detection. The best model performance is achieved using bi-directional convolutional long-short term memory (biCLSTM) in both TAM and VCM, and it outperforms a previous spatial model on all static and dynamic saliency metrics. As an auxiliary task to validate the clinical relevance of the visual attention modelling, the predicted visual attention maps were used to guide standard biometry plane detection in consecutive US video frames. All spatio-temporal TSEN models achieve higher scores compared to a spatial-only baseline; the best performing TSEN model achieves F1 scores on these standard biometry planes of 83.7%, 89.9% and 81.1%, respectively. (C) 2020 The Authors. Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101762	10.1016/j.media.2020.101762													
J								Weakly supervised object detection with 2D and 3D regression neural networks	MEDICAL IMAGE ANALYSIS										Weakly-supervised; Regression; Lesion; Detection; Weak-labels; Count; Brain; Deep learning; MRI; Enlarged perivascular spaces; Perivascular spaces	ENLARGED PERIVASCULAR SPACES	Finding automatically multiple lesions in large images is a common problem in medical image analysis. Solving this problem can be challenging if, during optimization, the automated method cannot access information about the location of the lesions nor is given single examples of the lesions. We propose a new weakly supervised detection method using neural networks, that computes attention maps revealing the locations of brain lesions. These attention maps are computed using the last feature maps of a segmentation network optimized only with global image-level labels. The proposed method can generate attention maps at full input resolution without need for interpolation during preprocessing, which allows small lesions to appear in attention maps. For comparison, we modify state-of-the-art methods to compute attention maps for weakly supervised object detection, by using a global regression objective instead of the more conventional classification objective. This regression objective optimizes the number of occurrences of the target object in an image, e.g. the number of brain lesions in a scan, or the number of digits in an image. We study the behavior of the proposed method in MNIST-based detection datasets, and evaluate it for the challenging detection of enlarged perivascular spaces - a type of brain lesion - in a dataset of 2202 3D scans with point-wise annotations in the center of all lesions in four brain regions. In MNIST-based datasets, the proposed method outperforms the other methods. In the brain dataset, the weakly supervised detection methods come close to the human intrarater agreement in each region. The proposed method reaches the best area under the curve in two out of four regions, and has the lowest number of false positive detections in all regions, while its average sensitivity over all regions is similar to that of the other best methods. The proposed method can facilitate epidemiological and clinical studies of enlarged perivascular spaces and help advance research in the etiology of enlarged perivascular spaces and in their relationship with cerebrovascular diseases. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license. ( http://creativecommons.org/licenses/by/4.0/ )																	1361-8415	1361-8423				OCT	2020	65								101767	10.1016/j.media.2020.101767													
J								Time-distanced gates in long short-term memory networks	MEDICAL IMAGE ANALYSIS										Lung cancer diagnosis; Longitudinal; Distanced LSTM; Temporal Emphasis Model		The Long Short-Term Memory (LSTM) network is widely used in modeling sequential observations in fields ranging from natural language processing to medical imaging. The LSTM has shown promise for interpreting computed tomography (CT) in lung screening protocols. Yet, traditional image-based LSTM models ignore interval differences, while recently proposed interval-modeled LSTM variants are limited in their ability to interpret temporal proximity. Meanwhile, clinical imaging acquisition may be irregularly sampled, and such sampling patterns may be commingled with clinical usages. In this paper, we propose the Distanced L STM (DL STM) by introducing time-distanced (i.e., time distance to the last scan) gates with a temporal emphasis model (TEM) targeting at lung cancer diagnosis (i.e., evaluating the malignancy of pulmonary nodules) . Briefly, (1) the time distance of every scan to the last scan is modeled explicitly, (2) time-distanced input and forget gates in DLSTM are introduced across regular and irregular sampling sequences, and (3) the newer scan in serial data is emphasized by the TEM. The DLSTM algorithm is evaluated with both simulated data and real CT images (from 1794 National Lung Screening Trial (NLST) patients with longitudinal scans and 1420 clinical studied patients). Experimental results on simulated data indicate the DLSTM can capture families of temporal relationships that cannot be detected with traditional LSTM. Cross-validation on empirical CT datasets demonstrates that DLSTM achieves leading performance on both regularly and irregularly sampled data (e.g., improving LSTM from 0.6785 to 0.7085 on F1 score in NLST). In external-validation on irregularly acquired data, the benchmarks achieved 0.8350 (CNN feature) and 0.8380 (with LSTM) on AUC score, while the proposed DLSTM achieves 0.8905. In conclusion, the DLSTM approach is shown to be compatible with families of linear, quadratic, exponential, and log-exponential temporal models. The DLSTM can be readily extended with other temporal dependence interactions while hardly increasing overall model complexity. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101785	10.1016/j.media.2020.101785													
J								The state-of-the-art in ultrasound-guided spine interventions	MEDICAL IMAGE ANALYSIS										Spine intervention; Intraoperative ultrasound; Image registration; Image-guided surgery	PEDICLE SCREW PLACEMENT; FREEHAND 3D ULTRASOUND; AUGMENTED REALITY; CT REGISTRATION; LUMBAR SPINE; 3-D ULTRASOUND; INTRAOPERATIVE ULTRASOUND; NONRIGID REGISTRATION; SURGICAL NAVIGATION; COMPUTED TOMOGRAPHY	During the last two decades, intra-operative ultrasound (iUS) imaging has been employed for various surgical procedures of the spine, including spinal fusion and needle injections. Accurate and efficient registration of pre-operative computed tomography or magnetic resonance images with iUS images are key elements in the success of iUS-based spine navigation. While widely investigated in research, iUS-based spine navigation has not yet been established in the clinic. This is due to several factors including the lack of a standard methodology for the assessment of accuracy, robustness, reliability, and usability of the registration method. To address these issues, we present a systematic review of the state-of-the-art techniques for iUS-guided registration in spinal image-guided surgery (IGS). The review follows a new taxonomy based on the four steps involved in the surgical workflow that include pre-processing, registration initialization, estimation of the required patient to image transformation, and a visualization process. We provide a detailed analysis of the measurements in terms of accuracy, robustness, reliability, and usability that need to be met during the evaluation of a spinal IGS framework. Although this review is focused on spinal navigation, we expect similar evaluation criteria to be relevant for other IGS applications. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101769	10.1016/j.media.2020.101769													
J								GCTI-SN: Geometry-inspired chemical and tissue invariant stain normalization of microscopic medical images	MEDICAL IMAGE ANALYSIS										Stain normalization; Microscopic images; Jenner-Giemsa stain; Hematoxylin-Eosin stain		Stain normalization of microscopic images is the first pre-processing step in any computer-assisted automated diagnostic tool. This paper proposes Geometry-inspired Chemical-invariant and Tissue Invariant Stain Normalization method, namely GCTI-SN, for microscopic medical images. The proposed GCTISN method corrects for illumination variation, stain chemical, and stain quantity variation in a unified framework by exploiting the underlying color vector space's geometry. While existing stain normalization methods have demonstrated their results on a single tissue and stain type, GCTI-SN is benchmarked on three cancer datasets of three cell/tissue types prepared with two different stain chemicals. GCTI-SN method is also benchmarked against the existing methods via quantitative and qualitative results, validating its robustness for stain chemical and cell/tissue type. Further, the utility and the efficacy of the proposed GCTI-SN stain normalization method is demonstrated diagnostically in the application of breast cancer detection via a CNN-based classifier. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101788	10.1016/j.media.2020.101788													
J								Integrating uncertainty in deep neural networks for MRI based stroke analysis	MEDICAL IMAGE ANALYSIS										Bayesian convolutional neural networks; Uncertainty; Magnetic resonance imaging; Ischemic stroke	SEGMENTATION	At present, the majority of the proposed Deep Learning (DL) methods provide point predictions without quantifying the model's uncertainty. However, a quantification of the reliability of automated image analysis is essential, in particular in medicine when physicians rely on the results for making critical treatment decisions. In this work, we provide an entire framework to diagnose ischemic stroke patients incorporating Bayesian uncertainty into the analysis procedure. We present a Bayesian Convolutional Neural Network (CNN) yielding a probability for a stroke lesion on 2D Magnetic Resonance (MR) images with corresponding uncertainty information about the reliability of the prediction. For patient-level diagnoses, different aggregation methods are proposed and evaluated, which combine the individual image-level predictions. Those methods take advantage of the uncertainty in the image predictions and report model uncertainty at the patient-level. In a cohort of 511 patients, our Bayesian CNN achieved an accuracy of 95.33% at the image-level representing a significant improvement of 2% over a non-Bayesian counterpart. The best patient aggregation method yielded 95.89% of accuracy. Integrating uncertainty information about image predictions in aggregation models resulted in higher uncertainty measures to false patient classifications, which enabled to filter critical patient diagnoses that are supposed to be closer examined by a medical doctor. We therefore recommend using Bayesian approaches not only for improved image level prediction and uncertainty estimation but also for the detection of uncertain aggregations at the patient-level. (c) 2020 Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101790	10.1016/j.media.2020.101790													
J								A novel node-level structure emb e dding and alignment representation of structural networks for brain disease analysis	MEDICAL IMAGE ANALYSIS										Brain network; Structural embedding; Node vector alignment; Group-level analysis; Schizophrenia	FUNCTIONAL CONNECTIVITY; NEURAL-NETWORK; SCHIZOPHRENIA; IDENTIFICATION; REGIONS; PARCELLATION; ATTENTION; GYRUS	Brain networks based on various neuroimaging technologies, such as diffusion tensor image (DTI) and functional magnetic resonance imaging (fMRI), have been widely applied to brain disease analysis. Currently, there are several node-level structural measures (e.g., local clustering coefficients and node degrees) for representing and analyzing brain networks since they usually can reflect the topological structure of brain regions. However, these measures typically describe specific types of structural information, ignoring important network properties (i.e., small structural changes) that could further improve the performance of brain network analysis. To overcome this problem, in this paper, we first define a novel node level structure embedding and alignment (nSEA) representation to accurately characterize the node-level structural information of the brain network. Different from existing measures that characterize a specific type of structural properties with a single value, our proposed nSEA method can learn a vector representation for each node, thus contain richer structure information to capture small structural changes. Furthermore, we develop an nSEA representation based learning (nSEAL) framework for brain disease analysis. Specifically, we first perform structural embedding to calculate node vector representations for each brain network and then align vector representations of all brain networks into the common space for two group-level network analyses, including a statistical analysis and brain disease classifications. Experiment results on a real schizophrenia dataset demonstrate that our proposed method not only discover disease-related brain regions that could help to better understand the pathology of brain diseases, but also improve the classification performance of brain diseases, compared with state-of-the-art methods. (c) 2020 Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101755	10.1016/j.media.2020.101755													
J								Yottixel - An Image Search Engine for Large Archives of Histopathology Whole Slide Images	MEDICAL IMAGE ANALYSIS										Image Search; Digital Pathology; Deep Learning	RETRIEVAL	With the emergence of digital pathology, searching for similar images in large archives has gained considerable attention. Image retrieval can provide pathologists with unprecedented access to the evidence embodied in already diagnosed and treated cases from the past. This paper proposes a search engine specialized for digital pathology, called Yottixel, a portmanteau for "one yotta pixel ," alluding to the big-data nature of histopathology images. The most impressive characteristic of Yottixel is its ability to represent whole slide images (WSIs) in a compact manner. Yottixel can perform millions of searches in real-time with a high search accuracy and low storage profile. Yottixel uses an intelligent indexing algorithm capable of representing WSIs with a mosaic of patches which are then converted into barcodes, called "Bunch of Barcodes" (BoB), the most prominent performance enabler of Yottixel. The performance of the prototype platform is qualitatively tested using 300 WSIs from the University of Pittsburgh Medical Center (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA) provided by the National Cancer Institute. Both datasets amount to more than 4,0 0 0,0 0 0 patches of 10 0 0 x 10 0 0 pixels. We report three sets of experiments that show that Yottixel can accurately retrieve organs and malignancies, and its semantic ordering shows good agreement with the subjective evaluation of human observers. (c) 2020 The Author(s). Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101757	10.1016/j.media.2020.101757													
J								Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis	MEDICAL IMAGE ANALYSIS										Label noise; Deep learning; Machine learning; Big data; Medical image annotation	DECISION TREES; LUNG-CANCER; CLASSIFICATION; PERFORMANCE; ALGORITHM; MICROARRAYS; VALIDATION; TRUTH	Supervised training of deep learning models requires large labeled datasets. There is a growing interest in obtaining such datasets for medical image analysis applications. However, the impact of label noise has not received sufficient attention. Recent studies have shown that label noise can significantly impact the performance of deep learning models in many machine learning and computer vision applications. This is especially concerning for medical applications, where datasets are typically small, labeling requires domain expertise and suffers from high interand intra-observer variability, and erroneous predictions may influence decisions that directly impact human health. In this paper, we first review the state-of-theart in handling label noise in deep learning. Then, we review studies that have dealt with label noise in deep learning for medical image analysis. Our review shows that recent progress on handling label noise in deep learning has gone largely unnoticed by the medical image analysis community. To help achieve a better understanding of the extent of the problem and its potential remedies, we conducted experiments with three medical imaging datasets with different types of label noise, where we investigated several existing strategies and developed new methods to combat the negative effect of label noise. Based on the results of these experiments and our review of the literature, we have made recommendations on methods that can be used to alleviate the effects of different types of label noise on deep models trained for medical image analysis. We hope that this article helps the medical image analysis researchers and developers in choosing and devising new techniques that effectively handle label noise in deep learning. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101759	10.1016/j.media.2020.101759													
J								NuClick: A deep learning framework for interactive segmentation of microscopic images	MEDICAL IMAGE ANALYSIS										Annotation; Interactive segmentation; Nuclear segmentation; Cell segmentation; Gland segmentation; Computational pathology; Deep learning	VIDEO SEGMENTATION	Object segmentation is an important step in the workflow of computational pathology. Deep learning based models generally require large amount of labeled data for precise and reliable prediction. However, collecting labeled data is expensive because it often requires expert knowledge, particularly in medical imaging domain where labels are the result of a time-consuming analysis made by one or more human experts. As nuclei, cells and glands are fundamental objects for downstream analysis in computational pathology/cytology, in this paper we propose NuClick, a CNN-based approach to speed up collecting annotations for these objects requiring minimum interaction from the annotator. We show that for nuclei and cells in histology and cytology images, one click inside each object is enough for NuClick to yield a precise annotation. For multicellular structures such as glands, we propose a novel approach to provide the NuClick with a squiggle as a guiding signal, enabling it to segment the glandular boundaries. These supervisory signals are fed to the network as auxiliary inputs along with RGB channels. With detailed experiments, we show that NuClick is applicable to a wide range of object scales, robust against variations in the user input, adaptable to new domains, and delivers reliable annotations. An instance segmentation model trained on masks generated by NuClick achieved the first rank in LYON19 challenge. As exemplar outputs of our framework, we are releasing two datasets: 1) a dataset of lymphocyte annotations within IHC images, and 2) a dataset of segmented WBCs in blood smear images. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101771	10.1016/j.media.2020.101771													
J								R-fMRI reconstruction from k-t undersampled data using a subject-invariant dictionary model and VB-EM with nested minorization	MEDICAL IMAGE ANALYSIS										R-fMRI; Undersample; Reconstruction; Variational Bayesian factorization; Expectation maximization; Nested minorization; Dictionary prior; Robust; Subject-invariant; Sparse; Spatial regularization	LOW-RANK; UNCERTAINTY QUANTIFICATION; FUNCTIONAL CONNECTIVITY; MRI; ACQUISITION; ACCELERATION; RESOLUTION; ALGORITHM; SPARSITY; TIME	Higher spatial resolution in resting-state functional magnetic resonance imaging (R-fMRI) can give reliable information about the functional networks in the cerebral cortex. Typical methods can achieve higher spatial or temporal resolution by speeding up scans using either (i) complex pulse-sequence designs or (ii) k-space undersampling coupled with priors on the signal. We propose to undersample the R-fMRI acquisition in k-space and time to speedup scans in order to improve spatial resolution. We propose a novel model-based R-fMRI reconstruction framework using a robust, subject-invariant, spatially regularized dictionary prior on the signal. Furthermore, we propose a novel inference framework based on variational Bayesian expectation maximization with nested minorization (VB-EM-NM). Our inference framework allows us to provide an estimate of uncertainty of the reconstruction, unlike typical reconstruction methods. Empirical evaluation of (i) simulated R-fMRI reconstruction and (ii) functional-network estimates from brain R-fMRI reconstructions demonstrate that our framework improves over the state of the art, and, additionally, enables significantly higher spatial resolution. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101752	10.1016/j.media.2020.101752													
J								Multi-site fMRI analysis using privacy-preserving fe derate d learning and domain adaptation: ABIDE results	MEDICAL IMAGE ANALYSIS										Federated learning; Domain adaptation; Data sharing; Privacy; Rs-fmri; ABIDE	BIG DATA; AUTISM; POLICY; NOISE	Deep learning models have shown their advantage in many different tasks, including neuroimage analysis. However, to effectively train a high-quality deep learning model, the aggregation of a significant amount of patient information is required. The time and cost for acquisition and annotation in assembling, for example, large fMRI datasets make it difficult to acquire large numbers at a single site. However, due to the need to protect the privacy of patient data, it is hard to assemble a central database from multiple institutions. Federated learning allows for population-level models to be trained without centralizing entities' data by transmitting the global model to local entities, training the model locally, and then averaging the gradients or weights in the global model. However, some studies suggest that private information can be recovered from the model gradients or weights. In this work, we address the problem of multi-site fMRI classification with a privacy-preserving strategy. To solve the problem, we propose a federated learning approach, where a decentralized iterative optimization algorithm is implemented and shared local model weights are altered by a randomization mechanism. Considering the systemic differences of fMRI distributions from different sites, we further propose two domain adaptation methods in this federated learning formulation. We investigate various practical aspects of federated model optimization and compare federated learning with alternative training strategies. Overall, our results demonstrate that it is promising to utilize multi-site data without data sharing to boost neuroimage analysis performance and find reliable disease-related biomarkers. Our proposed pipeline can be generalized to other privacy-sensitive medical data analysis problems. Our code is publicly available at: https://github.com/xxlya/Fed _ ABIDE/ . (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license. (http://creativecommons.org/licenses/by-nc-nd/4.0/ )																	1361-8415	1361-8423				OCT	2020	65								101765	10.1016/j.media.2020.101765													
J								Cascaded one-shot deformable convolutional neural networks: Developing a deep learning model for respiratory motion estimation in ultrasound sequences	MEDICAL IMAGE ANALYSIS										Ultrasound sequence; Respiratory motion estimation; Cascaded Siamese network; One-shot deformable convolution	TIME TUMOR-TRACKING; LIVER	Improving the quality of image-guided radiation therapy requires the tracking of respiratory motion in ultrasound sequences. However, the low signal-to-noise ratio and the artifacts in ultrasound images make it difficult to track targets accurately and robustly. In this study, we propose a novel deep learning model, called a Cascaded One-shot Deformable Convolutional Neural Network (COSD-CNN), to track landmarks in real time in long ultrasound sequences. Specifically, we design a cascaded Siamese network structure to improve the tracking performance of CNN-based methods. We propose a one-shot deformable convolution module to enhance the robustness of the COSD-CNN to appearance variation in a meta-learning manner. Moreover, we design a simple and efficient unsupervised strategy to facilitate the network's training with a limited number of medical images, in which many corner points are selected from raw ultrasound images to learn network features with high generalizability. The proposed COSD-CNN has been extensively evaluated on the public Challenge on Liver UltraSound Tracking (CLUST) 2D dataset and on our own ultrasound image dataset from the First Affiliated Hospital of Sun Yat-sen University (FSYSU). Experiment results show that the proposed model can track a target through an ultrasound sequence with high accuracy and robustness. Our method achieves new state-of-the-art performance on the CLUST 2D benchmark set, indicating its strong potential for application in clinical practice. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license. ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )																	1361-8415	1361-8423				OCT	2020	65								101793	10.1016/j.media.2020.101793													
J								Attention convolutional neural network for accurate segmentation and quantification of lesions in ischemic stroke disease	MEDICAL IMAGE ANALYSIS										Stroke; White matter hyperintensity; U-net; Attention module	WHITE-MATTER HYPERINTENSITY; AUTOMATED SEGMENTATION; DEEP NETWORK; CLASSIFICATION; ALGORITHM	Ischemic stroke lesion and white matter hyperintensity (WMH) lesion appear as regions of abnormally signal intensity on magnetic resonance image (MRI) sequences. Ischemic stroke is a frequent cause of death and disability, while WMH is a risk factor for stroke. Accurate segmentation and quantification of ischemic stroke and WMH lesions are important for diagnosis and prognosis. However, radiologists have a difficult time distinguishing these two types of similar lesions. A novel deep residual attention convolutional neural network (DRANet) is proposed to accurately and simultaneously segment and quantify ischemic stroke and WMH lesions in the MRI images. DRANet inherits the advantages of the U-net design and applies a novel attention module that extracts high-quality features from the input images. Moreover, the Dice loss function is used to train DRANet to address data imbalance in the training data set. DRANet is trained and evaluated on 742 2D MRI images which are produced from the sub-acute ischemic stroke lesion segmentation (SISS) challenge. Empirical tests demonstrate that DRANet outperforms several other state-of-the-art segmentation methods. It accurately segments and quantifies both ischemic stroke lesion and WMH. Ablation experiments reveal that attention modules improve the predictive performance of DRANet. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101791	10.1016/j.media.2020.101791													
J								Brain graph super-resolution for boosting neurological disorder diagnosis using unsupervised multi-topology connectional brain template learning	MEDICAL IMAGE ANALYSIS										Graph super-resolution; Brain connectomes; Connectional brain template learning; Topology-based residual graph manifold learning; Neurological disorder diagnosis; Brain graph fusion	AUTISM SPECTRUM DISORDER; GENE SELECTION; NETWORK; RECONSTRUCTION; PARCELLATION; ASSOCIATION; FRAMEWORK; IMAGES; MEMORY	Existing graph analysis techniques generally focus on decreasing the dimensionality of graph data (i.e., removing nodes, edges, or both) in diverse predictive learning tasks in pattern recognition, computer vision, and medical data analysis such as dimensionality reduction, filtering and embedding techniques. However, graph super-resolution is strikingly lacking, i.e., the concept of super-resolving low-resolution (LR) graphs with n r nodes into high-resolution graphs (HR) with n(r') > n(r) nodes. Particularly, learning how to automatically generate HR brain connectomes, without resorting to the computationally expensive MRI processing steps such as image registration and parcellation, remains unexplored. To fill this gap, we propose the first technique to super-resolve undirected fully connected graphs with application to brain connectomes. First, we root our brain graph super-resolution (BGSR) framework in learning how to estimate a centered LR population-based brain graph representation, coined as connectional brain template (CBT), acting as a proxy in the target BGSR task. Specifically, we hypothesize that the estimation of a wellrepresentative and centered CBT would help better capture the individuality of each LR brain graph via its residual distance from the population-based CBT. This will eventually allow an accurate identification of the most similar individual graphs to a new testing graph in the LR domain for the target prediction task. Second, we leverage the estimated LR CBT (i.e., population mean) to derive residual LR brain graphs, capturing the deviation of all subjects from the estimated CBT. Third, we learn multi-topology LR graph manifolds using different graph topological measurements (e.g., degree, closeness, betweenness) by estimating residual LR similarity matrices modeling the relationship between pairs of residual LR graphs. These are then fused so we can effectively identify for each testing LR subject its most K similar training LR graphs. Last, the missing testing HR graph is predicted by averaging the HR graphs of the K selected training subjects. Predicted HR from LR functional brain graphs boosted classification results for autistic subjects by 16.48% compared with LR functional graphs. (C) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101768	10.1016/j.media.2020.101768													
J								Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning	MEDICAL IMAGE ANALYSIS										COVID-19; X-ray imaging; Deep learning; Transfer learning		The COVID-19 pandemic is causing a major outbreak in more than 150 countries around the world, having a severe impact on the health and life of many people globally. One of the crucial step in fighting COVID-19 is the ability to detect the infected patients early enough, and put them under special care. Detecting this disease from radiography and radiology images is perhaps one of the fastest ways to diagnose the patients. Some of the early studies showed specific abnormalities in the chest radiograms of patients infected with COVID-19. Inspired by earlier works, we study the application of deep learning models to detect COVID-19 patients from their chest radiography images. We first prepare a dataset of 50 0 0 Chest X-rays from the publicly available datasets. Images exhibiting COVID-19 disease presence were identified by board-certified radiologist. Transfer learning on a subset of 20 0 0 radiograms was used to train four popular convolutional neural networks, including ResNet18, ResNet50, SqueezeNet, and DenseNet-121, to identify COVID-19 disease in the analyzed chest X-ray images. We evaluated these models on the remaining 30 0 0 images, and most of these networks achieved a sensitivity rate of 98% ( +/- 3%), while having a specificity rate of around 90%. Besides sensitivity and specificity rates, we also present the receiver operating characteristic (ROC) curve, precision-recall curve, average prediction, and confusion matrix of each model. We also used a technique to generate heatmaps of lung regions potentially infected by COVID-19 and show that the generated heatmaps contain most of the infected areas annotated by our board certified radiologist. While the achieved performance is very encouraging, further analysis is required on a larger set of COVID-19 images, to have a more reliable estimation of accuracy rates. The dataset, model implementations (in PyTorch), and evaluations, are all made publicly available for research community at https://github.com/shervinmin/DeepCovid.git (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101794	10.1016/j.media.2020.101794													
J								Automatic estimation of aortic and mitral valve displacements in dynamic CTA with 4D graph-cuts	MEDICAL IMAGE ANALYSIS										Graph-cut; Computed tomographic angiography; Annulus segmentation; Mitral valve displacement; Aortic valve displacement	CARDIAC CT; ENERGY MINIMIZATION; COMPUTED-TOMOGRAPHY; LEFT-VENTRICLE; SEGMENTATION; HEART; MODEL; QUANTIFICATION; ECHOCARDIOGRAPHY; REGISTRATION	The location of the mitral and aortic valves in dynamic cardiac imaging is useful for extracting functional derived parameters such as ejection fraction, valve excursions, and global longitudinal strain, and when performing anatomical structures tracking using slice following or valve intervention's planning. Completely automatic segmentation methods are still challenging tasks because of their fast movements and the different positions that prevent good visibility of the leaflets along the full cardiac cycle. In this article, we propose a processing pipeline to track the displacement of the aortic and mitral valve annuli from high-resolution cardiac four-dimensional computed tomographic angiography (4D-CTA). The proposed method is based on the dynamic separation of left ventricle, left atrium and aorta using statistical shape modeling and an energy minimization algorithm based on graph-cuts and has been evaluated on a set of 15 electrocardiography-gated 4D-CTAs. We report a mean agreement distance between manual annotations and our proposed method of 2.52 +/- 1.06 mm for the mitral annulus and 2.00 +/- 0.69 mm for the aortic valve annulus based on valve locations detected from manual anatomical landmarks. In addition, we show the effect of detecting the valvular planes on derived functional parameters (ejection fraction, global longitudinal strain, and excursions of the mitral and aortic valves). (c) 2020 The Authors. Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101748	10.1016/j.media.2020.101748													
J								Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks	MEDICAL IMAGE ANALYSIS										Bone metastasis; Deep neural networks; Multi-view; Whole body bone scan	COMPUTER-AIDED DIAGNOSIS; SCINTIGRAPHY; MAMMOGRAMS; SYSTEM; MRI	Bone scintigraphy is accepted as an effective diagnostic tool for whole-body examination of bone metastasis. However, the manual analysis of bone scintigraphy images requires extensive experience and is exhausting and time-consuming. An automated diagnosis system for such images is therefore much desired. Although automatic or semi-automatic methods for the diagnosis of bone scintigraphy images have been widely studied, they employ various steps to classify the images, including segmentation of the entire skeleton, detection of hot spots, and feature extraction, which are complex and inadequately validated on small datasets, thereby resulting in low accuracy and reliability. In this paper, we describe the development of a deep convolutional neural network to determine the absence or presence of bone metastasis. This model consisting of three sub-networks that aim to extract, aggregate, and classify high-level features in a data-driven manner. There are two main innovations behind this method; First, the diagnosis is performed by jointly analyzing both anterior and posterior views, which leads to high accuracy. Second, a spatial attention feature aggregation operator is proposed to enhance the spatial location information. A large annotated bone scintigraphy image dataset containing 15,474 examinations from 13,811 patients was constructed to train and evaluate the model. The proposed method is compared with three human experts. The high classification accuracy achieved demonstrates the effectiveness of the proposed architecture for the diagnosis of bone scintigraphy images, and that it can be applied as a clinical decision support tool. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101784	10.1016/j.media.2020.101784													
J								Multi-task multi-modal learning for joint diagnosis and prognosis of human cancers	MEDICAL IMAGE ANALYSIS										Multi-task multi-Modal learning; Cancer prognosis; Cancer diagnosis; Image genomics	PROSTATE-CANCER; GENOMIC DATA; LUNG-CANCER; IMAGES; IDENTIFICATION; STRATIFICATION; EXPRESSION; CARCINOMA; FEATURES	With the tremendous development of artificial intelligence, many machine learning algorithms have been applied to the diagnosis of human cancers. Recently, rather than predicting categorical variables (e.g., stages and subtypes) as in cancer diagnosis, several prognosis prediction models basing on patients' survival information have been adopted to estimate the clinical outcome of cancer patients. However, most existing studies treat the diagnosis and prognosis tasks separately. In fact, the diagnosis information (e.g., TNM Stages) indicates the extent of the disease severity that is highly correlated with the patients' survival. While the diagnosis is largely made based on histopathological images, recent studies have also demonstrated that integrative analysis of histopathological images and genomic data can hold great promise for improving the diagnosis and prognosis of cancers. However, direct combination of these two types of data may bring redundant features that will negatively affect the prediction performance. Therefore, it is necessary to select informative features from the derived multi-modal data. Based on the above considerations, we propose a multi-task multi-modal feature selection method for joint diagnosis and prognosis of cancers. Specifically, we make use of the task relationship learning framework to automatically discover the relationships between the diagnosis and prognosis tasks, through which we can identify important image and genomics features for both tasks. In addition, we add a regularization term to ensure that the correlation within the multi-modal data can be captured. We evaluate our method on three cancer datasets from The Cancer Genome Atlas project, and the experimental results verify that our method can achieve better performance on both diagnosis and prognosis tasks than the related methods. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101795	10.1016/j.media.2020.101795													
J								Subsampled brain MRI reconstruction by generative adversarial neural networks	MEDICAL IMAGE ANALYSIS										MRI reconstruction; K-space subsampling; Deep learning; GANs	SEGMENTATION; ENSEMBLE; SENSE	A main challenge in magnetic resonance imaging (MRI) is speeding up scan time. Beyond improving patient experience and reducing operational costs, faster scans are essential for time-sensitive imaging, such as fetal, cardiac, or functional MRI, where temporal resolution is important and target movement is unavoidable, yet must be reduced. Current MRI acquisition methods speed up scan time at the expense of lower spatial resolution and costlier hardware. We introduce a practical, software-only framework, based on deep learning, for accelerating MRI acquisition, while maintaining anatomically meaningful imaging. This is accomplished by MRI subsampling followed by estimating the missing k-space samples via generative adversarial neural networks. A generator-discriminator interplay enables the introduction of an adversarial cost in addition to fidelity and image-quality losses used for optimizing the reconstruction. Promising reconstruction results are obtained from feasible sampling patterns of up to a fivefold acceleration of diverse brain MRIs, from a large publicly available dataset of healthy adult scans as well as multimodal acquisitions of multiple sclerosis patients and dynamic contrast-enhanced MRI (DCE-MRI) sequences of stroke and tumor patients. Clinical usability of the reconstructed MRI scans is assessed by performing either lesion or healthy tissue segmentation and comparing the results to those obtained by using the original, fully sampled images. Reconstruction quality and usability of the DCE-MRI sequences is demonstrated by calculating the pharmacokinetic (PK) parameters. The proposed MRI reconstruction approach is shown to outperform state-of-the-art methods for all datasets tested in terms of the peak signal-to-noise ratio (PSNR), the structural similarity index (SSIM), as well as either the mean squared error (MSE) with respect to the PK parameters, calculated for the fully sampled DCE-MRI sequences, or the segmentation compatibility, measured in terms of Dice scores and Hausdorff distance. The code is available on GitHub. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101747	10.1016/j.media.2020.101747													
J								Automated characterization of noise distributions in diffusion MRI data	MEDICAL IMAGE ANALYSIS										Diffusion MRI; Noise estimation; Parallel acceleration; Gamma distribution; GRAPPA; SENSE	WHOLE-BRAIN; K-SPACE; RESOLUTION; RECONSTRUCTION; HARMONIZATION; SENSITIVITY; COMBINATION; EPI	Knowledge of the noise distribution in magnitude diffusion MRI images is the centerpiece to quantify uncertainties arising from the acquisition process. The use of parallel imaging methods, the number of receiver coils and imaging filters applied by the scanner, amongst other factors, dictate the resulting signal distribution. Accurate estimation beyond textbook Rician or noncentral chi distributions often requires information about the acquisition process (e.g., coils sensitivity maps or reconstruction coefficients), which is usually not available. We introduce two new automated methods using the moments and maximum likelihood equations of the Gamma distribution to estimate noise distributions as they explicitly depend on the number of coils, making it possible to estimate all unknown parameters using only the magnitude data. A rejection step is used to make the framework automatic and robust to artifacts. Simulations using stationary and spatially varying noncentral chi noise distributions were created for two diffusion weightings with SENSE or GRAPPA reconstruction and 8, 12 or 32 receiver coils. Furthermore, MRI data of a water phantom with different combinations of parallel imaging were acquired on a 3T Philips scanner along with noise-only measurements. Finally, experiments on freely available datasets from a single subject acquired on a 3T GE scanner are used to assess reproducibility when limited information about the acquisition protocol is available. Additionally, we demonstrated the applicability of the proposed methods for a bias correction and denoising task on an in vivo dataset acquired on a 3T Siemens scanner. A generalized version of the bias correction framework for non integer degrees of freedom is also introduced. The proposed framework is compared with three other algorithms with datasets from three vendors, employing different reconstruction methods. Simulations showed that assuming a Rician distribution can lead to misestimation of the noise distribution in parallel imaging. Results on the acquired datasets showed that signal leakage in multiband can also lead to a misestimation of the noise distribution. Repeated acquisitions of in vivo datasets show that the estimated parameters are stable and have lower variability than compared methods. Results for the bias correction and denoising task show that the proposed methods reduce the appearance of noise at high b-value. The proposed algorithms herein can estimate both parameters of the noise distribution automatically, are robust to signal leakage artifacts and perform best when used on acquired noise maps. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license. ( http://creativecommons.org/licenses/by/4.0/ )																	1361-8415	1361-8423				OCT	2020	65								101758	10.1016/j.media.2020.101758													
J								Holistic multitask regression network for multiapplication shape regression segmentation	MEDICAL IMAGE ANALYSIS										Multiapplication; Shape regression segmentation; Multitask learning; Deep learning; Manifold regularization; Cross-stitch units	NECK CT IMAGES; SEMANTIC SEGMENTATION; AUTO-SEGMENTATION; SPINE; HEAD; RECOGNITION	A holistic multitask regression approach was implemented to tackle the limitations of clinical image analysis. Standard practice requires identifying multiple anatomic structures in multiple planes from multiple anatomic regions using multiple modalities. The proposed novel holistic multitask regression network (HMR-Net) formulates organ segmentation as a multitask learning problem. Multitask learning leverages the strength of joint task problem solving from capturing task correlations. HMR-Net performs multitask regression by estimating an organ's class, regional location, and precise contour coordinates. The estimation of each coordinate point also corresponds to another regression task. HMR-Net leverages hierarchical multiscale and fused organ features to handle nonlinear relationships between image appearance and distinct organ properties. Simultaneously, holistic shape information is captured by encoding coordinate correlations. The multitask pipeline enables the capturing of holistic organ information (e.g. class, location, shape) to perform shape regression for medical image segmentation. HMR-Net was validated on eight representative datasets obtained from a total of 222 subjects. A mean average precision and dice score reaching up to 0.81 and 0.93, respectively, was achieved on the representative multiapplication database. The generalized model demonstrates comparable or superior performance compared to state of-the-art algorithms. The high-performance accuracy demonstrates our model as an effective general framework to perform organ shape regression in multiple applications. This method was proven to provide high-contrast sensitivity to delineate even the smallest and oddly shaped organs. HMR-Net's flexible framework holds great potential in providing a fully automatic preliminary analysis for multiple types of medical images. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101783	10.1016/j.media.2020.101783													
J								Automatic ischemic stroke lesion segmentation from computed tomography perfusion images by image synthesis and attention-based deep neural networks	MEDICAL IMAGE ANALYSIS										Ischemic stroke lesion; Computed tomography perfusion; Image synthesis; Segmentation; Deep learning	SIMULATION; CNN; CT	Ischemic stroke lesion segmentation from Computed Tomography Perfusion (CTP) images is important for accurate diagnosis of stroke in acute care units. However, it is challenged by low image contrast and resolution of the perfusion parameter maps, in addition to the complex appearance of the lesion. To deal with this problem, we propose a novel framework based on synthesized pseudo Diffusion-Weighted Imaging (DWI) from perfusion parameter maps to obtain better image quality for more accurate segmentation. Our framework consists of three components based on Convolutional Neural Networks (CNNs) and is trained end-to-end. First, a feature extractor is used to obtain both a low-level and high-level compact representation of the raw spatiotemporal Computed Tomography Angiography (CTA) images. Second, a pseudo DWI generator takes as input the concatenation of CTP perfusion parameter maps and our extracted features to obtain the synthesized pseudo DWI. To achieve better synthesis quality, we propose a hybrid loss function that pays more attention to lesion regions and encourages high-level contextual consistency. Finally, we segment the lesion region from the synthesized pseudo DWI, where the segmentation network is based on switchable normalization and channel calibration for better performance. Experimental results showed that our framework achieved the top performance on ISLES 2018 challenge and: (1) our method using synthesized pseudo DWI outperformed methods segmenting the lesion from perfusion parameter maps directly; (2) the feature extractor exploiting additional spatiotemporal CTA images led to better synthesized pseudo DWI quality and higher segmentation accuracy; and (3) the proposed loss functions and network structure improved the pseudo DWI synthesis and lesion segmentation performance. The proposed framework has a potential for improving diagnosis and treatment of the ischemic stroke where access to real DWI scanning is limited. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101787	10.1016/j.media.2020.101787													
J								SLIR: Synthesis, localization, inpainting, and registration for image-guided thermal ablation of liver tumors	MEDICAL IMAGE ANALYSIS										Image registration; Image-guided intervention; Liver tumor thermal ablation; Deep learning	DEFORMABLE REGISTRATION; RADIOFREQUENCY ABLATION; SEGMENTATION; SURGERY; MODEL	Thermal ablation is a minimally invasive procedure for treating small or unresectable tumors. Although CT is widely used for guiding ablation procedures, yet the contrast of tumors against normal soft tissues is often poor in CT scans, aggravating the accurate thermal ablation. In this paper, we propose a fast MR-CT image registration method to overlay pre-procedural MR (pMR) and pre-procedural CT (pCT) images onto an intra-procedural CT (iCT) image to guide the thermal ablation of liver tumors. At the pre-procedural stage, the Cycle-GAN model with mutual information constraint is employed to generate the synthesized CT (sCT) image from the input pMR. Then, pMR-pCT image registration is carried out via traditional mono-modal sCT-pCT image registration. At the intra-procedural stage, the region of the probe and its artifacts are automatically localized and inpainted in the iCT image. Then, an unsupervised registration network (UR-Net) is used to efficiently align the pCT with the inpainted iCT (inpCT) image. The final transform from pMR to iCT is obtained by concatenating the two estimated transforms, i.e., (i) from pMR image space to pCT image space (via sCT) and (ii) from pCT image space to iCT image space (via inpCT). The proposed method has been evaluated over a real clinical dataset and compared with state of-the-art methods. Experimental results confirm that the proposed method achieves high registration accuracy with fast computation speed. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101763	10.1016/j.media.2020.101763													
J								Uncertainty-aware multi-view co-training for semi-supervise d me dical image segmentation and domain adaptation	MEDICAL IMAGE ANALYSIS										Segmentation; Semi-supervised learning; Uncertainty estimation; Domain adaptation	FRAMEWORK	Although having achieved great success in medical image segmentation, deep learning-based approaches usually require large amounts of well-annotated data, which can be extremely expensive in the field of medical image analysis. Unlabeled data, on the other hand, is much easier to acquire. Semi-supervised learning and unsupervised domain adaptation both take the advantage of unlabeled data, and they are closely related to each other. In this paper, we propose uncertainty-aware multi-view co-training (UMCT), a unified framework that addresses these two tasks for volumetric medical image segmentation. Our framework is capable of efficiently utilizing unlabeled data for better performance. We firstly rotate and permute the 3D volumes into multiple views and train a 3D deep network on each view. We then apply co-training by enforcing multi-view consistency on unlabeled data, where an uncertainty estimation of each view is utilized to achieve accurate labeling. Experiments on the NIH pancreas segmentation dataset and a multi-organ segmentation dataset show state-of-the-art performance of the proposed framework on semi-supervised medical image segmentation. Under unsupervised domain adaptation settings, we validate the effectiveness of this work by adapting our multi-organ segmentation model to two pathological organs from the Medical Segmentation Decathlon Datasets. Additionally, we show that our UMCT-DA model can even effectively handle the challenging situation where labeled source data is inaccessible, demonstrating strong potentials for real-world applications. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101766	10.1016/j.media.2020.101766													
J								MSCS-DeepLN: Evaluating lung nodule malignancy using multi-scale cost-sensitive neural networks	MEDICAL IMAGE ANALYSIS										Category imbalance; Small datasets; Neural networks; Lung cancer	TEXTURE	The accurate identification of malignant lung nodules using computed tomography (CT) screening images is vital for the early detection of lung cancer. It also offers patients the best chance of cure, because non-invasive CT imaging has the ability to capture intra-tumoral heterogeneity. Deep learning methods have obtained promising results for the malignancy identification problem; however, two substantial challenges still remain. First, small datasets cannot insufficiently train the model and tend to overfit it. Second, category imbalance in the data is a problem. In this paper, we propose a method called MSCSDeepLN that evaluates lung nodule malignancy and simultaneously solves these two problems. Three light models are trained and combined to evaluate the malignancy of a lung nodule. Three-dimensional convolutional neural networks (CNNs) are employed as the backbone of each light model to extract the lung nodule features from CT images and preserve lung nodule spatial heterogeneity. Multi-scale input cropped from CT images enables the sub-networks to learn the multi-level contextual features and preserve diverse. To tackle the imbalance problem, our proposed method employs an AUC approximation as the penalty term. During training, the error in this penalty term is generated from each major and minor class pair, so that negatives and positives can contribute equally to updating this model. Based on these methods, we obtain state-of-the-art results on the LIDC-IDRI dataset. Furthermore, we constructed a new dataset collected from a grade-A tertiary hospital and annotated using biopsy-based cytological analysis to verify the performance of our method in clinical practice. (c) 2020 Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101772	10.1016/j.media.2020.101772													
J								Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks	MEDICAL IMAGE ANALYSIS										Survival prediction; Multiple instance learning; Deep learning; Whole slide images	CLASSIFICATION; ALGORITHM	Traditional image-based survival prediction models rely on discriminative patch labeling which make those methods not scalable to extend to large datasets. Recent studies have shown Multiple Instance Learning (MIL) framework is useful for histopathological images when no annotations are available in classification task. Different to the current image-based survival models that limit to key patches or clusters derived from Whole Slide Images (WSIs), we propose Deep Attention Multiple Instance Survival Learning (DeepAttnMISL) by introducing both siamese MI-FCN and attention-based MIL pooling to efficiently learn imaging features from the WSI and then aggregate WSI-level information to patient-level. Attention-based aggregation is more flexible and adaptive than aggregation techniques in recent survival models. We evaluated our methods on two large cancer whole slide images datasets and our results suggest that the proposed approach is more effective and suitable for large datasets and has better interpretability in locating important patterns and features that contribute to accurate cancer survival predictions. The proposed framework can also be used to assess individual patient's risk and thus assisting in delivering personalized medicine. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101789	10.1016/j.media.2020.101789													
J								Deep white matter analysis (DeepWMA): Fast and consistent tractography segmentation	MEDICAL IMAGE ANALYSIS											HUMAN CONNECTOME PROJECT; DIFFUSION MRI; BRAIN; RECONSTRUCTION	White matter tract segmentation, i.e. identifying tractography fibers (streamline trajectories) belonging to anatomically meaningful fiber tracts, is an essential step to enable tract quantification and visualization. In this study, we present a deep learning tractography segmentation method (DeepWMA) that allows fast and consistent identification of 54 major deep white matter fiber tracts from the whole brain. We create a large-scale training tractography dataset of 1 million labeled fiber samples, and we propose a novel 2D multi-channel feature descriptor (FiberMap) that encodes spatial coordinates of points along each fiber. We learn a convolutional neural network (CNN) fiber classification model based on FiberMap and obtain a high fiber classification accuracy of 90.99% on the training tractography data with ground truth fiber labels. Then, the method is evaluated on a test dataset of 597 diffusion MRI scans from six independently acquired populations across genders, the lifespan (1 day 82 years), and different health conditions (healthy control, neuropsychiatric disorders, and brain tumor patients). We perform comparisons with two state-of-the-art tract segmentation methods. Experimental results show that our method obtains a highly consistent tract segmentation result, where on average over 99% of the fiber tracts are successfully identified across all subjects under study, most importantly, including neonates and patients with space-occupying brain tumors. We also demonstrate good generalization of the method to tractography data from multiple different fiber tracking methods. The proposed method leverages deep learning techniques and provides a fast and efficient tool for brain white matter segmentation in large diffusion MRI tractography datasets. (C) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101761	10.1016/j.media.2020.101761													
J								Triple U-net: Hematoxylin-aware nuclei segmentation with progressive dense feature aggregation	MEDICAL IMAGE ANALYSIS										Digital pathology; Nuclei segmentation; Convolutional neural networks	BRAIN-TUMOR SEGMENTATION; MRI	Nuclei segmentation is a vital step for pathological cancer research. It is still an open problem due to some difficulties, such as color inconsistency introduced by non-uniform manual operations, blurry tumor nucleus boundaries and overlapping tumor cells. In this paper, we aim to leverage the unique optical characteristic of H&E staining images that hematoxylin always stains cell nuclei blue, and eosin always stains the extracellular matrix and cytoplasm pink. Therefore, we extract the Hematoxylin component from RGB images by Beer-Lambert's Law. According to the optical attribute, the extracted Hematoxylin component is robust to color inconsistency. With the Hematoxylin component, we propose a Hematoxylin-aware CNN model for nuclei segmentation without the necessity of color normalization. Our proposed network is formulated as a Triple U-net structure which includes an RGB branch, a Hematoxylin branch and a Segmentation branch. Then we propose a novel feature aggregation strategy to allow the network to fuse features progressively and to learn better feature representations from different branches. Extensive experiments are performed to qualitatively and quantitatively evaluate the effectiveness of our proposed method. In the meanwhile, it outperforms state-of-the-art methods on three different nuclei segmentation datasets. (c) 2020 Elsevier B.V. All rights reserved.																	1361-8415	1361-8423				OCT	2020	65								101786	10.1016/j.media.2020.101786													
J								Supervised learning with cyclegan for low-dose FDG PET image denoising	MEDICAL IMAGE ANALYSIS										PET; Low-dose; Generative adversarial networks; Cycle consistent	CONVOLUTIONAL NEURAL-NETWORK; F-18-FDG PET; BRAIN; MRI; SEGMENTATION; TOMOGRAPHY; CT	PET imaging involves radiotracer injections, raising concerns about the risk of radiation exposure. To minimize the potential risk, one way is to reduce the injected tracer. However, this will lead to poor image quality with conventional image reconstruction and processing. In this paper, we proposed a supervised deep learning model, CycleWGANs, to boost low-dose PET image quality. Validations were performed on a low dose dataset simulated from a real dataset with biopsy-proven primary lung cancer or suspicious radiological abnormalities. Low dose PET images were reconstructed on reduced PET raw data by randomly discarding events in the PET list mode data towards the count level of 1 million. Traditional image denoising methods (Non-Local Mean (NLM) and block-matching 3D(BM3D)) and two recently-published deep learning methods (RED-CNN and 3D-cGAN) were included for comparisons. At the count level of 1 million (true counts), the proposed model can accurately estimate full-dose PET image from low-dose input image, which is superior to the other four methods in terms of the mean and maximum standardized uptake value (SUVmean and SUVmax) bias for lesions and normal tissues. The bias of SUV (SUVmean, SUVmax) for lesions and normal tissues are (-2. 06 +/- 3 . 50% , -0. 84 +/- 6 . 94% ) and (-0. 45 +/- 5 . 59% , N/A) in the estimated PET images, respectively. However, the RED-CNN achieved the best score in traditional metrics, such as structure similarity (SSIM), peak signal to noise ratio (PSNR) and normalized root mean square error (NRMSE). Correlation and profile analyses have successfully explained this phenomenon and further suggested that our method could effectively preserve edge and also SUV values than RED-CNN, 3D-cGAN and NLM with a slightly higher noise. (C) 2020 Published by Elsevier B.V.																	1361-8415	1361-8423				OCT	2020	65								101770	10.1016/j.media.2020.101770													
J								A novel feature representation: Aggregating convolution kernels for image retrieval	NEURAL NETWORKS										Image representation; Feature aggregating; Distance measurement; Image retrieval		Activated hidden units in convolutional neural networks (CNNs), known as feature maps, dominate image representation, which is compact and discriminative. For ultra-large datasets, high dimensional feature maps in float format not only result in high computational complexity, but also occupy massive memory space. To this end, a new image representation by aggregating convolution kernels (ACK) is proposed, where some convolution kernels capturing certain patterns are activated. The top-n index numbers of the convolution kernels are extracted directly as image representation in discrete integer values, which rebuild relationship between convolution kernels and image. Furthermore, a distance measurement is defined from the perspective of ordered sets to calculate position-sensitive similarities between image representations. Extensive experiments conducted on Oxford Buildings, Paris, and Holidays, etc., manifest that the proposed ACK achieves competitive performance on image retrieval with much lower computational cost, outperforming the ones using feature maps for image representation. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						1	10		10.1016/j.neunet.2020.06.010													
J								Block-term tensor neural networks	NEURAL NETWORKS										Tensor networks; Network compression; Neural networks; Deep learning	MODELS	Deep neural networks (DNNs) have achieved outstanding performance in a wide range of applications, e.g., image classification, natural language processing, etc. Despite the good performance, the huge number of parameters in DNNs brings challenges to efficient training of DNNs and also their deployment in low-end devices with limited computing resources. In this paper, we explore the correlations in the weight matrices, and approximate the weight matrices with the low-rank block term tensors. We name the new corresponding structure as block-term tensor layers (BT-layers), which can be easily adapted to neural network models, such as CNNs and RNNs. In particular, the inputs and the outputs in BT-layers are reshaped into low-dimensional high-order tensors with a similar or improved representation power. Sufficient experiments have demonstrated that BT-layers in CNNs and RNNs can achieve a very large compression ratio on the number of parameters while preserving or improving the representation power of the original DNNs. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						11	21		10.1016/j.neunet.2020.05.034													
J								Heart sound classification based on improved MFCC features and convolutional recurrent neural networks	NEURAL NETWORKS										Heart sound classification; Convolutional neural network; Recurrent neural network; Improved MFCC features	SEGMENTATION	Heart sound classification plays a vital role in the early detection of cardiovascular disorders, especially for small primary health care clinics. Despite that much progress has been made for heart sound classification in recent years, most of them are based on conventional segmented features and shallow structure based classifiers. These conventional acoustic representation and classification methods may be insufficient in characterizing heart sound, and generally suffer from a degraded performance due to the complicated and changeable cardiac acoustic environment. In this paper, we propose a new heart sound classification method based on improved Mel-frequency cepstrum coefficient (MFCC) features and convolutional recurrent neural networks. The Mel-frequency cepstrums are firstly calculated without dividing the heart sound signal. A new improved feature extraction scheme based on MFCC is proposed to elaborate the dynamic characteristics among consecutive heart sound signals. Finally, the MFCC-based features are fed to a deep convolutional and recurrent neural network (CRNN) for feature learning and later classification task. The proposed deep learning framework can take advantage of the encoded local characteristics extracted from the convolutional neural network (CNN) and the long-term dependencies captured by the recurrent neural network (RNN). Comprehensive studies on the performance of different network parameters and different network connection strategies are presented in this paper. Performance comparisons with state-of-the-art algorithms are given for discussions. Experiments show that, for the two-class classification problem (pathological or non-pathological), a classification accuracy of 98% has been achieved on the 2016 PhysioNet/CinC Challenge database. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						22	32		10.1016/j.neunet.2020.06.015													
J								Stability of delayed inertial neural networks on time scales: A unified matrix-measure approach	NEURAL NETWORKS										Stability; Inertial neural network; Time scale; Unified matrix-measure; Time delay	SYNCHRONIZATION; DISSIPATIVITY	This note introduces a unified matrix-measure concept to study the stability of a class of inertial neural networks with bounded time delays on time scales. The novel matrix-measure concept unifies the classic matrix-measure and the generalized matrix-measure concept. One sufficient global exponential stability criterion is obtained based on this key matrix-measure and no Lyapunov function is required. To make the stability performance better, another stability criterion in which more detailed information is involved has been acquired. The theoretical results in this note contain and extend some existing continuous-time and discrete-time works. A numerical example is given to show the validity of the results. (C) 2020 The Authors. Published by Elsevier Ltd.																	0893-6080	1879-2782				OCT	2020	130						33	38		10.1016/j.neunet.2020.06.020													
J								Learning explicitly transferable representations for domain adaptation	NEURAL NETWORKS										Domain adaptation; Transfer learning; Transferable representation		Domain adaptation tackles the problem where the training source domain and the test target domain have distinctive data distributions, and therefore improves the generalization ability of deep models. The very popular mechanism of domain adaptation is to learn a new feature representation which is supposed to be domain-invariant, so that the classifiers trained on the source domain can be directly applied to the target domain. However, recent work reveals that learning new feature representations may potentially deteriorate the adaptability of the original features and increase the expected error bound of the target domain. To address this, we propose to adapt classifiers rather than features. Specifically, we fill in the distribution gaps between domains by some additional transferable representations which are explicitly learned from the original features while keeping the original features unchanged. In addition, we argue that transferable representations should be able to be translated from one domain to the other with appropriate mappings. At the same time, we introduce conditional entropy to mitigate the semantic confusion during mapping. Experiments on both standard and large-scale datasets verify that our method is able to achieve the new state-of-the-art results on unsupervised domain adaptation. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						39	48		10.1016/j.neunet.2020.06.016													
J								R-ELMNet: Regularized extreme learning machine network	NEURAL NETWORKS										Shallow network; PCANet; ELM auto-encoder; ELMNet; R-ELMNet	LOCAL RECEPTIVE-FIELDS	Principal component analysis network (PCANet), as an unsupervised shallow network, demonstrates noticeable effectiveness on datasets of various volumes. It carries a two-layer convolution with PCA as filter learning method, followed by a block-wise histogram post-processing stage. Following the structure of PCANet, extreme learning machine auto-encoder (ELM-AE) variants are employed to replace the PCA's role, which come from extreme learning machine network (ELMNet) and hierarchical ELMNet. ELMNet emphasizes the importance of orthogonal projection while overlooking non-linearity. The latter introduces complex pre-processing to overcome drawback of non-linear ELM-AE. In this paper, we analyze intrinsic characteristics of ELM-AE variants and accordingly propose a regularized ELM-AE, which combines non-linearity learning capability and approximately orthogonal projection. Experiments on image classification show the effectiveness compared to supervised convolutional neural networks and related shallow networks on unsupervised feature learning. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						49	59		10.1016/j.neunet.2020.06.009													
J								Controller design for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks with uncertain parameters and time-varying delays	NEURAL NETWORKS										Fractional-order; Complex-valued BAM neural networks(CVBAMNNs); Memristor; Uncertain parameters; Time-varying delays	STABILITY ANALYSIS; EXPONENTIAL STABILIZATION; SYNCHRONIZATION ANALYSIS; FEEDBACK	In this paper we investigate controller design problem for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks (FMCVBAMNNs) with uncertain parameters and time-varying delays. By using the Lyapunov theory, differential inclusion theory, and fractional calculus theory, finite-time stabilization condition for fractional-order memristive complex-valued BAM neural networks and the upper bound of the settling time for stabilization are obtained. The nonlinear complex-valued activation functions are split into two (real and imaginary) components. Moreover, the settling time of fixed time stabilization, that does not depend upon the initial values, is merely calculated. A novel criterion for guaranteeing the fixed-time stabilization of FMCVBAMNNs is derived. Our control scheme achieves system stabilization within bounded time and has an advantage in convergence rate. Numerical simulations are furnished to demonstrate the effectiveness of the theoretical analysis. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						60	74		10.1016/j.neunet.2020.06.021													
J								Dynamical system based compact deep hybrid network for classification of Parkinson disease related EEG signals	NEURAL NETWORKS										Convolutional neural network; Long short-term memory; Chaotic systems; Parkinson disease; Embedding reconstruction; Electroencephalogram	BRAIN	Electroencephalogram (EEG) signals accumulate the brain's spiking activities using standardized electrodes placed at the scalp. These cumulative brain signals are chaotic in nature and vary depending upon current physical and/or mental activities. The anatomy of the brain is altered when dopamine releasing neurons die because of Parkinson Disease (PD), a neurodegenerative disorder. The resulting alterations force synchronized neuronal activity in beta frequency components deep within motor region of the brain. This synchronization in the motor region affects the dynamical behavior of the brain activities, which induce motor related impairments in patient's limbs. Identification of reliable bio-markers for PD is active research area since there are no tests or scans to diagnose PD. We use embedding reconstruction, a tool from chaos theory, to highlight PD-related alterations in dynamical properties of EEG and present it as a potentially reliable bio-marker for PD related classification. We use Individual Component Analysis (ICA) to demonstrate that the strengthened synchronizations can be cumulatively collected from EEG channels over the motor region of the brain. We use this information to select the 12 EEG channels for classification of On and Off medication PD patients. Additionally, there is the strong synchronization between amplitude of higher frequency components and phase of beta components for PD patients. This information is used to improve the performance of this classification. We apply embedding reconstruction to design a new architecture of a deep neural network called Dynamical system Generated Hybrid Network. We report that this network outperforms the state of the art in terms of classification accuracy of 99.2% (+0.52%) with approximately 24% of the computational resources. Apart from classification accuracy, we use well known statistical measures like specificity, sensitivity, Matthews Correlation Coefficient (MCC), F1 score, and Cohen Kappa score for the analysis and comparison of classification performances. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						75	84		10.1016/j.neunet.2020.06.018													
J								Quantifying the generalization error in deep learning in terms of data distribution and neural network smoothness	NEURAL NETWORKS										Neural networks; Generalization error; Learnability; Data distribution; Cover complexity; Neural network smoothness		The accuracy of deep learning, i.e., deep neural networks, can be characterized by dividing the total error into three main types: approximation error, optimization error, and generalization error. Whereas there are some satisfactory answers to the problems of approximation and optimization, much is known about the theory of generalization. Most existing theoretical works for generalization to explain the performance of neural networks in practice. To derive a meaningful bound, we study the generalization error of neural networks for classification problems in terms of data distribution and neural network smoothness. We introduce the cover complexity (CC) to measure the difficulty learning a data set and the inverse of the modulus of continuity to quantify neural network smoothness. A quantitative bound for expected accuracy/error is derived by considering both the CC and neural network smoothness. Although most of the analysis is general and not specific to neural networks, we validate our theoretical assumptions and results numerically for neural networks by several data sets of images. The numerical results confirm that the expected error of trained networks scaled with the square root of the number of classes has a linear relationship with respect to the CC. We observe a clear consistency between test loss and neural network smoothness during the training process. In addition, we demonstrate empirically that the neural network smoothness decreases when the network size increases whereas the smoothness is insensitive to training dataset size. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						85	99		10.1016/j.neunet.2020.06.024													
J								Visual interaction networks: A novel bio-inspired computational model for image classification	NEURAL NETWORKS										Biologically inspired computing; Convolutional neural network (CNN); Visual interaction mechanism; Textile defect; Image classification	NEURAL-NETWORK; OBJECT RECOGNITION; STREAMS; DORSAL; MEMORY; ADAPTATION; PERCEPTION; MECHANISMS; LAYER	Inspired by biological mechanisms and structures in neuroscience, many biologically inspired visual computational models have been presented to provide new solutions for visual recognition task. For example, convolutional neural network (CNN) was proposed according to the hierarchical structure of biological vision, which could achieve superior performance in large-scale image classification. In this paper, we propose a new framework called visual interaction networks (VIN-Net), which is inspired by visual interaction mechanisms. More specifically, self-interaction, mutual-interaction, multi-interaction, and adaptive interaction are proposed in VIN-Net, forming the first interactive completeness of the visual interaction model. To further enhance the representation ability of visual features, the adaptive adjustment mechanism is integrated into the VIN-Net model. Finally, our model is evaluated on three benchmark datasets and two self-built textile defect datasets. The experimental results demonstrate that the proposed model exhibits its efficiency on visual classification tasks. Furthermore, a textile industrial application shows that the proposed architecture outperforms the state-of-the-art approaches in classification performance. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						100	110		10.1016/j.neunet.2020.06.019													
J								A learning approach with incomplete pixel-level labels for deep neural networks	NEURAL NETWORKS										Incomplete labels; Loss function; Image segmentation; Comic speech balloon extraction; Nuclei segmentation	EXTRACTION; BALLOON	Learning with incomplete labels in Neural Networks has been actively investigated these last years. Among different kinds of incomplete labels, we investigate incomplete pixel-level labels which are tackled in many concrete problems. One of the challenges for incomplete pixel-level labels is the missing information at local-level. Most of the current researches with incomplete labels in Neural Network focus on the incompleteness of global labels, only a few works focus on the incompleteness of local labels. To deal with the local incompleteness, we propose a learning approach which uses two dynamic weighted maps in parallel: one for object pixels and another one for background pixels. The two maps are integrated into the loss function of the target Neural Networks, to optimize the model by the present labels and to minimize the damage of the missing labels. We validate our approach on the speech balloon extraction problem in comic book images. Our approach uses the output of a balloon extraction algorithm as incomplete labels. The results are comparable with the state of the art supervised approach with manual labels. The results are very promising because our method does not require any manual labels. In addition, we apply our method to the medical image segmentation task to confirm the generalization of our approach. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						111	125		10.1016/j.neunet.2020.06.025													
J								Hybrid multi-mode machine learning-based fault diagnosis strategies with application to aircraft gas turbine engines	NEURAL NETWORKS										Fault diagnosis; Machine learning; Self-organizing maps; Health monitoring; Aircraft gas turbine engines	SYSTEMS; ACTUATOR; SENSOR	In this work, a novel data-driven fault diagnostic framework is developed by using hybrid multi-mode machine learning strategies to monitor system health status. The coexistence of multi-mode and concurrent faults and their adverse coupling effects pose serious limitations for developing reliable diagnostic methodologies. A novel framework is proposed by exploiting inherent embedded health information contained in the I/O sensor data. The proposed hybrid strategies consist of optimal integration of recurrent neural network-based feature generation and self-organizing map diagnostic modules. To construct reliable fault diagnostic modules, a systematic clustering and modeling methodology is developed that has two primary advantages: (i) it does not require any a priori knowledge of data set characteristics or system mathematical model, and (ii) it does address and resolve the key limitations and challenges in conventional self-organizing map approaches. The effectiveness of our proposed framework is validated by utilizing sensor data including healthy and various degradation modes in application to compressor and turbine of an aircraft gas turbine engine. Comparisons with other machine learning-based methods in the literature are provided to demonstrate the performance and superiority of our proposed framework in fault diagnostic accuracy, false alarm rates, and in dealing with multi-mode and concurrent fault scenarios. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						126	142		10.1016/j.neunet.2020.07.001													
J								Delay-distribution-dependent state estimation for neural networks under stochastic communication protocol with uncertain transition probabilities	NEURAL NETWORKS										Artificial neural networks; Random delays; Stochastic communication protocol; Markov chain; Uncertain transition probability	H-INFINITY; SYSTEMS; SUBJECT	In this paper, the protocol-based remote state estimation problem is considered for a kind of delayed artificial neural networks. The random time-varying delays fall into certain intervals with known probability distributions. For the sake of reducing the data collisions in communication channel from the sensors to the estimator, the stochastic communication protocol (SCP) is employed to decide which sensor is allowed to transmit its data to the remote estimator through the channel at each fixed instant. The scheduling principle of the SCP is governed by a Markov chain whose transition probability is allowed to be uncertain so as to reflect the possible imprecision when implementing the SCP. Through a combination of Lyapunov-Krasovskii functional method and the stochastic analysis technique, a sufficient criterion is obtained for the existence of the desired remote state estimator ensuring that the corresponding augmented estimation error dynamics is asymptotically stable with a prescribed H-infinity performance index. Furthermore, the estimator parameter is acquired by solving a convex optimization problem. Finally, the validity of the established theoretical results is demonstrated via a numerical simulation example. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						143	151		10.1016/j.neunet.2020.06.023													
J								Quantum neural networks model based on swap test and phase estimation	NEURAL NETWORKS										Quantum computing; Swap test; Phase estimation; Quantum neuron; Quantum neural networks	PERCEPTRON; SYSTEM	In this paper, a neural networks model for quantum computer is proposed. The core of this model is quantum neuron. Firstly, the inner product of the input qubits and the weight qubits is mapped to the phase of the control qubits in the neuron by the swap test technology, and then these phases are obtained by the phase estimation method, which are further used as the phase of the output qubit in the neuron. In this way, the mapping of input qubits to output qubit in quantum neuron is completed. The quantum neurons mentioned above can be used to construct quantum neural networks. In this paper, the quantum circuit for each operation step are given. The simulation results on the classic computer verify the effectiveness of the proposed model. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						152	164		10.1016/j.neunet.2020.07.003													
J								Fixed-time synchronization of stochastic memristor-based neural networks with adaptive control	NEURAL NETWORKS										Fixed-time synchronization; Stochastic synchronization; Memristor-based neural networks; Time delays; Adaptive control	H-INFINITY CONTROL; EXPONENTIAL SYNCHRONIZATION; STABILIZATION; STABILITY; DELAY; ROBUST	In this study, we consider the fixed-time synchronization problem for stochastic memristor-based neural networks (MNNs) via two different controllers. First, a new stochastic differential equation is established using differential inclusions and set-valued maps. Next, two kinds of control protocols are designed, including a nonlinear delayed state feedback control scheme and a novel adaptive control strategy, by which fixed-time synchronization of MNNs can be achieved. Then based on stochastic analysis techniques and a Lyapunov function, some sufficient criteria are obtained to ensure that stochastic MNNs achieve stochastic fixed-time synchronization in probability. In addition, the upper bound of the settling time is estimated. Finally, simulation results are provided to demonstrate the validity of the proposed schemes. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						165	175		10.1016/j.neunet.2020.07.002													
J								Hybrid neural network with cost-sensitive support vector machine for class-imbalanced multimodal data	NEURAL NETWORKS										Deep learning (DL); Class-imbalance problem; Cost-sensitive approach; Multimodal analysis; Heterogeneous data; High-dimensional data	CLASSIFICATION; SMOTE; SVM	Although deep learning exhibits advantages in various applications involving multimodal data, it cannot effectively solve the class-imbalance problem. Herein, we propose a hybrid neural network with a cost-sensitive support vector machine (hybrid NN-CSSVM) for class-imbalanced multimodal data. We used a fused multiple-network structure obtained by extracting the features of different modality data, and used cost-sensitive support vector machines (SVMs) as a classifier. To alleviate the insufficiency of learning from minority-class data, our proposed cost-sensitive SVM loss function reflects different weights of misclassification errors from both majority and minority classes, by controlling cost parameters. Additionally, we present a theoretical setting of the cost parameters in our model. The proposed model is validated on real datasets that range from low to high imbalance ratios. By exploiting the complementary advantages of two architectures, the hybrid NN-CSSVM performs excellently, even with data having a minor-class proportion of only 2%. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						176	184		10.1016/j.neunet.2020.06.026													
J								Towards explainable deep neural networks (xDNN)	NEURAL NETWORKS										Explainable AI; Interpretability; Prototype-based models; Deep-learning	MODELS	In this paper, we propose an elegant solution that is directly addressing the bottlenecks of the traditional deep learning approaches and offers an explainable internal architecture that can outperform the existing methods, requires very little computational resources (no need for GPUs) and short training times (in the order of seconds). The proposed approach, xDNN is using prototypes. Prototypes are actual training data samples (images), which are local peaks of the empirical data distribution called typicality as well as of the data density. This generative model is identified in a closed form and equates to the pdf but is derived automatically and entirely from the training data with no user- or problem-specific thresholds, parameters or intervention. The proposed xDNN offers a new deep learning architecture that combines reasoning and learning in a synergy. It is non-iterative and non-parametric, which explains its efficiency in terms of time and computational resources. From the user perspective, the proposed approach is clearly understandable to human users. We tested it on challenging problems as the classification of different lighting conditions for driving scenes (iROADS), object detection (Caltech-256, and Caltech-101), and SARS-CoV-2 identification via computed tomography scan (COVID CT-scans dataset). xDNN outperforms the other methods including deep learning in terms of accuracy, time to train and offers an explainable classifier. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						185	194		10.1016/j.neunet.2020.07.010													
J								k-hop graph neural networks	NEURAL NETWORKS										Graph neural networks; Graph mining; Expressivity		Graph neural networks (GNNs) have emerged recently as a powerful architecture for learning node and graph representations. Standard GNNs have the same expressive power as the Weisfeiler-Lehman test of graph isomorphism in terms of distinguishing non-isomorphic graphs. However, it was recently shown that this test cannot identify fundamental graph properties such as connectivity and triangle freeness. We show that GNNs also suffer from the same limitation. To address this limitation, we propose a more expressive architecture, k-hop GNNs, which updates a node's representation by aggregating information not only from its direct neighbors, but from its k-hop neighborhood. We show that the proposed architecture can identify fundamental graph properties. We evaluate the proposed architecture on standard node classification and graph classification datasets. Our experimental evaluation confirms our theoretical findings since the proposed model achieves performance better or comparable to standard GNNs and to state-of-the-art algorithms. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						195	205		10.1016/j.neunet.2020.07.008													
J								Deep clustering with a Dynamic Autoencoder: From reconstruction towards centroids construction	NEURAL NETWORKS										Unsupervised learning; Deep learning; Clustering; Autoencoders		In unsupervised learning, there is no apparent straightforward cost function that can capture the significant factors of variations and similarities. Since natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static. The absence of concrete supervision suggests that smooth dynamics should be integrated during the training process. Compared to classical static cost functions, dynamic objective functions allow to better make use of the gradual and uncertain knowledge acquired through pseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a novel model for deep clustering that addresses a clustering-reconstruction trade-off, by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one. Experimental evaluations on benchmark datasets show that our approach achieves state-of-the-art results compared to the most relevant deep clustering methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						206	228		10.1016/j.neunet.2020.07.005													
J								Asynchronous dissipative filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts	NEURAL NETWORKS										Nonhomogeneous Markov switching; Neural network; Asynchronous filter; Variable packet dropout	JUMP SYSTEMS; STABILITY	This work focuses on the problem of asynchronous filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts (VPDs). The discrete-time nonhomogeneous Markov process is adopted to depict the modes switching of target plant, where time-varying transition probabilities are revealed by utilizing a polytope technology. By means of the Bernoulli distributed sequence, the randomly occurring packet dropouts are presented, where VPD rates are mode-dependent and remain variable. Unlike the existing results, the hidden Markov model scheme is formulated to describe the asynchronization between nonhomogeneous neural networks and filter, and resilient filters are presented, which makes the designed filters more general. Eventually, a simulation example is established to verify the effectiveness of the developed filter scheme. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						229	237		10.1016/j.neunet.2020.07.012													
J								Feature fusion via Deep Random Forest for facial age estimation	NEURAL NETWORKS										Age estimation; Cascade of classification trees ensembles; Deep Random Forest; Face descriptors; Deep features	MODEL	In the last few years, human age estimation from face images attracted the attention of many researchers in computer vision and machine learning fields. This is due to its numerous applications. In this paper, we propose a new architecture for age estimation based on facial images. It is mainly based on a cascade of classification trees ensembles, which are known recently as a Deep Random Forest. Our architecture is composed of two types of DRF. The first type extends and enhances the feature representation of a given facial descriptor. The second type operates on the fused form of all enhanced representations in order to provide a prediction for the age while taking into account the fuzziness property of the human age. While the proposed methodology is able to work with all kinds of image features, the face descriptors adopted in this work used off-the-shelf deep features allowing to retain both the rich deep features and the powerful enhancement and decision provided by the proposed architecture. Experiments conducted on six public databases prove the superiority of the proposed architecture over other state-of-the-art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						238	252		10.1016/j.neunet.2020.07.006													
J								Self-organizing subspace clustering for high-dimensional and multi-view data	NEURAL NETWORKS										Subspace clustering; Multi-view clustering; High-dimensional data; Self-organizing maps	ALGORITHM; SEGMENTATION; CANCER; MODEL	A surge in the availability of data from multiple sources and modalities is correlated with advances in how to obtain, compress, store, transfer, and process large amounts of complex high-dimensional data. The clustering challenge increases with the growth of data dimensionality which decreases the discriminate power of the distance metrics. Subspace clustering aims to group data drawn from a union of subspaces. In such a way, there is a large number of state-of-the-art approaches and we divide them into families regarding the method used in the clustering. We introduce a soft subspace clustering algorithm, a Self-organizing Map (SOM) with a time-varying structure, to cluster data without any prior knowledge of the number of categories or of the neural network topology, both determined during the training process. The model also assigns proper relevancies (weights) to different dimensions, capturing from the learning process the influence of each dimension on uncovering clusters. We employ a number of real-world datasets to validate the model. This algorithm presents a competitive performance in a diverse range of contexts among them data mining, gene expression, multi-view, computer vision and text clustering problems which include high-dimensional data. Extensive experiments suggest that our method very often outperforms the state-of-the-art approaches in all types of problems considered. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						253	268		10.1016/j.neunet.2020.06.022													
J								A pruning feedforward small-world neural network based on Katz centrality for nonlinear system modeling	NEURAL NETWORKS										Small-world neural network; Pruning algorithm; Katz centrality; Nonlinear system modeling	BRAIN NETWORKS; IDENTIFICATION	Approaching to the biological neural network, small-world neural networks have been demonstrated to improve the generalization performance of artificial neural networks. However, the architecture of small-world neural networks is typically large and predefined. This may cause the problems of overfitting and time consuming, and cannot obtain an optimal network structure automatically for a given problem. To solve the above problems, this paper proposes a pruning feedforward small-world neural network (PFSWNN), and applies it to nonlinear system modeling. Firstly, a feedforward small-world neural network (FSWNN) is constructed according to the rewiring rule of Watts-Strogatz. Secondly, the importance of each hidden neuron is evaluated based on its Katz centrality. If the Katz centrality of a hidden neuron is below the predefined threshold, this neuron is considered to be an unimportant node and then merged with its most correlated neuron in the same hidden layer. The connection weights are trained using the gradient-based algorithm, and the convergence of the proposed PFSWNN is theoretically analyzed in this paper. Finally, the PFSWNN model is tested on some problems for nonlinear system modeling, including the approximation for a rapidly changing function, CATS missing time-series prediction, four benchmark problems of UCI public datasets and a practical problem for wastewater treatment process. Experimental results demonstrate that PFSWNN exhibits superior generalization performance by small-world property as well as the pruning algorithm, and the training time of PFSWNN is shortened owning to a compact structure. (C) 2020 Elsevier Ltd. All rights reserved.																	0893-6080	1879-2782				OCT	2020	130						269	285		10.1016/j.neunet.2020.07.017													
J								Intel (R) RealSense (TM) SR300 Coded Light Depth Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Three-dimensional displays; Image reconstruction; Pipelines; Optical imaging; Optical sensors; Reflective binary codes; Intel; RealSense; 3D camera; SR300; coded light; depth reconstruction	SURFACE MEASUREMENT; MINIMAL-SURFACES; MOVIES; IMAGES; COLOR; MAPS	Intel (R) RealSense (TM) SR300 is a depth camera capable of providing a VGA-size depth map at 60 fps and 0.125mm depth resolution. In addition, it outputs an infrared VGA-resolution image and a 1080p color texture image at 30 fps. SR300 form-factor enables it to be integrated into small consumer products and as a front facing camera in laptops and Ultrabooks (TM). The SR300 depth camera is based on a coded-light technology where triangulation between projected patterns and images captured by a dedicated sensor is used to produce the depth map. Each projected line is coded by a special temporal optical code, that enables a dense depth map reconstruction from its reflection. The solid mechanical assembly of the camera allows it to stay calibrated throughout temperature and pressure changes, drops, and hits. In addition, active dynamic control maintains a calibrated depth output. An extended API LibRS released with the camera allows developers to integrate the camera in various applications. Algorithms for 3D scanning, facial analysis, hand gesture recognition, and tracking are within reach for applications using the SR300. In this paper, we describe the underlying technology, hardware, and algorithms of the SR300, as well as its calibration procedure, and outline some use cases. We believe that this paper will provide a full case study of a mass-produced depth sensing product and technology.																	0162-8828	1939-3539				OCT 1	2020	42	10					2333	2345		10.1109/TPAMI.2019.2915841													
J								Snapshot Compressive ToF plus Spectral Imaging via Optimized Color-Coded Apertures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Apertures; Cameras; Three-dimensional displays; Lenses; Image coding; Optical imaging; Compressive spectral imaging; time-of-flight imaging; color-coded apertures; multitoning; RGB plus D; MS plus D	BLUE-NOISE; DESIGN	Compressive multispectral imaging systems comprise a new generation of spectral imagers that capture coded projections of a scene where spectral data cubes are reconstructed computationally. Separately, time-of-flight (ToF) cameras obtain 2D range images where each pixel records the distance from the camera sensor to the target surface. The demand for these imaging modalities is rapidly increasing, and thus, there is strong interest in developing new image sensors that can simultaneously acquire multispectral-color-and-depth imagery (MS+D) using a single aperture. Work in this path has been mainly developed via RGB+D imaging. However, in RGB+D, the multispectral image is limited to three spectral channels, and the imaging system often relies on two image sensors. We recently proposed a compressive MS+D imaging device that used a digital-micromirror-device, requiring a bulky double imaging-and-relay path. To overcome the bulkiness and other difficulties of our previous imaging system, this work presents a more-compact MS+D imaging device with snapshot capabilities. It provides better spectral sensing, relying on a static color-coded-aperture (CCA) and a ToF sensor. To guarantee good quality in the recovery, we develop an optimization method for CCA based-on blue-noise-multitoning, solved via the direct-binary-search algorithm. A testbed-setup is reported along with simulated and real experiments that demonstrate the MS+D capabilities of the proposed system over static and dynamic scenes.																	0162-8828	1939-3539				OCT 1	2020	42	10					2346	2360		10.1109/TPAMI.2019.2912961													
J								Learning Depth with Convolutional Spatial Propagation Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Estimation; Task analysis; Three-dimensional displays; Cameras; Laser radar; Convolutional codes; Benchmark testing; Spatial propagation networks; depth completion; stereo matching; spatial pyramid pooling		In this paper, we propose the convolutional spatial propagation network (CSPN) and demonstrate its effectiveness for various depth estimation tasks. CSPN is a simple and efficient linear propagation model, where the propagation is performed with a manner of recurrent convolutional operations, in which the affinity among neighboring pixels is learned through a deep convolutional neural network (CNN). Compare to the previous state-of-the-art (SOTA) linear propagation model, i.e., spatial propagation networks (SPN), CSPN is 2 to 5x faster in practice. We concatenate CSPN and its variants to SOTA depth estimation networks, which significantly improve the depth accuracy. Specifically, we apply CSPN to two depth estimation problems: depth completion and stereo matching, in which we design modules which adapts the original 2D CSPN to embed sparse depth samples during the propagation, operate with 3D convolution and be synergistic with spatial pyramid pooling. In our experiments, we show that all these modules contribute to the final performance. For the task of depth completion, our method reduce the depth error over 30 percent in the NYU v2 and KITTI datasets. For the task of stereo matching, our method currently ranks 1st on both the KITTI Stereo 2012 and 2015 benchmarks.																	0162-8828	1939-3539				OCT 1	2020	42	10					2361	2379		10.1109/TPAMI.2019.2947374													
J								Progressive Fusion for Unsupervised Binocular Depth Estimation Using Cycled Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Estimation; Training; Deep learning; Cameras; Solid modeling; Predictive models; Network architecture; Stereo depth estimation; convolutional neural networks (ConvNet); deep multi-scale fusion; cycle network		Recent deep monocular depth estimation approaches based on supervised regression have achieved remarkable performance. However, they require costly ground truth annotations during training. To cope with this issue, in this paper we present a novel unsupervised deep learning approach for predicting depth maps. We introduce a new network architecture, named Progressive Fusion Network (PFN), that is specifically designed for binocular stereo depth estimation. This network is based on a multi-scale refinement strategy that combines the information provided by both stereo views. In addition, we propose to stack twice this network in order to form a cycle. This cycle approach can be interpreted as a form of data-augmentation since, at training time, the network learns both from the training set images (in the forward half-cycle) but also from the synthesized images (in the backward half-cycle). The architecture is jointly trained with adversarial learning. Extensive experiments on the publicly available datasets KITTI, Cityscapes and ApolloScape demonstrate the effectiveness of the proposed model which is competitive with other unsupervised deep learning methods for depth prediction.																	0162-8828	1939-3539				OCT 1	2020	42	10					2380	2395		10.1109/TPAMI.2019.2942928													
J								Unsupervised Domain Adaptation for Depth Prediction from Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Training; Reliability; Estimation; Loss measurement; Computer architecture; Prediction algorithms; Deep learning; Deep learning; depth estimation; unsupervised learning; self-supervised learning; domain adaptation	STEREO; ACCURATE	State-of-the-art approaches to infer dense depth measurements from images rely on CNNs trained end-to-end on a vast amount of data. However, these approaches suffer a drastic drop in accuracy when dealing with environments much different in appearance and/or context from those observed at training time. This domain shift issue is usually addressed by fine-tuning on smaller sets of images from the target domain annotated with depth labels. Unfortunately, relying on such supervised labeling is seldom feasible in most practical settings. Therefore, we propose an unsupervised domain adaptation technique which does not require groundtruth labels. Our method relies only on image pairs and leverages on classical stereo algorithms to produce disparity measurements alongside with confidence estimators to assess upon their reliability. We propose to fine-tune both depth-from-stereo as well as depth-from-mono architectures by a novel confidence-guided loss function that handles the measured disparities as noisy labels weighted according to the estimated confidence. Extensive experimental results based on standard datasets and evaluation protocols prove that our technique can address effectively the domain shift issue with both stereo and monocular depth prediction architectures and outperforms other state-of-the-art unsupervised loss functions that may be alternatively deployed to pursue domain adaptation.																	0162-8828	1939-3539				OCT 1	2020	42	10					2396	2409		10.1109/TPAMI.2019.2940948													
J								Semi-Supervised Adversarial Monocular Depth Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Estimation; Generators; Training; Image reconstruction; Sensors; Adaptation models; Data models; Monocular depth estimation; generative adversarial learning; semi-supervise learning	SHAPE	In this paper, we address the problem of monocular depth estimation when only a limited number of training image-depth pairs are available. To achieve a high regression accuracy, the state-of-the-art estimation methods rely on CNNs trained with a large number of image-depth pairs, which are prohibitively costly or even infeasible to acquire. Aiming to break the curse of such expensive data collections, we propose a semi-supervised adversarial learning framework that only utilizes a small number of image-depth pairs in conjunction with a large number of easily-available monocular images to achieve high performance. In particular, we use one generator to regress the depth and two discriminators to evaluate the predicted depth, i.e., one inspects the image-depth pair while the other inspects the depth channel alone. These two discriminators provide their feedbacks to the generator as the loss to generate more realistic and accurate depth predictions. Experiments show that the proposed approach can (1) improve most state-of-the-art models on the NYUD v2 dataset by effectively leveraging additional unlabeled data sources; (2) reach state-of-the-art accuracy when the training set is small, e.g., on the Make3D dataset; (3) adapt well to an unseen new dataset (Make3D in our case) after training on an annotated dataset (KITTI in our case).																	0162-8828	1939-3539				OCT 1	2020	42	10					2410	2422		10.1109/TPAMI.2019.2936024													
J								Confidence Propagation through CNNs for Guided Sparse Depth Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Convolution; Sensors; Task analysis; Computer architecture; Cameras; Autonomous vehicles; Reliability; Sparse data; CNNs; depth completion; normalized convolution; confidence propagation	RECONSTRUCTION	Generally, convolutional neural networks (CNNs) process data on a regular grid, e.g., data generated by ordinary cameras. Designing CNNs for sparse and irregularly spaced input data is still an open research problem with numerous applications in autonomous driving, robotics, and surveillance. In this paper, we propose an algebraically-constrained normalized convolution layer for CNNs with highly sparse input that has a smaller number of network parameters compared to related work. We propose novel strategies for determining the confidence from the convolution operation and propagating it to consecutive layers. We also propose an objective function that simultaneously minimizes the data error while maximizing the output confidence. To integrate structural information, we also investigate fusion strategies to combine depth and RGB information in our normalized convolution network framework. In addition, we introduce the use of output confidence as an auxiliary information to improve the results. The capabilities of our normalized convolution network framework are demonstrated for the problem of scene depth completion. Comprehensive experiments are performed on the KITTI-Depth and the NYU-Depth-v2 datasets. The results clearly demonstrate that the proposed approach achieves superior performance while requiring only about 1-5 percent of the number of parameters compared to the state-of-the-art methods.																	0162-8828	1939-3539				OCT 1	2020	42	10					2423	2436		10.1109/TPAMI.2019.2929170													
J								Learned Dynamic Guidance for Depth Image Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Task analysis; Analytical models; Optimization; Image reconstruction; Training data; Data models; Network architecture	MINIMIZATION	The depth images acquired by consumer depth sensors (e.g., Kinect and ToF) usually are of low resolution and insufficient quality. One natural solution is to incorporate a high resolution RGB camera and exploit the statistical correlation of its data and depth. In recent years, both optimization-based and learning-based approaches have been proposed to deal with the guided depth reconstruction problems. In this paper, we introduce a weighted analysis sparse representation (WASR) model for guided depth image enhancement, which can be considered a generalized formulation of a wide range of previous optimization-based models. We unfold the optimization by the WASR model and conduct guided depth reconstruction with dynamically changed stage-wise operations. Such a guidance strategy enables us to dynamically adjust the stage-wise operations that update the depth image, thus improving the reconstruction quality and speed. To learn the stage-wise operations in a task-driven manner, we propose two parameterizations and their corresponding methods: dynamic guidance with Gaussian RBF nonlinearity parameterization (DG-RBF) and dynamic guidance with CNN nonlinearity parameterization (DG-CNN). The network structures of the proposed DG-RBF and DG-CNN methods are designed with the the objective function of our WASR model in mind and the optimal network parameters are learned from paired training data. Such optimization-inspired network architectures enable our models to leverage the previous expertise as well as take benefit from training data. The effectiveness is validated for guided depth image super-resolution and for realistic depth image reconstruction tasks using standard benchmarks. Our DG-RBF and DG-CNN methods achieve the best quantitative results (RMSE) and better visual quality than the state-of-the-art approaches at the time of writing. The code is available at https://github.com/ShuhangGu/GuidedDepthSR.																	0162-8828	1939-3539				OCT 1	2020	42	10					2437	2452		10.1109/TPAMI.2019.2961672													
J								Photometric Depth Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Image resolution; Lighting; Shape; Training; Cameras; Color; Frequency measurement; RGB-D cameras; depth super-resolution; shape-from-shading; photometric stereo; variational methods; deep learning	VISCOSITY SOLUTIONS; SHAPE; IMAGE; STEREO; REFLECTANCE; CONSISTENT	This study explores the use of photometric techniques (shape-from-shading and uncalibrated photometric stereo) for upsampling the low-resolution depth map from an RGB-D sensor to the higher resolution of the companion RGB image. A single-shot variational approach is first put forward, which is effective as long as the target's reflectance is piecewise-constant. It is then shown that this dependency upon a specific reflectance model can be relaxed by focusing on a specific class of objects (e.g., faces), and delegate reflectance estimation to a deep neural network. A multi-shot strategy based on randomly varying lighting conditions is eventually discussed. It requires no training or prior on the reflectance, yet this comes at the price of a dedicated acquisition setup. Both quantitative and qualitative evaluations illustrate the effectiveness of the proposed methods on synthetic and real-world scenarios.																	0162-8828	1939-3539				OCT 1	2020	42	10					2453	2464		10.1109/TPAMI.2019.2923621													
J								Real-Time RGB-D Camera Pose Estimation in Novel Scenes Using a Relocalisation Cascade	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Forestry; Three-dimensional displays; Real-time systems; Pose estimation; Impedance matching; Training; Camera pose estimation; relocalisation; RGB-D; online adaptation; cascade		Camera pose estimation is an important problem in computer vision, with applications as diverse as simultaneous localisation and mapping, virtual/augmented reality and navigation. Common techniques match the current image against keyframes with known poses coming from a tracker, directly regress the pose, or establish correspondences between keypoints in the current image and points in the scene in order to estimate the pose. In recent years, regression forests have become a popular alternative to establish such correspondences. They achieve accurate results, but have traditionally needed to be trained offline on the target scene, preventing relocalisation in new environments. Recently, we showed how to circumvent this limitation by adapting a pre-trained forest to a new scene on the fly. The adapted forests achieved relocalisation performance that was on par with that of offline forests, and our approach was able to estimate the camera pose in close to real time, which made it desirable for systems that require online relocalisation. In this paper, we present an extension of this work that achieves significantly better relocalisation performance whilst running fully in real time. To achieve this, we make several changes to the original approach: (i) instead of simply accepting the camera pose hypothesis produced by RANSAC without question, we make it possible to score the final few hypotheses it considers using a geometric approach and select the most promising one; (ii) we chain several instantiations of our relocaliser (with different parameter settings) together in a cascade, allowing us to try faster but less accurate relocalisation first, only falling back to slower, more accurate relocalisation as necessary; and (iii) we tune the parameters of our cascade, and the individual relocalisers it contains, to achieve effective overall performance. Taken together, these changes allow us to significantly improve upon the performance our original state-of-the-art method was able to achieve on the well-known 7-Scenes and Stanford 4 Scenes benchmarks. As additional contributions, we present a novel way of visualising the internal behaviour of our forests, and use the insights gleaned from this to show how to entirely circumvent the need to pre-train a forest on a generic scene.																	0162-8828	1939-3539				OCT 1	2020	42	10					2465	2477		10.1109/TPAMI.2019.2915068													
J								Unsupervised Deep Visual-Inertial Odometry with Online Error Correction for RGB-D Imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Trajectory; Image reconstruction; Simultaneous localization and mapping; Estimation; Visualization; Jacobian matrices; Visual-inertial odometry; unsupervised deep learning; refinement; localization; neural networks	KALMAN FILTER; VISION; SLAM	While numerous deep approaches to the problem of vision-aided localization have been recently proposed, systems operating in the real world will undoubtedly experience novel sensory states previously unseen even under the most prodigious training regimens. We address the localization problem with online error correction (OEC) modules that are trained to correct a vision-aided localization network's mistakes. We demonstrate the generalizability of the OEC modules and describe our unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to spatial grids of pixel coordinates. We evaluate our network against state-of-the-art (SoA) VIO, visual odometry (VO), and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset as well as a micro aerial vehicle (MAV) dataset that we collected in the AirSim simulation environment. We demonstrate better than SoA translational localization performance against comparable SoA approaches on our evaluation sequences.																	0162-8828	1939-3539				OCT 1	2020	42	10					2478	2493		10.1109/TPAMI.2019.2909895													
J								SurfelMeshing: Online Surfel-Based Mesh Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Real-time systems; Simultaneous localization and mapping; Three-dimensional displays; Surface reconstruction; Cameras; Noise reduction; Image reconstruction; Applications of RGB-D vision; depth fusion; loop closure; 3-D modeling and scene reconstruction; RGB-D SLAM; real-time dense mapping; surfels	INTEGRATION	We address the problem of mesh reconstruction from live RGB-D video, assuming a calibrated camera and poses provided externally (e.g., by a SLAM system). In contrast to most existing approaches, we do not fuse depth measurements in a volume but in a dense surfel cloud. We asynchronously (re)triangulate the smoothed surfels to reconstruct a surface mesh. This novel approach enables to maintain a dense surface representation of the scene during SLAM which can quickly adapt to loop closures. This is possible by deforming the surfel cloud and asynchronously remeshing the surface where necessary. The surfel-based representation also naturally supports strongly varying scan resolution. In particular, it reconstructs colors at the input camera's resolution. Moreover, in contrast to many volumetric approaches, ours can reconstruct thin objects since objects do not need to enclose a volume. We demonstrate our approach in a number of experiments, showing that it produces reconstructions that are competitive with the state-of-the-art, and we discuss its advantages and limitations. The algorithm (excluding loop closure functionality) is available as open source at https://github.com/puzzlepaint/surfelmeshing.																	0162-8828	1939-3539				OCT 1	2020	42	10					2494	2507		10.1109/TPAMI.2019.2947048													
J								UnstructuredFusion: Realtime 4D Geometry and Texture Reconstruction Using Commercial RGBD Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Cameras; Geometry; Skeleton; Dynamics; Surface reconstruction; Image reconstruction; Videos; 4D reconstruction; performance capture; multi-camera; atlas texturing; skeleton warping; online calibration	MARKERLESS MOTION CAPTURE; TRACKING; CHARACTERS	A high-quality 4D geometry and texture reconstruction for human activities usually requires multiview perceptions via highly structured multi-camera setup, where both the specifically designed cameras and the tedious pre-calibration restrict the popularity of professional multi-camera systems for daily applications. In this paper, we propose UnstructuredFusion, a practicable realtime markerless human performance capture method using unstructured commercial RGBD cameras. Along with the flexible hardware setup using simply three unstructured RGBD cameras without any careful pre-calibration, the challenge 4D reconstruction through multiple asynchronous videos is solved by proposing three novel technique contributions, i.e., online multi-camera calibration, skeleton warping based non-rigid tracking, and temporal blending based atlas texturing. The overall insights behind lie in the solid global constraints of human body and human motion which are modeled by the skeleton and the skeleton warping, respectively. Extensive experiments such as allocating three cameras flexibly in a handheld way demonstrate that the proposed UnstructuredFusion achieves high-quality 4D geometry and texture reconstruction without tiresome pre-calibration, liberating the cumbersome hardware and software restrictions in conventional structured multi-camera system, while eliminating the inherent occlusion issues of the single camera setup.																	0162-8828	1939-3539				OCT 1	2020	42	10					2508	2522		10.1109/TPAMI.2019.2915229													
J								DoubleFusion: Real-Time Capture of Human Performances with Inner Body Shapes from a Single Depth Sensor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Shape; Surface reconstruction; Real-time systems; Tracking; Strain; Cameras; Skeleton; RGBD sensor; human performance capture; human shape reconstruction; real-time	MARKERLESS MOTION CAPTURE; INTERACTING CHARACTERS; OBJECTS; REGISTRATION; TRACKING	We propose DoubleFusion, a new real-time system that combines volumetric non-rigid reconstruction with data-driven template fitting to simultaneously reconstruct detailed surface geometry, large non-rigid motion and the optimized human body shape from a single depth camera. One of the key contributions of this method is a double-layer representation consisting of a complete parametric body model inside, and a gradually fused detailed surface outside. A pre-defined node graph on the body parameterizes the non-rigid deformations near the body, and a free-form dynamically changing graph parameterizes the outer surface layer far from the body, which allows more general reconstruction. We further propose a joint motion tracking method based on the double-layer representation to enable robust and fast motion tracking performance. Moreover, the inner parametric body is optimized online and forced to fit inside the outer surface layer as well as the live depth input. Overall, our method enables increasingly denoised, detailed and complete surface reconstructions, fast motion tracking performance and plausible inner body shape reconstruction in real-time. Experiments and comparisons show improved fast motion tracking and loop closure performance on more challenging scenarios. Two extended applications including body measurement and shape retargeting show the potential of our system in terms of practical use.																	0162-8828	1939-3539				OCT 1	2020	42	10					2523	2539		10.1109/TPAMI.2019.2928296													
J								Learning and Tracking the 3D Body Shape of Freely Moving Infants from RGB-D sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Shape; Biological system modeling; Three-dimensional displays; Data models; Animals; Face; Avatars; Body models; data-driven; RGB-D; infants; motion analysis	MODEL; MOVEMENTS; POSE	Statistical models of the human body surface are generally learned from thousands of high-quality 3D scans in predefined poses to cover the wide variety of human body shapes and articulations. Acquisition of such data requires expensive equipment, calibration procedures, and is limited to cooperative subjects who can understand and follow instructions, such as adults. We present a method for learning a statistical 3D Skinned Multi-Infant Linear body model (SMIL) from incomplete, low-quality RGB-D sequences of freely moving infants. Quantitative experiments show that SMIL faithfully represents the RGB-D data and properly factorizes the shape and pose of the infants. To demonstrate the applicability of SMIL, we fit the model to RGB-D sequences of freely moving infants and show, with a case study, that our method captures enough motion detail for General Movements Assessment (GMA), a method used in clinical practice for early detection of neurodevelopmental disorders in infants. SMIL provides a new tool for analyzing infant shape and movement and is a step towards an automated system for GMA.																	0162-8828	1939-3539				OCT 1	2020	42	10					2540	2551		10.1109/TPAMI.2019.2917908													
J								Robust RGB-D Face Recognition Using Attribute-Aware Loss	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Face recognition; Face; Training; Training data; Feature extraction; Task analysis; Deep learning; Face recognition; RGB-D images; uneven sampling density; attribute-aware loss		Existing convolutional neural network (CNN) based face recognition algorithms typically learn a discriminative feature mapping, using a loss function that enforces separation of features from different classes and/or aggregation of features within the same class. However, they may suffer from bias in the training data such as uneven sampling density, because they optimize the adjacency relationship of the learned features without considering the proximity of the underlying faces. Moreover, since they only use facial images for training, the learned feature mapping may not correctly indicate the relationship of other attributes such as gender and ethnicity, which can be important for some face recognition applications. In this paper, we propose a new CNN-based face recognition approach that incorporates such attributes into the training process. Using an attribute-aware loss function that regularizes the feature mapping using attribute proximity, our approach learns more discriminative features that are correlated with the attributes. We train our face recognition model on a large-scale RGB-D data set with over 100K identities captured under real application conditions. By comparing our approach with other methods on a variety of experiments, we demonstrate that depth channel and attribute-aware loss greatly improve the accuracy and robustness of face recognition.																	0162-8828	1939-3539				OCT 1	2020	42	10					2552	2566		10.1109/TPAMI.2019.2919284													
J								Local-LDA: Open-Ended Learning of Latent Topics for 3D Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Object recognition; Robots; Visualization; Task analysis; Training; Shape; Latent dirichlet allocation (LDA); local-LDA; open-ended learning; 3D object learning and recognition; object perception	MODEL; PERCEPTION	Service robots are expected to be more autonomous and work effectively in human-centric environments. This implies that robots should have special capabilities, such as learning from past experiences and real-time object category recognition. This paper proposes an open-ended 3D object recognition system which concurrently learns both the object categories and the statistical features for encoding objects. In particular, we propose an extension of Latent Dirichlet Allocation to learn structural semantic features (i.e., visual topics), from low-level feature co-occurrences, for each category independently. Moreover, topics in each category are discovered in an unsupervised fashion and are updated incrementally using new object views. In this way, the advantages of both the (hand-crafted) local features and the (learned) structural semantic features have been considered and combined in an efficient way. An extensive set of experiments has been performed to assess the performance of the proposed Local-LDA in terms of descriptiveness, scalability, and computation time. Experimental results show that the overall classification performance obtained with Local-LDA is clearly better than the best performances obtained with the state-of-the-art approaches. Moreover, the best scalability, in terms of number of learned categories, was obtained with the proposed Local-LDA approach, closely followed by a Bag-of-Words (BoW) approach. Concerning computation time, the best result was obtained with BoW, immediately followed by the Local-LDA approach.																	0162-8828	1939-3539				OCT 1	2020	42	10					2567	2580		10.1109/TPAMI.2019.2926459													
J								Learning with Privileged Information via Adversarial Discriminative Modality Distillation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Task analysis; Training; Videos; Data models; Analytical models; Deep learning; Two dimensional displays; Multimodal deep learning; adversarial learning; privileged information; network distillation; modality hallucination		Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robust algorithms and better performance. However, while training data can be accurately collected to include a variety of sensory modalities, it is often the case that not all of them are available in real life (testing) scenarios, where a model has to be deployed. This raises the challenge of how to extract information from multimodal data in the training stage, in a form that can be exploited at test time, considering limitations such as noisy or missing modalities. This paper presents a new approach in this direction for RGB-D vision tasks, developed within the adversarial learning and privileged information frameworks. We consider the practical case of learning representations from depth and RGB videos, while relying only on RGB data at test time. We propose a new approach to train a hallucination network that learns to distill depth information via adversarial learning, resulting in a clean approach without several losses to balance or hyperparameters. We report state-of-the-art results for object classification on the NYUD dataset, and video action recognition on the largest multimodal dataset available for this task, the NTU RGB+D, as well as on the Northwestern-UCLA.																	0162-8828	1939-3539				OCT 1	2020	42	10					2581	2593		10.1109/TPAMI.2019.2929038													
J								Sparse Coding of Shape Trajectories for Facial Expression and Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Manifolds; Two dimensional displays; Shape; Three-dimensional displays; Face recognition; Trajectory; Encoding; Kendall's shape space; shape trajectories; sparse coding and dictionary learning; action recognition; facial expression recognition	CLASSIFICATION; REPRESENTATION; MANIFOLDS	The detection and tracking of human landmarks in video streams has gained in reliability partly due to the availability of affordable RGB-D sensors. The analysis of such time-varying geometric data is playing an important role in the automatic human behavior understanding. However, suitable shape representations as well as their temporal evolution, termed trajectories, often lie to nonlinear manifolds. This puts an additional constraint (i.e., nonlinearity) in using conventional Machine Learning techniques. As a solution, this paper accommodates the well-known Sparse Coding and Dictionary Learning approach to study time-varying shapes on the Kendall shape spaces of 2D and 3D landmarks. We illustrate effective coding of 3D skeletal sequences for action recognition and 2D facial landmark sequences for macro- and micro-expression recognition. To overcome the inherent nonlinearity of the shape spaces, intrinsic and extrinsic solutions were explored. As main results, shape trajectories give rise to more discriminative time-series with suitable computational properties, including sparsity and vector space structure. Extensive experiments conducted on commonly-used datasets demonstrate the competitiveness of the proposed approaches with respect to state-of-the-art.																	0162-8828	1939-3539				OCT 1	2020	42	10					2594	2607		10.1109/TPAMI.2019.2932979													
J								Joint Task-Recursive Learning for RGB-D Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Task analysis; Estimation; Semantics; Image segmentation; Learning systems; Fuses; Cameras; Depth estimation; surface normal estimation; semantic segmentation; recursive learning; RGB-D scene understanding		RGB-D scene understanding under monocular camera is an emerging and challenging topic with many potential applications. In this paper, we propose a novel Task-Recursive Learning (TRL) framework to jointly and recurrently conduct three representative tasks therein containing depth estimation, surface normal prediction and semantic segmentation. TRL recursively refines the prediction results through a series of task-level interactions, where one-time cross-task interaction is abstracted as one network block of one time stage. In each stage, we serialize multiple tasks into a sequence and then recursively perform their interactions. To adaptively enhance counterpart patterns, we encapsulate interactions into a specific Task-Attentional Module (TAM) to mutually-boost the tasks from each other. Across stages, the historical experiences of previous states of tasks are selectively propagated into the next stages by using Feature-Selection unit (FS-Unit), which takes advantage of complementary information across tasks. The sequence of task-level interactions is also evolved along a coarse-to-fine scale space such that the required details may be refined progressively. Finally the task-abstracted sequence problem of multi-task prediction is framed into a recursive network. Extensive experiments on NYU-Depth v2 and SUN RGB-D datasets demonstrate that our method can recursively refines the results of the triple tasks and achieves state-of-the-art performance.																	0162-8828	1939-3539				OCT 1	2020	42	10					2608	2623		10.1109/TPAMI.2019.2926728													
J								Every Pixel Counts plus plus : Joint Learning of Geometry and Motion with 3D Holistic Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Estimation; Optical imaging; Three-dimensional displays; Cameras; Videos; Geometry; Task analysis; Depth estimation; optical flow prediction; unsupervised learning	STRUCTURE-FROM-MOTION; FLOW	Learning to estimate 3D geometry in a single frame and optical flow from consecutive frames by watching unlabeled videos via deep convolutional network has made significant progress recently. Current state-of-the-art (SoTA) methods treat the two tasks independently. One typical assumption of the existing depth estimation methods is that the scenes contain no independent moving objects. while object moving could be easily modeled using optical flow. In this paper, we propose to address the two tasks as a whole, i.e., to jointly understand per-pixel 3D geometry and motion. This eliminates the need of static scene assumption and enforces the inherent geometrical consistency during the learning process, yielding significantly improved results for both tasks. We call our method as "Every Pixel Counts++" or "EPC++". Specifically, during training, given two consecutive frames from a video, we adopt three parallel networks to predict the camera motion (MotionNet), dense depth map (DepthNet), and per-pixel optical flow between two frames (OptFlowNet) respectively. The three types of information, are fed into a holistic 3D motion parser (HMP), and per-pixel 3D motion of both rigid background and moving objects are disentangled and recovered. Various loss terms are formulated to jointly supervise the three networks. An effective adaptive training strategy is proposed to achieve better performance and more efficient convergence. Comprehensive experiments were conducted on datasets with different scenes, including driving scenario (KITTI 2012 and KITTI 2015 datasets), mixed outdoor/indoor scenes (Make3D) and synthetic animation (MPI Sintel dataset). Performance on the five tasks of depth estimation, optical flow estimation, odometry, moving object segmentation and scene flow estimation shows that our approach outperforms other SoTA methods, demonstrating the effectiveness of each module of our proposed method. Code will be available at: https://github.com/chenxuluo/EPC.																	0162-8828	1939-3539				OCT 1	2020	42	10					2624	2641		10.1109/TPAMI.2019.2930258													
J								Zig-Zag Network for Semantic Segmentation of RGB-D Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Image segmentation; Semantics; Computer architecture; Decoding; Image resolution; Feature extraction; Correlation; RGB-D images; semantic segmentation; convolutional neural networks		Semantic segmentation of images requires an understanding of appearances of objects and their spatial relationships in scenes. The fully convolutional network (FCN) has been successfully applied to recognize objects' appearances, which are represented with RGB channels. Images augmented with depth channels provide more understanding of the geometric information of the scene in an image. In this paper, we present a multiple-branch neural network to utilize depth information to assist in the semantic segmentation of images. Our approach splits the image into layers according to the "scene-scale". We introduce the context-aware receptive field (CARF), which provides better control of the relevant context information of learned features. Each branch of the network is equipped with CARF to adaptively aggregate the context information of image regions, leading to a more focused domain that is easier to learn. Furthermore, we propose a new zig-zag architecture to exchange information between the feature maps at different levels, augmented by the CARFs of the backbone network and decoder network. With the flexible information propagation allowed by our zig-zag network, we enrich the context information of feature maps for the segmentation. We show that the zig-zag network achieves state-of-the-art performances on several public datasets.																	0162-8828	1939-3539				OCT 1	2020	42	10					2642	2655		10.1109/TPAMI.2019.2923513													
J								Globally Optimal Inlier Set Maximization for Atlanta World Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Estimation; Gravity; Cameras; Lasers; Optimization; Layout; Atlanta frame; RGB-D image; branch-and-bound; global optimization; scene understanding	CONSENSUS; SPACE	In this work, we describe man-made structures via an appropriate structure assumption, called the Atlanta world assumption, which contains a vertical direction (typically the gravity direction) and a set of horizontal directions orthogonal to the vertical direction. Contrary to the commonly used Manhattan world assumption, the horizontal directions in Atlanta world are not necessarily orthogonal to each other. While Atlanta world can encompass a wider range of scenes, this makes the search space much larger and the problem more challenging. Our input data is a set of surface normals, for example, acquired from RGB-D cameras or 3D laser scanners, as well as lines from calibrated images. Given this input data, we propose the first globally optimal method of inlier set maximization for Atlanta direction estimation. We define a novel search space for Atlanta world, as well as its parametrization, and solve this challenging problem using a branch-and-bound (BnB) framework. To alleviate the computational bottleneck in BnB, i.e., the bound computation, we present two bound computation strategies: rectangular bound and slice bound in an efficient measurement domain, i.e., the extended Gaussian image (EGI). In addition, we propose an efficient two-stage method which automatically estimates the number of horizontal directions of a scene. Experimental results with synthetic and real-world datasets have successfully confirmed the validity of our approach.																	0162-8828	1939-3539				OCT 1	2020	42	10					2656	2669		10.1109/TPAMI.2019.2909863													
J								Clouds of Oriented Gradients for 3D Detection of Objects, Surfaces, and Indoor Scene Layouts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Layout; Two dimensional displays; Solid modeling; Feature extraction; Detectors; Object detection; 3D scene understanding; object detection; room layout estimation; structured prediction; cascaded classification	SUPPORT	We develop new representations and algorithms for three-dimensional (3D) object detection and spatial layout prediction in cluttered indoor scenes. We first propose a clouds of oriented gradient (COG) descriptor that links the 2D appearance and 3D pose of object categories, and thus accurately models how perspective projection affects perceived image gradients. To better represent the 3D visual styles of large objects and provide contextual cues to improve the detection of small objects, we introduce latent support surfaces. We then propose a "Manhattan voxel" representation which better captures the 3D room layout geometry of common indoor environments. Effective classification rules are learned via a latent structured prediction framework. Contextual relationships among categories and layout are captured via a cascade of classifiers, leading to holistic scene hypotheses that exceed the state-of-the-art on the SUN RGB-D database.																	0162-8828	1939-3539				OCT 1	2020	42	10					2670	2683		10.1109/TPAMI.2019.2923201													
J								NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Benchmark testing; Cameras; Deep learning; Semantics; Lighting; Skeleton; Activity understanding; video analysis; 3D action recognition; RGB plus D vision; deep learning; large-scale benchmark	ACTION RECOGNITION; ACTIONLET ENSEMBLE; FEATURES	Research on depth-based human activity analysis achieved outstanding performance and demonstrated the effectiveness of 3D representation for action recognition. The existing depth-based and RGB+D-based action recognition benchmarks have a number of limitations, including the lack of large-scale training samples, realistic number of distinct class categories, diversity in camera views, varied environmental conditions, and variety of human subjects. In this work, we introduce a large-scale dataset for RGB+D human action recognition, which is collected from 106 distinct subjects and contains more than 114 thousand video samples and 8 million frames. This dataset contains 120 different action classes including daily, mutual, and health-related activities. We evaluate the performance of a series of existing 3D activity analysis methods on this dataset, and show the advantage of applying deep learning methods for 3D-based human action recognition. Furthermore, we investigate a novel one-shot 3D activity recognition problem on our dataset, and a simple yet effective Action-Part Semantic Relevance-aware (APSR) framework is proposed for this task, which yields promising results for recognition of the novel action classes. We believe the introduction of this large-scale dataset will enable the community to apply, adapt, and develop various data-hungry learning techniques for depth-based and RGB+D-based human activity understanding.																	0162-8828	1939-3539				OCT 1	2020	42	10					2684	2701		10.1109/TPAMI.2019.2916873													
J								The ApolloScape Open Dataset for Autonomous Driving and Its Application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Three-dimensional displays; Semantics; Task analysis; Videos; Labeling; Two dimensional displays; Image segmentation; Autonomous driving; large-scale datasets; scene; lane parsing; self localization; 3D understanding	POSE	Autonomous driving has attracted tremendous attention especially in the past few years. The key techniques for a self-driving car include solving tasks like 3D map construction, self-localization, parsing the driving road and understanding objects, which enable vehicles to reason and act. However, large scale data set for training and system evaluation is still a bottleneck for developing robust perception models. In this paper, we present the ApolloScape dataset [1] and its applications for autonomous driving. Compared with existing public datasets from real scenes, e.g., KITTI [2] or Cityscapes [3] , ApolloScape contains much large and richer labelling including holistic semantic dense point cloud for each site, stereo, per-pixel semantic labelling, lanemark labelling, instance segmentation, 3D car instance, high accurate location for every frame in various driving videos from multiple sites, cities and daytimes. For each task, it contains at lease 15x larger amount of images than SOTA datasets. To label such a complete dataset, we develop various tools and algorithms specified for each task to accelerate the labelling process, such as joint 3D-2D segment labeling, active labelling in videos etc. Depend on ApolloScape, we are able to develop algorithms jointly consider the learning and inference of multiple tasks. In this paper, we provide a sensor fusion scheme integrating camera videos, consumer-grade motion sensors (GPS/IMU), and a 3D semantic map in order to achieve robust self-localization and semantic segmentation for autonomous driving. We show that practically, sensor fusion and joint learning of multiple tasks are beneficial to achieve a more robust and accurate system. We expect our dataset and proposed relevant algorithms can support and motivate researchers for further development of multi-sensor fusion and multi-task learning in the field of computer vision.																	0162-8828	1939-3539				OCT 1	2020	42	10					2702	2719		10.1109/TPAMI.2019.2926463													
J								Detailed Surface Geometry and Albedo Recovery from RGB-D Video under Natural Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE										Lighting; Shape; Geometry; Sensors; Image color analysis; Cameras; Color; Depth enhancement; intrinsic decomposition; shape from shading	INTRINSIC IMAGE DECOMPOSITION; PHOTOMETRIC STEREO; MULTIVIEW; RETINEX; SHAPE	This article presents a novel approach for depth map enhancement from an RGB-D video sequence. The basic idea is to exploit the photometric information in the color sequence to resolve the inherent ambiguity of shape from shading problem. Instead of making any assumption about surface albedo or controlled object motion and lighting, we use the lighting variations introduced by casual object movement. We are effectively calculating photometric stereo from a moving object under natural illuminations. One of the key technical challenges is to establish correspondences over the entire image set. We, therefore, develop a lighting insensitive robust pixel matching technique that out-performs optical flow method in presence of lighting variations. An adaptive reference frame selection procedure is introduced to get more robust to imperfect lambertian reflections. In addition, we present an expectation-maximization framework to recover the surface normal and albedo simultaneously, without any regularization term. We have validated our method on both synthetic and real datasets to show its superior performance on both surface details recovery and intrinsic decomposition.																	0162-8828	1939-3539				OCT 1	2020	42	10					2720	2734		10.1109/TPAMI.2019.2955459													
J								MRF Model-Based Estimation of Camera Parameters and Detection of Underwater Moving Objects	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										EM algorithm; Feature Extraction; Iterated Conditional Mode; MAP Estimation; Model Camera Calibration; Multi-Resolution framework; Simulated annealing; Spatio Temporal Markov Random Field Model	TRACKING; IMAGE	The detection of underwater objects in a video is a challenging problem particularly when both the camera and the objects are in motion. In this article, this problem has been conceived as an incomplete data problem and hence the problem is formulated in expectation maximization (EM) framework. In the E-step, the frame labels are the maximum a posterior (MAP) estimates, which are obtained using simulated annealing (SA) and the iterated conditional mode (ICM) algorithm. In the M-step, the camera model parameters, both intrinsic and extrinsic, are estimated. In case of parameter estimation, the features are extracted at coarse and fine scale. In order to continuously detect the object in different video frames, EM algorithm is repeated for each frame. The performance of the proposed scheme has been compared with other algorithms and the proposed algorithm is found to outperform.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					1	29		10.4018/IJCINI.2020100101													
J								Adaptive Parameter Estimation of IIR System-Based WSN Using Multihop Diffusion in Distributed Approach	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										Diffusion LMS; Distributed Estimation; IIR Systems; LMS; Multihop Diffusion; Parameter Estimation; Sparse Network; Wireless Sensor Network	LMS	Distributed estimation of parameters in wireless sensor networks is taken into consideration to reduce the communication overhead of the network which makes the sensor system energy efficient. Most of the distributed approaches in literature, the sensor system is modeled with finite impulse response as it is inherently stable. Whereas in real time applications of WSN like target tracking, fast rerouting requires, infinite impulse response system (IIR) is used to model and that has been chosen in this work. It is assumed that every sensor node is equipped with IIR adaptive system. The diffusion least mean square (DLMS) algorithm is used to estimate the parameters of the IIR system where each node in the network cooperates themselves. In a sparse WSN, the performance of a DLMS algorithm reduces as the degree of the node decreases. In order to increase the estimation accuracy with a smaller number of iterations, the sensor node needs to share their information with more neighbors. This is feasible by communicating each node with multi-hop nodes instead of one-hop only. Therefore the parameters of an IIR system is estimated in distributed sparse sensor network using multihop diffusion LMS algorithm. The simulation results exhibit superior performance of the multihop diffusion LMS over non-cooperative and conventional diffusion algorithms.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					30	41		10.4018/IJCINI.2020100102													
J								Scalable Recommendation Using Large Scale Graph Partitioning With Pregel and Giraph	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										Data Analytics; Giraph; Pregel; Social Big Data; Social Recommendation	CHALLENGES	Social Big Data is generated by interactions of connected users on social network. Sharing of opinions and contents amongst users, reviews of users for products, result in social Big Data. If any user intends to select products such as movies, books, etc., from e-commerce sites or view any topic or opinion on social networking sites, there are a lot of options and these options result in information overload. Social recommendation systems assist users to make better selection as per their likings. Recent research works have improved recommendation systems by using matrix factorization, social regularization or social trust inference. Furthermore, these improved systems are able to alleviate cold start and sparsity, but not efficient for scalability. The main focus of this article is to improve scalability in terms of locality and throughput and provides better recommendations to users with large-scale data in less response time. In this article, the social big graph is partitioned and distributed on different nodes based on Pregel and Giraph. In the proposed approach ScaleRec, partitioning is based on direct as well as indirect trust between users and comparison with state-of-the-art approaches proves that statistically better partitioning quality is achieved using proposed approach. In ScaleRec, hyperedge and transitive closure are used to enhance social trust amongst users. Experiment analysis on standard datasets such as Epinions and LiveJournal proves that better locality and recommendation accuracy is achieved by using ScaleRec.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					42	61		10.4018/IJCINI.2020100103													
J								Efficient Regularization Framework for Histopathological Image Classification Using Convolutional Neural Networks	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										Convolutional Neural Network; Deep Learning; Ensemble Learning; Histopathology; Lymphoma; MobileNet	FUTURE	Deep learning methods are characterized by their capacity to learn data representation compared to the traditional machine learning algorithms. However, these methods are prone to overfitting on small volumes of data. The objective of this research is to overcome this limitation by improving the generalization in the proposed deep learning framework based on various techniques: data augmentation, small models, optimizer selection, and ensemble learning. For ensembling, the authors used selected models from different checkpoints and both voting and unweighted average methods for combination. The experimental study on the lymphomas histopathological dataset highlights the efficiency of the MobileNet2 network combined with the stochastic gradient descent (SGD) optimizer in terms of generalization. The best results have been achieved by the combination of the best three checkpoint models (98.67% of accuracy). These findings provide important insights into the efficiency of the checkpoint ensemble learning method for histopathological image classification.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					62	81		10.4018/IJCINI.2020100104													
J								A Multi-Agent Approach to Segment Arabic Handwritten Text Lines	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										Connected Components; Diacritic Points; Handwritten Arabic Document; Intersection Points; Multi-Agent System; Overlapping Situation; Text Lines Segmentation	DOCUMENTS; RECOGNITION	In text line segmentation, there are three classes of methods: either by sorting physical units such as pixels or connected components (CC) constituting a line or by searching for the baseline of each word and grouping together those who participate in the same line. The third class analyzes the separation locations between the lines. After an overview of lines segmentation approaches, the authors introduced a new method emphasizing its simplicity, speed, and originality. The proposed approach detects the starting components of the lines in the first step. In the second step, it defines a number of agents that start the segmentation process from their starting points between the starting components of lines. Each agent aims to reach the left edge of the document through the correct path. The algorithm used by the agents is based on the morphological process, characteristics of the Arabic manuscript and a communication system. The experimental results on an Arabic dataset show that this approach is an effective solution for the segmentation of lines from different Arabic manuscripts.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					82	100		10.4018/IJCINI.2020100105													
J								Classification of Eyes Based on Fuzzy Logic	INTERNATIONAL JOURNAL OF COGNITIVE INFORMATICS AND NATURAL INTELLIGENCE										Classification; Corner Detector; Defuzzification; Eye Detection; Eye Segmentation; Fuzzification; Fuzzy Controller; Inference System	SYSTEM	The systems of eye classification in an image are indispensable in several domains. To better find the class of membership of the eye in a minimal time, the classic methods of detection are inadequate. Fuzzy logic is considered to be an effective technique for solving an eye classification problem. This article proposes a fuzzy approach for eye classification. The tasks of classification are realized in two steps. In the first step, the characteristic points of the image are extracted in order to locate the eye. These characteristic points allow generating a representative model of the eye. In the second step, the detected eyes have to pass by a fuzzy controller containing several parts: Fuzzification, inference rules, and defuzzification. Finally, the system gives the degree of membership of the detected eyes to each class in the database.																	1557-3958	1557-3966				OCT-DEC	2020	14	4					101	112		10.4018/IJCINI.2020100106													
J								Fast and Accurate Langevin Simulations of Stochastic Hodgkin-Huxley Dynamics	NEURAL COMPUTATION											ION CHANNELS; NERVE MEMBRANE; NOISE; APPROXIMATION; RELIABILITY; REDUCTIONS; KINETICS; BEHAVIOR; MODELS	Fox and Lu introduced a Langevin framework for discrete-time stochastic models of randomly gated ion channels such as the HodgkinHuxley (HH) system. They derived a Fokker-Planck equation with state-dependent diffusion tensor D and suggested a Langevin formulation with noise coefficient matrix S such that SS inverted perpendicular = D. Subsequently, several authors introduced a variety of Langevin equations for the HH system. In this article, we present a natural 14-dimensional dynamics for the HH system in which each directed edge in the ion channel state transition graph acts as an independent noise source, leading to a 14 x 28 noise coefficient matrix S. We show that (1) the corresponding 14D system of ordinary differential equations is consistent with the classical 4D representation of the HH system; (2) the 14D representation leads to a noise coefficient matrix S that can be obtained cheaply on each time step, without requiring a matrix decomposition; (3) sample trajectories of the 14D representation are pathwise equivalent to trajectories of Fox and Lu's system, aswell as trajectories of several existing Langevin models; (4) our 14D representation (and those equivalent to it) gives the most accurate interspike interval distribution, not only with respect to moments but under both the L-1 and L-infinity metric-space norms; and (5) the 14D representation gives an approximation to exactMarkov chain simulations that are as fast and as efficient as all equivalent models. Our approach goes beyond existing models, in that it supports a stochastic shielding decomposition that dramatically simplifies S with minimal loss of accuracy under both voltage- and current-clamp conditions.																	0899-7667	1530-888X				OCT	2020	32	10					1775	1835		10.1162/neco_a_01312													
J								A Predictive-Coding Network That Is Both Discriminative and Generative	NEURAL COMPUTATION											VISUAL-CORTEX; BACKPROPAGATION	Predictive coding (PC) networks are a biologically interesting class of neural networks. Their layered hierarchy mimics the reciprocal connectivity pattern observed in the mammalian cortex, and they can be trained using local learning rules that approximate backpropagation (Bogacz,2017). However, despite having feedback connections that enable information to flow down the network hierarchy, discriminative PC networks are not typically generative. Clamping the output class and running the network to equilibrium yields an input sample that usually does not resemble the training input. This letter studies this phenomenon and proposes a simple solution that promotes the generation of input samples that resemble the training inputs. Simple decay, a technique already in wide use in neural networks, pushes the PC network toward a unique minimum two-norm solution, and that unique solution provably (for linear networks) matches the training inputs. The method also vastly improves the samples generated for nonlinear networks, as we demonstrate on MNIST.																	0899-7667	1530-888X				OCT	2020	32	10					1836	1862		10.1162/neco_a_01311													
J								Binless Kernel Machine: Modeling Spike Train Transformation for Cognitive Neural Prostheses	NEURAL COMPUTATION											TIME-RESCALING THEOREM; IDENTIFICATION; FRAMEWORK; ENSEMBLE; SPACE	Modeling spike train transformation among brain regions helps in designing a cognitive neural prosthesis that restores lost cognitive functions. Various methods analyze the nonlinear dynamic spike train transformation between two cortical areas with low computational eficiency. The application of a real-time neural prosthesis requires computational eficiency, performance stability, and better interpretation of the neural firing patterns that modulate target spike generation. We propose the binless kernel machine in the point-process framework to describe nonlinear dynamic spike train transformations. Our approach embeds the binless kernel to eficiently capture the feedforward dynamics of spike trains and maps the input spike timings into reproducing kernel Hilbert space (RKHS). An inhomogeneous Bernoulli process is designed to combine with a kernel logistic regression that operates on the binless kernel to generate an output spike train as a point process. Weights of the proposed model are estimated by maximizing the log likelihood of output spike trains in RKHS, which allows a global-optimal solution. To reduce computational complexity, we design a streaming-based clustering algorithm to extract typical and important spike train features. The cluster centers and their weights enable the visualization of the important input spike train patterns that motivate or inhibit output neuron firing. We test the proposed model on both synthetic data and real spike train data recorded from the dorsal premotor cortex and the primary motor cortex of a monkey performing a center-out task. Performances are evaluated by discrete-time rescaling Kolmogorov-Smirnov tests. Our model outperforms the existing methods with higher stability regardless of weight initialization and demonstrates higher eficiency in analyzing neural patterns from spike timing with less historical input (50%). Meanwhile, the typical spike train patterns selected according to weights are validated to encode output spike from the spike train of single-input neuron and the interaction of two input neurons.																	0899-7667	1530-888X				OCT	2020	32	10					1863	1900		10.1162/neco_a_01306													
J								Modal Principal Component Analysis	NEURAL COMPUTATION											PROJECTION-PURSUIT APPROACH; DENSITY-FUNCTION; ROBUST; REGRESSION; ESTIMATOR	Principal component analysis (PCA) is a widely used method for data processing, such as for dimension reduction and visualization. Standard PCA is known to be sensitive to outliers, and various robust PCA methods have been proposed. It has been shown that the robustness of many statistical methods can be improved using mode estimation instead of mean estimation, because mode estimation is not significantly affected by the presence of outliers. Thus, this study proposes a modal principal component analysis (MPCA), which is a robust PCA method based on mode estimation. The proposed method finds the minor component by estimating the mode of the projected data points. As a theoretical contribution, probabilistic convergence property, influence function, finite-sample breakdown point, and its lower bound for the proposed MPCA are derived. The experimental results show that the proposed method has advantages over conventional methods.																	0899-7667	1530-888X				OCT	2020	32	10					1901	1935		10.1162/neco_a_01308													
J								Multiview Alignment and Generation in CCA via Consistent Latent Encoding	NEURAL COMPUTATION												Multiview alignment, achieving one-to-one correspondence of multiview inputs, is critical in many real-world multiview applications, especially for cross-view data analysis problems. An increasing amount of work has studied this alignment problem with canonical correlation analysis (CCA). However, existing CCA models are prone to misalign the multiple views due to either the neglect of uncertainty or the inconsistent encoding of the multiple views. To tackle these two issues, this letter studies multiview alignment from a Bayesian perspective. Delving into the impairments of inconsistent encodings, we propose to recover correspondence of the multiview inputs by matching the marginalization of the joint distribution of multiview random variables under different forms of factorization. To realize our design, we present adversarial CCA (ACCA), which achieves consistent latent encodings by matching the marginalized latent encodings through the adversarial training paradigm. Our analysis, based on conditional mutual information, reveals that ACCA is flexible for handling implicit distributions. Extensive experiments on correlation analysis and cross-view generation under noisy input settings demonstrate the superiority of our model.																	0899-7667	1530-888X				OCT	2020	32	10					1936	1979		10.1162/neco_a_01309													
J								Analysis of Regression Algorithms with Unbounded Sampling	NEURAL COMPUTATION											LEAST-SQUARES; LEARNING RATES	In this letter, we study a class of the regularized regression algorithms when the sampling process is unbounded. By choosing different loss functions, the learning algorithms can include a wide range of commonly used algorithms for regression. Unlike the prior work on theoretical analysis of unbounded sampling, no constraint on the output variables is specified in our setting. By an elegant error analysis, we prove consistency and finite sample bounds on the excess risk of the proposed algorithms under regular conditions.																	0899-7667	1530-888X				OCT	2020	32	10					1980	1997		10.1162/neco_a_01313													
J								Active Learning of Bayesian Linear Models with High-Dimensional Binary Features by Parameter Confidence-Region Estimation	NEURAL COMPUTATION											WORKING SET SELECTION	In this letter, we study an active learning problem for maximizing an unknown linear function with high-dimensional binary features. This problem is notoriously complex but arises in many important contexts. When the sampling budget, that is, the number of possible function evaluations, is smaller than the number of dimensions, it tends to be impossible to identify all of the optimal binary features. Therefore, in practice, only a small number of such features are considered, with the majority kept fixed at certain default values, which we call theworking set heuristic. The main contribution of this letter is to formally study the working set heuristic and present a suite of theoretically robust algorithms for more efficient use of the sampling budget. Technically, we introduce a novel method for estimating the confidence regions of model parameters that is tailored to active learning with high-dimensional binary features. We provide a rigorous theoretical analysis of these algorithms and prove that a commonly used working set heuristic can identify optimal binary features with favorable sample complexity. We explore the performance of the proposed approach through numerical simulations and an application to a functional protein design problem.																	0899-7667	1530-888X				OCT	2020	32	10					1998	2031		10.1162/neco_a_01310													
J								Active Learning for Enumerating Local Minima Based on Gaussian Process Derivatives	NEURAL COMPUTATION											OPTIMIZATION; SEARCH	We study active learning (AL) based on gaussian processes (GPs) for efficiently enumerating all of the local minimum solutions of a black-box function. This problem is challenging because local solutions are characterized by their zero gradient and positive-definite Hessian properties, but those derivatives cannot be directly observed. We propose a new AL method in which the input points are sequentially selected such that the confidence intervals of the GP derivatives are effectively updated for enumerating local minimum solutions. We theoretically analyze the proposed method and demonstrate its usefulness through numerical experiments.																	0899-7667	1530-888X				OCT	2020	32	10					2032	2068		10.1162/neco_a_01307													
J								A two-stage machine learning framework to predict heart transplantation survival probabilities over time with a monotonic probability constraint	DECISION SUPPORT SYSTEMS										Data mining; Heart transplant; Isotonic regression; Medical informatics; Multi-period forecasting; United network for organ sharing	ISOTONIC REGRESSION; ANALYTICS	The overarching goal of this paper is to develop a modeling framework that can be used to obtain personalized, data-driven and monotonically constrained probability curves. This research is motivated by the important problem of improving the predictions for organ transplantation outcomes, which can inform updates made to organ allocation protocols, post-transplantation care pathways, and clinical resource utilization. In pursuit of our overarching goal and motivating problem, we propose a novel two-stage machine learning-based framework for obtaining monotonic probabilities over time. The first stage uses the standard approach of using independent machine learning models to predict transplantation outcomes for each time-period of interest. In the second stage, we calibrate the survival probabilities over time using isotonic regression. To show the utility of our framework, we applied it on a national registry of U.S. heart transplants from 1987 to 2016. The first stage produces an area under the receiver operating curve (AUC) between 0.60 and 0.71 for years 1-10. While the 1-year prediction AUC result is comparable to the reported results in the literature, our 10-year AUC of 0.70 is higher than the current state-of-the-art results. More importantly, we show that the application of isotonic regression to calibrate the survival probabilities for each patient over the 10-year period guarantees monotonicity, while capitalizing on the data-driven and individualized nature of machine learning models. To promote future research, our code and analysis are publicly available on GitHub. Furthermore, we created a web app titled "H-TOP: Heart Transplantation Outcome Predictor" to encourage practical applications.																	0167-9236	1873-5797				OCT	2020	137								113363	10.1016/j.dss.2020.113363													
J								A data-driven methodology for the automated configuration of online algorithms	DECISION SUPPORT SYSTEMS										Automated decision making; Data-driven optimization; Automated algorithm configuration; Online optimization; Simulated annealing; Lean decision making	BIN-PACKING; COMBINATORIAL OPTIMIZATION; FIXED START; METAHEURISTICS; HEURISTICS; SYSTEMS; JOBS	With the goal of devising algorithms for decision support in operational tasks, we introduce a new methodology for the automated configuration of algorithms for combinatorial online optimization problems. The procedure draws upon available instance data and is capable of recognizing data patterns which prove beneficial to the overall outcome. Since online optimization requires repetitive decision making without complete future information, no online algorithm can be optimal for every instance and it is reasonable to restrict attention to rule-based algorithms. We consider such algorithms in the form of procedures which derive their decisions using a threshold value. Threshold values are computed by evaluating a mathematical term (threshold value expression) composed of the available instance data elements. The goal then consists of determining the structure of the threshold value expression leading to the best algorithm performance. To this end, we employ a simulated annealing scheme returning the most favorable term composition given the available instance data. The resulting methodology can be implemented as part of data-driven decision support systems in order to facilitate knowledge-based decision making. Decision rules are generated in an automated fashion once historical input data is provided. The methodology is successfully instantiated in a series of computational experiments for three classes of combinatorial online optimization problems (scheduling, packing, lot sizing). Results show that automatically configured online algorithms are even capable of substantially outperforming well-known online algorithms in respective problem settings. We attribute this effect to the methodology's capability of integrating instance data into the process of algorithm configuration.																	0167-9236	1873-5797				OCT	2020	137								113343	10.1016/j.dss.2020.113343													
J								An integrated decision analysis methodology based on IF-DEMATEL and IF-ELECTRE for personnel selection	DECISION SUPPORT SYSTEMS										Business analytics; Group decision-making; IF-DEMATEL; IF-ELECTRE; Multicriteria decision-making (MCDM); Personnel selection	HYBRID MCDM APPROACH; FUZZY TOPSIS; OUTRANKING METHODS; MANAGER SELECTION; PROJECT MANAGERS; MAKING APPROACH; SUPPLY CHAIN; PERFORMANCE; SYSTEM; ANP	Due to its complex, time-demanding, and multifaceted structure, personnel selection is considered as a multi-criteria decision-making problem, the framework of which includes both qualitative and quantitative criteria. Although various techniques have been proposed to address this problem in various industries, a robust methodology that is capable of explicitly considering the presence of uncertainty/vagueness is still a necessity. Therefore, with this study, we propose an integrated methodology that leverages Decision Making Trial and Evaluation Laboratory (DEMATEL) and Elimination and Choice Expressing the Reality (ELECTRE) methods under Intuitionistic Fuzzy (IF) environment. Within the proposed methodology, firstly, the IF-DEMATEL method is employed to obtain the importance-weights of the elicited criteria, and then the IF-ELECTRE method is formulated and applied to rank the candidates based on cardinal and ordinal evaluations. To illustrate the viability of the proposed methodology, an application case is performed at an air-filter manufacturing company. Hence, this study aims to contribute to the theoretical and practical extent of the related literature by proposing and illustrating an integrated analytics methodology capable of addressing personnel selection decisions in complex and imprecise real-world scenarios.																	0167-9236	1873-5797				OCT	2020	137								113360	10.1016/j.dss.2020.113360													
J								Minimizing the data quality problem of information systems: A process-based method	DECISION SUPPORT SYSTEMS										Data quality; Information system; Petri net; Optimization model; Process model	SELECTION; IMPACT; RISK	The low quality of data in information systems poses enormous risks to business operations and decision making. In this paper, a single-period resource allocation problem for controlling the information system's data quality problem is considered. We develop a Data-Quality-Petri net to capture the process through which data quality problem generates, propagates, and accumulates in the information system. The net considers not only the factors leading to the production of the data quality problem by the data operation nodes and the data flow structure, but also the data transfer ratio of the nodes. Then, we propose a nonlinear programming optimization model with control resource constraints. The result of the model provides an optimal strategy to allocate resources for minimizing the expected data quality problem of an information system. Further, we examine the impact of the data flow structure on optimal resource allocation. The result shows that the optimal resource input level for a data operation node is proportional to its potential for downstream propagation. A warehouse management system of an e-commerce company is utilized to illustrate the model. Our study provides a method for data managers to control the information system's data quality problem by employing a process perspective.																	0167-9236	1873-5797				OCT	2020	137								113381	10.1016/j.dss.2020.113381													
J								Novice digital service designers' decision-making with decision aids - A comparison of taxonomy and tags	DECISION SUPPORT SYSTEMS										Cognitive effort; Decision aid; Decision style; Tags; Taxonomy	COGNITIVE EFFORT; INDIVIDUAL-DIFFERENCES; DATA QUALITY; E-COMMERCE; FIT; PATTERNS; STYLES; CHOICE; TASK; CLASSIFICATION	Digital services are a key driver of contemporary businesses. In order to scale the implementation of design-centric development processes, companies increasingly assign design work to design novices. As design novices have limited design knowledge and experience, they are challenged to select adequate design techniques throughout the entire lifecycle of digital services. Thus, providing decision aids to design novices is becoming increasingly important. In this research, we investigate taxonomy-based and tags-based decision aids. We draw on cognitive fit theory to construct a research model explaining the relationship between different decision aids and selection accuracy while considering the cognitive effort and the decision styles of novice designers. To test our hypotheses, we conducted a between-subject laboratory experiment with 195 subjects. Our experimental results provide extensive support to our hypotheses. Taxonomy-based decision aids outperform tags-based decision aids concerning selection accuracy mediated by cognitive effort. Furthermore, the results suggest rational decision style as a moderator in the relationship between taxonomy-based decision aids and selection accuracy. Our results have practical implications: First, taxonomy-based decision aids should be primarily leveraged on decision support platforms supporting design processes. Second, design novices' decision style and cognitive effort are influential factors when developing decision aids to support digital service design processes.																	0167-9236	1873-5797				OCT	2020	137								113367	10.1016/j.dss.2020.113367													
J								Is user-generated content always helpful? The effects of online forum browsing on consumers' travel purchase decisions	DECISION SUPPORT SYSTEMS											WORD-OF-MOUTH; INFORMATION OVERLOAD; SOCIAL COMMERCE; PARTICIPATION; BEHAVIOR; MEMBERS; IMPACT; EXPLORATION; COMMUNITY; DILUTION	This study examines how the unique information environment of online forums affects consumers' information acquisitions, and further impacts their purchase behavior. Based on the information foraging theory, we hypothesize that the relevant information patches in online forums facilitate consumers' information acquisition processes and increase purchase intention. However, the mixed information scents within online forums could also lead to fewer or no purchases because of distraction from unrelated information. To test the proposed hypotheses, we empirically analyze a unique data set of consumers' webpage browsing histories and purchase behavior from a major online travel agency in China. The findings of this study provide insights into how online forum browsing behavior affects consumers' purchase decisions. The findings also offer important implications for online forum design.																	0167-9236	1873-5797				OCT	2020	137								113368	10.1016/j.dss.2020.113368													
J								Decision support system for a heat-recovery section with equipment degradation	DECISION SUPPORT SYSTEMS										Mathematical modeling; Maintenance decisions; Heat recovery; Real-time optimization; Industrial DSS	DATA RECONCILIATION	In the framework of Industry 4.0, decision support systems (DSS) are an essential part in the process of converting information into managerial actions. This paper proposes a specific DSS to improve the daily operation of an industrial heat-recovery section (a network of heat exchangers) in a fiber-production factory. In this process, the aim is to optimize the resource utilization in real time while satisfying a set of production constraints. The operational decisions to be taken by the network operators is to set up the heat-source allocation to heat exchangers. Furthermore, the heat transfer decreases over time due to fouling in the exchangers, so an additional decision to take is which exchanger to clean and when. The proposed model-based DSS builds upon a rigorous mathematical representation of the network, integrating continuous operation with the discrete decisions on maintenance. Then, a mixed-integer nonlinear optimization, solved in real time, drives the analysis and choice phases to fulfill product specifications according to an economic criterion. In this way, the proposed DSS not only provides the user with a right allocation of heat sources to exchangers, but also suggests which of them are potentially beneficial to be cleaned.																	0167-9236	1873-5797				OCT	2020	137								113380	10.1016/j.dss.2020.113380													
J								Three-stage reject inference learning framework for credit scoring using unsupervised transfer learning and three-way decision theory	DECISION SUPPORT SYSTEMS										Reject inference; Unsupervised transfer learning; Three-way decision theory; Credit scoring	AUGMENTATION	There has been significant research into reject inference, with several statistical methods and machine learning techniques having been employed to infer the possible repayment behavior of rejected credit applicants. This study proposes a novel three-stage reject inference learning framework using unsupervised transfer learning and three-way decision theory that integrates: (1) the rejected credit sample selection using three-way decision theory, (2) higher-level representations to transfer learning from both accepted and selected rejected credit samples; and (3) credit scoring using the reconstructed accepted credit samples. This method was found to both perform well for reject inference and handle negative transfer learning problems. The numerical results were validated on Chinese credit data, the results from which demonstrated the superiority of the proposed reject inference method for credit risk management applications.																	0167-9236	1873-5797				OCT	2020	137								113366	10.1016/j.dss.2020.113366													
J								Facilitating Complex Product Choices on E-commerce Sites: An Unconscious Thought and Circadian Preference Perspective	DECISION SUPPORT SYSTEMS										Unconscious thought theory; Online shopping; Consumer choice; Circadian preference; Human-computer interaction	INDIVIDUAL-DIFFERENCES; DECISION-MAKING; USER ACCEPTANCE; INHIBITORY CONTROL; CONSCIOUS THOUGHT; AGE-DIFFERENCES; WORKING-MEMORY; TIME; ATTENTION; BENEFITS	E-commerce consumers often face complex product choices and have to make decisions at various times of the day. Extant research has primarily focused on providing decision aids and eliminating "distracting" features to help consumers' conscious thought when making complex decisions. Our research adopts a novel perspective that consumers' unconscious thought may have some advantages and be exploited to help consumers make complex purchase decisions, especially when one's circadian preference (optimal time of day for decision-making, e.g., morning vs. evening) is not met. Drawing on the Unconscious Thought Theory (UTT), we developed two hypotheses regarding the effects of consumers' unconscious thought and its interaction with consumer circadian preference on decision quality. A controlled experiment was conducted to test our hypotheses. The findings show that unconscious thought outperforms conscious thought for making complex product choices in general and such effects are amplified when there is an asynchrony between one's circadian preference and the time of decision. The new circadian synchrony perspective enriches our understanding of the effects of unconscious thought on decision-making, helps explain the somewhat mixed findings in prior work on UTT, and thus contributes back to the UTT literature. The findings have implications about how unconscious thought can be leveraged to facilitate online shopping, and underscores the importance of considering consumer's circadian preference and time of decision.																	0167-9236	1873-5797				OCT	2020	137								113365	10.1016/j.dss.2020.113365													
J								A novel probabilistic graphic model to detect product defects from social media data	DECISION SUPPORT SYSTEMS										Product defect detection; Social media data; Probabilistic graphic model; Text analysis	CUSTOMER SATISFACTION; SERVICE QUALITY; ONLINE; REVIEWS; INTELLIGENCE; PREDICTION; DISCOVERY; ANALYTICS	Product defects are a major concern for manufacturers and customers. Detecting product defects is vital for manufacturers to prevent enormous product failure costs. As the surge of social media is in vogue, social media data become an important information source for manufacturers to collect defect information. In this study, we propose a novel probabilistic graphic model to discover defects from social media data. We first use three filters, namely, sentiment filter, component-symptom filter and similarity filter, to select informative data. Second, we analyze the remaining data via the proposed probabilistic graphic model and identify defect-related data. Our method provides detailed defect information including defect types, defective components and defect symptoms which is omitted by previous research. A case study in the automobile industry validates the effectiveness and superior performance of our method compared to prior approaches.																	0167-9236	1873-5797				OCT	2020	137								113369	10.1016/j.dss.2020.113369													
J								Real-time iris segmentation and its implementation on FPGA	JOURNAL OF REAL-TIME IMAGE PROCESSING										Pupil segmentation; Pupil localization; Region properties	HOUGH TRANSFORM; LOCALIZATION; ARCHITECTURE; RECOGNITION; DESIGN	This paper presents a real-time iris segmentation technique that is well suited to a fast implementation on an FPGA. One major hurdle associated with iris segmentation techniques is the use of iterative processes that lead to expensive hardware implementations. To circumvent this, the proposed algorithm uses the sign image obtained from subtracting the background, along with morphological operators to localise the pupil. The outer boundary is located by first normalising a selected image region that contains the iris, and then using a first-order gradient operator. The proposed non-iterative algorithm is implemented on an FPGA. Four near infrared (NIR) iris public databases, namely: CASIA-IrisV3-Lamp, MMU v1.0, ND-IRIS-0405 and NIST ICE 2005, are used to test the proposed algorithm. The proposed method for iris segmentation and normalization gives much better accuracy than the existing state-of-the-art methods implemented on hardware. The proposed realisation requires about 45% fewer logic registers and 52% fewer logic elements than the existing state-of-the-art implementations.																	1861-8200	1861-8219				OCT	2020	17	5					1089	1102		10.1007/s11554-019-00859-w													
J								Real-time adaptive visible and infrared image registration based on morphological gradient and C_SIFT	JOURNAL OF REAL-TIME IMAGE PROCESSING										Visible image; Infrared image; Registration; Morphological gradient; SIFT; Real-time	MUTUAL-INFORMATION; MAXIMIZATION	Since the visible and infrared images have different imaging mechanisms, the difficulty of image registration has greatly increased. The grayscale difference between visible and infrared images is very disadvantageous for extracting feature points in homogenous region, but they both retain the obvious contour edge in the scene. After using the morphological gradient method, the grayscale edge of visible and infrared images can be obtained and their similarity is greatly improved, and their difference may be seen as the difference in brightness or grayscale. Therefore, we proposed a novel algorithm to realise real-time adaptive registration of visible and infrared images using morphological gradient and C_SIFT. Firstly, the morphological gradient method is used to extract the rough edges of visible and infrared images for aligning their visual features as a single similar type. Secondly, the C_SIFT feature detection operator is used to detect and extract feature points from the extracted edges. The C_SIFT uses the centroid method to describe the main direction of feature points, makes rotation invariance feasible. Finally, to verify the effectiveness of the proposed algorithm, we carried out a series of experiments in eight various scenarios. The experimental results show that the proposed algorithm has achieved good experimental results. The registration of visible and infrared images can be completed quickly by the proposed algorithm, and the registration accuracy is satisfactory.																	1861-8200	1861-8219				OCT	2020	17	5					1103	1115		10.1007/s11554-019-00858-x													
J								Scalable implementation of particle filter-based visual object tracking on network-on-chip (NoC)	JOURNAL OF REAL-TIME IMAGE PROCESSING										Particle filter; Object tracking; FPGA; Network-on-chip (NoC); Real-time image processing; Scalability; Low power; Smart camera		Particle filter algorithms have been successfully used in various visual object tracking applications. They handle non-linear model and non-Gaussian noise, but are computationally demanding. In this paper, we propose a scalable implementation of particle filter algorithm for visual object tracking, using scalable interconnect such as network-on-chip on an FPGA platform. Here, several processing elements execute parallelly to handle large number of particles. We propose two designs and implementations, with one optimized for speed and other optimized for area. These implementations can easily support different image sizes, object sizes, and number of particles, without modifying the complete architecture. Multi-target tracking is also demonstrated for four objects. We validated the particle filter-based visual tracking with video feed from a Petalinux-based system. With image size of320x240\ frame rates of 348 fps and 310 fps were achieved for single-object tracking of size17x17nd33x33pixels, respectively, with a reasonable low-power consumption of 1.7 mW/fps on Zynq XC7Z020 (Zedboard) with an operating frequency of 69 MHz. This makes our implementation a good candidate for low-power, visual object tracking using FPGA, especially in low-power, smart camera applications.																	1861-8200	1861-8219				OCT	2020	17	5					1117	1134		10.1007/s11554-018-0841-5													
J								Mass center direction-based decision method for intraprediction in HEVC standard	JOURNAL OF REAL-TIME IMAGE PROCESSING										Mass center direction; Intracoding; Prediction mode; HEVC	FAST CU SIZE; INTRA PREDICTION; PERFORMANCE EVALUATION; ALGORITHM; H.264/AVC; MODES	Increasing the prediction modes and recursive quad-tree structure, can be the reasons for high compression efficiency in high-efficiency video coding (HEVC) standard. For the same reasons, the computational complexity of HEVC is increased compared with the previous standards. One of the parts that impose a high computational load is the intraprediction unit. In this paper, an improved intraprediction mode decision method is presented to accelerate intracoding of HEVC. A mass center direction-based approach is used to find correlation direction of pixels which can effectively eliminate the prediction modes that have low chance to be selected as the best intramode from the rate-distortion optimization computations. According to the founded correlation direction for 4 x 4 blocks, the depth range of coding units can also be reduced to accelerate the intracoding further. The performance of the proposed method evaluated with different test sequences proposed by the joint collaborative team on video coding. The coding results indicate that the proposed method reduces the encoding time significantly as compared with the HM-16.19 reference software with negligible loss of peak signal-to-noise ratio quality.																	1861-8200	1861-8219				OCT	2020	17	5					1153	1168		10.1007/s11554-019-00864-z													
J								GPU acceleration of the KAZE image feature extraction algorithm	JOURNAL OF REAL-TIME IMAGE PROCESSING										Nonlinear scale space; Feature detection; Feature description; GPU acceleration; KAZE features	DIFFUSION; CLASSIFICATION; DESCRIPTORS; PERFORMANCE; DETECTORS; TRACKING	The recently proposed, KAZE image feature detection and description algorithm (Alcantarilla et al. in Proceedings of the British machine vision conference. LNCS, vol 7577, no 6, pp 13.1-13.11,2013) offers significantly improved robustness in comparison to conventional algorithms like SIFT (scale-invariant feature transform) and SURF (speeded-up robust features). The improved robustness comes at a significant computational cost, however, limiting its use for many applications. We report a GPU acceleration of the KAZE algorithm that is significantly faster than its CPU counterpart. Unlike previous reports, our acceleration does not resort to binary descriptors and can serve as a drop-in replacement for CPU-KAZE, SIFT, SURF etc. By achieving nearly tenfold speedup (for a 1920 by 1200 sized image, our Compute Unified Device Architecture (CUDA)-C implementation took around 245 ms on a single GPU in comparison to nearly 2400 ms for a 16-threaded CPU version) without degradation in feature extraction performance, our work expands the applicability of the KAZE algorithm. Additionally, the strategies described here could also prove useful for the GPU implementation of other nonlinear scale-space-based image processing algorithms.																	1861-8200	1861-8219				OCT	2020	17	5					1169	1182		10.1007/s11554-019-00861-2													
J								Efficient cascading of multi-domain image Gaussian noise filters	JOURNAL OF REAL-TIME IMAGE PROCESSING										Image denoising; Multi-domain denoiser; Cascaded filters; White noise	SPARSE; TRANSFORM; DICTIONARY	Image denoising is a well explored but still an active research topic. The focus is usually on achieving higher numerical quality which is theoretically interesting, however, often the factor of computation cost is not considered. Our idea is to employ different image Gaussian noise filters to construct an effective image denoiser, where the deficiency of each filter is compensated with others, while a wide variation of quality versus speed can be achieved. We integrate filters using different cascaded forms and show that if two filters use uncorrelated features, their cascaded form provides a higher quality than each separately. We start with easy-to-implement filters employing pixel- and frequency-domain with different kernel size to construct a fast yet high-quality multi-domain denoiser. Then, we propose more complex denoisers by integrating our cascaded multi-domain denoiser to other state-of-the-art denoising methods. Simulations show that the quality of proposed multi-domain denoiser is significantly higher than its building-blocks. We also show that the proposed multi-domain denoiser can be integrated to state-of-the-art denoisers to from a more effective denoiser, while adding negligible complexity.																	1861-8200	1861-8219				OCT	2020	17	5					1183	1195		10.1007/s11554-019-00868-9													
J								GPU-based chromatic co-occurrence matrices for tracking moving objects	JOURNAL OF REAL-TIME IMAGE PROCESSING										Chromatic co-occurrence matrices; Particle filter; Real time; GPU; Embedded system	VISUAL TRACKING	Generally, a good tracking system requires a huge computation time to localize, with accuracy, the target object. For real-time tracking applications, the running time is a critical factor. In this paper, a GPU implementation of the chromatic co-occurrence matrices (CCM) tracking system is proposed. Indeed, the descriptors based on CCM help to improve the accuracy of the tracking. However, they require a long computation time. To overcome this limitation, a parallel implementation of these matrices based on GPU is incorporated to the tracker. The developed algorithm is then integrated into an embedded system to build a real-time autonomous embedded tracking system. The experimental results show a speed up of 150% in the GPU version of the tracker compared to the CPU version.																	1861-8200	1861-8219				OCT	2020	17	5					1197	1210		10.1007/s11554-019-00874-x													
J								Real-time video freezing detection for 4K UHD videos	JOURNAL OF REAL-TIME IMAGE PROCESSING										No-reference; 4K UHD; Video freezing detection; Real-time; FPGA	QUALITY; JERKINESS	Video frame freezing is a common artifact which can occur during video content delivery due to errors in the video coding process, video transmission, storage or reproduction. This artifact can significantly decrease the end-user Quality of Experience. Therefore, accurate video frame freezing detection is of great importance for different parties involved in video content delivery. In this paper, a new Real-Time no-reference Freezing Detection Algorithm, called the RTFDA, is proposed. As newly video frames are acquired, the RTFDA performs comparison of the current video frame with the corresponding previous one to detect whether video freezing is occurring. The comparison is made by calculating the corresponding subsampled video frames and their pixel-by-pixel absolute difference comparison. The benefit of such approach is twofold: the influence of noise in freezing frames on frame comparison is significantly reduced as well as computational complexity of frame comparison. The RTFDA has a high detection rate with a very low rate of both false-positive and false-negative detections, outperforming four freezing detection algorithms on four different video databases. The proposed implementation on an x86-64 platform achieves real-time performance on 4K Ultra High Definition (UHD) videos by processing 216 frames per second (fps). Apart from that, FPGA implementation is proposed, which has efficient FPGA resource utilization.																	1861-8200	1861-8219				OCT	2020	17	5					1211	1225		10.1007/s11554-019-00873-y													
J								Hybrid stopping model-based fast PU and CU decision for 3D-HEVC texture coding	JOURNAL OF REAL-TIME IMAGE PROCESSING										3D High-Efficiency Video Coding; Prediction unit; Coding unit; Rate distortion cost; Hybrid stopping model	MULTIVIEW VIDEO; DEPTH; SELECTION; MAP	As an extension of High-Efficiency Video Coding (HEVC) standard, 3D-HEVC needs to encode multiple texture views and depth maps, which further increases the computational complexity. To reduce the complexity of dependent texture view coding, a fast prediction unit (PU) and coding unit (CU) decision method is proposed for 3D-HEVC based on hybrid stopping model. The inter-view correlation is used as a priori information to roughly predict the possible optimal PU and CU sizes. Then, by exploiting the encoded posterior information, the rate distortion cost correlation and the code block flag, the optimal PU and CU are further examined as being optimal or not. Experimental results show that the proposed fast PU and CU decision method achieves 52.7% encoding time saving on average with negligible loss of coding efficiency for 3D-HEVC-dependent texture view coding.																	1861-8200	1861-8219				OCT	2020	17	5					1227	1238		10.1007/s11554-019-00876-9													
J								A novel unified method for the fast computation of discrete image moments on grayscale images	JOURNAL OF REAL-TIME IMAGE PROCESSING										Feature extraction; Discrete image moments; Moment calculation; Fast algorithms	PATTERN-RECOGNITION; RECURSIVE COMPUTATION; ACCURATE COMPUTATION; TCHEBICHEF MOMENT; ZERNIKE MOMENTS; INVARIANTS; EFFICIENT	We proposed a new method to compute the discrete image moments in this paper. By simple mathematical deduction, the discrete image moments can be transformed into first-order moments. Therefore, the fast algorithm for first-order moments' calculation can be used to compute discrete image moments. We also design an efficient computation structure based on systolic array to implement this approach. Since our method does not use the moment kernel polynomials' properties in the calculation process, the proposed method can be used to compute any discrete image moments in the same way. The presented algorithm has several advantages such as regular and simple computation structure, without multiplication, independent of the image's intensity distribution, applicable to any discrete moment family. Various experiments demonstrate the effectiveness of the proposed algorithm in comparison with some state-of-the-art methods.																	1861-8200	1861-8219				OCT	2020	17	5					1239	1253		10.1007/s11554-019-00878-7													
J								Parallel implementation of multiple kernel self-organizing maps for spectral unmixing	JOURNAL OF REAL-TIME IMAGE PROCESSING										Spectral unmixing; Hyperspectral image; GPU; Self-organization map; Remote sensing applications	ALGORITHM	Spectral unmixing algorithms are commonly used in processing of hyperspectral images to identify the elemental components, called end-members, and their corresponding information in each pixel of the image. However, these algorithms are computationally intensive and can become a bottleneck for remote sensing hyperspectral image processing, especially in large aerial imagery processing centers. This paper, explores the use of massive parallel processing graphical processing unit to speed up the multi kernel self-organizing map (MKSOM) unmixing algorithm. MKSOM is based on artificial neural networks, which makes it suitable to be efficiently parallelized. Two real benchmark hyperspectral images; AVIRIS Cuprite and Brullus are used to evaluate the performance of the parallel algorithm. The experimental results show that the proposed implementation is appropriated for real-time hyperspectral remote sensing applications due to a very small worst case parallel execution time (0.83 s when the number of classes is less than 9) which makes it feasible to be integrated as on-board processing on any Hyperspectral remote sensors. Our parallel technique achieved a significant speedup compared with a multi-threaded CPU implementation applied on the same hyperspectral image. The results showed a speedup of 93.46 x for SOM size of 256 and trained for 100 epochs on medium-sized HSI such as AVIRIS Cuprite.																	1861-8200	1861-8219				OCT	2020	17	5					1267	1284		10.1007/s11554-019-00880-z													
J								Real-time implementation of moving object detection in UAV videos using GPUs	JOURNAL OF REAL-TIME IMAGE PROCESSING										Connected component labelling (CCL); GPU optimizations; Image registration; Morphology; Moving object detection	MULTICORE; TRACKING; CPU	Unmanned aerial vehicles (UAVs) are being increasingly used for video surveillance and remote sensing. Moving object detection is an important algorithm for many such applications. Real-time processing of moving object detection is required for various decision-making tasks in many of these applications. However, being compute-intensive in nature, it is difficult to process high-resolution UAV-sourced videos in real-time. GPU vendors regularly release newer architectures with new features to speed up various kinds of applications. Hence, it becomes imperative to explore parallel implementations of such algorithms using the new GPU architectures. This paper describes parallel implementation strategies for algorithms like feature detection, feature matching, image transformation, frame differencing, morphological processing and connected component labeling which are used to detect moving objects in UAV-sourced videos. The implementation is tested on different NVIDIA GPU microarchitectures (Fermi, Maxwell, and Pascal). Experimental results show the achieved frame processing rates of 43.1 fps, 35.5 fps and 9.1 fps for 1080p videos on Pascal, Maxwell, and Fermi microarchitectures respectively.																	1861-8200	1861-8219				OCT	2020	17	5					1301	1317		10.1007/s11554-019-00888-5													
J								A high throughput two-dimensional discrete cosine transform and MPEG4 motion estimation using vector coprocessor	JOURNAL OF REAL-TIME IMAGE PROCESSING										Motion estimation; Two dimensional discrete cosine transformation; Vector coprocessor; FPGA; High throughput	ARCHITECTURE DESIGN	In this work a configurable and scalable vector coprocessor for real time processing of MPEG4 motion estimation (ME) and two-dimensional DCT (2D DCT) is presented. A sequential DSP processor based on a reduced instruction set computer (RISC) processor architecture would require a frequency of 15 GHz for the real time processing of these two processes for a common intermediate format (CIF) sized sequence at 25 frames per second (fps). This frequency requirement will increase further if the image dimensions are increased. On the other hand our architecture on FPGA can achieve the real time processing rate at low frequency for CIF sized sequence and at higher frequency for full high definition (FHD) sequence for combined ME and 2D DCT. Due to configurable nature of the architecture and FPGA, this can be extended to higher dimensional image sequences. An important aspect of the architecture is that same datapath that is used for ME is also used for 2D DCT, with minor modification, leading to saving in area and time consumption. In addition the processor-coprocessor architecture has lower energy consumption and cost than the sequential processor.																	1861-8200	1861-8219				OCT	2020	17	5					1319	1330		10.1007/s11554-019-00892-9													
J								Reviewing GPU architectures to build efficient back projection for parallel geometries	JOURNAL OF REAL-TIME IMAGE PROCESSING										Parallel algorithms; Hardware architecture; GPU computing; Synchrotron tomography; Back-projection; CUDA; OpenCL	X-RAY TOMOGRAPHY; RECONSTRUCTION; FRAMEWORK	Back-Projection is the major algorithm in Computed Tomography to reconstruct images from a set of recorded projections. It is used for both fast analytical methods and high-quality iterative techniques. X-ray imaging facilities rely on Back-Projection to reconstruct internal structures in material samples and living organisms with high spatial and temporal resolution. Fast image reconstruction is also essential to track and control processes under study in real-time. In this article, we present efficient implementations of the Back-Projection algorithm for parallel hardware. We survey a range of parallel architectures presented by the major hardware vendors during the last 10 years. Similarities and differences between these architectures are analyzed and we highlight how specific features can be used to enhance the reconstruction performance. In particular, we build a performance model to find hardware hotspots and propose several optimizations to balance the load between texture engine, computational and special function units, as well as different types of memory maximizing the utilization of all GPU subsystems in parallel. We further show that targeting architecture-specific features allows one to boost the performance 2-7 times compared to the current state-of-the-art algorithms used in standard reconstructions codes. The suggested load-balancing approach is not limited to the back-projection but can be used as a general optimization strategy for implementing parallel algorithms.																	1861-8200	1861-8219				OCT	2020	17	5					1331	1373		10.1007/s11554-019-00883-w													
J								CUDA implementation of fractal image compression	JOURNAL OF REAL-TIME IMAGE PROCESSING										Fractal image compression; Quad-tree partitioning; GPU; Parallel processing; CUDA		Fractal coding is a lossy image compression technique, which encodes the image in a way that would require less storage space using the self-similar nature of the image. The main drawback of fractal compression is the high encoding time. This is due to the hard task of finding all fractals during the partition step and the search for the best match of fractals. Lately, GPUs (Graphical Processing Unit) have been exploited to implement fractal image compression algorithms due to their high computational power. The prime aim of this paper is to design and implement a parallel version of the Fisher classification scheme using CUDA to exploit the computational power available in the GPUs. Fisher classification scheme is used to reduce the encoding time of fractal images by limiting the search for the best match of fractals. Encoding time, compression ratio and peak signal-to-noise ratio was used as metrics to assess the correctness and the performance of the developed algorithm. Eight images with different sizes (512 x 512, 1024 x 1024 and 2048 x 2048) have been used for the experiments. The conducted experiments showed that a speedup of 6.4 x was achieved in some images using NVIDIA GeForce GT 660 M GPU.																	1861-8200	1861-8219				OCT	2020	17	5					1375	1387		10.1007/s11554-019-00894-7													
J								A new pipeline for the recognition of universal expressions of multiple faces in a video sequence	JOURNAL OF REAL-TIME IMAGE PROCESSING										Facial expression recognition; Histogram of oriented gradient; Linear discriminant analysis	EXTRACTION	Facial expression recognition (FER) is a crucial issue in human-machine interaction. It allows machines to act according to facial expression changes. However, acting in real time requires recognizing the expressions at video speed. Usually, the video speed differs from one device to another. However, one of the standard settings for shooting videos is 24 fps. This speed is considered as the low end of what our brain can perceive as fluid video. From this perspective, to achieve a real-time FER, the image analysis must be completed, strictly, in less than 0.042 s no matter how the background complexity is or how many faces exists in the scene. In this paper, a new pipeline has been proposed to recognize the fundamental facial expressions for more than one person in real-world sequence videos. First, the pipeline takes as input a video and performs a face detection and tracking. Regions of Interest (ROI) are extracted from the detected face to extract the shape information when applying the histogram of oriented gradient (HOG) descriptor. The number of features yield by HOG descriptor is reduced by means of a linear discriminant analysis (LDA). Then, a deep data analysis was carried out, exploiting the pipeline, for the objective of setting up the LDA classifier. The analysis aimed at proving the suitability of the decision rule selected to separate the facial expression clusters in the LDA training phase. To conduct our analysis, we used ChonKanade (CK+) database and F-measure as an evaluation metric to calculate the average recognition rates. An automatic evaluation over time is proposed, where labelled videos is utilized to investigate the suitability of the pipeline in real-world condition. The pipeline results showed that the use of HOG descriptor and the LDA gives a high recognition rate of 94.66%. It should be noted that the proposed pipeline achieves an average processing time of 0.018 s, without requiring any device that speeds up the processing.																	1861-8200	1861-8219				OCT	2020	17	5					1389	1402		10.1007/s11554-019-00896-5													
J								Dynamic multifoveated structure for real-time vision tasks in robotic systems A tool for removing redundancy in multifoveated image processing	JOURNAL OF REAL-TIME IMAGE PROCESSING										Real time processing; Feature extraction; Multifoveated image	COMPLEXITY VIDEO COMPRESSION; ADAPTIVE MULTIFOVEATION; ATTENTION	Foveation is a technique that allows real-time image processing by drastically reducing the amount of visual data without loosing essential information around some focused area. When a robot needs to pay attention at two or more regions of the image at the same time, e.g., for tracking two or more objects, multifoveation is necessary. In this case, computing features twice in the intersections between the different foveated structures, which could linearly increase the processing time, must be avoided. To solve this redundancy removal problem, we propose two algorithms. The first one is based on the previous calculation of redundant blocks and the second one is based on a pixel-by-pixel processing at execution time. Experimental results show a gain in processing time for the block-based model in comparison with the pixel-by-pixel and also of both in comparison with other approaches that sequentially calculate various single foveated images. Robotics vision and other tasks related to dynamic visual attention, as recognition, real-time surveillance, video transmission, and image rendering, are examples of applications that can rely on and strongly benefit from such model.																	1861-8200	1861-8219				OCT	2020	17	5					1403	1419		10.1007/s11554-019-00895-6													
J								A memory and area-efficient distributed arithmetic based modular VLSI architecture of 1D/2D reconfigurable 9/7 and 5/3 DWT filters for real-time image decomposition	JOURNAL OF REAL-TIME IMAGE PROCESSING										DWT; Distributed arithmetic; Memory efficient; Digital VLSI design; Parallelism; Image decomposition; PSNR	DISCRETE WAVELET TRANSFORM	In this article, we have proposed the internal architecture of a dedicated hardware for 1D/2D convolution-based 9/7 and 5/3 DWT filters, exploiting bit-parallel 'distributed arithmetic' (DA) to reduce the computation time of our proposed DWT design while retaining the area at a comparable level to other recent existing designs. Despite using memory extensive bit-parallel DA, we have successfully achieved 90% reduction in the memory size than that of the other notable architectures. Through our proposed architecture, both the 9/7 and 5/3 DWT filters can be realized with a selection input, mode. With the introduction of DA, we have incorporated pipelining and parallelism into our proposed convolution-based 1D/2D DWT architectures. We have reduced the area by 38.3% and memory requirement by 90% than that of the latest remarkable designs. The critical-path delay of our design is almost 50% than that of the other latest designs. We have successfully applied our prototype 2D design for real-time image decomposition. The quality of the architecture in case of real-time image decomposition is measured by 'peak signal-to-noise ratio' and 'computation time', where our proposed design outperforms other similar kind of software- and hardware-based implementations.																	1861-8200	1861-8219				OCT	2020	17	5					1421	1446		10.1007/s11554-019-00901-x													
J								An FPGA-based real-time occlusion robust stereo vision system using semi-global matching	JOURNAL OF REAL-TIME IMAGE PROCESSING										Stereo matching; Real time; High precision; Occlusion check; FPGA		Stereo matching approaches are an appealing choice for acquiring depth information in a number of video processing applications. It is desirable that these solutions generate dense, robust disparity maps in real time. However, occlusion regions may disturb the applications that need these maps. Among the best of these approaches is the semi-global matching (SGM) technique. This paper presents an FPGA-based stereo vision system based on SGM. This system calculates disparity maps by streaming, which are scalable to several resolutions and disparity ranges. To increase the robustness of the SGM technique even further, the present work has implemented a combination of the gradient filter and the sampling-insensitive absolute difference in the pre-processing phase. Furthermore, as a post-processing step, this paper proposes a novel streaming architecture to detect noisy and occluded regions. The FPGA-based implementations of the proposed stereo matching system in two distinct heterogeneous architecture (GPP-general purpose processor, and FPGA) were evaluated using the Middlebury stereo vision benchmark. The achieved results reported a frame rate of 25 FPS for the disparity maps processing in HD resolution (1024x 768 pixels), with 256 disparity levels. The results have demonstrated that the memory utilization, processing performance, and accuracy are among the best of FPGA-based stereo vision systems.																	1861-8200	1861-8219				OCT	2020	17	5					1447	1468		10.1007/s11554-019-00902-w													
J								Speedup evaluation of HEVC parallel video coding using Tiles	JOURNAL OF REAL-TIME IMAGE PROCESSING										Parallel video coding; HEVC; Tiles; Speedup	EFFICIENCY	This paper presents an extensive evaluation of the HEVC parallel video coding when using Tiles. The evaluation consists on finding the tiling pattern that yields the maximum possible speedup for a set of video sequences considering several encoding parameters, measuring the coding efficiency variation of using such tiling pattern instead of the uniform tiling pattern, and calculating how far from the uniform tiling the maximum speedup tiling pattern is. To perform these evaluations, a different number of Tiles with different tiling patterns are applied; apart from that, different encoding profiles are employed. The results show that the speedup yielded by the uniform tiling is highly dependent on the video sequence and employed encoding profile. When encoding a set of video sequences with the same encoding parameters, the greater speedup may be up to 25% higher than the minor speedup, whereas when encoding the same video sequence with different encoding profiles, the greater speedup may be up to 21% higher than the minor speedup. When applying the maximum speedup tiling pattern to an encoding, distinct speedup gains may be achieved. While for some video sequences the maximum possible speedup equals the speedup yielded by the uniform tiling pattern, for others, changing from the uniform tiling to a better one may result in more than 40% of speedup gain. The results also show that when changing from the uniform tiling pattern to one that results in the maximum possible speedup, the coding efficiency variation is negligible; therefore, it is rewarding to seek better tiling patterns.																	1861-8200	1861-8219				OCT	2020	17	5					1469	1486		10.1007/s11554-019-00900-y													
J								Speeding up inference on deep neural networks for object detection by performing partial convolution	JOURNAL OF REAL-TIME IMAGE PROCESSING										Deep neural networks; DNNs object detection; Convolution; Inference acceleration		Real-time object detection is an expected application of deep neural networks (DNNs). It can be achieved by employing graphic processing units (GPUs) or dedicated hardware accelerators. Alternatively, in this work, we present a software scheme to accelerate the inference stage of DNNs designed for object detection. The scheme relies on partial processing within the consecutive convolution layers of a DNN. It makes use of different relationships between the locations of the components of an input feature, an intermediate feature representation, and an output feature to effectively identify the modified components. This downsizes the matrix multiplicand to cover only those modified components. Therefore, matrix multiplication is accelerated within a convolution layer. In addition, the aforementioned relationships can also be employed to signal the next consecutive convolution layer regarding the modified components. This further helps reduce the overhead of the comparison on a member-by-member basis to identify the modified components. The proposed scheme has been experimentally benchmarked against a similar concept approach, namely, CBinfer, and against the original Darknet on the Tiny-You Only Look Once network. The experiments were conducted on a personal computer with dual CPU running at 3.5 GHz without GPU acceleration upon video data sets from YouTube. The results show that improvement ratios of 1.56 and 13.10 in terms of detection frame rate over CBinfer and Darknet, respectively, are attainable on average. Our scheme was also extended to exploit GPU-assisted acceleration. The experimental results of NVIDIA Jetson TX2 reached a detection frame rate of 28.12 frames per second (1.25x with respect to CBinfer). The accuracy of detection of all experiments was preserved at 90% of the original Darknet.																	1861-8200	1861-8219				OCT	2020	17	5					1487	1503		10.1007/s11554-019-00906-6													
J								Real-time localization of multi-oriented text in natural scene images using a linear spatial filter	JOURNAL OF REAL-TIME IMAGE PROCESSING										Text detection; Real-time; Multi-oriented; Linear spatial filter	SEGMENTATION; RECOGNITION; EXTRACTION; DETECT	This paper proposes a multi-oriented text localization method in natural images suitable for real-time processing of high-definition video on portable and mobile devices. Our method is based on the connected components (CC) approach: first, CC are isolated by convolving a multi-scale pyramid with a specifically designed linear spatial filter followed by hysteresis thresholding. Next, non-textual CC are pruned employing a local classifier consisting of a cascade of multilayer perceptron (MLP) fed with increasingly extended feature vectors. The stroke width feature is estimated in linear time complexity by computing the maximal inscribed squares in the CC. Candidate CC and their neighbors are then checked using a more context aware neural network classifier that takes into account the target CC and their vicinity. Finally, text sequences are extracted in all pyramid levels and fused using dynamic programming. The main contribution of the work presented here is execution speed: the CPU-only parallel implementation of the proposed method is capable of processing 1080p HD video at nearly 30 frames per second on a standard laptop. Furthermore, when benchmarked on the ICDAR 2013 Robust Reading and on the ICDAR 2015 Incidental Scene Text data sets, our system performs more than twice faster than the state-of-the-art, while still delivering competitive results in terms of precision and recall.																	1861-8200	1861-8219				OCT	2020	17	5					1505	1525		10.1007/s11554-019-00911-9													
J								A labeling algorithm based on a forest of decision trees	JOURNAL OF REAL-TIME IMAGE PROCESSING										Connected component labelling; Algorithm; Decision tree; Optimisation	SEGMENTATION	Connected component labeling (CCL) is one of the most fundamental operations in image processing. CCL is a procedure for assigning a unique label to each connected component. It is a mandatory step between low-level and high-level image processing. In this work, a general method is given to improve the neighbourhood exploration in a two-scan labeling. The neighbourhood values are considered as commands of a decision table. This decision table can be represented as a decision tree. A block-based approach is proposed so that values of several pixels are given by one decision tree. This block-based approach can be extended to multiple connectivities, 2D and 3D. In a raster scan, already seen pixels can be exploited to generate smaller decision trees. New decision trees are automatically generated from every possible command. This process creates a decision forest that minimises the number of memory accesses. Experimental results show that this method is faster than the state-of-the-art labelling algorithms and require fewer memory accesses. The whole process can be generalised to any given connectivity.																	1861-8200	1861-8219				OCT	2020	17	5					1527	1545		10.1007/s11554-019-00912-8													
J								Low-complexity open-loop coding of IDR infrared images having JPEG compatibility	JOURNAL OF REAL-TIME IMAGE PROCESSING										Infrared image coding; JPEG-XT; IDR		In this paper, we present a low-complexity open-loop Intermediate Dynamic Range (IDR) infrared image coding algorithm which provides two scalability layers. The first layer corresponds to a low dynamic range (LDR) version of the image which can be obtained by a JPEG decoder, while the second layer corresponds to the original IDR image. To achieve bit-depth scalability, we separate an input IDR image into LDR and residual images by simple operations, so that the residual image has a bit depth not higher than 8 bits per pixel, i.e., it can be compressed by JPEG baseline or other coding algorithm, developed for 8-bit depth formats. For real-time applications, we introduce a predefined look-up table containing quality factors for both the LDR and the residual images, so that increase of the table index corresponds to reduction of bit rate and increase of distortion close to an operational rate-distortion curve. Experimental results show that the proposed algorithm is significantly less complex than JPEG-XT Profile C, part 6, and provides better coding performance than its reference software with default tone mapping operator for the vast majority of the infrared test images.																	1861-8200	1861-8219				OCT	2020	17	5					1547	1565		10.1007/s11554-019-00898-3													
J								Efficient adaptive load balancing approach for compressive background subtraction algorithm on heterogeneous CPU-GPU platforms	JOURNAL OF REAL-TIME IMAGE PROCESSING										Adaptive workload balancing; High-performance computing; Heterogeneous CPU-GPU platforms; Compressive sensing; MoG background subtraction		Mixture of Gaussians (MoG) and compressive sensing (CS) are two common approaches in many image and audio processing systems. The combination of these algorithms is recently used for the compressive background subtraction task. Nevertheless, the result of this combination has not been exploited to take advantage of the evolution of parallel computing architectures. This paper proposes an efficient strategy to implement CS-MoG on heterogeneous CPU-GPU computing platforms. This is achieved through two elements. The first one is ensuring the better acceleration and accuracy that can be achieved for this algorithm on both CPU and GPU processors: The obtained results of the improved CS-MoG are more accurate and performant than other published MoG implementations. The second contribution is the proposition of the Optimal Data Distribution Cursor ODDC, a novel adaptive data partitioning approach to exploit simultaneously the heterogeneous processors on any given platform. It aims to ensure an automatic workload balancing by estimating the optimal data chunk size that must be assigned to each processor, with taking into consideration its computing capacity. Furthermore, our method ensures an update of the partitioning at runtime to take into account any influence of data content irregularity. The experimental results, on different platforms and data sets, show that the combination of these two contributions allows reaching 98% of the maximal possible performance of targeted platforms.																	1861-8200	1861-8219				OCT	2020	17	5					1567	1583		10.1007/s11554-019-00916-4													
J								Voxel transformation: scalable scene geometry discretization for global illumination	JOURNAL OF REAL-TIME IMAGE PROCESSING										Voxelization; Cone-tracing; Indirect Illumination		In real-time computer graphics, efficient discretization of scenes is required in order to accelerate graphics related algorithms such as realistic rendering with indirect illumination and visibility checking. Sparse voxel octree (SVO) is a popular data structure for such a discretization task. Populating an SVO with data is challenging when dynamic object count is high, especially when data per spatial location is large. Problem of populating such trees is adressed with our Voxel Transformation method, where pre-generated voxel data is transformed from model space to world space on demand, in contrast to the common way of voxelizing each dynamic object over each frame. Additionally, an accompanying filtering technique for voxel transformation is also proposed. This technique serves proposed system in two ways: (1) resolves issues introduced by the proposed fast and scalable voxel transformation method, and (2) enables smooth transitions between frames and handles the aliasing problem naturally as shown in the supplementary video. As an application use case, the proposed Voxel Transformation method is demonstrated in order to achieve indirect illumination using the well-known voxel cone tracing method. Results, which is compared with the standard voxelization method and ground-truth, are visually appealing and also scalable over large number of dynamic objects as shown in the supplementary video.																	1861-8200	1861-8219				OCT	2020	17	5					1585	1596		10.1007/s11554-019-00919-1													
J								Benchmarking neural embeddings for link prediction in knowledge graphs under semantic and structural changes	JOURNAL OF WEB SEMANTICS										Knowledge graphs; Neural embeddings; Benchmarks; Evaluation; Link prediction		Recently, link prediction algorithms based on neural embeddings have gained tremendous popularity in the Semantic Web community, and are extensively used for knowledge graph completion. While algorithmic advances have strongly focused on efficient ways of learning embeddings, fewer attention has been drawn to the different ways their performance and robustness can be evaluated. In this work we propose an open-source evaluation pipeline, which benchmarks the accuracy of neural embeddings in situations where knowledge graphs may experience semantic and structural changes. We define relation-centric connectivity measures that allow us to connect the link prediction capacity to the structure of the knowledge graph. Such an evaluation pipeline is especially important to simulate the accuracy of embeddings for knowledge graphs that are expected to be frequently updated. (C) 2020 Elsevier B.V. All rights reserved.																	1570-8268	1873-7749				OCT	2020	64								100590	10.1016/j.websem.2020.100590													
J								Uncovering hidden semantics of set information in knowledge bases	JOURNAL OF WEB SEMANTICS												Knowledge Bases (KBs) contain a wealth of structured information about entities and predicates. This paper focuses on set-valued predicates, i.e., the relationship between an entity and a set of entities. In KBs, this information is often represented in two formats: (i) via counting predicates such as number Of Children and staff Size, that store aggregated integers, and (ii) via enumerating predicates such as parent Of and works For, that store individual set memberships. Both formats are typically complementary: unlike enumerating predicates, counting predicates do not give away individuals, but are more likely informative towards the true set size, thus this coexistence could enable interesting applications in question answering and KB curation. In this paper we aim at uncovering this hidden knowledge. We proceed in two steps. (i) We identify set-valued predicates from a given KB predicates via statistical and embedding-based features. (ii) We link counting predicates and enumerating predicates by a combination of co-occurrence, correlation and textual relatedness metrics. We analyse the prevalence of count information in four prominent knowledge bases, and show that our linking method achieves up to 0.55 F1 score in set predicate identification versus 0.40 F1 score of a random selection, and normalized discounted gains of up to 0.84 at position 1 and 0.75 at position 3 in relevant predicate alignments. Our predicate alignments are showcased in a demonstration system available at https://counqer.mpi-inf.mpg.de/spo. (C) 2020 Elsevier B.V. All rights reserved.																	1570-8268	1873-7749				OCT	2020	64								100588	10.1016/j.websem.2020.100588													
J								Evaluating and comparing ontology alignment systems: An MCDM approach	JOURNAL OF WEB SEMANTICS										Ontology alignment; Ranking; Evaluation; MCDM; Bayesian BWM	INTEGRATION	Ontology alignment is vital in Semantic Web technologies with numerous applications in diverse disciplines. Due to diversity and abundance of ontology alignment systems, a proper evaluation can portray the evolution of ontology alignment and depicts the efficiency of a system for a particular domain. Evaluation can help system designers recognize the strength and shortcomings of their systems, and aid application developers to select a proper alignment system. This article presents a new evaluation and comparison methodology based on multiple performance metrics that accommodates experts' preferences via a multi-criteria decision-making (MCDM) method, i.e., Bayesian best-worst method (BWM). First, the importance of a performance metric for a specific task/application is determined according to experts' preferences. The alignment systems are then evaluated based on proposed expert-based collective performance (ECP) that takes into account multiple metrics as well as their calibrated importance. For comparison, the alignment systems are ranked based on a probabilistic scheme, where it includes the extent to which one alignment system is preferred over another. The proposed methodology is applied to six tracks from ontology alignment evaluation initiative (OAEI), where the importance of performance metrics are calibrated by designing a survey and eliciting the preferences of ontology alignment experts. Accordingly, the participating alignment systems in the OAEI 2018 are evaluated and ranked. While the proposed methodology is applied to six OAEI tracks to demonstrate its applicability, it can also be applied to any benchmark or application of ontology alignment. (C) 2020 The Author(s). Published by Elsevier B.V.																	1570-8268	1873-7749				OCT	2020	64								100592	10.1016/j.websem.2020.100592													
J								IQA: Interactive query construction in semantic question answering systems	JOURNAL OF WEB SEMANTICS										User interaction; Question answering; Knowledge graphs; Option gain	KNOWLEDGE-BASE	Semantic Question Answering (SQA) systems automatically interpret user questions expressed in a natural language in terms of semantic queries. This process involves uncertainty, such that the resulting queries do not always accurately match the user intent, especially for more complex and less common questions. In this article, we aim to empower users in guiding SQA systems towards the intended semantic queries through interaction. We introduce IQA - an interaction scheme for SQA pipelines. This scheme facilitates seamless integration of user feedback in the question answering process and relies on Option Gain - a novel metric that enables efficient and intuitive user interaction. Our evaluation shows that using the proposed scheme, even a small number of user interactions can lead to significant improvements in the performance of SQA systems. (C) 2020 Elsevier B.V. All rights reserved.																	1570-8268	1873-7749				OCT	2020	64								100586	10.1016/j.websem.2020.100586													
J								Data-driven prognostic method based on self-supervised learning approaches for fault detection	JOURNAL OF INTELLIGENT MANUFACTURING										Fault detection; Self-supervised; Kernel PCA; Prognostics and health management	NEAREST-NEIGHBOR RULE; ONLINE MONITORING STRATEGY; COMPONENT ANALYSIS; PRODUCT QUALITY; DIAGNOSIS; PCA	As a part of prognostics and health management (PHM), fault detection has been used in many fields to improve the reliability of the system and reduce the manufacturing costs. Due to the complexity of the system and the richness of the sensors, fault detection still faces some challenges. In this paper, we propose a data-driven method in a self-supervised manner, which is different from previous prognostic methods. In our algorithm, we first extract feature indices of each batch and concatenate them into one feature vector. Then the principal components are extracted by Kernel PCA. Finally, the fault is detected by the reconstruction error in the feature space. Samples with high reconstruction error are identified as faulty. To demonstrate the effectiveness of the proposed algorithm, we evaluate our algorithm on a benchmark dataset for fault detection, and the results show that our algorithm outperforms other fault detection methods.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1611	1619		10.1007/s10845-018-1431-x													
J								Approach for fault prognosis using recurrent neural network	JOURNAL OF INTELLIGENT MANUFACTURING										Fault prognosis; Recurrent neural network; Long short-term memory; Turbofan engine; Remaining useful life	DEGRADATION ASSESSMENT; PREDICTION	In general, fault prognosis research usually leads to the research of remaining useful life prediction and performance prediction (prediction of target feature), which can be regarded as a sequence learning problem. Considering the significant success achieved by the recurrent neural network in sequence learning problems such as precise timing, speech recognition, and so on, this paper proposes a novel approach for fault prognosis with the degradation sequence of equipment based on the recurrent neural network. Long short-term memory (LSTM) network is utilized due to its capability of learning long-term dependencies, which takes the concatenated feature and operation state indicator of the equipment as the input. Note that the indicator is a one-hot vector, and based on it, the remaining useful life can be estimated without any pre-defined threshold. The outputs of the LSTM networks are connected to a fully-connected layer to map the hidden state into the parameters of a Gaussian mixture model and a categorical distribution so that the predicted output sequence can be sampled from them. The performance of the proposed method is verified by the health monitoring data of aircraft turbofan engines. The result shows that the proposed approach is able to achieve significant performance whether in one-step prediction task, in long-term prediction task, or in remaining useful life prediction task.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1621	1633		10.1007/s10845-018-1428-5													
J								Optimizing human-robot task allocation using a simulation tool based on standardized work descriptions	JOURNAL OF INTELLIGENT MANUFACTURING										Human-robot collaboration; Simulation; Task allocation; Optimization	COLLABORATION; INTELLIGENT; COOPERATION; INDUSTRIAL; SYSTEMS	Human-robot collaboration is enabled by the digitization of production and has become a key technology for the factory of the future. It combines the strengths of both the human worker and the assistant robot and allows the implementation of an varying degree of automation in workplaces in order to meet the increasing demand of flexibility of manufacturing systems. Intelligent planning and control algorithms are needed for the organization of the work in hybrid teams of humans and robots. This paper introduces an approach to use standardized work description for automated procedure generation of mobile assistant robots. A simulation tool is developed that implements the procedure model and is therefore capable of calculating different objective parameters like production time or ergonomics during a production cycle as a function of the human-robot task allocation. The simulation is validated with an existing workplace in an assembly line at the Volkswagen plant in Wolfsburg, Germany. Furthermore, a new method is presented to optimize the task allocation in human-robot teams for a given workplace, using the simulation as fitness function in a genetic algorithm. The advantage of this new approach is the possibility to evaluate different distributions of the tasks, while considering the dynamics of the interaction between the worker and the robot in their shared workplace. Using the presented approach for a given workplace, an optimized human-robot task allocation is found, in which the tasks are allocated in an intelligent and comprehensible way.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1635	1648		10.1007/s10845-018-1411-1													
J								Cloud manufacturing service QoS prediction based on neighbourhood enhanced matrix factorization	JOURNAL OF INTELLIGENT MANUFACTURING										Cloud manufacturing; Quality of service; Collaborative filtering; Service recommendation; Matrix factorization	RECOMMENDATION; OPTIMIZATION; SELECTION; LOCATION; RESOURCE; PLATFORM; QUALITY; NETWORK	With the rapid development of cloud manufacturing (CMfg), quality-of-service (QoS) prediction becomes increasingly important in CMfg service platform because it turns out to be impractical to acquire all service QoS values. In this paper, we present a neighbourhood enhanced matrix factorization approach to predict missing QoS values. We first systematically consider geographical information, sample set diversity computation and platform context to extend basic Pearson Correlation Coefficient (PCC) similarity and extract neighbourhood information. Then, we integrate neighbourhood information into matrix factorization (MF) and make prediction of missing values. Compared with existing methods, the proposed method has the following new features: (1) entropy information is adopted to derive personal weights for different users or services when computing PCC similarity; (2) location information and sample set similarity are considered to enhance PCC similarity; (3) topology information is introduced to address data sparsity issue; (4) neighbourhood information is incorporated with MF to improve prediction accuracy. We conduct an experiment on a real-world dataset which includes web service invocations from 339 service users on 5825 services to verify the feasibility and efficiency of our method.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1649	1660		10.1007/s10845-018-1409-8													
J								An effective approach for causal variables analysis in diesel engine production by using mutual information and network deconvolution	JOURNAL OF INTELLIGENT MANUFACTURING										Power consistency; Causal variables analysis; Transitive effects; Mutual information; Network deconvolution	FEATURE-SELECTION; CYCLE TIME; PREDICTION	The effective control of the power consistency, which is one of the most important quality indicators of diesel engine, plays a decisive role for improving the competitiveness of the products. The widely used sensors and other data acquisition equipment make the "data-driven quality control" become possible. However, how to determine the highly related parameters with the engine power from massive captured manufacturing data and effectively discriminated the direct and indirect dependencies between these variables are still challenging. This paper proposed a feature selection algorithm named NMI-ND which uses network deconvolution (ND) to infer causal correlations among various diesel engine manufacturing parameters from the observed correlations based on normalized mutual information (NMI). The proposed algorithm is thoroughly evaluated through the experimental study by comparing it with other representative feature selection algorithms. The comparison demonstrates that NMI-ND performs better in both effectiveness and efficiency.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1661	1671		10.1007/s10845-018-1397-8													
J								A scheduling optimization method for maintenance, repair and operations service resources of complex products	JOURNAL OF INTELLIGENT MANUFACTURING										Maintenance; repair and operations; Scheduling optimization; Improved genetic algorithm; NSGA-II algorithm	DESIGN	Scheduling optimization of maintenance, repair and operations (MRO) service resources of complex product can help an enterprise improve customer service satisfaction, build value-added products, and enhance the enterprise's market competitiveness. This paper studies a scheduling optimization method for the MRO service resources of complex product. First, the scheduling problem in service resources is analyzed, a mathematical model for the service scheduling problem is given, and three objective functions to be optimized are proposed, which are to reduce customer waiting time, reduce excessive human resources, and maximize the cost performance index of the resources. Then, three separate objectives for optimizing service resource scheduling are analyzed based on three proposed methods which are improved genetic algorithm method, combined weight coefficient optimization method, and multi-objective optimization method based on the nondominated sorting genetic algorithm II (NSGA-II). Finally, we use the three methods to carry out scheduling optimization of MRO service resources in the case of a large vertical mill. According to the analysis and comparison of results, the multi-objective optimization method based on the NSGA-II algorithm has an advantage in the scheduling optimization of complex product MRO service resources. In the engineering application, the service scheduling of complex products for managers provides theoretical basis, and can reduce the loss caused by subjective judgment.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1673	1691		10.1007/s10845-018-1400-4													
J								A data-driven method based on deep belief networks for backlash error prediction in machining centers	JOURNAL OF INTELLIGENT MANUFACTURING										Data mining; Machining centers; Data-driven method; Deep belief network; Backlash error	NEURAL-NETWORKS; GEOMETRIC ERRORS; COMPENSATION; TOOL; IDENTIFICATION	Backlash error occurs in a machining center may lead to a series of changes in the geometry of the components and subsequently deteriorate the overall performance of the equipment. Due to the uncertainty of mechanical wear between kinematic pairs, it is challenging to predict backlash error through physical models directly. An alternative method is to leverage data-driven models to map the degradation. This paper proposes a data-driven method for backlash error predication through Deep Belief Network (DBN). The proposed method focuses on the assessment of both current and future geometric errors for backlash error prediction and subsequent maintenance in machining centers. During the process of prognosis, a DBN via stacking Restricted Boltzmann Machines is constructed for backlash error prediction. Energy-based models enable DBN to mine information hidden behind highly coupled inputs, which makes DBN a feasible method for fault diagnosis and prognosis when the target condition is beyond the historical data. In the experiment, to confirm the effectiveness of deep learning for backlash error prediction, similar popular regression methods, including Support Vector Machine Regression and Back Propagation Neural Network, are employed to present a comprehensive comparison in both diagnosis and prognosis. The experimental results show that the performances of all these regression methods are acceptable in the diagnostic stage. In the prognostic stage, DBN demonstrates its superiority and significantly outperforms the other models for backlash error prediction in machining centers.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1693	1705		10.1007/s10845-017-1380-9													
J								Hypernetwork-based manufacturing service scheduling for distributed and collaborative manufacturing operations towards smart manufacturing	JOURNAL OF INTELLIGENT MANUFACTURING										Manufacturing service scheduling; Distributed collaboration; Smart manufacturing (SM); Complex networks; Graph coloring	SUPPLY CHAIN; COORDINATION; ALGORITHM; OPTIMIZATION; DEMAND	In the future smart manufacturing, both of sensor-based environment in shop floors and cloud-based environment among more and more enterprises are deployed gradually. Various distributed and separated manufacturing facilities are as collaborative cloud services, integrated and aggregated with their real-time information. It provides opportunities for thedistributed and collaborative manufacturing operationsacross lots of distributed but networked enterprises on demand with enough flexibility. To this end, the scheduling problem and its result of those collaborative services for distributed manufacturing operations play an important role in improving manufacturing utilization and efficiency. In this paper, we put forward the hypernetwork-based models introducing the thought of graph coloring and an artificial bee colony algorithm based method for this scheduling problem. Three groups of experiments are carried out respectively to discuss therein different situations of distributed and collaborative manufacturing operations, i.e., in a private cloud, in a public cloud, and in a hybrid cloud. Some future studies with further consideration of collaboration equilibrium, dynamic control and data-based intelligence, are finally pointed out in the conclusion.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1707	1720		10.1007/s10845-018-1417-8													
J								Data-driven customer requirements discernment in the product lifecycle management via intuitionistic fuzzy sets and electroencephalogram	JOURNAL OF INTELLIGENT MANUFACTURING										Big data; Product lifecycle management; Customer requirements discernment; Electroencephalogram; Intuitionistic fuzzy sets	SUPPORT VECTOR MACHINE; BIG DATA; SATISFACTION; NETWORKS; ENTROPY; MODEL; EEG	Large amount of data are collected through the product lifecycle management, and the benefits of big data analytics permeate the entire manufacturing value chain. However, the existing methods pay little attention to the analysis of customer requirements data in the beginning of life period. Thus, a data-driven approach for customer requirements discernment is proposed in this paper. It not only manages the vagueness in the semantic expression level using the intuitionistic fuzzy sets, but also adopts the electroencephalogram data as endogenous neural indicators to handle the vagueness in the neurocognitive level. An experimental research integrated with the Kano model is developed to record the EEG data which inherently interpret customers' psychological states. Benefit from the data mining method, the effect of customer requirements on psychological response can be investigated using the EEG data. Taking the data of initial requirement importance, performance realization levels and customers' psychological states into consideration, three novel adjusting models are established to acquire the comprehensive importance of each requirement. A case study is conducted to illustrate the feasibility of the approach proposed in this paper.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1721	1736		10.1007/s10845-018-1395-x													
J								Blockchain-based business process management (BPM) framework for service composition in industry 4.0	JOURNAL OF INTELLIGENT MANUFACTURING										Industry 4; 0; Business process management (BPM); Block-chain technology (BCT); Internet of things (IoT); Trustworthiness; Service selection and composition; Smart contracts; Quality of Services (QoS)	WEB-SERVICES; COMPLIANCE CHECKING; WORKFLOW; COORDINATION; SELECTION; ONTOLOGY	Business process management (BPM) aims to optimize business processes to achieve better system performance such as higher profit, quicker response, and better services. BPM systems in Industry 4.0 are required to digitize and automate business process workflows and support the transparent interoperations of service vendors. The critical bottleneck to advance BPM systems is the evaluation, verification, and transformation of trustworthiness and digitized assets. Most of BPM systems rely heavily on domain experts or third parties to deal with trustworthiness. In this paper, an automated BPM solution is investigated to select and compose services in open business environment, Blockchain technology (BCT) is explored and proposed to transfer and verify the trustiness of businesses and partners, and a BPM framework is developed to illustrate how BCT can be integrated to support prompt, reliable, and cost-effective evaluation and transferring of Quality of Services in the workflow composition and management.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1737	1748		10.1007/s10845-018-1422-y													
J								A knowledge based intelligent process planning method for controller of computer numerical control machine tools	JOURNAL OF INTELLIGENT MANUFACTURING										Process planning; Intelligent CNC controller; Knowledge base	STEP-NC CONTROLLER; SYSTEM; NETWORK; DESIGN	The development of computer, internet and information technology puts forward higher demands for Computer Numerical Control (CNC) machine tools to improve the intelligence in many aspects. Among these aspects, intelligent process planning plays an important role in current changeable market and customized product promotion by shortening production cycle and providing more stable process planning ability. To realize intelligent process planning, a CNC controller with cloud knowledge base support is proposed with ability of making process planning autonomously based on workpiece design. Previous work of knowledge model and cloud knowledge base framework design is introduced, and then this paper focuses on the complete process planning method within the intelligent CNC controller. Both interactivity between knowledge base and CNC controller, and query/infer mechanism in knowledge base are illustrated in detail. A case study of two shafts process planning is shown to demonstrate the feasibility of the intelligent process planning method.																	0956-5515	1572-8145				OCT	2020	31	7			SI		1751	1767		10.1007/s10845-018-1401-3													
J								COMPARATIVE STUDY ON HEURISTIC OPTIMIZATION TECHNIQUES IN THE DESIGN OF ROBUST POWER SYSTEMS STABILIZERS USING H-infinity CRITERION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										PSS tuning; Robustness; Heuristic optimization; Multi-machine system	CONTROLLER	This work employs a combination of Relative Gains Array (RGA) and singular values, adapted for a multi-machine system, in order to simplify the application of their controllers and reducing their order, without reducing the power system model. After that, three optimization techniques, genetic algorithms, particle swarm and simulated annealing, which are based on heuristics, are applied, in order to determine the parameters of the controllers that guarantee a robust performance. The performance of heuristic optimization techniques is studied when applied to the design of Power System Stabilizers (PSS), based on H-infinity criterion to robustness. The New England - New York benchmark, a reasonably complex, and coupled classical case study, is chosen to compare the performance of the designed PSS with these heuristic techniques. In this way, the paper presents a methodology for the design and allocation of PSS, and the same performance criteria are applied to the three methods in order to determine the one that presents a superior response in the process of tuning of the controllers.																	1349-4198	1349-418X				OCT	2020	16	5					1485	1495		10.24507/ijicic.16.05.1485													
J								ADMISSIBILITY AND DESIGN ISSUES FOR DISCRETE FUZZY SINGULAR DELAY SYSTEMS WITH MULTIPLE DIFFERENCE MATRICES	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Fuzzy inference systems; Discrete singular systems; Delay state; Admissibility; PDC (parallel distributed compensation) design; Linear matrix inequalities (LMIs)	STABILITY ANALYSIS; NONLINEAR-SYSTEMS; CONTROLLER SYNTHESIS; DESCRIPTOR SYSTEMS; RELAXED STABILITY; ROBUST STABILITY; TIME-DELAY; STABILIZATION; MODEL	This paper studies the problem of admissibility analysis and stabilizing controller design for discrete fuzzy singular delay systems with multiple difference matrices. By utilizing matrix algebraic manipulating, an explicit admissibility analysis condition for the nominal discrete singular delay system is originally derived. The distinct condition is different from existing ones, which can cope with the fuzzy singular delay system with distinct difference matrices in the rules. Based on Lyapunov stability theory associated with the linear matrix inequalities (LMIs) approach, we thus can investigate the admissibility analysis and controller design for the regarded systems. Since the proposed criteria are expressed in terms of LMIs or parametric LMIs, we can handily evaluate them via current LMI solvers. Finally, illustrative examples are given to show the validity and practicability of the proposed method.																	1349-4198	1349-418X				OCT	2020	16	5					1497	1510		10.24507/ijicic.16.05.1497													
J								ANALYTICAL MODELING OF OPTIMAL CHUNK SIZE FOR EFFICIENT TRANSMISSION IN INFORMATION-CENTRIC NETWORKING	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Chunk size; ICN; Modeling; Transmission efficiency	LOW LATENCY	As an innovative network architecture, information-centric networking (ICN) is potential to promote network with name-based content retrieval. In ICN, contents are divided into chunks by default. Because chunk is the basic data unit, the size of chunk dramatically affects the transmission efficiency. In this paper, an analytical model is developed to obtain the optimal value of chunk size for content transfer in ICN. Intuitively the larger the chunk size, the better the performance of data transfer. This is because the protocol overhead of each chunk is relatively fixed. However, larger chunk usually leads to larger chunk loss rate and larger response latency. Therefore, the content transfer process is modeled by considering both the protocol overhead and network status. Three typical transmission modes are analyzed, and the expressions for the goodput are derived. By using numerical analysis, the effects of chunk size on goodput under different round-trip times (RTTs), packet loss rates and bandwidths are studied in depth. Based on the model, the recommended values of the chunk size are provided for two deployment approaches in ICN. Finally, experiments are conducted to verify the accuracy of the proposed model.																	1349-4198	1349-418X				OCT	2020	16	5					1511	1525		10.24507/ijicic.16.05.1511													
J								INCREMENTAL ATTRIBUTE REDUCTION ALGORITHM IN PROBABILISTIC ROUGH SETS UNDER THE VARIATION OF ATTRIBUTES	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Probabilistic rough set; Attribute reduction; Incremental learning; Updating approximations	DYNAMIC MAINTENANCE; APPROXIMATIONS	First, a heuristic attribute reduction method based on probabilistic rough sets (PRSs) is introduced, and the incremental calculation method is used to improve the calculation methods of probabilistic approximation accuracy (PAA) and modified probabilistic approximation accuracy (MPAA), which improves the efficiency of the attribute reduction algorithm. Based on PAA and MPAA, a fast method for calculating attribute core and minimal attribute reduction is presented in PRSs under the variation of attributes. Then, we focus on the new strategy of dynamically updating the attribute core and calculating the minimum attribute reduction when the attribute set changes in PRS. Based on PRS, two incremental calculation attribute cores and one incremental calculation algorithm for minimum attribute reduction when adding and deleting attributes are proposed respectively. Finally, the feasibility and effectiveness of the proposed method are illustrated by an example. Compared with the non-incremental algorithm, the incremental algorithm has lower time complexity.																	1349-4198	1349-418X				OCT	2020	16	5					1527	1545		10.24507/ijicic.16.05.1527													
J								IMAGE DENOISING USING LOW RANK MATRIX COMPLETION VIA BILINEAR GENERALIZED APPROXIMATE MESSAGE PASSING	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Image denoising; Low rank matrix completion; Bilinear generalized approximate message passing; Mixed noise		A robust denoising algorithm, which is capable of removing mixed noise from natural images, is proposed based on the bilinear generalized approximate message passing (BiGAMP). This algorithm utilizes the non-local self-similarities of natural images, changes the problem of removing mixed noise to a low-rank matrix completion problem, and takes use of BiGAMP to solve this inherently bilinear problem. Experimental results show that this BiGAMP-based image denoising algorithm is good at removing Gaussian noise mixed with impulsive noise. Its performance is better than the well-known block-matching and 3D filtering (MOD) algorithm and some state-of-the-art image denoising algorithms via low-rank matrix completion.																	1349-4198	1349-418X				OCT	2020	16	5					1547	1558		10.24507/ijicic.16.05.1547													
J								DAMPING POWER SYSTEM OSCILLATIONS IN MULTI-MACHINE SYSTEM: A PARTIAL EIGENSTRUCTURE ASSIGNMENT PLUS STATE OBSERVER APPROACH	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Stability; Electrical power system; Small disturbance; Eigenvalue assignment; Genetic algorithm	DESIGN; CONTROLLERS; PSS	In this study, a partial eigenstructure assignment (PEVA) is applied to the damping of small, sometimes dangerous electromechanical low-frequency oscillations in power systems using a multi-machine connection. The approach is based on the nospillover spectrum assignment, and an optimal design is developed using genetic algorithm (GA) techniques. Because the system order may be higher in the general case, state observers are employed to estimate the system state and then to offer a feasible implementation in practice. Simulation examples show that the application method is efficient with respect to dampening the local and inter-area oscillation modes as well as quickly establishing the system in the event of a small disturbance, as compared to a classic power system stabilizer (PSS). GA has made it possible to define a region for the PEVA to employ state observers without requiring significant effort from the controller, thereby enabling its implementation for larger systems.																	1349-4198	1349-418X				OCT	2020	16	5					1559	1578		10.24507/ijicic.16.05.1559													
J								A NEW DAMAGE INDICATOR IN TIME AND FREQUENCY DOMAINS FOR STRUCTURAL HEALTH MONITORING: THE CASE OF BEAM WITH A BREATHING CRACK	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Euler-Bernoulli beam; Structural health monitoring; Damage indicator; Natural frequency; Finite element method	NEURAL-NETWORK; SYSTEM	With the adoption of the damage tolerance design principle, the health monitoring system has become an integral part of the operation of engineering structures. For the system to work, a damage indicator that describes the structural integrity level should be established and monitored. The damage indicator is usually derived from structural responses. Many quantities have been proposed for damage indicator including natural frequency, mode shape, curvature, strain energy, and t-, F-, and z-statistics. In this paper, we propose a new damage indicator in the time and frequency domains derived from the Euler-Bernoulli beam theory. We evaluate the method by using data obtained from a numerical simulation of a cracked beam. The beam deformation is nonlinear due to the contact between the crack faces during vibration. The proposed damage index is estimated in the domains for various observation points on the beam. Besides, the existence of the crack is also predicted by the widely used traditional method based on the change of the natural frequency and mode shape. A comparison is made between the present method and the existing ones. We conclude the present proposal is more sensitive to detect the crack.																	1349-4198	1349-418X				OCT	2020	16	5					1579	1591		10.24507/ijicic.16.05.1579													
J								A LABEL-ORIENTED APPROACH FOR TEXT CLASSIFICATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Machine learning; Supervised machine learning; Label-oriented score; Text classification	NAIVE BAYES; CATEGORIZATION	Text classification is a well known problem in the machine learning community. A widely used approach is that based on the Term Frequency - Inverse Document Frequency (TF-IDF) feature. This feature represents very well the characteristic of a text. However, this feature could not clearly represent the relationship from a text to its assigned label. This paper presents a Label-Oriented (LO) approach for text classification problem. This approach takes account of the relationship between a text and its assigned label by introducing a new feature label-oriented score. This score represents the level of the importance of the term regarding all terms and texts assigned to the label compared to all terms and texts unassigned to the label. In the training phase, this model calculates the label-oriented score of each term to a label. In the testing phase, the sum of this score of all terms in a text will help us to determine whether the text should be assigned to the label or not. The proposed model is then evaluated in two cases: short and regular texts. The experiment results indicate that the proposed model is significantly better than baseline models on the considered datasets.																	1349-4198	1349-418X				OCT	2020	16	5					1593	1609		10.24507/ijicic.16.05.1593													
J								LOCAL SPATIAL INFORMATION WITH BAG-OF-VISUAL-WORDS MODEL VIA GRAPH-BASED REPRESENTATION FOR TEXTURE CLASSIFICATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Spatial-BoVW; Graph theory; Feature descriptor; Texture analysis; LSPMAuto		This paper proposes an enhanced feature descriptor for texture classification through graph-based representation. Searching the meaningful texture descriptor is a crucial process in pattern analysis and applications. Graph theory is a model-based approach that applies to texture analysis with outstanding results. Therefore, to develop feature descriptors that are robust against many variations images collected from random viewpoints, change in scale, and illumination remains a challenge for researchers. In this work, we propose an Automatically Local Spatial Pattern Mapping (LSPMAuto) method based on the spatial-BoVW model that can extract local and global features information from the spatial arrangement of image pixels. The proposed approach is evaluated by using three different texture databases: Brodatz, UIUC, and Outex. The experimental results show that the proposed method can achieve highly discriminant descriptors superior to the other methods.																	1349-4198	1349-418X				OCT	2020	16	5					1611	1621		10.24507/ijicic.16.05.1611													
J								CUSTOMIZABLE HIERARCHICAL WIRELESS SENSOR NETWORKS BASED ON GENETIC ALGORITHM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Genetic algorithm; Weight; Optimization; Fitness function	ROUTING PROTOCOLS	This paper presents a design tool for WSNs based to optimization mechanisms that enable the user to build a network topology selected by optimizing different potential configurations. Through the suggested mechanisms, it can also be determined the optimal number of active network nodes to meet the requirements of a specific application before the physical implementation of the system. In this paper we propose a customizable heuristic approach of WSNs topology design based on genetic algorithms, in order to take account of specific application parameters: coverage, energy efficiency, system node degree in the environment and network lifetime. Innovation of our method is in a proper representation of different weight coefficients used to study the optimization of the network. The results of simulations prove that the overall network performance of the proposed heuristic deployment approach is superior compared to random WSN deployment.																	1349-4198	1349-418X				OCT	2020	16	5					1623	1638		10.24507/ijicic.16.05.1623													
J								SPARSE RECONSTRUCTION METHOD BASED ON STARLET TRANSFORM FOR HIGH NOISE ASTRONOMICAL IMAGE DENOISING	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										High noise astronomical image denoising; Compressed sensing; Starlet transform; Iterative starlet shrinkage thresholding; FRTV	ALGORITHM; NETWORK	High noise astronomical image denoising has been the bottleneck and key point in deep space exploration. Designing an effective astronomical image denoising method plays a crucial role in analyzing astronomical image details. The famous compressed sensing (CS) has been proved to be a successful technique for high dimensional signal. In this paper, CS is adopted to address the denoising problem of high noise astronomical images, and a CS recovery model and an iterative starlet shrinkage thresholding (ISST) reconstruction algorithm are put forward simultaneously. In l(1) norm CS recovery model, the internal structure of astronomical images is fully considered, which affects the result of image reconstruction. Combining l(1) norm and fractional-order total variation (FRTV), an improved CS reconstruction model is first established to preserve more astronomical image details. In this framework, an adaptive starlet thresholding operator proposed in ISST algorithm is used to select these sparse coefficients in the process of astronomical image starlet sparsity transform. Moreover, an optimized BayesShrink thresholding is developed to pick out the reconstructed astronomical image data in each iteration. The results of various experiments consistently show that the algorithm proposed can efficiently recover high quality astronomical images, and preserve more astronomical image details. Therefore, this algorithm can be applied in the ground receiving station to accurately recondstructing high quality images from high noise astronomical images.																	1349-4198	1349-418X				OCT	2020	16	5					1639	1654		10.24507/ijicic.16.05.1639													
J								TRANSLATING THE CONWAY'S GAME OF LIFE AS A DISCRETE LOGISTIC CELLULAR AUTOMATA MODEL WITH DENSITY EFFECTS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Allee effect; Cellular automata; Game of Life; Hill equation; Logistic model	GREEN PARAMECIA; ALLEE; POPULATION; EQUATIONS; CURVES	John H. Conway (1937-2020) has introduced a series of cellular automata (CA) models to demonstrate that simple rules can lead to very complex phenomena. Game of Life (GoL) is one of the most renowned CA models invented by Conway in 1970's. In fact, GoL is a 'game' without players, by which the spread of artificial life on 2-dimensional plane under periodic boundary conditions is progressively simulated. The present study shows that GoL can be remodeled as a parameter-adjustable CA-based logistic model applicable for simulating the population dynamics of organisms, by emphasizing the intrinsic modes of density effects found in original GoL which are equivalent to the logistic and Allee effects observed in population dynamics in living organisms. The strategy taken was to design a novel Hill-type density-responsive algorithm functioning behind the actions of the logistic CA model extended from GoL. Lastly, the growth curves simulated by the modified GoL and logistic model were compared to clarify that the growth patterns in GoL obey the logistic growth prediction under strong influence of carrying capacity, but the harm by low density could be overcome by local configuration of live cells.																	1349-4198	1349-418X				OCT	2020	16	5					1655	1666		10.24507/ijicic.16.05.1655													
J								MULTI-RESOURCE EQUILIBRIUM OPTIMIZATION OF SCIENTIFIC RESEARCH PROJECTS BASED ON PIGEON COLONY ALGORITHM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Pigeon colony algorithm; Resource importance evaluation; Multi-resource balanced optimization; Research project management	PARTICLE SWARM OPTIMIZATION; INSPIRED OPTIMIZATION; FRAMEWORK	Balanced use of multiple resources has a significant impact on the quality of scientific research projects. Resources can be balanced by rationally arranging the implementation time of each project task. Traditional optimization problem solutions such as `fixed project cycle and resource balance' include intelligent optimization algorithms such as genetic algorithms and particle swarm optimization. However, this paper innovatively applies the pigeon population algorithm to balancing and optimizing the use of multiple resources in scientific research projects. Firstly, the three aspects of cost, time difference and work importance are considered in order to establish a comprehensive evaluation system based on resource importance. A multi-resource equilibrium optimization mathematical model is then proposed in order to minimize the resource use variance. Finally, an example is tested to verify the effectiveness of the algorithm. Experiments show that the pigeon colony algorithm can effectively solve the optimal solution of multi-resource equilibrium optimization in scientific research. The work plan arrangement provided is more balanced than the initial solution and the suboptimal result chosen by project managers. Therefore, the pigeon colony algorithm has wide application prospects for scientific research projects and will have wide application prospects.																	1349-4198	1349-418X				OCT	2020	16	5					1667	1680		10.24507/ijicic.16.05.1667													
J								IMPUTATION USING THE SINGULAR VALUE DECOMPOSITION: VARIANTS OF EXISTING METHODS, PROPOSED AND ASSESSED	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Missing values; Singular value decomposition; Uncertainty; Imputation; Iterative computational scheme	MULTIPLE IMPUTATION; CROSS-VALIDATION; MATRIX; AMMI; COMPONENTS; CHOICE; MODELS	Complete data matrices are required for some statistical analysis techniques, making imputation of missing data necessary in certain circumstances. The Krzanowski imputation system is based on singular value decomposition of a matrix and has no distributional or structural assumptions, but the system needs an imputation refining process through an iterative scheme. Two such iterative schemes already exist: expectation-maximization, Bro et al. and parity check, Arciniegas-Alarcon et al. The aim of this study is to present new variants of the basic method and to determine which iterative scheme produces the higher quality imputations. For this a simulation study was performed, and from incomplete matrices the quality of the imputations was assessed by estimating their uncertainty and by other criteria such as variance, bias and mean square error when a parameter of interest is considered. The best results were found using iterations with parity check and eliminating the singular values of the imputation equation.																	1349-4198	1349-418X				OCT	2020	16	5					1681	1696		10.24507/ijicic.16.05.1681													
J								H-infinity FAULT DETECTION AND CONTROL FOR CONTINUOUS-TIME TAKAGI-SUGENO FUZZY SYSTEMS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Fault detection; Control; Lyapunov function; Linear matrix inequality; Takagi-Sugeno fuzzy model	EXPONENTIAL STABILITY; SWITCHED SYSTEMS; FILTER DESIGN; DELAY	This paper studies the fault detection and control problem for nonlinear continuous-time fuzzy systems. The nonlinear control systems are modeled through a Takagi-Sugeno model. The main idea focuses on designing a fault detection observer and controller such that the impact of the unknown inputs and the faults on the system is minimized in the sense of the H-infinity norm. To develop sufficient condition of exponential stability, we design an observer to construct the residual signal and the controller by using the Lyapunov function and the H-infinity performance. The results are established in terms of linear matrix inequalities (LMIs). Finally, simulations results are provided to verify the effectiveness of the presented scheme.																	1349-4198	1349-418X				OCT	2020	16	5					1697	1710		10.24507/ijicic.16.05.1697													
J								RESEARCH ON ENGLISH SPEECH ENHANCEMENT ALGORITHM BASED ON IMPROVED SPECTRAL SUBTRACTION AND DEEP NEURAL NETWORK	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Improved spectrum subtraction; Deep neural network; Speech enhancement; Amplitude spectrum; English communication	NOISE	In order to solve the introduced unstructured voiceless problems of conventional spectrum subtraction in English speech signals enhancement, this paper proposes a novel English speech signals enhancement algorithm. This algorithm uses an improved minimal controlled recursive averaging (IMCRA) method to estimate noise spectrum, and tracks the estimated noise spectrum in real time. Then, the deep neural network (DNN) is used to construct the nonlinear mapping function of log amplitude spectrum between speech with noises and ideal pure speech for English speech enhancement. To validate the feasibility and effectiveness of the proposed algorithm, the standard IEEE speech signals and Noise-91 noise signals are used for experiments. Experimental results have shown that the proposed IMCRA method has stronger ability to avoid noises in speech signals, and the DNN method can well recover the speech components and spectrum structure polluted by noises. To enhance English speech in daily international speech communication, the proposed combination method has strong robustness to various real noise environments, and brings significant improvement to interpersonal communication and human computer communication.																	1349-4198	1349-418X				OCT	2020	16	5					1711	1723		10.24507/ijicic.16.05.1711													
J								DIMENSION FOR MULTI-FUZZY FRACTAL SETS USING HYPERBOLIC FUZZY DYNAMICAL SYSTEM	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Fractal dimension (FD); Multi-fractal space (MFS); Multi-fuzzy fractal space (MFFS); Multi-fractal set (MF-set); Iterated function system (IFS); Capacity dimension		One of the approaches to a fuzzy metric space (FMS) is a fuzzy fractal space (FFS). The important properties of an FFS provide advantages when approximating and analyzing images and many other objects. A finite number of FFSs collected via a Cartesian product generate a new space known as a multi-fuzzy fractal space (MFFS). Therefore, the elements of an MFFS form the union of the elements of the FFSs. However, finding the dimension of the MFFS is a challenge, and it should be constructed based on the dimensions of the FFSs making up the space. In this paper, we proposed a theoretical proof for the existence of the fractal dimension of a nonoverlapping or just touching multi-fuzzy fractal set (MFF-set) using a hyperbolic fuzzy dynamical system consisting of n = 2, 3 and .4 objects. However, a theoretical proof must first be provided for transforming the notation used in a geometrical figure to that used in matrix algebra, taking account of the notation used when showing the existence of an attractor of hyperbolic fuzzy dynamical system and the dimension for MFF-sets.																	1349-4198	1349-418X				OCT	2020	16	5					1725	1738		10.24507/ijicic.16.05.1725													
J								RELIABLE BROADCAST FOR WIFI-BASED INTERNET OF THINGS THROUGH MULTI-ACCESS EDGE-DYNAMIC FEC ADAPTATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										FEC; Internet of Things (IoT); Reliable broadcast; MEC; Wireless access point; LT; WiFi		In WiFi-based IoT scenarios, reliable broadcast plays an important role in distributing data to surrounding devices. However, it has been greatly challenged due to nonperfect channel and network conditions. To improve the reliability of the broadcast, this paper presents an architecture which takes advantage of FEC dynamic adaptation scheme and Multi-access Edge Computing (MEC) providing services near the end devices. The proposal involves an element, called the Multi-access Edge-Dynamic FEC adaptation function (ME-DFEC), which includes Wireless Monitor module, Adaptive FEC Algorithm module and FEC Encoder module. Upon the element, by introducing a standard deviation threshold and an equilibrium parameter, the proposed Adaptive FEC Algorithm adjusts FEC rate adaptively according to the wireless channel and network traffic load conditions. The experiment results show that the data recovery probability of ME-DFEC outperforms the Legacy scheme by 59.89% and 45.08% at best under light and heavy network load conditions, respectively. It can also significantly improve packet delivery ratio and get a relatively high data recovery efficiency compared with the Sender-Based FEC scheme, the AP-Based SFEC scheme and the Legacy scheme. Moreover, ME-DFEC can significantly improve wired network resources utilization compared with the traditional Sender-Based FEC scheme.																	1349-4198	1349-418X				OCT	2020	16	5					1739	1755		10.24507/ijicic.16.05.1739													
J								FLOW TRACKING OF GLUE SYSTEM BASED ON NON-SINGULAR TERMINAL SLIDING MODE ACTIVE DISTURBANCE REJECTION CONTROL	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Traffic tracking; Extended state observer; Auto disturbance rejection control; Non-singular terminal sliding mode control; Glue system		In this study, a control strategy combining active disturbance rejection control (ADRC) with non-singular terminal sliding mode control (NTSMC) is proposed for the uncertainty and external interference of the glue system model. The total disturbance of the system is mainly estimated by the extended state observer in ADRC, and NTSMC is used to compensate the system. The introduction of NTSMC can lead the system to converge in a limited time and can improve the control accuracy of the system. The extended state observer is also effective in eliminating chattering caused by discontinuous control. Through data collection on an experimental platform and MATLAB system identification, the proposed method is analyzed for stability. The proposed ADRC-NTSMC method achieves higher flow tracking accuracy and better active suppression of time-varying disturbances than the nonlinear proportional-integral-derivative method and existing ADRC. The simulation results thus verify the feasibility and effectiveness of the proposed strategy.																	1349-4198	1349-418X				OCT	2020	16	5					1757	1768		10.24507/ijicic.16.05.1757													
J								PERCEPTIVE AUGMENTED REALITY-BASED INTERFACE FOR ROBOT TASK PLANNING AND VISUALIZATION	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Robot programming; Human-Robot Interaction (HRI); Augmented reality; Collision-free path; Stereo vision	SIMULATION	Robots are often used to replace humans in hazardous, uncomfortable and tedious works. However, due to the low repeatability and high versatility in High-Mix Low-Volume (HMLV) manufacturing, the cost of robots' programming is still significant. Programming methods based on getting in direct contact with robots, although intuitive, are not always allowed for safety concerns. Moreover, unstructured environments pose an additional challenge where a collision-free path including, not only the end-effector but also the entire robot links, is required. In this research, an intuitive semi-automatic offline robot programming method based on Augmented Reality (AR) and Stereo Vision (SV) system is proposed. The method has a simple user interface where the operator can intuitively program a remotely located robot in unstructured environments. The human,robot interface system is formulated by information fusion of stereo vision data, proposed AR algorithm, and human intuitiveness. Experiments are conducted to evaluate the proposed system. Candidate operators are given a task of programming a remotely located 6-DOF robot to accomplish a free-of-collision pick-and-place operation in unstructured environment. The results showed effectiveness in robotic task implementation.																	1349-4198	1349-418X				OCT	2020	16	5					1769	1785		10.24507/ijicic.16.05.1769													
J								MINING PUBLIC OPINION ON RADICALISM IN SOCIAL MEDIA VIA SENTIMENT ANALYSIS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Social media; Sentiment classification; Hate speech; Extremism; Radicalism; Deep learning		The identification and classification of hate speech, extremism, and radicalism in social media are very important topics today because they have a wide negative impact on society. Hostile groups use this media to spread their hate speech, ideology, and recruitment of individuals. This study aims to propose a new method using deep learning to classify the utterances of hate, extremism, and radicalism in Indonesian which are posted on social media. This method uses word2vec as word embedding and the combination of Restricted Boltzmann Machine and back-propagation network as our basic classification method. The model can achieve 81.63% accuracy to predict radicalism and hate-speech. Our model outperforms the baseline classifier methods based on the comparison in experimental results.																	1349-4198	1349-418X				OCT	2020	16	5					1787	1800		10.24507/ijicic.16.05.1787													
J								PERSONAL IDENTIFICATION BY STEADY-STATE VISUAL EVOKED POTENTIALS BASED ON VOTING PROCESS BY MAHALANOBIS DISTANCE	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Personal identification; Steady-state visual evoked potential (SSVEP); Electroencephalogram (EEG); Voting process; Mahalanobis distance	EEG; AUTHENTICATION; ROBUSTNESS	In this study, we attempt personal authentication using steady-state visual evoked potentials (SSVEPs), a type of evoked electroencephalographic brain activity generated by external visual stimuli. We recorded SSVEPs induced by a 5-Hz light stimulus from 16 participants. Recordings were from four electrodes, and multivariate autoregressive coefficients were used as features for authentication. Subsequently, classification based on the Mahalanobis distance was performed using the multivariate autoregressive coefficients. The authentication was performed under two conditions: 1) considering only those registered in the database and 2) considering unregistered third persons. Furthermore, we examined the effectiveness of the voting process, in which the person is authenticated on the basis of voting on multiple test samples. When authentication proceeded using only registrants, accuracy was higher when four electrodes were used than when two electrodes were used, and the voting process improved identification accuracy to 96.4%. Authentication using unregistered third persons was also more accurate with four electrodes than with two electrodes. The accuracy was 75.8% when voting was not applied and reached 90.4% when voting was applied. Our method, which can authenticate an individual in just a few seconds, is considered effective for realizing personal authentication by SSVEP.																	1349-4198	1349-418X				OCT	2020	16	5					1801	1810		10.24507/ijicic.16.05.1801													
J								A NOVEL FINITE-TIME EXTENDED STATE OBSERVER FOR A CLASS OF NONLINEAR SYSTEM WITH EXTERNAL DISTURBANCE	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Extended state observer; Finite time convergence; Disturbance observer; Switching term; Fractional power	SLIDING MODE CONTROL; POSITION TRACKING; VEHICLE	In this paper, a novel finite-time extended state observer is proposed for a class of nonlinear systems with external disturbance. Considering external disturbance as an additional state, disturbance observer design is transformed into state observer design. The newly developed extended state observer adopts fractional power and switching term that are related to output estimation error to achieve finite time convergence for all error states. A numerical simulation is implemented to verify the performance of the proposed novel finite-time extended state observer.																	1349-4198	1349-418X				OCT	2020	16	5					1811	1820		10.24507/ijicic.16.05.1811													
J								DEVELOPMENT OF A SKIN TEXTURE EVALUATION SYSTEM USING A CONVOLUTIONAL NEURAL NETWORK	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL										Skin texture; Evaluation system; Convolutional neural network (CNN); Deep learning		Currently, various methods are used to evaluate the beauty of skin, but problems arise with evaluation accuracy and the time required for evaluation. Previous research has proposed a method in which researchers select features and evaluate skin texture using machine learning with a three-layer neural network. However, results of this research were discrepant from visual evaluation by experts. In this paper, we describe the development of a convolutional neural network that acquires skin features through learning. We used images captured with a microscope as input data and visual evaluation scores as training data. To evaluate performance, we examined the correlation coefficient between the estimated evaluation score by the convolutional neural network and the visual evaluation score, as well as the matching rate of all data scores. When data from a single subject were used for learning but were not used as test data (an "open set"), the correlation coefficient and matching rate were 0.903 and 73.2%, respectively. Alternately, when data from a single subject were used for both learning and test data (a "closed set"), the correlation coefficient and matching rate were 0.922 and 77.8%, respectively. In each case, these values were significantly higher than those of previous studies.																	1349-4198	1349-418X				OCT	2020	16	5					1821	1827		10.24507/ijicic.16.05.1821													
J								Measuring text similarity based on structure and word embedding	COGNITIVE SYSTEMS RESEARCH												The problem of finding the similarity between natural language sentences is crucial for many applications in Natural Language Processing (NLP). An accurate calculation of similarity between sentences is highly needed. Many approaches depend on word-to-word similarity to measure sentence similarity. This paper proposes a new approach to improve the accuracy of the sentence similarity calculation. The proposed approach combines different similarity measures in the calculation of sentence similarity. In addition to traditional word-to-word similarity measure, the proposed approach exploits sentence semantic structure. Discourse representation structure (DRS) which is a semantic representation for natural sentences is generated and used to calculated structure similarity. Furthermore, word order similarity is measured to consider the order of words in sentences. Experiments show that exploiting structural information achieves good results. Moreover, the proposed method outperforms the current approaches on a standard benchmark dataset achieving 0.8813 Pearson correlation with human similarity. (C) 2020 Elsevier B.V. All rights reserved.																	2214-4366	1389-0417				OCT	2020	63						1	10		10.1016/j.cogsys.2020.04.002													
J								Hierarchical growing grid networks for skeleton based action recognition	COGNITIVE SYSTEMS RESEARCH										Action recognition; Growing grid networks; Human-robot interaction; Self-organizing neural networks; Hierarchical models; Semi-supervised learning	NEURAL-NETWORK; POSE; FEATURES; CLASSIFICATION; PERCEPTION; DYNAMICS; MOTION	In this paper, a novel cognitive architecture for action recognition is developed by applying layers of growing grid neural networks. Using these layers makes the system capable of automatically arranging its representational structure. In addition to the expansion of the neural map during the growth phase, the system is provided with a prior knowledge of the input space, which increases the processing speed of the learning phase. Apart from two layers of growing grid networks the architecture is composed of a preprocessing layer, an ordered vector representation layer and a one-layer supervised neural network. These layers are designed to solve the action recognition problem. The first-layer growing grid receives the input data of human actions and the neural map generates an action pattern vector representing each action sequence by connecting the elicited activation of the trained map. The pattern vectors are then sent to the ordered vector representation layer to build the time-invariant input vectors of key activations for the second-layer growing grid. The second-layer growing grid categorizes the input vectors to the corresponding action clusters/sub-clusters and finally the one-layer supervised neural network labels the shaped clusters with action labels. Three experiments using different datasets of actions show that the system is capable of learning to categorize the actions quickly and efficiently. The performance of the growing grid architecture is compared with the results from a system based on Self-Organizing Maps, showing that the growing grid architecture performs significantly superior on the action recognition tasks. (C) 2020 The Author. Published by Elsevier B.V.																	2214-4366	1389-0417				OCT	2020	63						11	29		10.1016/j.cogsys.2020.05.002													
J								ELM-HTM guided bio-inspired unsupervised learning for anomalous trajectory classification	COGNITIVE SYSTEMS RESEARCH										Trajectory analysis; Anomaly detection; ELM; HTM; Bio-inspired learning	MACHINE	Artificial intelligent systems often model the solutions of typical machine learning problems, inspired by biological processes, because of the biological system is faster and much adaptive than deep learning. The utility of bio-inspired learning methods lie in its ability to discover unknown patterns, and its less dependence on mathematical modeling or exhaustive training. In this paper, we propose a new bio-inspired learning model for a single-class classifier to detect abnormality in video object trajectories. The method uses a simple but dynamic extreme learning machine (ELM) and hierarchical temporal memory (HTM) together referred to as ELM-HTM in an unsupervised way to learn and classify time series patterns. The method has been tested on trajectory sequences in traffic surveillance to find abnormal behaviors such as high-speed, unusual stops, driving in wrong directions, loitering, etc. Experiments have also been performed with 3D air signatures captured using sensors and used for biometric authentication(forged/genuine). The results indicate a significant gain over training time and classification accuracy. The proposed method outperforms in predicting long-time patterns by observing small steps with an average accuracy gain of 15% as compared to the state-of-the-art HTM. The method has applications in detecting abnormal activities in videos by learning the movement patterns as well as in biometric authentication. (C) 2020 The Author(s). Published by Elsevier B.V.																	2214-4366	1389-0417				OCT	2020	63						30	41		10.1016/j.cogsys.2020.04.003													
J								Safe and optimal navigation for autonomous multi-rotor aerial vehicle in a dynamic known environment by a decomposition-coordination method	COGNITIVE SYSTEMS RESEARCH										Unmanned aerial vehicle; Decomposition-Coordination Method; Optimal navigation; Nonlinear control; Autonomous navigation	DRONES	In this paper, we present a new solution for the Autonomous navigation problem, using a Decomposition-Coordination Method (DCM) 1. The main purpose of this work is to compute an optimal and safe path for the multi-rotor Unmanned Aerial Vehicle (UAV) in a dynamic environment, moving from an initial location to the desired state. We assume that the flight environment is totally known to a supervisory unit, and the positions and trajectories of dynamic obstacles could be known in real-time, thus to perform in such environment a high reactivity is required as well as good connectivity with the supervisory unit that provides the safe path, each time one obstacle or more are detected on the road, so that the UAV could autonomously diverts from the unsafe path to the new safe one, and avoid the potential collisions. First and foremost, we choose a generalized nonlinear model for the multi-rotors in view of the rotational and translational dynamics of the UAV. We then associate that model with the objective functions. After that, we proceed to the resolution of the multi-objective optimization problem using our approach of decomposition-coordination. The principle of this method consists in decomposing the system into several smaller subsystems to simplify the treatment. Then we achieve the coordination afterward using Lagrange multipliers. To prove the convergence and stability of our method we make use of a Lyapunov function chosen particularly for this system. In the last section we present the simulation results, to confirm the reliability of our method. (C) 2020 Elsevier B.V. All rights reserved.																	2214-4366	1389-0417				OCT	2020	63						42	54		10.1016/j.cogsys.2020.05.003													
J								Importance-weighted conditional adversarial network for unsupervised domain adaptation	EXPERT SYSTEMS WITH APPLICATIONS										Domain adaptation; Deep learning; Adversarial learning; Importance weightage; Sample selection		In the construction of expert and intelligent systems, annotating and curating large datasets is very expensive; hence, there is a need to transfer the knowledge from existing annotated datasets to unlabeled data. However, data that are relevant for a specific application usually differ from publicly available datasets because they are sampled from a different domain. Domain adaptation (DA) has emerged as an efficient technique to compensate for such a domain shift. Recent studies have suggested that deep adversarial networks can achieve promising results for DA problems. However, existing adversarial DA methods assign equal importance to different examples and ignore the effect of difference in source domain samples or noise on adversarial performance. Moreover, most DA methods only focus on reducing the distribution difference, but not to learn a good target domain model. To address these issues, we propose an importance-weighted conditional adversarial (IWCA) network for unsupervised DA. In this study, an importance criterion based on domain similarity and prediction certainty is proposed to assign weights to different samples, which can reduce the harmful effects of difficult-to-transfer samples when reducing their cross-domain class conditional distribution differences. Furthermore, a sample selection criterion derived from the perspective of transfer cross validation is used to progressively select appropriate pseudo-labeled target samples to fine-tune the target model. These two criteria work in an EM-like manner that alternating align class conditional distribution for weighted samples and progressively select certain pseudo-labeled target samples to fine-tune the joint model. In this manner, the network will gradually generate features that approximate the actual conditional distribution of the target domain. The results of extensive experiments conducted on four datasets show that IWCA outperforms several state-of-the-art deep DA methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155						CP3	U18	113404	10.1016/j.eswa.2020.113404													
J								An event-driven behavior trees extension to facilitate non-player multi-agent coordination in video games	EXPERT SYSTEMS WITH APPLICATIONS										Agents; Coordination; Event-driven behavior trees; Multi-agent systems; Video game development		In this paper, we extend behavior trees (BTs), a behavior creation method that is popular in the video game industry, with three new types of nodes that facilitate the design and implementation of non-player characters (NPCs) that need to coordinate with each other. We provide an implementation and a methodology to use the coordination nodes of our extension appropriately, and we show how to use them to develop an application scenario. In the last years, coordination in multi-agent systems has been a very active research field, both from theoretical and practical points of view. Something similar has happened with the development of new tools for the video game industry. Our approach contributes to both areas by providing a novel extension that facilitates the design and implementation of agents that need to coordinate with each other. In video games, agents or NPCs are-as their name implies-characters that are not controlled by the player but by the game through an algorithmic, predetermined, or responsive behavior, or a more sophisticated AI technique. Some video games require NPCs with dynamic, credible, and intelligently unpredictable behaviors to keep players engaged and immersed. Instead of endowing NPCs with very complex individual behaviors, a feasible way to improve their unpredictability in an intelligent and credible manner is allowing them to coordinate with each other. Since BTs focus on the creation of individual behaviors, coordinated behaviors nowadays tend to be achieved by hard-coding the coordination itself. However, that ad hoc solution partially drives away some of the benefits that popularized BTs: Being visually intuitive, scalable, and reusable. For this reason, we propose an extension to BTs that developers can use to coordinate NPCs without going against the development paradigm: creating complex behaviors by designing an intuitive tree structure. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113457	10.1016/j.eswa.2020.113457													
J								No free lunch but a cheaper supper: A general framework for streaming anomaly detection	EXPERT SYSTEMS WITH APPLICATIONS										Anomaly detection; Stream mining; Reservoir sampling; Online learning	LOCAL OUTLIER DETECTION; FAULT-DIAGNOSIS; TIME-SERIES	In recent years, research interest in detecting anomalies in temporal streaming data has increased significantly. A variety of algorithms are being developed in the data mining community. They can be broadly divided into two categories, namely general-purpose and ad hoc ones. In most cases, general approaches assume a one-size-fits-all solution model, and strive to design a single "optimal" anomaly detector which can detect all anomalies in any domain. To date, there exists no universal method that has been shown to outperform the others across different anomaly types, use cases and datasets. In this paper, we propose SAFARI, a framework created by abstracting and unifying the fundamental tasks within the streaming anomaly detection. SAFARI provides a flexible and extensible anomaly detection procedure to overcome the limitations of one-size-fits-all solutions. Such abstraction helps to facilitate more elaborate algorithm comparisons by allowing us to isolate the effects of shared and unique characteristics of diverse algorithms on the performance. Using the framework, we have identified a research gap that motivated us to propose a novel learning strategy. We implemented twenty different anomaly detectors and conducted an extensive evaluation study, comparing their performances using real-world benchmark datasets with different properties. The results indicate that there is no single superior detector which works perfectly for every case, proving our hypothesis that "there is no free lunch" in the streaming anomaly detection world. Finally, we discuss the benefits and drawbacks of each method in-depth, drawing a set of conclusions and guidelines to guide future users of SAFARI. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113453	10.1016/j.eswa.2020.113453													
J								A data analytic framework for physical fatigue management using wearable sensors	EXPERT SYSTEMS WITH APPLICATIONS										Functional data analysis; Human performance modeling; Internet of Things (IoT); Manufacturing; Occupational safety	MUSCLE FATIGUE; ACTIVITY RECOGNITION; ENSEMBLE METHODS; LIFTING TASKS; GAIT; WORK; SELECTION; CANCER; LUMBAR; AGE	The use of expert systems in optimizing and transforming human performance has been limited in practice due to the lack of understanding of how an individual's performance deteriorates with fatigue accumulation, which can vary based on both the worker and the workplace conditions. As a first step toward realizing the human-centered approach to artificial intelligence and expert systems, this paper lays the foundation for a data analytic approach to managing fatigue in physically-demanding workplaces. The proposed framework capitalizes on continuously collected human performance data from wearable sensor technologies, and is centered around four distinct phases of fatigue: (a) detection, where machine learning methodologies are deployed to detect the occurrence of fatigue; (b) identification, where key features relating to the fatigue occurrence is to be identified; (c) diagnosis, where the fatigue mode is identified based on the knowledge generated in the previous two phases; and (d) recovery, where a suitable intervention is applied to return the worker to mitigate the detrimental effects of fatigue on the worker. Moreover, the framework establishes criteria for feature and machine learning algorithm selection for fatigue management. Two specific application cases of the framework, for two types of manufacturing-related tasks, are presented. Based on the proposed framework and a large number of test sets used in the two case studies, we have shown that: (i) only one wearable sensor is needed for fatigue detection with an average accuracy of >= 0.850 and a random forest model comprised of < 7 features; and (ii) the selected features are task-dependent, and thus capturing different modes of fatigue. Therefore, this research presents an important foundation for future expert systems that attempt to quantify/predict changes in workers' performance as an input to prescriptive rest-break scheduling, job-rotation, and task assignment models. To encourage future work in this important area, we provide links to our data and code as Supplementary materials. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113405	10.1016/j.eswa.2020.113405													
J								An efficient Harris hawks-inspired image segmentation method	EXPERT SYSTEMS WITH APPLICATIONS										Multilevel thresholding; Digital mammograms; Harris hawks optimization; Metaheuristics; Minimum cross entropy	WHALE OPTIMIZATION ALGORITHM; SALP SWARM ALGORITHM; GLOBAL OPTIMIZATION; ENTROPY; SEARCH; COLOR; IDENTIFICATION; QUANTIZATION; STRATEGY	Segmentation is a crucial phase in image processing because it simplifies the representation of an image and facilitates its analysis. The multilevel thresholding method is more efficient for segmenting digital mammograms compared to the classic bi-level thresholding since it uses a higher number of intensities to represent different regions in the image. In the literature, there are different techniques for multilevel segmentation; however, most of these approaches do not obtain good segmented images. In addition, they are computationally expensive. Recently, statistical criteria such as Otsu, Kapur, and cross-entropy have been utilized in combination with evolutionary and swarm-based strategies to investigate the optimal threshold values for multilevel segmentation. In this paper, an efficient methodology for multilevel segmentation is proposed using the Harris Hawks Optimization (HHO) algorithm and the minimum cross-entropy as a fitness function. To substantiate the results and effectiveness of the HHO-based method, it has been tested over a benchmark set of reference images, with the Berkeley segmentation database, and with medical images of digital mammography. The proposed HHO-based solver is verified based on other comparable optimizers and two machine learning algorithms K-means and the Fuzzy IterAg. The comparisons were performed based on three groups. This first one is to provide evidence of the optimization capabilities of the HHO using the Wilcoxon test, and the second is to verify segmented image quality using the PSNR, SSIM, and FSIM metrics. Then, the third way is to verify the segmented image comparing it with the ground-truth through the metrics PRI, GCE, and VoI. The experimental results, which are validated by statistical analysis, show that the introduced method produces efficient and reliable results in terms of quality, consistency, and accuracy in comparison with the other methods. This HHO-based method presents an improvement over other segmentation approaches that are currently used in the literature. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113428	10.1016/j.eswa.2020.113428													
J								The estimation of low and high-pass active filter parameters with opposite charged system search algorithm	EXPERT SYSTEMS WITH APPLICATIONS										Charged system search algorithm (CSS); Opposite charged system search algorithm (OCSS); Sallen-Key topology Butterworth low and high-pass active filters; E24 standard series	POWER DISPATCH PROBLEMS; DIFFERENTIAL EVOLUTION; COMPONENT SELECTION; OPTIMIZATION; DESIGN	Algorithms are frequently used to solve problems that have a large search space and take a long time to be mathematically solved. They can later be improved with different improvement methods based on the structure and the type of the problem. In this study, the charged system search algorithm (CSS), which has been successfully implemented in the solutions of numerous engineering problems studied within the literature, was improved by introducing opposition-based learning method (OBL) to it in two different methods. With these improved algorithms, solutions were developed for 30-dimensional multimodal test functions in the first place and the results were discussed. In the second place, the parameters of active filters given below were determined from E24 standard series with developed approaches. Filters are electronic circuits that enhance the wanted frequency components of electric signals applied on their inputs and remove harmonics and interferences from these signals. They are divided into two types; active and passive filters. Active filters are produced with transistors or op-amps. They are financially more advantageous compared to passive filters. These filters are preferred especially in low frequencies due to their low costs. Adjustable for a large frequency domain, active filters are very convenient in terms of size and weight and their designs are highly simple. They can easily be connected successively without affecting one another. In this study, the parameter values of Sallen-Key topology Butterworth low and high-pass active filters, which have an extensive area of use, were determined through improved algorithms. My suggestions for the future studies are these: the effects of the opposite position learning approach on other heuristic algorithms can be analysed solving test functions and different engineering problems; different approaches other than the two approaches proposed in this study, can be developed for the opposite position learning concept; LPF and HPF designs solved in the study can be solved for different degrees and stages and finally new designs can be done for different filter types and different resistor and capacitor series that haven't been handled in this study. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113474	10.1016/j.eswa.2020.113474													
J								A physics-informed Run-to-Run control framework for semiconductor manufacturing	EXPERT SYSTEMS WITH APPLICATIONS										Advanced Process Control (APC); Chemical-Mechanical Polishing (CMP); Dynamic Bayesian Network (DBN); Fault Detection and Classification (FDC); Physics-informed; Run-to-Run (R2R) control	VIRTUAL METROLOGY	For decades, Run-to-Run (R2R) controllers have been widely implemented in semiconductor manufacturing. They operate over key process parameters on the basis of the metrological measurements acquired from the process and their deviations from the target setpoints. Conventionally, R2R controllers have been implemented independently of the actual equipment condition, which is obviously affecting the process stability and performance. Therefore, both equipment signals and process states shall be considered to make the R2R controllers more robust to the equipment condition drifts. In this paper, we propose a novel physics-informed framework to integrate the real-time equipment condition, based on the Fault Detection and Classification (FDC) data, into the R2R controllers. By utilizing Dynamic Bayesian Networks (DBN), the implicit relationship structure between metrology measurements, FDC indicators, and R2R regulators can be learned and reviewed explicitly. The structure shall be further reviewed to valid with the existing relationships and expert knowledge. Infeasible causalities on the structure will be constrained via setting up the blacklist at the structure learning stage. The proposed framework consists of the offline modeling stage, which incorporates the process, equipment variables, and the expert knowledge in the structure learning, and the online control stage, which constructs the Structured R2R controller (SRC) based on the relationship structure. As a result, the model is consistent by design with empirically known relationships and fundamental physical laws. The proposed SRC not only optimizes the operation with respect to the target control values but also considers the equipment and process states simultaneously. The effectiveness of SRC and the derivative control strategy are validated through a real dataset of a Chemical-Mechanical Polishing (CMP) process, and two simulated studies. (C) 2020 Elsevier Ltd. All rights reserved.																	0957-4174	1873-6793				OCT 1	2020	155								113424	10.1016/j.eswa.2020.113424													
J								BROWSER FINGERPRINT CODING METHODS INCREASING THE EFFECTIVENESS OF USER IDENTIFICATION IN THE WEB TRAFFIC	JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING RESEARCH										browser fingerprint; device fingerprint; LSH algorithm; autoencoder		Web-based browser fingerprint (or device fingerprint) is a tool used to identify and track user activity in web traffic. It is also used to identify computers that are abusing online advertising and also to prevent credit card fraud. A device fingerprint is created by extracting multiple parameter values from a browser API (e.g. operating system type or browser version). The acquired parameter values are then used to create a hash using the hash function. The disadvantage of using this method is too high susceptibility to small, normally occurring changes (e.g. when changing the browser version number or screen resolution). Minor changes in the input values generate a completely different fingerprint hash, making it impossible to find similar ones in the database. On the other hand, omitting these unstable values when creating a hash, significantly limits the ability of the fingerprint to distinguish between devices. This weak point is commonly exploited by fraudsters who knowingly evade this form of protection by deliberately changing the value of device parameters. The paper presents methods that significantly limit this type of activity. New algorithms for coding and comparing fingerprints are presented, in which the values of parameters with low stability and low entropy are especially taken into account. The fingerprint generation methods are based on popular Minhash, the LSH, and autoencoder methods. The effectiveness of coding and comparing each of the presented methods was also examined in comparison with the currently used hash generation method. Authentic data of the devices and browsers of users visiting 186 different websites were collected for the research.																	2083-2567	2449-6499				OCT	2020	10	4					243	253		10.2478/jaiscr-2020-0016													
J								DATA-DRIVEN TEMPORAL-SPATIAL MODEL FOR THE PREDICTION OF AQI IN NANJING	JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING RESEARCH										Air quality prediction; k-Nearest Neighbor; BP neural network; Non-monitoring stations	URBAN BACKGROUND SITES; PARTICULATE MATTER; FORECASTING-MODEL; HAZE POLLUTION; AIR-POLLUTION; PM2.5; PM10; FOG; CHINA	Air quality data prediction in urban area is of great significance to control air pollution and protect the public health. The prediction of the air quality in the monitoring station is well studied in existing researches. However, air-quality-monitor stations are insufficient in most cities and the air quality varies from one place to another dramatically due to complex factors. A novel model is established in this paper to estimate and predict the Air Quality Index (AQI) of the areas without monitoring stations in Nanjing. The proposed model predicts AQI in a non-monitoring area both in temporal dimension and in spatial dimension respectively. The temporal dimension model is presented at first based on the enhanced k-Nearest Neighbor (KNN) algorithm to predict the AQI values among monitoring stations, the acceptability of the results achieves 92% for one-hour prediction. Meanwhile, in order to forecast the evolution of air quality in the spatial dimension, the method is utilized with the help of Back Propagation neural network (BP), which considers geographical distance. Furthermore, to improve the accuracy and adaptability of the spatial model, the similarity of topological structure is introduced. Especially, the temporal-spatial model is built and its adaptability is tested on a specific non-monitoring site, Jiulonghu Campus of Southeast University. The result demonstrates that the acceptability achieves 73.8% on average. The current paper provides strong evidence suggesting that the proposed non-parametric and data-driven approach for air quality forecasting provides promising results.																	2083-2567	2449-6499				OCT	2020	10	4					255	270		10.2478/jaiscr-2020-0017													
J								TRIANGULAR FUZZY-ROUGH SET BASED FUZZIFICATION OF FUZZY RULE-BASED SYSTEMS	JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING RESEARCH										general type-2 fuzzy logic systems; fuzzy-rough fuzzification; regular type-2 t-norms; cropped triangular secondary membership functions	DEFUZZIFICATION; STRATEGIES	In real-world approximation problems, precise input data are economically expensive. Therefore, fuzzy methods devoted to uncertain data are in the focus of current research. Consequently, a method based on fuzzy-rough sets for fuzzification of inputs in a rule-based fuzzy system is discussed in this paper. A triangular membership function is applied to describe the nature of imprecision in data. Firstly, triangular fuzzy partitions are introduced to approximate common antecedent fuzzy rule sets. As a consequence of the proposed method, we obtain a structure of a general (non-interval) type-2 fuzzy logic system in which secondary membership functions are cropped triangular. Then, the possibility of applying so-called regular triangular norms is discussed. Finally, an experimental system constructed on precise data, which is then transformed and verified for uncertain data, is provided to demonstrate its basic properties.																	2083-2567	2449-6499				OCT	2020	10	4					271	285		10.2478/jaiscr-2020-0018													
J								A NOVEL DRIFT DETECTION ALGORITHM BASED ON FEATURES' IMPORTANCE ANALYSIS IN A DATA STREAMS ENVIRONMENT	JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING RESEARCH										data stream mining; random forest; features importance	DECISION TREES; ENSEMBLE	The training set consists of many features that influence the classifier in different degrees. Choosing the most important features and rejecting those that do not carry relevant information is of great importance to the operating of the learned model. In the case of data streams, the importance of the features may additionally change over time. Such changes affect the performance of the classifier but can also be an important indicator of occurring concept-drift. In this work, we propose a new algorithm for data streams classification, called Random Forest with Features Importance (RFFI), which uses the measure of features importance as a drift detector. The RFFT algorithm implements solutions inspired by the Random Forest algorithm to the data stream scenarios. The proposed algorithm combines the ability of ensemble methods for handling slow changes in a data stream with a new method for detecting concept drift occurrence. The work contains an experimental analysis of the proposed algorithm, carried out on synthetic and real data.																	2083-2567	2449-6499				OCT	2020	10	4					287	298		10.2478/jaiscr-2020-0019													
J								LOCAL LEVENBERG-MARQUARDT ALGORITHM FOR LEARNING FEEDFORWAD NEURAL NETWORKS	JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING RESEARCH										feed-forward neural network; neural network learning algorithm; optimization problem; Levenberg-Marquardt algorithm; QR decomposition; Givens rotation	CLASSIFICATION; RECOGNITION	This paper presents a local modification of the Levenberg-Marquardt algorithm (LM). First, the mathematical basics of the classic LM method are shown. The classic LM algorithm is very efficient for learning small neural networks. For bigger neural networks, whose computational complexity grows significantly, it makes this method practically inefficient. In order to overcome this limitation, local modification of the LM is introduced in this paper. The main goal of this paper is to develop a more complexity efficient modification of the LM method by using a local computation. The introduced modification has been tested on the following benchmarks: the function approximation and classification problems. The obtained results have been compared to the classic LM method performance. The paper shows that the local modification of the LM method significantly improves the algorithm's performance for bigger networks. Several possible proposals for future works are suggested.																	2083-2567	2449-6499				OCT	2020	10	4					299	316		10.2478/jaiscr-2020-0020													
J								An efficient attribute-space connected filter on graphs to reconstruct paths in point-clouds	PATTERN RECOGNITION										Graph-based image analysis; Attribute-space connectivity; Orientation-based segmentation; Irregular graph morphology; Graph morphology; Orientation-based path merging; Sub-atomic particle tracking; Straw tube tracker (STT)	OPENINGS	Measurements by many multi-sensor systems can be considered as point-clouds. One such system is the tracker for the PANDA experiment. Charged particles passing through the tracker produce patterns representing their paths. We present a new, graph-based, attribute-space morphological connected filter for reconstructing particle paths through such a detector. We introduce the concept of attribute-spaces and attribute-space connected filters on graphs, rather than binary images and show a new processing scheme to reduce the size of the memory required to store the attribute-space representations of binary images and graphs. The result is an O(Nlog(N)) algorithm with a total recognition error of approximately 0.10, a significant improvement compared to our previous state-of-the-art O(N-2) algorithm with a total error of 0.17. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107467	10.1016/j.patcog.2020.107467													
J								New label propagation algorithm with pairwise constraints	PATTERN RECOGNITION										Cluster analysis; Semi-supervised clustering; Label propagation algorithm; Pairwise constraint; Spectral clustering		The label propagation algorithm is a well-known semi-supervised clustering method, which uses pre-given partial labels as constraints to predict the labels of unlabeled data. However, the algorithm has the following limitations: (1) it does not fully consider the misalignment between the pre-given labels and clustering labels, and (2) it only uses label information as clustering constraints. Real applications not only contain partial label information but pairwise constraints on a dataset. To overcome these deficiencies, a new version of the label propagation algorithm is proposed, which makes use of pairwise relations of labels as constraints to construct an optimization model for spreading labels. Experimental analysis was used to compare the proposed algorithm with 8 other semi-supervised clustering algorithms on 11 benchmark datasets. The experimental results demonstrated that the proposed algorithm is more effective than other algorithms. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107411	10.1016/j.patcog.2020.107411													
J								Structure-aware human pose estimation with graph convolutional networks	PATTERN RECOGNITION										Human pose estimation; Graph convolutional networks; Key points structural relations	CLASSIFICATION; FEATURES	Human pose estimation is the task of localizing body key points from still images. As body key points are inter-connected, it is desirable to model the structural relationships between body key points to further improve the localization performance. In this paper, based on original graph convolutional networks, we propose a novel model, termed Pose Graph Convolutional Network (PGCN), to exploit these important relationships for pose estimation. Specifically, our model builds a directed graph between body key points according to the natural compositional model of a human body. Each node (key point) is represented by a 3-D tensor consisting of multiple feature maps, initially generated by our backbone network, to retain accurate spatial information. Furthermore, attention mechanism is presented to focus on crucial edges (structured information) between key points. PGCN is then learned to map the graph into a set of structure-aware key point representations which encode both structure of human body and appearance information of specific key points. Additionally, we propose two modules for PGCN, i.e., the Local PGCN (L-PGCN) module and Non-Local PGCN (NL-PGCN) module. The former utilizes spatial attention to capture the correlations between the local areas of adjacent key points to refine the location of key points. While the latter captures long-range relationships via non-local operation to associate the challenging key points. By equipping with these two modules, our PGCN can further improve localization performance. Experiments both on single- and multi-person estimation benchmark datasets show that our method consistently outperforms competing state-of-the-art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107410	10.1016/j.patcog.2020.107410													
J								Multi-view subspace clustering via simultaneously learning the representation tensor and affinity matrix	PATTERN RECOGNITION										Multi-view subspace clustering; Low-rank tensor representation; Tensor-singular value decomposition; Adaptive weights; Local manifold	FACTORIZATION; NORM; VIEW	Multi-view subspace clustering aims at separating data points into multiple underlying subspaces according to their multi-view features. Existing low-rank tensor representation-based multi-view subspace clustering algorithms are robust to noise and can preserve the high-order correlations of multi-view features. However, they may suffer from two common problems: (1) the local structures and different importance of each view feature are often neglected; (2) the low-rank representation tensor and affinity matrix are learned separately. To address these issues, we propose a unified framework to learn the Graph regularized Low-rank representation Tensor and Affinity matrix (GLTA) for multi-view subspace clustering. In the proposed GLTA framework, the tensor singular value decomposition-based tensor nuclear norm is adopted to explore the high-order cross-view correlations. The manifold regularization is exploited to preserve the local structures embedded in high-dimensional space. The importance of different features is automatically measured when constructing the final affinity matrix. An iterative algorithm is developed to solve GLTA using the alternating direction method of multipliers. Extensive experiments on seven challenging datasets demonstrate the superiority of GLTA over the state-of-the-art methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107441	10.1016/j.patcog.2020.107441													
J								Orthogonal neighborhood preserving discriminant analysis with patch embedding for face recognition	PATTERN RECOGNITION										Neighborhood preserving; Inter-class separability; Orthogonal projection; Patch alignment; Face recognition	DIMENSIONALITY REDUCTION; FEATURE-EXTRACTION; PROJECTIONS; ILLUMINATION; EIGENFACES; MANIFOLD	Intuitively, all facial images of a person are located on or near a manifold in the high-dimensional image space, and the process of face recognition can be regarded as the recovery process of multiple low-dimensional manifolds. To preserve the manifold structure information of intra-class samples after dimensionality reduction, we proposed a patch-based multi-manifold orthogonal neighborhood-preserving discriminant analysis algorithm, namely ONPDA. From the perspective of path alignment, we consider the intra-class compactness, intra-class structure and inter-class separability simultaneously. Moreover, we infuse intra-class structure information described by the sample reconstruction into intra-class compactness loss, considering the compactness of two reconstruction groups instead of sample pairs in the same class. By analyzing the relationship between the projection direction and the maximum inter-class margin, we select the samples that should participate in the inter-class separability on the patch. Meanwhile, a fast orthogonalization method is performed to obtain the orthogonal projection matrix. Besides, we perform ONPDA in reproducing kernel Hilbert space which gives rise to nonlinear maps, resulting in the kernel ONPDA (KONPDA). Experimental results compared with some state-of-the-art methods on a toy dataset and several benchmark face image databases demonstrate the effectiveness of ONPDA and KONPDA. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107450	10.1016/j.patcog.2020.107450													
J								Multi-dimensional classification via kNN feature augmentation	PATTERN RECOGNITION										Machine learning; Multi-dimensional classification; Feature augmentation; Class dependencies	BAYESIAN NETWORK CLASSIFIERS	In multi-dimensional classification (MDC), each training example is represented by a single instance (feature vector) while associated with multiple class variables, each of which specifies its class membership w.r.t. one specific class space. Most existing MDC approaches try to model dependencies among class variables in output space when inducing predictive functions, while the potential usefulness of manipulating feature space hasn't been investigated. As a first attempt towards feature manipulation in input space for MDC, a simple yet effective approach named KRAM is proposed which enriches the original feature space with augmented features based on kNN techniques. Specifically, simple counting statistics on the class membership of neighboring MDC examples as well as distance information between MDC examples and their k nearest neighbors are used to generate augmented feature vector. In this way, discriminative information from class space is expected to be brought into the feature space which would be helpful to the following MDC predictive model induction. To validate the effectiveness of the proposed feature augmentation techniques, comprehensive comparative studies are conducted over fifteen benchmark data sets. Compared to the original feature space, it is clearly shown that the kNN-augmented features generated by the proposed KRAM approach can significantly improve generalization abilities of existing MDC approaches. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107423	10.1016/j.patcog.2020.107423													
J								A CNN-based 3D human pose estimation based on projection of depth and ridge data	PATTERN RECOGNITION										3D Human pose estimation; 3D Point projection; Ridge data	TRACKING; NETWORK; HAND	We propose a method that use a convolutional neural network (CNN) to estimate human pose by analyzing the projection of the depth and ridge data, which represent local maxima in a distance transform map. To fully utilize the 3D information of depth points, we propose a method to project the depth and ridge data on various directions. The proposed projection method can reduce the 3D information loss, the ridge data can avoid joint drift, and the CNN increases localization accuracy. The proposed method proceeds as follows. (1) We use depth data to segment the human from the background and extract ridge data from human silhouettes. (2) We project the depth and ridge data onto XY, XZ, and ZY planes. (3) ResNet-101 accepts six projected images and use 1 x 1 convolution layers to generate 2D heatmaps and offsets. (4) We generate 2D keypoints per plane by using the soft-argmax operation. (5) We obtain 3D joint positions by using the fully-connected layers. In experiments on the SMMC-10, EVAL, and ITOP datasets, the proposed method achieved the state-of-the-art pose estimation accuracies. The proposed method can eliminate the 3D information loss and drift of joint positions that can occur during estimation of human pose. Keywords: 3D Human pose estimation 3D Point projection Ridge data (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107462	10.1016/j.patcog.2020.107462													
J								Recurrent bag-of-features for visual information analysis	PATTERN RECOGNITION										Bag-of-Features; Recurrent neural networks; Pooling operators; Activity recognition	WORDS; RECOGNITION	Deep Learning (DL) has provided powerful tools for visual information analysis. For example, Convolutional Neural Networks (CNNs) are excelling in complex and challenging image analysis tasks by extracting meaningful feature vectors with high discriminative power. However, these powerful feature vectors are crushed through the pooling layers of the network, that usually implement the pooling operation in a less sophisticated manner. This can lead to significant information loss, especially in cases where the informative content of the data is sequentially distributed over the spatial or temporal dimension, e.g., videos, which often require extracting fine-grained temporal information. A novel stateful recurrent pooling approach, that can overcome the aforementioned limitations, is proposed in this paper. The proposed method is inspired by the well-known Bag-of-Features (BoF) model, but employs a stateful trainable recurrent quantizer, instead of plain static quantization, allowing for efficiently processing sequential data and encoding both their temporal, as well as their spatial aspects. The effectiveness of the proposed Recurrent BoF model to enclose spatio-temporal information compared to other competitive methods is demonstrated using six different datasets and two different tasks. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107380	10.1016/j.patcog.2020.107380													
J								Structure alignment of attributes and visual features for cross-dataset person re-identification	PATTERN RECOGNITION										Person re-identification; Self-supervised strategy; Domain adaptation; Structure alignment; Self-reconstruction	DOMAIN ADAPTATION; IMAGE FUSION	In cross-dataset person re-identification, it is challenging to address the problem of domain shift between training and test data. Although unsupervised domain adaptation methods have been developed, the performance is still much weaker compared with that of supervised methods because these models cannot follow a supervised optimization in unlabeled target domains. To address this problem, a transductive structure alignment-based self-reconstruction dictionary learning approach is proposed in this paper for cross-dataset person re-identification (PRID). Specifically, visual-attribute embedding is first learned to achieve knowledge transfer from the source domain to the target domain. In this process, visual-attribute structures are aligned via class prototype dictionaries to promote the discrimination of predicted semantic attributes by exploiting structure information between the visual feature and class prototype. Moreover, to mitigate domain shift, domain-invariant visual-attribute self-reconstruction is integrated into our dictionary learning framework. An identifier is then constructed by integrating the discriminativeness of attribute and compatibility matrix shared both source domain and target domain. Finally, the pre-learned model is tuned by selecting samples from the target domain which are not labeled but assigned pseudo-labels. Extensive experimental results on benchmark datasets show that our approach outperforms several state-of-the-art approaches. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107414	10.1016/j.patcog.2020.107414													
J								Scale balance for prototype-based binary quantization	PATTERN RECOGNITION										Approximate nearest neighbor search; High-dimensional vectors; Prototype-based binary quantization	PRODUCT QUANTIZATION; NEIGHBOR	Nowadays, prototype-based binary quantization (PBQ) is a promising solution for the approximate nearest neighbor search problem, which simultaneously preserves the affinity structures of prototypes in both Euclidean space as well as those of their codes in binary space. To learn longer binary codes, space decomposition based on product quantization is usually adopted. In practice, we find that the scale between Euclidean distance and Hamming distance usually varies across these decomposed subspaces, which degenerates the performance of PBQ based methods. We make an attempt to balance the scale of these subspaces via a joint optimization problem in the classic PBQ model, and present both an iterative and alternate algorithm for optimization. We conducted experiments on 6 public databases, and demonstrated that our scale balancing based methods SKMH and SABQ outperform state-of-the-art hashing methods including popular prototype-based binary quantization methods, with up to 81.62% relative performance gains when learning 256-bit binary codes. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107409	10.1016/j.patcog.2020.107409													
J								A survey on deep learning methods for scene flow estimation	PATTERN RECOGNITION										Scene flow; Optical flow; Depth estimation; Deep learning	OBJECT DETECTION; STEREO; SUPERRESOLUTION; ACCURACY	Recently, computer vision has achieved remarkable accomplishments in many domains under the thriving of deep learning. Scene flow estimation turns from the classical manual feature construction to the deep convolutional neural network (DCNN) approaches. In this paper, we review recent works about scene flow, mainly focusing on DCNN methods. We present some milestones of scene flow in recent years, and categorize these methods into supervised and unsupervised based methods. Meanwhile, we also review some multi-task methods related to scene flow. At last, we present a performance comparison among different methods. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107378	10.1016/j.patcog.2020.107378													
J								Nonparallel support vector machine with large margin distribution for pattern classification	PATTERN RECOGNITION										Pattern classification; Nonparallel support vector machine; Margin distribution; Generalization performance		The large margin distribution machine (LDM) combines the working principle of support vector machine (SVM) and the margin distribution to directly improve the algorithm's generalization. The margin distribution can be expressed with the margin mean and margin variance. It has been proved to be an efficient algorithm for binary classification. Inspired by the LDM, a novel classifier termed as LMD-NPSVM is proposed to improve the generalization performance of the nonparallel support vector machine (NPSVM) in this paper. Firstly, to meet the structure of NPSVM, the large margin distribution is reconstructed. Then, the linear LMD-NPSVM is built by introducing the reconstructed margin distribution into NPSVM. In addition, the linear case is extended to the nonlinear case with a kernel trick. All experiments show that our LMD-NPSVM is superior to the state-of-the-art algorithms in generalization performance. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107374	10.1016/j.patcog.2020.107374													
J								Graph-based boosting algorithm to learn labeled and unlabeled data	PATTERN RECOGNITION										Graph; Boosting; Semi-supervised learning; Imbalance learning	SEMI-SUPERVISED CLASSIFICATION; MACHINE; PREDICTION; SELECTION; ADABOOST	Ensemble learning is an effective technique to learn the information of data by combining multiple models. But usually the combined models are supervised learning algorithms which need a lot of labeled data to tune their parameters. Some ensemble learning algorithms were proposed to exploit the information of unlabeled data. These methods had to learn the samples with pseudo-labels due to the scarcity of labeled data. But it's inevitable for the samples with pseudo-labels to bring wrong information during training process. In this paper, we will propose a novel graph-based boosting (GBB) algorithm to learn labeled and unlabeled data. GBB is a framework combining many models linearly. And pseudo-labels will not occur during training process. GBB will assign a new weighting vector for the labeled samples and a transformed similarity matrix for all samples to train the combined model at each iteration. We also extend GBB, termed as weighted GBB (WGBB), to learn imbalanced data by adding a weighting vector for the labeled data. Finally, 14 relatively balanced datasets and 22 imbalanced datasets are used to validate the performances of GBB and WGBB respectively. Experimental results illustrate that GBB can achieve a competitive performance and WGBB has an obvious advantage to handle classification problem of imbalanced data, comparing with other related algorithms. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107417	10.1016/j.patcog.2020.107417													
J								Every node counts: Self-ensembling graph convolutional networks for semi-supervised learning	PATTERN RECOGNITION										Teacher-student models; Self-ensemble learning; Graph convolutional networks; Semi-supervised learning		Graph convolutional network (GCN) provides a powerful means for graph-based semi-supervised tasks. However, as a localized first-order approximation of spectral graph convolution, the classic GCN can not take full advantage of unlabeled data, especially when the unlabeled node is far from labeled ones. To capitalize on the information from unlabeled nodes to boost the training for GCN, we propose a novel framework named Self-Ensembling GCN (SEGCN), which marries GCN with Mean Teacher - a powerful self-ensemble learning mechanism for semi-supervised task. SEGCN contains a student model and a teacher model. As a student, it not only learns to correctly classify the labeled nodes, but also tries to be consistent with the teacher on unlabeled nodes in more challenging situations, such as a high dropout rate and graph corrosion. As a teacher, it averages the student model weights and generates more accurate predictions to lead the student. In such a mutual-promoting process, both labeled and unlabeled samples can be fully utilized for backpropagating effective gradients to train GCN. In a variety of semi-supervised classification benchmarks, i.e. Citeseer, Cora, Pubmed and NELL, we validate that the proposed method matches the state of the arts in the classification accuracy. The code is publicly available at https://github.com/RoyalVane/SEGCN. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107451	10.1016/j.patcog.2020.107451													
J								SMPLR: Deep learning based SMPL reverse for 3D human pose and shape recovery	PATTERN RECOGNITION										Deep learning; 3D Human pose; Body shape; SMPL; Denoising autoencoder; Volumetric stack hourglass		In this paper we propose to embed SMPL within a deep-based model to accurately estimate 3D pose and shape from a still RGB image. We use CNN-based 3D joint predictions as an intermediate representation to regress SMPL pose and shape parameters. Later, 3D joints are reconstructed again in the SMPL output. This module can be seen as an autoencoder where the encoder is a deep neural network and the decoder is SMPL model. We refer to this as SMPL reverse (SMPLR). By implementing SMPLR as an encoder-decoder we avoid the need of complex constraints on pose and shape. Furthermore, given that in-the-wild datasets usually lack accurate 3D annotations, it is desirable to lift 2D joints to 3D without pairing 3D annotations with RGB images. Therefore, we also propose a denoising autoencoder (DAE) module between CNN and SMPLR, able to lift 2D joints to 3D and partially recover from structured error. We evaluate our method on SURREAL and Human3.6M datasets, showing improvement over SMPL-based state-of-the-art alternatives by about 4 and 12 mm, respectively. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107472	10.1016/j.patcog.2020.107472													
J								Non-rigid infrared and visible image registration by enhanced affine transformation	PATTERN RECOGNITION										Registration; Non-rigid transformation; Infrared image; Image fusion	FUSION; ALGORITHM; SPLINES	Image registration is a prerequisite for infrared (IR) and visible (VIS) image fusion. In practical application, most scenes are not planar and there is significant distinctness between IR and VIS cameras. Therefore, for non-rigid IR and VIS image registration, non-linear transformation is more applicable than affine transformation. Typically, non-linear transformation is modeled with point feature. However, this can degrade the generalization ability of transformation model and increase computational complexity. Aim at this problem, we propose an enhanced affine transformation (EAT) for non-rigid IR and VIS image registration. In this paper, image registration is transformed into point set registration and then the optimal EAT model constructed by global deformation is estimated from local feature. At first, a Gaussian-fields-based objective function is established and simplified by using the potential correspondence between an image pair. With the combination of affine and polynomial transformation, the EAT model is then proposed to describe the regular pattern of non-rigid and global deformation between an image pair. Finally, a coarse-to-fine strategy based on quasi-Newton method is designed and applied to determine the optimal transformation coefficients from edge point feature of IR and VIS images, in order to accomplish non-rigid image registration. The qualitative and quantitative comparisons on synthesized point sets and real images demonstrate that the proposed method is superior over the state-of-the-art methods in the accuracy and efficiency of image registration. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107377	10.1016/j.patcog.2020.107377													
J								U-2-Net: Going deeper with nested U-structure for salient object detection	PATTERN RECOGNITION										Salient object detection; Convolutional neural network; Network architecture design; Nested U-structure; Multi-scale feature extraction		In this paper, we design a simple yet powerful deep network architecture, U-2-Net, for salient object detection (SOD). The architecture of our U-2-Net is a two-level nested U-structure. The design has the following advantages: (1) it is able to capture more contextual information from different scales thanks to the mixture of receptive fields of different sizes in our proposed ReSidual U-blocks (RSU), (2) it increases the depth of the whole architecture without significantly increasing the computational cost because of the pooling operations used in these RSU blocks. This architecture enables us to train a deep network from scratch without using backbones from image classification tasks. We instantiate two models of the proposed architecture, U-2-Net (176.3 MB, 30 FPS on GTX 1080Ti GPU) and U-2-Nett (4.7 MB, 40 FPS), to facilitate the usage in different environments. Both models achieve competitive performance on six SOD datasets. The code is available: https://github.com/NathanUA/U-2-Net. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107404	10.1016/j.patcog.2020.107404													
J								Manifold learning for user profiling and identity verification using motion sensors	PATTERN RECOGNITION										User profiling; Motion sensor; Gait; Manifold learning; Open-set user profiling; Cross-dataset user profiling	GAIT; PERFORMANCE	Mobile devices are becoming ubiquitous and being increasingly used for data-sensitive activities such as communication, personal media storage, and banking. The protection of such data commonly relies on passwords and biometric traits such as fingerprints. These methods perform the user authentication sporadically and often require action from the user, which may make them susceptible to spoofing attacks. This scenario can be mitigated if we bring to bear motion-sensing based methods for authentication, which operate continuously and without requiring user action, hence are harder to attack. Such methods could be used allied with traditional authentication methods or on their own. This paper explores this idea in a novel user-agnostic approach for identity verification based on motion traits acquired by mobile sensors. The proposed approach does not require user-specific training before deployment in mobile devices nor does it require any extra sensor in the device. This solution is capable of learning a user profiling manifold from a small user subset and extend it to unknown users. We validated the proposal on two public datasets. The reported experiments demonstrate remarkable results under a cross-dataset protocol and an open-set setup. Moreover, we performed several analyses aiming at answering critical questions of a biometric method and the presented solution. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107408	10.1016/j.patcog.2020.107408													
J								Can we automate diagrammatic reasoning?	PATTERN RECOGNITION										Abstract reasoning; Raven,s Progressive Matrices (RPM); Diagrammatic reasoning; Visual IQ test	FUSION	Diagrammatic reasoning (DR) problems are well known. However, solving DR problems represented in 4 x 1 Raven's Progressive Matrix (RPM) form using computer vision and pattern recognition has not yet been tried. Emergence of deep learning techniques aided by advanced computing can be exploited to solve such DR problems. In this paper, we propose a new learning framework by combining LSTM and Convolutional LSTM to solve 4 x 1 DR problems. Initially, the elementary geometrical shapes in such problems are detected using a typical CNN-based detector. Next, relations of various shapes are analyzed and a high-level feature set is produced and processed in the LSTM framework. A new 4 x 1 DR dataset has been prepared and made available to the research community. We believe, it will be helpful in advancing this research further. We have compared our method with some of the existing frameworks that can be used for solving RPM-guided DR problems. We have recorded 18-20% increase in the average prediction accuracy as compared to the prior frameworks when applied to RPM-guided DR problems. We believe the CV research community will be interested to carry out similar research, particularly to investigate the feasibility of solving other types of known DR problems. (C) 2020 The Author(s). Published by Elsevier Ltd.																	0031-3203	1873-5142				OCT	2020	106								107412	10.1016/j.patcog.2020.107412													
J								Adaptive ROI generation for video object segmentation using reinforcement learning	PATTERN RECOGNITION										Model adaptation; Video object segmentation; Reinforcement learning; Training accelerate		The task of the proposed method is semi-supervised video object segmentation where only the ground-truth segmentation of the first frame is provided. The existing approaches rely on selecting the region of interest for model update; however it is rough and inflexible, leading to performance degradation. To overcome this limitation, a novel approach is proposed which utilizes reinforcement learning to select optimal adaptation areas for each frame, based on the historical segmentation information. The RL model learns to take optimal actions to adjust the region of interest inferred from the previous frame for online model updating. To speed up the model adaption, a novel multi-branch tree based exploration method is designed to quickly select the best state action pairs. The proposed method is evaluated on three common video object segmentation datasets including DAVIS 2016, SegTrack V2 and Youtube-Object. The results show that the proposed work improves the state-of-the-art of the mean region similarity to 87.1% on the DAVIS 2016 dataset, and to 79.5% on the Youtube-Object dataset. Meanwhile, competitive performance is obtained on the SegTrack V2 dataset. Code is at https://github.com/insomnia94/ARG. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107465	10.1016/j.patcog.2020.107465													
J								Ellipse fitting by spatial averaging of random ensembles	PATTERN RECOGNITION										Ellipse fitting; Geometric curve fitting; Ensemble methods; Spatial median; Robust estimation	ROBUST ELLIPSE; TUTORIAL; CIRCLE	Earlier ellipse fitting methods often consider the algebraic and geometric forms of the ellipse. The work presented here makes use of an ensemble to provide better results. The method proposes a new ellipse parametrization based on the coordinates of both foci, and the distance between them and each point of the ellipse where the Euclidean norm is applied. Besides, a certain number of subsets are uniformly drawn without replacement from the overall training set which allows estimating the center of the distribution robustly by employing the L1 median of each estimated focus. An additional postprocessing stage is proposed to filter out the effect of bad fits. In order to evaluate the performance of this method, four different error measures were considered. Results show that our proposal outperforms all its competitors, especially when higher levels of outliers are presented. Several synthetic and real data tests were developed and confirmed such finding. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107406	10.1016/j.patcog.2020.107406													
J								Improving the performance of lightweight CNNs for binary classification using quadratic mutual information regularization	PATTERN RECOGNITION										Hinge loss; Cross entropy loss; Binary classification problems; Quadratic mutual information; Regularizer; Lightweight models; Real-time; Convolutional neural networks; Deep learning	NEURAL-NETWORKS; DEEP	In this paper, we propose regularized lightweight deep convolutional neural network models, capable of effectively operating in real-time on-drone for high-resolution video input. Furthermore, we study the impact of hinge loss against the cross entropy loss on the classification performance, mainly in binary classification problems. Finally, we propose a novel regularization method motivated by the Quadratic Mutual Information, in order to improve the generalization ability of the utilized models. Extensive experiments on various binary classification problems involved in autonomous systems are performed, indicating the effectiveness of the proposed models. The experimental evaluation on four datasets indicates that hinge loss is the optimal choice for binary classification problems, considering lightweight deep models. Finally, the effectiveness of the proposed regularizer in enhancing the generalization ability of the proposed models is also validated. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107407	10.1016/j.patcog.2020.107407													
J								Multistage attention network for image inpainting	PATTERN RECOGNITION										Image inpainting; Irregular mask; Deep learning; Attention mechanism; Unet-like network	FILTER	Image inpainting refers to the process of restoring the mask regions of damaged images. Existing inpainting algorithms have exhibited outstanding performance on certain inpainting tasks that are focused on recovering small masks or square masks. Tasks that attempt to reconstruct large proportion of damaged images can still be improved. Although many attention-related algorithms have been proposed to solve image inpainting tasks, most of them ignore the requirements to balancing the detail and style level. In this paper, we propose a novel image inpainting method for large-scale irregular masks. We introduce a special multistage attention module that considers structure consistency and detail fineness. The proposed multistage attention module operates in a coarse to-fine manner, where the early stage performs large feature patch swapping and ensures the global consistency in images, and the next stage swaps small patches to refine the texture. Then, we adopt a partial convolution strategy to avoid the misuse of invalid data during convolution. Several losses are combined as the training objective function to generate excellent results with global consistency and exquisite detail. Qualitative and quantitative experiments on the Paris StreetView, CelebA, and Places2 datasets demonstrate the superior performance of the proposed approach compared with state-of-the-art models. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107448	10.1016/j.patcog.2020.107448													
J								Building outline extraction from ALS point clouds using medial axis transform descriptors	PATTERN RECOGNITION										Skeleton; Point cloud; Building outline; Medial axis transform; Segmentation	3D SKELETONS; ALGORITHMS; SHAPE; REPRESENTATION; CENTERLINES; COMPUTATION; CURVE	Automatic building extraction and delineation from airborne LiDAR point cloud data of urban environments is still a challenging task due to the variety and complexity at which buildings appear. The Medial Axis Transform (MAT) is able to describe the geometric shape and topology of an object, but has never been applied for building roof outline extraction. It represents the shape of an object by its centerline, or skeleton structure instead of its boundary. Notably, end points of the MAT in principle coincide with corner points of building outlines. However, the MAT is sensitive to small boundary irregularities, which makes shape detection in airborne point clouds challenging. We propose a robust MAT-based method for detecting building corner points, which are then connected to form a building boundary polygon. First, we approximate the 2D MAT of a set of building edge points acquired by the alpha-shape algorithm to derive a so-called building roof skeleton. We then propose a hierarchical corner-aware segmentation to cluster skeleton points based on their properties which are the so-called separation angle, radius of the maximally inscribe circle, and defining edge point indices. From each segment, a corner point is then estimated by extrapolating the position of the zero radius inscribed circle based on the skeleton point positions within the segment. Our experiment uses point cloud datasets of Makassar, Indonesia and EYE-Amsterdam, The Netherlands. The average positional accuracy of the building outline results for Makassar and EYE-Amsterdam is 65 cm and 70 cm, respectively, which meet one-meter base map accuracy criteria. The results imply that skeletonization is a promising tool to extract relevant geometric information on e.g. building outlines even from far from perfect geographical point cloud data. (C) 2020 The Author(s). Published by Elsevier Ltd.																	0031-3203	1873-5142				OCT	2020	106								107447	10.1016/j.patcog.2020.107447													
J								Probabilistic SVM classifier ensemble selection based on GMDH-type neural network	PATTERN RECOGNITION										Probabilistic SVM; Group method of data handling; Ensemble selection; Regularity criterion; Borda sorting	SUPPORT VECTOR MACHINE; RANDOM SUBSPACE; PREDICTION	Support vector machine (SVM) provides a good classification and regression ability, especially, for small sample learning. However, in practice, the learning ability of implemented SVM is occasionally far from the expected level. Group method of data handling neural network (GMDH-NN) has been applied in various fields for pattern recognition and data mining. It makes it possible to automatically find interrelations in data, to select an optimal structure of network or model and to improve the accuracy of existing algorithms. In this work we propose to take the advantages of GMDH-NN for further increasing the classification performance of SVM. One weakness of the symmetric regularity criterion of GMDH-NN is that if one of the input attributes has a relatively big range, then it may overcome the other attributes. Thus, we first define a standardized symmetric regularity criterion (SSRC) to evaluate and select the candidate models, and optimize a classifier ensemble selection approach. Secondly, we define a novel structure of initial model of GMDH-NN which is from the posterior probability outputs of SVMs. These probabilistic outputs are generated from the improved Platt's probabilistic outputs. Thirdly, in real classification tasks, different classifiers usually have different classification advantages. So we use probabilistic SVM as base learner and integrate the probabilistic SVMs with GMDH-NN, and then propose a special classifier ensemble selection approach for probabilistic SVM classifiers based on GMDH-NN called GMDH-PSVM. Moreover, we use the Borda sorting and Random weighted Borda sorting to discuss the results of our experiments. Experiments on standard UCI datasets demonstrate the effectiveness of our method. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107373	10.1016/j.patcog.2020.107373													
J								Data-augmented matched subspace detector for hyperspectral subpixel target detection	PATTERN RECOGNITION										Hyperspectral imaging; Matched subspace detector (MSD); Subpixel target detection; Data augmentation	MODEL	The performance of subspace-based methods such as matched subspace detector (MSD) and MSD with interaction effects (MSDinter) heavily depends on the background subspace and the target subspace. Nonetheless, constructing a representative target subspace is challenging due to the limited availability of target spectra in a collected hyperspectral image. In this paper, we propose two new hyperspectral target detection methods termed data-augmented MSD (DAMSD) and data-augmented MSDinter (DAMSDI) that can effectively solve the scarcity problem of target spectra and from which a representative target-background mixed subspace can be learned. We first synthesise target-background mixed spectra based on classical hyperspectral mixing models and then learn a target-background mixed subspace via principal component analysis. Compared with MSD and MSDinter, the learned mixed subspace is more representative as spectral variability of target spectra is explained to the largest extent and it leads to an improvement in computational speed and numerical stability. We demonstrate the efficacy of DAMSD and DAMSDI for subpixel target detection on two public hyperspectral image datasets. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107464	10.1016/j.patcog.2020.107464													
J								A novel online action detection framework from untrimmed video streams	PATTERN RECOGNITION										Online action detection; Untrimmed video stream; Future frame generation; 3D convolutional neural network; Long short-term memory	HUMAN ACTION RECOGNITION	Online temporal action localization from an untrimmed video stream is a challenging problem in computer vision. It is challenging because of i) in an untrimmed video stream, more than one action instance may appear, including background scenes, and ii) in online settings, only past and current information is available. Therefore, temporal priors, such as the average action duration of training data, which have been exploited by previous action detection methods, are not suitable for this task because of the high intra-class variation in human actions. We propose a novel online action detection framework that considers actions as a set of temporally ordered subclasses and leverages a future frame generation network to cope with the limited information issue associated with the problem outlined above. Additionally, we augment our data by varying the lengths of videos to allow the proposed method to learn about the high intra-class variation in human actions. We evaluate our method using two benchmark datasets, THUMOS'14 and ActivityNet, for an online temporal action localization scenario and demonstrate that the performance is comparable to state-of-the-art methods that have been proposed for offline settings. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107396	10.1016/j.patcog.2020.107396													
J								Fast matching via ergodic markov chain for super-large graphs	PATTERN RECOGNITION										Spectral matching; Graph matching; Ergodic markov chain; Space complexity		In theory, graph matching is a combinatorial problem. One state-of-the-art technique in graph matching, called spectral matching, relaxes the matching problem for consistent correspondence into spectral decomposition of the affinity matrix of graphs, but the most variations of spectral based algorithms suffer from their O(n(4)) memory requirement. In this paper we propose a probabilistic spectral matching approach, in which the graph matching problem is formulated as an ergodic Markov chain, and the process of matching is addressed to reach the steady-state of the Markov chain. The approach decomposes the probability transition matrix, and solves the matching problem in O(n(2)) space complexity using limited computing resource and RAM. This property makes the approach suitable for super-large graphs matching (for example, graphs with the number of points over 1000). We evaluate our algorithm on both the synthetic and the real datasets, and demonstrate that the proposed approach is significantly faster, and consumes smaller memory than SM, RRWM and FaSM with no loss of accuracy. (C) 2020 Elsevier Ltd. All rights reserved.																	0031-3203	1873-5142				OCT	2020	106								107418	10.1016/j.patcog.2020.107418													
J								Baptizo: A sensor fusion based model for tracking the identity of human poses	INFORMATION FUSION											ACTIVITY RECOGNITION; MULTISENSOR FUSION; NETWORKS; VISION; PEOPLE; KINECT																		1566-2535	1872-6305				OCT	2020	62						1	13		10.1016/j.inffus.2020.03.011													
J								A Quantum -Like multimodal network framework for modeling interaction dynamics in multiparty conversational sentiment analysis	INFORMATION FUSION											AUDIO; TEXT; CLASSIFICATION; FUSION; SYSTEM																		1566-2535	1872-6305				OCT	2020	62						14	31		10.1016/j.inffus.2020.04.003													
J								DependData: Data collection dependability through three -layer decision -making in BSNs for healthcare monitoring	INFORMATION FUSION											DATA FUSION; SENSOR; BODY																		1566-2535	1872-6305				OCT	2020	62						32	46		10.1016/j.inffus.2020.03.004													
J								Classical and deep learning methods for recognizing human activities and modes of transportation with smartphone sensors ?	INFORMATION FUSION											MOBILE																		1566-2535	1872-6305				OCT	2020	62						47	62		10.1016/j.inffus.2020.04.004													
J								General multi -view semi -supervised least squares support vector machines with multi -manifold regularization	INFORMATION FUSION											CLASSIFICATION																		1566-2535	1872-6305				OCT	2020	62						63	72		10.1016/j.inffus.2020.04.005													
J								MNIST-NET10: A heterogeneous deep networks fusion based on the degree of certainty to reach 0.1% error rate. Ensembles overview and proposal	INFORMATION FUSION											AUTOENCODERS; PERFORMANCE; CLASSIFIERS																		1566-2535	1872-6305				OCT	2020	62						73	80		10.1016/j.inffus.2020.04.002													
J								Target tracking in the framework of possibility theory: The possibilistic Bernoulli filter	INFORMATION FUSION											PROBABILITIES; TUTORIAL																		1566-2535	1872-6305				OCT	2020	62						81	88		10.1016/j.inffus.2020.04.008													
J								A survey on secure communication techniques for 5G wireless heterogeneous networks	INFORMATION FUSION											PUBLIC-KEY ENCRYPTION; ATTRIBUTE-BASED ENCRYPTION; PROXY RE-ENCRYPTION; IDENTITY-BASED ENCRYPTION; SEARCHABLE SYMMETRIC-ENCRYPTION; IMAGE ENCRYPTION; AUTHENTICATED ENCRYPTION; ELLIPTIC CURVE; CHAOTIC SYSTEM; BROADCAST ENCRYPTION																		1566-2535	1872-6305				OCT	2020	62						89	109		10.1016/j.inffus.2020.04.009													
J								Pan-GAN: An unsupervised pan -sharpening method for remote sensing image fusion	INFORMATION FUSION											MULTISPECTRAL IMAGES; GENERAL FRAMEWORK; LANDSAT TM; RESOLUTION; REGISTRATION; TRANSFORM; MS																		1566-2535	1872-6305				OCT	2020	62						110	120		10.1016/j.inffus.2020.04.006													
J								A Choquet integral -based hesitant fuzzy gained and lost dominance score method for multi -criteria group decision making considering the risk preferences of experts: Case study of higher business education evaluation	INFORMATION FUSION											LINGUISTIC TERM SETS; OF-THE-ART; PROSPECT-THEORY; INFORMATION FUSION; AGGREGATION; HIERARCHY; DISTANCE; ORDERS; TOPSIS																		1566-2535	1872-6305				OCT	2020	62						121	133		10.1016/j.inffus.2020.05.003													
J								Kernelized fuzzy rough sets based online streaming feature selection for large-scale hierarchical classification	APPLIED INTELLIGENCE										Online feature selection; Hierarchical classification; Kernelized fuzzy rough sets; Sibling strategy	KRILL HERD ALGORITHM	In recent years, many online streaming feature selection approaches focus on flat data, which means that all data are taken as a whole. However, in the era of big data, not only the feature space of data has unknown and evolutionary characteristics, but also the label space of data exists hierarchical structure. To address this problem, an online streaming feature selection framework for large-scale hierarchical classification task is proposed. The framework consists of three parts: (1) a new hierarchical data-oriented kernelized fuzzy rough model with sibling strategy is constructed, (2) the online important feature is selected based on feature correlation analysis, and (3) the online redundant feature is deleted based on feature redundancy. Finally, an empirical study using several hierarchical classification data sets manifests that the proposed method outperforms other state-of-the-art online streaming feature selection methods.																	0924-669X	1573-7497															10.1007/s10489-020-01863-5		SEP 2020											
J								Proof searching and prediction in HOL4 with evolutionary/heuristic and deep learning techniques	APPLIED INTELLIGENCE										HOL4; Genetic algorithm; Simulated Annealing; LSTM; Proof searching; Proof learning; Fitness		Interactive theorem provers (ITPs), also known as proof assistants, allow human users to write and verify formal proofs. The proof development process in ITPs can be a cumbersome and time-consuming activity due to manual user interactions. This makes proof guidance and proof automation the two most desired features for ITPs. In this paper, we first provide two evolutionary and heuristic-based proof searching approaches for the HOL4 proof assistant, where a genetic algorithm (GA) and simulated annealing (SA) is used to search and optimize the proofs in different HOL theories. In both approaches, random proof sequences are first generated from a population of frequently occurring HOL4 proof steps that are discovered with sequential pattern mining. Generated proof sequences are then evolved using GA operators (crossover and mutation) and by applying the annealing process of SA till their fitness match the fitness of the target proof sequences. Experiments were done to compare the performance of SA with that of GA. Results have shown that the two proof searching approaches can be used to efficiently evolve the random sequences to obtain the target sequences. However, these approaches lack the ability to learn the proof process, that is important for the prediction of new proof sequences. For this purpose, we propose to use a deep learning technique known as long short-term memory (LSTM). LSTM is trained on various HOL4 theories for proof learning and prediction. Experimental results suggest that combining evolutionary/heuristic and deep learning techniques with proof assistants can greatly facilitate proof finding/optimization and proof prediction.																	0924-669X	1573-7497															10.1007/s10489-020-01837-7		SEP 2020											
J								Novel First Order Bayesian Optimization with an Application to Reinforcement Learning	APPLIED INTELLIGENCE										Bayesian optimization; Reinforcement learning; First order methods; Policy gradient	GRADIENT; POLICY	Zeroth Order Bayesian Optimization (ZOBO) methods optimize an unknown function based on its black-box evaluations at the query locations. Unlike most optimization procedures, ZOBO methods fail to utilize gradient information even when it is available. On the other hand, First Order Bayesian Optimization (FOBO) methods exploit the available gradient information to arrive at better solutions faster. However, the existing FOBO methods do not utilize a crucial information that the gradient is zero at the optima. Further, the inherent sequential nature of the FOBO methods incur high computational cost limiting their wide applicability. To alleviate the aforementioned difficulties of FOBO methods, we propose a relaxed statistical model to leverage the gradient information that directly searches for points where gradient vanishes. To accomplish this, we develop novel acquisition algorithms that search for global optima effectively. Unlike the existing FOBO methods, the proposed methods are parallelizable. Through extensive experimentation on standard test functions, we compare the performance of our methods over the existing methods. Furthermore, we explore an application of the proposed FOBO methods in the context of policy gradient reinforcement learning.																	0924-669X	1573-7497															10.1007/s10489-020-01896-w		SEP 2020											
J								Text categorization: past and present	ARTIFICIAL INTELLIGENCE REVIEW										Text categorization; Conventional methods; Fuzzy logic; Deep learning; Nature-inspired algorithms; Graph-based methods	TERM WEIGHTING SCHEMES; FEATURE-SELECTION; FUZZY SIMILARITY; CLASSIFICATION; REPRESENTATION; DOCUMENTS; MODEL; FRAMEWORK	Automatic text categorization is the operation of sorting out the text documents into pre-defined text categories using some machine learning algorithms. Normally, it defines the most important approaches to organizing and making the use of a large volume of information exists in unstructured form. Nowadays, text categorization is becoming an extensively researched field of text mining and processing of languages. Word sense, semantic relationships among terms, text documents and categories are quite essential in order of enhancing the performances of categorization. Various surveys on text categorization have already been available which involve techniques of various text representation schemes to such extent but do not include several approaches that have been explored in text categorization over the standard techniques. Here, an exhaustive analysis of different text categorization approaches over the conventional approaches has been undertaken. This survey paper explores a wide variety of algorithms used for categorizing text documents and tries to assemble the existing works into three basic fields: conventional methods, fuzzy logic-based methods, deep learning-based methods. Further, conventional methods have been categorized into three fields: text categorization using handcrafted features, text categorization using nature-inspired algorithms and text categorization using graph-based methods. Furthermore, this survey provides a clear idea about the available libraries used for different algorithms, availability of datasets, categorization technologies explored in various non-Indian and Indian languages as well.																	0269-2821	1573-7462															10.1007/s10462-020-09919-1		SEP 2020											
J								Tensor decomposition for analysing time-evolving social networks: an overview	ARTIFICIAL INTELLIGENCE REVIEW										Social networks; Tensor decomposition; Time evolution; Network analysis	ANOMALY DETECTION; COMPONENTS; MODELS; SPARSE; FACTORIZATION; ALGORITHMS; NUMBERS	Social networks are becoming larger and more complex as new ways of collecting social interaction data arise (namely from online social networks, mobile devices sensors, ...). These networks are often large-scale and of high dimensionality. Therefore, dealing with such networks became a challenging task. An intuitive way to deal with this complexity is to resort to tensors. In this context, the application of tensor decomposition has proven its usefulness in modelling and mining these networks: it has not only been applied for exploratory analysis (thus allowing the discovery of interaction patterns), but also for more demanding and elaborated tasks such as community detection and link prediction. In this work, we provide an overview of the methods based on tensor decomposition for the purpose of analysing time-evolving social networks from various perspectives: from community detection, link prediction and anomaly/event detection to network summarization and visualization. In more detail, we discuss the ideas exploited to carry out each social network analysis task as well as its limitations in order to give a complete coverage of the topic.																	0269-2821	1573-7462															10.1007/s10462-020-09916-4		SEP 2020											
J								Reinforcement based mobile robot path planning with improved dynamic window approach in unknown environment	AUTONOMOUS ROBOTS										Robot navigation; Path planning; DWA; Q-learning; Evaluation function	POTENTIAL-FIELD METHOD; NAVIGATION; OPTIMIZATION; UNCERTAINTY; SEARCH	Mobile robot path planning in an unknown environment is a fundamental and challenging problem in the field of robotics. Dynamic window approach (DWA) is an effective method of local path planning, however some of its evaluation functions are inadequate and the algorithm for choosing the weights of these functions is lacking, which makes it highly dependent on the global reference and prone to fail in an unknown environment. In this paper, an improved DWA based on Q-learning is proposed. First, the original evaluation functions are modified and extended by adding two new evaluation functions to enhance the performance of global navigation. Then, considering the balance of effectiveness and speed, we define the state space, action space and reward function of the adopted Q-learning algorithm for the robot motion planning. After that, the parameters of the proposed DWA are adaptively learned by Q-learning and a trained agent is obtained to adapt to the unknown environment. At last, by a series of comparative simulations, the proposed method shows higher navigation efficiency and successful rate in the complex unknown environment. The proposed method is also validated in experiments based on XQ-4 Pro robot to verify its navigation capability in both static and dynamic environment.																	0929-5593	1573-7527															10.1007/s10514-020-09947-4		SEP 2020											
